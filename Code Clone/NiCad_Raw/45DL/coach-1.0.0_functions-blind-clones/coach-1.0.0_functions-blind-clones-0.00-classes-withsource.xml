<clones>
<systeminfo processor="nicad6" system="coach-1.0.0" granularity="functions-blind" threshold="0%" minlines="10" maxlines="2500"/>
<cloneinfo npcs="1771" npairs="12"/>
<runinfo ncompares="7001" cputime="62924"/>
<classinfo nclasses="8"/>

<class classid="1" nclones="2" nlines="10" similarity="100">
<source file="systems/coach-1.0.0/rl_coach/tests/test_golden.py" startline="36" endline="47" pcid="716">
def read_csv_paths(test_path, filename_pattern, read_csv_tries=200):
    csv_paths = []
    tries_counter = 0
    while not csv_paths:
        csv_paths = glob.glob(path.join(test_path, '*', filename_pattern))
        if tries_counter > read_csv_tries:
            break
        tries_counter += 1
        time.sleep(1)
    return csv_paths


</source>
<source file="systems/coach-1.0.0/rl_coach/tests/trace_tests.py" startline="52" endline="63" pcid="856">
def read_csv_paths(test_path, filename_pattern, read_csv_tries=100):
    csv_paths = []
    tries_counter = 0
    while not csv_paths:
        csv_paths = glob.glob(path.join(test_path, '*', filename_pattern))
        if tries_counter > read_csv_tries:
            break
        tries_counter += 1
        time.sleep(1)
    return csv_paths


</source>
</class>

<class classid="2" nclones="2" nlines="15" similarity="100">
<source file="systems/coach-1.0.0/rl_coach/tests/test_dist_coach.py" startline="11" endline="35" pcid="782">
def generate_config(image, memory_backend, s3_end_point, s3_bucket_name, s3_creds_file, config_file):
    """
    Generate the s3 config file to be used and also the dist-coach-config.template to be used for the test
    It reads the `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` env vars and fails if they are not provided.
    """
    # Write s3 creds
    aws_config = ConfigParser({
        'aws_access_key_id': os.environ.get('AWS_ACCESS_KEY_ID'),
        'aws_secret_access_key': os.environ.get('AWS_SECRET_ACCESS_KEY')
    }, default_section='default')
    with open(s3_creds_file, 'w') as f:
        aws_config.write(f)

    coach_config = ConfigParser({
        'image': image,
        'memory_backend': memory_backend,
        'data_store': 's3',
        's3_end_point': s3_end_point,
        's3_bucket_name': s3_bucket_name,
        's3_creds_file': s3_creds_file
    }, default_section="coach")
    with open(config_file, 'w') as f:
        coach_config.write(f)


</source>
<source file="systems/coach-1.0.0/rl_coach/tests/trace_tests.py" startline="174" endline="198" pcid="860">
def generate_config(image, memory_backend, s3_end_point, s3_bucket_name, s3_creds_file, config_file):
    """
    Generate the s3 config file to be used and also the dist-coach-config.template to be used for the test
    It reads the `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` env vars and fails if they are not provided.
    """
    # Write s3 creds
    aws_config = ConfigParser({
        'aws_access_key_id': os.environ.get('AWS_ACCESS_KEY_ID'),
        'aws_secret_access_key': os.environ.get('AWS_SECRET_ACCESS_KEY')
    }, default_section='default')
    with open(s3_creds_file, 'w') as f:
        aws_config.write(f)

    coach_config = ConfigParser({
        'image': image,
        'memory_backend': memory_backend,
        'data_store': 's3',
        's3_end_point': s3_end_point,
        's3_bucket_name': s3_bucket_name,
        's3_creds_file': s3_creds_file
    }, default_section="coach")
    with open(config_file, 'w') as f:
        coach_config.write(f)


</source>
</class>

<class classid="3" nclones="2" nlines="15" similarity="100">
<source file="systems/coach-1.0.0/rl_coach/tests/architectures/mxnet_components/heads/test_q_head.py" startline="46" endline="60" pcid="899">
def test_ppo_v_head():
    agent_parameters = ClippedPPOAgentParameters()
    num_actions = 5
    action_space = DiscreteActionSpace(num_actions=num_actions)
    spaces = SpacesDefinition(state=None, goal=None, action=action_space, reward=None)
    value_net = QHead(agent_parameters=agent_parameters,
                      spaces=spaces,
                      network_name="test_q_head")
    value_net.initialize()
    batch_size = 15
    middleware_data = mx.nd.random.uniform(shape=(batch_size, 100))
    values = value_net(middleware_data)
    assert values.ndim == 2  # (batch_size, num_actions)
    assert values.shape[0] == batch_size
    assert values.shape[1] == num_actions
</source>
<source file="systems/coach-1.0.0/rl_coach/tests/architectures/mxnet_components/heads/test_ppo_head.py" startline="389" endline="405" pcid="926">
@pytest.mark.unit_test
def test_ppo_head():
    agent_parameters = ClippedPPOAgentParameters()
    num_actions = 5
    action_space = DiscreteActionSpace(num_actions=num_actions)
    spaces = SpacesDefinition(state=None, goal=None, action=action_space, reward=None)
    head = PPOHead(agent_parameters=agent_parameters,
                   spaces=spaces,
                   network_name="test_ppo_head")

    head.initialize()

    batch_size = 15
    middleware_data = mx.nd.random.uniform(shape=(batch_size, 100))
    probs = head(middleware_data)
    assert probs.ndim == 2  # (batch_size, num_actions)
    assert probs.shape[0] == batch_size
</source>
</class>

<class classid="4" nclones="2" nlines="13" similarity="100">
<source file="systems/coach-1.0.0/rl_coach/tests/architectures/mxnet_components/heads/test_v_head.py" startline="45" endline="57" pcid="902">
def test_ppo_v_head():
    agent_parameters = ClippedPPOAgentParameters()
    action_space = DiscreteActionSpace(num_actions=5)
    spaces = SpacesDefinition(state=None, goal=None, action=action_space, reward=None)
    value_net = VHead(agent_parameters=agent_parameters,
                      spaces=spaces,
                      network_name="test_v_head")
    value_net.initialize()
    batch_size = 15
    middleware_data = mx.nd.random.uniform(shape=(batch_size, 100))
    values = value_net(middleware_data)
    assert values.ndim == 1  # (batch_size)
    assert values.shape[0] == batch_size
</source>
<source file="systems/coach-1.0.0/rl_coach/tests/architectures/mxnet_components/heads/test_ppo_v_head.py" startline="78" endline="90" pcid="906">
def test_ppo_v_head():
    agent_parameters = ClippedPPOAgentParameters()
    action_space = DiscreteActionSpace(num_actions=5)
    spaces = SpacesDefinition(state=None, goal=None, action=action_space, reward=None)
    value_net = PPOVHead(agent_parameters=agent_parameters,
                         spaces=spaces,
                         network_name="test_ppo_v_head")
    value_net.initialize()
    batch_size = 15
    middleware_data = mx.nd.random.uniform(shape=(batch_size, 100))
    values = value_net(middleware_data)
    assert values.ndim == 1  # (batch_size)
    assert values.shape[0] == batch_size
</source>
</class>

<class classid="5" nclones="2" nlines="10" similarity="100">
<source file="systems/coach-1.0.0/rl_coach/memories/episodic/episodic_experience_replay.py" startline="319" endline="336" pcid="1037">
    def get_episode(self, episode_index: int, lock: bool = True) -> Union[None, Episode]:
        """
        Returns the episode in the given index. If the episode does not exist, returns None instead.
        :param episode_index: the index of the episode to return
        :return: the corresponding episode
        """
        if lock:
            self.reader_writer_lock.lock_writing()

        if self.length() == 0 or episode_index >= self.length():
            episode = None
        else:
            episode = self._buffer[episode_index]

        if lock:
            self.reader_writer_lock.release_writing()
        return episode

</source>
<source file="systems/coach-1.0.0/rl_coach/memories/non_episodic/experience_replay.py" startline="152" endline="171" pcid="1064">
    def get_transition(self, transition_index: int, lock: bool=True) -> Union[None, Transition]:
        """
        Returns the transition in the given index. If the transition does not exist, returns None instead.
        :param transition_index: the index of the transition to return
        :param lock: use write locking if this is a shared memory
        :return: the corresponding transition
        """
        if lock:
            self.reader_writer_lock.lock_writing()

        if self.length() == 0 or transition_index >= self.length():
            transition = None
        else:
            transition = self.transitions[transition_index]

        if lock:
            self.reader_writer_lock.release_writing()

        return transition

</source>
</class>

<class classid="6" nclones="3" nlines="10" similarity="100">
<source file="systems/coach-1.0.0/rl_coach/architectures/head_parameters.py" startline="51" endline="62" pcid="1433">
    def __init__(self, activation_function: str ='relu', name: str='v_head_params',
                 num_output_head_copies: int = 1, rescale_gradient_from_head_by_factor: float = 1.0,
                 loss_weight: float = 1.0, dense_layer=None, initializer='normalized_columns',
                 output_bias_initializer=None):
        super().__init__(parameterized_class_name="VHead", activation_function=activation_function, name=name,
                         dense_layer=dense_layer, num_output_head_copies=num_output_head_copies,
                         rescale_gradient_from_head_by_factor=rescale_gradient_from_head_by_factor,
                         loss_weight=loss_weight)
        self.initializer = initializer
        self.output_bias_initializer = output_bias_initializer


</source>
<source file="systems/coach-1.0.0/rl_coach/architectures/head_parameters.py" startline="240" endline="249" pcid="1451">
    def __init__(self, activation_function: str ='relu', name: str='td3_v_head_params',
                 num_output_head_copies: int = 1, rescale_gradient_from_head_by_factor: float = 1.0,
                 loss_weight: float = 1.0, dense_layer=None, initializer='xavier',
                 output_bias_initializer=None):
        super().__init__(parameterized_class_name="TD3VHead", activation_function=activation_function, name=name,
                         dense_layer=dense_layer, num_output_head_copies=num_output_head_copies,
                         rescale_gradient_from_head_by_factor=rescale_gradient_from_head_by_factor,
                         loss_weight=loss_weight)
        self.initializer = initializer
        self.output_bias_initializer = output_bias_initializer
</source>
<source file="systems/coach-1.0.0/rl_coach/architectures/head_parameters.py" startline="64" endline="75" pcid="1434">
    def __init__(self, activation_function: str ='relu', name: str='ddpg_v_head_params',
                 num_output_head_copies: int = 1, rescale_gradient_from_head_by_factor: float = 1.0,
                 loss_weight: float = 1.0, dense_layer=None, initializer='normalized_columns',
                 output_bias_initializer=None):
        super().__init__(parameterized_class_name="DDPGVHead", activation_function=activation_function, name=name,
                         dense_layer=dense_layer, num_output_head_copies=num_output_head_copies,
                         rescale_gradient_from_head_by_factor=rescale_gradient_from_head_by_factor,
                         loss_weight=loss_weight)
        self.initializer = initializer
        self.output_bias_initializer = output_bias_initializer


</source>
</class>

<class classid="7" nclones="2" nlines="15" similarity="100">
<source file="systems/coach-1.0.0/rl_coach/architectures/mxnet_components/middlewares/fc_middleware.py" startline="39" endline="68" pcid="1510">
    def schemes(self) -> dict:
        """
        Schemes are the pre-defined network architectures of various depths and complexities that can be used for the
        Middleware. Are used to create Block when FCMiddleware is initialised.

        :return: dictionary of schemes, with key of type MiddlewareScheme enum and value being list of mxnet.gluon.Block.
        """
        return {
            MiddlewareScheme.Empty:
                [],

            # Use for PPO
            MiddlewareScheme.Shallow:
                [
                    Dense(units=64)
                ],

            # Use for DQN
            MiddlewareScheme.Medium:
                [
                    Dense(units=512)
                ],

            MiddlewareScheme.Deep:
                [
                    Dense(units=128),
                    Dense(units=128),
                    Dense(units=128)
                ]
        }
</source>
<source file="systems/coach-1.0.0/rl_coach/architectures/mxnet_components/middlewares/lstm_middleware.py" startline="50" endline="80" pcid="1512">
    def schemes(self) -> dict:
        """
        Schemes are the pre-defined network architectures of various depths and complexities that can be used for the
        Middleware. Are used to create Block when LSTMMiddleware is initialised, and are applied before the LSTM.

        :return: dictionary of schemes, with key of type MiddlewareScheme enum and value being list of mxnet.gluon.Block.
        """
        return {
            MiddlewareScheme.Empty:
                [],

            # Use for PPO
            MiddlewareScheme.Shallow:
                [
                    Dense(units=64)
                ],

            # Use for DQN
            MiddlewareScheme.Medium:
                [
                    Dense(units=512)
                ],

            MiddlewareScheme.Deep:
                [
                    Dense(units=128),
                    Dense(units=128),
                    Dense(units=128)
                ]
        }

</source>
</class>

<class classid="8" nclones="3" nlines="14" similarity="100">
<source file="systems/coach-1.0.0/rl_coach/architectures/tensorflow_components/middlewares/fc_middleware.py" startline="55" endline="78" pcid="1623">
    def schemes(self):
        return {
            MiddlewareScheme.Empty:
                [],

            # ppo
            MiddlewareScheme.Shallow:
                [
                    self.dense_layer(64)
                ],

            # dqn
            MiddlewareScheme.Medium:
                [
                    self.dense_layer(512)
                ],

            MiddlewareScheme.Deep: \
                [
                    self.dense_layer(128),
                    self.dense_layer(128),
                    self.dense_layer(128)
                ]
        }
</source>
<source file="systems/coach-1.0.0/rl_coach/architectures/tensorflow_components/embedders/vector_embedder.py" startline="46" endline="68" pcid="1736">
    def schemes(self):
        return {
            EmbedderScheme.Empty:
                [],

            EmbedderScheme.Shallow:
                [
                    self.dense_layer(128)
                ],

            # dqn
            EmbedderScheme.Medium:
                [
                    self.dense_layer(256)
                ],

            # carla
            EmbedderScheme.Deep: \
                [
                    self.dense_layer(128),
                    self.dense_layer(128),
                    self.dense_layer(128)
                ]
</source>
<source file="systems/coach-1.0.0/rl_coach/architectures/tensorflow_components/middlewares/lstm_middleware.py" startline="77" endline="100" pcid="1627">
    def schemes(self):
        return {
            MiddlewareScheme.Empty:
                [],

            # ppo
            MiddlewareScheme.Shallow:
                [
                    self.dense_layer(64)
                ],

            # dqn
            MiddlewareScheme.Medium:
                [
                    self.dense_layer(512)
                ],

            MiddlewareScheme.Deep: \
                [
                    self.dense_layer(128),
                    self.dense_layer(128),
                    self.dense_layer(128)
                ]
        }
</source>
</class>

</clones>
