<clones>
<systeminfo processor="nicad6" system="ansible-2.12.4rc1" granularity="functions-blind" threshold="30%" minlines="10" maxlines="2500"/>
<cloneinfo npcs="9092" npairs="640"/>
<runinfo ncompares="2023879" cputime="969582"/>
<classinfo nclasses="250"/>

<class classid="1" nclones="2" nlines="12" similarity="100">
<source file="systems/ansible-2.12.4rc1/hacking/build_library/build_ansible/command_plugins/collection_meta.py" startline="38" endline="50" pcid="37">
    def init_parser(cls, add_parser):
        parser = add_parser(cls.name, description='Generate collection galaxy.yml documentation from shared metadata')
        parser.add_argument("-t", "--template-file", action="store", dest="template_file",
                            default=DEFAULT_TEMPLATE_FILE,
                            help="Jinja2 template to use for the config")
        parser.add_argument("-T", "--template-dir", action="store", dest="template_dir",
                            default=str(DEFAULT_TEMPLATE_DIR),
                            help="directory containing Jinja2 templates")
        parser.add_argument("-o", "--output-dir", action="store", dest="output_dir", default='/tmp/',
                            help="Output directory for rst files")
        parser.add_argument("collection_defs", metavar="COLLECTION-OPTION-DEFINITIONS.yml", type=str,
                            help="Source for collection metadata option docs")

</source>
<source file="systems/ansible-2.12.4rc1/hacking/build_library/build_ansible/command_plugins/dump_config.py" startline="49" endline="61" pcid="51">
    def init_parser(cls, add_parser):
        parser = add_parser(cls.name, description='Generate module documentation from metadata')
        parser.add_argument("-t", "--template-file", action="store", dest="template_file",
                            default=DEFAULT_TEMPLATE_FILE,
                            help="Jinja2 template to use for the config")
        parser.add_argument("-T", "--template-dir", action="store", dest="template_dir",
                            default=str(DEFAULT_TEMPLATE_DIR),
                            help="directory containing Jinja2 templates")
        parser.add_argument("-o", "--output-dir", action="store", dest="output_dir", default='/tmp/',
                            help="Output directory for rst files")
        parser.add_argument("config_defs", metavar="CONFIG-OPTION-DEFINITIONS.yml", type=str,
                            help="Source for config option docs")

</source>
</class>

<class classid="2" nclones="2" nlines="15" similarity="93">
<source file="systems/ansible-2.12.4rc1/hacking/build_library/build_ansible/command_plugins/collection_meta.py" startline="52" endline="72" pcid="38">
    def main(args):
        output_dir = os.path.abspath(args.output_dir)
        template_file_full_path = os.path.abspath(os.path.join(args.template_dir, args.template_file))
        template_file = os.path.basename(template_file_full_path)
        template_dir = os.path.dirname(template_file_full_path)

        with open(args.collection_defs) as f:
            options = yaml.safe_load(f)

        normalize_options(options)

        env = doc_environment(template_dir)

        template = env.get_template(template_file)
        output_name = os.path.join(output_dir, template_file.replace('.j2', ''))
        temp_vars = {'options': options}

        data = to_bytes(template.render(temp_vars))
        update_file_if_different(output_name, data)

        return 0
</source>
<source file="systems/ansible-2.12.4rc1/hacking/build_library/build_ansible/command_plugins/dump_config.py" startline="63" endline="82" pcid="52">
    def main(args):
        output_dir = os.path.abspath(args.output_dir)
        template_file_full_path = os.path.abspath(os.path.join(args.template_dir, args.template_file))
        template_file = os.path.basename(template_file_full_path)
        template_dir = os.path.dirname(template_file_full_path)

        with open(args.config_defs) as f:
            config_options = yaml.safe_load(f)

        config_options = fix_description(config_options)

        env = Environment(loader=FileSystemLoader(template_dir), trim_blocks=True,)
        template = env.get_template(template_file)
        output_name = os.path.join(output_dir, template_file.replace('.j2', ''))
        temp_vars = {'config_options': config_options}

        data = to_bytes(template.render(temp_vars))
        update_file_if_different(output_name, data)

        return 0
</source>
</class>

<class classid="3" nclones="5" nlines="11" similarity="72">
<source file="systems/ansible-2.12.4rc1/lib/ansible/cli/scripts/ansible_connection_cli_stub.py" startline="73" endline="87" pcid="201">
    def __init__(self, fd, play_context, socket_path, original_path, task_uuid=None, ansible_playbook_pid=None):
        self.play_context = play_context
        self.socket_path = socket_path
        self.original_path = original_path
        self._task_uuid = task_uuid

        self.fd = fd
        self.exception = None

        self.srv = JsonRpcServer()
        self.sock = None

        self.connection = None
        self._ansible_playbook_pid = ansible_playbook_pid

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/modules/postgresql_privs.py" startline="789" endline="799" pcid="7427">
            return e

        status_before.sort(key=nonesorted)
        status_after.sort(key=nonesorted)
        return status_before != status_after


class QueryBuilder(object):
    def __init__(self, state):
        self._grant_option = None
        self._for_whom = None
</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/playbook/role/definition.py" startline="48" endline="64" pcid="783">
    def __init__(self, play=None, role_basedir=None, variable_manager=None, loader=None, collection_list=None):

        super(RoleDefinition, self).__init__()

        self._play = play
        self._variable_manager = variable_manager
        self._loader = loader

        self._role_path = None
        self._role_collection = None
        self._role_basedir = role_basedir
        self._role_params = dict()
        self._collection_list = collection_list

    # def __repr__(self):
    #     return 'ROLEDEF: ' + self._attributes.get('role', '<no name set>')

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/executor/process/worker.py" startline="46" endline="62" pcid="1842">
    def __init__(self, final_q, task_vars, host, task, play_context, loader, variable_manager, shared_loader_obj):

        super(WorkerProcess, self).__init__()
        # takes a task queue manager as the sole param:
        self._final_q = final_q
        self._task_vars = task_vars
        self._host = host
        self._task = task
        self._play_context = play_context
        self._loader = loader
        self._variable_manager = variable_manager
        self._shared_loader_obj = shared_loader_obj

        # NOTE: this works due to fork, if switching to threads this should change to per thread storage of temp files
        # clear var to ensure we only delete files for this child
        self._loader._tempfiles = set()

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/executor/task_executor.py" startline="85" endline="98" pcid="1886">
    def __init__(self, host, task, job_vars, play_context, new_stdin, loader, shared_loader_obj, final_q):
        self._host = host
        self._task = task
        self._job_vars = job_vars
        self._play_context = play_context
        self._new_stdin = new_stdin
        self._loader = loader
        self._shared_loader_obj = shared_loader_obj
        self._connection = None
        self._final_q = final_q
        self._loop_eval_error = None

        self._task.squash()

</source>
</class>

<class classid="4" nclones="2" nlines="10" similarity="90">
<source file="systems/ansible-2.12.4rc1/lib/ansible/utils/display.py" startline="399" endline="411" pcid="423">
    def warning(self, msg, formatted=False):

        if not formatted:
            new_msg = "[WARNING]: %s" % msg
            wrapped = textwrap.wrap(new_msg, self.columns)
            new_msg = "\n".join(wrapped) + "\n"
        else:
            new_msg = "\n[WARNING]: \n%s" % msg

        if new_msg not in self._warns:
            self.display(new_msg, color=C.COLOR_WARN, stderr=True)
            self._warns[new_msg] = 1

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/utils/display.py" startline="456" endline="466" pcid="427">
    def error(self, msg, wrap_text=True):
        if wrap_text:
            new_msg = u"\n[ERROR]: %s" % msg
            wrapped = textwrap.wrap(new_msg, self.columns)
            new_msg = u"\n".join(wrapped) + u"\n"
        else:
            new_msg = u"ERROR! %s" % msg
        if new_msg not in self._errors:
            self.display(new_msg, color=C.COLOR_ERROR, stderr=True)
            self._errors[new_msg] = 1

</source>
</class>

<class classid="5" nclones="2" nlines="19" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/utils/collection_loader/_collection_finder.py" startline="77" endline="109" pcid="517">
    def __init__(self, paths=None, scan_sys_paths=True):
        # TODO: accept metadata loader override
        self._ansible_pkg_path = to_native(os.path.dirname(to_bytes(sys.modules['ansible'].__file__)))

        if isinstance(paths, string_types):
            paths = [paths]
        elif paths is None:
            paths = []

        # expand any placeholders in configured paths
        paths = [os.path.expanduser(to_native(p, errors='surrogate_or_strict')) for p in paths]

        # add syspaths if needed
        if scan_sys_paths:
            paths.extend(sys.path)

        good_paths = []
        # expand any placeholders in configured paths
        for p in paths:

            # ensure we always have ansible_collections
            if os.path.basename(p) == 'ansible_collections':
                p = os.path.dirname(p)

            if p not in good_paths and os.path.isdir(to_bytes(os.path.join(p, 'ansible_collections'), errors='surrogate_or_strict')):
                good_paths.append(p)

        self._n_configured_paths = good_paths
        self._n_cached_collection_paths = None
        self._n_cached_collection_qualified_paths = None

        self._n_playbook_paths = []

</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/target/legacy_collection_loader/_collection_finder.py" startline="77" endline="109" pcid="8020">
    def __init__(self, paths=None, scan_sys_paths=True):
        # TODO: accept metadata loader override
        self._ansible_pkg_path = to_native(os.path.dirname(to_bytes(sys.modules['ansible'].__file__)))

        if isinstance(paths, string_types):
            paths = [paths]
        elif paths is None:
            paths = []

        # expand any placeholders in configured paths
        paths = [os.path.expanduser(to_native(p, errors='surrogate_or_strict')) for p in paths]

        # add syspaths if needed
        if scan_sys_paths:
            paths.extend(sys.path)

        good_paths = []
        # expand any placeholders in configured paths
        for p in paths:

            # ensure we always have ansible_collections
            if os.path.basename(p) == 'ansible_collections':
                p = os.path.dirname(p)

            if p not in good_paths and os.path.isdir(to_bytes(os.path.join(p, 'ansible_collections'), errors='surrogate_or_strict')):
                good_paths.append(p)

        self._n_configured_paths = good_paths
        self._n_cached_collection_paths = None
        self._n_cached_collection_qualified_paths = None

        self._n_playbook_paths = []

</source>
</class>

<class classid="6" nclones="2" nlines="11" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/utils/collection_loader/_collection_finder.py" startline="111" endline="129" pcid="518">
    def _remove(cls):
        for mps in sys.meta_path:
            if isinstance(mps, _AnsibleCollectionFinder):
                sys.meta_path.remove(mps)

        # remove any path hooks that look like ours
        for ph in sys.path_hooks:
            if hasattr(ph, '__self__') and isinstance(ph.__self__, _AnsibleCollectionFinder):
                sys.path_hooks.remove(ph)

        # zap any cached path importer cache entries that might refer to us
        sys.path_importer_cache.clear()

        AnsibleCollectionConfig._collection_finder = None

        # validate via the public property that we really killed it
        if AnsibleCollectionConfig.collection_finder is not None:
            raise AssertionError('_AnsibleCollectionFinder remove did not reset AnsibleCollectionConfig.collection_finder')

</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/target/legacy_collection_loader/_collection_finder.py" startline="111" endline="129" pcid="8021">
    def _remove(cls):
        for mps in sys.meta_path:
            if isinstance(mps, _AnsibleCollectionFinder):
                sys.meta_path.remove(mps)

        # remove any path hooks that look like ours
        for ph in sys.path_hooks:
            if hasattr(ph, '__self__') and isinstance(ph.__self__, _AnsibleCollectionFinder):
                sys.path_hooks.remove(ph)

        # zap any cached path importer cache entries that might refer to us
        sys.path_importer_cache.clear()

        AnsibleCollectionConfig._collection_finder = None

        # validate via the public property that we really killed it
        if AnsibleCollectionConfig.collection_finder is not None:
            raise AssertionError('_AnsibleCollectionFinder remove did not reset AnsibleCollectionConfig.collection_finder')

</source>
</class>

<class classid="7" nclones="2" nlines="15" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/utils/collection_loader/_collection_finder.py" startline="138" endline="157" pcid="520">
    def _ansible_collection_path_hook(self, path):
        path = to_native(path)
        interesting_paths = self._n_cached_collection_qualified_paths
        if not interesting_paths:
            interesting_paths = []
            for p in self._n_collection_paths:
                if os.path.basename(p) != 'ansible_collections':
                    p = os.path.join(p, 'ansible_collections')

                if p not in interesting_paths:
                    interesting_paths.append(p)

            interesting_paths.insert(0, self._ansible_pkg_path)
            self._n_cached_collection_qualified_paths = interesting_paths

        if any(path.startswith(p) for p in interesting_paths):
            return _AnsiblePathHookFinder(self, path)

        raise ImportError('not interested')

</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/target/legacy_collection_loader/_collection_finder.py" startline="138" endline="157" pcid="8023">
    def _ansible_collection_path_hook(self, path):
        path = to_native(path)
        interesting_paths = self._n_cached_collection_qualified_paths
        if not interesting_paths:
            interesting_paths = []
            for p in self._n_collection_paths:
                if os.path.basename(p) != 'ansible_collections':
                    p = os.path.join(p, 'ansible_collections')

                if p not in interesting_paths:
                    interesting_paths.append(p)

            interesting_paths.insert(0, self._ansible_pkg_path)
            self._n_cached_collection_qualified_paths = interesting_paths

        if any(path.startswith(p) for p in interesting_paths):
            return _AnsiblePathHookFinder(self, path)

        raise ImportError('not interested')

</source>
</class>

<class classid="8" nclones="2" nlines="26" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/utils/collection_loader/_collection_finder.py" startline="187" endline="230" pcid="524">
    def find_module(self, fullname, path=None):
        # Figure out what's being asked for, and delegate to a special-purpose loader

        split_name = fullname.split('.')
        toplevel_pkg = split_name[0]
        module_to_find = split_name[-1]
        part_count = len(split_name)

        if toplevel_pkg not in ['ansible', 'ansible_collections']:
            # not interested in anything other than ansible_collections (and limited cases under ansible)
            return None

        # sanity check what we're getting from import, canonicalize path values
        if part_count == 1:
            if path:
                raise ValueError('path should not be specified for top-level packages (trying to find {0})'.format(fullname))
            else:
                # seed the path to the configured collection roots
                path = self._n_collection_paths

        if part_count > 1 and path is None:
            raise ValueError('path must be specified for subpackages (trying to find {0})'.format(fullname))

        # NB: actual "find"ing is delegated to the constructors on the various loaders; they'll ImportError if not found
        try:
            if toplevel_pkg == 'ansible':
                # something under the ansible package, delegate to our internal loader in case of redirections
                return _AnsibleInternalRedirectLoader(fullname=fullname, path_list=path)
            if part_count == 1:
                return _AnsibleCollectionRootPkgLoader(fullname=fullname, path_list=path)
            if part_count == 2:  # ns pkg eg, ansible_collections, ansible_collections.somens
                return _AnsibleCollectionNSPkgLoader(fullname=fullname, path_list=path)
            elif part_count == 3:  # collection pkg eg, ansible_collections.somens.somecoll
                return _AnsibleCollectionPkgLoader(fullname=fullname, path_list=path)
            # anything below the collection
            return _AnsibleCollectionLoader(fullname=fullname, path_list=path)
        except ImportError:
            # TODO: log attempt to load context
            return None


# Implements a path_hook finder for iter_modules (since it's only path based). This finder does not need to actually
# function as a finder in most cases, since our meta_path finder is consulted first for *almost* everything, except
# pkgutil.iter_modules, and under py2, pkgutil.get_data if the parent package passed has not been loaded yet.
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/target/legacy_collection_loader/_collection_finder.py" startline="187" endline="230" pcid="8027">
    def find_module(self, fullname, path=None):
        # Figure out what's being asked for, and delegate to a special-purpose loader

        split_name = fullname.split('.')
        toplevel_pkg = split_name[0]
        module_to_find = split_name[-1]
        part_count = len(split_name)

        if toplevel_pkg not in ['ansible', 'ansible_collections']:
            # not interested in anything other than ansible_collections (and limited cases under ansible)
            return None

        # sanity check what we're getting from import, canonicalize path values
        if part_count == 1:
            if path:
                raise ValueError('path should not be specified for top-level packages (trying to find {0})'.format(fullname))
            else:
                # seed the path to the configured collection roots
                path = self._n_collection_paths

        if part_count > 1 and path is None:
            raise ValueError('path must be specified for subpackages (trying to find {0})'.format(fullname))

        # NB: actual "find"ing is delegated to the constructors on the various loaders; they'll ImportError if not found
        try:
            if toplevel_pkg == 'ansible':
                # something under the ansible package, delegate to our internal loader in case of redirections
                return _AnsibleInternalRedirectLoader(fullname=fullname, path_list=path)
            if part_count == 1:
                return _AnsibleCollectionRootPkgLoader(fullname=fullname, path_list=path)
            if part_count == 2:  # ns pkg eg, ansible_collections, ansible_collections.somens
                return _AnsibleCollectionNSPkgLoader(fullname=fullname, path_list=path)
            elif part_count == 3:  # collection pkg eg, ansible_collections.somens.somecoll
                return _AnsibleCollectionPkgLoader(fullname=fullname, path_list=path)
            # anything below the collection
            return _AnsibleCollectionLoader(fullname=fullname, path_list=path)
        except ImportError:
            # TODO: log attempt to load context
            return None


# Implements a path_hook finder for iter_modules (since it's only path based). This finder does not need to actually
# function as a finder in most cases, since our meta_path finder is consulted first for *almost* everything, except
# pkgutil.iter_modules, and under py2, pkgutil.get_data if the parent package passed has not been loaded yet.
</source>
</class>

<class classid="9" nclones="2" nlines="18" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/utils/collection_loader/_collection_finder.py" startline="254" endline="287" pcid="527">
    def find_module(self, fullname, path=None):
        # we ignore the passed in path here- use what we got from the path hook init
        split_name = fullname.split('.')
        toplevel_pkg = split_name[0]

        if toplevel_pkg == 'ansible_collections':
            # collections content? delegate to the collection finder
            return self._collection_finder.find_module(fullname, path=[self._pathctx])
        else:
            # Something else; we'd normally restrict this to `ansible` descendent modules so that any weird loader
            # behavior that arbitrary Python modules have can be serviced by those loaders. In some dev/test
            # scenarios (eg a venv under a collection) our path_hook signs us up to load non-Ansible things, and
            # it's too late by the time we've reached this point, but also too expensive for the path_hook to figure
            # out what we *shouldn't* be loading with the limited info it has. So we'll just delegate to the
            # normal path-based loader as best we can to service it. This also allows us to take advantage of Python's
            # built-in FS caching and byte-compilation for most things.
            if PY3:
                # create or consult our cached file finder for this path
                if not self._file_finder:
                    try:
                        self._file_finder = _AnsiblePathHookFinder._filefinder_path_hook(self._pathctx)
                    except ImportError:
                        # FUTURE: log at a high logging level? This is normal for things like python36.zip on the path, but
                        # might not be in some other situation...
                        return None

                spec = self._file_finder.find_spec(fullname)
                if not spec:
                    return None
                return spec.loader
            else:
                # call py2's internal loader
                return pkgutil.ImpImporter(self._pathctx).find_module(fullname)

</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/target/legacy_collection_loader/_collection_finder.py" startline="254" endline="288" pcid="8030">
    def find_module(self, fullname, path=None):
        # we ignore the passed in path here- use what we got from the path hook init
        split_name = fullname.split('.')
        toplevel_pkg = split_name[0]

        if toplevel_pkg == 'ansible_collections':
            # collections content? delegate to the collection finder
            return self._collection_finder.find_module(fullname, path=[self._pathctx])
        else:
            # Something else; we'd normally restrict this to `ansible` descendent modules so that any weird loader
            # behavior that arbitrary Python modules have can be serviced by those loaders. In some dev/test
            # scenarios (eg a venv under a collection) our path_hook signs us up to load non-Ansible things, and
            # it's too late by the time we've reached this point, but also too expensive for the path_hook to figure
            # out what we *shouldn't* be loading with the limited info it has. So we'll just delegate to the
            # normal path-based loader as best we can to service it. This also allows us to take advantage of Python's
            # built-in FS caching and byte-compilation for most things.
            if PY3:
                # create or consult our cached file finder for this path
                if not self._file_finder:
                    try:
                        self._file_finder = _AnsiblePathHookFinder._filefinder_path_hook(self._pathctx)
                    except ImportError:
                        # FUTURE: log at a high logging level? This is normal for things like python36.zip on the path, but
                        # might not be in some other situation...
                        return None

                spec = self._file_finder.find_spec(fullname)
                if not spec:
                    return None
                return spec.loader
            else:
                # call py2's internal loader
                # noinspection PyDeprecation
                return pkgutil.ImpImporter(self._pathctx).find_module(fullname)  # pylint: disable=deprecated-class

</source>
</class>

<class classid="10" nclones="2" nlines="14" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/utils/collection_loader/_collection_finder.py" startline="299" endline="318" pcid="530">
    def __init__(self, fullname, path_list=None):
        self._fullname = fullname
        self._redirect_module = None
        self._split_name = fullname.split('.')
        self._rpart_name = fullname.rpartition('.')
        self._parent_package_name = self._rpart_name[0]  # eg ansible_collections for ansible_collections.somens, '' for toplevel
        self._package_to_load = self._rpart_name[2]  # eg somens for ansible_collections.somens

        self._source_code_path = None
        self._decoded_source = None
        self._compiled_code = None

        self._validate_args()

        self._candidate_paths = self._get_candidate_paths([to_native(p) for p in path_list])
        self._subpackage_search_paths = self._get_subpackage_search_paths(self._candidate_paths)

        self._validate_final()

    # allow subclasses to validate args and sniff split values before we start digging around
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/target/legacy_collection_loader/_collection_finder.py" startline="300" endline="319" pcid="8033">
    def __init__(self, fullname, path_list=None):
        self._fullname = fullname
        self._redirect_module = None
        self._split_name = fullname.split('.')
        self._rpart_name = fullname.rpartition('.')
        self._parent_package_name = self._rpart_name[0]  # eg ansible_collections for ansible_collections.somens, '' for toplevel
        self._package_to_load = self._rpart_name[2]  # eg somens for ansible_collections.somens

        self._source_code_path = None
        self._decoded_source = None
        self._compiled_code = None

        self._validate_args()

        self._candidate_paths = self._get_candidate_paths([to_native(p) for p in path_list])
        self._subpackage_search_paths = self._get_subpackage_search_paths(self._candidate_paths)

        self._validate_final()

    # allow subclasses to validate args and sniff split values before we start digging around
</source>
</class>

<class classid="11" nclones="2" nlines="16" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/utils/collection_loader/_collection_finder.py" startline="338" endline="358" pcid="535">
    def _new_or_existing_module(name, **kwargs):
        # handle all-or-nothing sys.modules creation/use-existing/delete-on-exception-if-created behavior
        created_module = False
        module = sys.modules.get(name)
        try:
            if not module:
                module = ModuleType(name)
                created_module = True
                sys.modules[name] = module
            # always override the values passed, except name (allow reference aliasing)
            for attr, value in kwargs.items():
                setattr(module, attr, value)
            yield module
        except Exception:
            if created_module:
                if sys.modules.get(name):
                    sys.modules.pop(name)
            raise

    # basic module/package location support
    # NB: this does not support distributed packages!
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/target/legacy_collection_loader/_collection_finder.py" startline="339" endline="359" pcid="8038">
    def _new_or_existing_module(name, **kwargs):
        # handle all-or-nothing sys.modules creation/use-existing/delete-on-exception-if-created behavior
        created_module = False
        module = sys.modules.get(name)
        try:
            if not module:
                module = ModuleType(name)
                created_module = True
                sys.modules[name] = module
            # always override the values passed, except name (allow reference aliasing)
            for attr, value in kwargs.items():
                setattr(module, attr, value)
            yield module
        except Exception:
            if created_module:
                if sys.modules.get(name):
                    sys.modules.pop(name)
            raise

    # basic module/package location support
    # NB: this does not support distributed packages!
</source>
</class>

<class classid="12" nclones="2" nlines="15" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/utils/collection_loader/_collection_finder.py" startline="360" endline="379" pcid="536">
    def _module_file_from_path(leaf_name, path):
        has_code = True
        package_path = os.path.join(to_native(path), to_native(leaf_name))
        module_path = None

        # if the submodule is a package, assemble valid submodule paths, but stop looking for a module
        if os.path.isdir(to_bytes(package_path)):
            # is there a package init?
            module_path = os.path.join(package_path, '__init__.py')
            if not os.path.isfile(to_bytes(module_path)):
                module_path = os.path.join(package_path, '__synthetic__')
                has_code = False
        else:
            module_path = package_path + '.py'
            package_path = None
            if not os.path.isfile(to_bytes(module_path)):
                raise ImportError('{0} not found at {1}'.format(leaf_name, path))

        return module_path, has_code, package_path

</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/target/legacy_collection_loader/_collection_finder.py" startline="361" endline="380" pcid="8039">
    def _module_file_from_path(leaf_name, path):
        has_code = True
        package_path = os.path.join(to_native(path), to_native(leaf_name))
        module_path = None

        # if the submodule is a package, assemble valid submodule paths, but stop looking for a module
        if os.path.isdir(to_bytes(package_path)):
            # is there a package init?
            module_path = os.path.join(package_path, '__init__.py')
            if not os.path.isfile(to_bytes(module_path)):
                module_path = os.path.join(package_path, '__synthetic__')
                has_code = False
        else:
            module_path = package_path + '.py'
            package_path = None
            if not os.path.isfile(to_bytes(module_path)):
                raise ImportError('{0} not found at {1}'.format(leaf_name, path))

        return module_path, has_code, package_path

</source>
</class>

<class classid="13" nclones="2" nlines="16" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/utils/collection_loader/_collection_finder.py" startline="380" endline="405" pcid="537">
    def load_module(self, fullname):
        # short-circuit redirect; we've already imported the redirected module, so just alias it and return it
        if self._redirect_module:
            sys.modules[self._fullname] = self._redirect_module
            return self._redirect_module

        # we're actually loading a module/package
        module_attrs = dict(
            __loader__=self,
            __file__=self.get_filename(fullname),
            __package__=self._parent_package_name  # sane default for non-packages
        )

        # eg, I am a package
        if self._subpackage_search_paths is not None:  # empty is legal
            module_attrs['__path__'] = self._subpackage_search_paths
            module_attrs['__package__'] = fullname  # per PEP366

        with self._new_or_existing_module(fullname, **module_attrs) as module:
            # execute the module's code in its namespace
            code_obj = self.get_code(fullname)
            if code_obj is not None:  # things like NS packages that can't have code on disk will return None
                exec(code_obj, module.__dict__)

            return module

</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/target/legacy_collection_loader/_collection_finder.py" startline="381" endline="406" pcid="8040">
    def load_module(self, fullname):
        # short-circuit redirect; we've already imported the redirected module, so just alias it and return it
        if self._redirect_module:
            sys.modules[self._fullname] = self._redirect_module
            return self._redirect_module

        # we're actually loading a module/package
        module_attrs = dict(
            __loader__=self,
            __file__=self.get_filename(fullname),
            __package__=self._parent_package_name  # sane default for non-packages
        )

        # eg, I am a package
        if self._subpackage_search_paths is not None:  # empty is legal
            module_attrs['__path__'] = self._subpackage_search_paths
            module_attrs['__package__'] = fullname  # per PEP366

        with self._new_or_existing_module(fullname, **module_attrs) as module:
            # execute the module's code in its namespace
            code_obj = self.get_code(fullname)
            if code_obj is not None:  # things like NS packages that can't have code on disk will return None
                exec(code_obj, module.__dict__)

            return module

</source>
</class>

<class classid="14" nclones="2" nlines="15" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/utils/collection_loader/_collection_finder.py" startline="422" endline="447" pcid="540">
    def get_data(self, path):
        if not path:
            raise ValueError('a path must be specified')

        # TODO: ensure we're being asked for a path below something we own
        # TODO: try to handle redirects internally?

        if not path[0] == '/':
            # relative to current package, search package paths if possible (this may not be necessary)
            # candidate_paths = [os.path.join(ssp, path) for ssp in self._subpackage_search_paths]
            raise ValueError('relative resource paths not supported')
        else:
            candidate_paths = [path]

        for p in candidate_paths:
            b_path = to_bytes(p)
            if os.path.isfile(b_path):
                with open(b_path, 'rb') as fd:
                    return fd.read()
            # HACK: if caller asks for __init__.py and the parent dir exists, return empty string (this keep consistency
            # with "collection subpackages don't require __init__.py" working everywhere with get_data
            elif b_path.endswith(b'__init__.py') and os.path.isdir(os.path.dirname(b_path)):
                return ''

        return None

</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/target/legacy_collection_loader/_collection_finder.py" startline="423" endline="448" pcid="8043">
    def get_data(self, path):
        if not path:
            raise ValueError('a path must be specified')

        # TODO: ensure we're being asked for a path below something we own
        # TODO: try to handle redirects internally?

        if not path[0] == '/':
            # relative to current package, search package paths if possible (this may not be necessary)
            # candidate_paths = [os.path.join(ssp, path) for ssp in self._subpackage_search_paths]
            raise ValueError('relative resource paths not supported')
        else:
            candidate_paths = [path]

        for p in candidate_paths:
            b_path = to_bytes(p)
            if os.path.isfile(b_path):
                with open(b_path, 'rb') as fd:
                    return fd.read()
            # HACK: if caller asks for __init__.py and the parent dir exists, return empty string (this keep consistency
            # with "collection subpackages don't require __init__.py" working everywhere with get_data
            elif b_path.endswith(b'__init__.py') and os.path.isdir(os.path.dirname(b_path)):
                return ''

        return None

</source>
</class>

<class classid="15" nclones="2" nlines="10" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/utils/collection_loader/_collection_finder.py" startline="451" endline="464" pcid="542">
    def get_filename(self, fullname):
        if fullname != self._fullname:
            raise ValueError('this loader cannot find files for {0}, only {1}'.format(fullname, self._fullname))

        filename = self._source_code_path

        if not filename and self.is_package(fullname):
            if len(self._subpackage_search_paths) == 1:
                filename = os.path.join(self._subpackage_search_paths[0], '__synthetic__')
            else:
                filename = self._synthetic_filename(fullname)

        return filename

</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/target/legacy_collection_loader/_collection_finder.py" startline="452" endline="465" pcid="8045">
    def get_filename(self, fullname):
        if fullname != self._fullname:
            raise ValueError('this loader cannot find files for {0}, only {1}'.format(fullname, self._fullname))

        filename = self._source_code_path

        if not filename and self.is_package(fullname):
            if len(self._subpackage_search_paths) == 1:
                filename = os.path.join(self._subpackage_search_paths[0], '__synthetic__')
            else:
                filename = self._synthetic_filename(fullname)

        return filename

</source>
</class>

<class classid="16" nclones="2" nlines="11" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/utils/collection_loader/_collection_finder.py" startline="465" endline="484" pcid="543">
    def get_code(self, fullname):
        if self._compiled_code:
            return self._compiled_code

        # this may or may not be an actual filename, but it's the value we'll use for __file__
        filename = self.get_filename(fullname)
        if not filename:
            filename = '<string>'

        source_code = self.get_source(fullname)

        # for things like synthetic modules that really have no source on disk, don't return a code object at all
        # vs things like an empty package init (which has an empty string source on disk)
        if source_code is None:
            return None

        self._compiled_code = compile(source=source_code, filename=filename, mode='exec', flags=0, dont_inherit=True)

        return self._compiled_code

</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/target/legacy_collection_loader/_collection_finder.py" startline="466" endline="485" pcid="8046">
    def get_code(self, fullname):
        if self._compiled_code:
            return self._compiled_code

        # this may or may not be an actual filename, but it's the value we'll use for __file__
        filename = self.get_filename(fullname)
        if not filename:
            filename = '<string>'

        source_code = self.get_source(fullname)

        # for things like synthetic modules that really have no source on disk, don't return a code object at all
        # vs things like an empty package init (which has an empty string source on disk)
        if source_code is None:
            return None

        self._compiled_code = compile(source=source_code, filename=filename, mode='exec', flags=0, dont_inherit=True)

        return self._compiled_code

</source>
</class>

<class classid="17" nclones="2" nlines="26" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/utils/collection_loader/_collection_finder.py" startline="534" endline="568" pcid="551">
    def load_module(self, fullname):
        if not _meta_yml_to_dict:
            raise ValueError('ansible.utils.collection_loader._meta_yml_to_dict is not set')

        module = super(_AnsibleCollectionPkgLoader, self).load_module(fullname)

        module._collection_meta = {}
        # TODO: load collection metadata, cache in __loader__ state

        collection_name = '.'.join(self._split_name[1:3])

        if collection_name == 'ansible.builtin':
            # ansible.builtin is a synthetic collection, get its routing config from the Ansible distro
            ansible_pkg_path = os.path.dirname(import_module('ansible').__file__)
            metadata_path = os.path.join(ansible_pkg_path, 'config/ansible_builtin_runtime.yml')
            with open(to_bytes(metadata_path), 'rb') as fd:
                raw_routing = fd.read()
        else:
            b_routing_meta_path = to_bytes(os.path.join(module.__path__[0], 'meta/runtime.yml'))
            if os.path.isfile(b_routing_meta_path):
                with open(b_routing_meta_path, 'rb') as fd:
                    raw_routing = fd.read()
            else:
                raw_routing = ''
        try:
            if raw_routing:
                routing_dict = _meta_yml_to_dict(raw_routing, (collection_name, 'runtime.yml'))
                module._collection_meta = self._canonicalize_meta(routing_dict)
        except Exception as ex:
            raise ValueError('error parsing collection metadata: {0}'.format(to_native(ex)))

        AnsibleCollectionConfig.on_collection_load.fire(collection_name=collection_name, collection_path=os.path.dirname(module.__file__))

        return module

</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/target/legacy_collection_loader/_collection_finder.py" startline="535" endline="569" pcid="8054">
    def load_module(self, fullname):
        if not _meta_yml_to_dict:
            raise ValueError('ansible.utils.collection_loader._meta_yml_to_dict is not set')

        module = super(_AnsibleCollectionPkgLoader, self).load_module(fullname)

        module._collection_meta = {}
        # TODO: load collection metadata, cache in __loader__ state

        collection_name = '.'.join(self._split_name[1:3])

        if collection_name == 'ansible.builtin':
            # ansible.builtin is a synthetic collection, get its routing config from the Ansible distro
            ansible_pkg_path = os.path.dirname(import_module('ansible').__file__)
            metadata_path = os.path.join(ansible_pkg_path, 'config/ansible_builtin_runtime.yml')
            with open(to_bytes(metadata_path), 'rb') as fd:
                raw_routing = fd.read()
        else:
            b_routing_meta_path = to_bytes(os.path.join(module.__path__[0], 'meta/runtime.yml'))
            if os.path.isfile(b_routing_meta_path):
                with open(b_routing_meta_path, 'rb') as fd:
                    raw_routing = fd.read()
            else:
                raw_routing = ''
        try:
            if raw_routing:
                routing_dict = _meta_yml_to_dict(raw_routing, (collection_name, 'runtime.yml'))
                module._collection_meta = self._canonicalize_meta(routing_dict)
        except Exception as ex:
            raise ValueError('error parsing collection metadata: {0}'.format(to_native(ex)))

        AnsibleCollectionConfig.on_collection_load.fire(collection_name=collection_name, collection_path=os.path.dirname(module.__file__))

        return module

</source>
</class>

<class classid="18" nclones="2" nlines="25" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/utils/collection_loader/_collection_finder.py" startline="605" endline="658" pcid="555">
    def _get_subpackage_search_paths(self, candidate_paths):
        collection_name = '.'.join(self._split_name[1:3])
        collection_meta = _get_collection_metadata(collection_name)

        # check for explicit redirection, as well as ancestor package-level redirection (only load the actual code once!)
        redirect = None
        explicit_redirect = False

        routing_entry = _nested_dict_get(collection_meta, ['import_redirection', self._fullname])
        if routing_entry:
            redirect = routing_entry.get('redirect')

        if redirect:
            explicit_redirect = True
        else:
            redirect = _get_ancestor_redirect(self._redirected_package_map, self._fullname)

        # NB: package level redirection requires hooking all future imports beneath the redirected source package
        # in order to ensure sanity on future relative imports. We always import everything under its "real" name,
        # then add a sys.modules entry with the redirected name using the same module instance. If we naively imported
        # the source for each redirection, most submodules would import OK, but we'd have N runtime copies of the module
        # (one for each name), and relative imports that ascend above the redirected package would break (since they'd
        # see the redirected ancestor package contents instead of the package where they actually live).
        if redirect:
            # FIXME: wrap this so we can be explicit about a failed redirection
            self._redirect_module = import_module(redirect)
            if explicit_redirect and hasattr(self._redirect_module, '__path__') and self._redirect_module.__path__:
                # if the import target looks like a package, store its name so we can rewrite future descendent loads
                self._redirected_package_map[self._fullname] = redirect

            # if we redirected, don't do any further custom package logic
            return None

        # we're not doing a redirect- try to find what we need to actually load a module/package

        # this will raise ImportError if we can't find the requested module/package at all
        if not candidate_paths:
            # noplace to look, just ImportError
            raise ImportError('package has no paths')

        found_path, has_code, package_path = self._module_file_from_path(self._package_to_load, candidate_paths[0])

        # still here? we found something to load...
        if has_code:
            self._source_code_path = found_path

        if package_path:
            return [package_path]  # always needs to be a list

        return None


# This loader only answers for intercepted Ansible Python modules. Normal imports will fail here and be picked up later
# by our path_hook importer (which proxies the built-in import mechanisms, allowing normal caching etc to occur)
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/target/legacy_collection_loader/_collection_finder.py" startline="606" endline="659" pcid="8058">
    def _get_subpackage_search_paths(self, candidate_paths):
        collection_name = '.'.join(self._split_name[1:3])
        collection_meta = _get_collection_metadata(collection_name)

        # check for explicit redirection, as well as ancestor package-level redirection (only load the actual code once!)
        redirect = None
        explicit_redirect = False

        routing_entry = _nested_dict_get(collection_meta, ['import_redirection', self._fullname])
        if routing_entry:
            redirect = routing_entry.get('redirect')

        if redirect:
            explicit_redirect = True
        else:
            redirect = _get_ancestor_redirect(self._redirected_package_map, self._fullname)

        # NB: package level redirection requires hooking all future imports beneath the redirected source package
        # in order to ensure sanity on future relative imports. We always import everything under its "real" name,
        # then add a sys.modules entry with the redirected name using the same module instance. If we naively imported
        # the source for each redirection, most submodules would import OK, but we'd have N runtime copies of the module
        # (one for each name), and relative imports that ascend above the redirected package would break (since they'd
        # see the redirected ancestor package contents instead of the package where they actually live).
        if redirect:
            # FIXME: wrap this so we can be explicit about a failed redirection
            self._redirect_module = import_module(redirect)
            if explicit_redirect and hasattr(self._redirect_module, '__path__') and self._redirect_module.__path__:
                # if the import target looks like a package, store its name so we can rewrite future descendent loads
                self._redirected_package_map[self._fullname] = redirect

            # if we redirected, don't do any further custom package logic
            return None

        # we're not doing a redirect- try to find what we need to actually load a module/package

        # this will raise ImportError if we can't find the requested module/package at all
        if not candidate_paths:
            # noplace to look, just ImportError
            raise ImportError('package has no paths')

        found_path, has_code, package_path = self._module_file_from_path(self._package_to_load, candidate_paths[0])

        # still here? we found something to load...
        if has_code:
            self._source_code_path = found_path

        if package_path:
            return [package_path]  # always needs to be a list

        return None


# This loader only answers for intercepted Ansible Python modules. Normal imports will fail here and be picked up later
# by our path_hook importer (which proxies the built-in import mechanisms, allowing normal caching etc to occur)
</source>
</class>

<class classid="19" nclones="2" nlines="13" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/utils/collection_loader/_collection_finder.py" startline="660" endline="678" pcid="556">
    def __init__(self, fullname, path_list):
        self._redirect = None

        split_name = fullname.split('.')
        toplevel_pkg = split_name[0]
        module_to_load = split_name[-1]

        if toplevel_pkg != 'ansible':
            raise ImportError('not interested')

        builtin_meta = _get_collection_metadata('ansible.builtin')

        routing_entry = _nested_dict_get(builtin_meta, ['import_redirection', fullname])
        if routing_entry:
            self._redirect = routing_entry.get('redirect')

        if not self._redirect:
            raise ImportError('not redirected, go ask path_hook')

</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/target/legacy_collection_loader/_collection_finder.py" startline="661" endline="679" pcid="8059">
    def __init__(self, fullname, path_list):
        self._redirect = None

        split_name = fullname.split('.')
        toplevel_pkg = split_name[0]
        module_to_load = split_name[-1]

        if toplevel_pkg != 'ansible':
            raise ImportError('not interested')

        builtin_meta = _get_collection_metadata('ansible.builtin')

        routing_entry = _nested_dict_get(builtin_meta, ['import_redirection', fullname])
        if routing_entry:
            self._redirect = routing_entry.get('redirect')

        if not self._redirect:
            raise ImportError('not redirected, go ask path_hook')

</source>
</class>

<class classid="20" nclones="2" nlines="36" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/utils/collection_loader/_collection_finder.py" startline="705" endline="761" pcid="558">
    def __init__(self, collection_name, subdirs, resource, ref_type):
        """
        Create an AnsibleCollectionRef from components
        :param collection_name: a collection name of the form 'namespace.collectionname'
        :param subdirs: optional subdir segments to be appended below the plugin type (eg, 'subdir1.subdir2')
        :param resource: the name of the resource being references (eg, 'mymodule', 'someaction', 'a_role')
        :param ref_type: the type of the reference, eg 'module', 'role', 'doc_fragment'
        """
        collection_name = to_text(collection_name, errors='strict')
        if subdirs is not None:
            subdirs = to_text(subdirs, errors='strict')
        resource = to_text(resource, errors='strict')
        ref_type = to_text(ref_type, errors='strict')

        if not self.is_valid_collection_name(collection_name):
            raise ValueError('invalid collection name (must be of the form namespace.collection): {0}'.format(to_native(collection_name)))

        if ref_type not in self.VALID_REF_TYPES:
            raise ValueError('invalid collection ref_type: {0}'.format(ref_type))

        self.collection = collection_name
        if subdirs:
            if not re.match(self.VALID_SUBDIRS_RE, subdirs):
                raise ValueError('invalid subdirs entry: {0} (must be empty/None or of the form subdir1.subdir2)'.format(to_native(subdirs)))
            self.subdirs = subdirs
        else:
            self.subdirs = u''

        self.resource = resource
        self.ref_type = ref_type

        package_components = [u'ansible_collections', self.collection]
        fqcr_components = [self.collection]

        self.n_python_collection_package_name = to_native('.'.join(package_components))

        if self.ref_type == u'role':
            package_components.append(u'roles')
        elif self.ref_type == u'playbook':
            package_components.append(u'playbooks')
        else:
            # we assume it's a plugin
            package_components += [u'plugins', self.ref_type]

        if self.subdirs:
            package_components.append(self.subdirs)
            fqcr_components.append(self.subdirs)

        if self.ref_type in (u'role', u'playbook'):
            # playbooks and roles are their own resource
            package_components.append(self.resource)

        fqcr_components.append(self.resource)

        self.n_python_package_name = to_native('.'.join(package_components))
        self._fqcr = u'.'.join(fqcr_components)

</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/target/legacy_collection_loader/_collection_finder.py" startline="706" endline="762" pcid="8061">
    def __init__(self, collection_name, subdirs, resource, ref_type):
        """
        Create an AnsibleCollectionRef from components
        :param collection_name: a collection name of the form 'namespace.collectionname'
        :param subdirs: optional subdir segments to be appended below the plugin type (eg, 'subdir1.subdir2')
        :param resource: the name of the resource being references (eg, 'mymodule', 'someaction', 'a_role')
        :param ref_type: the type of the reference, eg 'module', 'role', 'doc_fragment'
        """
        collection_name = to_text(collection_name, errors='strict')
        if subdirs is not None:
            subdirs = to_text(subdirs, errors='strict')
        resource = to_text(resource, errors='strict')
        ref_type = to_text(ref_type, errors='strict')

        if not self.is_valid_collection_name(collection_name):
            raise ValueError('invalid collection name (must be of the form namespace.collection): {0}'.format(to_native(collection_name)))

        if ref_type not in self.VALID_REF_TYPES:
            raise ValueError('invalid collection ref_type: {0}'.format(ref_type))

        self.collection = collection_name
        if subdirs:
            if not re.match(self.VALID_SUBDIRS_RE, subdirs):
                raise ValueError('invalid subdirs entry: {0} (must be empty/None or of the form subdir1.subdir2)'.format(to_native(subdirs)))
            self.subdirs = subdirs
        else:
            self.subdirs = u''

        self.resource = resource
        self.ref_type = ref_type

        package_components = [u'ansible_collections', self.collection]
        fqcr_components = [self.collection]

        self.n_python_collection_package_name = to_native('.'.join(package_components))

        if self.ref_type == u'role':
            package_components.append(u'roles')
        elif self.ref_type == u'playbook':
            package_components.append(u'playbooks')
        else:
            # we assume it's a plugin
            package_components += [u'plugins', self.ref_type]

        if self.subdirs:
            package_components.append(self.subdirs)
            fqcr_components.append(self.subdirs)

        if self.ref_type in (u'role', u'playbook'):
            # playbooks and roles are their own resource
            package_components.append(self.resource)

        fqcr_components.append(self.resource)

        self.n_python_package_name = to_native('.'.join(package_components))
        self._fqcr = u'.'.join(fqcr_components)

</source>
</class>

<class classid="21" nclones="2" nlines="22" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/utils/collection_loader/_collection_finder.py" startline="770" endline="811" pcid="561">
    def from_fqcr(ref, ref_type):
        """
        Parse a string as a fully-qualified collection reference, raises ValueError if invalid
        :param ref: collection reference to parse (a valid ref is of the form 'ns.coll.resource' or 'ns.coll.subdir1.subdir2.resource')
        :param ref_type: the type of the reference, eg 'module', 'role', 'doc_fragment'
        :return: a populated AnsibleCollectionRef object
        """
        # assuming the fq_name is of the form (ns).(coll).(optional_subdir_N).(resource_name),
        # we split the resource name off the right, split ns and coll off the left, and we're left with any optional
        # subdirs that need to be added back below the plugin-specific subdir we'll add. So:
        # ns.coll.resource -> ansible_collections.ns.coll.plugins.(plugintype).resource
        # ns.coll.subdir1.resource -> ansible_collections.ns.coll.plugins.subdir1.(plugintype).resource
        # ns.coll.rolename -> ansible_collections.ns.coll.roles.rolename
        if not AnsibleCollectionRef.is_valid_fqcr(ref):
            raise ValueError('{0} is not a valid collection reference'.format(to_native(ref)))

        ref = to_text(ref, errors='strict')
        ref_type = to_text(ref_type, errors='strict')
        ext = ''

        if ref_type == u'playbook' and ref.endswith(PB_EXTENSIONS):
            resource_splitname = ref.rsplit(u'.', 2)
            package_remnant = resource_splitname[0]
            resource = resource_splitname[1]
            ext = '.' + resource_splitname[2]
        else:
            resource_splitname = ref.rsplit(u'.', 1)
            package_remnant = resource_splitname[0]
            resource = resource_splitname[1]

        # split the left two components of the collection package name off, anything remaining is plugin-type
        # specific subdirs to be added back on below the plugin type
        package_splitname = package_remnant.split(u'.', 2)
        if len(package_splitname) == 3:
            subdirs = package_splitname[2]
        else:
            subdirs = u''

        collection_name = u'.'.join(package_splitname[0:2])

        return AnsibleCollectionRef(collection_name, subdirs, resource + ext, ref_type)

</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/target/legacy_collection_loader/_collection_finder.py" startline="771" endline="812" pcid="8064">
    def from_fqcr(ref, ref_type):
        """
        Parse a string as a fully-qualified collection reference, raises ValueError if invalid
        :param ref: collection reference to parse (a valid ref is of the form 'ns.coll.resource' or 'ns.coll.subdir1.subdir2.resource')
        :param ref_type: the type of the reference, eg 'module', 'role', 'doc_fragment'
        :return: a populated AnsibleCollectionRef object
        """
        # assuming the fq_name is of the form (ns).(coll).(optional_subdir_N).(resource_name),
        # we split the resource name off the right, split ns and coll off the left, and we're left with any optional
        # subdirs that need to be added back below the plugin-specific subdir we'll add. So:
        # ns.coll.resource -> ansible_collections.ns.coll.plugins.(plugintype).resource
        # ns.coll.subdir1.resource -> ansible_collections.ns.coll.plugins.subdir1.(plugintype).resource
        # ns.coll.rolename -> ansible_collections.ns.coll.roles.rolename
        if not AnsibleCollectionRef.is_valid_fqcr(ref):
            raise ValueError('{0} is not a valid collection reference'.format(to_native(ref)))

        ref = to_text(ref, errors='strict')
        ref_type = to_text(ref_type, errors='strict')
        ext = ''

        if ref_type == u'playbook' and ref.endswith(PB_EXTENSIONS):
            resource_splitname = ref.rsplit(u'.', 2)
            package_remnant = resource_splitname[0]
            resource = resource_splitname[1]
            ext = '.' + resource_splitname[2]
        else:
            resource_splitname = ref.rsplit(u'.', 1)
            package_remnant = resource_splitname[0]
            resource = resource_splitname[1]

        # split the left two components of the collection package name off, anything remaining is plugin-type
        # specific subdirs to be added back on below the plugin type
        package_splitname = package_remnant.split(u'.', 2)
        if len(package_splitname) == 3:
            subdirs = package_splitname[2]
        else:
            subdirs = u''

        collection_name = u'.'.join(package_splitname[0:2])

        return AnsibleCollectionRef(collection_name, subdirs, resource + ext, ref_type)

</source>
</class>

<class classid="22" nclones="2" nlines="22" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/utils/collection_loader/_collection_finder.py" startline="880" endline="909" pcid="566">
def _get_collection_playbook_path(playbook):

    acr = AnsibleCollectionRef.try_parse_fqcr(playbook, u'playbook')
    if acr:
        try:
            # get_collection_path
            pkg = import_module(acr.n_python_collection_package_name)
        except (IOError, ModuleNotFoundError) as e:
            # leaving e as debug target, even though not used in normal code
            pkg = None

        if pkg:
            cpath = os.path.join(sys.modules[acr.n_python_collection_package_name].__file__.replace('__synthetic__', 'playbooks'))

            if acr.subdirs:
                paths = [to_native(x) for x in acr.subdirs.split(u'.')]
                paths.insert(0, cpath)
                cpath = os.path.join(*paths)

            path = os.path.join(cpath, to_native(acr.resource))
            if os.path.exists(to_bytes(path)):
                return acr.resource, path, acr.collection
            elif not acr.resource.endswith(PB_EXTENSIONS):
                for ext in PB_EXTENSIONS:
                    path = os.path.join(cpath, to_native(acr.resource + ext))
                    if os.path.exists(to_bytes(path)):
                        return acr.resource, path, acr.collection
    return None


</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/target/legacy_collection_loader/_collection_finder.py" startline="881" endline="910" pcid="8069">
def _get_collection_playbook_path(playbook):

    acr = AnsibleCollectionRef.try_parse_fqcr(playbook, u'playbook')
    if acr:
        try:
            # get_collection_path
            pkg = import_module(acr.n_python_collection_package_name)
        except (IOError, ModuleNotFoundError) as e:
            # leaving e as debug target, even though not used in normal code
            pkg = None

        if pkg:
            cpath = os.path.join(sys.modules[acr.n_python_collection_package_name].__file__.replace('__synthetic__', 'playbooks'))

            if acr.subdirs:
                paths = [to_native(x) for x in acr.subdirs.split(u'.')]
                paths.insert(0, cpath)
                cpath = os.path.join(*paths)

            path = os.path.join(cpath, to_native(acr.resource))
            if os.path.exists(to_bytes(path)):
                return acr.resource, path, acr.collection
            elif not acr.resource.endswith(PB_EXTENSIONS):
                for ext in PB_EXTENSIONS:
                    path = os.path.join(cpath, to_native(acr.resource + ext))
                    if os.path.exists(to_bytes(path)):
                        return acr.resource, path, acr.collection
    return None


</source>
</class>

<class classid="23" nclones="2" nlines="25" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/utils/collection_loader/_collection_finder.py" startline="914" endline="951" pcid="568">
def _get_collection_resource_path(name, ref_type, collection_list=None):

    if ref_type == u'playbook':
        # they are handled a bit diff due to 'extension variance' and no collection_list
        return _get_collection_playbook_path(name)

    acr = AnsibleCollectionRef.try_parse_fqcr(name, ref_type)
    if acr:
        # looks like a valid qualified collection ref; skip the collection_list
        collection_list = [acr.collection]
        subdirs = acr.subdirs
        resource = acr.resource
    elif not collection_list:
        return None  # not a FQ and no collection search list spec'd, nothing to do
    else:
        resource = name  # treat as unqualified, loop through the collection search list to try and resolve
        subdirs = ''

    for collection_name in collection_list:
        try:
            acr = AnsibleCollectionRef(collection_name=collection_name, subdirs=subdirs, resource=resource, ref_type=ref_type)
            # FIXME: error handling/logging; need to catch any import failures and move along
            pkg = import_module(acr.n_python_package_name)

            if pkg is not None:
                # the package is now loaded, get the collection's package and ask where it lives
                path = os.path.dirname(to_bytes(sys.modules[acr.n_python_package_name].__file__, errors='surrogate_or_strict'))
                return resource, to_text(path, errors='surrogate_or_strict'), collection_name

        except (IOError, ModuleNotFoundError) as e:
            continue
        except Exception as ex:
            # FIXME: pick out typical import errors first, then error logging
            continue

    return None


</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/target/legacy_collection_loader/_collection_finder.py" startline="915" endline="952" pcid="8071">
def _get_collection_resource_path(name, ref_type, collection_list=None):

    if ref_type == u'playbook':
        # they are handled a bit diff due to 'extension variance' and no collection_list
        return _get_collection_playbook_path(name)

    acr = AnsibleCollectionRef.try_parse_fqcr(name, ref_type)
    if acr:
        # looks like a valid qualified collection ref; skip the collection_list
        collection_list = [acr.collection]
        subdirs = acr.subdirs
        resource = acr.resource
    elif not collection_list:
        return None  # not a FQ and no collection search list spec'd, nothing to do
    else:
        resource = name  # treat as unqualified, loop through the collection search list to try and resolve
        subdirs = ''

    for collection_name in collection_list:
        try:
            acr = AnsibleCollectionRef(collection_name=collection_name, subdirs=subdirs, resource=resource, ref_type=ref_type)
            # FIXME: error handling/logging; need to catch any import failures and move along
            pkg = import_module(acr.n_python_package_name)

            if pkg is not None:
                # the package is now loaded, get the collection's package and ask where it lives
                path = os.path.dirname(to_bytes(sys.modules[acr.n_python_package_name].__file__, errors='surrogate_or_strict'))
                return resource, to_text(path, errors='surrogate_or_strict'), collection_name

        except (IOError, ModuleNotFoundError) as e:
            continue
        except Exception as ex:
            # FIXME: pick out typical import errors first, then error logging
            continue

    return None


</source>
</class>

<class classid="24" nclones="2" nlines="18" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/utils/collection_loader/_collection_finder.py" startline="952" endline="993" pcid="569">
def _get_collection_name_from_path(path):
    """
    Return the containing collection name for a given path, or None if the path is not below a configured collection, or
    the collection cannot be loaded (eg, the collection is masked by another of the same name higher in the configured
    collection roots).
    :param path: path to evaluate for collection containment
    :return: collection name or None
    """

    # ensure we compare full paths since pkg path will be abspath
    path = to_native(os.path.abspath(to_bytes(path)))

    path_parts = path.split('/')
    if path_parts.count('ansible_collections') != 1:
        return None

    ac_pos = path_parts.index('ansible_collections')

    # make sure it's followed by at least a namespace and collection name
    if len(path_parts) < ac_pos + 3:
        return None

    candidate_collection_name = '.'.join(path_parts[ac_pos + 1:ac_pos + 3])

    try:
        # we've got a name for it, now see if the path prefix matches what the loader sees
        imported_pkg_path = to_native(os.path.dirname(to_bytes(import_module('ansible_collections.' + candidate_collection_name).__file__)))
    except ImportError:
        return None

    # reassemble the original path prefix up the collection name, and it should match what we just imported. If not
    # this is probably a collection root that's not configured.

    original_path_prefix = os.path.join('/', *path_parts[0:ac_pos + 3])

    imported_pkg_path = to_native(os.path.abspath(to_bytes(imported_pkg_path)))
    if original_path_prefix != imported_pkg_path:
        return None

    return candidate_collection_name


</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/target/legacy_collection_loader/_collection_finder.py" startline="953" endline="994" pcid="8072">
def _get_collection_name_from_path(path):
    """
    Return the containing collection name for a given path, or None if the path is not below a configured collection, or
    the collection cannot be loaded (eg, the collection is masked by another of the same name higher in the configured
    collection roots).
    :param path: path to evaluate for collection containment
    :return: collection name or None
    """

    # ensure we compare full paths since pkg path will be abspath
    path = to_native(os.path.abspath(to_bytes(path)))

    path_parts = path.split('/')
    if path_parts.count('ansible_collections') != 1:
        return None

    ac_pos = path_parts.index('ansible_collections')

    # make sure it's followed by at least a namespace and collection name
    if len(path_parts) < ac_pos + 3:
        return None

    candidate_collection_name = '.'.join(path_parts[ac_pos + 1:ac_pos + 3])

    try:
        # we've got a name for it, now see if the path prefix matches what the loader sees
        imported_pkg_path = to_native(os.path.dirname(to_bytes(import_module('ansible_collections.' + candidate_collection_name).__file__)))
    except ImportError:
        return None

    # reassemble the original path prefix up the collection name, and it should match what we just imported. If not
    # this is probably a collection root that's not configured.

    original_path_prefix = os.path.join('/', *path_parts[0:ac_pos + 3])

    imported_pkg_path = to_native(os.path.abspath(to_bytes(imported_pkg_path)))
    if original_path_prefix != imported_pkg_path:
        return None

    return candidate_collection_name


</source>
</class>

<class classid="25" nclones="2" nlines="17" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/utils/collection_loader/_collection_finder.py" startline="1024" endline="1050" pcid="573">
def _iter_modules_impl(paths, prefix=''):
    # NB: this currently only iterates what's on disk- redirected modules are not considered
    if not prefix:
        prefix = ''
    else:
        prefix = to_native(prefix)
    # yield (module_loader, name, ispkg) for each module/pkg under path
    # TODO: implement ignore/silent catch for unreadable?
    for b_path in map(to_bytes, paths):
        if not os.path.isdir(b_path):
            continue
        for b_basename in sorted(os.listdir(b_path)):
            b_candidate_module_path = os.path.join(b_path, b_basename)
            if os.path.isdir(b_candidate_module_path):
                # exclude things that obviously aren't Python package dirs
                # FIXME: this dir is adjustable in py3.8+, check for it
                if b'.' in b_basename or b_basename == b'__pycache__':
                    continue

                # TODO: proper string handling?
                yield prefix + to_native(b_basename), True
            else:
                # FIXME: match builtin ordering for package/dir/file, support compiled?
                if b_basename.endswith(b'.py') and b_basename != b'__init__.py':
                    yield prefix + to_native(os.path.splitext(b_basename)[0]), False


</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/target/legacy_collection_loader/_collection_finder.py" startline="1025" endline="1051" pcid="8076">
def _iter_modules_impl(paths, prefix=''):
    # NB: this currently only iterates what's on disk- redirected modules are not considered
    if not prefix:
        prefix = ''
    else:
        prefix = to_native(prefix)
    # yield (module_loader, name, ispkg) for each module/pkg under path
    # TODO: implement ignore/silent catch for unreadable?
    for b_path in map(to_bytes, paths):
        if not os.path.isdir(b_path):
            continue
        for b_basename in sorted(os.listdir(b_path)):
            b_candidate_module_path = os.path.join(b_path, b_basename)
            if os.path.isdir(b_candidate_module_path):
                # exclude things that obviously aren't Python package dirs
                # FIXME: this dir is adjustable in py3.8+, check for it
                if b'.' in b_basename or b_basename == b'__pycache__':
                    continue

                # TODO: proper string handling?
                yield prefix + to_native(b_basename), True
            else:
                # FIXME: match builtin ordering for package/dir/file, support compiled?
                if b_basename.endswith(b'.py') and b_basename != b'__init__.py':
                    yield prefix + to_native(os.path.splitext(b_basename)[0]), False


</source>
</class>

<class classid="26" nclones="2" nlines="12" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/utils/collection_loader/_collection_finder.py" startline="1051" endline="1066" pcid="574">
def _get_collection_metadata(collection_name):
    collection_name = to_native(collection_name)
    if not collection_name or not isinstance(collection_name, string_types) or len(collection_name.split('.')) != 2:
        raise ValueError('collection_name must be a non-empty string of the form namespace.collection')

    try:
        collection_pkg = import_module('ansible_collections.' + collection_name)
    except ImportError:
        raise ValueError('unable to locate collection {0}'.format(collection_name))

    _collection_meta = getattr(collection_pkg, '_collection_meta', None)

    if _collection_meta is None:
        raise ValueError('collection metadata was not loaded for collection {0}'.format(collection_name))

    return _collection_meta
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/target/legacy_collection_loader/_collection_finder.py" startline="1052" endline="1067" pcid="8077">
def _get_collection_metadata(collection_name):
    collection_name = to_native(collection_name)
    if not collection_name or not isinstance(collection_name, string_types) or len(collection_name.split('.')) != 2:
        raise ValueError('collection_name must be a non-empty string of the form namespace.collection')

    try:
        collection_pkg = import_module('ansible_collections.' + collection_name)
    except ImportError:
        raise ValueError('unable to locate collection {0}'.format(collection_name))

    _collection_meta = getattr(collection_pkg, '_collection_meta', None)

    if _collection_meta is None:
        raise ValueError('collection metadata was not loaded for collection {0}'.format(collection_name))

    return _collection_meta
</source>
</class>

<class classid="27" nclones="3" nlines="14" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/playbook/block.py" startline="121" endline="135" pcid="677">
    def _load_block(self, attr, ds):
        try:
            return load_list_of_tasks(
                ds,
                play=self._play,
                block=self,
                role=self._role,
                task_include=None,
                variable_manager=self._variable_manager,
                loader=self._loader,
                use_handlers=self._use_handlers,
            )
        except AssertionError as e:
            raise AnsibleParserError("A malformed block was encountered while loading a block", obj=self._ds, orig_exc=e)

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/playbook/block.py" startline="151" endline="165" pcid="679">
    def _load_always(self, attr, ds):
        try:
            return load_list_of_tasks(
                ds,
                play=self._play,
                block=self,
                role=self._role,
                task_include=None,
                variable_manager=self._variable_manager,
                loader=self._loader,
                use_handlers=self._use_handlers,
            )
        except AssertionError as e:
            raise AnsibleParserError("A malformed block was encountered while loading always", obj=self._ds, orig_exc=e)

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/playbook/block.py" startline="136" endline="150" pcid="678">
    def _load_rescue(self, attr, ds):
        try:
            return load_list_of_tasks(
                ds,
                play=self._play,
                block=self,
                role=self._role,
                task_include=None,
                variable_manager=self._variable_manager,
                loader=self._loader,
                use_handlers=self._use_handlers,
            )
        except AssertionError as e:
            raise AnsibleParserError("A malformed block was encountered while loading rescue.", obj=self._ds, orig_exc=e)

</source>
</class>

<class classid="28" nclones="2" nlines="14" similarity="73">
<source file="systems/ansible-2.12.4rc1/lib/ansible/galaxy/role.py" startline="124" endline="141" pcid="849">
    def install_info(self):
        """
        Returns role install info
        """
        if self._install_info is None:

            info_path = os.path.join(self.path, self.META_INSTALL)
            if os.path.isfile(info_path):
                try:
                    f = open(info_path, 'r')
                    self._install_info = yaml_load(f)
                except Exception:
                    display.vvvvv("Unable to load Galaxy install info for %s" % self.name)
                    return False
                finally:
                    f.close()
        return self._install_info

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/galaxy/role.py" startline="389" endline="408" pcid="856">
    def requirements(self):
        """
        Returns role requirements
        """
        if self._requirements is None:
            self._requirements = []
            for meta_requirements in self.META_REQUIREMENTS:
                meta_path = os.path.join(self.path, meta_requirements)
                if os.path.isfile(meta_path):
                    try:
                        f = open(meta_path, 'r')
                        self._requirements = yaml_load(f)
                    except Exception:
                        display.vvvvv("Unable to load requirements for %s" % self.name)
                    finally:
                        f.close()

                    break

        return self._requirements
</source>
</class>

<class classid="29" nclones="2" nlines="13" similarity="71">
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/connection/paramiko_ssh.py" startline="455" endline="474" pcid="966">
    def put_file(self, in_path, out_path):
        ''' transfer a file from local to remote '''

        super(Connection, self).put_file(in_path, out_path)

        display.vvv("PUT %s TO %s" % (in_path, out_path), host=self._play_context.remote_addr)

        if not os.path.exists(to_bytes(in_path, errors='surrogate_or_strict')):
            raise AnsibleFileNotFound("file or module does not exist: %s" % in_path)

        try:
            self.sftp = self.ssh.open_sftp()
        except Exception as e:
            raise AnsibleError("failed to open a SFTP connection (%s)" % e)

        try:
            self.sftp.put(to_bytes(in_path, errors='surrogate_or_strict'), to_bytes(out_path, errors='surrogate_or_strict'))
        except IOError:
            raise AnsibleError("failed to transfer file to %s" % out_path)

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/connection/paramiko_ssh.py" startline="484" endline="500" pcid="968">
    def fetch_file(self, in_path, out_path):
        ''' save a remote file to the specified path '''

        super(Connection, self).fetch_file(in_path, out_path)

        display.vvv("FETCH %s TO %s" % (in_path, out_path), host=self._play_context.remote_addr)

        try:
            self.sftp = self._connect_sftp()
        except Exception as e:
            raise AnsibleError("failed to open a SFTP connection (%s)" % to_native(e))

        try:
            self.sftp.get(to_bytes(in_path, errors='surrogate_or_strict'), to_bytes(out_path, errors='surrogate_or_strict'))
        except IOError:
            raise AnsibleError("failed to transfer file from %s" % in_path)

</source>
</class>

<class classid="30" nclones="2" nlines="12" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/connection/psrp.py" startline="350" endline="365" pcid="1001">
    def __init__(self, *args, **kwargs):
        self.always_pipeline_modules = True
        self.has_native_async = True

        self.runspace = None
        self.host = None
        self._last_pipeline = False

        self._shell_type = 'powershell'
        super(Connection, self).__init__(*args, **kwargs)

        if not C.DEFAULT_DEBUG:
            logging.getLogger('pypsrp').setLevel(logging.WARNING)
            logging.getLogger('requests_credssp').setLevel(logging.INFO)
            logging.getLogger('urllib3').setLevel(logging.INFO)

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/connection/winrm.py" startline="223" endline="239" pcid="1014">
    def __init__(self, *args, **kwargs):

        self.always_pipeline_modules = True
        self.has_native_async = True

        self.protocol = None
        self.shell_id = None
        self.delegate = None
        self._shell_type = 'powershell'

        super(Connection, self).__init__(*args, **kwargs)

        if not C.DEFAULT_DEBUG:
            logging.getLogger('requests_credssp').setLevel(logging.INFO)
            logging.getLogger('requests_kerberos').setLevel(logging.INFO)
            logging.getLogger('urllib3').setLevel(logging.INFO)

</source>
</class>

<class classid="31" nclones="2" nlines="13" similarity="76">
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/callback/oneline.py" startline="58" endline="72" pcid="1105">
    def v2_runner_on_ok(self, result):

        if result._result.get('changed', False):
            color = C.COLOR_CHANGED
            state = 'CHANGED'
        else:
            color = C.COLOR_OK
            state = 'SUCCESS'

        if result._task.action in C.MODULE_NO_JSON and 'ansible_job_id' not in result._result:
            self._display.display(self._command_generic_msg(result._host.get_name(), result._result, state), color=color)
        else:
            self._display.display("%s | %s => %s" % (result._host.get_name(), state, self._dump_results(result._result, indent=0).replace('\n', '')),
                                  color=color)

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/callback/minimal.py" startline="53" endline="69" pcid="1116">
    def v2_runner_on_ok(self, result):
        self._clean_results(result._result, result._task.action)

        self._handle_warnings(result._result)

        if result._result.get('changed', False):
            color = C.COLOR_CHANGED
            state = 'CHANGED'
        else:
            color = C.COLOR_OK
            state = 'SUCCESS'

        if result._task.action in C.MODULE_NO_JSON and 'ansible_job_id' not in result._result:
            self._display.display(self._command_generic_msg(result._host.get_name(), result._result, state), color=color)
        else:
            self._display.display("%s | %s => %s" % (result._host.get_name(), state, self._dump_results(result._result, indent=4)), color=color)

</source>
</class>

<class classid="32" nclones="2" nlines="17" similarity="70">
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/loader.py" startline="116" endline="133" pcid="1189">
    def __init__(self):
        self.original_name = None
        self.redirect_list = []
        self.error_list = []
        self.import_error_list = []
        self.load_attempts = []
        self.pending_redirect = None
        self.exit_reason = None
        self.plugin_resolved_path = None
        self.plugin_resolved_name = None
        self.plugin_resolved_collection = None  # empty string for resolved plugins from user-supplied paths
        self.deprecated = False
        self.removal_date = None
        self.removal_version = None
        self.deprecation_warnings = []
        self.resolved = False
        self._resolved_fqcn = None

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/action/__init__.py" startline="51" endline="73" pcid="1467">
    def __init__(self, task, connection, play_context, loader, templar, shared_loader_obj):
        self._task = task
        self._connection = connection
        self._play_context = play_context
        self._loader = loader
        self._templar = templar
        self._shared_loader_obj = shared_loader_obj
        self._cleanup_remote_tmp = False

        self._supports_check_mode = True
        self._supports_async = False

        # interpreter discovery state
        self._discovered_interpreter_key = None
        self._discovered_interpreter = False
        self._discovery_deprecation_warnings = []
        self._discovery_warnings = []

        # Backwards compat: self._display isn't really needed, just import the global display and use that.
        self._display = display

        self._used_interpreter = None

</source>
</class>

<class classid="33" nclones="2" nlines="14" similarity="71">
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/loader.py" startline="276" endline="293" pcid="1199">
    def __getstate__(self):
        '''
        Serializer.
        '''

        return dict(
            class_name=self.class_name,
            base_class=self.base_class,
            package=self.package,
            config=self.config,
            subdir=self.subdir,
            aliases=self.aliases,
            _extra_dirs=self._extra_dirs,
            _searched_paths=self._searched_paths,
            PATH_CACHE=PATH_CACHE[self.class_name],
            PLUGIN_PATH_CACHE=PLUGIN_PATH_CACHE[self.class_name],
        )

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/vars/manager.py" startline="110" endline="124" pcid="2967">
    def __getstate__(self):
        data = dict(
            fact_cache=self._fact_cache,
            np_fact_cache=self._nonpersistent_fact_cache,
            vars_cache=self._vars_cache,
            extra_vars=self._extra_vars,
            host_vars_files=self._host_vars_files,
            group_vars_files=self._group_vars_files,
            omit_token=self._omit_token,
            options_vars=self._options_vars,
            inventory=self._inventory,
            safe_basedir=self.safe_basedir,
        )
        return data

</source>
</class>

<class classid="34" nclones="2" nlines="11" similarity="75">
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/lookup/pipe.py" startline="55" endline="76" pcid="1258">
    def run(self, terms, variables, **kwargs):

        ret = []
        for term in terms:
            '''
            https://docs.python.org/3/library/subprocess.html#popen-constructor

            The shell argument (which defaults to False) specifies whether to use the
            shell as the program to execute. If shell is True, it is recommended to pass
            args as a string rather than as a sequence

            https://github.com/ansible/ansible/issues/6550
            '''
            term = str(term)

            p = subprocess.Popen(term, cwd=self._loader.get_basedir(), shell=True, stdin=subprocess.PIPE, stdout=subprocess.PIPE)
            (stdout, stderr) = p.communicate()
            if p.returncode == 0:
                ret.append(stdout.decode("utf-8").rstrip())
            else:
                raise AnsibleError("lookup_plugin.pipe(%s) returned %d" % (term, p.returncode))
        return ret
</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/lookup/lines.py" startline="52" endline="62" pcid="1279">
    def run(self, terms, variables, **kwargs):

        ret = []
        for term in terms:
            p = subprocess.Popen(term, cwd=self._loader.get_basedir(), shell=True, stdin=subprocess.PIPE, stdout=subprocess.PIPE)
            (stdout, stderr) = p.communicate()
            if p.returncode == 0:
                ret.extend([to_text(l) for l in stdout.splitlines()])
            else:
                raise AnsibleError("lookup_plugin.lines(%s) returned %d" % (term, p.returncode))
        return ret
</source>
</class>

<class classid="35" nclones="2" nlines="10" similarity="70">
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/test/core.py" startline="115" endline="131" pcid="1324">
def regex(value='', pattern='', ignorecase=False, multiline=False, match_type='search'):
    ''' Expose `re` as a boolean filter using the `search` method by default.
        This is likely only useful for `search` and `match` which already
        have their own filters.
    '''
    # In addition to ensuring the correct type, to_text here will ensure
    # _fail_with_undefined_error happens if the value is Undefined
    value = to_text(value, errors='surrogate_or_strict')
    flags = 0
    if ignorecase:
        flags |= re.I
    if multiline:
        flags |= re.M
    _re = re.compile(pattern, flags=flags)
    return bool(getattr(_re, match_type, 'search')(value))


</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/filter/core.py" startline="113" endline="126" pcid="1604">
def regex_replace(value='', pattern='', replacement='', ignorecase=False, multiline=False):
    ''' Perform a `re.sub` returning a string '''

    value = to_text(value, errors='surrogate_or_strict', nonstring='simplerepr')

    flags = 0
    if ignorecase:
        flags |= re.I
    if multiline:
        flags |= re.M
    _re = re.compile(pattern, flags=flags)
    return _re.sub(replacement, value)


</source>
</class>

<class classid="36" nclones="4" nlines="17" similarity="71">
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/test/files.py" startline="29" endline="48" pcid="1337">
    def tests(self):
        return {
            # file testing
            'is_dir': isdir,
            'directory': isdir,
            'is_file': isfile,
            'file': isfile,
            'is_link': islink,
            'link': islink,
            'exists': exists,
            'link_exists': lexists,

            # path testing
            'is_abs': isabs,
            'abs': isabs,
            'is_same_file': samefile,
            'same_file': samefile,
            'is_mount': ismount,
            'mount': ismount,
        }
</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/vyos/vyos/plugins/cliconf/vyos.py" startline="299" endline="313" pcid="6186">
    def get_device_operations(self):
        return {
            "supports_diff_replace": False,
            "supports_commit": True,
            "supports_rollback": False,
            "supports_defaults": False,
            "supports_onbox_diff": True,
            "supports_commit_comment": True,
            "supports_multiline_delimiter": False,
            "supports_diff_match": True,
            "supports_diff_ignore_lines": False,
            "supports_generate_diff": False,
            "supports_replace": False,
        }

</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/cisco/ios/plugins/cliconf/ios.py" startline="299" endline="313" pcid="6778">
    def get_device_operations(self):
        return {
            "supports_diff_replace": True,
            "supports_commit": False,
            "supports_rollback": False,
            "supports_defaults": True,
            "supports_onbox_diff": False,
            "supports_commit_comment": False,
            "supports_multiline_delimiter": True,
            "supports_diff_match": True,
            "supports_diff_ignore_lines": True,
            "supports_generate_diff": True,
            "supports_replace": False,
        }

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/filter/mathstuff.py" startline="252" endline="286" pcid="1651">
    def filters(self):
        filters = {
            # general math
            'min': min,
            'max': max,

            # exponents and logarithms
            'log': logarithm,
            'pow': power,
            'root': inversepower,

            # set theory
            'unique': unique,
            'intersect': intersect,
            'difference': difference,
            'symmetric_difference': symmetric_difference,
            'union': union,

            # combinatorial
            'product': itertools.product,
            'permutations': itertools.permutations,
            'combinations': itertools.combinations,

            # computer theory
            'human_readable': human_readable,
            'human_to_bytes': human_to_bytes,
            'rekey_on_member': rekey_on_member,

            # zip
            'zip': zip,
            'zip_longest': zip_longest,

        }

        return filters
</source>
</class>

<class classid="37" nclones="2" nlines="12" similarity="83">
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/strategy/__init__.py" startline="1363" endline="1374" pcid="1392">
    def evaluate(self, args):
        try:
            return eval(args, globals(), self.scope)
        except Exception:
            t, v = sys.exc_info()[:2]
            if isinstance(t, str):
                exc_type_name = t
            else:
                exc_type_name = t.__name__
            display.display('***%s:%s' % (exc_type_name, repr(v)))
            raise

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/strategy/__init__.py" startline="1385" endline="1397" pcid="1394">
    def execute(self, args):
        try:
            code = compile(args + '\n', '<stdin>', 'single')
            exec(code, globals(), self.scope)
        except Exception:
            t, v = sys.exc_info()[:2]
            if isinstance(t, str):
                exc_type_name = t
            else:
                exc_type_name = t.__name__
            display.display('***%s:%s' % (exc_type_name, repr(v)))
            raise

</source>
</class>

<class classid="38" nclones="3" nlines="13" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/action/copy.py" startline="388" endline="401" pcid="1402">
    def _create_content_tempfile(self, content):
        ''' Create a tempfile containing defined content '''
        fd, content_tempfile = tempfile.mkstemp(dir=C.DEFAULT_LOCAL_TMP)
        f = os.fdopen(fd, 'wb')
        content = to_bytes(content)
        try:
            f.write(content)
        except Exception as err:
            os.remove(content_tempfile)
            raise Exception(err)
        finally:
            f.close()
        return content_tempfile

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/parsing/dataloader.py" startline="345" endline="358" pcid="2957">
    def _create_content_tempfile(self, content):
        ''' Create a tempfile containing defined content '''
        fd, content_tempfile = tempfile.mkstemp(dir=C.DEFAULT_LOCAL_TMP)
        f = os.fdopen(fd, 'wb')
        content = to_bytes(content)
        try:
            f.write(content)
        except Exception as err:
            os.remove(content_tempfile)
            raise Exception(err)
        finally:
            f.close()
        return content_tempfile

</source>
<source file="systems/ansible-2.12.4rc1/test/support/windows-integration/plugins/action/win_copy.py" startline="221" endline="234" pcid="6817">
    def _create_content_tempfile(self, content):
        ''' Create a tempfile containing defined content '''
        fd, content_tempfile = tempfile.mkstemp(dir=C.DEFAULT_LOCAL_TMP)
        f = os.fdopen(fd, 'wb')
        content = to_bytes(content)
        try:
            f.write(content)
        except Exception as err:
            os.remove(content_tempfile)
            raise Exception(err)
        finally:
            f.close()
        return content_tempfile

</source>
</class>

<class classid="39" nclones="2" nlines="16" similarity="82">
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/action/normal.py" startline="27" endline="59" pcid="1418">
    def run(self, tmp=None, task_vars=None):

        # individual modules might disagree but as the generic the action plugin, pass at this point.
        self._supports_check_mode = True
        self._supports_async = True

        result = super(ActionModule, self).run(tmp, task_vars)
        del tmp  # tmp no longer has any effect

        if not result.get('skipped'):

            if result.get('invocation', {}).get('module_args'):
                # avoid passing to modules in case of no_log
                # should not be set anymore but here for backwards compatibility
                del result['invocation']['module_args']

            # FUTURE: better to let _execute_module calculate this internally?
            wrap_async = self._task.async_val and not self._connection.has_native_async

            # do work!
            result = merge_hash(result, self._execute_module(task_vars=task_vars, wrap_async=wrap_async))

            # hack to keep --verbose from showing all the setup module result
            # moved from setup module as now we filter out all _ansible_ from result
            # FIXME: is this still accurate with gather_facts etc, or does it need support for FQ and other names?
            if self._task.action in C._ACTION_SETUP:
                result['_ansible_verbose_override'] = True

        if not wrap_async:
            # remove a temporary path we created
            self._remove_tmp_path(self._connection._shell.tmpdir)

        return result
</source>
<source file="systems/ansible-2.12.4rc1/test/integration/targets/async_fail/action_plugins/normal.py" startline="27" endline="62" pcid="7873">
    def run(self, tmp=None, task_vars=None):

        # individual modules might disagree but as the generic the action plugin, pass at this point.
        self._supports_check_mode = True
        self._supports_async = True

        result = super(ActionModule, self).run(tmp, task_vars)
        del tmp  # tmp no longer has any effect

        if not result.get('skipped'):

            if result.get('invocation', {}).get('module_args'):
                # avoid passing to modules in case of no_log
                # should not be set anymore but here for backwards compatibility
                del result['invocation']['module_args']

            # FUTURE: better to let _execute_module calculate this internally?
            wrap_async = self._task.async_val and not self._connection.has_native_async

            # do work!
            result = merge_hash(result, self._execute_module(task_vars=task_vars, wrap_async=wrap_async))

            # hack to keep --verbose from showing all the setup module result
            # moved from setup module as now we filter out all _ansible_ from result
            if self._task.action == 'setup':
                result['_ansible_verbose_override'] = True

        # Simulate a transient network failure
        if self._task.action == 'async_status' and 'finished' in result and result['finished'] != 1:
            raise AnsibleError('Pretend to fail somewher ein executing async_status')

        if not wrap_async:
            # remove a temporary path we created
            self._remove_tmp_path(self._connection._shell.tmpdir)

        return result
</source>
</class>

<class classid="40" nclones="2" nlines="30" similarity="70">
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/action/assemble.py" startline="40" endline="82" pcid="1453">
    def _assemble_from_fragments(self, src_path, delimiter=None, compiled_regexp=None, ignore_hidden=False, decrypt=True):
        ''' assemble a file from a directory of fragments '''

        tmpfd, temp_path = tempfile.mkstemp(dir=C.DEFAULT_LOCAL_TMP)
        tmp = os.fdopen(tmpfd, 'wb')
        delimit_me = False
        add_newline = False

        for f in (to_text(p, errors='surrogate_or_strict') for p in sorted(os.listdir(src_path))):
            if compiled_regexp and not compiled_regexp.search(f):
                continue
            fragment = u"%s/%s" % (src_path, f)
            if not os.path.isfile(fragment) or (ignore_hidden and os.path.basename(fragment).startswith('.')):
                continue

            with open(self._loader.get_real_file(fragment, decrypt=decrypt), 'rb') as fragment_fh:
                fragment_content = fragment_fh.read()

            # always put a newline between fragments if the previous fragment didn't end with a newline.
            if add_newline:
                tmp.write(b'\n')

            # delimiters should only appear between fragments
            if delimit_me:
                if delimiter:
                    # un-escape anything like newlines
                    delimiter = codecs.escape_decode(delimiter)[0]
                    tmp.write(delimiter)
                    # always make sure there's a newline after the
                    # delimiter, so lines don't run together
                    if delimiter[-1] != b'\n':
                        tmp.write(b'\n')

            tmp.write(fragment_content)
            delimit_me = True
            if fragment_content.endswith(b'\n'):
                add_newline = False
            else:
                add_newline = True

        tmp.close()
        return temp_path

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/assemble.py" startline="140" endline="185" pcid="3536">
def assemble_from_fragments(src_path, delimiter=None, compiled_regexp=None, ignore_hidden=False, tmpdir=None):
    ''' assemble a file from a directory of fragments '''
    tmpfd, temp_path = tempfile.mkstemp(dir=tmpdir)
    tmp = os.fdopen(tmpfd, 'wb')
    delimit_me = False
    add_newline = False

    for f in sorted(os.listdir(src_path)):
        if compiled_regexp and not compiled_regexp.search(f):
            continue
        fragment = os.path.join(src_path, f)
        if not os.path.isfile(fragment) or (ignore_hidden and os.path.basename(fragment).startswith('.')):
            continue
        with open(fragment, 'rb') as fragment_fh:
            fragment_content = fragment_fh.read()

        # always put a newline between fragments if the previous fragment didn't end with a newline.
        if add_newline:
            tmp.write(b('\n'))

        # delimiters should only appear between fragments
        if delimit_me:
            if delimiter:
                # un-escape anything like newlines
                delimiter = codecs.escape_decode(delimiter)[0]
                tmp.write(delimiter)
                # always make sure there's a newline after the
                # delimiter, so lines don't run together

                # byte indexing differs on Python 2 and 3,
                # use indexbytes for compat
                # chr(10) == '\n'
                if indexbytes(delimiter, -1) != 10:
                    tmp.write(b('\n'))

        tmp.write(fragment_content)
        delimit_me = True
        if fragment_content.endswith(b('\n')):
            add_newline = False
        else:
            add_newline = True

    tmp.close()
    return temp_path


</source>
</class>

<class classid="41" nclones="2" nlines="48" similarity="77">
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/action/service.py" startline="38" endline="103" pcid="1459">
    def run(self, tmp=None, task_vars=None):
        ''' handler for package operations '''

        self._supports_check_mode = True
        self._supports_async = True

        result = super(ActionModule, self).run(tmp, task_vars)
        del tmp  # tmp no longer has any effect

        module = self._task.args.get('use', 'auto').lower()

        if module == 'auto':
            try:
                if self._task.delegate_to:  # if we delegate, we should use delegated host's facts
                    module = self._templar.template("{{hostvars['%s']['ansible_facts']['service_mgr']}}" % self._task.delegate_to)
                else:
                    module = self._templar.template('{{ansible_facts.service_mgr}}')
            except Exception:
                pass  # could not get it from template!

        try:
            if module == 'auto':
                facts = self._execute_module(
                    module_name='ansible.legacy.setup',
                    module_args=dict(gather_subset='!all', filter='ansible_service_mgr'), task_vars=task_vars)
                self._display.debug("Facts %s" % facts)
                module = facts.get('ansible_facts', {}).get('ansible_service_mgr', 'auto')

            if not module or module == 'auto' or not self._shared_loader_obj.module_loader.has_plugin(module):
                module = 'ansible.legacy.service'

            if module != 'auto':
                # run the 'service' module
                new_module_args = self._task.args.copy()
                if 'use' in new_module_args:
                    del new_module_args['use']

                if module in self.UNUSED_PARAMS:
                    for unused in self.UNUSED_PARAMS[module]:
                        if unused in new_module_args:
                            del new_module_args[unused]
                            self._display.warning('Ignoring "%s" as it is not used in "%s"' % (unused, module))

                # get defaults for specific module
                context = self._shared_loader_obj.module_loader.find_plugin_with_context(module, collection_list=self._task.collections)
                new_module_args = get_action_args_with_defaults(
                    context.resolved_fqcn, new_module_args, self._task.module_defaults, self._templar,
                    action_groups=self._task._parent._play._action_groups
                )

                # collection prefix known internal modules to avoid collisions from collections search, while still allowing library/ overrides
                if module in self.BUILTIN_SVC_MGR_MODULES:
                    module = 'ansible.legacy.' + module

                self._display.vvvv("Running %s" % module)
                result.update(self._execute_module(module_name=module, module_args=new_module_args, task_vars=task_vars, wrap_async=self._task.async_val))
            else:
                raise AnsibleActionFail('Could not detect which service manager to use. Try gathering facts or setting the "use" option.')

        except AnsibleAction as e:
            result.update(e.result)
        finally:
            if not self._task.async_val:
                self._remove_tmp_path(self._connection._shell.tmpdir)

        return result
</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/action/package.py" startline="35" endline="96" pcid="1462">
    def run(self, tmp=None, task_vars=None):
        ''' handler for package operations '''

        self._supports_check_mode = True
        self._supports_async = True

        result = super(ActionModule, self).run(tmp, task_vars)
        del tmp  # tmp no longer has any effect

        module = self._task.args.get('use', 'auto')

        if module == 'auto':
            try:
                if self._task.delegate_to:  # if we delegate, we should use delegated host's facts
                    module = self._templar.template("{{hostvars['%s']['ansible_facts']['pkg_mgr']}}" % self._task.delegate_to)
                else:
                    module = self._templar.template('{{ansible_facts.pkg_mgr}}')
            except Exception:
                pass  # could not get it from template!

        try:
            if module == 'auto':
                facts = self._execute_module(
                    module_name='ansible.legacy.setup',
                    module_args=dict(filter='ansible_pkg_mgr', gather_subset='!all'),
                    task_vars=task_vars)
                display.debug("Facts %s" % facts)
                module = facts.get('ansible_facts', {}).get('ansible_pkg_mgr', 'auto')

            if module != 'auto':
                if not self._shared_loader_obj.module_loader.has_plugin(module):
                    raise AnsibleActionFail('Could not find a module for %s.' % module)
                else:
                    # run the 'package' module
                    new_module_args = self._task.args.copy()
                    if 'use' in new_module_args:
                        del new_module_args['use']

                    # get defaults for specific module
                    context = self._shared_loader_obj.module_loader.find_plugin_with_context(module, collection_list=self._task.collections)
                    new_module_args = get_action_args_with_defaults(
                        context.resolved_fqcn, new_module_args, self._task.module_defaults, self._templar,
                        action_groups=self._task._parent._play._action_groups
                    )

                    if module in self.BUILTIN_PKG_MGR_MODULES:
                        # prefix with ansible.legacy to eliminate external collisions while still allowing library/ override
                        module = 'ansible.legacy.' + module

                    display.vvvv("Running %s" % module)
                    result.update(self._execute_module(module_name=module, module_args=new_module_args, task_vars=task_vars, wrap_async=self._task.async_val))
            else:
                raise AnsibleActionFail('Could not detect which package manager to use. Try gathering facts or setting the "use" option.')

        except AnsibleAction as e:
            result.update(e.result)
        finally:
            if not self._task.async_val:
                # remove a temporary path we created
                self._remove_tmp_path(self._connection._shell.tmpdir)

        return result
</source>
</class>

<class classid="42" nclones="2" nlines="34" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/action/debug.py" startline="33" endline="80" pcid="1463">
    def run(self, tmp=None, task_vars=None):
        if task_vars is None:
            task_vars = dict()

        if 'msg' in self._task.args and 'var' in self._task.args:
            return {"failed": True, "msg": "'msg' and 'var' are incompatible options"}

        result = super(ActionModule, self).run(tmp, task_vars)
        del tmp  # tmp no longer has any effect

        # get task verbosity
        verbosity = int(self._task.args.get('verbosity', 0))

        if verbosity <= self._display.verbosity:
            if 'msg' in self._task.args:
                result['msg'] = self._task.args['msg']

            elif 'var' in self._task.args:
                try:
                    results = self._templar.template(self._task.args['var'], convert_bare=True, fail_on_undefined=True)
                    if results == self._task.args['var']:
                        # if results is not str/unicode type, raise an exception
                        if not isinstance(results, string_types):
                            raise AnsibleUndefinedVariable
                        # If var name is same as result, try to template it
                        results = self._templar.template("{{" + results + "}}", convert_bare=True, fail_on_undefined=True)
                except AnsibleUndefinedVariable as e:
                    results = u"VARIABLE IS NOT DEFINED!"
                    if self._display.verbosity > 0:
                        results += u": %s" % to_text(e)

                if isinstance(self._task.args['var'], (list, dict)):
                    # If var is a list or dict, use the type as key to display
                    result[to_text(type(self._task.args['var']))] = results
                else:
                    result[self._task.args['var']] = results
            else:
                result['msg'] = 'Hello world!'

            # force flag to make debug output module always verbose
            result['_ansible_verbose_always'] = True
        else:
            result['skipped_reason'] = "Verbosity threshold not met."
            result['skipped'] = True

        result['failed'] = False

        return result
</source>
<source file="systems/ansible-2.12.4rc1/test/integration/targets/module_defaults/action_plugins/debug.py" startline="33" endline="80" pcid="7730">
    def run(self, tmp=None, task_vars=None):
        if task_vars is None:
            task_vars = dict()

        if 'msg' in self._task.args and 'var' in self._task.args:
            return {"failed": True, "msg": "'msg' and 'var' are incompatible options"}

        result = super(ActionModule, self).run(tmp, task_vars)
        del tmp  # tmp no longer has any effect

        # get task verbosity
        verbosity = int(self._task.args.get('verbosity', 0))

        if verbosity <= self._display.verbosity:
            if 'msg' in self._task.args:
                result['msg'] = self._task.args['msg']

            elif 'var' in self._task.args:
                try:
                    results = self._templar.template(self._task.args['var'], convert_bare=True, fail_on_undefined=True)
                    if results == self._task.args['var']:
                        # if results is not str/unicode type, raise an exception
                        if not isinstance(results, string_types):
                            raise AnsibleUndefinedVariable
                        # If var name is same as result, try to template it
                        results = self._templar.template("{{" + results + "}}", convert_bare=True, fail_on_undefined=True)
                except AnsibleUndefinedVariable as e:
                    results = u"VARIABLE IS NOT DEFINED!"
                    if self._display.verbosity > 0:
                        results += u": %s" % to_text(e)

                if isinstance(self._task.args['var'], (list, dict)):
                    # If var is a list or dict, use the type as key to display
                    result[to_text(type(self._task.args['var']))] = results
                else:
                    result[self._task.args['var']] = results
            else:
                result['msg'] = 'Hello world!'

            # force flag to make debug output module always verbose
            result['_ansible_verbose_always'] = True
        else:
            result['skipped_reason'] = "Verbosity threshold not met."
            result['skipped'] = True

        result['failed'] = False

        return result
</source>
</class>

<class classid="43" nclones="2" nlines="18" similarity="83">
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/inventory/advanced_host_list.py" startline="43" endline="63" pcid="1517">
    def parse(self, inventory, loader, host_list, cache=True):
        ''' parses the inventory file '''

        super(InventoryModule, self).parse(inventory, loader, host_list)

        try:
            for h in host_list.split(','):
                h = h.strip()
                if h:
                    try:
                        (hostnames, port) = self._expand_hostpattern(h)
                    except AnsibleError as e:
                        self.display.vvv("Unable to parse address from hostname, leaving unchanged: %s" % to_text(e))
                        hostnames = [h]
                        port = None

                    for host in hostnames:
                        if host not in self.inventory.hosts:
                            self.inventory.add_host(host, group='ungrouped', port=port)
        except Exception as e:
            raise AnsibleParserError("Invalid data from string, could not parse: %s" % to_native(e))
</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/inventory/host_list.py" startline="47" endline="66" pcid="1530">
    def parse(self, inventory, loader, host_list, cache=True):
        ''' parses the inventory file '''

        super(InventoryModule, self).parse(inventory, loader, host_list)

        try:
            for h in host_list.split(','):
                h = h.strip()
                if h:
                    try:
                        (host, port) = parse_address(h, allow_ranges=False)
                    except AnsibleError as e:
                        self.display.vvv("Unable to parse address from hostname, leaving unchanged: %s" % to_text(e))
                        host = h
                        port = None

                    if host not in self.inventory.hosts:
                        self.inventory.add_host(host, group='ungrouped', port=port)
        except Exception as e:
            raise AnsibleParserError("Invalid data from string, could not parse: %s" % to_native(e))
</source>
</class>

<class classid="44" nclones="2" nlines="19" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/inventory/yaml.py" startline="96" endline="121" pcid="1538">
    def parse(self, inventory, loader, path, cache=True):
        ''' parses the inventory file '''

        super(InventoryModule, self).parse(inventory, loader, path)
        self.set_options()

        try:
            data = self.loader.load_from_file(path, cache=False)
        except Exception as e:
            raise AnsibleParserError(e)

        if not data:
            raise AnsibleParserError('Parsed empty YAML file')
        elif not isinstance(data, MutableMapping):
            raise AnsibleParserError('YAML inventory has invalid structure, it should be a dictionary, got: %s' % type(data))
        elif data.get('plugin'):
            raise AnsibleParserError('Plugin configuration YAML file, not YAML inventory')

        # We expect top level keys to correspond to groups, iterate over them
        # to get host, vars and subgroups (which we iterate over recursivelly)
        if isinstance(data, MutableMapping):
            for group_name in data:
                self._parse_group(group_name, data[group_name])
        else:
            raise AnsibleParserError("Invalid data from file, expected dictionary and got:\n\n%s" % to_native(data))

</source>
<source file="systems/ansible-2.12.4rc1/test/integration/targets/rel_plugin_loading/subdir/inventory_plugins/notyaml.py" startline="89" endline="114" pcid="7969">
    def parse(self, inventory, loader, path, cache=True):
        ''' parses the inventory file '''

        super(InventoryModule, self).parse(inventory, loader, path)
        self.set_options()

        try:
            data = self.loader.load_from_file(path, cache=False)
        except Exception as e:
            raise AnsibleParserError(e)

        if not data:
            raise AnsibleParserError('Parsed empty YAML file')
        elif not isinstance(data, MutableMapping):
            raise AnsibleParserError('YAML inventory has invalid structure, it should be a dictionary, got: %s' % type(data))
        elif data.get('plugin'):
            raise AnsibleParserError('Plugin configuration YAML file, not YAML inventory')

        # We expect top level keys to correspond to groups, iterate over them
        # to get host, vars and subgroups (which we iterate over recursivelly)
        if isinstance(data, MutableMapping):
            for group_name in data:
                self._parse_group(group_name, data[group_name])
        else:
            raise AnsibleParserError("Invalid data from file, expected dictionary and got:\n\n%s" % to_native(data))

</source>
</class>

<class classid="45" nclones="2" nlines="36" similarity="91">
<source file="systems/ansible-2.12.4rc1/lib/ansible/plugins/inventory/yaml.py" startline="122" endline="170" pcid="1539">
    def _parse_group(self, group, group_data):

        if isinstance(group_data, (MutableMapping, NoneType)):

            try:
                group = self.inventory.add_group(group)
            except AnsibleError as e:
                raise AnsibleParserError("Unable to add group %s: %s" % (group, to_text(e)))

            if group_data is not None:
                # make sure they are dicts
                for section in ['vars', 'children', 'hosts']:
                    if section in group_data:
                        # convert strings to dicts as these are allowed
                        if isinstance(group_data[section], string_types):
                            group_data[section] = {group_data[section]: None}

                        if not isinstance(group_data[section], (MutableMapping, NoneType)):
                            raise AnsibleParserError('Invalid "%s" entry for "%s" group, requires a dictionary, found "%s" instead.' %
                                                     (section, group, type(group_data[section])))

                for key in group_data:

                    if not isinstance(group_data[key], (MutableMapping, NoneType)):
                        self.display.warning('Skipping key (%s) in group (%s) as it is not a mapping, it is a %s' % (key, group, type(group_data[key])))
                        continue

                    if isinstance(group_data[key], NoneType):
                        self.display.vvv('Skipping empty key (%s) in group (%s)' % (key, group))
                    elif key == 'vars':
                        for var in group_data[key]:
                            self.inventory.set_variable(group, var, group_data[key][var])
                    elif key == 'children':
                        for subgroup in group_data[key]:
                            subgroup = self._parse_group(subgroup, group_data[key][subgroup])
                            self.inventory.add_child(group, subgroup)

                    elif key == 'hosts':
                        for host_pattern in group_data[key]:
                            hosts, port = self._parse_host(host_pattern)
                            self._populate_host_vars(hosts, group_data[key][host_pattern] or {}, group, port)
                    else:
                        self.display.warning('Skipping unexpected key (%s) in group (%s), only "vars", "children" and "hosts" are valid' % (key, group))

        else:
            self.display.warning("Skipping '%s' as this is not a valid group definition" % group)

        return group

</source>
<source file="systems/ansible-2.12.4rc1/test/integration/targets/rel_plugin_loading/subdir/inventory_plugins/notyaml.py" startline="115" endline="161" pcid="7970">
    def _parse_group(self, group, group_data):

        if isinstance(group_data, (MutableMapping, NoneType)):

            try:
                self.inventory.add_group(group)
            except AnsibleError as e:
                raise AnsibleParserError("Unable to add group %s: %s" % (group, to_text(e)))

            if group_data is not None:
                # make sure they are dicts
                for section in ['vars', 'children', 'hosts']:
                    if section in group_data:
                        # convert strings to dicts as these are allowed
                        if isinstance(group_data[section], string_types):
                            group_data[section] = {group_data[section]: None}

                        if not isinstance(group_data[section], (MutableMapping, NoneType)):
                            raise AnsibleParserError('Invalid "%s" entry for "%s" group, requires a dictionary, found "%s" instead.' %
                                                     (section, group, type(group_data[section])))

                for key in group_data:

                    if not isinstance(group_data[key], (MutableMapping, NoneType)):
                        self.display.warning('Skipping key (%s) in group (%s) as it is not a mapping, it is a %s' % (key, group, type(group_data[key])))
                        continue

                    if isinstance(group_data[key], NoneType):
                        self.display.vvv('Skipping empty key (%s) in group (%s)' % (key, group))
                    elif key == 'vars':
                        for var in group_data[key]:
                            self.inventory.set_variable(group, var, group_data[key][var])
                    elif key == 'children':
                        for subgroup in group_data[key]:
                            self._parse_group(subgroup, group_data[key][subgroup])
                            self.inventory.add_child(group, subgroup)

                    elif key == 'hosts':
                        for host_pattern in group_data[key]:
                            hosts, port = self._parse_host(host_pattern)
                            self._populate_host_vars(hosts, group_data[key][host_pattern] or {}, group, port)
                    else:
                        self.display.warning('Skipping unexpected key (%s) in group (%s), only "vars", "children" and "hosts" are valid' % (key, group))

        else:
            self.display.warning("Skipping '%s' as this is not a valid group definition" % group)

</source>
</class>

<class classid="46" nclones="2" nlines="13" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/compat/_selectors2.py" startline="400" endline="415" pcid="2046">
        def select(self, timeout=None):
            ready = []
            fd_events = _syscall_wrapper(self._wrap_poll, True, timeout=timeout)
            for fd, event_mask in fd_events:
                events = 0
                if event_mask & ~select.POLLIN:
                    events |= EVENT_WRITE
                if event_mask & ~select.POLLOUT:
                    events |= EVENT_READ

                key = self._key_from_fd(fd)
                if key:
                    ready.append((key, events & key.events))

            return ready

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/compat/_selectors2.py" startline="527" endline="542" pcid="2058">
        def select(self, timeout=None):
            ready = []
            fd_events = _syscall_wrapper(self._wrap_poll, True, timeout=timeout)
            for fd, event_mask in fd_events:
                events = 0
                if event_mask & ~select.POLLIN:
                    events |= EVENT_WRITE
                if event_mask & ~select.POLLOUT:
                    events |= EVENT_READ

                key = self._key_from_fd(fd)
                if key:
                    ready.append((key, events & key.events))

            return ready

</source>
</class>

<class classid="47" nclones="2" nlines="13" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/splitter.py" startline="33" endline="52" pcid="2249">
def _get_quote_state(token, quote_char):
    '''
    the goal of this block is to determine if the quoted string
    is unterminated in which case it needs to be put back together
    '''
    # the char before the current one, used to see if
    # the current character is escaped
    prev_char = None
    for idx, cur_char in enumerate(token):
        if idx > 0:
            prev_char = token[idx - 1]
        if cur_char in '"\'' and prev_char != '\\':
            if quote_char:
                if cur_char == quote_char:
                    quote_char = None
            else:
                quote_char = cur_char
    return quote_char


</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/parsing/splitter.py" startline="106" endline="125" pcid="2936">
def _get_quote_state(token, quote_char):
    '''
    the goal of this block is to determine if the quoted string
    is unterminated in which case it needs to be put back together
    '''
    # the char before the current one, used to see if
    # the current character is escaped
    prev_char = None
    for idx, cur_char in enumerate(token):
        if idx > 0:
            prev_char = token[idx - 1]
        if cur_char in '"\'' and prev_char != '\\':
            if quote_char:
                if cur_char == quote_char:
                    quote_char = None
            else:
                quote_char = cur_char
    return quote_char


</source>
</class>

<class classid="48" nclones="2" nlines="65" similarity="72">
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/splitter.py" startline="68" endline="210" pcid="2251">
def split_args(args):
    '''
    Splits args on whitespace, but intelligently reassembles
    those that may have been split over a jinja2 block or quotes.

    When used in a remote module, we won't ever have to be concerned about
    jinja2 blocks, however this function is/will be used in the
    core portions as well before the args are templated.

    example input: a=b c="foo bar"
    example output: ['a=b', 'c="foo bar"']

    Basically this is a variation shlex that has some more intelligence for
    how Ansible needs to use it.
    '''

    # the list of params parsed out of the arg string
    # this is going to be the result value when we are donei
    params = []

    # here we encode the args, so we have a uniform charset to
    # work with, and split on white space
    args = args.strip()
    try:
        args = args.encode('utf-8')
        do_decode = True
    except UnicodeDecodeError:
        do_decode = False
    items = args.split('\n')

    # iterate over the tokens, and reassemble any that may have been
    # split on a space inside a jinja2 block.
    # ex if tokens are "{{", "foo", "}}" these go together

    # These variables are used
    # to keep track of the state of the parsing, since blocks and quotes
    # may be nested within each other.

    quote_char = None
    inside_quotes = False
    print_depth = 0  # used to count nested jinja2 {{ }} blocks
    block_depth = 0  # used to count nested jinja2 {% %} blocks
    comment_depth = 0  # used to count nested jinja2 {# #} blocks

    # now we loop over each split chunk, coalescing tokens if the white space
    # split occurred within quotes or a jinja2 block of some kind
    for itemidx, item in enumerate(items):

        # we split on spaces and newlines separately, so that we
        # can tell which character we split on for reassembly
        # inside quotation characters
        tokens = item.strip().split(' ')

        line_continuation = False
        for idx, token in enumerate(tokens):

            # if we hit a line continuation character, but
            # we're not inside quotes, ignore it and continue
            # on to the next token while setting a flag
            if token == '\\' and not inside_quotes:
                line_continuation = True
                continue

            # store the previous quoting state for checking later
            was_inside_quotes = inside_quotes
            quote_char = _get_quote_state(token, quote_char)
            inside_quotes = quote_char is not None

            # multiple conditions may append a token to the list of params,
            # so we keep track with this flag to make sure it only happens once
            # append means add to the end of the list, don't append means concatenate
            # it to the end of the last token
            appended = False

            # if we're inside quotes now, but weren't before, append the token
            # to the end of the list, since we'll tack on more to it later
            # otherwise, if we're inside any jinja2 block, inside quotes, or we were
            # inside quotes (but aren't now) concat this token to the last param
            if inside_quotes and not was_inside_quotes:
                params.append(token)
                appended = True
            elif print_depth or block_depth or comment_depth or inside_quotes or was_inside_quotes:
                if idx == 0 and not inside_quotes and was_inside_quotes:
                    params[-1] = "%s%s" % (params[-1], token)
                elif len(tokens) > 1:
                    spacer = ''
                    if idx > 0:
                        spacer = ' '
                    params[-1] = "%s%s%s" % (params[-1], spacer, token)
                else:
                    spacer = ''
                    if not params[-1].endswith('\n') and idx == 0:
                        spacer = '\n'
                    params[-1] = "%s%s%s" % (params[-1], spacer, token)
                appended = True

            # if the number of paired block tags is not the same, the depth has changed, so we calculate that here
            # and may append the current token to the params (if we haven't previously done so)
            prev_print_depth = print_depth
            print_depth = _count_jinja2_blocks(token, print_depth, "{{", "}}")
            if print_depth != prev_print_depth and not appended:
                params.append(token)
                appended = True

            prev_block_depth = block_depth
            block_depth = _count_jinja2_blocks(token, block_depth, "{%", "%}")
            if block_depth != prev_block_depth and not appended:
                params.append(token)
                appended = True

            prev_comment_depth = comment_depth
            comment_depth = _count_jinja2_blocks(token, comment_depth, "{#", "#}")
            if comment_depth != prev_comment_depth and not appended:
                params.append(token)
                appended = True

            # finally, if we're at zero depth for all blocks and not inside quotes, and have not
            # yet appended anything to the list of params, we do so now
            if not (print_depth or block_depth or comment_depth) and not inside_quotes and not appended and token != '':
                params.append(token)

        # if this was the last token in the list, and we have more than
        # one item (meaning we split on newlines), add a newline back here
        # to preserve the original structure
        if len(items) > 1 and itemidx != len(items) - 1 and not line_continuation:
            if not params[-1].endswith('\n') or item == '':
                params[-1] += '\n'

        # always clear the line continuation flag
        line_continuation = False

    # If we're done and things are not at zero depth or we're still inside quotes,
    # raise an error to indicate that the args were unbalanced
    if print_depth or block_depth or comment_depth or inside_quotes:
        raise Exception("error while splitting arguments, either an unbalanced jinja2 block or quotes")

    # finally, we decode each param back to the unicode it was in the arg string
    if do_decode:
        params = [x.decode('utf-8') for x in params]

    return params


</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/parsing/splitter.py" startline="155" endline="286" pcid="2939">
def split_args(args):
    '''
    Splits args on whitespace, but intelligently reassembles
    those that may have been split over a jinja2 block or quotes.

    When used in a remote module, we won't ever have to be concerned about
    jinja2 blocks, however this function is/will be used in the
    core portions as well before the args are templated.

    example input: a=b c="foo bar"
    example output: ['a=b', 'c="foo bar"']

    Basically this is a variation shlex that has some more intelligence for
    how Ansible needs to use it.
    '''

    # the list of params parsed out of the arg string
    # this is going to be the result value when we are done
    params = []

    # Initial split on newlines
    items = args.split('\n')

    # iterate over the tokens, and reassemble any that may have been
    # split on a space inside a jinja2 block.
    # ex if tokens are "{{", "foo", "}}" these go together

    # These variables are used
    # to keep track of the state of the parsing, since blocks and quotes
    # may be nested within each other.

    quote_char = None
    inside_quotes = False
    print_depth = 0  # used to count nested jinja2 {{ }} blocks
    block_depth = 0  # used to count nested jinja2 {% %} blocks
    comment_depth = 0  # used to count nested jinja2 {# #} blocks

    # now we loop over each split chunk, coalescing tokens if the white space
    # split occurred within quotes or a jinja2 block of some kind
    for (itemidx, item) in enumerate(items):

        # we split on spaces and newlines separately, so that we
        # can tell which character we split on for reassembly
        # inside quotation characters
        tokens = item.split(' ')

        line_continuation = False
        for (idx, token) in enumerate(tokens):

            # Empty entries means we have subsequent spaces
            # We want to hold onto them so we can reconstruct them later
            if len(token) == 0 and idx != 0:
                params[-1] += ' '
                continue

            # if we hit a line continuation character, but
            # we're not inside quotes, ignore it and continue
            # on to the next token while setting a flag
            if token == '\\' and not inside_quotes:
                line_continuation = True
                continue

            # store the previous quoting state for checking later
            was_inside_quotes = inside_quotes
            quote_char = _get_quote_state(token, quote_char)
            inside_quotes = quote_char is not None

            # multiple conditions may append a token to the list of params,
            # so we keep track with this flag to make sure it only happens once
            # append means add to the end of the list, don't append means concatenate
            # it to the end of the last token
            appended = False

            # if we're inside quotes now, but weren't before, append the token
            # to the end of the list, since we'll tack on more to it later
            # otherwise, if we're inside any jinja2 block, inside quotes, or we were
            # inside quotes (but aren't now) concat this token to the last param
            if inside_quotes and not was_inside_quotes and not(print_depth or block_depth or comment_depth):
                params.append(token)
                appended = True
            elif print_depth or block_depth or comment_depth or inside_quotes or was_inside_quotes:
                if idx == 0 and was_inside_quotes:
                    params[-1] = "%s%s" % (params[-1], token)
                elif len(tokens) > 1:
                    spacer = ''
                    if idx > 0:
                        spacer = ' '
                    params[-1] = "%s%s%s" % (params[-1], spacer, token)
                else:
                    params[-1] = "%s\n%s" % (params[-1], token)
                appended = True

            # if the number of paired block tags is not the same, the depth has changed, so we calculate that here
            # and may append the current token to the params (if we haven't previously done so)
            prev_print_depth = print_depth
            print_depth = _count_jinja2_blocks(token, print_depth, "{{", "}}")
            if print_depth != prev_print_depth and not appended:
                params.append(token)
                appended = True

            prev_block_depth = block_depth
            block_depth = _count_jinja2_blocks(token, block_depth, "{%", "%}")
            if block_depth != prev_block_depth and not appended:
                params.append(token)
                appended = True

            prev_comment_depth = comment_depth
            comment_depth = _count_jinja2_blocks(token, comment_depth, "{#", "#}")
            if comment_depth != prev_comment_depth and not appended:
                params.append(token)
                appended = True

            # finally, if we're at zero depth for all blocks and not inside quotes, and have not
            # yet appended anything to the list of params, we do so now
            if not (print_depth or block_depth or comment_depth) and not inside_quotes and not appended and token != '':
                params.append(token)

        # if this was the last token in the list, and we have more than
        # one item (meaning we split on newlines), add a newline back here
        # to preserve the original structure
        if len(items) > 1 and itemidx != len(items) - 1 and not line_continuation:
            params[-1] += '\n'

        # always clear the line continuation flag
        line_continuation = False

    # If we're done and things are not at zero depth or we're still inside quotes,
    # raise an error to indicate that the args were unbalanced
    if print_depth or block_depth or comment_depth or inside_quotes:
        raise AnsibleParserError(u"failed at splitting arguments, either an unbalanced jinja2 block or quotes: {0}".format(args))

    return params
</source>
</class>

<class classid="49" nclones="2" nlines="17" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/common/network.py" startline="86" endline="115" pcid="2275">
def to_ipv6_subnet(addr):
    """ IPv6 addresses are eight groupings. The first four groupings (64 bits) comprise the subnet address. """

    # https://tools.ietf.org/rfc/rfc2374.txt

    # Split by :: to identify omitted zeros
    ipv6_prefix = addr.split('::')[0]

    # Get the first four groups, or as many as are found + ::
    found_groups = []
    for group in ipv6_prefix.split(':'):
        found_groups.append(group)
        if len(found_groups) == 4:
            break
    if len(found_groups) < 4:
        found_groups.append('::')

    # Concatenate network address parts
    network_addr = ''
    for group in found_groups:
        if group != '::':
            network_addr += str(group)
        network_addr += str(':')

    # Ensure network address ends with ::
    if not network_addr.endswith('::'):
        network_addr += str(':')
    return network_addr


</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/common/network.py" startline="116" endline="143" pcid="2276">
def to_ipv6_network(addr):
    """ IPv6 addresses are eight groupings. The first three groupings (48 bits) comprise the network address. """

    # Split by :: to identify omitted zeros
    ipv6_prefix = addr.split('::')[0]

    # Get the first three groups, or as many as are found + ::
    found_groups = []
    for group in ipv6_prefix.split(':'):
        found_groups.append(group)
        if len(found_groups) == 3:
            break
    if len(found_groups) < 3:
        found_groups.append('::')

    # Concatenate network address parts
    network_addr = ''
    for group in found_groups:
        if group != '::':
            network_addr += str(group)
        network_addr += str(':')

    # Ensure network address ends with ::
    if not network_addr.endswith('::'):
        network_addr += str(':')
    return network_addr


</source>
</class>

<class classid="50" nclones="3" nlines="15" similarity="70">
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/common/validation.py" startline="70" endline="102" pcid="2311">
def check_mutually_exclusive(terms, parameters, options_context=None):
    """Check mutually exclusive terms against argument parameters

    Accepts a single list or list of lists that are groups of terms that should be
    mutually exclusive with one another

    :arg terms: List of mutually exclusive parameters
    :arg parameters: Dictionary of parameters
    :kwarg options_context: List of strings of parent key names if ``terms`` are
        in a sub spec.

    :returns: Empty list or raises :class:`TypeError` if the check fails.
    """

    results = []
    if terms is None:
        return results

    for check in terms:
        count = count_terms(check, parameters)
        if count > 1:
            results.append(check)

    if results:
        full_list = ['|'.join(check) for check in results]
        msg = "parameters are mutually exclusive: %s" % ', '.join(full_list)
        if options_context:
            msg = "{0} found in {1}".format(msg, " -> ".join(options_context))
        raise TypeError(to_native(msg))

    return results


</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/common/validation.py" startline="103" endline="136" pcid="2312">
def check_required_one_of(terms, parameters, options_context=None):
    """Check each list of terms to ensure at least one exists in the given module
    parameters

    Accepts a list of lists or tuples

    :arg terms: List of lists of terms to check. For each list of terms, at
        least one is required.
    :arg parameters: Dictionary of parameters
    :kwarg options_context: List of strings of parent key names if ``terms`` are
        in a sub spec.

    :returns: Empty list or raises :class:`TypeError` if the check fails.
    """

    results = []
    if terms is None:
        return results

    for term in terms:
        count = count_terms(term, parameters)
        if count == 0:
            results.append(term)

    if results:
        for term in results:
            msg = "one of the following is required: %s" % ', '.join(term)
            if options_context:
                msg = "{0} found in {1}".format(msg, " -> ".join(options_context))
            raise TypeError(to_native(msg))

    return results


</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/common/validation.py" startline="137" endline="172" pcid="2313">
def check_required_together(terms, parameters, options_context=None):
    """Check each list of terms to ensure every parameter in each list exists
    in the given parameters.

    Accepts a list of lists or tuples.

    :arg terms: List of lists of terms to check. Each list should include
        parameters that are all required when at least one is specified
        in the parameters.
    :arg parameters: Dictionary of parameters
    :kwarg options_context: List of strings of parent key names if ``terms`` are
        in a sub spec.

    :returns: Empty list or raises :class:`TypeError` if the check fails.
    """

    results = []
    if terms is None:
        return results

    for term in terms:
        counts = [count_terms(field, parameters) for field in term]
        non_zero = [c for c in counts if c > 0]
        if len(non_zero) > 0:
            if 0 in counts:
                results.append(term)
    if results:
        for term in results:
            msg = "parameters are required together: %s" % ', '.join(term)
            if options_context:
                msg = "{0} found in {1}".format(msg, " -> ".join(options_context))
            raise TypeError(to_native(msg))

    return results


</source>
</class>

<class classid="51" nclones="2" nlines="33" similarity="72">
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/common/text/converters.py" startline="33" endline="149" pcid="2355">
def to_bytes(obj, encoding='utf-8', errors=None, nonstring='simplerepr'):
    """Make sure that a string is a byte string

    :arg obj: An object to make sure is a byte string.  In most cases this
        will be either a text string or a byte string.  However, with
        ``nonstring='simplerepr'``, this can be used as a traceback-free
        version of ``str(obj)``.
    :kwarg encoding: The encoding to use to transform from a text string to
        a byte string.  Defaults to using 'utf-8'.
    :kwarg errors: The error handler to use if the text string is not
        encodable using the specified encoding.  Any valid `codecs error
        handler <https://docs.python.org/3/library/codecs.html#codec-base-classes>`_
        may be specified. There are three additional error strategies
        specifically aimed at helping people to port code.  The first two are:

            :surrogate_or_strict: Will use ``surrogateescape`` if it is a valid
                handler, otherwise it will use ``strict``
            :surrogate_or_replace: Will use ``surrogateescape`` if it is a valid
                handler, otherwise it will use ``replace``.

        Because ``surrogateescape`` was added in Python3 this usually means that
        Python3 will use ``surrogateescape`` and Python2 will use the fallback
        error handler. Note that the code checks for ``surrogateescape`` when the
        module is imported.  If you have a backport of ``surrogateescape`` for
        Python2, be sure to register the error handler prior to importing this
        module.

        The last error handler is:

            :surrogate_then_replace: Will use ``surrogateescape`` if it is a valid
                handler.  If encoding with ``surrogateescape`` would traceback,
                surrogates are first replaced with a replacement characters
                and then the string is encoded using ``replace`` (which replaces
                the rest of the nonencodable bytes).  If ``surrogateescape`` is
                not present it will simply use ``replace``.  (Added in Ansible 2.3)
                This strategy is designed to never traceback when it attempts
                to encode a string.

        The default until Ansible-2.2 was ``surrogate_or_replace``
        From Ansible-2.3 onwards, the default is ``surrogate_then_replace``.

    :kwarg nonstring: The strategy to use if a nonstring is specified in
        ``obj``.  Default is 'simplerepr'.  Valid values are:

        :simplerepr: The default.  This takes the ``str`` of the object and
            then returns the bytes version of that string.
        :empty: Return an empty byte string
        :passthru: Return the object passed in
        :strict: Raise a :exc:`TypeError`

    :returns: Typically this returns a byte string.  If a nonstring object is
        passed in this may be a different type depending on the strategy
        specified by nonstring.  This will never return a text string.

    .. note:: If passed a byte string, this function does not check that the
        string is valid in the specified encoding.  If it's important that the
        byte string is in the specified encoding do::

            encoded_string = to_bytes(to_text(input_string, 'latin-1'), 'utf-8')

    .. version_changed:: 2.3

        Added the ``surrogate_then_replace`` error handler and made it the default error handler.
    """
    if isinstance(obj, binary_type):
        return obj

    # We're given a text string
    # If it has surrogates, we know because it will decode
    original_errors = errors
    if errors in _COMPOSED_ERROR_HANDLERS:
        if HAS_SURROGATEESCAPE:
            errors = 'surrogateescape'
        elif errors == 'surrogate_or_strict':
            errors = 'strict'
        else:
            errors = 'replace'

    if isinstance(obj, text_type):
        try:
            # Try this first as it's the fastest
            return obj.encode(encoding, errors)
        except UnicodeEncodeError:
            if original_errors in (None, 'surrogate_then_replace'):
                # We should only reach this if encoding was non-utf8 original_errors was
                # surrogate_then_escape and errors was surrogateescape

                # Slow but works
                return_string = obj.encode('utf-8', 'surrogateescape')
                return_string = return_string.decode('utf-8', 'replace')
                return return_string.encode(encoding, 'replace')
            raise

    # Note: We do these last even though we have to call to_bytes again on the
    # value because we're optimizing the common case
    if nonstring == 'simplerepr':
        try:
            value = str(obj)
        except UnicodeError:
            try:
                value = repr(obj)
            except UnicodeError:
                # Giving up
                return to_bytes('')
    elif nonstring == 'passthru':
        return obj
    elif nonstring == 'empty':
        # python2.4 doesn't have b''
        return to_bytes('')
    elif nonstring == 'strict':
        raise TypeError('obj must be a string type')
    else:
        raise TypeError('Invalid value %s for to_bytes\' nonstring parameter' % nonstring)

    return to_bytes(value, encoding, errors)


</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/common/text/converters.py" startline="150" endline="255" pcid="2356">
def to_text(obj, encoding='utf-8', errors=None, nonstring='simplerepr'):
    """Make sure that a string is a text string

    :arg obj: An object to make sure is a text string.  In most cases this
        will be either a text string or a byte string.  However, with
        ``nonstring='simplerepr'``, this can be used as a traceback-free
        version of ``str(obj)``.
    :kwarg encoding: The encoding to use to transform from a byte string to
        a text string.  Defaults to using 'utf-8'.
    :kwarg errors: The error handler to use if the byte string is not
        decodable using the specified encoding.  Any valid `codecs error
        handler <https://docs.python.org/3/library/codecs.html#codec-base-classes>`_
        may be specified.   We support three additional error strategies
        specifically aimed at helping people to port code:

            :surrogate_or_strict: Will use surrogateescape if it is a valid
                handler, otherwise it will use strict
            :surrogate_or_replace: Will use surrogateescape if it is a valid
                handler, otherwise it will use replace.
            :surrogate_then_replace: Does the same as surrogate_or_replace but
                `was added for symmetry with the error handlers in
                :func:`ansible.module_utils._text.to_bytes` (Added in Ansible 2.3)

        Because surrogateescape was added in Python3 this usually means that
        Python3 will use `surrogateescape` and Python2 will use the fallback
        error handler. Note that the code checks for surrogateescape when the
        module is imported.  If you have a backport of `surrogateescape` for
        python2, be sure to register the error handler prior to importing this
        module.

        The default until Ansible-2.2 was `surrogate_or_replace`
        In Ansible-2.3 this defaults to `surrogate_then_replace` for symmetry
        with :func:`ansible.module_utils._text.to_bytes` .
    :kwarg nonstring: The strategy to use if a nonstring is specified in
        ``obj``.  Default is 'simplerepr'.  Valid values are:

        :simplerepr: The default.  This takes the ``str`` of the object and
            then returns the text version of that string.
        :empty: Return an empty text string
        :passthru: Return the object passed in
        :strict: Raise a :exc:`TypeError`

    :returns: Typically this returns a text string.  If a nonstring object is
        passed in this may be a different type depending on the strategy
        specified by nonstring.  This will never return a byte string.
        From Ansible-2.3 onwards, the default is `surrogate_then_replace`.

    .. version_changed:: 2.3

        Added the surrogate_then_replace error handler and made it the default error handler.
    """
    if isinstance(obj, text_type):
        return obj

    if errors in _COMPOSED_ERROR_HANDLERS:
        if HAS_SURROGATEESCAPE:
            errors = 'surrogateescape'
        elif errors == 'surrogate_or_strict':
            errors = 'strict'
        else:
            errors = 'replace'

    if isinstance(obj, binary_type):
        # Note: We don't need special handling for surrogate_then_replace
        # because all bytes will either be made into surrogates or are valid
        # to decode.
        return obj.decode(encoding, errors)

    # Note: We do these last even though we have to call to_text again on the
    # value because we're optimizing the common case
    if nonstring == 'simplerepr':
        try:
            value = str(obj)
        except UnicodeError:
            try:
                value = repr(obj)
            except UnicodeError:
                # Giving up
                return u''
    elif nonstring == 'passthru':
        return obj
    elif nonstring == 'empty':
        return u''
    elif nonstring == 'strict':
        raise TypeError('obj must be a string type')
    else:
        raise TypeError('Invalid value %s for to_text\'s nonstring parameter' % nonstring)

    return to_text(value, encoding, errors)


#: :py:func:`to_native`
#:      Transform a variable into the native str type for the python version
#:
#:      On Python2, this is an alias for
#:      :func:`~ansible.module_utils.to_bytes`.  On Python3 it is an alias for
#:      :func:`~ansible.module_utils.to_text`.  It makes it easier to
#:      transform a variable into the native str type for the python version
#:      the code is running on.  Use this when constructing the message to
#:      send to exceptions or when dealing with an API that needs to take
#:      a native string.  Example::
#:
#:          try:
#:              1//0
#:          except ZeroDivisionError as e:
#:              raise MyException('Encountered and error: %s' % to_native(e))
</source>
</class>

<class classid="52" nclones="2" nlines="12" similarity="91">
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/common/text/converters.py" startline="286" endline="304" pcid="2359">
def container_to_bytes(d, encoding='utf-8', errors='surrogate_or_strict'):
    ''' Recursively convert dict keys and values to byte str

        Specialized for json return because this only handles, lists, tuples,
        and dict container types (the containers that the json module returns)
    '''

    if isinstance(d, text_type):
        return to_bytes(d, encoding=encoding, errors=errors)
    elif isinstance(d, dict):
        return dict(container_to_bytes(o, encoding, errors) for o in iteritems(d))
    elif isinstance(d, list):
        return [container_to_bytes(o, encoding, errors) for o in d]
    elif isinstance(d, tuple):
        return tuple(container_to_bytes(o, encoding, errors) for o in d)
    else:
        return d


</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/common/text/converters.py" startline="305" endline="322" pcid="2360">
def container_to_text(d, encoding='utf-8', errors='surrogate_or_strict'):
    """Recursively convert dict keys and values to text str

    Specialized for json return because this only handles, lists, tuples,
    and dict container types (the containers that the json module returns)
    """

    if isinstance(d, binary_type):
        # Warning, can traceback
        return to_text(d, encoding=encoding, errors=errors)
    elif isinstance(d, dict):
        return dict(container_to_text(o, encoding, errors) for o in iteritems(d))
    elif isinstance(d, list):
        return [container_to_text(o, encoding, errors) for o in d]
    elif isinstance(d, tuple):
        return tuple(container_to_text(o, encoding, errors) for o in d)
    else:
        return d
</source>
</class>

<class classid="53" nclones="2" nlines="11" similarity="81">
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/common/dict_transformations.py" startline="30" endline="42" pcid="2362">
    def value_is_list(camel_list):

        checked_list = []
        for item in camel_list:
            if isinstance(item, dict):
                checked_list.append(camel_dict_to_snake_dict(item, reversible))
            elif isinstance(item, list):
                checked_list.append(value_is_list(item))
            else:
                checked_list.append(item)

        return checked_list

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/ec2.py" startline="664" endline="679" pcid="7151">
    def value_is_list(my_list):

        checked_list = []
        for item in my_list:
            if isinstance(item, dict):
                checked_list.append(sort_json_policy_dict(item))
            elif isinstance(item, list):
                checked_list.append(value_is_list(item))
            else:
                checked_list.append(item)

        # Sort list. If it's a list of dictionaries, sort by tuple of key-value
        # pairs, since Python 3 doesn't allow comparisons such as `<` between dictionaries.
        checked_list.sort(key=lambda x: sorted(x.items()) if isinstance(x, dict) else x)
        return checked_list

</source>
</class>

<class classid="54" nclones="2" nlines="34" similarity="91">
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/basic.py" startline="804" endline="844" pcid="2401">
    def set_owner_if_different(self, path, owner, changed, diff=None, expand=True):

        if owner is None:
            return changed

        b_path = to_bytes(path, errors='surrogate_or_strict')
        if expand:
            b_path = os.path.expanduser(os.path.expandvars(b_path))

        if self.check_file_absent_if_check_mode(b_path):
            return True

        orig_uid, orig_gid = self.user_and_group(b_path, expand)
        try:
            uid = int(owner)
        except ValueError:
            try:
                uid = pwd.getpwnam(owner).pw_uid
            except KeyError:
                path = to_text(b_path)
                self.fail_json(path=path, msg='chown failed: failed to look up user %s' % owner)

        if orig_uid != uid:
            if diff is not None:
                if 'before' not in diff:
                    diff['before'] = {}
                diff['before']['owner'] = orig_uid
                if 'after' not in diff:
                    diff['after'] = {}
                diff['after']['owner'] = uid

            if self.check_mode:
                return True
            try:
                os.lchown(b_path, uid, -1)
            except (IOError, OSError) as e:
                path = to_text(b_path)
                self.fail_json(path=path, msg='chown failed: %s' % (to_text(e)))
            changed = True
        return changed

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/basic.py" startline="845" endline="885" pcid="2402">
    def set_group_if_different(self, path, group, changed, diff=None, expand=True):

        if group is None:
            return changed

        b_path = to_bytes(path, errors='surrogate_or_strict')
        if expand:
            b_path = os.path.expanduser(os.path.expandvars(b_path))

        if self.check_file_absent_if_check_mode(b_path):
            return True

        orig_uid, orig_gid = self.user_and_group(b_path, expand)
        try:
            gid = int(group)
        except ValueError:
            try:
                gid = grp.getgrnam(group).gr_gid
            except KeyError:
                path = to_text(b_path)
                self.fail_json(path=path, msg='chgrp failed: failed to look up group %s' % group)

        if orig_gid != gid:
            if diff is not None:
                if 'before' not in diff:
                    diff['before'] = {}
                diff['before']['group'] = orig_gid
                if 'after' not in diff:
                    diff['after'] = {}
                diff['after']['group'] = gid

            if self.check_mode:
                return True
            try:
                os.lchown(b_path, -1, gid)
            except OSError:
                path = to_text(b_path)
                self.fail_json(path=path, msg='chgrp failed')
            changed = True
        return changed

</source>
</class>

<class classid="55" nclones="3" nlines="27" similarity="73">
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/facts/virtual/openbsd.py" startline="36" endline="71" pcid="2521">
    def get_virtual_facts(self):
        virtual_facts = {}
        host_tech = set()
        guest_tech = set()

        # Set empty values as default
        virtual_facts['virtualization_type'] = ''
        virtual_facts['virtualization_role'] = ''

        virtual_product_facts = self.detect_virt_product('hw.product')
        guest_tech.update(virtual_product_facts['virtualization_tech_guest'])
        host_tech.update(virtual_product_facts['virtualization_tech_host'])
        virtual_facts.update(virtual_product_facts)

        virtual_vendor_facts = self.detect_virt_vendor('hw.vendor')
        guest_tech.update(virtual_vendor_facts['virtualization_tech_guest'])
        host_tech.update(virtual_vendor_facts['virtualization_tech_host'])

        if virtual_facts['virtualization_type'] == '':
            virtual_facts.update(virtual_vendor_facts)

        # Check the dmesg if vmm(4) attached, indicating the host is
        # capable of virtualization.
        dmesg_boot = get_file_content(OpenBSDVirtual.DMESG_BOOT)
        for line in dmesg_boot.splitlines():
            match = re.match('^vmm0 at mainbus0: (SVM/RVI|VMX/EPT)$', line)
            if match:
                host_tech.add('vmm')
                virtual_facts['virtualization_type'] = 'vmm'
                virtual_facts['virtualization_role'] = 'host'

        virtual_facts['virtualization_tech_guest'] = guest_tech
        virtual_facts['virtualization_tech_host'] = host_tech
        return virtual_facts


</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/facts/virtual/netbsd.py" startline="28" endline="70" pcid="2522">
    def get_virtual_facts(self):
        virtual_facts = {}
        host_tech = set()
        guest_tech = set()

        # Set empty values as default
        virtual_facts['virtualization_type'] = ''
        virtual_facts['virtualization_role'] = ''

        virtual_product_facts = self.detect_virt_product('machdep.dmi.system-product')
        guest_tech.update(virtual_product_facts['virtualization_tech_guest'])
        host_tech.update(virtual_product_facts['virtualization_tech_host'])
        virtual_facts.update(virtual_product_facts)

        virtual_vendor_facts = self.detect_virt_vendor('machdep.dmi.system-vendor')
        guest_tech.update(virtual_vendor_facts['virtualization_tech_guest'])
        host_tech.update(virtual_vendor_facts['virtualization_tech_host'])

        if virtual_facts['virtualization_type'] == '':
            virtual_facts.update(virtual_vendor_facts)

        # The above logic is tried first for backwards compatibility. If
        # something above matches, use it. Otherwise if the result is still
        # empty, try machdep.hypervisor.
        virtual_vendor_facts = self.detect_virt_vendor('machdep.hypervisor')
        guest_tech.update(virtual_vendor_facts['virtualization_tech_guest'])
        host_tech.update(virtual_vendor_facts['virtualization_tech_host'])

        if virtual_facts['virtualization_type'] == '':
            virtual_facts.update(virtual_vendor_facts)

        if os.path.exists('/dev/xencons'):
            guest_tech.add('xen')

            if virtual_facts['virtualization_type'] == '':
                virtual_facts['virtualization_type'] = 'xen'
                virtual_facts['virtualization_role'] = 'guest'

        virtual_facts['virtualization_tech_guest'] = guest_tech
        virtual_facts['virtualization_tech_host'] = host_tech
        return virtual_facts


</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/facts/virtual/freebsd.py" startline="33" endline="76" pcid="2524">
    def get_virtual_facts(self):
        virtual_facts = {}
        host_tech = set()
        guest_tech = set()

        # Set empty values as default
        virtual_facts['virtualization_type'] = ''
        virtual_facts['virtualization_role'] = ''

        if os.path.exists('/dev/xen/xenstore'):
            guest_tech.add('xen')
            virtual_facts['virtualization_type'] = 'xen'
            virtual_facts['virtualization_role'] = 'guest'

        kern_vm_guest = self.detect_virt_product('kern.vm_guest')
        guest_tech.update(kern_vm_guest['virtualization_tech_guest'])
        host_tech.update(kern_vm_guest['virtualization_tech_host'])

        hw_hv_vendor = self.detect_virt_product('hw.hv_vendor')
        guest_tech.update(hw_hv_vendor['virtualization_tech_guest'])
        host_tech.update(hw_hv_vendor['virtualization_tech_host'])

        sec_jail_jailed = self.detect_virt_product('security.jail.jailed')
        guest_tech.update(sec_jail_jailed['virtualization_tech_guest'])
        host_tech.update(sec_jail_jailed['virtualization_tech_host'])

        if virtual_facts['virtualization_type'] == '':
            sysctl = kern_vm_guest or hw_hv_vendor or sec_jail_jailed
            # We call update here, then re-set virtualization_tech_host/guest
            # later.
            virtual_facts.update(sysctl)

        virtual_vendor_facts = self.detect_virt_vendor('hw.model')
        guest_tech.update(virtual_vendor_facts['virtualization_tech_guest'])
        host_tech.update(virtual_vendor_facts['virtualization_tech_host'])

        if virtual_facts['virtualization_type'] == '':
            virtual_facts.update(virtual_vendor_facts)

        virtual_facts['virtualization_tech_guest'] = guest_tech
        virtual_facts['virtualization_tech_host'] = host_tech
        return virtual_facts


</source>
</class>

<class classid="56" nclones="2" nlines="12" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/facts/other/facter.py" startline="64" endline="85" pcid="2550">
    def collect(self, module=None, collected_facts=None):
        # Note that this mirrors previous facter behavior, where there isnt
        # a 'ansible_facter' key in the main fact dict, but instead, 'facter_whatever'
        # items are added to the main dict.
        facter_dict = {}

        if not module:
            return facter_dict

        facter_output = self.get_facter_output(module)

        # TODO: if we fail, should we add a empty facter key or nothing?
        if facter_output is None:
            return facter_dict

        try:
            facter_dict = json.loads(facter_output)
        except Exception:
            # FIXME: maybe raise a FactCollectorError with some info attrs?
            pass

        return facter_dict
</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/facts/other/ohai.py" startline="56" endline="72" pcid="2555">
    def collect(self, module=None, collected_facts=None):
        ohai_facts = {}
        if not module:
            return ohai_facts

        ohai_output = self.get_ohai_output(module)

        if ohai_output is None:
            return ohai_facts

        try:
            ohai_facts = json.loads(ohai_output)
        except Exception:
            # FIXME: useful error, logging, something...
            pass

        return ohai_facts
</source>
</class>

<class classid="57" nclones="2" nlines="39" similarity="72">
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/facts/network/generic_bsd.py" startline="111" endline="155" pcid="2572">
    def get_interfaces_info(self, ifconfig_path, ifconfig_options='-a'):
        interfaces = {}
        current_if = {}
        ips = dict(
            all_ipv4_addresses=[],
            all_ipv6_addresses=[],
        )
        # FreeBSD, DragonflyBSD, NetBSD, OpenBSD and macOS all implicitly add '-a'
        # when running the command 'ifconfig'.
        # Solaris must explicitly run the command 'ifconfig -a'.
        rc, out, err = self.module.run_command([ifconfig_path, ifconfig_options])

        for line in out.splitlines():

            if line:
                words = line.split()

                if words[0] == 'pass':
                    continue
                elif re.match(r'^\S', line) and len(words) > 3:
                    current_if = self.parse_interface_line(words)
                    interfaces[current_if['device']] = current_if
                elif words[0].startswith('options='):
                    self.parse_options_line(words, current_if, ips)
                elif words[0] == 'nd6':
                    self.parse_nd6_line(words, current_if, ips)
                elif words[0] == 'ether':
                    self.parse_ether_line(words, current_if, ips)
                elif words[0] == 'media:':
                    self.parse_media_line(words, current_if, ips)
                elif words[0] == 'status:':
                    self.parse_status_line(words, current_if, ips)
                elif words[0] == 'lladdr':
                    self.parse_lladdr_line(words, current_if, ips)
                elif words[0] == 'inet':
                    self.parse_inet_line(words, current_if, ips)
                elif words[0] == 'inet6':
                    self.parse_inet6_line(words, current_if, ips)
                elif words[0] == 'tunnel':
                    self.parse_tunnel_line(words, current_if, ips)
                else:
                    self.parse_unknown_line(words, current_if, ips)

        return interfaces, ips

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/facts/network/sunos.py" startline="39" endline="87" pcid="2599">
    def get_interfaces_info(self, ifconfig_path):
        interfaces = {}
        current_if = {}
        ips = dict(
            all_ipv4_addresses=[],
            all_ipv6_addresses=[],
        )
        rc, out, err = self.module.run_command([ifconfig_path, '-a'])

        for line in out.splitlines():

            if line:
                words = line.split()

                if re.match(r'^\S', line) and len(words) > 3:
                    current_if = self.parse_interface_line(words, current_if, interfaces)
                    interfaces[current_if['device']] = current_if
                elif words[0].startswith('options='):
                    self.parse_options_line(words, current_if, ips)
                elif words[0] == 'nd6':
                    self.parse_nd6_line(words, current_if, ips)
                elif words[0] == 'ether':
                    self.parse_ether_line(words, current_if, ips)
                elif words[0] == 'media:':
                    self.parse_media_line(words, current_if, ips)
                elif words[0] == 'status:':
                    self.parse_status_line(words, current_if, ips)
                elif words[0] == 'lladdr':
                    self.parse_lladdr_line(words, current_if, ips)
                elif words[0] == 'inet':
                    self.parse_inet_line(words, current_if, ips)
                elif words[0] == 'inet6':
                    self.parse_inet6_line(words, current_if, ips)
                else:
                    self.parse_unknown_line(words, current_if, ips)

        # 'parse_interface_line' and 'parse_inet*_line' leave two dicts in the
        # ipv4/ipv6 lists which is ugly and hard to read.
        # This quick hack merges the dictionaries. Purely cosmetic.
        for iface in interfaces:
            for v in 'ipv4', 'ipv6':
                combined_facts = {}
                for facts in interfaces[iface][v]:
                    combined_facts.update(facts)
                if len(combined_facts.keys()) > 0:
                    interfaces[iface][v] = [combined_facts]

        return interfaces, ips

</source>
</class>

<class classid="58" nclones="4" nlines="18" similarity="73">
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/facts/hardware/openbsd.py" startline="67" endline="87" pcid="2619">
    def get_mount_facts(self):
        mount_facts = {}

        mount_facts['mounts'] = []
        fstab = get_file_content('/etc/fstab')
        if fstab:
            for line in fstab.splitlines():
                if line.startswith('#') or line.strip() == '':
                    continue
                fields = re.sub(r'\s+', ' ', line).split()
                if fields[1] == 'none' or fields[3] == 'xx':
                    continue
                mount_statvfs_info = get_mount_size(fields[1])
                mount_info = {'mount': fields[1],
                              'device': fields[0],
                              'fstype': fields[2],
                              'options': fields[3]}
                mount_info.update(mount_statvfs_info)
                mount_facts['mounts'].append(mount_info)
        return mount_facts

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/facts/hardware/netbsd.py" startline="115" endline="136" pcid="2635">
    def get_mount_facts(self):
        mount_facts = {}

        mount_facts['mounts'] = []
        fstab = get_file_content('/etc/fstab')

        if not fstab:
            return mount_facts

        for line in fstab.splitlines():
            if line.startswith('#') or line.strip() == '':
                continue
            fields = re.sub(r'\s+', ' ', line).split()
            mount_statvfs_info = get_mount_size(fields[1])
            mount_info = {'mount': fields[1],
                          'device': fields[0],
                          'fstype': fields[2],
                          'options': fields[3]}
            mount_info.update(mount_statvfs_info)
            mount_facts['mounts'].append(mount_info)
        return mount_facts

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/facts/hardware/freebsd.py" startline="152" endline="171" pcid="2670">
    def get_mount_facts(self):
        mount_facts = {}

        mount_facts['mounts'] = []
        fstab = get_file_content('/etc/fstab')
        if fstab:
            for line in fstab.splitlines():
                if line.startswith('#') or line.strip() == '':
                    continue
                fields = re.sub(r'\s+', ' ', line).split()
                mount_statvfs_info = get_mount_size(fields[1])
                mount_info = {'mount': fields[1],
                              'device': fields[0],
                              'fstype': fields[2],
                              'options': fields[3]}
                mount_info.update(mount_statvfs_info)
                mount_facts['mounts'].append(mount_info)

        return mount_facts

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/facts/hardware/sunos.py" startline="146" endline="167" pcid="2677">
    def get_mount_facts(self):
        mount_facts = {}
        mount_facts['mounts'] = []

        # For a detailed format description see mnttab(4)
        #   special mount_point fstype options time
        fstab = get_file_content('/etc/mnttab')

        if fstab:
            for line in fstab.splitlines():
                fields = line.split('\t')
                mount_statvfs_info = get_mount_size(fields[1])
                mount_info = {'mount': fields[1],
                              'device': fields[0],
                              'fstype': fields[2],
                              'options': fields[3],
                              'time': fields[4]}
                mount_info.update(mount_statvfs_info)
                mount_facts['mounts'].append(mount_info)

        return mount_facts

</source>
</class>

<class classid="59" nclones="2" nlines="13" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/facts/hardware/openbsd.py" startline="159" endline="181" pcid="2624">
    def get_dmi_facts(self):
        dmi_facts = {}
        # We don't use dmidecode(8) here because:
        # - it would add dependency on an external package
        # - dmidecode(8) can only be ran as root
        # So instead we rely on sysctl(8) to provide us the information on a
        # best-effort basis. As a bonus we also get facts on non-amd64/i386
        # platforms this way.
        sysctl_to_dmi = {
            'hw.product': 'product_name',
            'hw.version': 'product_version',
            'hw.uuid': 'product_uuid',
            'hw.serialno': 'product_serial',
            'hw.vendor': 'system_vendor',
        }

        for mib in sysctl_to_dmi:
            if mib in self.sysctl:
                dmi_facts[sysctl_to_dmi[mib]] = self.sysctl[mib]

        return dmi_facts


</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/facts/hardware/netbsd.py" startline="137" endline="159" pcid="2636">
    def get_dmi_facts(self):
        dmi_facts = {}
        # We don't use dmidecode(8) here because:
        # - it would add dependency on an external package
        # - dmidecode(8) can only be ran as root
        # So instead we rely on sysctl(8) to provide us the information on a
        # best-effort basis. As a bonus we also get facts on non-amd64/i386
        # platforms this way.
        sysctl_to_dmi = {
            'machdep.dmi.system-product': 'product_name',
            'machdep.dmi.system-version': 'product_version',
            'machdep.dmi.system-uuid': 'product_uuid',
            'machdep.dmi.system-serial': 'product_serial',
            'machdep.dmi.system-vendor': 'system_vendor',
        }

        for mib in sysctl_to_dmi:
            if mib in self.sysctl:
                dmi_facts[sysctl_to_dmi[mib]] = self.sysctl[mib]

        return dmi_facts


</source>
</class>

<class classid="60" nclones="7" nlines="17" similarity="71">
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/facts/hardware/aix.py" startline="38" endline="56" pcid="2625">
    def populate(self, collected_facts=None):
        hardware_facts = {}

        cpu_facts = self.get_cpu_facts()
        memory_facts = self.get_memory_facts()
        dmi_facts = self.get_dmi_facts()
        vgs_facts = self.get_vgs_facts()
        mount_facts = self.get_mount_facts()
        devices_facts = self.get_device_facts()

        hardware_facts.update(cpu_facts)
        hardware_facts.update(memory_facts)
        hardware_facts.update(dmi_facts)
        hardware_facts.update(vgs_facts)
        hardware_facts.update(mount_facts)
        hardware_facts.update(devices_facts)

        return hardware_facts

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/facts/hardware/freebsd.py" startline="47" endline="70" pcid="2666">
    def populate(self, collected_facts=None):
        hardware_facts = {}

        cpu_facts = self.get_cpu_facts()
        memory_facts = self.get_memory_facts()
        uptime_facts = self.get_uptime_facts()
        dmi_facts = self.get_dmi_facts()
        device_facts = self.get_device_facts()

        mount_facts = {}
        try:
            mount_facts = self.get_mount_facts()
        except TimeoutError:
            pass

        hardware_facts.update(cpu_facts)
        hardware_facts.update(memory_facts)
        hardware_facts.update(uptime_facts)
        hardware_facts.update(dmi_facts)
        hardware_facts.update(device_facts)
        hardware_facts.update(mount_facts)

        return hardware_facts

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/facts/hardware/sunos.py" startline="37" endline="66" pcid="2674">
    def populate(self, collected_facts=None):
        hardware_facts = {}

        # FIXME: could pass to run_command(environ_update), but it also tweaks the env
        #        of the parent process instead of altering an env provided to Popen()
        # Use C locale for hardware collection helpers to avoid locale specific number formatting (#24542)
        locale = get_best_parsable_locale(self.module)
        self.module.run_command_environ_update = {'LANG': locale, 'LC_ALL': locale, 'LC_NUMERIC': locale}

        cpu_facts = self.get_cpu_facts()
        memory_facts = self.get_memory_facts()
        dmi_facts = self.get_dmi_facts()
        device_facts = self.get_device_facts()
        uptime_facts = self.get_uptime_facts()

        mount_facts = {}
        try:
            mount_facts = self.get_mount_facts()
        except timeout.TimeoutError:
            pass

        hardware_facts.update(cpu_facts)
        hardware_facts.update(memory_facts)
        hardware_facts.update(dmi_facts)
        hardware_facts.update(device_facts)
        hardware_facts.update(uptime_facts)
        hardware_facts.update(mount_facts)

        return hardware_facts

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/facts/hardware/darwin.py" startline="42" endline="57" pcid="2660">
    def populate(self, collected_facts=None):
        hardware_facts = {}

        self.sysctl = get_sysctl(self.module, ['hw', 'machdep', 'kern'])
        mac_facts = self.get_mac_facts()
        cpu_facts = self.get_cpu_facts()
        memory_facts = self.get_memory_facts()
        uptime_facts = self.get_uptime_facts()

        hardware_facts.update(mac_facts)
        hardware_facts.update(cpu_facts)
        hardware_facts.update(memory_facts)
        hardware_facts.update(uptime_facts)

        return hardware_facts

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/facts/hardware/linux.py" startline="87" endline="114" pcid="2638">
    def populate(self, collected_facts=None):
        hardware_facts = {}
        locale = get_best_parsable_locale(self.module)
        self.module.run_command_environ_update = {'LANG': locale, 'LC_ALL': locale, 'LC_NUMERIC': locale}

        cpu_facts = self.get_cpu_facts(collected_facts=collected_facts)
        memory_facts = self.get_memory_facts()
        dmi_facts = self.get_dmi_facts()
        device_facts = self.get_device_facts()
        uptime_facts = self.get_uptime_facts()
        lvm_facts = self.get_lvm_facts()

        mount_facts = {}
        try:
            mount_facts = self.get_mount_facts()
        except timeout.TimeoutError:
            self.module.warn("No mount facts were gathered due to timeout.")

        hardware_facts.update(cpu_facts)
        hardware_facts.update(memory_facts)
        hardware_facts.update(dmi_facts)
        hardware_facts.update(device_facts)
        hardware_facts.update(uptime_facts)
        hardware_facts.update(lvm_facts)
        hardware_facts.update(mount_facts)

        return hardware_facts

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/facts/hardware/netbsd.py" startline="46" endline="66" pcid="2632">
    def populate(self, collected_facts=None):
        hardware_facts = {}
        self.sysctl = get_sysctl(self.module, ['machdep'])
        cpu_facts = self.get_cpu_facts()
        memory_facts = self.get_memory_facts()

        mount_facts = {}
        try:
            mount_facts = self.get_mount_facts()
        except TimeoutError:
            pass

        dmi_facts = self.get_dmi_facts()

        hardware_facts.update(cpu_facts)
        hardware_facts.update(memory_facts)
        hardware_facts.update(mount_facts)
        hardware_facts.update(dmi_facts)

        return hardware_facts

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/facts/hardware/hurd.py" startline="33" endline="50" pcid="2673">
    def populate(self, collected_facts=None):
        hardware_facts = {}
        uptime_facts = self.get_uptime_facts()
        memory_facts = self.get_memory_facts()

        mount_facts = {}
        try:
            mount_facts = self.get_mount_facts()
        except TimeoutError:
            pass

        hardware_facts.update(uptime_facts)
        hardware_facts.update(memory_facts)
        hardware_facts.update(mount_facts)

        return hardware_facts


</source>
</class>

<class classid="61" nclones="2" nlines="12" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/facts/hardware/darwin.py" startline="134" endline="156" pcid="2665">
    def get_uptime_facts(self):
        # On Darwin, the default format is annoying to parse.
        # Use -b to get the raw value and decode it.
        sysctl_cmd = self.module.get_bin_path('sysctl')
        cmd = [sysctl_cmd, '-b', 'kern.boottime']

        # We need to get raw bytes, not UTF-8.
        rc, out, err = self.module.run_command(cmd, encoding=None)

        # kern.boottime returns seconds and microseconds as two 64-bits
        # fields, but we are only interested in the first field.
        struct_format = '@L'
        struct_size = struct.calcsize(struct_format)
        if rc != 0 or len(out) < struct_size:
            return {}

        (kern_boottime, ) = struct.unpack(struct_format, out[:struct_size])

        return {
            'uptime_seconds': int(time.time() - kern_boottime),
        }


</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/facts/hardware/freebsd.py" startline="129" endline="150" pcid="2669">
    def get_uptime_facts(self):
        # On FreeBSD, the default format is annoying to parse.
        # Use -b to get the raw value and decode it.
        sysctl_cmd = self.module.get_bin_path('sysctl')
        cmd = [sysctl_cmd, '-b', 'kern.boottime']

        # We need to get raw bytes, not UTF-8.
        rc, out, err = self.module.run_command(cmd, encoding=None)

        # kern.boottime returns seconds and microseconds as two 64-bits
        # fields, but we are only interested in the first field.
        struct_format = '@L'
        struct_size = struct.calcsize(struct_format)
        if rc != 0 or len(out) < struct_size:
            return {}

        (kern_boottime, ) = struct.unpack(struct_format, out[:struct_size])

        return {
            'uptime_seconds': int(time.time() - kern_boottime),
        }

</source>
</class>

<class classid="62" nclones="2" nlines="12" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/facts/system/distribution.py" startline="407" endline="424" pcid="2708">

    def parse_distribution_file_Coreos(self, name, data, path, collected_facts):
        coreos_facts = {}
        # FIXME: pass in ro copy of facts for this kind of thing
        distro = get_distribution()

        if distro.lower() == 'coreos':
            if not data:
                # include fix from #15230, #15228
                # TODO: verify this is ok for above bugs
                return False, coreos_facts
            release = re.search("^GROUP=(.*)", data)
            if release:
                coreos_facts['distribution_release'] = release.group(1).strip('"')
        else:
            return False, coreos_facts  # TODO: remove if tested without this

        return True, coreos_facts
</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/module_utils/facts/system/distribution.py" startline="425" endline="439" pcid="2709">

    def parse_distribution_file_Flatcar(self, name, data, path, collected_facts):
        flatcar_facts = {}
        distro = get_distribution()

        if distro.lower() == 'flatcar':
            if not data:
                return False, flatcar_facts
            release = re.search("^GROUP=(.*)", data)
            if release:
                flatcar_facts['distribution_release'] = release.group(1).strip('"')
        else:
            return False, flatcar_facts

        return True, flatcar_facts
</source>
</class>

<class classid="63" nclones="2" nlines="17" similarity="88">
<source file="systems/ansible-2.12.4rc1/lib/ansible/vars/manager.py" startline="231" endline="249" pcid="2973">
            def _get_plugin_vars(plugin, path, entities):
                data = {}
                try:
                    data = plugin.get_vars(self._loader, path, entities)
                except AttributeError:
                    try:
                        for entity in entities:
                            if isinstance(entity, Host):
                                data.update(plugin.get_host_vars(entity.name))
                            else:
                                data.update(plugin.get_group_vars(entity.name))
                    except AttributeError:
                        if hasattr(plugin, 'run'):
                            raise AnsibleError("Cannot use v1 type vars plugin %s from %s" % (plugin._load_name, plugin._original_path))
                        else:
                            raise AnsibleError("Invalid vars plugin %s from %s" % (plugin._load_name, plugin._original_path))
                return data

            # internal functions that actually do the work
</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/vars/plugins.py" startline="22" endline="41" pcid="3010">
def get_plugin_vars(loader, plugin, path, entities):

    data = {}
    try:
        data = plugin.get_vars(loader, path, entities)
    except AttributeError:
        try:
            for entity in entities:
                if isinstance(entity, Host):
                    data.update(plugin.get_host_vars(entity.name))
                else:
                    data.update(plugin.get_group_vars(entity.name))
        except AttributeError:
            if hasattr(plugin, 'run'):
                raise AnsibleError("Cannot use v1 type vars plugin %s from %s" % (plugin._load_name, plugin._original_path))
            else:
                raise AnsibleError("Invalid vars plugin %s from %s" % (plugin._load_name, plugin._original_path))
    return data


</source>
</class>

<class classid="64" nclones="2" nlines="22" similarity="95">
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/group.py" startline="206" endline="237" pcid="3080">
    def group_exists(self):
        # The grp module does not distinguish between local and directory accounts.
        # It's output cannot be used to determine whether or not a group exists locally.
        # It returns True if the group exists locally or in the directory, so instead
        # look in the local GROUP file for an existing account.
        if self.local:
            if not os.path.exists(self.GROUPFILE):
                self.module.fail_json(msg="'local: true' specified but unable to find local group file {0} to parse.".format(self.GROUPFILE))

            exists = False
            name_test = '{0}:'.format(self.name)
            with open(self.GROUPFILE, 'rb') as f:
                reversed_lines = f.readlines()[::-1]
                for line in reversed_lines:
                    if line.startswith(to_bytes(name_test)):
                        exists = True
                        break

            if not exists:
                self.module.warn(
                    "'local: true' specified and group was not found in {file}. "
                    "The local group may already exist if the local group database exists somewhere other than {file}.".format(file=self.GROUPFILE))

            return exists

        else:
            try:
                if grp.getgrnam(self.name):
                    return True
            except KeyError:
                return False

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/user.py" startline="1004" endline="1036" pcid="3433">
    def user_exists(self):
        # The pwd module does not distinguish between local and directory accounts.
        # It's output cannot be used to determine whether or not an account exists locally.
        # It returns True if the account exists locally or in the directory, so instead
        # look in the local PASSWORD file for an existing account.
        if self.local:
            if not os.path.exists(self.PASSWORDFILE):
                self.module.fail_json(msg="'local: true' specified but unable to find local account file {0} to parse.".format(self.PASSWORDFILE))

            exists = False
            name_test = '{0}:'.format(self.name)
            with open(self.PASSWORDFILE, 'rb') as f:
                reversed_lines = f.readlines()[::-1]
                for line in reversed_lines:
                    if line.startswith(to_bytes(name_test)):
                        exists = True
                        break

            if not exists:
                self.module.warn(
                    "'local: true' specified and user '{name}' was not found in {file}. "
                    "The local user account may already exist if the local account database exists "
                    "somewhere other than {file}.".format(file=self.PASSWORDFILE, name=self.name))

            return exists

        else:
            try:
                if pwd.getpwnam(self.name):
                    return True
            except KeyError:
                return False

</source>
</class>

<class classid="65" nclones="3" nlines="14" similarity="71">
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/group.py" startline="349" endline="365" pcid="3088">
    def group_mod(self, **kwargs):
        cmd = [self.module.get_bin_path('pw', True), 'groupmod', self.name]
        info = self.group_info()
        cmd_len = len(cmd)
        if self.gid is not None and int(self.gid) != info[2]:
            cmd.append('-g')
            cmd.append(str(self.gid))
            if self.non_unique:
                cmd.append('-o')
        # modify the group if cmd will do anything
        if cmd_len != len(cmd):
            if self.module.check_mode:
                return (0, '', '')
            return self.execute_command(cmd)
        return (None, '', '')


</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/group.py" startline="520" endline="538" pcid="3098">
    def group_mod(self, **kwargs):
        cmd = [self.module.get_bin_path('groupmod', True)]
        info = self.group_info()
        if self.gid is not None and int(self.gid) != info[2]:
            cmd.append('-g')
            cmd.append(str(self.gid))
            if self.non_unique:
                cmd.append('-o')
        if len(cmd) == 1:
            return (None, '', '')
        if self.module.check_mode:
            return (0, '', '')
        cmd.append(self.name)
        return self.execute_command(cmd)


# ===========================================


</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/group.py" startline="474" endline="491" pcid="3095">
    def group_mod(self, **kwargs):
        cmd = [self.module.get_bin_path('groupmod', True)]
        info = self.group_info()
        if self.gid is not None and int(self.gid) != info[2]:
            cmd.append('-g')
            cmd.append(str(self.gid))
            if self.non_unique:
                cmd.append('-o')
        if len(cmd) == 1:
            return (None, '', '')
        if self.module.check_mode:
            return (0, '', '')
        cmd.append(self.name)
        return self.execute_command(cmd)


# ===========================================

</source>
</class>

<class classid="66" nclones="2" nlines="12" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/hostname.py" startline="396" endline="409" pcid="3142">
    def get_permanent_hostname(self):
        if not os.path.isfile(self.FILE):
            return ''

        try:
            for line in get_file_lines(self.FILE):
                line = line.strip()
                if line.startswith('hostname='):
                    return line[10:].strip('"')
        except Exception as e:
            self.module.fail_json(
                msg="failed to read hostname: %s" % to_native(e),
                exception=traceback.format_exc())

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/hostname.py" startline="497" endline="510" pcid="3151">
    def get_permanent_hostname(self):
        if not os.path.isfile(self.FILE):
            return ''

        try:
            for line in get_file_lines(self.FILE):
                line = line.strip()
                if line.startswith('hostname='):
                    return line[10:].strip('"')
        except Exception as e:
            self.module.fail_json(
                msg="failed to read hostname: %s" % to_native(e),
                exception=traceback.format_exc())

</source>
</class>

<class classid="67" nclones="2" nlines="15" similarity="81">
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/hostname.py" startline="410" endline="426" pcid="3143">
    def set_permanent_hostname(self, name):
        try:
            lines = [x.strip() for x in get_file_lines(self.FILE)]

            for i, line in enumerate(lines):
                if line.startswith('hostname='):
                    lines[i] = 'hostname="%s"' % name
                    break

            with open(self.FILE, 'w') as f:
                f.write('\n'.join(lines) + '\n')
        except Exception as e:
            self.module.fail_json(
                msg="failed to update hostname: %s" % to_native(e),
                exception=traceback.format_exc())


</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/hostname.py" startline="511" endline="530" pcid="3152">
    def set_permanent_hostname(self, name):
        try:
            if os.path.isfile(self.FILE):
                lines = [x.strip() for x in get_file_lines(self.FILE)]

                for i, line in enumerate(lines):
                    if line.startswith('hostname='):
                        lines[i] = 'hostname="%s"' % name
                        break
            else:
                lines = ['hostname="%s"' % name]

            with open(self.FILE, 'w') as f:
                f.write('\n'.join(lines) + '\n')
        except Exception as e:
            self.module.fail_json(
                msg="failed to update hostname: %s" % to_native(e),
                exception=traceback.format_exc())


</source>
</class>

<class classid="68" nclones="2" nlines="12" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/file.py" startline="874" endline="887" pcid="3224">
def check_owner_exists(module, owner):
    try:
        uid = int(owner)
        try:
            getpwuid(uid).pw_name
        except KeyError:
            module.warn('failed to look up user with uid %s. Create user up to this point in real play' % uid)
    except ValueError:
        try:
            getpwnam(owner).pw_uid
        except KeyError:
            module.warn('failed to look up user %s. Create user up to this point in real play' % owner)


</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/file.py" startline="888" endline="901" pcid="3225">
def check_group_exists(module, group):
    try:
        gid = int(group)
        try:
            getgrgid(gid).gr_name
        except KeyError:
            module.warn('failed to look up group with gid %s. Create group up to this point in real play' % gid)
    except ValueError:
        try:
            getgrnam(group).gr_gid
        except KeyError:
            module.warn('failed to look up group %s. Create group up to this point in real play' % group)


</source>
</class>

<class classid="69" nclones="2" nlines="14" similarity="71">
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/unarchive.py" startline="302" endline="316" pcid="3264">
    def __init__(self, src, b_dest, file_args, module):
        self.src = src
        self.b_dest = b_dest
        self.file_args = file_args
        self.opts = module.params['extra_opts']
        self.module = module
        self.io_buffer_size = module.params["io_buffer_size"]
        self.excludes = module.params['exclude']
        self.includes = []
        self.include_files = self.module.params['include']
        self.cmd_path = None
        self.zipinfo_cmd_path = None
        self._files_in_archive = []
        self._infodict = dict()

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/unarchive.py" startline="747" endline="761" pcid="3272">
    def __init__(self, src, b_dest, file_args, module):
        self.src = src
        self.b_dest = b_dest
        self.file_args = file_args
        self.opts = module.params['extra_opts']
        self.module = module
        if self.module.check_mode:
            self.module.exit_json(skipped=True, msg="remote module (%s) does not support check mode when using gtar" % self.module._name)
        self.excludes = [path.rstrip('/') for path in self.module.params['exclude']]
        self.include_files = self.module.params['include']
        self.cmd_path = None
        self.tar_type = None
        self.zipflag = '-z'
        self._files_in_archive = []

</source>
</class>

<class classid="70" nclones="3" nlines="17" similarity="70">
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/lineinfile.py" startline="262" endline="283" pcid="3326">
def write_changes(module, b_lines, dest):

    tmpfd, tmpfile = tempfile.mkstemp(dir=module.tmpdir)
    with os.fdopen(tmpfd, 'wb') as f:
        f.writelines(b_lines)

    validate = module.params.get('validate', None)
    valid = not validate
    if validate:
        if "%s" not in validate:
            module.fail_json(msg="validate must contain %%s: %s" % (validate))
        (rc, out, err) = module.run_command(to_bytes(validate % tmpfile, errors='surrogate_or_strict'))
        valid = rc == 0
        if rc != 0:
            module.fail_json(msg='failed to validate: '
                                 'rc:%s error:%s' % (rc, err))
    if valid:
        module.atomic_move(tmpfile,
                           to_native(os.path.realpath(to_bytes(dest, errors='surrogate_or_strict')), errors='surrogate_or_strict'),
                           unsafe_writes=module.params['unsafe_writes'])


</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/replace.py" startline="192" endline="212" pcid="3607">
def write_changes(module, contents, path):

    tmpfd, tmpfile = tempfile.mkstemp(dir=module.tmpdir)
    f = os.fdopen(tmpfd, 'wb')
    f.write(contents)
    f.close()

    validate = module.params.get('validate', None)
    valid = not validate
    if validate:
        if "%s" not in validate:
            module.fail_json(msg="validate must contain %%s: %s" % (validate))
        (rc, out, err) = module.run_command(validate % tmpfile)
        valid = rc == 0
        if rc != 0:
            module.fail_json(msg='failed to validate: '
                                 'rc:%s error:%s' % (rc, err))
    if valid:
        module.atomic_move(tmpfile, path, unsafe_writes=module.params['unsafe_writes'])


</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/blockinfile.py" startline="172" endline="192" pcid="3339">
def write_changes(module, contents, path):

    tmpfd, tmpfile = tempfile.mkstemp(dir=module.tmpdir)
    f = os.fdopen(tmpfd, 'wb')
    f.write(contents)
    f.close()

    validate = module.params.get('validate', None)
    valid = not validate
    if validate:
        if "%s" not in validate:
            module.fail_json(msg="validate must contain %%s: %s" % (validate))
        (rc, out, err) = module.run_command(validate % tmpfile)
        valid = rc == 0
        if rc != 0:
            module.fail_json(msg='failed to validate: '
                                 'rc:%s error:%s' % (rc, err))
    if valid:
        module.atomic_move(tmpfile, path, unsafe_writes=module.params['unsafe_writes'])


</source>
</class>

<class classid="71" nclones="2" nlines="11" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/user.py" startline="1050" endline="1061" pcid="3436">
    def set_password_expire_max(self):
        command_name = 'chage'
        cmd = [self.module.get_bin_path(command_name, True)]
        cmd.append('-M')
        cmd.append(self.password_expire_max)
        cmd.append(self.name)
        if self.password_expire_max == spwd.getspnam(self.name).sp_max:
            self.module.exit_json(changed=False)
        else:
            self.execute_command(cmd)
            self.module.exit_json(changed=True)

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/user.py" startline="1062" endline="1073" pcid="3437">
    def set_password_expire_min(self):
        command_name = 'chage'
        cmd = [self.module.get_bin_path(command_name, True)]
        cmd.append('-m')
        cmd.append(self.password_expire_min)
        cmd.append(self.name)
        if self.password_expire_min == spwd.getspnam(self.name).sp_min:
            self.module.exit_json(changed=False)
        else:
            self.execute_command(cmd)
            self.module.exit_json(changed=True)

</source>
</class>

<class classid="72" nclones="4" nlines="40" similarity="70">
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/user.py" startline="1599" endline="1653" pcid="3453">
    def create_user(self):
        cmd = [self.module.get_bin_path('useradd', True)]

        if self.uid is not None:
            cmd.append('-u')
            cmd.append(self.uid)

            if self.non_unique:
                cmd.append('-o')

        if self.group is not None:
            if not self.group_exists(self.group):
                self.module.fail_json(msg="Group %s does not exist" % self.group)
            cmd.append('-g')
            cmd.append(self.group)

        if self.groups is not None:
            groups = self.get_groups_set()
            cmd.append('-G')
            cmd.append(','.join(groups))

        if self.comment is not None:
            cmd.append('-c')
            cmd.append(self.comment)

        if self.home is not None:
            cmd.append('-d')
            cmd.append(self.home)

        if self.shell is not None:
            cmd.append('-s')
            cmd.append(self.shell)

        if self.login_class is not None:
            cmd.append('-L')
            cmd.append(self.login_class)

        if self.password is not None and self.password != '*':
            cmd.append('-p')
            cmd.append(self.password)

        if self.create_home:
            cmd.append('-m')

            if self.skeleton is not None:
                cmd.append('-k')
                cmd.append(self.skeleton)

            if self.umask is not None:
                cmd.append('-K')
                cmd.append('UMASK=' + self.umask)

        cmd.append(self.name)
        return self.execute_command(cmd)

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/user.py" startline="2776" endline="2823" pcid="3483">

    def create_user(self):
        cmd = ['/usr/sam/lbin/useradd.sam']

        if self.uid is not None:
            cmd.append('-u')
            cmd.append(self.uid)

            if self.non_unique:
                cmd.append('-o')

        if self.group is not None:
            if not self.group_exists(self.group):
                self.module.fail_json(msg="Group %s does not exist" % self.group)
            cmd.append('-g')
            cmd.append(self.group)

        if self.groups is not None and len(self.groups):
            groups = self.get_groups_set()
            cmd.append('-G')
            cmd.append(','.join(groups))

        if self.comment is not None:
            cmd.append('-c')
            cmd.append(self.comment)

        if self.home is not None:
            cmd.append('-d')
            cmd.append(self.home)

        if self.shell is not None:
            cmd.append('-s')
            cmd.append(self.shell)

        if self.password is not None:
            cmd.append('-p')
            cmd.append(self.password)

        if self.create_home:
            cmd.append('-m')
        else:
            cmd.append('-M')

        if self.system:
            cmd.append('-r')

        cmd.append(self.name)
        return self.execute_command(cmd)
</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/user.py" startline="1773" endline="1829" pcid="3456">

    def create_user(self):
        cmd = [self.module.get_bin_path('useradd', True)]

        if self.uid is not None:
            cmd.append('-u')
            cmd.append(self.uid)

            if self.non_unique:
                cmd.append('-o')

        if self.group is not None:
            if not self.group_exists(self.group):
                self.module.fail_json(msg="Group %s does not exist" % self.group)
            cmd.append('-g')
            cmd.append(self.group)

        if self.groups is not None:
            groups = self.get_groups_set()
            if len(groups) > 16:
                self.module.fail_json(msg="Too many groups (%d) NetBSD allows for 16 max." % len(groups))
            cmd.append('-G')
            cmd.append(','.join(groups))

        if self.comment is not None:
            cmd.append('-c')
            cmd.append(self.comment)

        if self.home is not None:
            cmd.append('-d')
            cmd.append(self.home)

        if self.shell is not None:
            cmd.append('-s')
            cmd.append(self.shell)

        if self.login_class is not None:
            cmd.append('-L')
            cmd.append(self.login_class)

        if self.password is not None:
            cmd.append('-p')
            cmd.append(self.password)

        if self.create_home:
            cmd.append('-m')

            if self.skeleton is not None:
                cmd.append('-k')
                cmd.append(self.skeleton)

            if self.umask is not None:
                cmd.append('-K')
                cmd.append('UMASK=' + self.umask)

        cmd.append(self.name)
        return self.execute_command(cmd)
</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/user.py" startline="2584" endline="2637" pcid="3480">

    def create_user_useradd(self, command_name='useradd'):
        cmd = [self.module.get_bin_path(command_name, True)]

        if self.uid is not None:
            cmd.append('-u')
            cmd.append(self.uid)

        if self.group is not None:
            if not self.group_exists(self.group):
                self.module.fail_json(msg="Group %s does not exist" % self.group)
            cmd.append('-g')
            cmd.append(self.group)

        if self.groups is not None and len(self.groups):
            groups = self.get_groups_set()
            cmd.append('-G')
            cmd.append(','.join(groups))

        if self.comment is not None:
            cmd.append('-c')
            cmd.append(self.comment)

        if self.home is not None:
            cmd.append('-d')
            cmd.append(self.home)

        if self.shell is not None:
            cmd.append('-s')
            cmd.append(self.shell)

        if self.create_home:
            cmd.append('-m')

            if self.skeleton is not None:
                cmd.append('-k')
                cmd.append(self.skeleton)

            if self.umask is not None:
                cmd.append('-K')
                cmd.append('UMASK=' + self.umask)

        cmd.append(self.name)
        (rc, out, err) = self.execute_command(cmd)

        # set password with chpasswd
        if self.password is not None:
            cmd = []
            cmd.append(self.module.get_bin_path('chpasswd', True))
            cmd.append('-e')
            cmd.append('-c')
            self.execute_command(cmd, data="%s:%s" % (self.name, self.password))

        return (rc, out, err)
</source>
</class>

<class classid="73" nclones="4" nlines="65" similarity="76">
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/user.py" startline="1661" endline="1754" pcid="3455">
    def modify_user(self):
        cmd = [self.module.get_bin_path('usermod', True)]
        info = self.user_info()

        if self.uid is not None and info[2] != int(self.uid):
            cmd.append('-u')
            cmd.append(self.uid)

            if self.non_unique:
                cmd.append('-o')

        if self.group is not None:
            if not self.group_exists(self.group):
                self.module.fail_json(msg="Group %s does not exist" % self.group)
            ginfo = self.group_info(self.group)
            if info[3] != ginfo[2]:
                cmd.append('-g')
                cmd.append(self.group)

        if self.groups is not None:
            current_groups = self.user_group_membership()
            groups_need_mod = False
            groups_option = '-S'
            groups = []

            if self.groups == '':
                if current_groups and not self.append:
                    groups_need_mod = True
            else:
                groups = self.get_groups_set()
                group_diff = set(current_groups).symmetric_difference(groups)

                if group_diff:
                    if self.append:
                        for g in groups:
                            if g in group_diff:
                                groups_option = '-G'
                                groups_need_mod = True
                                break
                    else:
                        groups_need_mod = True

            if groups_need_mod:
                cmd.append(groups_option)
                cmd.append(','.join(groups))

        if self.comment is not None and info[4] != self.comment:
            cmd.append('-c')
            cmd.append(self.comment)

        if self.home is not None and info[5] != self.home:
            if self.move_home:
                cmd.append('-m')
            cmd.append('-d')
            cmd.append(self.home)

        if self.shell is not None and info[6] != self.shell:
            cmd.append('-s')
            cmd.append(self.shell)

        if self.login_class is not None:
            # find current login class
            user_login_class = None
            userinfo_cmd = [self.module.get_bin_path('userinfo', True), self.name]
            (rc, out, err) = self.execute_command(userinfo_cmd, obey_checkmode=False)

            for line in out.splitlines():
                tokens = line.split()

                if tokens[0] == 'class' and len(tokens) == 2:
                    user_login_class = tokens[1]

            # act only if login_class change
            if self.login_class != user_login_class:
                cmd.append('-L')
                cmd.append(self.login_class)

        if self.password_lock and not info[1].startswith('*'):
            cmd.append('-Z')
        elif self.password_lock is False and info[1].startswith('*'):
            cmd.append('-U')

        if self.update_password == 'always' and self.password is not None \
                and self.password != '*' and info[1] != self.password:
            cmd.append('-p')
            cmd.append(self.password)

        # skip if no changes to be made
        if len(cmd) == 1:
            return (None, '', '')

        cmd.append(self.name)
        return self.execute_command(cmd)

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/user.py" startline="1837" endline="1918" pcid="3458">

    def modify_user(self):
        cmd = [self.module.get_bin_path('usermod', True)]
        info = self.user_info()

        if self.uid is not None and info[2] != int(self.uid):
            cmd.append('-u')
            cmd.append(self.uid)

            if self.non_unique:
                cmd.append('-o')

        if self.group is not None:
            if not self.group_exists(self.group):
                self.module.fail_json(msg="Group %s does not exist" % self.group)
            ginfo = self.group_info(self.group)
            if info[3] != ginfo[2]:
                cmd.append('-g')
                cmd.append(self.group)

        if self.groups is not None:
            current_groups = self.user_group_membership()
            groups_need_mod = False
            groups = []

            if self.groups == '':
                if current_groups and not self.append:
                    groups_need_mod = True
            else:
                groups = self.get_groups_set()
                group_diff = set(current_groups).symmetric_difference(groups)

                if group_diff:
                    if self.append:
                        for g in groups:
                            if g in group_diff:
                                groups = set(current_groups).union(groups)
                                groups_need_mod = True
                                break
                    else:
                        groups_need_mod = True

            if groups_need_mod:
                if len(groups) > 16:
                    self.module.fail_json(msg="Too many groups (%d) NetBSD allows for 16 max." % len(groups))
                cmd.append('-G')
                cmd.append(','.join(groups))

        if self.comment is not None and info[4] != self.comment:
            cmd.append('-c')
            cmd.append(self.comment)

        if self.home is not None and info[5] != self.home:
            if self.move_home:
                cmd.append('-m')
            cmd.append('-d')
            cmd.append(self.home)

        if self.shell is not None and info[6] != self.shell:
            cmd.append('-s')
            cmd.append(self.shell)

        if self.login_class is not None:
            cmd.append('-L')
            cmd.append(self.login_class)

        if self.update_password == 'always' and self.password is not None and info[1] != self.password:
            cmd.append('-p')
            cmd.append(self.password)

        if self.password_lock and not info[1].startswith('*LOCKED*'):
            cmd.append('-C yes')
        elif self.password_lock is False and info[1].startswith('*LOCKED*'):
            cmd.append('-C no')

        # skip if no changes to be made
        if len(cmd) == 1:
            return (None, '', '')

        cmd.append(self.name)
        return self.execute_command(cmd)

</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/user.py" startline="2638" endline="2714" pcid="3481">

    def modify_user_usermod(self):
        cmd = [self.module.get_bin_path('usermod', True)]
        info = self.user_info()

        if self.uid is not None and info[2] != int(self.uid):
            cmd.append('-u')
            cmd.append(self.uid)

        if self.group is not None:
            if not self.group_exists(self.group):
                self.module.fail_json(msg="Group %s does not exist" % self.group)
            ginfo = self.group_info(self.group)
            if info[3] != ginfo[2]:
                cmd.append('-g')
                cmd.append(self.group)

        if self.groups is not None:
            current_groups = self.user_group_membership()
            groups_need_mod = False
            groups = []

            if self.groups == '':
                if current_groups and not self.append:
                    groups_need_mod = True
            else:
                groups = self.get_groups_set()
                group_diff = set(current_groups).symmetric_difference(groups)

                if group_diff:
                    if self.append:
                        for g in groups:
                            if g in group_diff:
                                groups_need_mod = True
                                break
                    else:
                        groups_need_mod = True

            if groups_need_mod:
                cmd.append('-G')
                cmd.append(','.join(groups))

        if self.comment is not None and info[4] != self.comment:
            cmd.append('-c')
            cmd.append(self.comment)

        if self.home is not None and info[5] != self.home:
            if self.move_home:
                cmd.append('-m')
            cmd.append('-d')
            cmd.append(self.home)

        if self.shell is not None and info[6] != self.shell:
            cmd.append('-s')
            cmd.append(self.shell)

        # skip if no changes to be made
        if len(cmd) == 1:
            (rc, out, err) = (None, '', '')
        else:
            cmd.append(self.name)
            (rc, out, err) = self.execute_command(cmd)

        # set password with chpasswd
        if self.update_password == 'always' and self.password is not None and info[1] != self.password:
            cmd = []
            cmd.append(self.module.get_bin_path('chpasswd', True))
            cmd.append('-e')
            cmd.append('-c')
            (rc2, out2, err2) = self.execute_command(cmd, data="%s:%s" % (self.name, self.password))
        else:
            (rc2, out2, err2) = (None, '', '')

        if rc is not None:
            return (rc, out + out2, err + err2)
        else:
            return (rc2, out + out2, err + err2)
</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/user.py" startline="2833" endline="2906" pcid="3485">

    def modify_user(self):
        cmd = ['/usr/sam/lbin/usermod.sam']
        info = self.user_info()

        if self.uid is not None and info[2] != int(self.uid):
            cmd.append('-u')
            cmd.append(self.uid)

            if self.non_unique:
                cmd.append('-o')

        if self.group is not None:
            if not self.group_exists(self.group):
                self.module.fail_json(msg="Group %s does not exist" % self.group)
            ginfo = self.group_info(self.group)
            if info[3] != ginfo[2]:
                cmd.append('-g')
                cmd.append(self.group)

        if self.groups is not None:
            current_groups = self.user_group_membership()
            groups_need_mod = False
            groups = []

            if self.groups == '':
                if current_groups and not self.append:
                    groups_need_mod = True
            else:
                groups = self.get_groups_set(remove_existing=False)
                group_diff = set(current_groups).symmetric_difference(groups)

                if group_diff:
                    if self.append:
                        for g in groups:
                            if g in group_diff:
                                groups_need_mod = True
                                break
                    else:
                        groups_need_mod = True

            if groups_need_mod:
                cmd.append('-G')
                new_groups = groups
                if self.append:
                    new_groups = groups | set(current_groups)
                cmd.append(','.join(new_groups))

        if self.comment is not None and info[4] != self.comment:
            cmd.append('-c')
            cmd.append(self.comment)

        if self.home is not None and info[5] != self.home:
            cmd.append('-d')
            cmd.append(self.home)
            if self.move_home:
                cmd.append('-m')

        if self.shell is not None and info[6] != self.shell:
            cmd.append('-s')
            cmd.append(self.shell)

        if self.update_password == 'always' and self.password is not None and info[1] != self.password:
            cmd.append('-F')
            cmd.append('-p')
            cmd.append(self.password)

        # skip if no changes to be made
        if len(cmd) == 1:
            return (None, '', '')

        cmd.append(self.name)
        return self.execute_command(cmd)

</source>
</class>

<class classid="74" nclones="4" nlines="12" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/ping.py" startline="71" endline="88" pcid="3535">
def main():
    module = AnsibleModule(
        argument_spec=dict(
            data=dict(type='str', default='pong'),
        ),
        supports_check_mode=True
    )

    if module.params['data'] == 'crash':
        raise Exception("boom")

    result = dict(
        ping=module.params['data'],
    )

    module.exit_json(**result)


</source>
<source file="systems/ansible-2.12.4rc1/test/integration/targets/ansible-galaxy-collection/files/test_module.py" startline="61" endline="78" pcid="7679">
def main():
    module = AnsibleModule(
        argument_spec=dict(
            data=dict(type='str', default='pong'),
        ),
        supports_check_mode=True
    )

    if module.params['data'] == 'crash':
        raise Exception("boom")

    result = dict(
        ping=module.params['data'],
    )

    module.exit_json(**result)


</source>
<source file="systems/ansible-2.12.4rc1/test/integration/targets/module_defaults/library/legacy_ping.py" startline="64" endline="81" pcid="7732">
def main():
    module = AnsibleModule(
        argument_spec=dict(
            data=dict(type='str', default='pong'),
        ),
        supports_check_mode=True
    )

    if module.params['data'] == 'crash':
        raise Exception("boom")

    result = dict(
        ping=module.params['data'],
    )

    module.exit_json(**result)


</source>
<source file="systems/ansible-2.12.4rc1/test/integration/targets/module_defaults/collections/ansible_collections/testns/testcoll/plugins/modules/ping.py" startline="64" endline="81" pcid="7738">
def main():
    module = AnsibleModule(
        argument_spec=dict(
            data=dict(type='str', default='pong'),
        ),
        supports_check_mode=True
    )

    if module.params['data'] == 'crash':
        raise Exception("boom")

    result = dict(
        ping=module.params['data'],
    )

    module.exit_json(**result)


</source>
</class>

<class classid="75" nclones="2" nlines="10" similarity="70">
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/wait_for.py" startline="463" endline="474" pcid="3579">
def get_connection_state_id(state):
    connection_state_id = {
        'ESTABLISHED': '01',
        'SYN_SENT': '02',
        'SYN_RECV': '03',
        'FIN_WAIT1': '04',
        'FIN_WAIT2': '05',
        'TIME_WAIT': '06',
    }
    return connection_state_id[state]


</source>
<source file="systems/ansible-2.12.4rc1/test/integration/targets/module_utils_urls/library/test_peercert.py" startline="37" endline="49" pcid="7890">
def get_x509_shorthand(name, value):
    prefix = {
        'countryName': 'C',
        'stateOrProvinceName': 'ST',
        'localityName': 'L',
        'organizationName': 'O',
        'commonName': 'CN',
        'organizationalUnitName': 'OU',
    }[name]

    return '%s=%s' % (prefix, value)


</source>
</class>

<class classid="76" nclones="2" nlines="11" similarity="100">
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/service.py" startline="1132" endline="1147" pcid="3636">
    def service_enable(self):
        if self.enable:
            self.rcconf_value = "YES"
        else:
            self.rcconf_value = "NO"

        rcfiles = ['/etc/rc.conf']  # Overkill?
        for rcfile in rcfiles:
            if os.path.isfile(rcfile):
                self.rcconf_file = rcfile

        self.rcconf_key = "%s" % self.name.replace("-", "_")

        return self.service_enable_rcconf()


</source>
<source file="systems/ansible-2.12.4rc1/lib/ansible/modules/service.py" startline="1320" endline="1334" pcid="3642">
    def service_enable(self):
        if self.enable:
            self.rcconf_value = "YES"
        else:
            self.rcconf_value = "NO"

        rcfiles = ['/etc/rc.conf']  # Overkill?
        for rcfile in rcfiles:
            if os.path.isfile(rcfile):
                self.rcconf_file = rcfile

        self.rcconf_key = "%s" % self.name.replace("-", "_")

        return self.service_enable_rcconf()

</source>
</class>

<class classid="77" nclones="2" nlines="11" similarity="81">
<source file="systems/ansible-2.12.4rc1/test/units/cli/test_vault.py" startline="106" endline="117" pcid="3723">
    def test_encrypt_string_prompt(self, mock_display, mock_vault_editor, mock_setup_vault_secrets):
        mock_setup_vault_secrets.return_value = [('default', TextVaultSecret('password'))]
        cli = VaultCLI(args=['ansible-vault',
                             'encrypt_string',
                             '--prompt',
                             '--show-input',
                             'some string to encrypt'])
        cli.parse()
        cli.run()
        args, kwargs = mock_display.call_args
        assert kwargs["private"] is False

</source>
<source file="systems/ansible-2.12.4rc1/test/units/cli/test_vault.py" startline="121" endline="131" pcid="3724">
    def test_shadowed_encrypt_string_prompt(self, mock_display, mock_vault_editor, mock_setup_vault_secrets):
        mock_setup_vault_secrets.return_value = [('default', TextVaultSecret('password'))]
        cli = VaultCLI(args=['ansible-vault',
                             'encrypt_string',
                             '--prompt',
                             'some string to encrypt'])
        cli.parse()
        cli.run()
        args, kwargs = mock_display.call_args
        assert kwargs["private"]

</source>
</class>

<class classid="78" nclones="2" nlines="18" similarity="72">
<source file="systems/ansible-2.12.4rc1/test/units/cli/test_doc.py" startline="43" endline="63" pcid="3735">
def test_rolemixin__build_summary():
    obj = RoleMixin()
    role_name = 'test_role'
    collection_name = 'test.units'
    argspec = {
        'main': {'short_description': 'main short description'},
        'alternate': {'short_description': 'alternate short description'},
    }
    expected = {
        'collection': collection_name,
        'entry_points': {
            'main': argspec['main']['short_description'],
            'alternate': argspec['alternate']['short_description'],
        }
    }

    fqcn, summary = obj._build_summary(role_name, collection_name, argspec)
    assert fqcn == '.'.join([collection_name, role_name])
    assert summary == expected


</source>
<source file="systems/ansible-2.12.4rc1/test/units/cli/test_doc.py" startline="79" endline="100" pcid="3737">
def test_rolemixin__build_doc():
    obj = RoleMixin()
    role_name = 'test_role'
    path = '/a/b/c'
    collection_name = 'test.units'
    entrypoint_filter = 'main'
    argspec = {
        'main': {'short_description': 'main short description'},
        'alternate': {'short_description': 'alternate short description'},
    }
    expected = {
        'path': path,
        'collection': collection_name,
        'entry_points': {
            'main': argspec['main'],
        }
    }
    fqcn, doc = obj._build_doc(role_name, path, collection_name, argspec, entrypoint_filter)
    assert fqcn == '.'.join([collection_name, role_name])
    assert doc == expected


</source>
</class>

<class classid="79" nclones="6" nlines="10" similarity="75">
<source file="systems/ansible-2.12.4rc1/test/units/cli/test_cli.py" startline="150" endline="164" pcid="3758">
    def test_prompt(self, mock_prompt_secret):
        mock_prompt_secret.return_value = MagicMock(bytes=b'prompt1_password',
                                                    vault_id='prompt1')

        res = cli.CLI.setup_vault_secrets(loader=self.fake_loader,
                                          vault_ids=['prompt1@prompt'],
                                          ask_vault_pass=True,
                                          auto_prompt=False)

        self.assertIsInstance(res, list)
        matches = vault.match_secrets(res, ['prompt1'])
        self.assertIn('prompt1', [x[0] for x in matches])
        match = matches[0][1]
        self.assertEqual(match.bytes, b'prompt1_password')

</source>
<source file="systems/ansible-2.12.4rc1/test/units/cli/test_cli.py" startline="342" endline="354" pcid="3768">
    def test_prompt_new_password_vault_id_prompt(self, mock_prompt_secret):
        mock_prompt_secret.return_value = MagicMock(bytes=b'prompt1_password',
                                                    vault_id='some_vault_id')

        res = cli.CLI.setup_vault_secrets(loader=self.fake_loader,
                                          vault_ids=['some_vault_id@prompt'],
                                          create_new_password=True,
                                          ask_vault_pass=False)

        self.assertIsInstance(res, list)
        match = vault.match_secrets(res, ['some_vault_id'])[0][1]
        self.assertEqual(match.bytes, b'prompt1_password')

</source>
<source file="systems/ansible-2.12.4rc1/test/units/cli/test_cli.py" startline="370" endline="381" pcid="3770">
    def test_prompt_new_password_vault_id_prompt_ask_vault_pass_ask_vault_pass(self, mock_prompt_secret):
        mock_prompt_secret.return_value = MagicMock(bytes=b'prompt1_password',
                                                    vault_id='default')

        res = cli.CLI.setup_vault_secrets(loader=self.fake_loader,
                                          vault_ids=['some_vault_id@prompt_ask_vault_pass'],
                                          create_new_password=True,
                                          ask_vault_pass=True)

        self.assertIsInstance(res, list)
        match = vault.match_secrets(res, ['some_vault_id'])[0][1]
        self.assertEqual(match.bytes, b'prompt1_password')
</source>
<source file="systems/ansible-2.12.4rc1/test/units/cli/test_cli.py" startline="356" endline="368" pcid="3769">
    def test_prompt_new_password_vault_id_prompt_ask_vault_pass(self, mock_prompt_secret):
        mock_prompt_secret.return_value = MagicMock(bytes=b'prompt1_password',
                                                    vault_id='default')

        res = cli.CLI.setup_vault_secrets(loader=self.fake_loader,
                                          vault_ids=['some_vault_id@prompt_ask_vault_pass'],
                                          create_new_password=True,
                                          ask_vault_pass=False)

        self.assertIsInstance(res, list)
        match = vault.match_secrets(res, ['some_vault_id'])[0][1]
        self.assertEqual(match.bytes, b'prompt1_password')

</source>
<source file="systems/ansible-2.12.4rc1/test/units/cli/test_cli.py" startline="328" endline="340" pcid="3767">
    def test_prompt_new_password_ask_vault_pass(self, mock_prompt_secret):
        mock_prompt_secret.return_value = MagicMock(bytes=b'prompt1_password',
                                                    vault_id='default')

        res = cli.CLI.setup_vault_secrets(loader=self.fake_loader,
                                          vault_ids=[],
                                          create_new_password=True,
                                          ask_vault_pass=True)

        self.assertIsInstance(res, list)
        match = vault.match_secrets(res, ['default'])[0][1]
        self.assertEqual(match.bytes, b'prompt1_password')

</source>
<source file="systems/ansible-2.12.4rc1/test/units/cli/test_cli.py" startline="314" endline="326" pcid="3766">
    def test_prompt_just_ask_vault_pass(self, mock_prompt_secret):
        mock_prompt_secret.return_value = MagicMock(bytes=b'prompt1_password',
                                                    vault_id='default')

        res = cli.CLI.setup_vault_secrets(loader=self.fake_loader,
                                          vault_ids=[],
                                          create_new_password=False,
                                          ask_vault_pass=True)

        self.assertIsInstance(res, list)
        match = vault.match_secrets(res, ['default'])[0][1]
        self.assertEqual(match.bytes, b'prompt1_password')

</source>
</class>

<class classid="80" nclones="4" nlines="20" similarity="76">
<source file="systems/ansible-2.12.4rc1/test/units/cli/test_galaxy.py" startline="752" endline="778" pcid="3832">

def test_collection_install_with_names(collection_install):
    mock_install, mock_warning, output_dir = collection_install

    galaxy_args = ['ansible-galaxy', 'collection', 'install', 'namespace.collection', 'namespace2.collection:1.0.1',
                   '--collections-path', output_dir]
    GalaxyCLI(args=galaxy_args).run()

    collection_path = os.path.join(output_dir, 'ansible_collections')
    assert os.path.isdir(collection_path)

    assert mock_warning.call_count == 1
    assert "The specified collections path '%s' is not part of the configured Ansible collections path" % output_dir \
        in mock_warning.call_args[0][0]

    assert mock_install.call_count == 1
    requirements = [('%s.%s' % (r.namespace, r.name), r.ver, r.src, r.type,) for r in mock_install.call_args[0][0]]
    assert requirements == [('namespace.collection', '*', None, 'galaxy'),
                            ('namespace2.collection', '1.0.1', None, 'galaxy')]
    assert mock_install.call_args[0][1] == collection_path
    assert len(mock_install.call_args[0][2]) == 1
    assert mock_install.call_args[0][2][0].api_server == 'https://galaxy.ansible.com'
    assert mock_install.call_args[0][2][0].validate_certs is True
    assert mock_install.call_args[0][3] is False  # ignore_errors
    assert mock_install.call_args[0][4] is False  # no_deps
    assert mock_install.call_args[0][5] is False  # force
    assert mock_install.call_args[0][6] is False  # force_deps
</source>
<source file="systems/ansible-2.12.4rc1/test/units/cli/test_galaxy.py" startline="874" endline="898" pcid="3836">
    assert mock_req.call_args[0][0] == os.path.expanduser(os.path.expandvars(requirements_file))


def test_collection_install_in_collection_dir(collection_install, monkeypatch):
    mock_install, mock_warning, output_dir = collection_install

    collections_path = C.COLLECTIONS_PATHS[0]

    galaxy_args = ['ansible-galaxy', 'collection', 'install', 'namespace.collection', 'namespace2.collection:1.0.1',
                   '--collections-path', collections_path]
    GalaxyCLI(args=galaxy_args).run()

    assert mock_warning.call_count == 0

    assert mock_install.call_count == 1
    requirements = [('%s.%s' % (r.namespace, r.name), r.ver, r.src, r.type,) for r in mock_install.call_args[0][0]]
    assert requirements == [('namespace.collection', '*', None, 'galaxy'),
                            ('namespace2.collection', '1.0.1', None, 'galaxy')]
    assert mock_install.call_args[0][1] == os.path.join(collections_path, 'ansible_collections')
    assert len(mock_install.call_args[0][2]) == 1
    assert mock_install.call_args[0][2][0].api_server == 'https://galaxy.ansible.com'
    assert mock_install.call_args[0][2][0].validate_certs is True
    assert mock_install.call_args[0][3] is False  # ignore_errors
    assert mock_install.call_args[0][4] is False  # no_deps
    assert mock_install.call_args[0][5] is False  # force
</source>
<source file="systems/ansible-2.12.4rc1/test/units/cli/test_galaxy.py" startline="779" endline="813" pcid="3833">


def test_collection_install_with_requirements_file(collection_install):
    mock_install, mock_warning, output_dir = collection_install

    requirements_file = os.path.join(output_dir, 'requirements.yml')
    with open(requirements_file, 'wb') as req_obj:
        req_obj.write(b'''---
collections:
- namespace.coll
- name: namespace2.coll
  version: '>2.0.1'
''')

    galaxy_args = ['ansible-galaxy', 'collection', 'install', '--requirements-file', requirements_file,
                   '--collections-path', output_dir]
    GalaxyCLI(args=galaxy_args).run()

    collection_path = os.path.join(output_dir, 'ansible_collections')
    assert os.path.isdir(collection_path)

    assert mock_warning.call_count == 1
    assert "The specified collections path '%s' is not part of the configured Ansible collections path" % output_dir \
        in mock_warning.call_args[0][0]

    assert mock_install.call_count == 1
    requirements = [('%s.%s' % (r.namespace, r.name), r.ver, r.src, r.type,) for r in mock_install.call_args[0][0]]
    assert requirements == [('namespace.coll', '*', None, 'galaxy'),
                            ('namespace2.coll', '>2.0.1', None, 'galaxy')]
    assert mock_install.call_args[0][1] == collection_path
    assert mock_install.call_args[0][2][0].api_server == 'https://galaxy.ansible.com'
    assert mock_install.call_args[0][2][0].validate_certs is True
    assert mock_install.call_args[0][3] is False  # ignore_errors
    assert mock_install.call_args[0][4] is False  # no_deps
    assert mock_install.call_args[0][5] is False  # force
</source>
<source file="systems/ansible-2.12.4rc1/test/units/cli/test_galaxy.py" startline="945" endline="972" pcid="3840">
        GalaxyCLI(args=['ansible-galaxy', 'collection', 'install', '--collections-path', test_path]).run()


def test_collection_install_path_with_ansible_collections(collection_install):
    mock_install, mock_warning, output_dir = collection_install

    collection_path = os.path.join(output_dir, 'ansible_collections')

    galaxy_args = ['ansible-galaxy', 'collection', 'install', 'namespace.collection', 'namespace2.collection:1.0.1',
                   '--collections-path', collection_path]
    GalaxyCLI(args=galaxy_args).run()

    assert os.path.isdir(collection_path)

    assert mock_warning.call_count == 1
    assert "The specified collections path '%s' is not part of the configured Ansible collections path" \
        % collection_path in mock_warning.call_args[0][0]

    assert mock_install.call_count == 1
    requirements = [('%s.%s' % (r.namespace, r.name), r.ver, r.src, r.type,) for r in mock_install.call_args[0][0]]
    assert requirements == [('namespace.collection', '*', None, 'galaxy'),
                            ('namespace2.collection', '1.0.1', None, 'galaxy')]
    assert mock_install.call_args[0][1] == collection_path
    assert len(mock_install.call_args[0][2]) == 1
    assert mock_install.call_args[0][2][0].api_server == 'https://galaxy.ansible.com'
    assert mock_install.call_args[0][2][0].validate_certs is True
    assert mock_install.call_args[0][3] is False  # ignore_errors
    assert mock_install.call_args[0][4] is False  # no_deps
</source>
</class>

<class classid="81" nclones="2" nlines="23" similarity="91">
<source file="systems/ansible-2.12.4rc1/test/units/cli/test_galaxy.py" startline="814" endline="843" pcid="3834">
    assert mock_install.call_args[0][6] is False  # force_deps


def test_collection_install_with_relative_path(collection_install, monkeypatch):
    mock_install = collection_install[0]

    mock_req = MagicMock()
    mock_req.return_value = {'collections': [('namespace.coll', '*', None, None)], 'roles': []}
    monkeypatch.setattr(ansible.cli.galaxy.GalaxyCLI, '_parse_requirements_file', mock_req)

    monkeypatch.setattr(os, 'makedirs', MagicMock())

    requirements_file = './requirements.myl'
    collections_path = './ansible_collections'
    galaxy_args = ['ansible-galaxy', 'collection', 'install', '--requirements-file', requirements_file,
                   '--collections-path', collections_path]
    GalaxyCLI(args=galaxy_args).run()

    assert mock_install.call_count == 1
    assert mock_install.call_args[0][0] == [('namespace.coll', '*', None, None)]
    assert mock_install.call_args[0][1] == os.path.abspath(collections_path)
    assert len(mock_install.call_args[0][2]) == 1
    assert mock_install.call_args[0][2][0].api_server == 'https://galaxy.ansible.com'
    assert mock_install.call_args[0][2][0].validate_certs is True
    assert mock_install.call_args[0][3] is False  # ignore_errors
    assert mock_install.call_args[0][4] is False  # no_deps
    assert mock_install.call_args[0][5] is False  # force
    assert mock_install.call_args[0][6] is False  # force_deps

    assert mock_req.call_count == 1
</source>
<source file="systems/ansible-2.12.4rc1/test/units/cli/test_galaxy.py" startline="844" endline="873" pcid="3835">
    assert mock_req.call_args[0][0] == os.path.abspath(requirements_file)


def test_collection_install_with_unexpanded_path(collection_install, monkeypatch):
    mock_install = collection_install[0]

    mock_req = MagicMock()
    mock_req.return_value = {'collections': [('namespace.coll', '*', None, None)], 'roles': []}
    monkeypatch.setattr(ansible.cli.galaxy.GalaxyCLI, '_parse_requirements_file', mock_req)

    monkeypatch.setattr(os, 'makedirs', MagicMock())

    requirements_file = '~/requirements.myl'
    collections_path = '~/ansible_collections'
    galaxy_args = ['ansible-galaxy', 'collection', 'install', '--requirements-file', requirements_file,
                   '--collections-path', collections_path]
    GalaxyCLI(args=galaxy_args).run()

    assert mock_install.call_count == 1
    assert mock_install.call_args[0][0] == [('namespace.coll', '*', None, None)]
    assert mock_install.call_args[0][1] == os.path.expanduser(os.path.expandvars(collections_path))
    assert len(mock_install.call_args[0][2]) == 1
    assert mock_install.call_args[0][2][0].api_server == 'https://galaxy.ansible.com'
    assert mock_install.call_args[0][2][0].validate_certs is True
    assert mock_install.call_args[0][3] is False  # ignore_errors
    assert mock_install.call_args[0][4] is False  # no_deps
    assert mock_install.call_args[0][5] is False  # force
    assert mock_install.call_args[0][6] is False  # force_deps

    assert mock_req.call_count == 1
</source>
</class>

<class classid="82" nclones="4" nlines="21" similarity="77">
<source file="systems/ansible-2.12.4rc1/test/units/cli/test_galaxy.py" startline="1234" endline="1262" pcid="3859">
collections:
- namespace.name
roles:
- namespace.name
'''], indirect=True)
def test_install_implicit_role_with_collections(requirements_file, monkeypatch):
    mock_collection_install = MagicMock()
    monkeypatch.setattr(GalaxyCLI, '_execute_install_collection', mock_collection_install)
    mock_role_install = MagicMock()
    monkeypatch.setattr(GalaxyCLI, '_execute_install_role', mock_role_install)

    mock_display = MagicMock()
    monkeypatch.setattr(Display, 'display', mock_display)

    cli = GalaxyCLI(args=['ansible-galaxy', 'install', '-r', requirements_file])
    cli.run()

    assert mock_collection_install.call_count == 1
    requirements = [('%s.%s' % (r.namespace, r.name), r.ver, r.src, r.type,) for r in mock_collection_install.call_args[0][0]]
    assert requirements == [('namespace.name', '*', None, 'galaxy')]
    assert mock_collection_install.call_args[0][1] == cli._get_default_collection_path()

    assert mock_role_install.call_count == 1
    assert len(mock_role_install.call_args[0][0]) == 1
    assert str(mock_role_install.call_args[0][0][0]) == 'namespace.name'

    found = False
    for mock_call in mock_display.mock_calls:
        if 'contains collections which will be ignored' in mock_call[1][0]:
</source>
<source file="systems/ansible-2.12.4rc1/test/units/cli/test_galaxy.py" startline="1301" endline="1326" pcid="3861">
collections:
- namespace.name
roles:
- namespace.name
'''], indirect=True)
def test_install_role_with_collections_and_path(requirements_file, monkeypatch):
    mock_collection_install = MagicMock()
    monkeypatch.setattr(GalaxyCLI, '_execute_install_collection', mock_collection_install)
    mock_role_install = MagicMock()
    monkeypatch.setattr(GalaxyCLI, '_execute_install_role', mock_role_install)

    mock_display = MagicMock()
    monkeypatch.setattr(Display, 'warning', mock_display)

    cli = GalaxyCLI(args=['ansible-galaxy', 'install', '-p', 'path', '-r', requirements_file])
    cli.run()

    assert mock_collection_install.call_count == 0

    assert mock_role_install.call_count == 1
    assert len(mock_role_install.call_args[0][0]) == 1
    assert str(mock_role_install.call_args[0][0][0]) == 'namespace.name'

    found = False
    for mock_call in mock_display.mock_calls:
        if 'contains collections which will be ignored' in mock_call[1][0]:
</source>
<source file="systems/ansible-2.12.4rc1/test/units/cli/test_galaxy.py" startline="1333" endline="1356" pcid="3862">
collections:
- namespace.name
roles:
- namespace.name
'''], indirect=True)
def test_install_collection_with_roles(requirements_file, monkeypatch):
    mock_collection_install = MagicMock()
    monkeypatch.setattr(GalaxyCLI, '_execute_install_collection', mock_collection_install)
    mock_role_install = MagicMock()
    monkeypatch.setattr(GalaxyCLI, '_execute_install_role', mock_role_install)

    mock_display = MagicMock()
    monkeypatch.setattr(Display, 'vvv', mock_display)

    cli = GalaxyCLI(args=['ansible-galaxy', 'collection', 'install', '-r', requirements_file])
    cli.run()

    assert mock_collection_install.call_count == 1
    requirements = [('%s.%s' % (r.namespace, r.name), r.ver, r.src, r.type,) for r in mock_collection_install.call_args[0][0]]
    assert requirements == [('namespace.name', '*', None, 'galaxy')]

    assert mock_role_install.call_count == 0

    found = False
</source>
<source file="systems/ansible-2.12.4rc1/test/units/cli/test_galaxy.py" startline="1269" endline="1294" pcid="3860">
collections:
- namespace.name
roles:
- namespace.name
'''], indirect=True)
def test_install_explicit_role_with_collections(requirements_file, monkeypatch):
    mock_collection_install = MagicMock()
    monkeypatch.setattr(GalaxyCLI, '_execute_install_collection', mock_collection_install)
    mock_role_install = MagicMock()
    monkeypatch.setattr(GalaxyCLI, '_execute_install_role', mock_role_install)

    mock_display = MagicMock()
    monkeypatch.setattr(Display, 'vvv', mock_display)

    cli = GalaxyCLI(args=['ansible-galaxy', 'role', 'install', '-r', requirements_file])
    cli.run()

    assert mock_collection_install.call_count == 0

    assert mock_role_install.call_count == 1
    assert len(mock_role_install.call_args[0][0]) == 1
    assert str(mock_role_install.call_args[0][0][0]) == 'namespace.name'

    found = False
    for mock_call in mock_display.mock_calls:
        if 'contains collections which will be ignored' in mock_call[1][0]:
</source>
</class>

<class classid="83" nclones="3" nlines="23" similarity="70">
<source file="systems/ansible-2.12.4rc1/test/units/cli/galaxy/test_execute_list_collection.py" startline="124" endline="153" pcid="3877">
def test_execute_list_collection_all(mocker, capsys, mock_collection_objects, tmp_path_factory):
    """Test listing all collections from multiple paths"""

    cliargs()

    mocker.patch('os.path.exists', return_value=True)
    mocker.patch('os.path.isdir', return_value=True)
    gc = GalaxyCLI(['ansible-galaxy', 'collection', 'list'])
    tmp_path = tmp_path_factory.mktemp('test- Collections')
    concrete_artifact_cm = collection.concrete_artifact_manager.ConcreteArtifactsManager(tmp_path, validate_certs=False)
    gc.execute_list_collection(artifacts_manager=concrete_artifact_cm)

    out, err = capsys.readouterr()
    out_lines = out.splitlines()

    assert len(out_lines) == 12
    assert out_lines[0] == ''
    assert out_lines[1] == '# /root/.ansible/collections/ansible_collections'
    assert out_lines[2] == 'Collection        Version'
    assert out_lines[3] == '----------------- -------'
    assert out_lines[4] == 'sandwiches.pbj    1.5.0  '
    assert out_lines[5] == 'sandwiches.reuben 2.5.0  '
    assert out_lines[6] == ''
    assert out_lines[7] == '# /usr/share/ansible/collections/ansible_collections'
    assert out_lines[8] == 'Collection     Version'
    assert out_lines[9] == '-------------- -------'
    assert out_lines[10] == 'sandwiches.ham 1.0.0  '
    assert out_lines[11] == 'sandwiches.pbj 1.0.0  '


</source>
<source file="systems/ansible-2.12.4rc1/test/units/cli/galaxy/test_execute_list_collection.py" startline="182" endline="213" pcid="3879">
def test_execute_list_collection_specific_duplicate(mocker, capsys, mock_collection_objects, mock_from_path, tmp_path_factory):
    """Test listing a specific collection that exists at multiple paths"""

    collection_name = 'sandwiches.pbj'
    mock_from_path(collection_name)

    cliargs(collection_name=collection_name)
    mocker.patch('os.path.exists', path_exists)
    mocker.patch('os.path.isdir', return_value=True)
    mocker.patch('ansible.galaxy.collection.validate_collection_name', collection_name)

    gc = GalaxyCLI(['ansible-galaxy', 'collection', 'list', collection_name])
    tmp_path = tmp_path_factory.mktemp('test- Collections')
    concrete_artifact_cm = collection.concrete_artifact_manager.ConcreteArtifactsManager(tmp_path, validate_certs=False)
    gc.execute_list_collection(artifacts_manager=concrete_artifact_cm)

    out, err = capsys.readouterr()
    out_lines = out.splitlines()

    assert len(out_lines) == 10
    assert out_lines[0] == ''
    assert out_lines[1] == '# /root/.ansible/collections/ansible_collections'
    assert out_lines[2] == 'Collection     Version'
    assert out_lines[3] == '-------------- -------'
    assert out_lines[4] == 'sandwiches.pbj 1.5.0  '
    assert out_lines[5] == ''
    assert out_lines[6] == '# /usr/share/ansible/collections/ansible_collections'
    assert out_lines[7] == 'Collection     Version'
    assert out_lines[8] == '-------------- -------'
    assert out_lines[9] == 'sandwiches.pbj 1.0.0  '


</source>
<source file="systems/ansible-2.12.4rc1/test/units/cli/galaxy/test_execute_list_collection.py" startline="154" endline="181" pcid="3878">
def test_execute_list_collection_specific(mocker, capsys, mock_collection_objects, mock_from_path, tmp_path_factory):
    """Test listing a specific collection"""

    collection_name = 'sandwiches.ham'
    mock_from_path(collection_name)

    cliargs(collection_name=collection_name)
    mocker.patch('os.path.exists', path_exists)
    mocker.patch('os.path.isdir', return_value=True)
    mocker.patch('ansible.galaxy.collection.validate_collection_name', collection_name)
    mocker.patch('ansible.cli.galaxy._get_collection_widths', return_value=(14, 5))

    gc = GalaxyCLI(['ansible-galaxy', 'collection', 'list', collection_name])
    tmp_path = tmp_path_factory.mktemp('test- Collections')
    concrete_artifact_cm = collection.concrete_artifact_manager.ConcreteArtifactsManager(tmp_path, validate_certs=False)
    gc.execute_list_collection(artifacts_manager=concrete_artifact_cm)

    out, err = capsys.readouterr()
    out_lines = out.splitlines()

    assert len(out_lines) == 5
    assert out_lines[0] == ''
    assert out_lines[1] == '# /usr/share/ansible/collections/ansible_collections'
    assert out_lines[2] == 'Collection     Version'
    assert out_lines[3] == '-------------- -------'
    assert out_lines[4] == 'sandwiches.ham 1.0.0  '


</source>
</class>

<class classid="84" nclones="4" nlines="15" similarity="75">
<source file="systems/ansible-2.12.4rc1/test/units/template/test_templar.py" startline="86" endline="102" pcid="3906">
    def test_is_possibly_template_true(self):
        tests = [
            '{{ foo }}',
            '{% foo %}',
            '{# foo #}',
            '{# {{ foo }} #}',
            '{# {{ nothing }} {# #}',
            '{# {{ nothing }} {# #} #}',
            '{% raw %}{{ foo }}{% endraw %}',
            '{{',
            '{%',
            '{#',
            '{% raw',
        ]
        for test in tests:
            self.assertTrue(self.templar.is_possibly_template(test))

</source>
<source file="systems/ansible-2.12.4rc1/test/units/template/test_templar.py" startline="135" endline="152" pcid="3910">
    def test_is_template_false(self):
        tests = [
            'foo',
            '{{ foo',
            '{% foo',
            '{# foo',
            '{{ foo %}',
            '{{ foo #}',
            '{% foo }}',
            '{% foo #}',
            '{# foo %}',
            '{# foo }}',
            '{{ foo {{',
            '{% raw %}{% foo %}',
        ]
        for test in tests:
            self.assertFalse(self.templar.is_template(test))

</source>
<source file="systems/ansible-2.12.4rc1/test/units/template/test_templar.py" startline="103" endline="116" pcid="3907">
    def test_is_possibly_template_false(self):
        tests = [
            '{',
            '%',
            '#',
            'foo',
            '}}',
            '%}',
            'raw %}',
            '#}',
        ]
        for test in tests:
            self.assertFalse(self.templar.is_possibly_template(test))

</source>
<source file="systems/ansible-2.12.4rc1/test/units/template/test_templar.py" startline="122" endline="134" pcid="3909">
    def test_is_template_true(self):
        tests = [
            '{{ foo }}',
            '{% foo %}',
            '{# foo #}',
            '{# {{ foo }} #}',
            '{# {{ nothing }} {# #}',
            '{# {{ nothing }} {# #} #}',
            '{% raw %}{{ foo }}{% endraw %}',
        ]
        for test in tests:
            self.assertTrue(self.templar.is_template(test))

</source>
</class>

<class classid="85" nclones="2" nlines="11" similarity="72">
<source file="systems/ansible-2.12.4rc1/test/units/utils/test_context_objects.py" startline="44" endline="58" pcid="4076">
def test_cliargs():
    class FakeOptions:
        pass
    options = FakeOptions()
    options.tags = [u'production', u'webservers']
    options.check_mode = True
    options.start_at_task = u'Start with '

    expected = frozenset((('tags', (u'production', u'webservers')),
                          ('check_mode', True),
                          ('start_at_task', u'Start with ')))

    assert frozenset(co.CLIArgs.from_options(options).items()) == expected


</source>
<source file="systems/ansible-2.12.4rc1/test/units/test_context.py" startline="16" endline="27" pcid="5008">
def test_set_global_context():
    options = FakeOptions()
    options.tags = [u'production', u'webservers']
    options.check_mode = True
    options.start_at_task = u'Start with '

    expected = frozenset((('tags', (u'production', u'webservers')),
                          ('check_mode', True),
                          ('start_at_task', u'Start with ')))

    context._init_global_context(options)
    assert frozenset(context.CLIARGS.items()) == expected
</source>
</class>

<class classid="86" nclones="7" nlines="12" similarity="78">
<source file="systems/ansible-2.12.4rc1/test/units/utils/test_vars.py" startline="118" endline="136" pcid="4102">
    def test_merge_hash_simple(self):
        for test in self.combine_vars_merge_data:
            self.assertEqual(merge_hash(test['a'], test['b']), test['result'])

        low = self.merge_hash_data['low_prio']
        high = self.merge_hash_data['high_prio']
        expected = {
            "a": {
                "a'": {
                    "x": "low_value",
                    "y": "high_value",
                    "z": "high_value",
                    "list": ["high_value"]
                }
            },
            "b": high['b']
        }
        self.assertEqual(merge_hash(low, high), expected)

</source>
<source file="systems/ansible-2.12.4rc1/test/units/utils/test_vars.py" startline="204" endline="219" pcid="4110">
    def test_merge_hash_recursive_and_list_keep(self):
        low = self.merge_hash_data['low_prio']
        high = self.merge_hash_data['high_prio']
        expected = {
            "a": {
                "a'": {
                    "x": "low_value",
                    "y": "high_value",
                    "z": "high_value",
                    "list": ["low_value"]
                }
            },
            "b": low['b']
        }
        self.assertEqual(merge_hash(low, high, True, 'keep'), expected)

</source>
<source file="systems/ansible-2.12.4rc1/test/units/utils/test_vars.py" startline="188" endline="203" pcid="4109">
    def test_merge_hash_recursive_and_list_replace(self):
        low = self.merge_hash_data['low_prio']
        high = self.merge_hash_data['high_prio']
        expected = {
            "a": {
                "a'": {
                    "x": "low_value",
                    "y": "high_value",
                    "z": "high_value",
                    "list": ["high_value"]
                }
            },
            "b": high['b']
        }
        self.assertEqual(merge_hash(low, high, True, 'replace'), expected)

</source>
<source file="systems/ansible-2.12.4rc1/test/units/utils/test_vars.py" startline="220" endline="235" pcid="4111">
    def test_merge_hash_recursive_and_list_append(self):
        low = self.merge_hash_data['low_prio']
        high = self.merge_hash_data['high_prio']
        expected = {
            "a": {
                "a'": {
                    "x": "low_value",
                    "y": "high_value",
                    "z": "high_value",
                    "list": ["low_value", "high_value"]
                }
            },
            "b": low['b'] + high['b']
        }
        self.assertEqual(merge_hash(low, high, True, 'append'), expected)

</source>
<source file="systems/ansible-2.12.4rc1/test/units/utils/test_vars.py" startline="236" endline="251" pcid="4112">
    def test_merge_hash_recursive_and_list_prepend(self):
        low = self.merge_hash_data['low_prio']
        high = self.merge_hash_data['high_prio']
        expected = {
            "a": {
                "a'": {
                    "x": "low_value",
                    "y": "high_value",
                    "z": "high_value",
                    "list": ["high_value", "low_value"]
                }
            },
            "b": high['b'] + low['b']
        }
        self.assertEqual(merge_hash(low, high, True, 'prepend'), expected)

</source>
<source file="systems/ansible-2.12.4rc1/test/units/utils/test_vars.py" startline="252" endline="267" pcid="4113">
    def test_merge_hash_recursive_and_list_append_rp(self):
        low = self.merge_hash_data['low_prio']
        high = self.merge_hash_data['high_prio']
        expected = {
            "a": {
                "a'": {
                    "x": "low_value",
                    "y": "high_value",
                    "z": "high_value",
                    "list": ["low_value", "high_value"]
                }
            },
            "b": [1, 1, 2] + high['b']
        }
        self.assertEqual(merge_hash(low, high, True, 'append_rp'), expected)

</source>
<source file="systems/ansible-2.12.4rc1/test/units/utils/test_vars.py" startline="268" endline="282" pcid="4114">
    def test_merge_hash_recursive_and_list_prepend_rp(self):
        low = self.merge_hash_data['low_prio']
        high = self.merge_hash_data['high_prio']
        expected = {
            "a": {
                "a'": {
                    "x": "low_value",
                    "y": "high_value",
                    "z": "high_value",
                    "list": ["high_value", "low_value"]
                }
            },
            "b": high['b'] + [1, 1, 2]
        }
        self.assertEqual(merge_hash(low, high, True, 'prepend_rp'), expected)
</source>
</class>

<class classid="87" nclones="2" nlines="13" similarity="85">
<source file="systems/ansible-2.12.4rc1/test/units/playbook/test_included_file.py" startline="66" endline="79" pcid="4124">
def test_equals_different_tasks():
    parent = MagicMock(name='MockParent')
    parent._uuid = '111-111'
    task_a = MagicMock(name='MockTask')
    task_a._uuid = '11-11'
    task_a._parent = parent
    task_b = MagicMock(name='MockTask')
    task_b._uuid = '22-22'
    task_b._parent = parent
    inc_a = IncludedFile('a.yml', {}, {}, task_a)
    inc_b = IncludedFile('a.yml', {}, {}, task_b)
    assert inc_a != inc_b


</source>
<source file="systems/ansible-2.12.4rc1/test/units/playbook/test_included_file.py" startline="80" endline="95" pcid="4125">
def test_equals_different_parents():
    parent_a = MagicMock(name='MockParent')
    parent_a._uuid = '111-111'
    parent_b = MagicMock(name='MockParent')
    parent_b._uuid = '222-222'
    task_a = MagicMock(name='MockTask')
    task_a._uuid = '11-11'
    task_a._parent = parent_a
    task_b = MagicMock(name='MockTask')
    task_b._uuid = '11-11'
    task_b._parent = parent_b
    inc_a = IncludedFile('a.yml', {}, {}, task_a)
    inc_b = IncludedFile('a.yml', {}, {}, task_b)
    assert inc_a != inc_b


</source>
</class>

<class classid="88" nclones="3" nlines="25" similarity="70">
<source file="systems/ansible-2.12.4rc1/test/units/playbook/test_included_file.py" startline="108" endline="135" pcid="4127">
def test_process_include_results(mock_iterator, mock_variable_manager):
    hostname = "testhost1"
    hostname2 = "testhost2"

    parent_task_ds = {'debug': 'msg=foo'}
    parent_task = Task.load(parent_task_ds)
    parent_task._play = None

    task_ds = {'include': 'include_test.yml'}
    loaded_task = TaskInclude.load(task_ds, task_include=parent_task)

    return_data = {'include': 'include_test.yml'}
    # The task in the TaskResult has to be a TaskInclude so it has a .static attr
    result1 = task_result.TaskResult(host=hostname, task=loaded_task, return_data=return_data)
    result2 = task_result.TaskResult(host=hostname2, task=loaded_task, return_data=return_data)
    results = [result1, result2]

    fake_loader = DictDataLoader({'include_test.yml': ""})

    res = IncludedFile.process_include_results(results, mock_iterator, fake_loader, mock_variable_manager)
    assert isinstance(res, list)
    assert len(res) == 1
    assert res[0]._filename == os.path.join(os.getcwd(), 'include_test.yml')
    assert res[0]._hosts == ['testhost1', 'testhost2']
    assert res[0]._args == {}
    assert res[0]._vars == {}


</source>
<source file="systems/ansible-2.12.4rc1/test/units/playbook/test_included_file.py" startline="178" endline="216" pcid="4129">
def test_process_include_simulate_free(mock_iterator, mock_variable_manager):
    hostname = "testhost1"
    hostname2 = "testhost2"

    parent_task_ds = {'debug': 'msg=foo'}
    parent_task1 = Task.load(parent_task_ds)
    parent_task2 = Task.load(parent_task_ds)

    parent_task1._play = None
    parent_task2._play = None

    task_ds = {'include': 'include_test.yml'}
    loaded_task1 = TaskInclude.load(task_ds, task_include=parent_task1)
    loaded_task2 = TaskInclude.load(task_ds, task_include=parent_task2)

    return_data = {'include': 'include_test.yml'}
    # The task in the TaskResult has to be a TaskInclude so it has a .static attr
    result1 = task_result.TaskResult(host=hostname, task=loaded_task1, return_data=return_data)
    result2 = task_result.TaskResult(host=hostname2, task=loaded_task2, return_data=return_data)
    results = [result1, result2]

    fake_loader = DictDataLoader({'include_test.yml': ""})

    res = IncludedFile.process_include_results(results, mock_iterator, fake_loader, mock_variable_manager)
    assert isinstance(res, list)
    assert len(res) == 2
    assert res[0]._filename == os.path.join(os.getcwd(), 'include_test.yml')
    assert res[1]._filename == os.path.join(os.getcwd(), 'include_test.yml')

    assert res[0]._hosts == ['testhost1']
    assert res[1]._hosts == ['testhost2']

    assert res[0]._args == {}
    assert res[1]._args == {}

    assert res[0]._vars == {}
    assert res[1]._vars == {}


</source>
<source file="systems/ansible-2.12.4rc1/test/units/playbook/test_included_file.py" startline="136" endline="177" pcid="4128">
def test_process_include_diff_files(mock_iterator, mock_variable_manager):
    hostname = "testhost1"
    hostname2 = "testhost2"

    parent_task_ds = {'debug': 'msg=foo'}
    parent_task = Task.load(parent_task_ds)
    parent_task._play = None

    task_ds = {'include': 'include_test.yml'}
    loaded_task = TaskInclude.load(task_ds, task_include=parent_task)
    loaded_task._play = None

    child_task_ds = {'include': 'other_include_test.yml'}
    loaded_child_task = TaskInclude.load(child_task_ds, task_include=loaded_task)
    loaded_child_task._play = None

    return_data = {'include': 'include_test.yml'}
    # The task in the TaskResult has to be a TaskInclude so it has a .static attr
    result1 = task_result.TaskResult(host=hostname, task=loaded_task, return_data=return_data)

    return_data = {'include': 'other_include_test.yml'}
    result2 = task_result.TaskResult(host=hostname2, task=loaded_child_task, return_data=return_data)
    results = [result1, result2]

    fake_loader = DictDataLoader({'include_test.yml': "",
                                  'other_include_test.yml': ""})

    res = IncludedFile.process_include_results(results, mock_iterator, fake_loader, mock_variable_manager)
    assert isinstance(res, list)
    assert res[0]._filename == os.path.join(os.getcwd(), 'include_test.yml')
    assert res[1]._filename == os.path.join(os.getcwd(), 'other_include_test.yml')

    assert res[0]._hosts == ['testhost1']
    assert res[1]._hosts == ['testhost2']

    assert res[0]._args == {}
    assert res[1]._args == {}

    assert res[0]._vars == {}
    assert res[1]._vars == {}


</source>
</class>

<class classid="89" nclones="2" nlines="10" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/units/playbook/test_conditional.py" startline="110" endline="123" pcid="4144">
    def test_dict_undefined_values_bare(self):
        variables = {'dict_value': 1,
                     'some_defined_dict_with_undefined_values': {'key1': 'value1',
                                                                 'key2': '{{ dict_value }}',
                                                                 'key3': '{{ undefined_dict_value }}'
                                                                 }}

        # raises an exception when a non-string conditional is passed to extract_defined_undefined()
        when = [u"some_defined_dict_with_undefined_values"]
        self.assertRaisesRegexp(errors.AnsibleError,
                                "The conditional check 'some_defined_dict_with_undefined_values' failed.",
                                self._eval_con,
                                when, variables)

</source>
<source file="systems/ansible-2.12.4rc1/test/units/playbook/test_conditional.py" startline="124" endline="136" pcid="4145">
    def test_dict_undefined_values_is_defined(self):
        variables = {'dict_value': 1,
                     'some_defined_dict_with_undefined_values': {'key1': 'value1',
                                                                 'key2': '{{ dict_value }}',
                                                                 'key3': '{{ undefined_dict_value }}'
                                                                 }}

        when = [u"some_defined_dict_with_undefined_values is defined"]
        self.assertRaisesRegexp(errors.AnsibleError,
                                "The conditional check 'some_defined_dict_with_undefined_values is defined' failed.",
                                self._eval_con,
                                when, variables)

</source>
</class>

<class classid="90" nclones="2" nlines="14" similarity="71">
<source file="systems/ansible-2.12.4rc1/test/units/playbook/test_conditional.py" startline="173" endline="186" pcid="4152">
    def test_is_hostvars_quotes_is_defined(self):
        variables = {'hostvars': {'some_host': {}},
                     'compare_targets_single': "hostvars['some_host']",
                     'compare_targets_double': 'hostvars["some_host"]',
                     'compare_targets': {'double': '{{ compare_targets_double }}',
                                         'single': "{{ compare_targets_single }}"},
                     }
        when = [u"hostvars['some_host'] is defined",
                u'hostvars["some_host"] is defined',
                u"{{ compare_targets.double }} is defined",
                u"{{ compare_targets.single }} is defined"]
        ret = self._eval_con(when, variables)
        self.assertTrue(ret)

</source>
<source file="systems/ansible-2.12.4rc1/test/units/playbook/test_conditional.py" startline="187" endline="202" pcid="4153">
    def test_is_hostvars_quotes_is_defined_but_is_not_defined(self):
        variables = {'hostvars': {'some_host': {}},
                     'compare_targets_single': "hostvars['some_host']",
                     'compare_targets_double': 'hostvars["some_host"]',
                     'compare_targets': {'double': '{{ compare_targets_double }}',
                                         'single': "{{ compare_targets_single }}"},
                     }
        when = [u"hostvars['some_host'] is defined",
                u'hostvars["some_host"] is defined',
                u"{{ compare_targets.triple }} is defined",
                u"{{ compare_targets.quadruple }} is defined"]
        self.assertRaisesRegexp(errors.AnsibleError,
                                "The conditional check '{{ compare_targets.triple }} is defined' failed",
                                self._eval_con,
                                when, variables)

</source>
</class>

<class classid="91" nclones="4" nlines="11" similarity="76">
<source file="systems/ansible-2.12.4rc1/test/units/playbook/test_play.py" startline="94" endline="106" pcid="4246">
def test_play_with_tasks():
    p = Play.load(dict(
        name="test play",
        hosts=['foo'],
        gather_facts=False,
        tasks=[dict(action='shell echo "hello world"')],
    ))

    assert len(p.tasks) == 1
    assert isinstance(p.tasks[0], Block)
    assert p.tasks[0].has_tasks() is True


</source>
<source file="systems/ansible-2.12.4rc1/test/units/playbook/test_play.py" startline="107" endline="120" pcid="4247">
def test_play_with_handlers():
    p = Play.load(dict(
        name="test play",
        hosts=['foo'],
        gather_facts=False,
        handlers=[dict(action='shell echo "hello world"')],
    ))

    assert len(p.handlers) >= 1
    assert len(p.get_handlers()) >= 1
    assert isinstance(p.handlers[0], Block)
    assert p.handlers[0].has_tasks() is True


</source>
<source file="systems/ansible-2.12.4rc1/test/units/playbook/test_play.py" startline="138" endline="150" pcid="4249">
def test_play_with_post_tasks():
    p = Play.load(dict(
        name="test play",
        hosts=['foo'],
        gather_facts=False,
        post_tasks=[dict(action='shell echo "hello world"')],
    ))

    assert len(p.post_tasks) >= 1
    assert isinstance(p.post_tasks[0], Block)
    assert p.post_tasks[0].has_tasks() is True


</source>
<source file="systems/ansible-2.12.4rc1/test/units/playbook/test_play.py" startline="121" endline="137" pcid="4248">
def test_play_with_pre_tasks():
    p = Play.load(dict(
        name="test play",
        hosts=['foo'],
        gather_facts=False,
        pre_tasks=[dict(action='shell echo "hello world"')],
    ))

    assert len(p.pre_tasks) >= 1
    assert isinstance(p.pre_tasks[0], Block)
    assert p.pre_tasks[0].has_tasks() is True

    assert len(p.get_tasks()) >= 1
    assert isinstance(p.get_tasks()[0][0], Task)
    assert p.get_tasks()[0][0].action == 'shell'


</source>
</class>

<class classid="92" nclones="2" nlines="12" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/units/playbook/test_play_context.py" startline="23" endline="38" pcid="4317">
def parser():
    parser = opt_help.create_base_parser('testparser')

    opt_help.add_runas_options(parser)
    opt_help.add_meta_options(parser)
    opt_help.add_runtask_options(parser)
    opt_help.add_vault_options(parser)
    opt_help.add_async_options(parser)
    opt_help.add_connect_options(parser)
    opt_help.add_subset_options(parser)
    opt_help.add_check_options(parser)
    opt_help.add_inventory_options(parser)

    return parser


</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/become/conftest.py" startline="17" endline="32" pcid="4528">
def parser():
    parser = opt_help.create_base_parser('testparser')

    opt_help.add_runas_options(parser)
    opt_help.add_meta_options(parser)
    opt_help.add_runtask_options(parser)
    opt_help.add_vault_options(parser)
    opt_help.add_async_options(parser)
    opt_help.add_connect_options(parser)
    opt_help.add_subset_options(parser)
    opt_help.add_check_options(parser)
    opt_help.add_inventory_options(parser)

    return parser


</source>
</class>

<class classid="93" nclones="2" nlines="14" similarity="85">
<source file="systems/ansible-2.12.4rc1/test/units/playbook/role/test_include_role.py" startline="119" endline="139" pcid="4324">
    def test_simple(self):

        """Test one-level include with default tasks and variables"""

        play = Play.load(dict(
            name="test play",
            hosts=['foo'],
            gather_facts=False,
            tasks=[
                {'include_role': 'name=l3'}
            ]
        ), loader=self.loader, variable_manager=self.var_manager)

        tasks = play.compile()
        tested = False
        for role, task_vars in self.get_tasks_vars(play, tasks):
            tested = True
            self.assertEqual(task_vars.get('l3_variable'), 'l3-main')
            self.assertEqual(task_vars.get('test_variable'), 'l3-main')
        self.assertTrue(tested)

</source>
<source file="systems/ansible-2.12.4rc1/test/units/playbook/role/test_include_role.py" startline="142" endline="160" pcid="4325">
    def test_simple_alt_files(self):

        """Test one-level include with alternative tasks and variables"""

        play = Play.load(dict(
            name="test play",
            hosts=['foo'],
            gather_facts=False,
            tasks=[{'include_role': 'name=l3 tasks_from=alt defaults_from=alt'}]),
            loader=self.loader, variable_manager=self.var_manager)

        tasks = play.compile()
        tested = False
        for role, task_vars in self.get_tasks_vars(play, tasks):
            tested = True
            self.assertEqual(task_vars.get('l3_variable'), 'l3-alt')
            self.assertEqual(task_vars.get('test_variable'), 'l3-alt')
        self.assertTrue(tested)

</source>
</class>

<class classid="94" nclones="2" nlines="29" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/units/playbook/role/test_include_role.py" startline="163" endline="206" pcid="4326">
    def test_nested(self):

        """
        Test nested includes with default tasks and variables.

        Variables from outer roles should be inherited, but overridden in inner
        roles.
        """

        play = Play.load(dict(
            name="test play",
            hosts=['foo'],
            gather_facts=False,
            tasks=[
                {'include_role': 'name=l1'}
            ]
        ), loader=self.loader, variable_manager=self.var_manager)

        tasks = play.compile()
        expected_roles = ['l1', 'l2', 'l3']
        for role, task_vars in self.get_tasks_vars(play, tasks):
            expected_roles.remove(role)
            # Outer-most role must not have variables from inner roles yet
            if role == 'l1':
                self.assertEqual(task_vars.get('l1_variable'), 'l1-main')
                self.assertEqual(task_vars.get('l2_variable'), None)
                self.assertEqual(task_vars.get('l3_variable'), None)
                self.assertEqual(task_vars.get('test_variable'), 'l1-main')
            # Middle role must have variables from outer role, but not inner
            elif role == 'l2':
                self.assertEqual(task_vars.get('l1_variable'), 'l1-main')
                self.assertEqual(task_vars.get('l2_variable'), 'l2-main')
                self.assertEqual(task_vars.get('l3_variable'), None)
                self.assertEqual(task_vars.get('test_variable'), 'l2-main')
            # Inner role must have variables from both outer roles
            elif role == 'l3':
                self.assertEqual(task_vars.get('l1_variable'), 'l1-main')
                self.assertEqual(task_vars.get('l2_variable'), 'l2-main')
                self.assertEqual(task_vars.get('l3_variable'), 'l3-main')
                self.assertEqual(task_vars.get('test_variable'), 'l3-main')
            else:
                self.fail()
        self.assertFalse(expected_roles)

</source>
<source file="systems/ansible-2.12.4rc1/test/units/playbook/role/test_include_role.py" startline="209" endline="251" pcid="4327">
    def test_nested_alt_files(self):

        """
        Test nested includes with alternative tasks and variables.

        Variables from outer roles should be inherited, but overridden in inner
        roles.
        """

        play = Play.load(dict(
            name="test play",
            hosts=['foo'],
            gather_facts=False,
            tasks=[
                {'include_role': 'name=l1 tasks_from=alt defaults_from=alt'}
            ]
        ), loader=self.loader, variable_manager=self.var_manager)

        tasks = play.compile()
        expected_roles = ['l1', 'l2', 'l3']
        for role, task_vars in self.get_tasks_vars(play, tasks):
            expected_roles.remove(role)
            # Outer-most role must not have variables from inner roles yet
            if role == 'l1':
                self.assertEqual(task_vars.get('l1_variable'), 'l1-alt')
                self.assertEqual(task_vars.get('l2_variable'), None)
                self.assertEqual(task_vars.get('l3_variable'), None)
                self.assertEqual(task_vars.get('test_variable'), 'l1-alt')
            # Middle role must have variables from outer role, but not inner
            elif role == 'l2':
                self.assertEqual(task_vars.get('l1_variable'), 'l1-alt')
                self.assertEqual(task_vars.get('l2_variable'), 'l2-alt')
                self.assertEqual(task_vars.get('l3_variable'), None)
                self.assertEqual(task_vars.get('test_variable'), 'l2-alt')
            # Inner role must have variables from both outer roles
            elif role == 'l3':
                self.assertEqual(task_vars.get('l1_variable'), 'l1-alt')
                self.assertEqual(task_vars.get('l2_variable'), 'l2-alt')
                self.assertEqual(task_vars.get('l3_variable'), 'l3-alt')
                self.assertEqual(task_vars.get('test_variable'), 'l3-alt')
            else:
                self.fail()
        self.assertFalse(expected_roles)
</source>
</class>

<class classid="95" nclones="8" nlines="11" similarity="72">
<source file="systems/ansible-2.12.4rc1/test/units/playbook/role/test_role.py" startline="170" endline="187" pcid="4347">
    def test_load_role_with_tasks(self):

        fake_loader = DictDataLoader({
            "/etc/ansible/roles/foo_tasks/tasks/main.yml": """
            - shell: echo 'hello world'
            """,
        })

        mock_play = MagicMock()
        mock_play.ROLE_CACHE = {}

        i = RoleInclude.load('foo_tasks', play=mock_play, loader=fake_loader)
        r = Role.load(i, play=mock_play)

        self.assertEqual(str(r), 'foo_tasks')
        self.assertEqual(len(r._task_blocks), 1)
        assert isinstance(r._task_blocks[0], Block)

</source>
<source file="systems/ansible-2.12.4rc1/test/units/playbook/role/test_role.py" startline="249" endline="268" pcid="4351">
    def test_load_role_with_vars_dirs(self):

        fake_loader = DictDataLoader({
            "/etc/ansible/roles/foo_vars/defaults/main/foo.yml": """
            foo: bar
            """,
            "/etc/ansible/roles/foo_vars/vars/main/bar.yml": """
            foo: bam
            """,
        })

        mock_play = MagicMock()
        mock_play.ROLE_CACHE = {}

        i = RoleInclude.load('foo_vars', play=mock_play, loader=fake_loader)
        r = Role.load(i, play=mock_play)

        self.assertEqual(r._default_vars, dict(foo='bar'))
        self.assertEqual(r._role_vars, dict(foo='bam'))

</source>
<source file="systems/ansible-2.12.4rc1/test/units/playbook/role/test_role.py" startline="270" endline="289" pcid="4352">
    def test_load_role_with_vars_nested_dirs(self):

        fake_loader = DictDataLoader({
            "/etc/ansible/roles/foo_vars/defaults/main/foo/bar.yml": """
            foo: bar
            """,
            "/etc/ansible/roles/foo_vars/vars/main/bar/foo.yml": """
            foo: bam
            """,
        })

        mock_play = MagicMock()
        mock_play.ROLE_CACHE = {}

        i = RoleInclude.load('foo_vars', play=mock_play, loader=fake_loader)
        r = Role.load(i, play=mock_play)

        self.assertEqual(r._default_vars, dict(foo='bar'))
        self.assertEqual(r._role_vars, dict(foo='bam'))

</source>
<source file="systems/ansible-2.12.4rc1/test/units/playbook/role/test_role.py" startline="228" endline="247" pcid="4350">
    def test_load_role_with_vars(self):

        fake_loader = DictDataLoader({
            "/etc/ansible/roles/foo_vars/defaults/main.yml": """
            foo: bar
            """,
            "/etc/ansible/roles/foo_vars/vars/main.yml": """
            foo: bam
            """,
        })

        mock_play = MagicMock()
        mock_play.ROLE_CACHE = {}

        i = RoleInclude.load('foo_vars', play=mock_play, loader=fake_loader)
        r = Role.load(i, play=mock_play)

        self.assertEqual(r._default_vars, dict(foo='bar'))
        self.assertEqual(r._role_vars, dict(foo='bam'))

</source>
<source file="systems/ansible-2.12.4rc1/test/units/playbook/role/test_role.py" startline="209" endline="226" pcid="4349">
    def test_load_role_with_handlers(self):

        fake_loader = DictDataLoader({
            "/etc/ansible/roles/foo_handlers/handlers/main.yml": """
            - name: test handler
              shell: echo 'hello world'
            """,
        })

        mock_play = MagicMock()
        mock_play.ROLE_CACHE = {}

        i = RoleInclude.load('foo_handlers', play=mock_play, loader=fake_loader)
        r = Role.load(i, play=mock_play)

        self.assertEqual(len(r._handler_blocks), 1)
        assert isinstance(r._handler_blocks[0], Block)

</source>
<source file="systems/ansible-2.12.4rc1/test/units/playbook/role/test_role.py" startline="291" endline="311" pcid="4353">
    def test_load_role_with_vars_nested_dirs_combined(self):

        fake_loader = DictDataLoader({
            "/etc/ansible/roles/foo_vars/defaults/main/foo/bar.yml": """
            foo: bar
            a: 1
            """,
            "/etc/ansible/roles/foo_vars/defaults/main/bar/foo.yml": """
            foo: bam
            b: 2
            """,
        })

        mock_play = MagicMock()
        mock_play.ROLE_CACHE = {}

        i = RoleInclude.load('foo_vars', play=mock_play, loader=fake_loader)
        r = Role.load(i, play=mock_play)

        self.assertEqual(r._default_vars, dict(foo='bar', a=1, b=2))

</source>
<source file="systems/ansible-2.12.4rc1/test/units/playbook/role/test_role.py" startline="313" endline="331" pcid="4354">
    def test_load_role_with_vars_dir_vs_file(self):

        fake_loader = DictDataLoader({
            "/etc/ansible/roles/foo_vars/vars/main/foo.yml": """
            foo: bar
            """,
            "/etc/ansible/roles/foo_vars/vars/main.yml": """
            foo: bam
            """,
        })

        mock_play = MagicMock()
        mock_play.ROLE_CACHE = {}

        i = RoleInclude.load('foo_vars', play=mock_play, loader=fake_loader)
        r = Role.load(i, play=mock_play)

        self.assertEqual(r._role_vars, dict(foo='bam'))

</source>
<source file="systems/ansible-2.12.4rc1/test/units/playbook/role/test_role.py" startline="189" endline="207" pcid="4348">
    def test_load_role_with_tasks_dir_vs_file(self):

        fake_loader = DictDataLoader({
            "/etc/ansible/roles/foo_tasks/tasks/custom_main/foo.yml": """
            - command: bar
            """,
            "/etc/ansible/roles/foo_tasks/tasks/custom_main.yml": """
            - command: baz
            """,
        })

        mock_play = MagicMock()
        mock_play.ROLE_CACHE = {}

        i = RoleInclude.load('foo_tasks', play=mock_play, loader=fake_loader)
        r = Role.load(i, play=mock_play, from_files=dict(tasks='custom_main'))

        self.assertEqual(r._task_blocks[0]._ds[0]['command'], 'baz')

</source>
</class>

<class classid="96" nclones="5" nlines="11" similarity="90">
<source file="systems/ansible-2.12.4rc1/test/units/galaxy/test_role_install.py" startline="77" endline="91" pcid="4412">
def test_role_download_github(mocker, galaxy_server, mock_role_download_api, monkeypatch):
    mock_api = mocker.MagicMock()
    mock_api.side_effect = [
        StringIO(u'{"available_versions":{"v1":"v1/"}}'),
        StringIO(u'{"results":[{"id":"123","github_user":"test_owner","github_repo": "test_role"}]}'),
        StringIO(u'{"results":[{"name": "0.0.1"},{"name": "0.0.2"}]}'),
    ]
    monkeypatch.setattr(api, 'open_url', mock_api)

    role.GalaxyRole(Galaxy(), galaxy_server, 'test_owner.test_role', version="0.0.1").install()

    assert mock_role_download_api.call_count == 1
    assert mock_role_download_api.mock_calls[0][1][0] == 'https://github.com/test_owner/test_role/archive/0.0.1.tar.gz'


</source>
<source file="systems/ansible-2.12.4rc1/test/units/galaxy/test_role_install.py" startline="107" endline="121" pcid="4414">
def test_role_download_github_no_download_url_for_version(mocker, galaxy_server, mock_role_download_api, monkeypatch):
    mock_api = mocker.MagicMock()
    mock_api.side_effect = [
        StringIO(u'{"available_versions":{"v1":"v1/"}}'),
        StringIO(u'{"results":[{"id":"123","github_user":"test_owner","github_repo": "test_role"}]}'),
        StringIO(u'{"results":[{"name": "0.0.1"},{"name": "0.0.2","download_url":"http://localhost:8080/test_owner/test_role/0.0.2.tar.gz"}]}'),
    ]
    monkeypatch.setattr(api, 'open_url', mock_api)

    role.GalaxyRole(Galaxy(), galaxy_server, 'test_owner.test_role', version="0.0.1").install()

    assert mock_role_download_api.call_count == 1
    assert mock_role_download_api.mock_calls[0][1][0] == 'https://github.com/test_owner/test_role/archive/0.0.1.tar.gz'


</source>
<source file="systems/ansible-2.12.4rc1/test/units/galaxy/test_role_install.py" startline="138" endline="151" pcid="4416">
def test_role_download_url_default_version(mocker, galaxy_server, mock_role_download_api, monkeypatch):
    mock_api = mocker.MagicMock()
    mock_api.side_effect = [
        StringIO(u'{"available_versions":{"v1":"v1/"}}'),
        StringIO(u'{"results":[{"id":"123","github_user":"test_owner","github_repo": "test_role"}]}'),
        StringIO(u'{"results":[{"name": "0.0.1","download_url":"http://localhost:8080/test_owner/test_role/0.0.1.tar.gz"},'
                 u'{"name": "0.0.2","download_url":"http://localhost:8080/test_owner/test_role/0.0.2.tar.gz"}]}'),
    ]
    monkeypatch.setattr(api, 'open_url', mock_api)

    role.GalaxyRole(Galaxy(), galaxy_server, 'test_owner.test_role').install()

    assert mock_role_download_api.call_count == 1
    assert mock_role_download_api.mock_calls[0][1][0] == 'http://localhost:8080/test_owner/test_role/0.0.2.tar.gz'
</source>
<source file="systems/ansible-2.12.4rc1/test/units/galaxy/test_role_install.py" startline="92" endline="106" pcid="4413">
def test_role_download_github_default_version(mocker, galaxy_server, mock_role_download_api, monkeypatch):
    mock_api = mocker.MagicMock()
    mock_api.side_effect = [
        StringIO(u'{"available_versions":{"v1":"v1/"}}'),
        StringIO(u'{"results":[{"id":"123","github_user":"test_owner","github_repo": "test_role"}]}'),
        StringIO(u'{"results":[{"name": "0.0.1"},{"name": "0.0.2"}]}'),
    ]
    monkeypatch.setattr(api, 'open_url', mock_api)

    role.GalaxyRole(Galaxy(), galaxy_server, 'test_owner.test_role').install()

    assert mock_role_download_api.call_count == 1
    assert mock_role_download_api.mock_calls[0][1][0] == 'https://github.com/test_owner/test_role/archive/0.0.2.tar.gz'


</source>
<source file="systems/ansible-2.12.4rc1/test/units/galaxy/test_role_install.py" startline="122" endline="137" pcid="4415">
def test_role_download_url(mocker, galaxy_server, mock_role_download_api, monkeypatch):
    mock_api = mocker.MagicMock()
    mock_api.side_effect = [
        StringIO(u'{"available_versions":{"v1":"v1/"}}'),
        StringIO(u'{"results":[{"id":"123","github_user":"test_owner","github_repo": "test_role"}]}'),
        StringIO(u'{"results":[{"name": "0.0.1","download_url":"http://localhost:8080/test_owner/test_role/0.0.1.tar.gz"},'
                 u'{"name": "0.0.2","download_url":"http://localhost:8080/test_owner/test_role/0.0.2.tar.gz"}]}'),
    ]
    monkeypatch.setattr(api, 'open_url', mock_api)

    role.GalaxyRole(Galaxy(), galaxy_server, 'test_owner.test_role', version="0.0.1").install()

    assert mock_role_download_api.call_count == 1
    assert mock_role_download_api.mock_calls[0][1][0] == 'http://localhost:8080/test_owner/test_role/0.0.1.tar.gz'


</source>
</class>

<class classid="97" nclones="3" nlines="16" similarity="72">
<source file="systems/ansible-2.12.4rc1/test/units/galaxy/test_collection.py" startline="221" endline="239" pcid="4430">
def test_validate_certs(global_ignore_certs, monkeypatch):
    cli_args = [
        'ansible-galaxy',
        'collection',
        'install',
        'namespace.collection:1.0.0',
    ]
    if global_ignore_certs:
        cli_args.append('--ignore-certs')

    galaxy_cli = GalaxyCLI(args=cli_args)
    mock_execute_install = MagicMock()
    monkeypatch.setattr(galaxy_cli, '_execute_install_collection', mock_execute_install)
    galaxy_cli.run()

    assert len(galaxy_cli.api_servers) == 1
    assert galaxy_cli.api_servers[0].validate_certs is not global_ignore_certs


</source>
<source file="systems/ansible-2.12.4rc1/test/units/galaxy/test_collection.py" startline="241" endline="261" pcid="4431">
def test_validate_certs_with_server_url(global_ignore_certs, monkeypatch):
    cli_args = [
        'ansible-galaxy',
        'collection',
        'install',
        'namespace.collection:1.0.0',
        '-s',
        'https://galaxy.ansible.com'
    ]
    if global_ignore_certs:
        cli_args.append('--ignore-certs')

    galaxy_cli = GalaxyCLI(args=cli_args)
    mock_execute_install = MagicMock()
    monkeypatch.setattr(galaxy_cli, '_execute_install_collection', mock_execute_install)
    galaxy_cli.run()

    assert len(galaxy_cli.api_servers) == 1
    assert galaxy_cli.api_servers[0].validate_certs is not global_ignore_certs


</source>
<source file="systems/ansible-2.12.4rc1/test/units/galaxy/test_collection.py" startline="263" endline="285" pcid="4432">
def test_validate_certs_with_server_config(global_ignore_certs, server_config, monkeypatch):
    get_plugin_options = MagicMock(side_effect=server_config)
    monkeypatch.setattr(C.config, 'get_plugin_options', get_plugin_options)

    cli_args = [
        'ansible-galaxy',
        'collection',
        'install',
        'namespace.collection:1.0.0',
    ]
    if global_ignore_certs:
        cli_args.append('--ignore-certs')

    galaxy_cli = GalaxyCLI(args=cli_args)
    mock_execute_install = MagicMock()
    monkeypatch.setattr(galaxy_cli, '_execute_install_collection', mock_execute_install)
    galaxy_cli.run()

    assert galaxy_cli.api_servers[0].validate_certs is False
    assert galaxy_cli.api_servers[1].validate_certs is True
    assert galaxy_cli.api_servers[2].validate_certs is not global_ignore_certs


</source>
</class>

<class classid="98" nclones="2" nlines="15" similarity="75">
<source file="systems/ansible-2.12.4rc1/test/units/galaxy/test_collection.py" startline="657" endline="677" pcid="4449">
        linked_file_obj.close()

        assert actual_file == '63444bfc766154e1bc7557ef6280de20d03fcd81'


def test_publish_no_wait(galaxy_server, collection_artifact, monkeypatch):
    mock_display = MagicMock()
    monkeypatch.setattr(Display, 'display', mock_display)

    artifact_path, mock_open = collection_artifact
    fake_import_uri = 'https://galaxy.server.com/api/v2/import/1234'

    mock_publish = MagicMock()
    mock_publish.return_value = fake_import_uri
    monkeypatch.setattr(galaxy_server, 'publish_collection', mock_publish)

    collection.publish_collection(artifact_path, galaxy_server, False, 0)

    assert mock_publish.call_count == 1
    assert mock_publish.mock_calls[0][1][0] == artifact_path

</source>
<source file="systems/ansible-2.12.4rc1/test/units/galaxy/test_collection.py" startline="678" endline="702" pcid="4450">
    assert mock_display.call_count == 1
    assert mock_display.mock_calls[0][1][0] == \
        "Collection has been pushed to the Galaxy server %s %s, not waiting until import has completed due to " \
        "--no-wait being set. Import task results can be found at %s" % (galaxy_server.name, galaxy_server.api_server,
                                                                         fake_import_uri)


def test_publish_with_wait(galaxy_server, collection_artifact, monkeypatch):
    mock_display = MagicMock()
    monkeypatch.setattr(Display, 'display', mock_display)

    artifact_path, mock_open = collection_artifact
    fake_import_uri = 'https://galaxy.server.com/api/v2/import/1234'

    mock_publish = MagicMock()
    mock_publish.return_value = fake_import_uri
    monkeypatch.setattr(galaxy_server, 'publish_collection', mock_publish)

    mock_wait = MagicMock()
    monkeypatch.setattr(galaxy_server, 'wait_import_task', mock_wait)

    collection.publish_collection(artifact_path, galaxy_server, True, 0)

    assert mock_publish.call_count == 1
    assert mock_publish.mock_calls[0][1][0] == artifact_path
</source>
</class>

<class classid="99" nclones="3" nlines="14" similarity="80">
<source file="systems/ansible-2.12.4rc1/test/units/galaxy/test_collection.py" startline="944" endline="965" pcid="4467">
    requirements, search_paths, galaxy_apis, ignore_errors = mock_verify_collections.call_args[0]

    assert [('%s.%s' % (r.namespace, r.name), r.ver, r.src, r.type) for r in requirements] == [('namespace.collection', '1.0.4', None, 'galaxy')]
    for install_path in search_paths:
        assert install_path.endswith('ansible_collections')
    assert galaxy_apis[0].api_server == 'http://galaxy-dev.com'
    assert ignore_errors is True


def test_verify_file_hash_deleted_file(manifest_info):
    data = to_bytes(json.dumps(manifest_info))
    digest = sha256(data).hexdigest()

    namespace = manifest_info['collection_info']['namespace']
    name = manifest_info['collection_info']['name']
    version = manifest_info['collection_info']['version']
    server = 'http://galaxy.ansible.com'

    error_queue = []

    with patch.object(builtins, 'open', mock_open(read_data=data)) as m:
        with patch.object(collection.os.path, 'isfile', MagicMock(return_value=False)) as mock_isfile:
</source>
<source file="systems/ansible-2.12.4rc1/test/units/galaxy/test_collection.py" startline="966" endline="986" pcid="4468">
            collection._verify_file_hash(b'path/', 'file', digest, error_queue)

            assert mock_isfile.called_once

    assert len(error_queue) == 1
    assert error_queue[0].installed is None
    assert error_queue[0].expected == digest


def test_verify_file_hash_matching_hash(manifest_info):

    data = to_bytes(json.dumps(manifest_info))
    digest = sha256(data).hexdigest()

    namespace = manifest_info['collection_info']['namespace']
    name = manifest_info['collection_info']['name']
    version = manifest_info['collection_info']['version']
    server = 'http://galaxy.ansible.com'

    error_queue = []

</source>
<source file="systems/ansible-2.12.4rc1/test/units/galaxy/test_collection.py" startline="987" endline="1010" pcid="4469">
    with patch.object(builtins, 'open', mock_open(read_data=data)) as m:
        with patch.object(collection.os.path, 'isfile', MagicMock(return_value=True)) as mock_isfile:
            collection._verify_file_hash(b'path/', 'file', digest, error_queue)

            assert mock_isfile.called_once

    assert error_queue == []


def test_verify_file_hash_mismatching_hash(manifest_info):

    data = to_bytes(json.dumps(manifest_info))
    digest = sha256(data).hexdigest()
    different_digest = 'not_{0}'.format(digest)

    namespace = manifest_info['collection_info']['namespace']
    name = manifest_info['collection_info']['name']
    version = manifest_info['collection_info']['version']
    server = 'http://galaxy.ansible.com'

    error_queue = []

    with patch.object(builtins, 'open', mock_open(read_data=data)) as m:
        with patch.object(collection.os.path, 'isfile', MagicMock(return_value=True)) as mock_isfile:
</source>
</class>

<class classid="100" nclones="2" nlines="13" similarity="92">
<source file="systems/ansible-2.12.4rc1/test/units/galaxy/test_collection_install.py" startline="183" endline="201" pcid="4486">
def test_concrete_artifact_manager_scm_cmd(url, version, trailing_slash, monkeypatch):
    mock_subprocess_check_call = MagicMock()
    monkeypatch.setattr(collection.concrete_artifact_manager.subprocess, 'check_call', mock_subprocess_check_call)
    mock_mkdtemp = MagicMock(return_value='')
    monkeypatch.setattr(collection.concrete_artifact_manager, 'mkdtemp', mock_mkdtemp)

    collection.concrete_artifact_manager._extract_collection_from_git(url, version, b'path')

    assert mock_subprocess_check_call.call_count == 2

    repo = 'https://github.com/org/repo'
    if trailing_slash:
        repo += '/'
    clone_cmd = ('git', 'clone', repo, '')

    assert mock_subprocess_check_call.call_args_list[0].args[0] == clone_cmd
    assert mock_subprocess_check_call.call_args_list[1].args[0] == ('git', 'checkout', 'commitish')


</source>
<source file="systems/ansible-2.12.4rc1/test/units/galaxy/test_collection_install.py" startline="212" endline="230" pcid="4487">
def test_concrete_artifact_manager_scm_cmd_shallow(url, version, trailing_slash, monkeypatch):
    mock_subprocess_check_call = MagicMock()
    monkeypatch.setattr(collection.concrete_artifact_manager.subprocess, 'check_call', mock_subprocess_check_call)
    mock_mkdtemp = MagicMock(return_value='')
    monkeypatch.setattr(collection.concrete_artifact_manager, 'mkdtemp', mock_mkdtemp)

    collection.concrete_artifact_manager._extract_collection_from_git(url, version, b'path')

    assert mock_subprocess_check_call.call_count == 2

    repo = 'https://github.com/org/repo'
    if trailing_slash:
        repo += '/'
    shallow_clone_cmd = ('git', 'clone', '--depth=1', repo, '')

    assert mock_subprocess_check_call.call_args_list[0].args[0] == shallow_clone_cmd
    assert mock_subprocess_check_call.call_args_list[1].args[0] == ('git', 'checkout', 'HEAD')


</source>
</class>

<class classid="101" nclones="2" nlines="17" similarity="77">
<source file="systems/ansible-2.12.4rc1/test/units/galaxy/test_collection_install.py" startline="364" endline="388" pcid="4495">
def test_build_requirement_from_tar_no_manifest(tmp_path_factory):
    test_dir = to_bytes(tmp_path_factory.mktemp('test- Collections Input'))

    json_data = to_bytes(json.dumps(
        {
            'files': [],
            'format': 1,
        }
    ))

    tar_path = os.path.join(test_dir, b'ansible-collections.tar.gz')
    with tarfile.open(tar_path, 'w:gz') as tfile:
        b_io = BytesIO(json_data)
        tar_info = tarfile.TarInfo('FILES.json')
        tar_info.size = len(json_data)
        tar_info.mode = 0o0644
        tfile.addfile(tarinfo=tar_info, fileobj=b_io)

    concrete_artifact_cm = collection.concrete_artifact_manager.ConcreteArtifactsManager(test_dir, validate_certs=False)

    expected = "Collection at '%s' does not contain the required file MANIFEST.json." % to_native(tar_path)
    with pytest.raises(AnsibleError, match=expected):
        Requirement.from_requirement_dict({'name': to_text(tar_path)}, concrete_artifact_cm)


</source>
<source file="systems/ansible-2.12.4rc1/test/units/galaxy/test_collection_install.py" startline="389" endline="410" pcid="4496">
def test_build_requirement_from_tar_no_files(tmp_path_factory):
    test_dir = to_bytes(tmp_path_factory.mktemp('test- Collections Input'))

    json_data = to_bytes(json.dumps(
        {
            'collection_info': {},
        }
    ))

    tar_path = os.path.join(test_dir, b'ansible-collections.tar.gz')
    with tarfile.open(tar_path, 'w:gz') as tfile:
        b_io = BytesIO(json_data)
        tar_info = tarfile.TarInfo('MANIFEST.json')
        tar_info.size = len(json_data)
        tar_info.mode = 0o0644
        tfile.addfile(tarinfo=tar_info, fileobj=b_io)

    concrete_artifact_cm = collection.concrete_artifact_manager.ConcreteArtifactsManager(test_dir, validate_certs=False)
    with pytest.raises(KeyError, match='namespace'):
        Requirement.from_requirement_dict({'name': to_text(tar_path)}, concrete_artifact_cm)


</source>
</class>

<class classid="102" nclones="2" nlines="20" similarity="85">
<source file="systems/ansible-2.12.4rc1/test/units/galaxy/test_collection_install.py" startline="463" endline="489" pcid="4499">
def test_build_requirement_from_name_with_prerelease(galaxy_server, monkeypatch, tmp_path_factory):
    mock_get_versions = MagicMock()
    mock_get_versions.return_value = ['1.0.1', '2.0.1-beta.1', '2.0.1']
    monkeypatch.setattr(galaxy_server, 'get_collection_versions', mock_get_versions)

    mock_get_info = MagicMock()
    mock_get_info.return_value = api.CollectionVersionMetadata('namespace', 'collection', '2.0.1', None, None, {})
    monkeypatch.setattr(galaxy_server, 'get_collection_version_metadata', mock_get_info)

    test_dir = to_bytes(tmp_path_factory.mktemp('test- Collections Input'))
    concrete_artifact_cm = collection.concrete_artifact_manager.ConcreteArtifactsManager(test_dir, validate_certs=False)

    cli = GalaxyCLI(args=['ansible-galaxy', 'collection', 'install', 'namespace.collection'])
    requirements = cli._require_one_of_collections_requirements(
        ['namespace.collection'], None, artifacts_manager=concrete_artifact_cm
    )['collections']
    actual = collection._resolve_depenency_map(requirements, [galaxy_server], concrete_artifact_cm, None, True, False, False)['namespace.collection']

    assert actual.namespace == u'namespace'
    assert actual.name == u'collection'
    assert actual.src == galaxy_server
    assert actual.ver == u'2.0.1'

    assert mock_get_versions.call_count == 1
    assert mock_get_versions.mock_calls[0][1] == ('namespace', 'collection')


</source>
<source file="systems/ansible-2.12.4rc1/test/units/galaxy/test_collection_install.py" startline="490" endline="517" pcid="4500">
def test_build_requirment_from_name_with_prerelease_explicit(galaxy_server, monkeypatch, tmp_path_factory):
    mock_get_versions = MagicMock()
    mock_get_versions.return_value = ['1.0.1', '2.0.1-beta.1', '2.0.1']
    monkeypatch.setattr(galaxy_server, 'get_collection_versions', mock_get_versions)

    mock_get_info = MagicMock()
    mock_get_info.return_value = api.CollectionVersionMetadata('namespace', 'collection', '2.0.1-beta.1', None, None,
                                                               {})
    monkeypatch.setattr(galaxy_server, 'get_collection_version_metadata', mock_get_info)

    test_dir = to_bytes(tmp_path_factory.mktemp('test- Collections Input'))
    concrete_artifact_cm = collection.concrete_artifact_manager.ConcreteArtifactsManager(test_dir, validate_certs=False)

    cli = GalaxyCLI(args=['ansible-galaxy', 'collection', 'install', 'namespace.collection:2.0.1-beta.1'])
    requirements = cli._require_one_of_collections_requirements(
        ['namespace.collection:2.0.1-beta.1'], None, artifacts_manager=concrete_artifact_cm
    )['collections']
    actual = collection._resolve_depenency_map(requirements, [galaxy_server], concrete_artifact_cm, None, True, False, False)['namespace.collection']

    assert actual.namespace == u'namespace'
    assert actual.name == u'collection'
    assert actual.src == galaxy_server
    assert actual.ver == u'2.0.1-beta.1'

    assert mock_get_info.call_count == 1
    assert mock_get_info.mock_calls[0][1] == ('namespace', 'collection', '2.0.1-beta.1')


</source>
</class>

<class classid="103" nclones="2" nlines="13" similarity="76">
<source file="systems/ansible-2.12.4rc1/test/units/galaxy/test_collection_install.py" startline="556" endline="574" pcid="4502">
def test_build_requirement_from_name_missing(galaxy_server, monkeypatch, tmp_path_factory):
    mock_open = MagicMock()
    mock_open.return_value = []

    monkeypatch.setattr(galaxy_server, 'get_collection_versions', mock_open)

    test_dir = to_bytes(tmp_path_factory.mktemp('test- Collections Input'))
    concrete_artifact_cm = collection.concrete_artifact_manager.ConcreteArtifactsManager(test_dir, validate_certs=False)

    cli = GalaxyCLI(args=['ansible-galaxy', 'collection', 'install', 'namespace.collection:>1.0.1'])
    requirements = cli._require_one_of_collections_requirements(
        ['namespace.collection'], None, artifacts_manager=concrete_artifact_cm
    )['collections']

    expected = "Failed to resolve the requested dependencies map. Could not satisfy the following requirements:\n* namespace.collection:* (direct request)"
    with pytest.raises(AnsibleError, match=re.escape(expected)):
        collection._resolve_depenency_map(requirements, [galaxy_server, galaxy_server], concrete_artifact_cm, None, False, True, False)


</source>
<source file="systems/ansible-2.12.4rc1/test/units/galaxy/test_collection_install.py" startline="575" endline="594" pcid="4503">
def test_build_requirement_from_name_401_unauthorized(galaxy_server, monkeypatch, tmp_path_factory):
    mock_open = MagicMock()
    mock_open.side_effect = api.GalaxyError(urllib_error.HTTPError('https://galaxy.server.com', 401, 'msg', {},
                                                                   StringIO()), "error")

    monkeypatch.setattr(galaxy_server, 'get_collection_versions', mock_open)

    test_dir = to_bytes(tmp_path_factory.mktemp('test- Collections Input'))
    concrete_artifact_cm = collection.concrete_artifact_manager.ConcreteArtifactsManager(test_dir, validate_certs=False)

    cli = GalaxyCLI(args=['ansible-galaxy', 'collection', 'install', 'namespace.collection:>1.0.1'])
    requirements = cli._require_one_of_collections_requirements(
        ['namespace.collection'], None, artifacts_manager=concrete_artifact_cm
    )['collections']

    expected = "error (HTTP Code: 401, Message: msg)"
    with pytest.raises(api.GalaxyError, match=re.escape(expected)):
        collection._resolve_depenency_map(requirements, [galaxy_server, galaxy_server], concrete_artifact_cm, None, False, False, False)


</source>
</class>

<class classid="104" nclones="3" nlines="27" similarity="77">
<source file="systems/ansible-2.12.4rc1/test/units/galaxy/test_collection_install.py" startline="595" endline="630" pcid="4504">
def test_build_requirement_from_name_single_version(galaxy_server, monkeypatch, tmp_path_factory):
    test_dir = to_bytes(tmp_path_factory.mktemp('test- Collections Input'))
    concrete_artifact_cm = collection.concrete_artifact_manager.ConcreteArtifactsManager(test_dir, validate_certs=False)
    multi_api_proxy = collection.galaxy_api_proxy.MultiGalaxyAPIProxy([galaxy_server], concrete_artifact_cm)
    dep_provider = dependency_resolution.providers.CollectionDependencyProvider(apis=multi_api_proxy, concrete_artifacts_manager=concrete_artifact_cm)

    matches = RequirementCandidates()
    mock_find_matches = MagicMock(side_effect=matches.func_wrapper(dep_provider.find_matches), autospec=True)
    monkeypatch.setattr(dependency_resolution.providers.CollectionDependencyProvider, 'find_matches', mock_find_matches)

    mock_get_versions = MagicMock()
    mock_get_versions.return_value = ['2.0.0']
    monkeypatch.setattr(galaxy_server, 'get_collection_versions', mock_get_versions)

    mock_get_info = MagicMock()
    mock_get_info.return_value = api.CollectionVersionMetadata('namespace', 'collection', '2.0.0', None, None,
                                                               {})
    monkeypatch.setattr(galaxy_server, 'get_collection_version_metadata', mock_get_info)

    cli = GalaxyCLI(args=['ansible-galaxy', 'collection', 'install', 'namespace.collection:==2.0.0'])
    requirements = cli._require_one_of_collections_requirements(
        ['namespace.collection:==2.0.0'], None, artifacts_manager=concrete_artifact_cm
    )['collections']

    actual = collection._resolve_depenency_map(requirements, [galaxy_server], concrete_artifact_cm, None, False, True, False)['namespace.collection']

    assert actual.namespace == u'namespace'
    assert actual.name == u'collection'
    assert actual.src == galaxy_server
    assert actual.ver == u'2.0.0'
    assert [c.ver for c in matches.candidates] == [u'2.0.0']

    assert mock_get_info.call_count == 1
    assert mock_get_info.mock_calls[0][1] == ('namespace', 'collection', '2.0.0')


</source>
<source file="systems/ansible-2.12.4rc1/test/units/galaxy/test_collection_install.py" startline="631" endline="669" pcid="4505">
def test_build_requirement_from_name_multiple_versions_one_match(galaxy_server, monkeypatch, tmp_path_factory):
    test_dir = to_bytes(tmp_path_factory.mktemp('test- Collections Input'))
    concrete_artifact_cm = collection.concrete_artifact_manager.ConcreteArtifactsManager(test_dir, validate_certs=False)
    multi_api_proxy = collection.galaxy_api_proxy.MultiGalaxyAPIProxy([galaxy_server], concrete_artifact_cm)
    dep_provider = dependency_resolution.providers.CollectionDependencyProvider(apis=multi_api_proxy, concrete_artifacts_manager=concrete_artifact_cm)

    matches = RequirementCandidates()
    mock_find_matches = MagicMock(side_effect=matches.func_wrapper(dep_provider.find_matches), autospec=True)
    monkeypatch.setattr(dependency_resolution.providers.CollectionDependencyProvider, 'find_matches', mock_find_matches)

    mock_get_versions = MagicMock()
    mock_get_versions.return_value = ['2.0.0', '2.0.1', '2.0.2']
    monkeypatch.setattr(galaxy_server, 'get_collection_versions', mock_get_versions)

    mock_get_info = MagicMock()
    mock_get_info.return_value = api.CollectionVersionMetadata('namespace', 'collection', '2.0.1', None, None,
                                                               {})
    monkeypatch.setattr(galaxy_server, 'get_collection_version_metadata', mock_get_info)

    cli = GalaxyCLI(args=['ansible-galaxy', 'collection', 'install', 'namespace.collection:>=2.0.1,<2.0.2'])
    requirements = cli._require_one_of_collections_requirements(
        ['namespace.collection:>=2.0.1,<2.0.2'], None, artifacts_manager=concrete_artifact_cm
    )['collections']

    actual = collection._resolve_depenency_map(requirements, [galaxy_server], concrete_artifact_cm, None, False, True, False)['namespace.collection']

    assert actual.namespace == u'namespace'
    assert actual.name == u'collection'
    assert actual.src == galaxy_server
    assert actual.ver == u'2.0.1'
    assert [c.ver for c in matches.candidates] == [u'2.0.1']

    assert mock_get_versions.call_count == 1
    assert mock_get_versions.mock_calls[0][1] == ('namespace', 'collection')

    assert mock_get_info.call_count == 1
    assert mock_get_info.mock_calls[0][1] == ('namespace', 'collection', '2.0.1')


</source>
<source file="systems/ansible-2.12.4rc1/test/units/galaxy/test_collection_install.py" startline="670" endline="708" pcid="4506">
def test_build_requirement_from_name_multiple_version_results(galaxy_server, monkeypatch, tmp_path_factory):
    test_dir = to_bytes(tmp_path_factory.mktemp('test- Collections Input'))
    concrete_artifact_cm = collection.concrete_artifact_manager.ConcreteArtifactsManager(test_dir, validate_certs=False)
    multi_api_proxy = collection.galaxy_api_proxy.MultiGalaxyAPIProxy([galaxy_server], concrete_artifact_cm)
    dep_provider = dependency_resolution.providers.CollectionDependencyProvider(apis=multi_api_proxy, concrete_artifacts_manager=concrete_artifact_cm)

    matches = RequirementCandidates()
    mock_find_matches = MagicMock(side_effect=matches.func_wrapper(dep_provider.find_matches), autospec=True)
    monkeypatch.setattr(dependency_resolution.providers.CollectionDependencyProvider, 'find_matches', mock_find_matches)

    mock_get_info = MagicMock()
    mock_get_info.return_value = api.CollectionVersionMetadata('namespace', 'collection', '2.0.5', None, None, {})
    monkeypatch.setattr(galaxy_server, 'get_collection_version_metadata', mock_get_info)

    mock_get_versions = MagicMock()
    mock_get_versions.return_value = ['1.0.1', '1.0.2', '1.0.3']
    monkeypatch.setattr(galaxy_server, 'get_collection_versions', mock_get_versions)

    mock_get_versions.return_value = ['2.0.0', '2.0.1', '2.0.2', '2.0.3', '2.0.4', '2.0.5']
    monkeypatch.setattr(galaxy_server, 'get_collection_versions', mock_get_versions)

    cli = GalaxyCLI(args=['ansible-galaxy', 'collection', 'install', 'namespace.collection:!=2.0.2'])
    requirements = cli._require_one_of_collections_requirements(
        ['namespace.collection:!=2.0.2'], None, artifacts_manager=concrete_artifact_cm
    )['collections']

    actual = collection._resolve_depenency_map(requirements, [galaxy_server], concrete_artifact_cm, None, False, True, False)['namespace.collection']

    assert actual.namespace == u'namespace'
    assert actual.name == u'collection'
    assert actual.src == galaxy_server
    assert actual.ver == u'2.0.5'
    # should be ordered latest to earliest
    assert [c.ver for c in matches.candidates] == [u'2.0.5', u'2.0.4', u'2.0.3', u'2.0.1', u'2.0.0']

    assert mock_get_versions.call_count == 1
    assert mock_get_versions.mock_calls[0][1] == ('namespace', 'collection')


</source>
</class>

<class classid="105" nclones="2" nlines="25" similarity="96">
<source file="systems/ansible-2.12.4rc1/test/units/galaxy/test_collection_install.py" startline="853" endline="887" pcid="4512">


def test_install_collections_from_tar(collection_artifact, monkeypatch):
    collection_path, collection_tar = collection_artifact
    temp_path = os.path.split(collection_tar)[0]
    shutil.rmtree(collection_path)

    mock_display = MagicMock()
    monkeypatch.setattr(Display, 'display', mock_display)

    concrete_artifact_cm = collection.concrete_artifact_manager.ConcreteArtifactsManager(temp_path, validate_certs=False)

    requirements = [Requirement('ansible_namespace.collection', '0.1.0', to_text(collection_tar), 'file')]
    collection.install_collections(requirements, to_text(temp_path), [], False, False, False, False, False, False, concrete_artifact_cm)

    assert os.path.isdir(collection_path)

    actual_files = os.listdir(collection_path)
    actual_files.sort()
    assert actual_files == [b'FILES.json', b'MANIFEST.json', b'README.md', b'docs', b'playbooks', b'plugins', b'roles',
                            b'runme.sh']

    with open(os.path.join(collection_path, b'MANIFEST.json'), 'rb') as manifest_obj:
        actual_manifest = json.loads(to_text(manifest_obj.read()))

    assert actual_manifest['collection_info']['namespace'] == 'ansible_namespace'
    assert actual_manifest['collection_info']['name'] == 'collection'
    assert actual_manifest['collection_info']['version'] == '0.1.0'

    # Filter out the progress cursor display calls.
    display_msgs = [m[1][0] for m in mock_display.mock_calls if 'newline' not in m[2] and len(m[1]) == 1]
    assert len(display_msgs) == 4
    assert display_msgs[0] == "Process install dependency map"
    assert display_msgs[1] == "Starting collection install process"
    assert display_msgs[2] == "Installing 'ansible_namespace.collection:0.1.0' to '%s'" % to_text(collection_path)
</source>
<source file="systems/ansible-2.12.4rc1/test/units/galaxy/test_collection_install.py" startline="943" endline="975" pcid="4515">
    {'ansible_namespace.collection': '>=0.0.1'},
], indirect=True)
def test_install_collection_with_circular_dependency(collection_artifact, monkeypatch):
    collection_path, collection_tar = collection_artifact
    temp_path = os.path.split(collection_tar)[0]
    shutil.rmtree(collection_path)

    mock_display = MagicMock()
    monkeypatch.setattr(Display, 'display', mock_display)

    concrete_artifact_cm = collection.concrete_artifact_manager.ConcreteArtifactsManager(temp_path, validate_certs=False)
    requirements = [Requirement('ansible_namespace.collection', '0.1.0', to_text(collection_tar), 'file')]
    collection.install_collections(requirements, to_text(temp_path), [], False, False, False, False, False, False, concrete_artifact_cm)

    assert os.path.isdir(collection_path)

    actual_files = os.listdir(collection_path)
    actual_files.sort()
    assert actual_files == [b'FILES.json', b'MANIFEST.json', b'README.md', b'docs', b'playbooks', b'plugins', b'roles',
                            b'runme.sh']

    with open(os.path.join(collection_path, b'MANIFEST.json'), 'rb') as manifest_obj:
        actual_manifest = json.loads(to_text(manifest_obj.read()))

    assert actual_manifest['collection_info']['namespace'] == 'ansible_namespace'
    assert actual_manifest['collection_info']['name'] == 'collection'
    assert actual_manifest['collection_info']['version'] == '0.1.0'

    # Filter out the progress cursor display calls.
    display_msgs = [m[1][0] for m in mock_display.mock_calls if 'newline' not in m[2] and len(m[1]) == 1]
    assert len(display_msgs) == 4
    assert display_msgs[0] == "Process install dependency map"
    assert display_msgs[1] == "Starting collection install process"
</source>
</class>

<class classid="106" nclones="2" nlines="10" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/units/plugins/connection/test_connection.py" startline="48" endline="60" pcid="4532">
    def test_subclass_error(self):
        class ConnectionModule1(ConnectionBase):
            pass
        with self.assertRaises(TypeError):
            ConnectionModule1()  # pylint: disable=abstract-class-instantiated

        class ConnectionModule2(ConnectionBase):
            def get(self, key):
                super(ConnectionModule2, self).get(key)

        with self.assertRaises(TypeError):
            ConnectionModule2()  # pylint: disable=abstract-class-instantiated

</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/cache/test_cache.py" startline="205" endline="217" pcid="4834">
    def test_subclass_error(self):
        class CacheModule1(BaseCacheModule):
            pass
        with self.assertRaises(TypeError):
            CacheModule1()  # pylint: disable=abstract-class-instantiated

        class CacheModule2(BaseCacheModule):
            def get(self, key):
                super(CacheModule2, self).get(key)

        with self.assertRaises(TypeError):
            CacheModule2()  # pylint: disable=abstract-class-instantiated

</source>
</class>

<class classid="107" nclones="2" nlines="15" similarity="86">
<source file="systems/ansible-2.12.4rc1/test/units/plugins/connection/test_winrm.py" startline="298" endline="315" pcid="4560">
        assert mock_calls[4][0] == "().wait"

    def test_kinit_with_missing_executable_subprocess(self, monkeypatch):
        expected_err = "[Errno 2] No such file or directory: " \
                       "'/fake/kinit': '/fake/kinit'"
        mock_popen = MagicMock(side_effect=OSError(expected_err))

        monkeypatch.setattr("subprocess.Popen", mock_popen)

        winrm.HAS_PEXPECT = False
        pc = PlayContext()
        new_stdin = StringIO()
        conn = connection_loader.get('winrm', pc, new_stdin)
        options = {"_extras": {}, "ansible_winrm_kinit_cmd": "/fake/kinit"}
        conn.set_options(var_options=options)
        conn._build_winrm_kwargs()

        with pytest.raises(AnsibleConnectionFailure) as err:
</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/connection/test_winrm.py" startline="316" endline="335" pcid="4561">
            conn._kerb_auth("user@domain", "pass")
        assert str(err.value) == "Kerberos auth failure when calling " \
                                 "kinit cmd '/fake/kinit': %s" % expected_err

    def test_kinit_with_missing_executable_pexpect(self, monkeypatch):
        pexpect = pytest.importorskip("pexpect")

        expected_err = "The command was not found or was not " \
                       "executable: /fake/kinit"
        mock_pexpect = \
            MagicMock(side_effect=pexpect.ExceptionPexpect(expected_err))

        monkeypatch.setattr("pexpect.spawn", mock_pexpect)

        winrm.HAS_PEXPECT = True
        pc = PlayContext()
        new_stdin = StringIO()
        conn = connection_loader.get('winrm', pc, new_stdin)
        options = {"_extras": {}, "ansible_winrm_kinit_cmd": "/fake/kinit"}
        conn.set_options(var_options=options)
</source>
</class>

<class classid="108" nclones="4" nlines="17" similarity="70">
<source file="systems/ansible-2.12.4rc1/test/units/plugins/connection/test_winrm.py" startline="336" endline="358" pcid="4562">
        conn._build_winrm_kwargs()

        with pytest.raises(AnsibleConnectionFailure) as err:
            conn._kerb_auth("user@domain", "pass")
        assert str(err.value) == "Kerberos auth failure when calling " \
                                 "kinit cmd '/fake/kinit': %s" % expected_err

    def test_kinit_error_subprocess(self, monkeypatch):
        expected_err = "kinit: krb5_parse_name: " \
                       "Configuration file does not specify default realm"

        def mock_communicate(input=None, timeout=None):
            return b"", to_bytes(expected_err)

        mock_popen = MagicMock()
        mock_popen.return_value.communicate = mock_communicate
        mock_popen.return_value.returncode = 1
        monkeypatch.setattr("subprocess.Popen", mock_popen)

        winrm.HAS_PEXPECT = False
        pc = PlayContext()
        new_stdin = StringIO()
        conn = connection_loader.get('winrm', pc, new_stdin)
</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/connection/test_winrm.py" startline="402" endline="422" pcid="4567">

        winrm.HAS_PEXPECT = False
        pc = PlayContext()
        new_stdin = StringIO()
        conn = connection_loader.get('winrm', pc, new_stdin)
        conn.set_options(var_options={"_extras": {}})
        conn._build_winrm_kwargs()

        with pytest.raises(AnsibleConnectionFailure) as err:
            conn._kerb_auth("username", "password")
        assert str(err.value) == \
            "Kerberos auth failure for principal username with subprocess: " \
            "Error with kinit\n<redacted>"

    def test_kinit_error_pass_in_output_pexpect(self, monkeypatch):
        pytest.importorskip("pexpect")

        mock_pexpect = MagicMock()
        mock_pexpect.return_value.expect = MagicMock()
        mock_pexpect.return_value.read.return_value = \
            b"Error with kinit\npassword\n"
</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/connection/test_winrm.py" startline="359" endline="381" pcid="4564">
        conn.set_options(var_options={"_extras": {}})
        conn._build_winrm_kwargs()

        with pytest.raises(AnsibleConnectionFailure) as err:
            conn._kerb_auth("invaliduser", "pass")

        assert str(err.value) == \
            "Kerberos auth failure for principal invaliduser with " \
            "subprocess: %s" % (expected_err)

    def test_kinit_error_pexpect(self, monkeypatch):
        pytest.importorskip("pexpect")

        expected_err = "Configuration file does not specify default realm"
        mock_pexpect = MagicMock()
        mock_pexpect.return_value.expect = MagicMock(side_effect=OSError)
        mock_pexpect.return_value.read.return_value = to_bytes(expected_err)
        mock_pexpect.return_value.exitstatus = 1

        monkeypatch.setattr("pexpect.spawn", mock_pexpect)

        winrm.HAS_PEXPECT = True
        pc = PlayContext()
</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/connection/test_winrm.py" startline="382" endline="401" pcid="4565">
        new_stdin = StringIO()
        conn = connection_loader.get('winrm', pc, new_stdin)
        conn.set_options(var_options={"_extras": {}})
        conn._build_winrm_kwargs()

        with pytest.raises(AnsibleConnectionFailure) as err:
            conn._kerb_auth("invaliduser", "pass")

        assert str(err.value) == \
            "Kerberos auth failure for principal invaliduser with " \
            "pexpect: %s" % (expected_err)

    def test_kinit_error_pass_in_output_subprocess(self, monkeypatch):
        def mock_communicate(input=None, timeout=None):
            return b"", b"Error with kinit\n" + input

        mock_popen = MagicMock()
        mock_popen.return_value.communicate = mock_communicate
        mock_popen.return_value.returncode = 1
        monkeypatch.setattr("subprocess.Popen", mock_popen)
</source>
</class>

<class classid="109" nclones="2" nlines="39" similarity="87">
<source file="systems/ansible-2.12.4rc1/test/units/plugins/connection/test_ssh.py" startline="235" endline="291" pcid="4578">
    def test_plugins_connection_ssh_put_file(self, mock_ospe, mock_sleep):
        pc = PlayContext()
        new_stdin = StringIO()
        conn = connection_loader.get('ssh', pc, new_stdin)
        conn._build_command = MagicMock()
        conn._bare_run = MagicMock()

        mock_ospe.return_value = True
        conn._build_command.return_value = 'some command to run'
        conn._bare_run.return_value = (0, '', '')
        conn.host = "some_host"

        conn.set_option('reconnection_retries', 9)
        conn.set_option('ssh_transfer_method', None)  # unless set to None scp_if_ssh is ignored

        # Test with SCP_IF_SSH set to smart
        # Test when SFTP works
        conn.set_option('scp_if_ssh', 'smart')
        expected_in_data = b' '.join((b'put', to_bytes(shlex_quote('/path/to/in/file')), to_bytes(shlex_quote('/path/to/dest/file')))) + b'\n'
        conn.put_file('/path/to/in/file', '/path/to/dest/file')
        conn._bare_run.assert_called_with('some command to run', expected_in_data, checkrc=False)

        # Test when SFTP doesn't work but SCP does
        conn._bare_run.side_effect = [(1, 'stdout', 'some errors'), (0, '', '')]
        conn.put_file('/path/to/in/file', '/path/to/dest/file')
        conn._bare_run.assert_called_with('some command to run', None, checkrc=False)
        conn._bare_run.side_effect = None

        # test with SCP_IF_SSH enabled
        conn.set_option('scp_if_ssh', True)
        conn.put_file('/path/to/in/file', '/path/to/dest/file')
        conn._bare_run.assert_called_with('some command to run', None, checkrc=False)

        conn.put_file(u'/path/to/in/file/with/unicode-f', u'/path/to/dest/file/with/unicode-f')
        conn._bare_run.assert_called_with('some command to run', None, checkrc=False)

        # test with SCPP_IF_SSH disabled
        conn.set_option('scp_if_ssh', False)
        expected_in_data = b' '.join((b'put', to_bytes(shlex_quote('/path/to/in/file')), to_bytes(shlex_quote('/path/to/dest/file')))) + b'\n'
        conn.put_file('/path/to/in/file', '/path/to/dest/file')
        conn._bare_run.assert_called_with('some command to run', expected_in_data, checkrc=False)

        expected_in_data = b' '.join((b'put',
                                      to_bytes(shlex_quote('/path/to/in/file/with/unicode-f')),
                                      to_bytes(shlex_quote('/path/to/dest/file/with/unicode-f')))) + b'\n'
        conn.put_file(u'/path/to/in/file/with/unicode-f', u'/path/to/dest/file/with/unicode-f')
        conn._bare_run.assert_called_with('some command to run', expected_in_data, checkrc=False)

        # test that a non-zero rc raises an error
        conn._bare_run.return_value = (1, 'stdout', 'some errors')
        self.assertRaises(AnsibleError, conn.put_file, '/path/to/bad/file', '/remote/path/to/file')

        # test that a not-found path raises an error
        mock_ospe.return_value = False
        conn._bare_run.return_value = (0, 'stdout', '')
        self.assertRaises(AnsibleFileNotFound, conn.put_file, '/path/to/bad/file', '/remote/path/to/file')

</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/connection/test_ssh.py" startline="293" endline="347" pcid="4579">
    def test_plugins_connection_ssh_fetch_file(self, mock_sleep):
        pc = PlayContext()
        new_stdin = StringIO()
        conn = connection_loader.get('ssh', pc, new_stdin)
        conn._build_command = MagicMock()
        conn._bare_run = MagicMock()
        conn._load_name = 'ssh'

        conn._build_command.return_value = 'some command to run'
        conn._bare_run.return_value = (0, '', '')
        conn.host = "some_host"

        conn.set_option('reconnection_retries', 9)
        conn.set_option('ssh_transfer_method', None)  # unless set to None scp_if_ssh is ignored

        # Test with SCP_IF_SSH set to smart
        # Test when SFTP works
        conn.set_option('scp_if_ssh', 'smart')
        expected_in_data = b' '.join((b'get', to_bytes(shlex_quote('/path/to/in/file')), to_bytes(shlex_quote('/path/to/dest/file')))) + b'\n'
        conn.set_options({})
        conn.fetch_file('/path/to/in/file', '/path/to/dest/file')
        conn._bare_run.assert_called_with('some command to run', expected_in_data, checkrc=False)

        # Test when SFTP doesn't work but SCP does
        conn._bare_run.side_effect = [(1, 'stdout', 'some errors'), (0, '', '')]
        conn.fetch_file('/path/to/in/file', '/path/to/dest/file')
        conn._bare_run.assert_called_with('some command to run', None, checkrc=False)

        # test with SCP_IF_SSH enabled
        conn._bare_run.side_effect = None
        conn.set_option('ssh_transfer_method', None)  # unless set to None scp_if_ssh is ignored
        conn.set_option('scp_if_ssh', 'True')
        conn.fetch_file('/path/to/in/file', '/path/to/dest/file')
        conn._bare_run.assert_called_with('some command to run', None, checkrc=False)

        conn.fetch_file(u'/path/to/in/file/with/unicode-f', u'/path/to/dest/file/with/unicode-f')
        conn._bare_run.assert_called_with('some command to run', None, checkrc=False)

        # test with SCP_IF_SSH disabled
        conn.set_option('scp_if_ssh', False)
        expected_in_data = b' '.join((b'get', to_bytes(shlex_quote('/path/to/in/file')), to_bytes(shlex_quote('/path/to/dest/file')))) + b'\n'
        conn.fetch_file('/path/to/in/file', '/path/to/dest/file')
        conn._bare_run.assert_called_with('some command to run', expected_in_data, checkrc=False)

        expected_in_data = b' '.join((b'get',
                                      to_bytes(shlex_quote('/path/to/in/file/with/unicode-f')),
                                      to_bytes(shlex_quote('/path/to/dest/file/with/unicode-f')))) + b'\n'
        conn.fetch_file(u'/path/to/in/file/with/unicode-f', u'/path/to/dest/file/with/unicode-f')
        conn._bare_run.assert_called_with('some command to run', expected_in_data, checkrc=False)

        # test that a non-zero rc raises an error
        conn._bare_run.return_value = (1, 'stdout', 'some errors')
        self.assertRaises(AnsibleError, conn.fetch_file, '/path/to/bad/file', '/remote/path/to/file')


</source>
</class>

<class classid="110" nclones="5" nlines="20" similarity="72">
<source file="systems/ansible-2.12.4rc1/test/units/plugins/connection/test_ssh.py" startline="414" endline="433" pcid="4585">
    def test_no_escalation(self):
        self.mock_popen_res.stdout.read.side_effect = [b"my_stdout\n", b"second_line"]
        self.mock_popen_res.stderr.read.side_effect = [b"my_stderr"]
        self.mock_selector.select.side_effect = [
            [(SelectorKey(self.mock_popen_res.stdout, 1001, [EVENT_READ], None), EVENT_READ)],
            [(SelectorKey(self.mock_popen_res.stdout, 1001, [EVENT_READ], None), EVENT_READ)],
            [(SelectorKey(self.mock_popen_res.stderr, 1002, [EVENT_READ], None), EVENT_READ)],
            []]
        self.mock_selector.get_map.side_effect = lambda: True

        return_code, b_stdout, b_stderr = self.conn._run("ssh", "this is input data")
        assert return_code == 0
        assert b_stdout == b'my_stdout\nsecond_line'
        assert b_stderr == b'my_stderr'
        assert self.mock_selector.register.called is True
        assert self.mock_selector.register.call_count == 2
        assert self.conn._send_initial_data.called is True
        assert self.conn._send_initial_data.call_count == 1
        assert self.conn._send_initial_data.call_args[0][1] == 'this is input data'

</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/connection/test_ssh.py" startline="518" endline="543" pcid="4590">
    def test_pasword_without_data(self):
        # simulate no data input but Popen using new pty's fails
        self.mock_popen.return_value = None
        self.mock_popen.side_effect = [OSError(), self.mock_popen_res]

        # simulate no data input
        self.mock_openpty.return_value = (98, 99)
        self.mock_popen_res.stdout.read.side_effect = [b"some data", b"", b""]
        self.mock_popen_res.stderr.read.side_effect = [b""]
        self.mock_selector.select.side_effect = [
            [(SelectorKey(self.mock_popen_res.stdout, 1001, [EVENT_READ], None), EVENT_READ)],
            [(SelectorKey(self.mock_popen_res.stdout, 1001, [EVENT_READ], None), EVENT_READ)],
            [(SelectorKey(self.mock_popen_res.stderr, 1002, [EVENT_READ], None), EVENT_READ)],
            [(SelectorKey(self.mock_popen_res.stdout, 1001, [EVENT_READ], None), EVENT_READ)],
            []]
        self.mock_selector.get_map.side_effect = lambda: True

        return_code, b_stdout, b_stderr = self.conn._run("ssh", "")
        assert return_code == 0
        assert b_stdout == b'some data'
        assert b_stderr == b''
        assert self.mock_selector.register.called is True
        assert self.mock_selector.register.call_count == 2
        assert self.conn._send_initial_data.called is False


</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/connection/test_ssh.py" startline="464" endline="488" pcid="4588">
    def test_password_with_prompt(self):
        # test with password prompting enabled
        self.pc.password = None
        self.conn.become.prompt = b'Password:'
        self.conn._examine_output.side_effect = self._password_with_prompt_examine_output
        self.mock_popen_res.stdout.read.side_effect = [b"Password:", b"Success", b""]
        self.mock_popen_res.stderr.read.side_effect = [b""]
        self.mock_selector.select.side_effect = [
            [(SelectorKey(self.mock_popen_res.stdout, 1001, [EVENT_READ], None), EVENT_READ)],
            [(SelectorKey(self.mock_popen_res.stdout, 1001, [EVENT_READ], None), EVENT_READ)],
            [(SelectorKey(self.mock_popen_res.stderr, 1002, [EVENT_READ], None), EVENT_READ),
             (SelectorKey(self.mock_popen_res.stdout, 1001, [EVENT_READ], None), EVENT_READ)],
            []]
        self.mock_selector.get_map.side_effect = lambda: True

        return_code, b_stdout, b_stderr = self.conn._run("ssh", "this is input data")
        assert return_code == 0
        assert b_stdout == b''
        assert b_stderr == b''
        assert self.mock_selector.register.called is True
        assert self.mock_selector.register.call_count == 2
        assert self.conn._send_initial_data.called is True
        assert self.conn._send_initial_data.call_count == 1
        assert self.conn._send_initial_data.call_args[0][1] == 'this is input data'

</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/connection/test_ssh.py" startline="434" endline="456" pcid="4586">
    def test_with_password(self):
        # test with a password set to trigger the sshpass write
        self.pc.password = '12345'
        self.mock_popen_res.stdout.read.side_effect = [b"some data", b"", b""]
        self.mock_popen_res.stderr.read.side_effect = [b""]
        self.mock_selector.select.side_effect = [
            [(SelectorKey(self.mock_popen_res.stdout, 1001, [EVENT_READ], None), EVENT_READ)],
            [(SelectorKey(self.mock_popen_res.stdout, 1001, [EVENT_READ], None), EVENT_READ)],
            [(SelectorKey(self.mock_popen_res.stderr, 1002, [EVENT_READ], None), EVENT_READ)],
            [(SelectorKey(self.mock_popen_res.stdout, 1001, [EVENT_READ], None), EVENT_READ)],
            []]
        self.mock_selector.get_map.side_effect = lambda: True

        return_code, b_stdout, b_stderr = self.conn._run(["ssh", "is", "a", "cmd"], "this is more data")
        assert return_code == 0
        assert b_stdout == b'some data'
        assert b_stderr == b''
        assert self.mock_selector.register.called is True
        assert self.mock_selector.register.call_count == 2
        assert self.conn._send_initial_data.called is True
        assert self.conn._send_initial_data.call_count == 1
        assert self.conn._send_initial_data.call_args[0][1] == 'this is more data'

</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/connection/test_ssh.py" startline="489" endline="517" pcid="4589">
    def test_password_with_become(self):
        # test with some become settings
        self.pc.prompt = b'Password:'
        self.conn.become.prompt = b'Password:'
        self.pc.become = True
        self.pc.success_key = 'BECOME-SUCCESS-abcdefg'
        self.conn.become._id = 'abcdefg'
        self.conn._examine_output.side_effect = self._password_with_prompt_examine_output
        self.mock_popen_res.stdout.read.side_effect = [b"Password:", b"BECOME-SUCCESS-abcdefg", b"abc"]
        self.mock_popen_res.stderr.read.side_effect = [b"123"]
        self.mock_selector.select.side_effect = [
            [(SelectorKey(self.mock_popen_res.stdout, 1001, [EVENT_READ], None), EVENT_READ)],
            [(SelectorKey(self.mock_popen_res.stdout, 1001, [EVENT_READ], None), EVENT_READ)],
            [(SelectorKey(self.mock_popen_res.stderr, 1002, [EVENT_READ], None), EVENT_READ)],
            [(SelectorKey(self.mock_popen_res.stdout, 1001, [EVENT_READ], None), EVENT_READ)],
            []]
        self.mock_selector.get_map.side_effect = lambda: True

        return_code, b_stdout, b_stderr = self.conn._run("ssh", "this is input data")
        self.mock_popen_res.stdin.flush.assert_called_once_with()
        assert return_code == 0
        assert b_stdout == b'abc'
        assert b_stderr == b'123'
        assert self.mock_selector.register.called is True
        assert self.mock_selector.register.call_count == 2
        assert self.conn._send_initial_data.called is True
        assert self.conn._send_initial_data.call_count == 1
        assert self.conn._send_initial_data.call_args[0][1] == 'this is input data'

</source>
</class>

<class classid="111" nclones="3" nlines="23" similarity="91">
<source file="systems/ansible-2.12.4rc1/test/units/plugins/connection/test_ssh.py" startline="571" endline="599" pcid="4592">
    def test_retry_then_success(self, monkeypatch):
        self.conn.set_option('host_key_checking', False)
        self.conn.set_option('reconnection_retries', 3)

        monkeypatch.setattr('time.sleep', lambda x: None)

        self.mock_popen_res.stdout.read.side_effect = [b"", b"my_stdout\n", b"second_line"]
        self.mock_popen_res.stderr.read.side_effect = [b"", b"my_stderr"]
        type(self.mock_popen_res).returncode = PropertyMock(side_effect=[255] * 3 + [0] * 4)

        self.mock_selector.select.side_effect = [
            [(SelectorKey(self.mock_popen_res.stdout, 1001, [EVENT_READ], None), EVENT_READ)],
            [(SelectorKey(self.mock_popen_res.stderr, 1002, [EVENT_READ], None), EVENT_READ)],
            [],
            [(SelectorKey(self.mock_popen_res.stdout, 1001, [EVENT_READ], None), EVENT_READ)],
            [(SelectorKey(self.mock_popen_res.stdout, 1001, [EVENT_READ], None), EVENT_READ)],
            [(SelectorKey(self.mock_popen_res.stderr, 1002, [EVENT_READ], None), EVENT_READ)],
            []
        ]
        self.mock_selector.get_map.side_effect = lambda: True

        self.conn._build_command = MagicMock()
        self.conn._build_command.return_value = 'ssh'

        return_code, b_stdout, b_stderr = self.conn.exec_command('ssh', 'some data')
        assert return_code == 0
        assert b_stdout == b'my_stdout\nsecond_line'
        assert b_stderr == b'my_stderr'

</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/connection/test_ssh.py" startline="667" endline="696" pcid="4596">
    def test_fetch_file_retries(self, monkeypatch):
        self.conn.set_option('host_key_checking', False)
        self.conn.set_option('reconnection_retries', 3)

        monkeypatch.setattr('time.sleep', lambda x: None)
        monkeypatch.setattr('ansible.plugins.connection.ssh.os.path.exists', lambda x: True)

        self.mock_popen_res.stdout.read.side_effect = [b"", b"my_stdout\n", b"second_line"]
        self.mock_popen_res.stderr.read.side_effect = [b"", b"my_stderr"]
        type(self.mock_popen_res).returncode = PropertyMock(side_effect=[255] * 4 + [0] * 4)

        self.mock_selector.select.side_effect = [
            [(SelectorKey(self.mock_popen_res.stdout, 1001, [EVENT_READ], None), EVENT_READ)],
            [(SelectorKey(self.mock_popen_res.stderr, 1002, [EVENT_READ], None), EVENT_READ)],
            [],
            [(SelectorKey(self.mock_popen_res.stdout, 1001, [EVENT_READ], None), EVENT_READ)],
            [(SelectorKey(self.mock_popen_res.stdout, 1001, [EVENT_READ], None), EVENT_READ)],
            [(SelectorKey(self.mock_popen_res.stderr, 1002, [EVENT_READ], None), EVENT_READ)],
            []
        ]
        self.mock_selector.get_map.side_effect = lambda: True

        self.conn._build_command = MagicMock()
        self.conn._build_command.return_value = 'sftp'

        return_code, b_stdout, b_stderr = self.conn.fetch_file('/path/to/in/file', '/path/to/dest/file')
        assert return_code == 0
        assert b_stdout == b"my_stdout\nsecond_line"
        assert b_stderr == b"my_stderr"
        assert self.mock_popen.call_count == 2
</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/connection/test_ssh.py" startline="636" endline="666" pcid="4595">
    def test_put_file_retries(self, monkeypatch):
        self.conn.set_option('host_key_checking', False)
        self.conn.set_option('reconnection_retries', 3)

        monkeypatch.setattr('time.sleep', lambda x: None)
        monkeypatch.setattr('ansible.plugins.connection.ssh.os.path.exists', lambda x: True)

        self.mock_popen_res.stdout.read.side_effect = [b"", b"my_stdout\n", b"second_line"]
        self.mock_popen_res.stderr.read.side_effect = [b"", b"my_stderr"]
        type(self.mock_popen_res).returncode = PropertyMock(side_effect=[255] * 4 + [0] * 4)

        self.mock_selector.select.side_effect = [
            [(SelectorKey(self.mock_popen_res.stdout, 1001, [EVENT_READ], None), EVENT_READ)],
            [(SelectorKey(self.mock_popen_res.stderr, 1002, [EVENT_READ], None), EVENT_READ)],
            [],
            [(SelectorKey(self.mock_popen_res.stdout, 1001, [EVENT_READ], None), EVENT_READ)],
            [(SelectorKey(self.mock_popen_res.stdout, 1001, [EVENT_READ], None), EVENT_READ)],
            [(SelectorKey(self.mock_popen_res.stderr, 1002, [EVENT_READ], None), EVENT_READ)],
            []
        ]
        self.mock_selector.get_map.side_effect = lambda: True

        self.conn._build_command = MagicMock()
        self.conn._build_command.return_value = 'sftp'

        return_code, b_stdout, b_stderr = self.conn.put_file('/path/to/in/file', '/path/to/dest/file')
        assert return_code == 0
        assert b_stdout == b"my_stdout\nsecond_line"
        assert b_stderr == b"my_stderr"
        assert self.mock_popen.call_count == 2

</source>
</class>

<class classid="112" nclones="2" nlines="12" similarity="91">
<source file="systems/ansible-2.12.4rc1/test/units/plugins/callback/test_callback.py" startline="91" endline="106" pcid="4604">
    def test_clean_results_debug_task(self):
        cb = CallbackBase()
        result = {'item': 'some_item',
                  'invocation': 'foo --bar whatever [some_json]',
                  'a': 'a single a in result note letter a is in invocation',
                  'b': 'a single b in result note letter b is not in invocation',
                  'changed': True}

        cb._clean_results(result, 'debug')

        # See https://github.com/ansible/ansible/issues/33723
        self.assertTrue('a' in result)
        self.assertTrue('b' in result)
        self.assertFalse('invocation' in result)
        self.assertFalse('changed' in result)

</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/callback/test_callback.py" startline="107" endline="119" pcid="4605">
    def test_clean_results_debug_task_no_invocation(self):
        cb = CallbackBase()
        result = {'item': 'some_item',
                  'a': 'a single a in result note letter a is in invocation',
                  'b': 'a single b in result note letter b is not in invocation',
                  'changed': True}

        cb._clean_results(result, 'debug')
        self.assertTrue('a' in result)
        self.assertTrue('b' in result)
        self.assertFalse('changed' in result)
        self.assertFalse('invocation' in result)

</source>
</class>

<class classid="113" nclones="2" nlines="16" similarity="75">
<source file="systems/ansible-2.12.4rc1/test/units/plugins/action/test_action.py" startline="234" endline="258" pcid="4710">
    def test_action_base__early_needs_tmp_path(self):
        # create our fake task
        mock_task = MagicMock()

        # create a mock connection, so we don't actually try and connect to things
        mock_connection = MagicMock()

        # we're using a real play context here
        play_context = PlayContext()

        # our test class
        action_base = DerivedActionBase(
            task=mock_task,
            connection=mock_connection,
            play_context=play_context,
            loader=None,
            templar=None,
            shared_loader_obj=None,
        )

        self.assertFalse(action_base._early_needs_tmp_path())

        action_base.TRANSFERS_FILES = True
        self.assertTrue(action_base._early_needs_tmp_path())

</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/action/test_action.py" startline="539" endline="565" pcid="4721">
    def test_action_base__remove_tmp_path(self):
        # create our fake task
        mock_task = MagicMock()

        # create a mock connection, so we don't actually try and connect to things
        mock_connection = MagicMock()
        mock_connection._shell.remove.return_value = 'rm some stuff'

        # we're using a real play context here
        play_context = PlayContext()

        # our test class
        action_base = DerivedActionBase(
            task=mock_task,
            connection=mock_connection,
            play_context=play_context,
            loader=None,
            templar=None,
            shared_loader_obj=None,
        )

        action_base._low_level_execute_command = MagicMock()
        # these don't really return anything or raise errors, so
        # we're pretty much calling these for coverage right now
        action_base._remove_tmp_path('/bad/path/dont/remove')
        action_base._remove_tmp_path('/good/path/to/ansible-tmp-thing')

</source>
</class>

<class classid="114" nclones="4" nlines="13" similarity="76">
<source file="systems/ansible-2.12.4rc1/test/units/plugins/action/test_action.py" startline="841" endline="854" pcid="4731">
    def test_fail_no_json(self):
        action_base = _action_base()
        rc = 0
        stdout = 'foo\nbar\n'
        err = 'oopsy'
        returned_data = {'rc': rc,
                         'stdout': stdout,
                         'stdout_lines': stdout.splitlines(),
                         'stderr': err}
        res = action_base._parse_returned_data(returned_data)
        self.assertFalse(res['_ansible_parsed'])
        self.assertTrue(res['failed'])
        self.assertEqual(res['module_stderr'], err)

</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/action/test_action.py" startline="885" endline="903" pcid="4734">
    def test_json_facts_add_host(self):
        action_base = _action_base()
        rc = 0
        stdout = '''{"ansible_facts": {"foo": "bar", "ansible_blip": "blip_value"},
        "add_host": {"host_vars": {"some_key": ["whatever the add_host object is"]}
        }
        }\n'''
        err = ''

        returned_data = {'rc': rc,
                         'stdout': stdout,
                         'stdout_lines': stdout.splitlines(),
                         'stderr': err}
        res = action_base._parse_returned_data(returned_data)
        self.assertTrue(res['ansible_facts'])
        self.assertIn('ansible_blip', res['ansible_facts'])
        self.assertIn('add_host', res)
        # TODO: Should this be an AnsibleUnsafe?
        # self.assertIsInstance(res['ansible_facts'], AnsibleUnsafe)
</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/action/test_action.py" startline="855" endline="868" pcid="4732">
    def test_json_empty(self):
        action_base = _action_base()
        rc = 0
        stdout = '{}\n'
        err = ''
        returned_data = {'rc': rc,
                         'stdout': stdout,
                         'stdout_lines': stdout.splitlines(),
                         'stderr': err}
        res = action_base._parse_returned_data(returned_data)
        del res['_ansible_parsed']  # we always have _ansible_parsed
        self.assertEqual(len(res), 0)
        self.assertFalse(res)

</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/action/test_action.py" startline="869" endline="884" pcid="4733">
    def test_json_facts(self):
        action_base = _action_base()
        rc = 0
        stdout = '{"ansible_facts": {"foo": "bar", "ansible_blip": "blip_value"}}\n'
        err = ''

        returned_data = {'rc': rc,
                         'stdout': stdout,
                         'stdout_lines': stdout.splitlines(),
                         'stderr': err}
        res = action_base._parse_returned_data(returned_data)
        self.assertTrue(res['ansible_facts'])
        self.assertIn('ansible_blip', res['ansible_facts'])
        # TODO: Should this be an AnsibleUnsafe?
        # self.assertIsInstance(res['ansible_facts'], AnsibleUnsafe)

</source>
</class>

<class classid="115" nclones="2" nlines="16" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/units/plugins/action/test_gather_facts.py" startline="49" endline="73" pcid="4737">
    def test_network_gather_facts_smart_facts_module(self, mock_collection_metadata):
        self.fqcn_task_vars = {'ansible_network_os': 'ios'}
        self.task.action = 'gather_facts'
        self.task.async_val = False
        self.task.args = {}

        plugin = GatherFactsAction(self.task, self.connection, self.play_context, loader=None, templar=self.templar, shared_loader_obj=None)
        get_module_args = MagicMock()
        plugin._get_module_args = get_module_args
        plugin._execute_module = MagicMock()

        res = plugin.run(task_vars=self.fqcn_task_vars)

        # assert the gather_facts config is 'smart'
        facts_modules = C.config.get_config_value('FACTS_MODULES', variables=self.fqcn_task_vars)
        self.assertEqual(facts_modules, ['smart'])

        # assert the correct module was found
        self.assertEqual(get_module_args.call_count, 1)

        self.assertEqual(
            get_module_args.call_args.args,
            ('ansible.legacy.ios_facts', {'ansible_network_os': 'ios'},)
        )

</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/action/test_gather_facts.py" startline="75" endline="98" pcid="4738">
    def test_network_gather_facts_smart_facts_module_fqcn(self, mock_collection_metadata):
        self.fqcn_task_vars = {'ansible_network_os': 'cisco.ios.ios'}
        self.task.action = 'gather_facts'
        self.task.async_val = False
        self.task.args = {}

        plugin = GatherFactsAction(self.task, self.connection, self.play_context, loader=None, templar=self.templar, shared_loader_obj=None)
        get_module_args = MagicMock()
        plugin._get_module_args = get_module_args
        plugin._execute_module = MagicMock()

        res = plugin.run(task_vars=self.fqcn_task_vars)

        # assert the gather_facts config is 'smart'
        facts_modules = C.config.get_config_value('FACTS_MODULES', variables=self.fqcn_task_vars)
        self.assertEqual(facts_modules, ['smart'])

        # assert the correct module was found
        self.assertEqual(get_module_args.call_count, 1)

        self.assertEqual(
            get_module_args.call_args.args,
            ('cisco.ios.ios_facts', {'ansible_network_os': 'cisco.ios.ios'},)
        )
</source>
</class>

<class classid="116" nclones="3" nlines="11" similarity="72">
<source file="systems/ansible-2.12.4rc1/test/units/plugins/action/test_raw.py" startline="47" endline="62" pcid="4741">
    def test_raw_executable_is_not_empty_string(self):

        task = MagicMock(Task)
        task.async_val = False

        task.args = {'_raw_params': 'Args1'}
        self.play_context.check_mode = False

        self.mock_am = ActionModule(task, self.connection, self.play_context, loader=None, templar=None, shared_loader_obj=None)
        self.mock_am._low_level_execute_command = Mock(return_value={})
        self.mock_am.display = Mock()
        self.mock_am._admin_users = ['root', 'toor']

        self.mock_am.run()
        self.mock_am._low_level_execute_command.assert_called_with('Args1', executable=False)

</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/action/test_raw.py" startline="91" endline="105" pcid="4744">
    def test_raw_task_vars_is_not_None(self):

        task = MagicMock(Task)
        task.async_val = False

        task.args = {'_raw_params': 'Args1'}
        task.environment = None
        self.play_context.check_mode = False

        self.mock_am = ActionModule(task, self.connection, self.play_context, loader=None, templar=None, shared_loader_obj=None)
        self.mock_am._low_level_execute_command = Mock(return_value={})
        self.mock_am.display = Mock()

        self.mock_am.run(task_vars={'a': 'b'})
        self.assertEqual(task.environment, None)
</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/action/test_raw.py" startline="76" endline="90" pcid="4743">
    def test_raw_test_environment_is_None(self):

        task = MagicMock(Task)
        task.async_val = False

        task.args = {'_raw_params': 'Args1'}
        task.environment = None
        self.play_context.check_mode = False

        self.mock_am = ActionModule(task, self.connection, self.play_context, loader=None, templar=None, shared_loader_obj=None)
        self.mock_am._low_level_execute_command = Mock(return_value={})
        self.mock_am.display = Mock()

        self.assertEqual(task.environment, None)

</source>
</class>

<class classid="117" nclones="3" nlines="16" similarity="75">
<source file="systems/ansible-2.12.4rc1/test/units/plugins/action/test_pause.py" startline="22" endline="44" pcid="4745">
def test_pause_curses_tigetstr_none(mocker, monkeypatch):
    monkeypatch.delitem(sys.modules, 'ansible.plugins.action.pause')

    dunder_import = __import__

    def _import(*args, **kwargs):
        if args[0] == 'curses':
            mock_curses = mocker.Mock()
            mock_curses.setupterm = mocker.Mock(return_value=True)
            mock_curses.tigetstr = mocker.Mock(return_value=None)
            return mock_curses
        else:
            return dunder_import(*args, **kwargs)

    mocker.patch(builtin_import, _import)

    mod = importlib.import_module('ansible.plugins.action.pause')

    assert mod.HAS_CURSES is True
    assert mod.MOVE_TO_BOL == b'\r'
    assert mod.CLEAR_TO_EOL == b'\x1b[K'


</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/action/test_pause.py" startline="69" endline="89" pcid="4749">
def test_pause_curses_setupterm_error(mocker, monkeypatch, exc):
    monkeypatch.delitem(sys.modules, 'ansible.plugins.action.pause')

    dunder_import = __import__

    def _import(*args, **kwargs):
        if args[0] == 'curses':
            mock_curses = mocker.Mock()
            mock_curses.setupterm = mocker.Mock(side_effect=exc)
            mock_curses.error = curses.error
            return mock_curses
        else:
            return dunder_import(*args, **kwargs)

    mocker.patch(builtin_import, _import)

    mod = importlib.import_module('ansible.plugins.action.pause')

    assert mod.HAS_CURSES is False
    assert mod.MOVE_TO_BOL == b'\r'
    assert mod.CLEAR_TO_EOL == b'\x1b[K'
</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/action/test_pause.py" startline="45" endline="67" pcid="4747">
def test_pause_missing_curses(mocker, monkeypatch):
    monkeypatch.delitem(sys.modules, 'ansible.plugins.action.pause')

    dunder_import = __import__

    def _import(*args, **kwargs):
        if args[0] == 'curses':
            raise ImportError
        else:
            return dunder_import(*args, **kwargs)

    mocker.patch(builtin_import, _import)

    mod = importlib.import_module('ansible.plugins.action.pause')

    with pytest.raises(AttributeError):
        mod.curses

    assert mod.HAS_CURSES is False
    assert mod.MOVE_TO_BOL == b'\r'
    assert mod.CLEAR_TO_EOL == b'\x1b[K'


</source>
</class>

<class classid="118" nclones="11" nlines="13" similarity="71">
<source file="systems/ansible-2.12.4rc1/test/units/plugins/inventory/test_constructed.py" startline="40" endline="58" pcid="4769">
def test_group_by_value_only(inventory_module):
    inventory_module.inventory.add_host('foohost')
    inventory_module.inventory.set_variable('foohost', 'bar', 'my_group_name')
    host = inventory_module.inventory.get_host('foohost')
    keyed_groups = [
        {
            'prefix': '',
            'separator': '',
            'key': 'bar'
        }
    ]
    inventory_module._add_host_to_keyed_groups(
        keyed_groups, host.vars, host.name, strict=False
    )
    assert 'my_group_name' in inventory_module.inventory.groups
    group = inventory_module.inventory.groups['my_group_name']
    assert group.hosts == [host]


</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/inventory/test_constructed.py" startline="284" endline="301" pcid="4780">
def test_keyed_group_str_with_default_value(inventory_module):
    inventory_module.inventory.add_host('server0')
    inventory_module.inventory.set_variable('server0', 'tags', '')
    host = inventory_module.inventory.get_host('server0')
    keyed_groups = [
        {
            'prefix': 'tag',
            'separator': '_',
            'key': 'tags',
            'default_value': 'running'
        }
    ]
    inventory_module._add_host_to_keyed_groups(
        keyed_groups, host.vars, host.name, strict=False
    )
    assert "tag_running" in inventory_module.inventory.groups


</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/inventory/test_constructed.py" startline="100" endline="119" pcid="4772">
def test_keyed_group_host_confusion(inventory_module):
    inventory_module.inventory.add_host('cow')
    inventory_module.inventory.add_group('cow')
    host = inventory_module.inventory.get_host('cow')
    host.vars['species'] = 'cow'
    keyed_groups = [
        {
            'separator': '',
            'prefix': '',
            'key': 'species'
        }
    ]
    inventory_module._add_host_to_keyed_groups(
        keyed_groups, host.vars, host.name, strict=True
    )
    group = inventory_module.inventory.groups['cow']
    # group cow has host of cow
    assert group.hosts == [host]


</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/inventory/test_constructed.py" startline="266" endline="283" pcid="4779">
def test_keyed_group_str_no_default_value(inventory_module):
    inventory_module.inventory.add_host('server0')
    inventory_module.inventory.set_variable('server0', 'tags', '')
    host = inventory_module.inventory.get_host('server0')
    keyed_groups = [
        {
            'prefix': 'tag',
            'separator': '_',
            'key': 'tags'
        }
    ]
    inventory_module._add_host_to_keyed_groups(
        keyed_groups, host.vars, host.name, strict=False
    )
    # when the value is an empty string. this group is not generated
    assert "tag_" not in inventory_module.inventory.groups


</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/inventory/test_constructed.py" startline="229" endline="246" pcid="4777">
def test_keyed_group_empty_value(inventory_module):
    inventory_module.inventory.add_host('server0')
    inventory_module.inventory.set_variable('server0', 'tags', {'environment': 'prod', 'status': ''})
    host = inventory_module.inventory.get_host('server0')
    keyed_groups = [
        {
            'prefix': 'tag',
            'separator': '_',
            'key': 'tags'
        }
    ]
    inventory_module._add_host_to_keyed_groups(
        keyed_groups, host.vars, host.name, strict=False
    )
    for group_name in ('tag_environment_prod', 'tag_status_'):
        assert group_name in inventory_module.inventory.groups


</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/inventory/test_constructed.py" startline="210" endline="228" pcid="4776">
def test_keyed_group_exclusive_argument(inventory_module):
    inventory_module.inventory.add_host('cow')
    inventory_module.inventory.set_variable('cow', 'nickname', 'betsy')
    host = inventory_module.inventory.get_host('cow')
    keyed_groups = [
        {
            'key': 'tag',
            'separator': '_',
            'default_value': 'default_value_name',
            'trailing_separator': True
        }
    ]
    with pytest.raises(AnsibleParserError) as err_message:
        inventory_module._add_host_to_keyed_groups(
            keyed_groups, host.vars, host.name, strict=True
        )
        assert 'parameters are mutually exclusive' in err_message


</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/inventory/test_constructed.py" startline="247" endline="265" pcid="4778">
def test_keyed_group_dict_with_default_value(inventory_module):
    inventory_module.inventory.add_host('server0')
    inventory_module.inventory.set_variable('server0', 'tags', {'environment': 'prod', 'status': ''})
    host = inventory_module.inventory.get_host('server0')
    keyed_groups = [
        {
            'prefix': 'tag',
            'separator': '_',
            'key': 'tags',
            'default_value': 'running'
        }
    ]
    inventory_module._add_host_to_keyed_groups(
        keyed_groups, host.vars, host.name, strict=False
    )
    for group_name in ('tag_environment_prod', 'tag_status_running'):
        assert group_name in inventory_module.inventory.groups


</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/inventory/test_constructed.py" startline="302" endline="320" pcid="4781">
def test_keyed_group_list_with_default_value(inventory_module):
    inventory_module.inventory.add_host('server0')
    inventory_module.inventory.set_variable('server0', 'tags', ['test', ''])
    host = inventory_module.inventory.get_host('server0')
    keyed_groups = [
        {
            'prefix': 'tag',
            'separator': '_',
            'key': 'tags',
            'default_value': 'prod'
        }
    ]
    inventory_module._add_host_to_keyed_groups(
        keyed_groups, host.vars, host.name, strict=False
    )
    for group_name in ('tag_test', 'tag_prod'):
        assert group_name in inventory_module.inventory.groups


</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/inventory/test_constructed.py" startline="321" endline="337" pcid="4782">
def test_keyed_group_with_trailing_separator(inventory_module):
    inventory_module.inventory.add_host('server0')
    inventory_module.inventory.set_variable('server0', 'tags', {'environment': 'prod', 'status': ''})
    host = inventory_module.inventory.get_host('server0')
    keyed_groups = [
        {
            'prefix': 'tag',
            'separator': '_',
            'key': 'tags',
            'trailing_separator': False
        }
    ]
    inventory_module._add_host_to_keyed_groups(
        keyed_groups, host.vars, host.name, strict=False
    )
    for group_name in ('tag_environment_prod', 'tag_status'):
        assert group_name in inventory_module.inventory.groups
</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/inventory/test_constructed.py" startline="186" endline="209" pcid="4775">
def test_parent_group_templating_error(inventory_module):
    inventory_module.inventory.add_host('cow')
    inventory_module.inventory.set_variable('cow', 'nickname', 'betsy')
    host = inventory_module.inventory.get_host('cow')
    keyed_groups = [
        {
            'key': 'nickname',
            'separator': '',
            'parent_group': '{{ location.barn-yard }}'
        }
    ]
    with pytest.raises(AnsibleParserError) as err_message:
        inventory_module._add_host_to_keyed_groups(
            keyed_groups, host.vars, host.name, strict=True
        )
        assert 'Could not generate parent group' in err_message
    # invalid parent group did not raise an exception with strict=False
    inventory_module._add_host_to_keyed_groups(
        keyed_groups, host.vars, host.name, strict=False
    )
    # assert group was never added with invalid parent
    assert 'betsy' not in inventory_module.inventory.groups


</source>
<source file="systems/ansible-2.12.4rc1/test/units/plugins/inventory/test_constructed.py" startline="84" endline="99" pcid="4771">
def test_keyed_group_empty_construction(inventory_module):
    inventory_module.inventory.add_host('farm')
    inventory_module.inventory.set_variable('farm', 'barn', {})
    host = inventory_module.inventory.get_host('farm')
    keyed_groups = [
        {
            'separator': 'mmmmmmmmmm',
            'key': 'barn'
        }
    ]
    inventory_module._add_host_to_keyed_groups(
        keyed_groups, host.vars, host.name, strict=True
    )
    assert host.groups == []


</source>
</class>

<class classid="119" nclones="4" nlines="14" similarity="78">
<source file="systems/ansible-2.12.4rc1/test/units/config/manager/test_find_ini_config_file.py" startline="160" endline="179" pcid="4906">
    def test_no_cwd_cfg_no_warning_on_writable(self, setup_env, setup_existing_files, monkeypatch):
        """If the cwd is writable but there is no config file there, move on with no warning"""
        real_stat = os.stat

        def _os_stat(path):
            if path == working_dir:
                from posix import stat_result
                stat_info = list(real_stat(path))
                stat_info[stat.ST_MODE] |= stat.S_IWOTH
                return stat_result(stat_info)
            else:
                return real_stat(path)

        monkeypatch.setattr('os.stat', _os_stat)

        warnings = set()
        assert find_ini_config_file(warnings) == cfg_in_homedir
        assert len(warnings) == 0

    # ANSIBLE_CONFIG not specified
</source>
<source file="systems/ansible-2.12.4rc1/test/units/config/manager/test_find_ini_config_file.py" startline="185" endline="207" pcid="4908">
    def test_cwd_warning_on_writable(self, setup_env, setup_existing_files, monkeypatch):
        """If the cwd is writable, warn and skip it """
        real_stat = os.stat

        def _os_stat(path):
            if path == working_dir:
                from posix import stat_result
                stat_info = list(real_stat(path))
                stat_info[stat.ST_MODE] |= stat.S_IWOTH
                return stat_result(stat_info)
            else:
                return real_stat(path)

        monkeypatch.setattr('os.stat', _os_stat)

        warnings = set()
        assert find_ini_config_file(warnings) == cfg_in_homedir
        assert len(warnings) == 1
        warning = warnings.pop()
        assert u'Ansible is being run in a world writable directory' in warning
        assert u'ignoring it as an ansible.cfg source' in warning

    # ANSIBLE_CONFIG is sepcified
</source>
<source file="systems/ansible-2.12.4rc1/test/units/config/manager/test_find_ini_config_file.py" startline="238" endline="253" pcid="4912">
    def test_cwd_warning_on_writable_no_warning_set(self, setup_env, setup_existing_files, monkeypatch):
        """Smoketest that the function succeeds even though no warning set was passed in"""
        real_stat = os.stat

        def _os_stat(path):
            if path == working_dir:
                from posix import stat_result
                stat_info = list(real_stat(path))
                stat_info[stat.ST_MODE] |= stat.S_IWOTH
                return stat_result(stat_info)
            else:
                return real_stat(path)

        monkeypatch.setattr('os.stat', _os_stat)

        assert find_ini_config_file() == cfg_in_homedir
</source>
<source file="systems/ansible-2.12.4rc1/test/units/config/manager/test_find_ini_config_file.py" startline="213" endline="232" pcid="4910">
    def test_no_warning_on_writable_if_env_used(self, setup_env, setup_existing_files, monkeypatch, expected):
        """If the cwd is writable but ANSIBLE_CONFIG was used, no warning should be issued"""
        real_stat = os.stat

        def _os_stat(path):
            if path == working_dir:
                from posix import stat_result
                stat_info = list(real_stat(path))
                stat_info[stat.ST_MODE] |= stat.S_IWOTH
                return stat_result(stat_info)
            else:
                return real_stat(path)

        monkeypatch.setattr('os.stat', _os_stat)

        warnings = set()
        assert find_ini_config_file(warnings) == expected
        assert warnings == set()

    # ANSIBLE_CONFIG not specified
</source>
</class>

<class classid="120" nclones="2" nlines="22" similarity="79">
<source file="systems/ansible-2.12.4rc1/test/units/executor/test_task_executor.py" startline="38" endline="57" pcid="4922">
    def test_task_executor_init(self):
        fake_loader = DictDataLoader({})
        mock_host = MagicMock()
        mock_task = MagicMock()
        mock_play_context = MagicMock()
        mock_shared_loader = MagicMock()
        new_stdin = None
        job_vars = dict()
        mock_queue = MagicMock()
        te = TaskExecutor(
            host=mock_host,
            task=mock_task,
            job_vars=job_vars,
            play_context=mock_play_context,
            new_stdin=new_stdin,
            loader=fake_loader,
            shared_loader_obj=mock_shared_loader,
            final_q=mock_queue,
        )

</source>
<source file="systems/ansible-2.12.4rc1/test/units/executor/test_task_executor.py" startline="122" endline="153" pcid="4925">
    def test_task_executor_get_loop_items(self):
        fake_loader = DictDataLoader({})

        mock_host = MagicMock()

        mock_task = MagicMock()
        mock_task.loop_with = 'items'
        mock_task.loop = ['a', 'b', 'c']

        mock_play_context = MagicMock()

        mock_shared_loader = MagicMock()
        mock_shared_loader.lookup_loader = lookup_loader

        new_stdin = None
        job_vars = dict()
        mock_queue = MagicMock()

        te = TaskExecutor(
            host=mock_host,
            task=mock_task,
            job_vars=job_vars,
            play_context=mock_play_context,
            new_stdin=new_stdin,
            loader=fake_loader,
            shared_loader_obj=mock_shared_loader,
            final_q=mock_queue,
        )

        items = te._get_loop_items()
        self.assertEqual(items, ['a', 'b', 'c'])

</source>
</class>

<class classid="121" nclones="3" nlines="28" similarity="79">
<source file="systems/ansible-2.12.4rc1/test/units/executor/test_task_executor.py" startline="195" endline="228" pcid="4929">
    def test_task_executor_get_action_handler(self):
        te = TaskExecutor(
            host=MagicMock(),
            task=MagicMock(),
            job_vars={},
            play_context=MagicMock(),
            new_stdin=None,
            loader=DictDataLoader({}),
            shared_loader_obj=MagicMock(),
            final_q=MagicMock(),
        )

        action_loader = te._shared_loader_obj.action_loader
        action_loader.has_plugin.return_value = True
        action_loader.get.return_value = mock.sentinel.handler

        mock_connection = MagicMock()
        mock_templar = MagicMock()
        action = 'namespace.prefix_suffix'
        te._task.action = action

        handler = te._get_action_handler(mock_connection, mock_templar)

        self.assertIs(mock.sentinel.handler, handler)

        action_loader.has_plugin.assert_called_once_with(
            action, collection_list=te._task.collections)

        action_loader.get.assert_called_once_with(
            te._task.action, task=te._task, connection=mock_connection,
            play_context=te._play_context, loader=te._loader,
            templar=mock_templar, shared_loader_obj=te._shared_loader_obj,
            collection_list=te._task.collections)

</source>
<source file="systems/ansible-2.12.4rc1/test/units/executor/test_task_executor.py" startline="264" endline="298" pcid="4931">
    def test_task_executor_get_handler_normal(self):
        te = TaskExecutor(
            host=MagicMock(),
            task=MagicMock(),
            job_vars={},
            play_context=MagicMock(),
            new_stdin=None,
            loader=DictDataLoader({}),
            shared_loader_obj=MagicMock(),
            final_q=MagicMock(),
        )

        action_loader = te._shared_loader_obj.action_loader
        action_loader.has_plugin.return_value = False
        action_loader.get.return_value = mock.sentinel.handler
        action_loader.__contains__.return_value = False

        mock_connection = MagicMock()
        mock_templar = MagicMock()
        action = 'namespace.prefix_suffix'
        module_prefix = action.split('_', 1)[0]
        te._task.action = action
        handler = te._get_action_handler(mock_connection, mock_templar)

        self.assertIs(mock.sentinel.handler, handler)

        action_loader.has_plugin.assert_has_calls([mock.call(action, collection_list=te._task.collections),
                                                   mock.call(module_prefix, collection_list=te._task.collections)])

        action_loader.get.assert_called_once_with(
            'ansible.legacy.normal', task=te._task, connection=mock_connection,
            play_context=te._play_context, loader=te._loader,
            templar=mock_templar, shared_loader_obj=te._shared_loader_obj,
            collection_list=None)

</source>
<source file="systems/ansible-2.12.4rc1/test/units/executor/test_task_executor.py" startline="229" endline="263" pcid="4930">
    def test_task_executor_get_handler_prefix(self):
        te = TaskExecutor(
            host=MagicMock(),
            task=MagicMock(),
            job_vars={},
            play_context=MagicMock(),
            new_stdin=None,
            loader=DictDataLoader({}),
            shared_loader_obj=MagicMock(),
            final_q=MagicMock(),
        )

        action_loader = te._shared_loader_obj.action_loader
        action_loader.has_plugin.side_effect = [False, True]
        action_loader.get.return_value = mock.sentinel.handler
        action_loader.__contains__.return_value = True

        mock_connection = MagicMock()
        mock_templar = MagicMock()
        action = 'namespace.netconf_suffix'
        module_prefix = action.split('_', 1)[0]
        te._task.action = action

        handler = te._get_action_handler(mock_connection, mock_templar)

        self.assertIs(mock.sentinel.handler, handler)
        action_loader.has_plugin.assert_has_calls([mock.call(action, collection_list=te._task.collections),
                                                   mock.call(module_prefix, collection_list=te._task.collections)])

        action_loader.get.assert_called_once_with(
            module_prefix, task=te._task, connection=mock_connection,
            play_context=te._play_context, loader=te._loader,
            templar=mock_templar, shared_loader_obj=te._shared_loader_obj,
            collection_list=te._task.collections)

</source>
</class>

<class classid="122" nclones="2" nlines="13" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/units/executor/test_task_result.py" startline="40" endline="61" pcid="4938">
    def test_task_result_is_changed(self):
        mock_host = MagicMock()
        mock_task = MagicMock()

        # test with no changed in result
        tr = TaskResult(mock_host, mock_task, dict())
        self.assertFalse(tr.is_changed())

        # test with changed in the result
        tr = TaskResult(mock_host, mock_task, dict(changed=True))
        self.assertTrue(tr.is_changed())

        # test with multiple results but none changed
        mock_task.loop = 'foo'
        tr = TaskResult(mock_host, mock_task, dict(results=[dict(foo='bar'), dict(bam='baz'), True]))
        self.assertFalse(tr.is_changed())

        # test with multiple results and one changed
        mock_task.loop = 'foo'
        tr = TaskResult(mock_host, mock_task, dict(results=[dict(changed=False), dict(changed=True), dict(some_key=False)]))
        self.assertTrue(tr.is_changed())

</source>
<source file="systems/ansible-2.12.4rc1/test/units/executor/test_task_result.py" startline="98" endline="119" pcid="4940">
    def test_task_result_is_unreachable(self):
        mock_host = MagicMock()
        mock_task = MagicMock()

        # test with no unreachable in result
        tr = TaskResult(mock_host, mock_task, dict())
        self.assertFalse(tr.is_unreachable())

        # test with unreachable in the result
        tr = TaskResult(mock_host, mock_task, dict(unreachable=True))
        self.assertTrue(tr.is_unreachable())

        # test with multiple results but none unreachable
        mock_task.loop = 'foo'
        tr = TaskResult(mock_host, mock_task, dict(results=[dict(foo='bar'), dict(bam='baz'), True]))
        self.assertFalse(tr.is_unreachable())

        # test with multiple results and one unreachable
        mock_task.loop = 'foo'
        tr = TaskResult(mock_host, mock_task, dict(results=[dict(unreachable=False), dict(unreachable=True), dict(some_key=False)]))
        self.assertTrue(tr.is_unreachable())

</source>
</class>

<class classid="123" nclones="3" nlines="10" similarity="75">
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/urls/test_Request.py" startline="123" endline="137" pcid="5044">
def test_Request_open_http(urlopen_mock, install_opener_mock):
    r = Request().open('GET', 'http://ansible.com/')
    args = urlopen_mock.call_args[0]

    opener = install_opener_mock.call_args[0][0]
    handlers = opener.handlers

    found_handlers = []
    for handler in handlers:
        if isinstance(handler, SSLValidationHandler):
            found_handlers.append(handler)

    assert len(found_handlers) == 0


</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/urls/test_Request.py" startline="153" endline="170" pcid="5046">
def test_Request_open_https_unix_socket(urlopen_mock, install_opener_mock):
    r = Request().open('GET', 'https://ansible.com/', unix_socket='/foo/bar/baz.sock')
    args = urlopen_mock.call_args[0]

    opener = install_opener_mock.call_args[0][0]
    handlers = opener.handlers

    found_handlers = []
    for handler in handlers:
        if isinstance(handler, HTTPSClientAuthHandler):
            found_handlers.append(handler)

    assert len(found_handlers) == 1

    inst = found_handlers[0]._build_https_connection('foo')
    assert isinstance(inst, UnixHTTPSConnection)


</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/urls/test_Request.py" startline="138" endline="152" pcid="5045">
def test_Request_open_unix_socket(urlopen_mock, install_opener_mock):
    r = Request().open('GET', 'http://ansible.com/', unix_socket='/foo/bar/baz.sock')
    args = urlopen_mock.call_args[0]

    opener = install_opener_mock.call_args[0][0]
    handlers = opener.handlers

    found_handlers = []
    for handler in handlers:
        if isinstance(handler, UnixHTTPHandler):
            found_handlers.append(handler)

    assert len(found_handlers) == 1


</source>
</class>

<class classid="124" nclones="4" nlines="14" similarity="75">
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/urls/test_Request.py" startline="185" endline="203" pcid="5049">
def test_Request_open_username(urlopen_mock, install_opener_mock):
    r = Request().open('GET', 'http://ansible.com/', url_username='user')

    opener = install_opener_mock.call_args[0][0]
    handlers = opener.handlers

    expected_handlers = (
        urllib_request.HTTPBasicAuthHandler,
        urllib_request.HTTPDigestAuthHandler,
    )

    found_handlers = []
    for handler in handlers:
        if isinstance(handler, expected_handlers):
            found_handlers.append(handler)
    assert len(found_handlers) == 2
    assert found_handlers[0].passwd.passwd[None] == {(('ansible.com', '/'),): ('user', None)}


</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/urls/test_Request.py" startline="204" endline="221" pcid="5050">
def test_Request_open_username_in_url(urlopen_mock, install_opener_mock):
    r = Request().open('GET', 'http://user2@ansible.com/')

    opener = install_opener_mock.call_args[0][0]
    handlers = opener.handlers

    expected_handlers = (
        urllib_request.HTTPBasicAuthHandler,
        urllib_request.HTTPDigestAuthHandler,
    )

    found_handlers = []
    for handler in handlers:
        if isinstance(handler, expected_handlers):
            found_handlers.append(handler)
    assert found_handlers[0].passwd.passwd[None] == {(('ansible.com', '/'),): ('user2', '')}


</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/urls/test_Request.py" startline="222" endline="244" pcid="5051">
def test_Request_open_username_force_basic(urlopen_mock, install_opener_mock):
    r = Request().open('GET', 'http://ansible.com/', url_username='user', url_password='passwd', force_basic_auth=True)

    opener = install_opener_mock.call_args[0][0]
    handlers = opener.handlers

    expected_handlers = (
        urllib_request.HTTPBasicAuthHandler,
        urllib_request.HTTPDigestAuthHandler,
    )

    found_handlers = []
    for handler in handlers:
        if isinstance(handler, expected_handlers):
            found_handlers.append(handler)

    assert len(found_handlers) == 0

    args = urlopen_mock.call_args[0]
    req = args[0]
    assert req.headers.get('Authorization') == b'Basic dXNlcjpwYXNzd2Q='


</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/urls/test_Request.py" startline="245" endline="266" pcid="5052">
def test_Request_open_auth_in_netloc(urlopen_mock, install_opener_mock):
    r = Request().open('GET', 'http://user:passwd@ansible.com/')
    args = urlopen_mock.call_args[0]
    req = args[0]
    assert req.get_full_url() == 'http://ansible.com/'

    opener = install_opener_mock.call_args[0][0]
    handlers = opener.handlers

    expected_handlers = (
        urllib_request.HTTPBasicAuthHandler,
        urllib_request.HTTPDigestAuthHandler,
    )

    found_handlers = []
    for handler in handlers:
        if isinstance(handler, expected_handlers):
            found_handlers.append(handler)

    assert len(found_handlers) == 2


</source>
</class>

<class classid="125" nclones="2" nlines="19" similarity="80">
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/common/validation/test_check_type_bytes.py" startline="14" endline="36" pcid="5118">
def test_check_type_bytes():
    test_cases = (
        ('1', 1),
        (99, 99),
        (1.5, 2),
        ('1.5', 2),
        ('2b', 2),
        ('2B', 2),
        ('2k', 2048),
        ('2K', 2048),
        ('2KB', 2048),
        ('1m', 1048576),
        ('1M', 1048576),
        ('1MB', 1048576),
        ('1g', 1073741824),
        ('1G', 1073741824),
        ('1GB', 1073741824),
        (1073741824, 1073741824),
    )
    for case in test_cases:
        assert case[1] == check_type_bytes(case[0])


</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/common/validation/test_check_type_bits.py" startline="14" endline="32" pcid="5161">
def test_check_type_bits():
    test_cases = (
        ('1', 1),
        (99, 99),
        (1.5, 2),
        ('1.5', 2),
        ('2b', 2),
        ('2k', 2048),
        ('2K', 2048),
        ('1m', 1048576),
        ('1M', 1048576),
        ('1g', 1073741824),
        ('1G', 1073741824),
        (1073741824, 1073741824),
    )
    for case in test_cases:
        assert case[1] == check_type_bits(case[0])


</source>
</class>

<class classid="126" nclones="4" nlines="12" similarity="72">
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/common/validation/test_check_type_bytes.py" startline="37" endline="50" pcid="5119">
def test_check_type_bytes_fail():
    test_cases = (
        'foo',
        '2kb',
        '2Kb',
        '1mb',
        '1Mb',
        '1gb',
        '1Gb',
    )
    for case in test_cases:
        with pytest.raises(TypeError) as e:
            check_type_bytes(case)
        assert 'cannot be converted to a Byte value' in to_native(e.value)
</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/common/validation/test_check_type_bits.py" startline="33" endline="43" pcid="5162">
def test_check_type_bits_fail():
    test_cases = (
        'foo',
        '2KB',
        '1MB',
        '1GB',
    )
    for case in test_cases:
        with pytest.raises(TypeError) as e:
            check_type_bits(case)
        assert 'cannot be converted to a Bit value' in to_native(e.value)
</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/common/validation/test_check_type_float.py" startline="29" endline="38" pcid="5134">
def test_check_type_float_fail():
    test_cases = (
        {'k1': 'v1'},
        ['a', 'b'],
        'b',
    )
    for case in test_cases:
        with pytest.raises(TypeError) as e:
            check_type_float(case)
        assert 'cannot be converted to a float' in to_native(e.value)
</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/common/validation/test_check_type_int.py" startline="24" endline="34" pcid="5173">
def test_check_type_int_fail():
    test_cases = (
        {'k1': 'v1'},
        (b'1', 1),
        (3.14159, 3),
        'b',
    )
    for case in test_cases:
        with pytest.raises(TypeError) as e:
            check_type_int(case)
        assert 'cannot be converted to an int' in to_native(e.value)
</source>
</class>

<class classid="127" nclones="2" nlines="12" similarity="75">
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/common/validation/test_check_type_jsonarg.py" startline="14" endline="27" pcid="5131">
def test_check_type_jsonarg():
    test_cases = (
        ('a', 'a'),
        ('a  ', 'a'),
        (b'99', b'99'),
        (b'99  ', b'99'),
        ({'k1': 'v1'}, '{"k1": "v1"}'),
        ([1, 'a'], '[1, "a"]'),
        ((1, 2, 'three'), '[1, 2, "three"]'),
    )
    for case in test_cases:
        assert case[1] == check_type_jsonarg(case[0])


</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/common/validation/test_check_type_raw.py" startline="12" endline="23" pcid="5150">
def test_check_type_raw():
    test_cases = (
        (1, 1),
        ('1', '1'),
        ('a', 'a'),
        ({'k1': 'v1'}, {'k1': 'v1'}),
        ([1, 2], [1, 2]),
        (b'42', b'42'),
        (u'42', u'42'),
    )
    for case in test_cases:
        assert case[1] == check_type_raw(case[0])
</source>
</class>

<class classid="128" nclones="2" nlines="12" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/common/validation/test_check_required_arguments.py" startline="15" endline="28" pcid="5165">
def arguments_terms():
    return {
        'foo': {
            'required': True,
        },
        'bar': {
            'required': False,
        },
        'tomato': {
            'irrelevant': 72,
        },
    }


</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/common/validation/test_check_required_arguments.py" startline="30" endline="43" pcid="5166">
def arguments_terms_multiple():
    return {
        'foo': {
            'required': True,
        },
        'bar': {
            'required': True,
        },
        'tomato': {
            'irrelevant': 72,
        },
    }


</source>
</class>

<class classid="129" nclones="2" nlines="10" similarity="75">
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/common/parameters/test_handle_aliases.py" startline="49" endline="62" pcid="5224">
def test_handle_aliases_value_error():
    argument_spec = {
        'name': {'type': 'str', 'aliases': ['surname', 'nick'], 'default': 'bob', 'required': True},
    }

    params = {
        'name': 'foo',
    }

    with pytest.raises(ValueError) as ve:
        _handle_aliases(argument_spec, params)
        assert 'internal error: aliases must be a list or tuple' == to_native(ve.error)


</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/common/parameters/test_handle_aliases.py" startline="63" endline="74" pcid="5225">
def test_handle_aliases_type_error():
    argument_spec = {
        'name': {'type': 'str', 'aliases': 'surname'},
    }

    params = {
        'name': 'foo',
    }

    with pytest.raises(TypeError) as te:
        _handle_aliases(argument_spec, params)
        assert 'internal error: required and default are mutually exclusive' in to_native(te.error)
</source>
</class>

<class classid="130" nclones="2" nlines="31" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/common/test_sys_info.py" startline="52" endline="97" pcid="5244">
    def test_distro_known(self):
        with patch('ansible.module_utils.distro.id', return_value="alpine"):
            assert get_distribution() == "Alpine"

        with patch('ansible.module_utils.distro.id', return_value="arch"):
            assert get_distribution() == "Arch"

        with patch('ansible.module_utils.distro.id', return_value="centos"):
            assert get_distribution() == "Centos"

        with patch('ansible.module_utils.distro.id', return_value="clear-linux-os"):
            assert get_distribution() == "Clear-linux-os"

        with patch('ansible.module_utils.distro.id', return_value="coreos"):
            assert get_distribution() == "Coreos"

        with patch('ansible.module_utils.distro.id', return_value="debian"):
            assert get_distribution() == "Debian"

        with patch('ansible.module_utils.distro.id', return_value="flatcar"):
            assert get_distribution() == "Flatcar"

        with patch('ansible.module_utils.distro.id', return_value="linuxmint"):
            assert get_distribution() == "Linuxmint"

        with patch('ansible.module_utils.distro.id', return_value="opensuse"):
            assert get_distribution() == "Opensuse"

        with patch('ansible.module_utils.distro.id', return_value="oracle"):
            assert get_distribution() == "Oracle"

        with patch('ansible.module_utils.distro.id', return_value="raspian"):
            assert get_distribution() == "Raspian"

        with patch('ansible.module_utils.distro.id', return_value="rhel"):
            assert get_distribution() == "Redhat"

        with patch('ansible.module_utils.distro.id', return_value="ubuntu"):
            assert get_distribution() == "Ubuntu"

        with patch('ansible.module_utils.distro.id', return_value="virtuozzo"):
            assert get_distribution() == "Virtuozzo"

        with patch('ansible.module_utils.distro.id', return_value="foo"):
            assert get_distribution() == "Foo"

</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/basic/test_platform_distribution.py" startline="48" endline="93" pcid="5478">
    def test_distro_known(self):
        with patch('ansible.module_utils.distro.id', return_value="alpine"):
            assert get_distribution() == "Alpine"

        with patch('ansible.module_utils.distro.id', return_value="arch"):
            assert get_distribution() == "Arch"

        with patch('ansible.module_utils.distro.id', return_value="centos"):
            assert get_distribution() == "Centos"

        with patch('ansible.module_utils.distro.id', return_value="clear-linux-os"):
            assert get_distribution() == "Clear-linux-os"

        with patch('ansible.module_utils.distro.id', return_value="coreos"):
            assert get_distribution() == "Coreos"

        with patch('ansible.module_utils.distro.id', return_value="debian"):
            assert get_distribution() == "Debian"

        with patch('ansible.module_utils.distro.id', return_value="flatcar"):
            assert get_distribution() == "Flatcar"

        with patch('ansible.module_utils.distro.id', return_value="linuxmint"):
            assert get_distribution() == "Linuxmint"

        with patch('ansible.module_utils.distro.id', return_value="opensuse"):
            assert get_distribution() == "Opensuse"

        with patch('ansible.module_utils.distro.id', return_value="oracle"):
            assert get_distribution() == "Oracle"

        with patch('ansible.module_utils.distro.id', return_value="raspian"):
            assert get_distribution() == "Raspian"

        with patch('ansible.module_utils.distro.id', return_value="rhel"):
            assert get_distribution() == "Redhat"

        with patch('ansible.module_utils.distro.id', return_value="ubuntu"):
            assert get_distribution() == "Ubuntu"

        with patch('ansible.module_utils.distro.id', return_value="virtuozzo"):
            assert get_distribution() == "Virtuozzo"

        with patch('ansible.module_utils.distro.id', return_value="foo"):
            assert get_distribution() == "Foo"

</source>
</class>

<class classid="131" nclones="3" nlines="13" similarity="76">
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/test_api.py" startline="77" endline="91" pcid="5303">
    def test_no_retry_exception(self):
        @retry_with_delays_and_condition(
            backoff_iterator=[1],
            should_retry_error=lambda x: False,
        )
        def login_database():
            login_database.counter += 1
            if login_database.counter == 1:
                raise CustomException("Error")

        login_database.counter = 0
        with pytest.raises(CustomException, match="Error"):
            login_database()
        assert login_database.counter == 1

</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/test_api.py" startline="108" endline="121" pcid="5307">
    def test_retry_exception(self):
        @retry_with_delays_and_condition(
            backoff_iterator=[1],
            should_retry_error=lambda x: isinstance(x, CustomException),
        )
        def login_database():
            login_database.counter += 1
            if login_database.counter == 1:
                raise CustomException("Retry")
            return 'success'

        login_database.counter = 0
        assert login_database() == 'success'
        assert login_database.counter == 2
</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/test_api.py" startline="92" endline="107" pcid="5305">
    def test_no_retry_baseexception(self):
        @retry_with_delays_and_condition(
            backoff_iterator=[1],
            should_retry_error=lambda x: True,  # Retry all exceptions inheriting from Exception
        )
        def login_database():
            login_database.counter += 1
            if login_database.counter == 1:
                # Raise an exception inheriting from BaseException
                raise CustomBaseException("Error")

        login_database.counter = 0
        with pytest.raises(CustomBaseException, match="Error"):
            login_database()
        assert login_database.counter == 1

</source>
</class>

<class classid="132" nclones="2" nlines="15" similarity="75">
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/basic/test_sanitize_keys.py" startline="28" endline="53" pcid="5322">
def _run_comparison(obj):
    no_log_strings = set(['secret', 'password'])

    ret = sanitize_keys(obj, no_log_strings)

    expected = [
        None,
        True,
        100,
        "some string",
        set([1, 2]),
        [1, 2],

        {'key1': ['value1a', 'value1b'],
         'some-********': 'value-for-some-password',
         'key2': {'key3': set(['value3a', 'value3b']),
                  'i-have-a-********': {'********-********': 'value-for-secret-password', 'key4': 'value4'}
                  }
         },

        {'foo': [{'VALUE_SPECIFIED_IN_NO_LOG_PARAMETER': 1}]}
    ]

    assert ret == expected


</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/basic/test_sanitize_keys.py" startline="54" endline="77" pcid="5323">
def test_sanitize_keys_dict():
    """ Test that santize_keys works with a dict. """

    d = [
        None,
        True,
        100,
        "some string",
        set([1, 2]),
        [1, 2],

        {'key1': ['value1a', 'value1b'],
         'some-password': 'value-for-some-password',
         'key2': {'key3': set(['value3a', 'value3b']),
                  'i-have-a-secret': {'secret-password': 'value-for-secret-password', 'key4': 'value4'}
                  }
         },

        {'foo': [{'secret': 1}]}
    ]

    _run_comparison(d)


</source>
</class>

<class classid="133" nclones="2" nlines="29" similarity="93">
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/basic/test_filesystem.py" startline="60" endline="98" pcid="5346">
    def test_module_utils_basic_ansible_module_set_owner_if_different(self):
        from ansible.module_utils import basic
        basic._ANSIBLE_ARGS = None

        am = basic.AnsibleModule(
            argument_spec=dict(),
        )

        self.assertEqual(am.set_owner_if_different('/path/to/file', None, True), True)
        self.assertEqual(am.set_owner_if_different('/path/to/file', None, False), False)

        am.user_and_group = MagicMock(return_value=(500, 500))

        with patch('os.lchown', return_value=None) as m:
            self.assertEqual(am.set_owner_if_different('/path/to/file', 0, False), True)
            m.assert_called_with(b'/path/to/file', 0, -1)

            def _mock_getpwnam(*args, **kwargs):
                mock_pw = MagicMock()
                mock_pw.pw_uid = 0
                return mock_pw

            m.reset_mock()
            with patch('pwd.getpwnam', side_effect=_mock_getpwnam):
                self.assertEqual(am.set_owner_if_different('/path/to/file', 'root', False), True)
                m.assert_called_with(b'/path/to/file', 0, -1)

            with patch('pwd.getpwnam', side_effect=KeyError):
                self.assertRaises(SystemExit, am.set_owner_if_different, '/path/to/file', 'root', False)

            m.reset_mock()
            am.check_mode = True
            self.assertEqual(am.set_owner_if_different('/path/to/file', 0, False), True)
            self.assertEqual(m.called, False)
            am.check_mode = False

        with patch('os.lchown', side_effect=OSError) as m:
            self.assertRaises(SystemExit, am.set_owner_if_different, '/path/to/file', 'root', False)

</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/basic/test_filesystem.py" startline="99" endline="136" pcid="5348">
    def test_module_utils_basic_ansible_module_set_group_if_different(self):
        from ansible.module_utils import basic
        basic._ANSIBLE_ARGS = None

        am = basic.AnsibleModule(
            argument_spec=dict(),
        )

        self.assertEqual(am.set_group_if_different('/path/to/file', None, True), True)
        self.assertEqual(am.set_group_if_different('/path/to/file', None, False), False)

        am.user_and_group = MagicMock(return_value=(500, 500))

        with patch('os.lchown', return_value=None) as m:
            self.assertEqual(am.set_group_if_different('/path/to/file', 0, False), True)
            m.assert_called_with(b'/path/to/file', -1, 0)

            def _mock_getgrnam(*args, **kwargs):
                mock_gr = MagicMock()
                mock_gr.gr_gid = 0
                return mock_gr

            m.reset_mock()
            with patch('grp.getgrnam', side_effect=_mock_getgrnam):
                self.assertEqual(am.set_group_if_different('/path/to/file', 'root', False), True)
                m.assert_called_with(b'/path/to/file', -1, 0)

            with patch('grp.getgrnam', side_effect=KeyError):
                self.assertRaises(SystemExit, am.set_group_if_different, '/path/to/file', 'root', False)

            m.reset_mock()
            am.check_mode = True
            self.assertEqual(am.set_group_if_different('/path/to/file', 0, False), True)
            self.assertEqual(m.called, False)
            am.check_mode = False

        with patch('os.lchown', side_effect=OSError) as m:
            self.assertRaises(SystemExit, am.set_group_if_different, '/path/to/file', 'root', False)
</source>
</class>

<class classid="134" nclones="4" nlines="28" similarity="83">
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/basic/test_set_cwd.py" startline="46" endline="82" pcid="5409">
    def test_set_cwd_unreadable_use_self_tmpdir(self, monkeypatch):

        '''pwd is not readable, use instance's tmpdir property'''

        def mock_getcwd():
            return '/tmp'

        def mock_access(path, perm):
            if path == '/tmp' and perm == 4:
                return False
            return True

        def mock_expandvars(var):
            if var == '$HOME':
                return '/home/foobar'
            return var

        def mock_gettempdir():
            return '/tmp/testdir'

        def mock_chdir(path):
            if path == '/tmp':
                raise Exception()
            return

        monkeypatch.setattr(os, 'getcwd', mock_getcwd)
        monkeypatch.setattr(os, 'chdir', mock_chdir)
        monkeypatch.setattr(os, 'access', mock_access)
        monkeypatch.setattr(os.path, 'expandvars', mock_expandvars)
        monkeypatch.setattr(basic, '_ANSIBLE_ARGS', to_bytes(json.dumps({'ANSIBLE_MODULE_ARGS': {}})))
        with patch('time.time', return_value=42):
            am = basic.AnsibleModule(argument_spec={})

        am._tmpdir = '/tmp2'
        result = am._set_cwd()
        assert result == am._tmpdir

</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/basic/test_set_cwd.py" startline="120" endline="159" pcid="5421">
    def test_set_cwd_unreadable_use_gettempdir(self, monkeypatch):

        '''fallback to tempfile.gettempdir'''

        thisdir = None

        def mock_getcwd():
            return '/tmp'

        def mock_access(path, perm):
            if path in ['/tmp', '/tmp2', '/home/foobar'] and perm == 4:
                return False
            return True

        def mock_expandvars(var):
            if var == '$HOME':
                return '/home/foobar'
            return var

        def mock_gettempdir():
            return '/tmp3'

        def mock_chdir(path):
            if path == '/tmp':
                raise Exception()
            thisdir = path

        monkeypatch.setattr(os, 'getcwd', mock_getcwd)
        monkeypatch.setattr(os, 'chdir', mock_chdir)
        monkeypatch.setattr(os, 'access', mock_access)
        monkeypatch.setattr(os.path, 'expandvars', mock_expandvars)
        monkeypatch.setattr(basic, '_ANSIBLE_ARGS', to_bytes(json.dumps({'ANSIBLE_MODULE_ARGS': {}})))
        with patch('time.time', return_value=42):
            am = basic.AnsibleModule(argument_spec={})

        am._tmpdir = '/tmp2'
        monkeypatch.setattr(tempfile, 'gettempdir', mock_gettempdir)
        result = am._set_cwd()
        assert result == '/tmp3'

</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/basic/test_set_cwd.py" startline="83" endline="119" pcid="5415">
    def test_set_cwd_unreadable_use_home(self, monkeypatch):

        '''cwd and instance tmpdir are unreadable, use home'''

        def mock_getcwd():
            return '/tmp'

        def mock_access(path, perm):
            if path in ['/tmp', '/tmp2'] and perm == 4:
                return False
            return True

        def mock_expandvars(var):
            if var == '$HOME':
                return '/home/foobar'
            return var

        def mock_gettempdir():
            return '/tmp/testdir'

        def mock_chdir(path):
            if path == '/tmp':
                raise Exception()
            return

        monkeypatch.setattr(os, 'getcwd', mock_getcwd)
        monkeypatch.setattr(os, 'chdir', mock_chdir)
        monkeypatch.setattr(os, 'access', mock_access)
        monkeypatch.setattr(os.path, 'expandvars', mock_expandvars)
        monkeypatch.setattr(basic, '_ANSIBLE_ARGS', to_bytes(json.dumps({'ANSIBLE_MODULE_ARGS': {}})))
        with patch('time.time', return_value=42):
            am = basic.AnsibleModule(argument_spec={})

        am._tmpdir = '/tmp2'
        result = am._set_cwd()
        assert result == '/home/foobar'

</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/basic/test_set_cwd.py" startline="160" endline="195" pcid="5427">
    def test_set_cwd_unreadable_use_None(self, monkeypatch):

        '''all paths are unreable, should return None and not an exception'''

        def mock_getcwd():
            return '/tmp'

        def mock_access(path, perm):
            if path in ['/tmp', '/tmp2', '/tmp3', '/home/foobar'] and perm == 4:
                return False
            return True

        def mock_expandvars(var):
            if var == '$HOME':
                return '/home/foobar'
            return var

        def mock_gettempdir():
            return '/tmp3'

        def mock_chdir(path):
            if path == '/tmp':
                raise Exception()

        monkeypatch.setattr(os, 'getcwd', mock_getcwd)
        monkeypatch.setattr(os, 'chdir', mock_chdir)
        monkeypatch.setattr(os, 'access', mock_access)
        monkeypatch.setattr(os.path, 'expandvars', mock_expandvars)
        monkeypatch.setattr(basic, '_ANSIBLE_ARGS', to_bytes(json.dumps({'ANSIBLE_MODULE_ARGS': {}})))
        with patch('time.time', return_value=42):
            am = basic.AnsibleModule(argument_spec={})

        am._tmpdir = '/tmp2'
        monkeypatch.setattr(tempfile, 'gettempdir', mock_gettempdir)
        result = am._set_cwd()
        assert result is None
</source>
</class>

<class classid="135" nclones="2" nlines="15" similarity="81">
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/basic/test_set_mode_if_different.py" startline="113" endline="132" pcid="5517">
def test_missing_lchmod_is_not_link(am, mock_stats, mocker, monkeypatch, check_mode):
    """Some platforms have lchmod (*BSD) others do not (Linux)"""

    am.check_mode = check_mode
    original_hasattr = hasattr

    monkeypatch.delattr(os, 'lchmod', raising=False)

    mocker.patch('os.lstat', side_effect=[mock_stats['before'], mock_stats['after']])
    mocker.patch('os.path.islink', return_value=False)
    mocker.patch('os.path.exists', return_value=True)
    m_chmod = mocker.patch('os.chmod', return_value=None)

    assert am.set_mode_if_different('/path/to/file/no_lchmod', 0o660, False)
    if check_mode:
        assert not m_chmod.called
    else:
        m_chmod.assert_called_with(b'/path/to/file/no_lchmod', 0o660)


</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/basic/test_set_mode_if_different.py" startline="136" endline="159" pcid="5518">
def test_missing_lchmod_is_link(am, mock_stats, mocker, monkeypatch, check_mode):
    """Some platforms have lchmod (*BSD) others do not (Linux)"""

    am.check_mode = check_mode
    original_hasattr = hasattr

    monkeypatch.delattr(os, 'lchmod', raising=False)

    mocker.patch('os.lstat', side_effect=[mock_stats['before'], mock_stats['after']])
    mocker.patch('os.path.islink', return_value=True)
    mocker.patch('os.path.exists', return_value=True)
    m_chmod = mocker.patch('os.chmod', return_value=None)
    mocker.patch('os.stat', return_value=mock_stats['after'])

    assert am.set_mode_if_different('/path/to/file/no_lchmod', 0o660, False)
    if check_mode:
        assert not m_chmod.called
    else:
        m_chmod.assert_called_with(b'/path/to/file/no_lchmod', 0o660)

    mocker.resetall()
    mocker.stopall()


</source>
</class>

<class classid="136" nclones="2" nlines="14" similarity="78">
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/basic/test_atomic_move.py" startline="75" endline="93" pcid="5524">
def test_new_file(atomic_am, atomic_mocks, mocker, selinux):
    # test destination does not exist, login name = 'root', no environment, os.rename() succeeds
    mock_context = atomic_am.selinux_default_context.return_value
    atomic_mocks['path_exists'].return_value = False
    atomic_am.selinux_enabled.return_value = selinux

    atomic_am.atomic_move('/path/to/src', '/path/to/dest')

    atomic_mocks['rename'].assert_called_with(b'/path/to/src', b'/path/to/dest')
    assert atomic_mocks['chmod'].call_args_list == [mocker.call(b'/path/to/dest', basic.DEFAULT_PERM & ~18)]

    if selinux:
        assert atomic_am.selinux_default_context.call_args_list == [mocker.call('/path/to/dest')]
        assert atomic_am.set_context_if_different.call_args_list == [mocker.call('/path/to/dest', mock_context, False)]
    else:
        assert not atomic_am.selinux_default_context.called
        assert not atomic_am.set_context_if_different.called


</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/basic/test_atomic_move.py" startline="95" endline="114" pcid="5525">
def test_existing_file(atomic_am, atomic_mocks, fake_stat, mocker, selinux):
    # Test destination already present
    mock_context = atomic_am.selinux_context.return_value
    atomic_mocks['stat'].return_value = fake_stat
    atomic_mocks['path_exists'].return_value = True
    atomic_am.selinux_enabled.return_value = selinux

    atomic_am.atomic_move('/path/to/src', '/path/to/dest')

    atomic_mocks['rename'].assert_called_with(b'/path/to/src', b'/path/to/dest')
    assert atomic_mocks['chmod'].call_args_list == [mocker.call(b'/path/to/src', basic.DEFAULT_PERM & ~18)]

    if selinux:
        assert atomic_am.set_context_if_different.call_args_list == [mocker.call('/path/to/dest', mock_context, False)]
        assert atomic_am.selinux_context.call_args_list == [mocker.call('/path/to/dest')]
    else:
        assert not atomic_am.selinux_default_context.called
        assert not atomic_am.set_context_if_different.called


</source>
</class>

<class classid="137" nclones="2" nlines="14" similarity="71">
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/facts/virtual/test_linux.py" startline="17" endline="34" pcid="5536">
def test_get_virtual_facts_docker(mocker):
    mocker.patch('os.path.exists', mock_os_path_is_file_docker)

    module = mocker.Mock()
    module.run_command.return_value = (0, '', '')
    inst = linux.LinuxVirtual(module)
    facts = inst.get_virtual_facts()

    expected = {
        'virtualization_role': 'guest',
        'virtualization_tech_host': set(),
        'virtualization_type': 'docker',
        'virtualization_tech_guest': set(['docker', 'container']),
    }

    assert facts == expected


</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/facts/virtual/test_linux.py" startline="35" endline="52" pcid="5537">
def test_get_virtual_facts_bhyve(mocker):
    mocker.patch('os.path.exists', return_value=False)
    mocker.patch('ansible.module_utils.facts.virtual.linux.get_file_content', return_value='')
    mocker.patch('ansible.module_utils.facts.virtual.linux.get_file_lines', return_value=[])

    module = mocker.Mock()
    module.run_command.return_value = (0, 'BHYVE\n', '')
    inst = linux.LinuxVirtual(module)

    facts = inst.get_virtual_facts()
    expected = {
        'virtualization_role': 'guest',
        'virtualization_tech_host': set(),
        'virtualization_type': 'bhyve',
        'virtualization_tech_guest': set(['bhyve']),
    }

    assert facts == expected
</source>
</class>

<class classid="138" nclones="2" nlines="11" similarity="72">
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/facts/test_sysctl.py" startline="155" endline="166" pcid="5541">
    def test_get_sysctl_all_invalid_output(self):
        module = MagicMock()
        module.get_bin_path.return_value = '/sbin/sysctl'
        module.run_command.return_value = (0, BAD_SYSCTL, '')
        sysctl = get_sysctl(module, ['hw'])
        module.run_command.assert_called_once_with(['/sbin/sysctl', 'hw'])
        lines = [l for l in BAD_SYSCTL.splitlines() if l]
        for call in module.warn.call_args_list:
            self.assertIn('Unable to split sysctl line', call[0][0])
        self.assertEqual(module.warn.call_count, len(lines))
        self.assertEqual(sysctl, {})

</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/facts/test_sysctl.py" startline="167" endline="178" pcid="5542">
    def test_get_sysctl_mixed_invalid_output(self):
        module = MagicMock()
        module.get_bin_path.return_value = '/sbin/sysctl'
        module.run_command.return_value = (0, GOOD_BAD_SYSCTL, '')
        sysctl = get_sysctl(module, ['hw'])
        module.run_command.assert_called_once_with(['/sbin/sysctl', 'hw'])
        bad_lines = ['bad.output.here', 'and.bad.output.here']
        for call in module.warn.call_args_list:
            self.assertIn('Unable to split sysctl line', call[0][0])
        self.assertEqual(module.warn.call_count, 2)
        self.assertEqual(sysctl, {'hw.smt': '0'})

</source>
</class>

<class classid="139" nclones="2" nlines="19" similarity="71">
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/facts/test_sysctl.py" startline="179" endline="198" pcid="5543">
    def test_get_sysctl_openbsd_hw(self):
        expected_lines = [l for l in OPENBSD_SYSCTL_HW.splitlines() if l]
        module = MagicMock()
        module.get_bin_path.return_value = '/sbin/sysctl'
        module.run_command.return_value = (0, OPENBSD_SYSCTL_HW, '')
        sysctl = get_sysctl(module, ['hw'])
        module.run_command.assert_called_once_with(['/sbin/sysctl', 'hw'])
        self.assertEqual(len(sysctl), len(expected_lines))
        self.assertEqual(sysctl['hw.machine'], 'amd64')  # first line
        self.assertEqual(sysctl['hw.smt'], '0')  # random line
        self.assertEqual(sysctl['hw.ncpuonline'], '1')  # last line
        # weird chars in value
        self.assertEqual(
            sysctl['hw.disknames'],
            'cd0:,sd0:9e1bd96cb20ab429,fd0:')
        # more symbols/spaces in value
        self.assertEqual(
            sysctl['hw.product'],
            'Standard PC (i440FX + PIIX, 1996)')

</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/facts/test_sysctl.py" startline="199" endline="223" pcid="5544">
    def test_get_sysctl_openbsd_kern(self):
        module = MagicMock()
        module.get_bin_path.return_value = '/sbin/sysctl'
        module.run_command.return_value = (0, OPENBSD_SYSCTL_KERN_PARTIAL, '')
        sysctl = get_sysctl(module, ['kern'])
        module.run_command.assert_called_once_with(['/sbin/sysctl', 'kern'])
        self.assertEqual(
            len(sysctl),
            len(
                [l for l
                 in OPENBSD_SYSCTL_KERN_PARTIAL.splitlines()
                 if l.startswith('kern')]))
        self.assertEqual(sysctl['kern.ostype'], 'OpenBSD')  # first line
        self.assertEqual(sysctl['kern.maxproc'], '1310')  # random line
        self.assertEqual(sysctl['kern.posix1version'], '200809')  # last line
        # multiline
        self.assertEqual(
            sysctl['kern.version'],
            'OpenBSD 6.7 (GENERIC) #179: Thu May  7 11:02:37 MDT 2020\n    '
            'deraadt@amd64.openbsd.org:/usr/src/sys/arch/amd64/compile/GENERIC')
        # more symbols/spaces in value
        self.assertEqual(
            sysctl['kern.clockrate'],
            'tick = 10000, tickadj = 40, hz = 100, profhz = 100, stathz = 100')

</source>
</class>

<class classid="140" nclones="2" nlines="13" similarity="76">
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/facts/test_sysctl.py" startline="224" endline="238" pcid="5545">
    def test_get_sysctl_linux_vm(self):
        module = MagicMock()
        module.get_bin_path.return_value = '/usr/sbin/sysctl'
        module.run_command.return_value = (0, LINUX_SYSCTL_VM_PARTIAL, '')
        sysctl = get_sysctl(module, ['vm'])
        module.run_command.assert_called_once_with(['/usr/sbin/sysctl', 'vm'])
        self.assertEqual(
            len(sysctl),
            len([l for l in LINUX_SYSCTL_VM_PARTIAL.splitlines() if l]))
        self.assertEqual(sysctl['vm.dirty_background_ratio'], '10')
        self.assertEqual(sysctl['vm.laptop_mode'], '0')
        self.assertEqual(sysctl['vm.min_slab_ratio'], '5')
        # tabs
        self.assertEqual(sysctl['vm.lowmem_reserve_ratio'], '256\t256\t32\t0')

</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/facts/test_sysctl.py" startline="239" endline="251" pcid="5546">
    def test_get_sysctl_macos_vm(self):
        module = MagicMock()
        module.get_bin_path.return_value = '/usr/sbin/sysctl'
        module.run_command.return_value = (0, MACOS_SYSCTL_VM_PARTIAL, '')
        sysctl = get_sysctl(module, ['vm'])
        module.run_command.assert_called_once_with(['/usr/sbin/sysctl', 'vm'])
        self.assertEqual(
            len(sysctl),
            len([l for l in MACOS_SYSCTL_VM_PARTIAL.splitlines() if l]))
        self.assertEqual(sysctl['vm.loadavg'], '{ 1.28 1.18 1.13 }')
        self.assertEqual(
            sysctl['vm.swapusage'],
            'total = 2048.00M  used = 1017.50M  free = 1030.50M  (encrypted)')
</source>
</class>

<class classid="141" nclones="2" nlines="13" similarity="78">
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/facts/test_ansible_collector.py" startline="361" endline="376" pcid="5581">
                                   filter='ansible_this_doesnt_exist')

        facts_dict = self._collect(_mock_module)

        expected = {}
        self.assertEqual(expected, facts_dict)

    def test_concat_collector(self):
        _mock_module = mock_module(gather_subset=['all', '!facter', '!ohai'])

        _collectors = self._collectors(_mock_module)
        _collectors.append(ConCatFactCollector())

        fact_collector = \
            ansible_collector.AnsibleFactCollector(collectors=_collectors,
                                                   namespace=ns,
</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/facts/test_ansible_collector.py" startline="377" endline="394" pcid="5582">
                                                   filter_spec=_mock_module.params['filter'])

        collected_facts = {}
        facts_dict = fact_collector.collect(module=_mock_module,
                                            collected_facts=collected_facts)
        self.assertIn('concat_fact', facts_dict)
        self.assertTrue('THE_NEEDED_FACT_VALUE' in facts_dict['concat_fact'])

    def test_concat_collector_with_filter_on_concat(self):
        _mock_module = mock_module(gather_subset=['all', '!facter', '!ohai'],
                                   filter='concat_fact')

        _collectors = self._collectors(_mock_module)
        _collectors.append(ConCatFactCollector())

        fact_collector = \
            ansible_collector.AnsibleFactCollector(collectors=_collectors,
                                                   namespace=ns,
</source>
</class>

<class classid="142" nclones="2" nlines="12" similarity="83">
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/facts/hardware/test_linux_get_cpu_info.py" startline="13" endline="27" pcid="5715">
def test_get_cpu_info(mocker):
    module = mocker.Mock()
    inst = linux.LinuxHardware(module)

    mocker.patch('os.path.exists', return_value=False)
    mocker.patch('os.access', return_value=True)
    for test in CPU_INFO_TEST_SCENARIOS:
        mocker.patch('ansible.module_utils.facts.hardware.linux.get_file_lines', side_effect=[[], test['cpuinfo']])
        mocker.patch('os.sched_getaffinity', create=True, return_value=test['sched_getaffinity'])
        module.run_command.return_value = (0, test['nproc_out'], '')
        collected_facts = {'ansible_architecture': test['architecture']}

        assert test['expected_result'] == inst.get_cpu_facts(collected_facts=collected_facts)


</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/facts/hardware/test_linux_get_cpu_info.py" startline="28" endline="43" pcid="5716">
def test_get_cpu_info_nproc(mocker):
    module = mocker.Mock()
    inst = linux.LinuxHardware(module)

    mocker.patch('os.path.exists', return_value=False)
    mocker.patch('os.access', return_value=True)
    for test in CPU_INFO_TEST_SCENARIOS:
        mocker.patch('ansible.module_utils.facts.hardware.linux.get_file_lines', side_effect=[[], test['cpuinfo']])
        mocker.patch('os.sched_getaffinity', create=True, side_effect=AttributeError)
        mocker.patch('ansible.module_utils.facts.hardware.linux.get_bin_path', return_value='/usr/bin/nproc')
        module.run_command.return_value = (0, test['nproc_out'], '')
        collected_facts = {'ansible_architecture': test['architecture']}

        assert test['expected_result'] == inst.get_cpu_facts(collected_facts=collected_facts)


</source>
</class>

<class classid="143" nclones="2" nlines="15" similarity="73">
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/facts/system/distribution/test_distribution_sles4sap.py" startline="14" endline="33" pcid="5723">
def test_distribution_sles4sap_suse_sles_sap(mock_module, mocker, realpath):
    mocker.patch('os.path.islink', return_value=True)
    mocker.patch('os.path.realpath', return_value='/etc/products.d/' + realpath)

    test_input = {
        'name': 'SUSE',
        'path': '',
        'data': 'suse',
        'collected_facts': None,
    }

    test_result = (
        True,
        {
            'distribution': 'SLES_SAP',
        }
    )

    distribution = DistributionFiles(module=mock_module())
    assert test_result == distribution.parse_distribution_file_SUSE(**test_input)
</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/facts/system/distribution/test_parse_distribution_file_Slackware.py" startline="21" endline="37" pcid="5741">
def test_parse_distribution_file_slackware(mock_module, distro_file, expected_version):
    test_input = {
        'name': 'Slackware',
        'data': open(os.path.join(os.path.dirname(__file__), '../../fixtures/distribution_files', distro_file)).read(),
        'path': '/etc/os-release',
        'collected_facts': None,
    }

    result = (
        True,
        {
            'distribution': 'Slackware',
            'distribution_version': expected_version
        }
    )
    distribution = DistributionFiles(module=mock_module())
    assert result == distribution.parse_distribution_file_Slackware(**test_input)
</source>
</class>

<class classid="144" nclones="2" nlines="14" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/facts/system/test_lsb.py" startline="78" endline="93" pcid="5744">
    def test_etc_lsb_release(self):
        module = self._mock_module()
        module.get_bin_path = Mock(return_value=None)
        with patch('ansible.module_utils.facts.system.lsb.os.path.exists',
                   return_value=True):
            with patch('ansible.module_utils.facts.system.lsb.get_file_lines',
                       return_value=etc_lsb_release_ubuntu14.splitlines()):
                fact_collector = self.collector_class()
                facts_dict = fact_collector.collect(module=module)

        self.assertIsInstance(facts_dict, dict)
        self.assertEqual(facts_dict['lsb']['release'], '14.04')
        self.assertEqual(facts_dict['lsb']['id'], 'Ubuntu')
        self.assertEqual(facts_dict['lsb']['description'], 'Ubuntu 14.04.3 LTS')
        self.assertEqual(facts_dict['lsb']['codename'], 'trusty')

</source>
<source file="systems/ansible-2.12.4rc1/test/units/module_utils/facts/system/test_lsb.py" startline="94" endline="108" pcid="5745">
    def test_etc_lsb_release_no_decimal_release(self):
        module = self._mock_module()
        module.get_bin_path = Mock(return_value=None)
        with patch('ansible.module_utils.facts.system.lsb.os.path.exists',
                   return_value=True):
            with patch('ansible.module_utils.facts.system.lsb.get_file_lines',
                       return_value=etc_lsb_release_no_decimal.splitlines()):
                fact_collector = self.collector_class()
                facts_dict = fact_collector.collect(module=module)

        self.assertIsInstance(facts_dict, dict)
        self.assertEqual(facts_dict['lsb']['release'], '11')
        self.assertEqual(facts_dict['lsb']['id'], 'AwesomeOS')
        self.assertEqual(facts_dict['lsb']['description'], 'AwesomeS 11')
        self.assertEqual(facts_dict['lsb']['codename'], 'stonehenge')
</source>
</class>

<class classid="145" nclones="2" nlines="14" similarity="73">
<source file="systems/ansible-2.12.4rc1/test/units/parsing/yaml/test_loader.py" startline="118" endline="134" pcid="5790">
    def test_parse_short_dict(self):
        stream = StringIO(u"""{"foo": "bar"}""")
        loader = AnsibleLoader(stream, 'myfile.yml')
        data = loader.get_single_data()
        self.assertEqual(data, dict(foo=u'bar'))

        self.assertEqual(data.ansible_pos, ('myfile.yml', 1, 1))
        self.assertEqual(data[u'foo'].ansible_pos, ('myfile.yml', 1, 9))

        stream = StringIO(u"""foo: bar""")
        loader = AnsibleLoader(stream, 'myfile.yml')
        data = loader.get_single_data()
        self.assertEqual(data, dict(foo=u'bar'))

        self.assertEqual(data.ansible_pos, ('myfile.yml', 1, 1))
        self.assertEqual(data[u'foo'].ansible_pos, ('myfile.yml', 1, 6))

</source>
<source file="systems/ansible-2.12.4rc1/test/units/parsing/yaml/test_loader.py" startline="145" endline="165" pcid="5793">
    def test_front_matter(self):
        stream = StringIO(u"""---\nfoo: bar""")
        loader = AnsibleLoader(stream, 'myfile.yml')
        data = loader.get_single_data()
        self.assertEqual(data, dict(foo=u'bar'))

        self.assertEqual(data.ansible_pos, ('myfile.yml', 2, 1))
        self.assertEqual(data[u'foo'].ansible_pos, ('myfile.yml', 2, 6))

        # Initial indent (See: #6348)
        stream = StringIO(u""" - foo: bar\n   baz: qux""")
        loader = AnsibleLoader(stream, 'myfile.yml')
        data = loader.get_single_data()
        self.assertEqual(data, [{u'foo': u'bar', u'baz': u'qux'}])

        self.assertEqual(data.ansible_pos, ('myfile.yml', 1, 2))
        self.assertEqual(data[0].ansible_pos, ('myfile.yml', 1, 4))
        self.assertEqual(data[0][u'foo'].ansible_pos, ('myfile.yml', 1, 9))
        self.assertEqual(data[0][u'baz'].ansible_pos, ('myfile.yml', 2, 9))


</source>
</class>

<class classid="146" nclones="2" nlines="10" similarity="90">
<source file="systems/ansible-2.12.4rc1/test/units/parsing/utils/test_addresses.py" startline="74" endline="86" pcid="5852">
    def test_without_ranges(self):
        for t in self.tests:
            test = self.tests[t]

            try:
                (host, port) = parse_address(t)
            except Exception:
                host = None
                port = None

            assert host == test[0]
            assert port == test[1]

</source>
<source file="systems/ansible-2.12.4rc1/test/units/parsing/utils/test_addresses.py" startline="87" endline="98" pcid="5853">
    def test_with_ranges(self):
        for t in self.range_tests:
            test = self.range_tests[t]

            try:
                (host, port) = parse_address(t, allow_ranges=True)
            except Exception:
                host = None
                port = None

            assert host == test[0]
            assert port == test[1]
</source>
</class>

<class classid="147" nclones="2" nlines="10" similarity="90">
<source file="systems/ansible-2.12.4rc1/test/units/parsing/vault/test_vault.py" startline="178" endline="193" pcid="5875">
    def test_file(self):
        password = 'some password'

        tmp_file = tempfile.NamedTemporaryFile(delete=False)
        tmp_file.write(to_bytes(password))
        tmp_file.close()

        fake_loader = DictDataLoader({tmp_file.name: 'sdfadf'})

        secret = vault.FileVaultSecret(loader=fake_loader, filename=tmp_file.name)
        secret.load()

        os.unlink(tmp_file.name)

        self.assertEqual(secret.bytes, to_bytes(password))

</source>
<source file="systems/ansible-2.12.4rc1/test/units/parsing/vault/test_vault.py" startline="365" endline="380" pcid="5895">
    def test_file(self):
        password = 'some password'

        tmp_file = tempfile.NamedTemporaryFile(delete=False)
        tmp_file.write(to_bytes(password))
        tmp_file.close()

        fake_loader = DictDataLoader({tmp_file.name: 'sdfadf'})

        secret = vault.get_file_vault_secret(filename=tmp_file.name, loader=fake_loader)
        secret.load()

        os.unlink(tmp_file.name)

        self.assertEqual(secret.bytes, to_bytes(password))

</source>
</class>

<class classid="148" nclones="2" nlines="11" similarity="90">
<source file="systems/ansible-2.12.4rc1/test/units/parsing/vault/test_vault.py" startline="703" endline="718" pcid="5942">

    def test_encrypt_decrypt_aes256_none_secrets(self):
        vault_secrets = self._vault_secrets_from_password('default', 'ansible')
        v = vault.VaultLib(vault_secrets)

        plaintext = u"foobar"
        b_vaulttext = v.encrypt(plaintext)

        # VaultLib will default to empty {} if secrets is None
        v_none = vault.VaultLib(None)
        # so set secrets None explicitly
        v_none.secrets = None
        self.assertRaisesRegexp(vault.AnsibleVaultError,
                                '.*A vault password must be specified to decrypt data.*',
                                v_none.decrypt,
                                b_vaulttext)
</source>
<source file="systems/ansible-2.12.4rc1/test/units/parsing/vault/test_vault.py" startline="719" endline="733" pcid="5943">

    def test_encrypt_decrypt_aes256_empty_secrets(self):
        vault_secrets = self._vault_secrets_from_password('default', 'ansible')
        v = vault.VaultLib(vault_secrets)

        plaintext = u"foobar"
        b_vaulttext = v.encrypt(plaintext)

        vault_secrets_empty = []
        v_none = vault.VaultLib(vault_secrets_empty)

        self.assertRaisesRegexp(vault.AnsibleVaultError,
                                '.*Attempting to decrypt but no vault secrets found.*',
                                v_none.decrypt,
                                b_vaulttext)
</source>
</class>

<class classid="149" nclones="3" nlines="11" similarity="72">
<source file="systems/ansible-2.12.4rc1/test/units/parsing/vault/test_vault_editor.py" startline="243" endline="257" pcid="5971">
    def test_rekey_file_no_new_password(self):
        self._test_dir = self._create_test_dir()

        src_file_contents = to_bytes("some info in a file\nyup.")
        src_file_path = self._create_file(self._test_dir, 'src_file', content=src_file_contents)

        ve = self._vault_editor()
        ve.encrypt_file(src_file_path, self.vault_secret)

        self.assertRaisesRegexp(errors.AnsibleError,
                                'The value for the new_password to rekey',
                                ve.rekey_file,
                                src_file_path,
                                None)

</source>
<source file="systems/ansible-2.12.4rc1/test/units/parsing/vault/test_vault_editor.py" startline="434" endline="445" pcid="5985">
    def test_create_file_exists(self):
        self._test_dir = self._create_test_dir()
        src_contents = to_bytes("some info in a file\nyup.")
        src_file_path = self._create_file(self._test_dir, 'src_file', content=src_contents)

        ve = self._vault_editor()
        self.assertRaisesRegexp(errors.AnsibleError,
                                'please use .edit. instead',
                                ve.create_file,
                                src_file_path,
                                self.vault_secret)

</source>
<source file="systems/ansible-2.12.4rc1/test/units/parsing/vault/test_vault_editor.py" startline="258" endline="271" pcid="5972">
    def test_rekey_file_not_encrypted(self):
        self._test_dir = self._create_test_dir()

        src_file_contents = to_bytes("some info in a file\nyup.")
        src_file_path = self._create_file(self._test_dir, 'src_file', content=src_file_contents)

        ve = self._vault_editor()

        new_password = 'password2:electricbugaloo'
        self.assertRaisesRegexp(errors.AnsibleError,
                                'input is not vault encrypted data',
                                ve.rekey_file,
                                src_file_path, new_password)

</source>
</class>

<class classid="150" nclones="3" nlines="17" similarity="83">
<source file="systems/ansible-2.12.4rc1/test/units/parsing/vault/test_vault_editor.py" startline="324" endline="349" pcid="5977">
    def test_edit_file_no_vault_id(self, mock_sp_call):
        self._test_dir = self._create_test_dir()
        src_contents = to_bytes("some info in a file\nyup.")

        src_file_path = self._create_file(self._test_dir, 'src_file', content=src_contents)

        new_src_contents = to_bytes("The info is different now.")

        def faux_editor(editor_args):
            self._faux_editor(editor_args, new_src_contents)

        mock_sp_call.side_effect = faux_editor

        ve = self._vault_editor()

        ve.encrypt_file(src_file_path, self.vault_secret)
        ve.edit_file(src_file_path)

        new_src_file = open(src_file_path, 'rb')
        new_src_file_contents = new_src_file.read()

        self.assertTrue(b'$ANSIBLE_VAULT;1.1;AES256' in new_src_file_contents)

        src_file_plaintext = ve.vault.decrypt(new_src_file_contents)
        self.assertEqual(src_file_plaintext, new_src_contents)

</source>
<source file="systems/ansible-2.12.4rc1/test/units/parsing/vault/test_vault_editor.py" startline="379" endline="413" pcid="5981">
    def test_edit_file_symlink(self, mock_sp_call):
        self._test_dir = self._create_test_dir()
        src_contents = to_bytes("some info in a file\nyup.")

        src_file_path = self._create_file(self._test_dir, 'src_file', content=src_contents)

        new_src_contents = to_bytes("The info is different now.")

        def faux_editor(editor_args):
            self._faux_editor(editor_args, new_src_contents)

        mock_sp_call.side_effect = faux_editor

        ve = self._vault_editor()

        ve.encrypt_file(src_file_path, self.vault_secret)

        src_file_link_path = os.path.join(self._test_dir, 'a_link_to_dest_file')

        os.symlink(src_file_path, src_file_link_path)

        ve.edit_file(src_file_link_path)

        new_src_file = open(src_file_path, 'rb')
        new_src_file_contents = new_src_file.read()

        src_file_plaintext = ve.vault.decrypt(new_src_file_contents)

        self._assert_file_is_link(src_file_link_path, src_file_path)

        self.assertEqual(src_file_plaintext, new_src_contents)

        # self.assertEqual(src_file_plaintext, new_src_contents,
        #                 'The decrypted plaintext of the editted file is not the expected contents.')

</source>
<source file="systems/ansible-2.12.4rc1/test/units/parsing/vault/test_vault_editor.py" startline="351" endline="377" pcid="5979">
    def test_edit_file_with_vault_id(self, mock_sp_call):
        self._test_dir = self._create_test_dir()
        src_contents = to_bytes("some info in a file\nyup.")

        src_file_path = self._create_file(self._test_dir, 'src_file', content=src_contents)

        new_src_contents = to_bytes("The info is different now.")

        def faux_editor(editor_args):
            self._faux_editor(editor_args, new_src_contents)

        mock_sp_call.side_effect = faux_editor

        ve = self._vault_editor()

        ve.encrypt_file(src_file_path, self.vault_secret,
                        vault_id='vault_secrets')
        ve.edit_file(src_file_path)

        new_src_file = open(src_file_path, 'rb')
        new_src_file_contents = new_src_file.read()

        self.assertTrue(b'$ANSIBLE_VAULT;1.2;AES256;vault_secrets' in new_src_file_contents)

        src_file_plaintext = ve.vault.decrypt(new_src_file_contents)
        self.assertEqual(src_file_plaintext, new_src_contents)

</source>
</class>

<class classid="151" nclones="2" nlines="13" similarity="71">
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_iptables.py" startline="35" endline="52" pcid="6062">
    def test_flush_table_without_chain(self):
        """Test flush without chain, flush the table"""
        set_module_args({
            'flush': True,
        })

        with patch.object(basic.AnsibleModule, 'run_command') as run_command:
            run_command.return_value = 0, '', ''  # successful execution, no output
            with self.assertRaises(AnsibleExitJson) as result:
                iptables.main()
                self.assertTrue(result.exception.args[0]['changed'])

        self.assertEqual(run_command.call_count, 1)
        self.assertEqual(run_command.call_args[0][0][0], '/sbin/iptables')
        self.assertEqual(run_command.call_args[0][0][1], '-t')
        self.assertEqual(run_command.call_args[0][0][2], 'filter')
        self.assertEqual(run_command.call_args[0][0][3], '-F')

</source>
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_iptables.py" startline="53" endline="71" pcid="6063">
    def test_flush_table_check_true(self):
        """Test flush without parameters and check == true"""
        set_module_args({
            'flush': True,
            '_ansible_check_mode': True,
        })

        with patch.object(basic.AnsibleModule, 'run_command') as run_command:
            run_command.return_value = 0, '', ''  # successful execution, no output
            with self.assertRaises(AnsibleExitJson) as result:
                iptables.main()
                self.assertTrue(result.exception.args[0]['changed'])

        self.assertEqual(run_command.call_count, 0)

# TODO ADD test flush table nat
# TODO ADD test flush with chain
# TODO ADD test flush with chain and table nat

</source>
</class>

<class classid="152" nclones="13" nlines="37" similarity="70">
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_iptables.py" startline="72" endline="105" pcid="6064">
    def test_policy_table(self):
        """Test change policy of a chain"""
        set_module_args({
            'policy': 'ACCEPT',
            'chain': 'INPUT',
        })
        commands_results = [
            (0, 'Chain INPUT (policy DROP)\n', ''),
            (0, '', '')
        ]

        with patch.object(basic.AnsibleModule, 'run_command') as run_command:
            run_command.side_effect = commands_results
            with self.assertRaises(AnsibleExitJson) as result:
                iptables.main()
                self.assertTrue(result.exception.args[0]['changed'])

        self.assertEqual(run_command.call_count, 2)
        self.assertEqual(run_command.call_args_list[0][0][0], [
            '/sbin/iptables',
            '-t',
            'filter',
            '-L',
            'INPUT',
        ])
        self.assertEqual(run_command.call_args_list[1][0][0], [
            '/sbin/iptables',
            '-t',
            'filter',
            '-P',
            'INPUT',
            'ACCEPT',
        ])

</source>
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_iptables.py" startline="870" endline="910" pcid="6081">
    def test_comment_position_at_end(self):
        """Test comment position to make sure it is at the end of command"""
        set_module_args({
            'chain': 'INPUT',
            'jump': 'ACCEPT',
            'action': 'insert',
            'ctstate': ['NEW'],
            'comment': 'this is a comment',
            '_ansible_check_mode': True,
        })

        commands_results = [
            (0, '', ''),
        ]

        with patch.object(basic.AnsibleModule, 'run_command') as run_command:
            run_command.side_effect = commands_results
            with self.assertRaises(AnsibleExitJson) as result:
                iptables.main()
                self.assertTrue(result.exception.args[0]['changed'])

        self.assertEqual(run_command.call_count, 1)
        self.assertEqual(run_command.call_args_list[0][0][0], [
            '/sbin/iptables',
            '-t',
            'filter',
            '-C',
            'INPUT',
            '-j',
            'ACCEPT',
            '-m',
            'conntrack',
            '--ctstate',
            'NEW',
            '-m',
            'comment',
            '--comment',
            'this is a comment'
        ])
        self.assertEqual(run_command.call_args[0][0][14], 'this is a comment')

</source>
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_iptables.py" startline="832" endline="869" pcid="6080">
    def test_insert_rule_with_wait(self):
        """Test flush without parameters"""
        set_module_args({
            'chain': 'OUTPUT',
            'source': '1.2.3.4/32',
            'destination': '7.8.9.10/42',
            'jump': 'ACCEPT',
            'action': 'insert',
            'wait': '10'
        })

        commands_results = [
            (0, '', ''),
        ]

        with patch.object(basic.AnsibleModule, 'run_command') as run_command:
            run_command.side_effect = commands_results
            with self.assertRaises(AnsibleExitJson) as result:
                iptables.main()
                self.assertTrue(result.exception.args[0]['changed'])

        self.assertEqual(run_command.call_count, 1)
        self.assertEqual(run_command.call_args_list[0][0][0], [
            '/sbin/iptables',
            '-t',
            'filter',
            '-C',
            'OUTPUT',
            '-w',
            '10',
            '-s',
            '1.2.3.4/32',
            '-d',
            '7.8.9.10/42',
            '-j',
            'ACCEPT'
        ])

</source>
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_iptables.py" startline="162" endline="198" pcid="6067">
    def test_insert_rule_change_false(self):
        """Test flush without parameters"""
        set_module_args({
            'chain': 'OUTPUT',
            'source': '1.2.3.4/32',
            'destination': '7.8.9.10/42',
            'jump': 'ACCEPT',
            'action': 'insert',
            '_ansible_check_mode': True,
        })

        commands_results = [
            (1, '', ''),
            (0, '', '')
        ]

        with patch.object(basic.AnsibleModule, 'run_command') as run_command:
            run_command.side_effect = commands_results
            with self.assertRaises(AnsibleExitJson) as result:
                iptables.main()
                self.assertTrue(result.exception.args[0]['changed'])

        self.assertEqual(run_command.call_count, 1)
        self.assertEqual(run_command.call_args_list[0][0][0], [
            '/sbin/iptables',
            '-t',
            'filter',
            '-C',
            'OUTPUT',
            '-s',
            '1.2.3.4/32',
            '-d',
            '7.8.9.10/42',
            '-j',
            'ACCEPT'
        ])

</source>
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_iptables.py" startline="547" endline="580" pcid="6074">
    def test_insert_jump_reject_with_reject(self):
        """ Using reject_with with a previously defined jump: REJECT results in two Jump statements #18988 """
        set_module_args({
            'chain': 'INPUT',
            'protocol': 'tcp',
            'jump': 'REJECT',
            'reject_with': 'tcp-reset',
            'ip_version': 'ipv4',
        })
        commands_results = [
            (0, '', ''),
        ]

        with patch.object(basic.AnsibleModule, 'run_command') as run_command:
            run_command.side_effect = commands_results
            with self.assertRaises(AnsibleExitJson) as result:
                iptables.main()
                self.assertTrue(result.exception.args[0]['changed'])

        self.assertEqual(run_command.call_count, 1)
        self.assertEqual(run_command.call_args_list[0][0][0], [
            '/sbin/iptables',
            '-t',
            'filter',
            '-C',
            'INPUT',
            '-p',
            'tcp',
            '-j',
            'REJECT',
            '--reject-with',
            'tcp-reset',
        ])

</source>
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_iptables.py" startline="106" endline="131" pcid="6065">
    def test_policy_table_no_change(self):
        """Test don't change policy of a chain if the policy is right"""
        set_module_args({
            'policy': 'ACCEPT',
            'chain': 'INPUT',
        })
        commands_results = [
            (0, 'Chain INPUT (policy ACCEPT)\n', ''),
            (0, '', '')
        ]

        with patch.object(basic.AnsibleModule, 'run_command') as run_command:
            run_command.side_effect = commands_results
            with self.assertRaises(AnsibleExitJson) as result:
                iptables.main()
                self.assertFalse(result.exception.args[0]['changed'])

        self.assertEqual(run_command.call_count, 1)
        self.assertEqual(run_command.call_args_list[0][0][0], [
            '/sbin/iptables',
            '-t',
            'filter',
            '-L',
            'INPUT',
        ])

</source>
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_iptables.py" startline="514" endline="546" pcid="6073">
    def test_insert_with_reject(self):
        """ Using reject_with with a previously defined jump: REJECT results in two Jump statements #18988 """
        set_module_args({
            'chain': 'INPUT',
            'protocol': 'tcp',
            'reject_with': 'tcp-reset',
            'ip_version': 'ipv4',
        })
        commands_results = [
            (0, '', ''),
        ]

        with patch.object(basic.AnsibleModule, 'run_command') as run_command:
            run_command.side_effect = commands_results
            with self.assertRaises(AnsibleExitJson) as result:
                iptables.main()
                self.assertTrue(result.exception.args[0]['changed'])

        self.assertEqual(run_command.call_count, 1)
        self.assertEqual(run_command.call_args_list[0][0][0], [
            '/sbin/iptables',
            '-t',
            'filter',
            '-C',
            'INPUT',
            '-p',
            'tcp',
            '-j',
            'REJECT',
            '--reject-with',
            'tcp-reset',
        ])

</source>
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_iptables.py" startline="199" endline="247" pcid="6068">
    def test_insert_rule(self):
        """Test flush without parameters"""
        set_module_args({
            'chain': 'OUTPUT',
            'source': '1.2.3.4/32',
            'destination': '7.8.9.10/42',
            'jump': 'ACCEPT',
            'action': 'insert'
        })

        commands_results = [
            (1, '', ''),
            (0, '', '')
        ]

        with patch.object(basic.AnsibleModule, 'run_command') as run_command:
            run_command.side_effect = commands_results
            with self.assertRaises(AnsibleExitJson) as result:
                iptables.main()
                self.assertTrue(result.exception.args[0]['changed'])

        self.assertEqual(run_command.call_count, 2)
        self.assertEqual(run_command.call_args_list[0][0][0], [
            '/sbin/iptables',
            '-t',
            'filter',
            '-C',
            'OUTPUT',
            '-s',
            '1.2.3.4/32',
            '-d',
            '7.8.9.10/42',
            '-j',
            'ACCEPT'
        ])
        self.assertEqual(run_command.call_args_list[1][0][0], [
            '/sbin/iptables',
            '-t',
            'filter',
            '-I',
            'OUTPUT',
            '-s',
            '1.2.3.4/32',
            '-d',
            '7.8.9.10/42',
            '-j',
            'ACCEPT'
        ])

</source>
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_iptables.py" startline="248" endline="295" pcid="6069">
    def test_append_rule_check_mode(self):
        """Test append a redirection rule in check mode"""
        set_module_args({
            'chain': 'PREROUTING',
            'source': '1.2.3.4/32',
            'destination': '7.8.9.10/42',
            'jump': 'REDIRECT',
            'table': 'nat',
            'to_destination': '5.5.5.5/32',
            'protocol': 'udp',
            'destination_port': '22',
            'to_ports': '8600',
            '_ansible_check_mode': True,
        })

        commands_results = [
            (1, '', ''),
        ]

        with patch.object(basic.AnsibleModule, 'run_command') as run_command:
            run_command.side_effect = commands_results
            with self.assertRaises(AnsibleExitJson) as result:
                iptables.main()
                self.assertTrue(result.exception.args[0]['changed'])

        self.assertEqual(run_command.call_count, 1)
        self.assertEqual(run_command.call_args_list[0][0][0], [
            '/sbin/iptables',
            '-t',
            'nat',
            '-C',
            'PREROUTING',
            '-p',
            'udp',
            '-s',
            '1.2.3.4/32',
            '-d',
            '7.8.9.10/42',
            '-j',
            'REDIRECT',
            '--to-destination',
            '5.5.5.5/32',
            '--destination-port',
            '22',
            '--to-ports',
            '8600'
        ])

</source>
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_iptables.py" startline="132" endline="161" pcid="6066">
    def test_policy_table_changed_false(self):
        """Test flush without parameters and change == false"""
        set_module_args({
            'policy': 'ACCEPT',
            'chain': 'INPUT',
            '_ansible_check_mode': True,
        })
        commands_results = [
            (0, 'Chain INPUT (policy DROP)\n', ''),
        ]

        with patch.object(basic.AnsibleModule, 'run_command') as run_command:
            run_command.side_effect = commands_results
            with self.assertRaises(AnsibleExitJson) as result:
                iptables.main()
                self.assertTrue(result.exception.args[0]['changed'])

        self.assertEqual(run_command.call_count, 1)
        self.assertEqual(run_command.call_args_list[0][0][0], [
            '/sbin/iptables',
            '-t',
            'filter',
            '-L',
            'INPUT',
        ])

# TODO ADD test policy without chain fail
# TODO ADD test policy with chain don't exists
# TODO ADD test policy with wrong choice fail

</source>
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_iptables.py" startline="454" endline="513" pcid="6072">
    def test_remove_rule_check_mode(self):
        """Test flush without parameters check mode"""
        set_module_args({
            'chain': 'PREROUTING',
            'source': '1.2.3.4/32',
            'destination': '7.8.9.10/42',
            'jump': 'SNAT',
            'table': 'nat',
            'to_source': '5.5.5.5/32',
            'protocol': 'udp',
            'source_port': '22',
            'to_ports': '8600',
            'state': 'absent',
            'in_interface': 'eth0',
            'out_interface': 'eth1',
            'comment': 'this is a comment',
            '_ansible_check_mode': True,
        })

        commands_results = [
            (0, '', ''),
        ]

        with patch.object(basic.AnsibleModule, 'run_command') as run_command:
            run_command.side_effect = commands_results
            with self.assertRaises(AnsibleExitJson) as result:
                iptables.main()
                self.assertTrue(result.exception.args[0]['changed'])

        self.assertEqual(run_command.call_count, 1)
        self.assertEqual(run_command.call_args_list[0][0][0], [
            '/sbin/iptables',
            '-t',
            'nat',
            '-C',
            'PREROUTING',
            '-p',
            'udp',
            '-s',
            '1.2.3.4/32',
            '-d',
            '7.8.9.10/42',
            '-j',
            'SNAT',
            '--to-source',
            '5.5.5.5/32',
            '-i',
            'eth0',
            '-o',
            'eth1',
            '--source-port',
            '22',
            '--to-ports',
            '8600',
            '-m',
            'comment',
            '--comment',
            'this is a comment'
        ])

</source>
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_iptables.py" startline="296" endline="364" pcid="6070">
    def test_append_rule(self):
        """Test append a redirection rule"""
        set_module_args({
            'chain': 'PREROUTING',
            'source': '1.2.3.4/32',
            'destination': '7.8.9.10/42',
            'jump': 'REDIRECT',
            'table': 'nat',
            'to_destination': '5.5.5.5/32',
            'protocol': 'udp',
            'destination_port': '22',
            'to_ports': '8600'
        })

        commands_results = [
            (1, '', ''),
            (0, '', '')
        ]

        with patch.object(basic.AnsibleModule, 'run_command') as run_command:
            run_command.side_effect = commands_results
            with self.assertRaises(AnsibleExitJson) as result:
                iptables.main()
                self.assertTrue(result.exception.args[0]['changed'])

        self.assertEqual(run_command.call_count, 2)
        self.assertEqual(run_command.call_args_list[0][0][0], [
            '/sbin/iptables',
            '-t',
            'nat',
            '-C',
            'PREROUTING',
            '-p',
            'udp',
            '-s',
            '1.2.3.4/32',
            '-d',
            '7.8.9.10/42',
            '-j',
            'REDIRECT',
            '--to-destination',
            '5.5.5.5/32',
            '--destination-port',
            '22',
            '--to-ports',
            '8600'
        ])
        self.assertEqual(run_command.call_args_list[1][0][0], [
            '/sbin/iptables',
            '-t',
            'nat',
            '-A',
            'PREROUTING',
            '-p',
            'udp',
            '-s',
            '1.2.3.4/32',
            '-d',
            '7.8.9.10/42',
            '-j',
            'REDIRECT',
            '--to-destination',
            '5.5.5.5/32',
            '--destination-port',
            '22',
            '--to-ports',
            '8600'
        ])

</source>
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_iptables.py" startline="365" endline="453" pcid="6071">
    def test_remove_rule(self):
        """Test flush without parameters"""
        set_module_args({
            'chain': 'PREROUTING',
            'source': '1.2.3.4/32',
            'destination': '7.8.9.10/42',
            'jump': 'SNAT',
            'table': 'nat',
            'to_source': '5.5.5.5/32',
            'protocol': 'udp',
            'source_port': '22',
            'to_ports': '8600',
            'state': 'absent',
            'in_interface': 'eth0',
            'out_interface': 'eth1',
            'comment': 'this is a comment'
        })

        commands_results = [
            (0, '', ''),
            (0, '', ''),
        ]

        with patch.object(basic.AnsibleModule, 'run_command') as run_command:
            run_command.side_effect = commands_results
            with self.assertRaises(AnsibleExitJson) as result:
                iptables.main()
                self.assertTrue(result.exception.args[0]['changed'])

        self.assertEqual(run_command.call_count, 2)
        self.assertEqual(run_command.call_args_list[0][0][0], [
            '/sbin/iptables',
            '-t',
            'nat',
            '-C',
            'PREROUTING',
            '-p',
            'udp',
            '-s',
            '1.2.3.4/32',
            '-d',
            '7.8.9.10/42',
            '-j',
            'SNAT',
            '--to-source',
            '5.5.5.5/32',
            '-i',
            'eth0',
            '-o',
            'eth1',
            '--source-port',
            '22',
            '--to-ports',
            '8600',
            '-m',
            'comment',
            '--comment',
            'this is a comment'
        ])
        self.assertEqual(run_command.call_args_list[1][0][0], [
            '/sbin/iptables',
            '-t',
            'nat',
            '-D',
            'PREROUTING',
            '-p',
            'udp',
            '-s',
            '1.2.3.4/32',
            '-d',
            '7.8.9.10/42',
            '-j',
            'SNAT',
            '--to-source',
            '5.5.5.5/32',
            '-i',
            'eth0',
            '-o',
            'eth1',
            '--source-port',
            '22',
            '--to-ports',
            '8600',
            '-m',
            'comment',
            '--comment',
            'this is a comment'
        ])

</source>
</class>

<class classid="153" nclones="2" nlines="32" similarity="87">
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_iptables.py" startline="600" endline="638" pcid="6076">
    def test_jump_tee_gateway(self):
        """ Using gateway when JUMP is set to TEE """
        set_module_args({
            'table': 'mangle',
            'chain': 'PREROUTING',
            'in_interface': 'eth0',
            'protocol': 'udp',
            'match': 'state',
            'jump': 'TEE',
            'ctstate': ['NEW'],
            'destination_port': '9521',
            'gateway': '192.168.10.1',
            'destination': '127.0.0.1'
        })
        commands_results = [
            (0, '', ''),
        ]

        with patch.object(basic.AnsibleModule, 'run_command') as run_command:
            run_command.side_effect = commands_results
            with self.assertRaises(AnsibleExitJson) as result:
                iptables.main()
                self.assertTrue(result.exception.args[0]['changed'])

        self.assertEqual(run_command.call_count, 1)
        self.assertEqual(run_command.call_args_list[0][0][0], [
            '/sbin/iptables',
            '-t', 'mangle',
            '-C', 'PREROUTING',
            '-p', 'udp',
            '-d', '127.0.0.1',
            '-m', 'state',
            '-j', 'TEE',
            '--gateway', '192.168.10.1',
            '-i', 'eth0',
            '--destination-port', '9521',
            '--state', 'NEW'
        ])

</source>
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_iptables.py" startline="911" endline="946" pcid="6082">
    def test_destination_ports(self):
        """ Test multiport module usage with multiple ports """
        set_module_args({
            'chain': 'INPUT',
            'protocol': 'tcp',
            'in_interface': 'eth0',
            'source': '192.168.0.1/32',
            'destination_ports': ['80', '443', '8081:8085'],
            'jump': 'ACCEPT',
            'comment': 'this is a comment',
        })
        commands_results = [
            (0, '', ''),
        ]

        with patch.object(basic.AnsibleModule, 'run_command') as run_command:
            run_command.side_effect = commands_results
            with self.assertRaises(AnsibleExitJson) as result:
                iptables.main()
                self.assertTrue(result.exception.args[0]['changed'])

        self.assertEqual(run_command.call_count, 1)
        self.assertEqual(run_command.call_args_list[0][0][0], [
            '/sbin/iptables',
            '-t', 'filter',
            '-C', 'INPUT',
            '-p', 'tcp',
            '-s', '192.168.0.1/32',
            '-j', 'ACCEPT',
            '-m', 'multiport',
            '--dports', '80,443,8081:8085',
            '-i', 'eth0',
            '-m', 'comment',
            '--comment', 'this is a comment'
        ])

</source>
</class>

<class classid="154" nclones="3" nlines="13" similarity="85">
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_systemd.py" startline="10" endline="24" pcid="6084">
    def test_simple(self):
        lines = [
            'Type=simple',
            'Restart=no',
            'Requires=system.slice sysinit.target',
            'Description=Blah blah blah',
        ]
        parsed = parse_systemctl_show(lines)
        self.assertEqual(parsed, {
            'Type': 'simple',
            'Restart': 'no',
            'Requires': 'system.slice sysinit.target',
            'Description': 'Blah blah blah',
        })

</source>
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_systemd.py" startline="41" endline="52" pcid="6086">
    def test_single_line_with_brace(self):
        lines = [
            'Type=simple',
            'Description={ this is confusing',
            'Restart=no',
        ]
        parsed = parse_systemctl_show(lines)
        self.assertEqual(parsed, {
            'Type': 'simple',
            'Description': '{ this is confusing',
            'Restart': 'no',
        })
</source>
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_systemd.py" startline="25" endline="40" pcid="6085">
    def test_multiline_exec(self):
        # This was taken from a real service that specified "ExecStart=/bin/echo foo\nbar"
        lines = [
            'Type=simple',
            'ExecStart={ path=/bin/echo ; argv[]=/bin/echo foo',
            'bar ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }',
            'Description=blah',
        ]
        parsed = parse_systemctl_show(lines)
        self.assertEqual(parsed, {
            'Type': 'simple',
            'ExecStart': '{ path=/bin/echo ; argv[]=/bin/echo foo\n'
                         'bar ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }',
            'Description': 'blah',
        })

</source>
</class>

<class classid="155" nclones="6" nlines="11" similarity="72">
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_known_hosts.py" startline="24" endline="34" pcid="6120">
    def test_no_existing_file(self):
        path = "/tmp/this_file_does_not_exists_known_hosts"
        key = 'example.com ssh-rsa AAAAetc\n'
        diff = compute_diff(path, found_line=None, replace_or_add=False, state='present', key=key)
        self.assertEqual(diff, {
            'before_header': '/dev/null',
            'after_header': path,
            'before': '',
            'after': 'example.com ssh-rsa AAAAetc\n',
        })

</source>
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_known_hosts.py" startline="35" endline="47" pcid="6121">
    def test_key_addition(self):
        path = self._create_file(
            'two.example.com ssh-rsa BBBBetc\n'
        )
        key = 'one.example.com ssh-rsa AAAAetc\n'
        diff = compute_diff(path, found_line=None, replace_or_add=False, state='present', key=key)
        self.assertEqual(diff, {
            'before_header': path,
            'after_header': path,
            'before': 'two.example.com ssh-rsa BBBBetc\n',
            'after': 'two.example.com ssh-rsa BBBBetc\none.example.com ssh-rsa AAAAetc\n',
        })

</source>
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_known_hosts.py" startline="90" endline="102" pcid="6125">
    def test_key_removal_no_change(self):
        path = self._create_file(
            'two.example.com ssh-rsa BBBBetc\n'
        )
        key = 'one.example.com ssh-rsa AAAAetc\n'
        diff = compute_diff(path, found_line=None, replace_or_add=False, state='absent', key=key)
        self.assertEqual(diff, {
            'before_header': path,
            'after_header': path,
            'before': 'two.example.com ssh-rsa BBBBetc\n',
            'after': 'two.example.com ssh-rsa BBBBetc\n',
        })

</source>
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_known_hosts.py" startline="48" endline="61" pcid="6122">
    def test_no_change(self):
        path = self._create_file(
            'one.example.com ssh-rsa AAAAetc\n'
            'two.example.com ssh-rsa BBBBetc\n'
        )
        key = 'one.example.com ssh-rsa AAAAetc\n'
        diff = compute_diff(path, found_line=1, replace_or_add=False, state='present', key=key)
        self.assertEqual(diff, {
            'before_header': path,
            'after_header': path,
            'before': 'one.example.com ssh-rsa AAAAetc\ntwo.example.com ssh-rsa BBBBetc\n',
            'after': 'one.example.com ssh-rsa AAAAetc\ntwo.example.com ssh-rsa BBBBetc\n',
        })

</source>
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_known_hosts.py" startline="62" endline="75" pcid="6123">
    def test_key_change(self):
        path = self._create_file(
            'one.example.com ssh-rsa AAAaetc\n'
            'two.example.com ssh-rsa BBBBetc\n'
        )
        key = 'one.example.com ssh-rsa AAAAetc\n'
        diff = compute_diff(path, found_line=1, replace_or_add=True, state='present', key=key)
        self.assertEqual(diff, {
            'before_header': path,
            'after_header': path,
            'before': 'one.example.com ssh-rsa AAAaetc\ntwo.example.com ssh-rsa BBBBetc\n',
            'after': 'two.example.com ssh-rsa BBBBetc\none.example.com ssh-rsa AAAAetc\n',
        })

</source>
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_known_hosts.py" startline="76" endline="89" pcid="6124">
    def test_key_removal(self):
        path = self._create_file(
            'one.example.com ssh-rsa AAAAetc\n'
            'two.example.com ssh-rsa BBBBetc\n'
        )
        key = 'one.example.com ssh-rsa AAAAetc\n'
        diff = compute_diff(path, found_line=1, replace_or_add=False, state='absent', key=key)
        self.assertEqual(diff, {
            'before_header': path,
            'after_header': path,
            'before': 'one.example.com ssh-rsa AAAAetc\ntwo.example.com ssh-rsa BBBBetc\n',
            'after': 'two.example.com ssh-rsa BBBBetc\n',
        })

</source>
</class>

<class classid="156" nclones="2" nlines="19" similarity="78">
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_unarchive.py" startline="49" endline="70" pcid="6139">
    def test_no_zip_zipinfo_binary(self, mocker, fake_ansible_module, side_effect, expected_reason):
        mocker.patch("ansible.modules.unarchive.get_bin_path", side_effect=side_effect)
        fake_ansible_module.params = {
            "extra_opts": "",
            "exclude": "",
            "include": "",
            "io_buffer_size": 65536,
        }

        z = ZipArchive(
            src="",
            b_dest="",
            file_args="",
            module=fake_ansible_module,
        )
        can_handle, reason = z.can_handle_archive()

        assert can_handle is False
        assert expected_reason in reason
        assert z.cmd_path is None


</source>
<source file="systems/ansible-2.12.4rc1/test/units/modules/test_unarchive.py" startline="72" endline="93" pcid="6140">
    def test_no_tar_binary(self, mocker, fake_ansible_module):
        mocker.patch("ansible.modules.unarchive.get_bin_path", side_effect=ValueError)
        fake_ansible_module.params = {
            "extra_opts": "",
            "exclude": "",
            "include": "",
            "io_buffer_size": 65536,
        }
        fake_ansible_module.check_mode = False

        t = TgzArchive(
            src="",
            b_dest="",
            file_args="",
            module=fake_ansible_module,
        )
        can_handle, reason = t.can_handle_archive()

        assert can_handle is False
        assert 'Unable to find required' in reason
        assert t.cmd_path is None
        assert t.tar_type is None
</source>
</class>

<class classid="157" nclones="3" nlines="22" similarity="91">
<source file="systems/ansible-2.12.4rc1/test/sanity/code-smell/ansible-test-future-boilerplate.py" startline="8" endline="42" pcid="6173">
def main():
    for path in sys.argv[1:] or sys.stdin.read().splitlines():
        with open(path, 'rb') as path_fd:
            lines = path_fd.read().splitlines()

        missing = True
        if not lines:
            # Files are allowed to be empty of everything including boilerplate
            missing = False

        for text in lines:
            if text == b'from __future__ import annotations':
                missing = False
                break

        if missing:
            with open(path) as file:
                contents = file.read()

            # noinspection PyBroadException
            try:
                node = ast.parse(contents)

                # files consisting of only assignments have no need for future import boilerplate
                # the only exception would be division during assignment, but we'll overlook that for simplicity
                # the most likely case is that of a documentation only python file
                if all(isinstance(statement, ast.Assign) for statement in node.body):
                    missing = False
            except Exception:  # pylint: disable=broad-except
                pass  # the compile sanity test will report this error

        if missing:
            print('%s: missing: from __future__ import annotations' % path)


</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/controller/sanity/code-smell/metaclass-boilerplate.py" startline="8" endline="41" pcid="8149">
def main():
    for path in sys.argv[1:] or sys.stdin.read().splitlines():
        with open(path, 'rb') as path_fd:
            lines = path_fd.read().splitlines()

        missing = True
        if not lines:
            # Files are allowed to be empty of everything including boilerplate
            missing = False

        for text in lines:
            if text == b'__metaclass__ = type':
                missing = False
                break

        if missing:
            with open(path) as file:
                contents = file.read()

            # noinspection PyBroadException
            try:
                node = ast.parse(contents)

                # files consisting of only assignments have no need for metaclass boilerplate
                # the most likely case is that of a documentation only python file
                if all(isinstance(statement, ast.Assign) for statement in node.body):
                    missing = False
            except Exception:  # pylint: disable=broad-except
                pass  # the compile sanity test will report this error

        if missing:
            print('%s: missing: __metaclass__ = type' % path)


</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/controller/sanity/code-smell/future-import-boilerplate.py" startline="8" endline="43" pcid="8167">
def main():
    for path in sys.argv[1:] or sys.stdin.read().splitlines():
        with open(path, 'rb') as path_fd:
            lines = path_fd.read().splitlines()

        missing = True
        if not lines:
            # Files are allowed to be empty of everything including boilerplate
            missing = False

        for text in lines:
            if text in (b'from __future__ import (absolute_import, division, print_function)',
                        b'from __future__ import absolute_import, division, print_function'):
                missing = False
                break

        if missing:
            with open(path) as file:
                contents = file.read()

            # noinspection PyBroadException
            try:
                node = ast.parse(contents)

                # files consisting of only assignments have no need for future import boilerplate
                # the only exception would be division during assignment, but we'll overlook that for simplicity
                # the most likely case is that of a documentation only python file
                if all(isinstance(statement, ast.Assign) for statement in node.body):
                    missing = False
            except Exception:  # pylint: disable=broad-except
                pass  # the compile sanity test will report this error

        if missing:
            print('%s: missing: from __future__ import (absolute_import, division, print_function)' % path)


</source>
</class>

<class classid="158" nclones="2" nlines="23" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/vyos/vyos/plugins/cliconf/vyos.py" startline="146" endline="171" pcid="6181">
    def get(
        self,
        command=None,
        prompt=None,
        answer=None,
        sendonly=False,
        output=None,
        newline=True,
        check_all=False,
    ):
        if not command:
            raise ValueError("must provide value of command to execute")
        if output:
            raise ValueError(
                "'output' value %s is not supported for get" % output
            )

        return self.send_command(
            command=command,
            prompt=prompt,
            answer=answer,
            sendonly=sendonly,
            newline=newline,
            check_all=check_all,
        )

</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/cisco/ios/plugins/cliconf/ios.py" startline="241" endline="266" pcid="6776">
    def get(
        self,
        command=None,
        prompt=None,
        answer=None,
        sendonly=False,
        output=None,
        newline=True,
        check_all=False,
    ):
        if not command:
            raise ValueError("must provide value of command to execute")
        if output:
            raise ValueError(
                "'output' value %s is not supported for get" % output
            )

        return self.send_command(
            command=command,
            prompt=prompt,
            answer=answer,
            sendonly=sendonly,
            newline=newline,
            check_all=check_all,
        )

</source>
</class>

<class classid="159" nclones="2" nlines="20" similarity="95">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/vyos/vyos/plugins/cliconf/vyos.py" startline="272" endline="298" pcid="6185">
    def run_commands(self, commands=None, check_rc=True):
        if commands is None:
            raise ValueError("'commands' value is required")

        responses = list()
        for cmd in to_list(commands):
            if not isinstance(cmd, Mapping):
                cmd = {"command": cmd}

            output = cmd.pop("output", None)
            if output:
                raise ValueError(
                    "'output' value %s is not supported for run_commands"
                    % output
                )

            try:
                out = self.send_command(**cmd)
            except AnsibleConnectionFailure as e:
                if check_rc:
                    raise
                out = getattr(e, "err", e)

            responses.append(out)

        return responses

</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/cisco/ios/plugins/cliconf/ios.py" startline="371" endline="397" pcid="6782">
    def run_commands(self, commands=None, check_rc=True):
        if commands is None:
            raise ValueError("'commands' value is required")

        responses = list()
        for cmd in to_list(commands):
            if not isinstance(cmd, Mapping):
                cmd = {"command": cmd}

            output = cmd.pop("output", None)
            if output:
                raise ValueError(
                    "'output' value %s is not supported for run_commands"
                    % output
                )

            try:
                out = self.send_command(**cmd)
            except AnsibleConnectionFailure as e:
                if check_rc:
                    raise
                out = getattr(e, "err", to_text(e))

            responses.append(out)

        return responses

</source>
</class>

<class classid="160" nclones="2" nlines="11" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/vyos/vyos/plugins/cliconf/vyos.py" startline="322" endline="333" pcid="6188">
    def get_capabilities(self):
        result = super(Cliconf, self).get_capabilities()
        result["rpc"] += [
            "commit",
            "discard_changes",
            "get_diff",
            "run_commands",
        ]
        result["device_operations"] = self.get_device_operations()
        result.update(self.get_option_values())
        return json.dumps(result)

</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/cisco/ios/plugins/cliconf/ios.py" startline="322" endline="333" pcid="6780">
    def get_capabilities(self):
        result = super(Cliconf, self).get_capabilities()
        result["rpc"] += [
            "edit_banner",
            "get_diff",
            "run_commands",
            "get_defaults_flag",
        ]
        result["device_operations"] = self.get_device_operations()
        result.update(self.get_option_values())
        return json.dumps(result)

</source>
</class>

<class classid="161" nclones="2" nlines="72" similarity="94">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/vyos/vyos/plugins/action/vyos.py" startline="41" endline="129" pcid="6190">
    def run(self, tmp=None, task_vars=None):
        del tmp  # tmp no longer has any effect

        module_name = self._task.action.split(".")[-1]
        self._config_module = True if module_name == "vyos_config" else False
        persistent_connection = self._play_context.connection.split(".")[-1]
        warnings = []

        if persistent_connection == "network_cli":
            provider = self._task.args.get("provider", {})
            if any(provider.values()):
                display.warning(
                    "provider is unnecessary when using network_cli and will be ignored"
                )
                del self._task.args["provider"]
        elif self._play_context.connection == "local":
            provider = load_provider(vyos_provider_spec, self._task.args)
            pc = copy.deepcopy(self._play_context)
            pc.connection = "ansible.netcommon.network_cli"
            pc.network_os = "vyos.vyos.vyos"
            pc.remote_addr = provider["host"] or self._play_context.remote_addr
            pc.port = int(provider["port"] or self._play_context.port or 22)
            pc.remote_user = (
                provider["username"] or self._play_context.connection_user
            )
            pc.password = provider["password"] or self._play_context.password
            pc.private_key_file = (
                provider["ssh_keyfile"] or self._play_context.private_key_file
            )

            connection = self._shared_loader_obj.connection_loader.get(
                "ansible.netcommon.persistent",
                pc,
                sys.stdin,
                task_uuid=self._task._uuid,
            )

            # TODO: Remove below code after ansible minimal is cut out
            if connection is None:
                pc.connection = "network_cli"
                pc.network_os = "vyos"
                connection = self._shared_loader_obj.connection_loader.get(
                    "persistent", pc, sys.stdin, task_uuid=self._task._uuid
                )

            display.vvv(
                "using connection plugin %s (was local)" % pc.connection,
                pc.remote_addr,
            )

            command_timeout = (
                int(provider["timeout"])
                if provider["timeout"]
                else connection.get_option("persistent_command_timeout")
            )
            connection.set_options(
                direct={"persistent_command_timeout": command_timeout}
            )

            socket_path = connection.run()
            display.vvvv("socket_path: %s" % socket_path, pc.remote_addr)
            if not socket_path:
                return {
                    "failed": True,
                    "msg": "unable to open shell. Please see: "
                    + "https://docs.ansible.com/ansible/latest/network/user_guide/network_debug_troubleshooting.html#category-unable-to-open-shell",
                }

            task_vars["ansible_socket"] = socket_path
            warnings.append(
                [
                    "connection local support for this module is deprecated and will be removed in version 2.14, use connection %s"
                    % pc.connection
                ]
            )
        else:
            return {
                "failed": True,
                "msg": "Connection type %s is not valid for this module"
                % self._play_context.connection,
            }

        result = super(ActionModule, self).run(task_vars=task_vars)
        if warnings:
            if "warnings" in result:
                result["warnings"].extend(warnings)
            else:
                result["warnings"] = warnings
        return result
</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/cisco/ios/plugins/action/ios.py" startline="41" endline="133" pcid="6787">
    def run(self, tmp=None, task_vars=None):
        del tmp  # tmp no longer has any effect

        module_name = self._task.action.split(".")[-1]
        self._config_module = True if module_name == "ios_config" else False
        persistent_connection = self._play_context.connection.split(".")[-1]
        warnings = []

        if persistent_connection == "network_cli":
            provider = self._task.args.get("provider", {})
            if any(provider.values()):
                display.warning(
                    "provider is unnecessary when using network_cli and will be ignored"
                )
                del self._task.args["provider"]
        elif self._play_context.connection == "local":
            provider = load_provider(ios_provider_spec, self._task.args)
            pc = copy.deepcopy(self._play_context)
            pc.connection = "ansible.netcommon.network_cli"
            pc.network_os = "cisco.ios.ios"
            pc.remote_addr = provider["host"] or self._play_context.remote_addr
            pc.port = int(provider["port"] or self._play_context.port or 22)
            pc.remote_user = (
                provider["username"] or self._play_context.connection_user
            )
            pc.password = provider["password"] or self._play_context.password
            pc.private_key_file = (
                provider["ssh_keyfile"] or self._play_context.private_key_file
            )
            pc.become = provider["authorize"] or False
            if pc.become:
                pc.become_method = "enable"
            pc.become_pass = provider["auth_pass"]

            connection = self._shared_loader_obj.connection_loader.get(
                "ansible.netcommon.persistent",
                pc,
                sys.stdin,
                task_uuid=self._task._uuid,
            )

            # TODO: Remove below code after ansible minimal is cut out
            if connection is None:
                pc.connection = "network_cli"
                pc.network_os = "ios"
                connection = self._shared_loader_obj.connection_loader.get(
                    "persistent", pc, sys.stdin, task_uuid=self._task._uuid
                )

            display.vvv(
                "using connection plugin %s (was local)" % pc.connection,
                pc.remote_addr,
            )

            command_timeout = (
                int(provider["timeout"])
                if provider["timeout"]
                else connection.get_option("persistent_command_timeout")
            )
            connection.set_options(
                direct={"persistent_command_timeout": command_timeout}
            )

            socket_path = connection.run()
            display.vvvv("socket_path: %s" % socket_path, pc.remote_addr)
            if not socket_path:
                return {
                    "failed": True,
                    "msg": "unable to open shell. Please see: "
                    + "https://docs.ansible.com/ansible/latest/network/user_guide/network_debug_troubleshooting.html#category-unable-to-open-shell",
                }

            task_vars["ansible_socket"] = socket_path
            warnings.append(
                [
                    "connection local support for this module is deprecated and will be removed in version 2.14, use connection %s"
                    % pc.connection
                ]
            )
        else:
            return {
                "failed": True,
                "msg": "Connection type %s is not valid for this module"
                % self._play_context.connection,
            }

        result = super(ActionModule, self).run(task_vars=task_vars)
        if warnings:
            if "warnings" in result:
                result["warnings"].extend(warnings)
            else:
                result["warnings"] = warnings
        return result
</source>
</class>

<class classid="162" nclones="2" nlines="11" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/vyos/vyos/plugins/module_utils/network/vyos/utils/utils.py" startline="114" endline="134" pcid="6197">
def list_diff_have_only(want_list, have_list):
    """
    This function generated the list containing values
    that are only in have list.
    :param want_list:
    :param have_list:
    :return: new list with values which are only in have list
    """
    if have_list and not want_list:
        diff = have_list
    elif not have_list:
        diff = None
    else:
        diff = [
            i
            for i in have_list + want_list
            if i in have_list and i not in want_list
        ]
    return diff


</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/vyos/vyos/plugins/module_utils/network/vyos/utils/utils.py" startline="135" endline="155" pcid="6198">
def list_diff_want_only(want_list, have_list):
    """
    This function generated the list containing values
    that are only in want list.
    :param want_list:
    :param have_list:
    :return: new list with values which are only in want list
    """
    if have_list and not want_list:
        diff = None
    elif not have_list:
        diff = want_list
    else:
        diff = [
            i
            for i in have_list + want_list
            if i in want_list and i not in have_list
        ]
    return diff


</source>
</class>

<class classid="163" nclones="2" nlines="16" similarity="81">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/vyos/vyos/plugins/module_utils/network/vyos/config/lldp_interfaces/lldp_interfaces.py" startline="391" endline="408" pcid="6226">
    def _add_civic_address(self, name, want, have):
        commands = []
        for item in want:
            ca_type = item["ca_type"]
            ca_value = item["ca_value"]
            obj_in_have = search_dict_tv_in_list(
                ca_type, ca_value, have, "ca_type", "ca_value"
            )
            if not obj_in_have:
                commands.append(
                    self._compute_command(
                        key=name + " location civic-based ca-type",
                        attrib=str(ca_type) + " ca-value",
                        value=ca_value,
                    )
                )
        return commands

</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/vyos/vyos/plugins/module_utils/network/vyos/config/lldp_interfaces/lldp_interfaces.py" startline="409" endline="427" pcid="6227">
    def _update_civic_address(self, name, want, have):
        commands = []
        for item in have:
            ca_type = item["ca_type"]
            ca_value = item["ca_value"]
            in_want = search_dict_tv_in_list(
                ca_type, ca_value, want, "ca_type", "ca_value"
            )
            if not in_want:
                commands.append(
                    self._compute_command(
                        name,
                        "location civic-based ca-type",
                        str(ca_type),
                        remove=True,
                    )
                )
        return commands

</source>
</class>

<class classid="164" nclones="3" nlines="10" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/vyos/vyos/plugins/module_utils/network/vyos/vyos.py" startline="59" endline="72" pcid="6230">
def get_connection(module):
    if hasattr(module, "_vyos_connection"):
        return module._vyos_connection

    capabilities = get_capabilities(module)
    network_api = capabilities.get("network_api")
    if network_api == "cliconf":
        module._vyos_connection = Connection(module._socket_path)
    else:
        module.fail_json(msg="Invalid connection type %s" % network_api)

    return module._vyos_connection


</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/network/netconf/netconf.py" startline="39" endline="52" pcid="6760">
def get_connection(module):
    if hasattr(module, "_netconf_connection"):
        return module._netconf_connection

    capabilities = get_capabilities(module)
    network_api = capabilities.get("network_api")
    if network_api == "netconf":
        module._netconf_connection = NetconfConnection(module._socket_path)
    else:
        module.fail_json(msg="Invalid connection type %s" % network_api)

    return module._netconf_connection


</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/cisco/ios/plugins/module_utils/network/ios/ios.py" startline="68" endline="81" pcid="6789">
def get_connection(module):
    if hasattr(module, "_ios_connection"):
        return module._ios_connection

    capabilities = get_capabilities(module)
    network_api = capabilities.get("network_api")
    if network_api == "cliconf":
        module._ios_connection = Connection(module._socket_path)
    else:
        module.fail_json(msg="Invalid connection type %s" % network_api)

    return module._ios_connection


</source>
</class>

<class classid="165" nclones="7" nlines="12" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/vyos/vyos/plugins/module_utils/network/vyos/facts/lag_interfaces/lag_interfaces.py" startline="30" endline="43" pcid="6235">
    def __init__(self, module, subspec="config", options="options"):
        self._module = module
        self.argument_spec = Lag_interfacesArgs.argument_spec
        spec = deepcopy(self.argument_spec)
        if subspec:
            if options:
                facts_argument_spec = spec[subspec][options]
            else:
                facts_argument_spec = spec[subspec]
        else:
            facts_argument_spec = spec

        self.generated_spec = utils.generate_dict(facts_argument_spec)

</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/vyos/vyos/plugins/module_utils/network/vyos/facts/lldp_interfaces/lldp_interfaces.py" startline="33" endline="46" pcid="6286">
    def __init__(self, module, subspec="config", options="options"):
        self._module = module
        self.argument_spec = Lldp_interfacesArgs.argument_spec
        spec = deepcopy(self.argument_spec)
        if subspec:
            if options:
                facts_argument_spec = spec[subspec][options]
            else:
                facts_argument_spec = spec[subspec]
        else:
            facts_argument_spec = spec

        self.generated_spec = utils.generate_dict(facts_argument_spec)

</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/vyos/vyos/plugins/module_utils/network/vyos/facts/l3_interfaces/l3_interfaces.py" startline="36" endline="49" pcid="6299">
    def __init__(self, module, subspec="config", options="options"):
        self._module = module
        self.argument_spec = L3_interfacesArgs.argument_spec
        spec = deepcopy(self.argument_spec)
        if subspec:
            if options:
                facts_argument_spec = spec[subspec][options]
            else:
                facts_argument_spec = spec[subspec]
        else:
            facts_argument_spec = spec

        self.generated_spec = utils.generate_dict(facts_argument_spec)

</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/vyos/vyos/plugins/module_utils/network/vyos/facts/interfaces/interfaces.py" startline="32" endline="45" pcid="6294">
    def __init__(self, module, subspec="config", options="options"):
        self._module = module
        self.argument_spec = InterfacesArgs.argument_spec
        spec = deepcopy(self.argument_spec)
        if subspec:
            if options:
                facts_argument_spec = spec[subspec][options]
            else:
                facts_argument_spec = spec[subspec]
        else:
            facts_argument_spec = spec

        self.generated_spec = utils.generate_dict(facts_argument_spec)

</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/vyos/vyos/plugins/module_utils/network/vyos/facts/static_routes/static_routes.py" startline="33" endline="46" pcid="6279">
    def __init__(self, module, subspec="config", options="options"):
        self._module = module
        self.argument_spec = Static_routesArgs.argument_spec
        spec = deepcopy(self.argument_spec)
        if subspec:
            if options:
                facts_argument_spec = spec[subspec][options]
            else:
                facts_argument_spec = spec[subspec]
        else:
            facts_argument_spec = spec

        self.generated_spec = utils.generate_dict(facts_argument_spec)

</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/vyos/vyos/plugins/module_utils/network/vyos/facts/firewall_rules/firewall_rules.py" startline="30" endline="43" pcid="6253">
    def __init__(self, module, subspec="config", options="options"):
        self._module = module
        self.argument_spec = Firewall_rulesArgs.argument_spec
        spec = deepcopy(self.argument_spec)
        if subspec:
            if options:
                facts_argument_spec = spec[subspec][options]
            else:
                facts_argument_spec = spec[subspec]
        else:
            facts_argument_spec = spec

        self.generated_spec = utils.generate_dict(facts_argument_spec)

</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/vyos/vyos/plugins/module_utils/network/vyos/facts/lldp_global/lldp_global.py" startline="31" endline="44" pcid="6274">
    def __init__(self, module, subspec="config", options="options"):
        self._module = module
        self.argument_spec = Lldp_globalArgs.argument_spec
        spec = deepcopy(self.argument_spec)
        if subspec:
            if options:
                facts_argument_spec = spec[subspec][options]
            else:
                facts_argument_spec = spec[subspec]
        else:
            facts_argument_spec = spec

        self.generated_spec = utils.generate_dict(facts_argument_spec)

</source>
</class>

<class classid="166" nclones="2" nlines="14" similarity="85">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/vyos/vyos/plugins/module_utils/network/vyos/facts/firewall_rules/firewall_rules.py" startline="135" endline="155" pcid="6258">
    def parse_rules_lst(self, conf):
        """
        This function forms the regex to fetch the 'rules' with in
        'rule-sets'
        :param conf: configuration data.
        :return: generated rule list configuration.
        """
        r_lst = []
        rules = findall(r"rule (?:\'*)(\d+)(?:\'*)", conf, M)
        if rules:
            rules_lst = []
            for r in set(rules):
                r_regex = r" %s .+$" % r
                cfg = "\n".join(findall(r_regex, conf, M))
                obj = self.parse_rules(cfg)
                obj["number"] = int(r)
                if obj:
                    rules_lst.append(obj)
            r_lst = sorted(rules_lst, key=lambda i: i["number"])
        return r_lst

</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/vyos/vyos/plugins/module_utils/network/vyos/facts/interfaces/interfaces.py" startline="102" endline="118" pcid="6297">
    def parse_vifs(self, conf):
        vif_names = findall(r"vif (?:\'*)(\d+)(?:\'*)", conf, M)
        vifs_list = None

        if vif_names:
            vifs_list = []
            for vif in set(vif_names):
                vif_regex = r" %s .+$" % vif
                cfg = "\n".join(findall(vif_regex, conf, M))
                obj = self.parse_attribs(["description", "mtu"], cfg)
                obj["vlan_id"] = int(vif)
                if obj:
                    vifs_list.append(obj)
            vifs_list = sorted(vifs_list, key=lambda i: i["vlan_id"])

        return vifs_list

</source>
</class>

<class classid="167" nclones="2" nlines="27" similarity="77">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/vyos/vyos/plugins/module_utils/network/vyos/facts/interfaces/interfaces.py" startline="46" endline="82" pcid="6295">
    def populate_facts(self, connection, ansible_facts, data=None):
        """ Populate the facts for interfaces
        :param connection: the device connection
        :param ansible_facts: Facts dictionary
        :param data: previously collected conf
        :rtype: dictionary
        :returns: facts
        """
        if not data:
            data = connection.get_config(flags=["| grep interfaces"])

        objs = []
        interface_names = findall(
            r"^set interfaces (?:ethernet|bonding|vti|loopback|vxlan) (?:\'*)(\S+)(?:\'*)",
            data,
            M,
        )
        if interface_names:
            for interface in set(interface_names):
                intf_regex = r" %s .+$" % interface.strip("'")
                cfg = findall(intf_regex, data, M)
                obj = self.render_config(cfg)
                obj["name"] = interface.strip("'")
                if obj:
                    objs.append(obj)
        facts = {}
        if objs:
            facts["interfaces"] = []
            params = utils.validate_config(
                self.argument_spec, {"config": objs}
            )
            for cfg in params["config"]:
                facts["interfaces"].append(utils.remove_empties(cfg))

        ansible_facts["ansible_network_resources"].update(facts)
        return ansible_facts

</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/vyos/vyos/plugins/module_utils/network/vyos/facts/l3_interfaces/l3_interfaces.py" startline="50" endline="89" pcid="6300">
    def populate_facts(self, connection, ansible_facts, data=None):
        """ Populate the facts for l3_interfaces
        :param connection: the device connection
        :param ansible_facts: Facts dictionary
        :param data: previously collected conf
        :rtype: dictionary
        :returns: facts
        """
        if not data:
            data = connection.get_config()

        # operate on a collection of resource x
        objs = []
        interface_names = re.findall(
            r"set interfaces (?:ethernet|bonding|vti|vxlan) (?:\'*)(\S+)(?:\'*)",
            data,
            re.M,
        )
        if interface_names:
            for interface in set(interface_names):
                intf_regex = r" %s .+$" % interface
                cfg = re.findall(intf_regex, data, re.M)
                obj = self.render_config(cfg)
                obj["name"] = interface.strip("'")
                if obj:
                    objs.append(obj)

        ansible_facts["ansible_network_resources"].pop("l3_interfaces", None)
        facts = {}
        if objs:
            facts["l3_interfaces"] = []
            params = utils.validate_config(
                self.argument_spec, {"config": objs}
            )
            for cfg in params["config"]:
                facts["l3_interfaces"].append(utils.remove_empties(cfg))

        ansible_facts["ansible_network_resources"].update(facts)
        return ansible_facts

</source>
</class>

<class classid="168" nclones="2" nlines="40" similarity="87">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/vyos/vyos/plugins/modules/vyos_command.py" startline="168" endline="221" pcid="6306">
def main():
    spec = dict(
        commands=dict(type="list", required=True),
        wait_for=dict(type="list", aliases=["waitfor"]),
        match=dict(default="all", choices=["all", "any"]),
        retries=dict(default=10, type="int"),
        interval=dict(default=1, type="int"),
    )

    spec.update(vyos_argument_spec)

    module = AnsibleModule(argument_spec=spec, supports_check_mode=True)

    warnings = list()
    result = {"changed": False, "warnings": warnings}
    commands = parse_commands(module, warnings)
    wait_for = module.params["wait_for"] or list()

    try:
        conditionals = [Conditional(c) for c in wait_for]
    except AttributeError as exc:
        module.fail_json(msg=to_text(exc))

    retries = module.params["retries"]
    interval = module.params["interval"]
    match = module.params["match"]

    for _ in range(retries):
        responses = run_commands(module, commands)

        for item in list(conditionals):
            if item(responses):
                if match == "any":
                    conditionals = list()
                    break
                conditionals.remove(item)

        if not conditionals:
            break

        time.sleep(interval)

    if conditionals:
        failed_conditions = [item.raw for item in conditionals]
        msg = "One or more conditional statements have not been satisfied"
        module.fail_json(msg=msg, failed_conditions=failed_conditions)

    result.update(
        {"stdout": responses, "stdout_lines": list(to_lines(responses)),}
    )

    module.exit_json(**result)


</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/cisco/ios/plugins/modules/ios_command.py" startline="169" endline="227" pcid="6807">
def main():
    """main entry point for module execution
    """
    argument_spec = dict(
        commands=dict(type="list", required=True),
        wait_for=dict(type="list", aliases=["waitfor"]),
        match=dict(default="all", choices=["all", "any"]),
        retries=dict(default=10, type="int"),
        interval=dict(default=1, type="int"),
    )

    argument_spec.update(ios_argument_spec)

    module = AnsibleModule(
        argument_spec=argument_spec, supports_check_mode=True
    )

    warnings = list()
    result = {"changed": False, "warnings": warnings}
    commands = parse_commands(module, warnings)
    wait_for = module.params["wait_for"] or list()

    try:
        conditionals = [Conditional(c) for c in wait_for]
    except AttributeError as exc:
        module.fail_json(msg=to_text(exc))

    retries = module.params["retries"]
    interval = module.params["interval"]
    match = module.params["match"]

    while retries > 0:
        responses = run_commands(module, commands)

        for item in list(conditionals):
            if item(responses):
                if match == "any":
                    conditionals = list()
                    break
                conditionals.remove(item)

        if not conditionals:
            break

        time.sleep(interval)
        retries -= 1

    if conditionals:
        failed_conditions = [item.raw for item in conditionals]
        msg = "One or more conditional statements have not been satisfied"
        module.fail_json(msg=msg, failed_conditions=failed_conditions)

    result.update(
        {"stdout": responses, "stdout_lines": list(to_lines(responses))}
    )

    module.exit_json(**result)


</source>
</class>

<class classid="169" nclones="2" nlines="38" similarity="94">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/action/net_put.py" startline="148" endline="193" pcid="6357">
    def _handle_existing_file(self, conn, source, dest, proto, timeout):
        """
        Determines whether the source and destination file match.

        :return: False if source and dest both exist and have matching sha1 sums, True otherwise.
        """
        cwd = self._loader.get_basedir()
        filename = str(uuid.uuid4())
        tmp_source_file = os.path.join(cwd, filename)
        try:
            conn.get_file(
                source=dest,
                destination=tmp_source_file,
                proto=proto,
                timeout=timeout,
            )
        except ConnectionError as exc:
            error = to_text(exc)
            if error.endswith("No such file or directory"):
                if os.path.exists(tmp_source_file):
                    os.remove(tmp_source_file)
                return True

        try:
            with open(source, "r") as f:
                new_content = f.read()
            with open(tmp_source_file, "r") as f:
                old_content = f.read()
        except (IOError, OSError):
            os.remove(tmp_source_file)
            raise

        sha1 = hashlib.sha1()
        old_content_b = to_bytes(old_content, errors="surrogate_or_strict")
        sha1.update(old_content_b)
        checksum_old = sha1.digest()

        sha1 = hashlib.sha1()
        new_content_b = to_bytes(new_content, errors="surrogate_or_strict")
        sha1.update(new_content_b)
        checksum_new = sha1.digest()
        os.remove(tmp_source_file)
        if checksum_old == checksum_new:
            return False
        return True

</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/action/net_get.py" startline="126" endline="174" pcid="6373">
    def _handle_existing_file(self, conn, source, dest, proto, timeout):
        """
        Determines whether the source and destination file match.

        :return: False if source and dest both exist and have matching sha1 sums, True otherwise.
        """
        if not os.path.exists(dest):
            return True

        cwd = self._loader.get_basedir()
        filename = str(uuid.uuid4())
        tmp_dest_file = os.path.join(cwd, filename)
        try:
            conn.get_file(
                source=source,
                destination=tmp_dest_file,
                proto=proto,
                timeout=timeout,
            )
        except ConnectionError as exc:
            error = to_text(exc)
            if error.endswith("No such file or directory"):
                if os.path.exists(tmp_dest_file):
                    os.remove(tmp_dest_file)
                return True

        try:
            with open(tmp_dest_file, "r") as f:
                new_content = f.read()
            with open(dest, "r") as f:
                old_content = f.read()
        except (IOError, OSError):
            os.remove(tmp_dest_file)
            raise

        sha1 = hashlib.sha1()
        old_content_b = to_bytes(old_content, errors="surrogate_or_strict")
        sha1.update(old_content_b)
        checksum_old = sha1.digest()

        sha1 = hashlib.sha1()
        new_content_b = to_bytes(new_content, errors="surrogate_or_strict")
        sha1.update(new_content_b)
        checksum_new = sha1.digest()
        os.remove(tmp_dest_file)
        if checksum_old == checksum_new:
            return False
        return True

</source>
</class>

<class classid="170" nclones="4" nlines="16" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/action/net_put.py" startline="217" endline="235" pcid="6360">
    def _get_network_os(self, task_vars):
        if "network_os" in self._task.args and self._task.args["network_os"]:
            display.vvvv("Getting network OS from task argument")
            network_os = self._task.args["network_os"]
        elif self._play_context.network_os:
            display.vvvv("Getting network OS from inventory")
            network_os = self._play_context.network_os
        elif (
            "network_os" in task_vars.get("ansible_facts", {})
            and task_vars["ansible_facts"]["network_os"]
        ):
            display.vvvv("Getting network OS from fact")
            network_os = task_vars["ansible_facts"]["network_os"]
        else:
            raise AnsibleError(
                "ansible_network_os must be specified on this host"
            )

        return network_os
</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/action/net_get.py" startline="181" endline="199" pcid="6375">
    def _get_network_os(self, task_vars):
        if "network_os" in self._task.args and self._task.args["network_os"]:
            display.vvvv("Getting network OS from task argument")
            network_os = self._task.args["network_os"]
        elif self._play_context.network_os:
            display.vvvv("Getting network OS from inventory")
            network_os = self._play_context.network_os
        elif (
            "network_os" in task_vars.get("ansible_facts", {})
            and task_vars["ansible_facts"]["network_os"]
        ):
            display.vvvv("Getting network OS from fact")
            network_os = task_vars["ansible_facts"]["network_os"]
        else:
            raise AnsibleError(
                "ansible_network_os must be specified on this host"
            )

        return network_os
</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/action/network.py" startline="191" endline="209" pcid="6365">
    def _get_network_os(self, task_vars):
        if "network_os" in self._task.args and self._task.args["network_os"]:
            display.vvvv("Getting network OS from task argument")
            network_os = self._task.args["network_os"]
        elif self._play_context.network_os:
            display.vvvv("Getting network OS from inventory")
            network_os = self._play_context.network_os
        elif (
            "network_os" in task_vars.get("ansible_facts", {})
            and task_vars["ansible_facts"]["network_os"]
        ):
            display.vvvv("Getting network OS from fact")
            network_os = task_vars["ansible_facts"]["network_os"]
        else:
            raise AnsibleError(
                "ansible_network_os must be specified on this host"
            )

        return network_os
</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/action/net_base.py" startline="55" endline="74" pcid="6367">
    def _get_network_os(self, task_vars):
        if "network_os" in self._task.args and self._task.args["network_os"]:
            display.vvvv("Getting network OS from task argument")
            network_os = self._task.args["network_os"]
        elif self._play_context.network_os:
            display.vvvv("Getting network OS from inventory")
            network_os = self._play_context.network_os
        elif (
            "network_os" in task_vars.get("ansible_facts", {})
            and task_vars["ansible_facts"]["network_os"]
        ):
            display.vvvv("Getting network OS from fact")
            network_os = task_vars["ansible_facts"]["network_os"]
        else:
            raise AnsibleError(
                "ansible_network_os must be specified on this host to use platform agnostic modules"
            )

        return network_os

</source>
</class>

<class classid="171" nclones="3" nlines="10" similarity="70">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/filter/ipaddr.py" startline="270" endline="281" pcid="6419">
def _next_usable_query(v, vtype):
    if vtype == "address":
        "Does it make sense to raise an error"
        raise errors.AnsibleFilterError("Not a network address")
    elif vtype == "network":
        if v.size > 1:
            first_usable, last_usable = _first_last(v)
            next_ip = int(netaddr.IPAddress(int(v.ip) + 1))
            if next_ip >= first_usable and next_ip <= last_usable:
                return str(netaddr.IPAddress(int(v.ip) + 1))


</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/filter/ipaddr.py" startline="334" endline="345" pcid="6425">
def _range_usable_query(v, vtype):
    if vtype == "address":
        "Does it make sense to raise an error"
        raise errors.AnsibleFilterError("Not a network address")
    elif vtype == "network":
        if v.size > 1:
            first_usable, last_usable = _first_last(v)
            first_usable = str(netaddr.IPAddress(first_usable))
            last_usable = str(netaddr.IPAddress(last_usable))
            return "{0}-{1}".format(first_usable, last_usable)


</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/filter/ipaddr.py" startline="305" endline="316" pcid="6422">
def _previous_usable_query(v, vtype):
    if vtype == "address":
        "Does it make sense to raise an error"
        raise errors.AnsibleFilterError("Not a network address")
    elif vtype == "network":
        if v.size > 1:
            first_usable, last_usable = _first_last(v)
            previous_ip = int(netaddr.IPAddress(int(v.ip) - 1))
            if previous_ip >= first_usable and previous_ip <= last_usable:
                return str(netaddr.IPAddress(int(v.ip) - 1))


</source>
</class>

<class classid="172" nclones="2" nlines="20" similarity="75">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/filter/ipaddr.py" startline="864" endline="891" pcid="6450">
def nthhost(value, query=""):
    """ Get the nth host within a given network """
    try:
        vtype = ipaddr(value, "type")
        if vtype == "address":
            v = ipaddr(value, "cidr")
        elif vtype == "network":
            v = ipaddr(value, "subnet")

        value = netaddr.IPNetwork(v)
    except Exception:
        return False

    if not query:
        return False

    try:
        nth = int(query)
        if value.size > nth:
            return value[nth]

    except ValueError:
        return False

    return False


# Returns the next nth usable ip within a network described by value.
</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/filter/ipaddr.py" startline="1063" endline="1092" pcid="6458">
def slaac(value, query=""):
    """ Get the SLAAC address within given network """
    try:
        vtype = ipaddr(value, "type")
        if vtype == "address":
            v = ipaddr(value, "cidr")
        elif vtype == "network":
            v = ipaddr(value, "subnet")

        if ipaddr(value, "version") != 6:
            return False

        value = netaddr.IPNetwork(v)
    except Exception:
        return False

    if not query:
        return False

    try:
        mac = hwaddr(query, alias="slaac")

        eui = netaddr.EUI(mac)
    except Exception:
        return False

    return eui.ipv6(value.network)


# ---- HWaddr / MAC address filters ----
</source>
</class>

<class classid="173" nclones="2" nlines="17" similarity="88">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/filter/ipaddr.py" startline="892" endline="913" pcid="6451">
def next_nth_usable(value, offset):
    try:
        vtype = ipaddr(value, "type")
        if vtype == "address":
            v = ipaddr(value, "cidr")
        elif vtype == "network":
            v = ipaddr(value, "subnet")

        v = netaddr.IPNetwork(v)
    except Exception:
        return False

    if type(offset) != int:
        raise errors.AnsibleFilterError("Must pass in an integer")
    if v.size > 1:
        first_usable, last_usable = _first_last(v)
        nth_ip = int(netaddr.IPAddress(int(v.ip) + offset))
        if nth_ip >= first_usable and nth_ip <= last_usable:
            return str(netaddr.IPAddress(int(v.ip) + offset))


# Returns the previous nth usable ip within a network described by value.
</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/filter/ipaddr.py" startline="914" endline="934" pcid="6452">
def previous_nth_usable(value, offset):
    try:
        vtype = ipaddr(value, "type")
        if vtype == "address":
            v = ipaddr(value, "cidr")
        elif vtype == "network":
            v = ipaddr(value, "subnet")

        v = netaddr.IPNetwork(v)
    except Exception:
        return False

    if type(offset) != int:
        raise errors.AnsibleFilterError("Must pass in an integer")
    if v.size > 1:
        first_usable, last_usable = _first_last(v)
        nth_ip = int(netaddr.IPAddress(int(v.ip) - offset))
        if nth_ip >= first_usable and nth_ip <= last_usable:
            return str(netaddr.IPAddress(int(v.ip) - offset))


</source>
</class>

<class classid="174" nclones="2" nlines="12" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/filter/ipaddr.py" startline="970" endline="996" pcid="6455">
def network_in_usable(value, test):
    """
    Checks whether 'test' is a useable address or addresses in 'value'

    :param: value: The string representation of an address or network to test against.
    :param test: The string representation of an address or network to validate if it is within the range of 'value'.

    :return: bool
    """
    # normalize value and test variables into an ipaddr
    v = _address_normalizer(value)
    w = _address_normalizer(test)

    # get first and last addresses as integers to compare value and test; or cathes value when case is /32
    v_first = ipaddr(ipaddr(v, "first_usable") or ipaddr(v, "address"), "int")
    v_last = ipaddr(ipaddr(v, "last_usable") or ipaddr(v, "address"), "int")
    w_first = ipaddr(ipaddr(w, "network") or ipaddr(w, "address"), "int")
    w_last = ipaddr(ipaddr(w, "broadcast") or ipaddr(w, "address"), "int")

    if _range_checker(w_first, v_first, v_last) and _range_checker(
        w_last, v_first, v_last
    ):
        return True
    else:
        return False


</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/filter/ipaddr.py" startline="997" endline="1023" pcid="6456">
def network_in_network(value, test):
    """
    Checks whether the 'test' address or addresses are in 'value', including broadcast and network

    :param: value: The network address or range to test against.
    :param test: The address or network to validate if it is within the range of 'value'.

    :return: bool
    """
    # normalize value and test variables into an ipaddr
    v = _address_normalizer(value)
    w = _address_normalizer(test)

    # get first and last addresses as integers to compare value and test; or cathes value when case is /32
    v_first = ipaddr(ipaddr(v, "network") or ipaddr(v, "address"), "int")
    v_last = ipaddr(ipaddr(v, "broadcast") or ipaddr(v, "address"), "int")
    w_first = ipaddr(ipaddr(w, "network") or ipaddr(w, "address"), "int")
    w_last = ipaddr(ipaddr(w, "broadcast") or ipaddr(w, "address"), "int")

    if _range_checker(w_first, v_first, v_last) and _range_checker(
        w_last, v_first, v_last
    ):
        return True
    else:
        return False


</source>
</class>

<class classid="175" nclones="2" nlines="13" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="112" endline="126" pcid="6469">
def _compat_to_bytes(intval, length, endianess):
    assert isinstance(intval, _compat_int_types)
    assert endianess == "big"
    if length == 4:
        if intval < 0 or intval >= 2 ** 32:
            raise struct.error("integer out of range for 'I' format code")
        return struct.pack(b"!I", intval)
    elif length == 16:
        if intval < 0 or intval >= 2 ** 128:
            raise struct.error("integer out of range for 'QQ' format code")
        return struct.pack(b"!QQ", intval >> 64, intval & 0xFFFFFFFFFFFFFFFF)
    else:
        raise NotImplementedError()


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="105" endline="119" pcid="6870">
def _compat_to_bytes(intval, length, endianess):
    assert isinstance(intval, _compat_int_types)
    assert endianess == 'big'
    if length == 4:
        if intval < 0 or intval >= 2 ** 32:
            raise struct.error("integer out of range for 'I' format code")
        return struct.pack(b'!I', intval)
    elif length == 16:
        if intval < 0 or intval >= 2 ** 128:
            raise struct.error("integer out of range for 'QQ' format code")
        return struct.pack(b'!QQ', intval >> 64, intval & 0xffffffffffffffff)
    else:
        raise NotImplementedError()


</source>
</class>

<class classid="176" nclones="6" nlines="13" similarity="78">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="202" endline="239" pcid="6479">
def ip_address(address):
    """Take an IP string/int and return an object of the correct type.

    Args:
        address: A string or integer, the IP address.  Either IPv4 or
          IPv6 addresses may be supplied; integers less than 2**32 will
          be considered to be IPv4 by default.

    Returns:
        An IPv4Address or IPv6Address object.

    Raises:
        ValueError: if the *address* passed isn't either a v4 or a v6
          address

    """
    try:
        return IPv4Address(address)
    except (AddressValueError, NetmaskValueError):
        pass

    try:
        return IPv6Address(address)
    except (AddressValueError, NetmaskValueError):
        pass

    if isinstance(address, bytes):
        raise AddressValueError(
            "%r does not appear to be an IPv4 or IPv6 address. "
            "Did you pass in a bytes (str in Python 2) instead of"
            " a unicode object?" % address
        )

    raise ValueError(
        "%r does not appear to be an IPv4 or IPv6 address" % address
    )


</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="278" endline="313" pcid="6481">
def ip_interface(address):
    """Take an IP string/int and return an object of the correct type.

    Args:
        address: A string or integer, the IP address.  Either IPv4 or
          IPv6 addresses may be supplied; integers less than 2**32 will
          be considered to be IPv4 by default.

    Returns:
        An IPv4Interface or IPv6Interface object.

    Raises:
        ValueError: if the string passed isn't either a v4 or a v6
          address.

    Notes:
        The IPv?Interface classes describe an Address on a particular
        Network, so they're basically a combination of both the Address
        and Network classes.

    """
    try:
        return IPv4Interface(address)
    except (AddressValueError, NetmaskValueError):
        pass

    try:
        return IPv6Interface(address)
    except (AddressValueError, NetmaskValueError):
        pass

    raise ValueError(
        "%r does not appear to be an IPv4 or IPv6 interface" % address
    )


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="192" endline="227" pcid="6880">
def ip_address(address):
    """Take an IP string/int and return an object of the correct type.

    Args:
        address: A string or integer, the IP address.  Either IPv4 or
          IPv6 addresses may be supplied; integers less than 2**32 will
          be considered to be IPv4 by default.

    Returns:
        An IPv4Address or IPv6Address object.

    Raises:
        ValueError: if the *address* passed isn't either a v4 or a v6
          address

    """
    try:
        return IPv4Address(address)
    except (AddressValueError, NetmaskValueError):
        pass

    try:
        return IPv6Address(address)
    except (AddressValueError, NetmaskValueError):
        pass

    if isinstance(address, bytes):
        raise AddressValueError(
            '%r does not appear to be an IPv4 or IPv6 address. '
            'Did you pass in a bytes (str in Python 2) instead of'
            ' a unicode object?' % address)

    raise ValueError('%r does not appear to be an IPv4 or IPv6 address' %
                     address)


</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="240" endline="277" pcid="6480">
def ip_network(address, strict=True):
    """Take an IP string/int and return an object of the correct type.

    Args:
        address: A string or integer, the IP network.  Either IPv4 or
          IPv6 networks may be supplied; integers less than 2**32 will
          be considered to be IPv4 by default.

    Returns:
        An IPv4Network or IPv6Network object.

    Raises:
        ValueError: if the string passed isn't either a v4 or a v6
          address. Or if the network has host bits set.

    """
    try:
        return IPv4Network(address, strict)
    except (AddressValueError, NetmaskValueError):
        pass

    try:
        return IPv6Network(address, strict)
    except (AddressValueError, NetmaskValueError):
        pass

    if isinstance(address, bytes):
        raise AddressValueError(
            "%r does not appear to be an IPv4 or IPv6 network. "
            "Did you pass in a bytes (str in Python 2) instead of"
            " a unicode object?" % address
        )

    raise ValueError(
        "%r does not appear to be an IPv4 or IPv6 network" % address
    )


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="264" endline="298" pcid="6882">
def ip_interface(address):
    """Take an IP string/int and return an object of the correct type.

    Args:
        address: A string or integer, the IP address.  Either IPv4 or
          IPv6 addresses may be supplied; integers less than 2**32 will
          be considered to be IPv4 by default.

    Returns:
        An IPv4Interface or IPv6Interface object.

    Raises:
        ValueError: if the string passed isn't either a v4 or a v6
          address.

    Notes:
        The IPv?Interface classes describe an Address on a particular
        Network, so they're basically a combination of both the Address
        and Network classes.

    """
    try:
        return IPv4Interface(address)
    except (AddressValueError, NetmaskValueError):
        pass

    try:
        return IPv6Interface(address)
    except (AddressValueError, NetmaskValueError):
        pass

    raise ValueError('%r does not appear to be an IPv4 or IPv6 interface' %
                     address)


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="228" endline="263" pcid="6881">
def ip_network(address, strict=True):
    """Take an IP string/int and return an object of the correct type.

    Args:
        address: A string or integer, the IP network.  Either IPv4 or
          IPv6 networks may be supplied; integers less than 2**32 will
          be considered to be IPv4 by default.

    Returns:
        An IPv4Network or IPv6Network object.

    Raises:
        ValueError: if the string passed isn't either a v4 or a v6
          address. Or if the network has host bits set.

    """
    try:
        return IPv4Network(address, strict)
    except (AddressValueError, NetmaskValueError):
        pass

    try:
        return IPv6Network(address, strict)
    except (AddressValueError, NetmaskValueError):
        pass

    if isinstance(address, bytes):
        raise AddressValueError(
            '%r does not appear to be an IPv4 or IPv6 network. '
            'Did you pass in a bytes (str in Python 2) instead of'
            ' a unicode object?' % address)

    raise ValueError('%r does not appear to be an IPv4 or IPv6 network' %
                     address)


</source>
</class>

<class classid="177" nclones="2" nlines="27" similarity="71">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="394" endline="452" pcid="6487">
def summarize_address_range(first, last):
    """Summarize a network range given the first and last IP addresses.

    Example:
        >>> list(summarize_address_range(IPv4Address('192.0.2.0'),
        ...                              IPv4Address('192.0.2.130')))
        ...                                #doctest: +NORMALIZE_WHITESPACE
        [IPv4Network('192.0.2.0/25'), IPv4Network('192.0.2.128/31'),
         IPv4Network('192.0.2.130/32')]

    Args:
        first: the first IPv4Address or IPv6Address in the range.
        last: the last IPv4Address or IPv6Address in the range.

    Returns:
        An iterator of the summarized IPv(4|6) network objects.

    Raise:
        TypeError:
            If the first and last objects are not IP addresses.
            If the first and last objects are not the same version.
        ValueError:
            If the last object is not greater than the first.
            If the version of the first address is not 4 or 6.

    """
    if not (
        isinstance(first, _BaseAddress) and isinstance(last, _BaseAddress)
    ):
        raise TypeError("first and last must be IP addresses, not networks")
    if first.version != last.version:
        raise TypeError(
            "%s and %s are not of the same version" % (first, last)
        )
    if first > last:
        raise ValueError("last IP address must be greater than first")

    if first.version == 4:
        ip = IPv4Network
    elif first.version == 6:
        ip = IPv6Network
    else:
        raise ValueError("unknown IP version")

    ip_bits = first._max_prefixlen
    first_int = first._ip
    last_int = last._ip
    while first_int <= last_int:
        nbits = min(
            _count_righthand_zero_bits(first_int, ip_bits),
            _compat_bit_length(last_int - first_int + 1) - 1,
        )
        net = ip((first_int, ip_bits - nbits))
        yield net
        first_int += 1 << nbits
        if first_int - 1 == ip._ALL_ONES:
            break


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="379" endline="433" pcid="6888">
def summarize_address_range(first, last):
    """Summarize a network range given the first and last IP addresses.

    Example:
        >>> list(summarize_address_range(IPv4Address('192.0.2.0'),
        ...                              IPv4Address('192.0.2.130')))
        ...                                #doctest: +NORMALIZE_WHITESPACE
        [IPv4Network('192.0.2.0/25'), IPv4Network('192.0.2.128/31'),
         IPv4Network('192.0.2.130/32')]

    Args:
        first: the first IPv4Address or IPv6Address in the range.
        last: the last IPv4Address or IPv6Address in the range.

    Returns:
        An iterator of the summarized IPv(4|6) network objects.

    Raise:
        TypeError:
            If the first and last objects are not IP addresses.
            If the first and last objects are not the same version.
        ValueError:
            If the last object is not greater than the first.
            If the version of the first address is not 4 or 6.

    """
    if (not (isinstance(first, _BaseAddress) and
             isinstance(last, _BaseAddress))):
        raise TypeError('first and last must be IP addresses, not networks')
    if first.version != last.version:
        raise TypeError("%s and %s are not of the same version" % (
                        first, last))
    if first > last:
        raise ValueError('last IP address must be greater than first')

    if first.version == 4:
        ip = IPv4Network
    elif first.version == 6:
        ip = IPv6Network
    else:
        raise ValueError('unknown IP version')

    ip_bits = first._max_prefixlen
    first_int = first._ip
    last_int = last._ip
    while first_int <= last_int:
        nbits = min(_count_righthand_zero_bits(first_int, ip_bits),
                    _compat_bit_length(last_int - first_int + 1) - 1)
        net = ip((first_int, ip_bits - nbits))
        yield net
        first_int += 1 << nbits
        if first_int - 1 == ip._ALL_ONES:
            break


</source>
</class>

<class classid="178" nclones="2" nlines="19" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="453" endline="501" pcid="6488">
def _collapse_addresses_internal(addresses):
    """Loops through the addresses, collapsing concurrent netblocks.

    Example:

        ip1 = IPv4Network('192.0.2.0/26')
        ip2 = IPv4Network('192.0.2.64/26')
        ip3 = IPv4Network('192.0.2.128/26')
        ip4 = IPv4Network('192.0.2.192/26')

        _collapse_addresses_internal([ip1, ip2, ip3, ip4]) ->
          [IPv4Network('192.0.2.0/24')]

        This shouldn't be called directly; it is called via
          collapse_addresses([]).

    Args:
        addresses: A list of IPv4Network's or IPv6Network's

    Returns:
        A list of IPv4Network's or IPv6Network's depending on what we were
        passed.

    """
    # First merge
    to_merge = list(addresses)
    subnets = {}
    while to_merge:
        net = to_merge.pop()
        supernet = net.supernet()
        existing = subnets.get(supernet)
        if existing is None:
            subnets[supernet] = net
        elif existing != net:
            # Merge consecutive subnets
            del subnets[supernet]
            to_merge.append(supernet)
    # Then iterate over resulting networks, skipping subsumed subnets
    last = None
    for net in sorted(subnets.values()):
        if last is not None:
            # Since they are sorted,
            # last.network_address <= net.network_address is a given.
            if last.broadcast_address >= net.broadcast_address:
                continue
        yield net
        last = net


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="434" endline="482" pcid="6889">
def _collapse_addresses_internal(addresses):
    """Loops through the addresses, collapsing concurrent netblocks.

    Example:

        ip1 = IPv4Network('192.0.2.0/26')
        ip2 = IPv4Network('192.0.2.64/26')
        ip3 = IPv4Network('192.0.2.128/26')
        ip4 = IPv4Network('192.0.2.192/26')

        _collapse_addresses_internal([ip1, ip2, ip3, ip4]) ->
          [IPv4Network('192.0.2.0/24')]

        This shouldn't be called directly; it is called via
          collapse_addresses([]).

    Args:
        addresses: A list of IPv4Network's or IPv6Network's

    Returns:
        A list of IPv4Network's or IPv6Network's depending on what we were
        passed.

    """
    # First merge
    to_merge = list(addresses)
    subnets = {}
    while to_merge:
        net = to_merge.pop()
        supernet = net.supernet()
        existing = subnets.get(supernet)
        if existing is None:
            subnets[supernet] = net
        elif existing != net:
            # Merge consecutive subnets
            del subnets[supernet]
            to_merge.append(supernet)
    # Then iterate over resulting networks, skipping subsumed subnets
    last = None
    for net in sorted(subnets.values()):
        if last is not None:
            # Since they are sorted,
            # last.network_address <= net.network_address is a given.
            if last.broadcast_address >= net.broadcast_address:
                continue
        yield net
        last = net


</source>
</class>

<class classid="179" nclones="2" nlines="28" similarity="78">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="502" endline="558" pcid="6489">
def collapse_addresses(addresses):
    """Collapse a list of IP objects.

    Example:
        collapse_addresses([IPv4Network('192.0.2.0/25'),
                            IPv4Network('192.0.2.128/25')]) ->
                           [IPv4Network('192.0.2.0/24')]

    Args:
        addresses: An iterator of IPv4Network or IPv6Network objects.

    Returns:
        An iterator of the collapsed IPv(4|6)Network objects.

    Raises:
        TypeError: If passed a list of mixed version objects.

    """
    addrs = []
    ips = []
    nets = []

    # split IP addresses and networks
    for ip in addresses:
        if isinstance(ip, _BaseAddress):
            if ips and ips[-1]._version != ip._version:
                raise TypeError(
                    "%s and %s are not of the same version" % (ip, ips[-1])
                )
            ips.append(ip)
        elif ip._prefixlen == ip._max_prefixlen:
            if ips and ips[-1]._version != ip._version:
                raise TypeError(
                    "%s and %s are not of the same version" % (ip, ips[-1])
                )
            try:
                ips.append(ip.ip)
            except AttributeError:
                ips.append(ip.network_address)
        else:
            if nets and nets[-1]._version != ip._version:
                raise TypeError(
                    "%s and %s are not of the same version" % (ip, nets[-1])
                )
            nets.append(ip)

    # sort and dedup
    ips = sorted(set(ips))

    # find consecutive address ranges in the sorted sequence and summarize them
    if ips:
        for first, last in _find_address_range(ips):
            addrs.extend(summarize_address_range(first, last))

    return _collapse_addresses_internal(addrs + nets)


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="483" endline="536" pcid="6890">
def collapse_addresses(addresses):
    """Collapse a list of IP objects.

    Example:
        collapse_addresses([IPv4Network('192.0.2.0/25'),
                            IPv4Network('192.0.2.128/25')]) ->
                           [IPv4Network('192.0.2.0/24')]

    Args:
        addresses: An iterator of IPv4Network or IPv6Network objects.

    Returns:
        An iterator of the collapsed IPv(4|6)Network objects.

    Raises:
        TypeError: If passed a list of mixed version objects.

    """
    addrs = []
    ips = []
    nets = []

    # split IP addresses and networks
    for ip in addresses:
        if isinstance(ip, _BaseAddress):
            if ips and ips[-1]._version != ip._version:
                raise TypeError("%s and %s are not of the same version" % (
                                ip, ips[-1]))
            ips.append(ip)
        elif ip._prefixlen == ip._max_prefixlen:
            if ips and ips[-1]._version != ip._version:
                raise TypeError("%s and %s are not of the same version" % (
                                ip, ips[-1]))
            try:
                ips.append(ip.ip)
            except AttributeError:
                ips.append(ip.network_address)
        else:
            if nets and nets[-1]._version != ip._version:
                raise TypeError("%s and %s are not of the same version" % (
                                ip, nets[-1]))
            nets.append(ip)

    # sort and dedup
    ips = sorted(set(ips))

    # find consecutive address ranges in the sorted sequence and summarize them
    if ips:
        for first, last in _find_address_range(ips):
            addrs.extend(summarize_address_range(first, last))

    return _collapse_addresses_internal(addrs + nets)


</source>
</class>

<class classid="180" nclones="2" nlines="12" similarity="83">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="652" endline="676" pcid="6498">
    def _prefix_from_ip_int(cls, ip_int):
        """Return prefix length from the bitwise netmask.

        Args:
            ip_int: An integer, the netmask in expanded bitwise format

        Returns:
            An integer, the prefix length.

        Raises:
            ValueError: If the input intermingles zeroes & ones
        """
        trailing_zeroes = _count_righthand_zero_bits(
            ip_int, cls._max_prefixlen
        )
        prefixlen = cls._max_prefixlen - trailing_zeroes
        leading_ones = ip_int >> trailing_zeroes
        all_ones = (1 << prefixlen) - 1
        if leading_ones != all_ones:
            byteslen = cls._max_prefixlen // 8
            details = _compat_to_bytes(ip_int, byteslen, "big")
            msg = "Netmask pattern %r mixes zeroes & ones"
            raise ValueError(msg % details)
        return prefixlen

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="627" endline="650" pcid="6899">
    def _prefix_from_ip_int(cls, ip_int):
        """Return prefix length from the bitwise netmask.

        Args:
            ip_int: An integer, the netmask in expanded bitwise format

        Returns:
            An integer, the prefix length.

        Raises:
            ValueError: If the input intermingles zeroes & ones
        """
        trailing_zeroes = _count_righthand_zero_bits(ip_int,
                                                     cls._max_prefixlen)
        prefixlen = cls._max_prefixlen - trailing_zeroes
        leading_ones = ip_int >> trailing_zeroes
        all_ones = (1 << prefixlen) - 1
        if leading_ones != all_ones:
            byteslen = cls._max_prefixlen // 8
            details = _compat_to_bytes(ip_int, byteslen, 'big')
            msg = 'Netmask pattern %r mixes zeroes & ones'
            raise ValueError(msg % details)
        return prefixlen

</source>
</class>

<class classid="181" nclones="2" nlines="10" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="683" endline="706" pcid="6500">
    def _prefix_from_prefix_string(cls, prefixlen_str):
        """Return prefix length from a numeric string

        Args:
            prefixlen_str: The string to be converted

        Returns:
            An integer, the prefix length.

        Raises:
            NetmaskValueError: If the input is not a valid netmask
        """
        # int allows a leading +/- as well as surrounding whitespace,
        # so we ensure that isn't the case
        if not _BaseV4._DECIMAL_DIGITS.issuperset(prefixlen_str):
            cls._report_invalid_netmask(prefixlen_str)
        try:
            prefixlen = int(prefixlen_str)
        except ValueError:
            cls._report_invalid_netmask(prefixlen_str)
        if not (0 <= prefixlen <= cls._max_prefixlen):
            cls._report_invalid_netmask(prefixlen_str)
        return prefixlen

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="657" endline="680" pcid="6901">
    def _prefix_from_prefix_string(cls, prefixlen_str):
        """Return prefix length from a numeric string

        Args:
            prefixlen_str: The string to be converted

        Returns:
            An integer, the prefix length.

        Raises:
            NetmaskValueError: If the input is not a valid netmask
        """
        # int allows a leading +/- as well as surrounding whitespace,
        # so we ensure that isn't the case
        if not _BaseV4._DECIMAL_DIGITS.issuperset(prefixlen_str):
            cls._report_invalid_netmask(prefixlen_str)
        try:
            prefixlen = int(prefixlen_str)
        except ValueError:
            cls._report_invalid_netmask(prefixlen_str)
        if not (0 <= prefixlen <= cls._max_prefixlen):
            cls._report_invalid_netmask(prefixlen_str)
        return prefixlen

</source>
</class>

<class classid="182" nclones="2" nlines="14" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="708" endline="740" pcid="6501">
    def _prefix_from_ip_string(cls, ip_str):
        """Turn a netmask/hostmask string into a prefix length

        Args:
            ip_str: The netmask/hostmask to be converted

        Returns:
            An integer, the prefix length.

        Raises:
            NetmaskValueError: If the input is not a valid netmask/hostmask
        """
        # Parse the netmask/hostmask like an IP address.
        try:
            ip_int = cls._ip_int_from_string(ip_str)
        except AddressValueError:
            cls._report_invalid_netmask(ip_str)

        # Try matching a netmask (this would be /1*0*/ as a bitwise regexp).
        # Note that the two ambiguous cases (all-ones and all-zeroes) are
        # treated as netmasks.
        try:
            return cls._prefix_from_ip_int(ip_int)
        except ValueError:
            pass

        # Invert the bits, and try matching a /0+1+/ hostmask instead.
        ip_int ^= cls._ALL_ONES
        try:
            return cls._prefix_from_ip_int(ip_int)
        except ValueError:
            cls._report_invalid_netmask(ip_str)

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="682" endline="714" pcid="6902">
    def _prefix_from_ip_string(cls, ip_str):
        """Turn a netmask/hostmask string into a prefix length

        Args:
            ip_str: The netmask/hostmask to be converted

        Returns:
            An integer, the prefix length.

        Raises:
            NetmaskValueError: If the input is not a valid netmask/hostmask
        """
        # Parse the netmask/hostmask like an IP address.
        try:
            ip_int = cls._ip_int_from_string(ip_str)
        except AddressValueError:
            cls._report_invalid_netmask(ip_str)

        # Try matching a netmask (this would be /1*0*/ as a bitwise regexp).
        # Note that the two ambiguous cases (all-ones and all-zeroes) are
        # treated as netmasks.
        try:
            return cls._prefix_from_ip_int(ip_int)
        except ValueError:
            pass

        # Invert the bits, and try matching a /0+1+/ hostmask instead.
        ip_int ^= cls._ALL_ONES
        try:
            return cls._prefix_from_ip_int(ip_int)
        except ValueError:
            cls._report_invalid_netmask(ip_str)

</source>
</class>

<class classid="183" nclones="4" nlines="13" similarity="71">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="764" endline="780" pcid="6505">
    def __lt__(self, other):
        if not isinstance(other, _IPAddressBase):
            return NotImplemented
        if not isinstance(other, _BaseAddress):
            raise TypeError(
                "%s and %s are not of the same type" % (self, other)
            )
        if self._version != other._version:
            raise TypeError(
                "%s and %s are not of the same version" % (self, other)
            )
        if self._ip != other._ip:
            return self._ip < other._ip
        return False

    # Shorthand for Integer addition and subtraction. This is not
    # meant to ever support addition/subtraction of addresses.
</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="856" endline="872" pcid="6519">
    def __lt__(self, other):
        if not isinstance(other, _IPAddressBase):
            return NotImplemented
        if not isinstance(other, _BaseNetwork):
            raise TypeError(
                "%s and %s are not of the same type" % (self, other)
            )
        if self._version != other._version:
            raise TypeError(
                "%s and %s are not of the same version" % (self, other)
            )
        if self.network_address != other.network_address:
            return self.network_address < other.network_address
        if self.netmask != other.netmask:
            return self.netmask < other.netmask
        return False

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="828" endline="842" pcid="6920">
    def __lt__(self, other):
        if not isinstance(other, _IPAddressBase):
            return NotImplemented
        if not isinstance(other, _BaseNetwork):
            raise TypeError('%s and %s are not of the same type' % (
                            self, other))
        if self._version != other._version:
            raise TypeError('%s and %s are not of the same version' % (
                            self, other))
        if self.network_address != other.network_address:
            return self.network_address < other.network_address
        if self.netmask != other.netmask:
            return self.netmask < other.netmask
        return False

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="739" endline="753" pcid="6906">
    def __lt__(self, other):
        if not isinstance(other, _IPAddressBase):
            return NotImplemented
        if not isinstance(other, _BaseAddress):
            raise TypeError('%s and %s are not of the same type' % (
                self, other))
        if self._version != other._version:
            raise TypeError('%s and %s are not of the same version' % (
                self, other))
        if self._ip != other._ip:
            return self._ip < other._ip
        return False

    # Shorthand for Integer addition and subtraction. This is not
    # meant to ever support addition/subtraction of addresses.
</source>
</class>

<class classid="184" nclones="2" nlines="12" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="843" endline="855" pcid="6518">
    def __getitem__(self, n):
        network = int(self.network_address)
        broadcast = int(self.broadcast_address)
        if n >= 0:
            if network + n > broadcast:
                raise IndexError("address out of range")
            return self._address_class(network + n)
        else:
            n += 1
            if broadcast + n < network:
                raise IndexError("address out of range")
            return self._address_class(broadcast + n)

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="815" endline="827" pcid="6919">
    def __getitem__(self, n):
        network = int(self.network_address)
        broadcast = int(self.broadcast_address)
        if n >= 0:
            if network + n > broadcast:
                raise IndexError('address out of range')
            return self._address_class(network + n)
        else:
            n += 1
            if broadcast + n < network:
                raise IndexError('address out of range')
            return self._address_class(broadcast + n)

</source>
</class>

<class classid="185" nclones="2" nlines="30" similarity="73">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="959" endline="1037" pcid="6532">
    def address_exclude(self, other):
        """Remove an address from a larger block.

        For example:

            addr1 = ip_network('192.0.2.0/28')
            addr2 = ip_network('192.0.2.1/32')
            list(addr1.address_exclude(addr2)) =
                [IPv4Network('192.0.2.0/32'), IPv4Network('192.0.2.2/31'),
                 IPv4Network('192.0.2.4/30'), IPv4Network('192.0.2.8/29')]

        or IPv6:

            addr1 = ip_network('2001:db8::1/32')
            addr2 = ip_network('2001:db8::1/128')
            list(addr1.address_exclude(addr2)) =
                [ip_network('2001:db8::1/128'),
                 ip_network('2001:db8::2/127'),
                 ip_network('2001:db8::4/126'),
                 ip_network('2001:db8::8/125'),
                 ...
                 ip_network('2001:db8:8000::/33')]

        Args:
            other: An IPv4Network or IPv6Network object of the same type.

        Returns:
            An iterator of the IPv(4|6)Network objects which is self
            minus other.

        Raises:
            TypeError: If self and other are of differing address
              versions, or if other is not a network object.
            ValueError: If other is not completely contained by self.

        """
        if not self._version == other._version:
            raise TypeError(
                "%s and %s are not of the same version" % (self, other)
            )

        if not isinstance(other, _BaseNetwork):
            raise TypeError("%s is not a network object" % other)

        if not other.subnet_of(self):
            raise ValueError("%s not contained in %s" % (other, self))
        if other == self:
            return

        # Make sure we're comparing the network of other.
        other = other.__class__(
            "%s/%s" % (other.network_address, other.prefixlen)
        )

        s1, s2 = self.subnets()
        while s1 != other and s2 != other:
            if other.subnet_of(s1):
                yield s2
                s1, s2 = s1.subnets()
            elif other.subnet_of(s2):
                yield s1
                s1, s2 = s2.subnets()
            else:
                # If we got here, there's a bug somewhere.
                raise AssertionError(
                    "Error performing exclusion: "
                    "s1: %s s2: %s other: %s" % (s1, s2, other)
                )
        if s1 == other:
            yield s2
        elif s2 == other:
            yield s1
        else:
            # If we got here, there's a bug somewhere.
            raise AssertionError(
                "Error performing exclusion: "
                "s1: %s s2: %s other: %s" % (s1, s2, other)
            )

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="920" endline="994" pcid="6933">
    def address_exclude(self, other):
        """Remove an address from a larger block.

        For example:

            addr1 = ip_network('192.0.2.0/28')
            addr2 = ip_network('192.0.2.1/32')
            list(addr1.address_exclude(addr2)) =
                [IPv4Network('192.0.2.0/32'), IPv4Network('192.0.2.2/31'),
                 IPv4Network('192.0.2.4/30'), IPv4Network('192.0.2.8/29')]

        or IPv6:

            addr1 = ip_network('2001:db8::1/32')
            addr2 = ip_network('2001:db8::1/128')
            list(addr1.address_exclude(addr2)) =
                [ip_network('2001:db8::1/128'),
                 ip_network('2001:db8::2/127'),
                 ip_network('2001:db8::4/126'),
                 ip_network('2001:db8::8/125'),
                 ...
                 ip_network('2001:db8:8000::/33')]

        Args:
            other: An IPv4Network or IPv6Network object of the same type.

        Returns:
            An iterator of the IPv(4|6)Network objects which is self
            minus other.

        Raises:
            TypeError: If self and other are of differing address
              versions, or if other is not a network object.
            ValueError: If other is not completely contained by self.

        """
        if not self._version == other._version:
            raise TypeError("%s and %s are not of the same version" % (
                            self, other))

        if not isinstance(other, _BaseNetwork):
            raise TypeError("%s is not a network object" % other)

        if not other.subnet_of(self):
            raise ValueError('%s not contained in %s' % (other, self))
        if other == self:
            return

        # Make sure we're comparing the network of other.
        other = other.__class__('%s/%s' % (other.network_address,
                                           other.prefixlen))

        s1, s2 = self.subnets()
        while s1 != other and s2 != other:
            if other.subnet_of(s1):
                yield s2
                s1, s2 = s1.subnets()
            elif other.subnet_of(s2):
                yield s1
                s1, s2 = s2.subnets()
            else:
                # If we got here, there's a bug somewhere.
                raise AssertionError('Error performing exclusion: '
                                     's1: %s s2: %s other: %s' %
                                     (s1, s2, other))
        if s1 == other:
            yield s2
        elif s2 == other:
            yield s1
        else:
            # If we got here, there's a bug somewhere.
            raise AssertionError('Error performing exclusion: '
                                 's1: %s s2: %s other: %s' %
                                 (s1, s2, other))

</source>
</class>

<class classid="186" nclones="2" nlines="13" similarity="84">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="1038" endline="1086" pcid="6533">
    def compare_networks(self, other):
        """Compare two IP objects.

        This is only concerned about the comparison of the integer
        representation of the network addresses.  This means that the
        host bits aren't considered at all in this method.  If you want
        to compare host bits, you can easily enough do a
        'HostA._ip < HostB._ip'

        Args:
            other: An IP object.

        Returns:
            If the IP versions of self and other are the same, returns:

            -1 if self < other:
              eg: IPv4Network('192.0.2.0/25') < IPv4Network('192.0.2.128/25')
              IPv6Network('2001:db8::1000/124') <
                  IPv6Network('2001:db8::2000/124')
            0 if self == other
              eg: IPv4Network('192.0.2.0/24') == IPv4Network('192.0.2.0/24')
              IPv6Network('2001:db8::1000/124') ==
                  IPv6Network('2001:db8::1000/124')
            1 if self > other
              eg: IPv4Network('192.0.2.128/25') > IPv4Network('192.0.2.0/25')
                  IPv6Network('2001:db8::2000/124') >
                      IPv6Network('2001:db8::1000/124')

          Raises:
              TypeError if the IP versions are different.

        """
        # does this need to raise a ValueError?
        if self._version != other._version:
            raise TypeError(
                "%s and %s are not of the same type" % (self, other)
            )
        # self._version == other._version below here:
        if self.network_address < other.network_address:
            return -1
        if self.network_address > other.network_address:
            return 1
        # self.network_address == other.network_address below here:
        if self.netmask < other.netmask:
            return -1
        if self.netmask > other.netmask:
            return 1
        return 0

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="995" endline="1042" pcid="6934">
    def compare_networks(self, other):
        """Compare two IP objects.

        This is only concerned about the comparison of the integer
        representation of the network addresses.  This means that the
        host bits aren't considered at all in this method.  If you want
        to compare host bits, you can easily enough do a
        'HostA._ip < HostB._ip'

        Args:
            other: An IP object.

        Returns:
            If the IP versions of self and other are the same, returns:

            -1 if self < other:
              eg: IPv4Network('192.0.2.0/25') < IPv4Network('192.0.2.128/25')
              IPv6Network('2001:db8::1000/124') <
                  IPv6Network('2001:db8::2000/124')
            0 if self == other
              eg: IPv4Network('192.0.2.0/24') == IPv4Network('192.0.2.0/24')
              IPv6Network('2001:db8::1000/124') ==
                  IPv6Network('2001:db8::1000/124')
            1 if self > other
              eg: IPv4Network('192.0.2.128/25') > IPv4Network('192.0.2.0/25')
                  IPv6Network('2001:db8::2000/124') >
                      IPv6Network('2001:db8::1000/124')

          Raises:
              TypeError if the IP versions are different.

        """
        # does this need to raise a ValueError?
        if self._version != other._version:
            raise TypeError('%s and %s are not of the same type' % (
                            self, other))
        # self._version == other._version below here:
        if self.network_address < other.network_address:
            return -1
        if self.network_address > other.network_address:
            return 1
        # self.network_address == other.network_address below here:
        if self.netmask < other.netmask:
            return -1
        if self.netmask > other.netmask:
            return 1
        return 0

</source>
</class>

<class classid="187" nclones="2" nlines="23" similarity="91">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="1097" endline="1150" pcid="6535">
    def subnets(self, prefixlen_diff=1, new_prefix=None):
        """The subnets which join to make the current subnet.

        In the case that self contains only one IP
        (self._prefixlen == 32 for IPv4 or self._prefixlen == 128
        for IPv6), yield an iterator with just ourself.

        Args:
            prefixlen_diff: An integer, the amount the prefix length
              should be increased by. This should not be set if
              new_prefix is also set.
            new_prefix: The desired new prefix length. This must be a
              larger number (smaller prefix) than the existing prefix.
              This should not be set if prefixlen_diff is also set.

        Returns:
            An iterator of IPv(4|6) objects.

        Raises:
            ValueError: The prefixlen_diff is too small or too large.
                OR
            prefixlen_diff and new_prefix are both set or new_prefix
              is a smaller number than the current prefix (smaller
              number means a larger network)

        """
        if self._prefixlen == self._max_prefixlen:
            yield self
            return

        if new_prefix is not None:
            if new_prefix < self._prefixlen:
                raise ValueError("new prefix must be longer")
            if prefixlen_diff != 1:
                raise ValueError("cannot set prefixlen_diff and new_prefix")
            prefixlen_diff = new_prefix - self._prefixlen

        if prefixlen_diff < 0:
            raise ValueError("prefix length diff must be > 0")
        new_prefixlen = self._prefixlen + prefixlen_diff

        if new_prefixlen > self._max_prefixlen:
            raise ValueError(
                "prefix length diff %d is invalid for netblock %s"
                % (new_prefixlen, self)
            )

        start = int(self.network_address)
        end = int(self.broadcast_address) + 1
        step = (int(self.hostmask) + 1) >> prefixlen_diff
        for new_addr in _compat_range(start, end, step):
            current = self.__class__((new_addr, new_prefixlen))
            yield current

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="1053" endline="1105" pcid="6936">
    def subnets(self, prefixlen_diff=1, new_prefix=None):
        """The subnets which join to make the current subnet.

        In the case that self contains only one IP
        (self._prefixlen == 32 for IPv4 or self._prefixlen == 128
        for IPv6), yield an iterator with just ourself.

        Args:
            prefixlen_diff: An integer, the amount the prefix length
              should be increased by. This should not be set if
              new_prefix is also set.
            new_prefix: The desired new prefix length. This must be a
              larger number (smaller prefix) than the existing prefix.
              This should not be set if prefixlen_diff is also set.

        Returns:
            An iterator of IPv(4|6) objects.

        Raises:
            ValueError: The prefixlen_diff is too small or too large.
                OR
            prefixlen_diff and new_prefix are both set or new_prefix
              is a smaller number than the current prefix (smaller
              number means a larger network)

        """
        if self._prefixlen == self._max_prefixlen:
            yield self
            return

        if new_prefix is not None:
            if new_prefix < self._prefixlen:
                raise ValueError('new prefix must be longer')
            if prefixlen_diff != 1:
                raise ValueError('cannot set prefixlen_diff and new_prefix')
            prefixlen_diff = new_prefix - self._prefixlen

        if prefixlen_diff < 0:
            raise ValueError('prefix length diff must be > 0')
        new_prefixlen = self._prefixlen + prefixlen_diff

        if new_prefixlen > self._max_prefixlen:
            raise ValueError(
                'prefix length diff %d is invalid for netblock %s' % (
                    new_prefixlen, self))

        start = int(self.network_address)
        end = int(self.broadcast_address) + 1
        step = (int(self.hostmask) + 1) >> prefixlen_diff
        for new_addr in _compat_range(start, end, step):
            current = self.__class__((new_addr, new_prefixlen))
            yield current

</source>
</class>

<class classid="188" nclones="2" nlines="12" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="1344" endline="1366" pcid="6548">
    def _make_netmask(cls, arg):
        """Make a (netmask, prefix_len) tuple from the given argument.

        Argument can be:
        - an integer (the prefix length)
        - a string representing the prefix length (e.g. "24")
        - a string representing the prefix netmask (e.g. "255.255.255.0")
        """
        if arg not in cls._netmask_cache:
            if isinstance(arg, _compat_int_types):
                prefixlen = arg
            else:
                try:
                    # Check for a netmask in prefix length form
                    prefixlen = cls._prefix_from_prefix_string(arg)
                except NetmaskValueError:
                    # Check for a netmask or hostmask in dotted-quad form.
                    # This may raise NetmaskValueError.
                    prefixlen = cls._prefix_from_ip_string(arg)
            netmask = IPv4Address(cls._ip_int_from_prefix(prefixlen))
            cls._netmask_cache[arg] = netmask, prefixlen
        return cls._netmask_cache[arg]

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="1276" endline="1298" pcid="6949">
    def _make_netmask(cls, arg):
        """Make a (netmask, prefix_len) tuple from the given argument.

        Argument can be:
        - an integer (the prefix length)
        - a string representing the prefix length (e.g. "24")
        - a string representing the prefix netmask (e.g. "255.255.255.0")
        """
        if arg not in cls._netmask_cache:
            if isinstance(arg, _compat_int_types):
                prefixlen = arg
            else:
                try:
                    # Check for a netmask in prefix length form
                    prefixlen = cls._prefix_from_prefix_string(arg)
                except NetmaskValueError:
                    # Check for a netmask or hostmask in dotted-quad form.
                    # This may raise NetmaskValueError.
                    prefixlen = cls._prefix_from_ip_string(arg)
            netmask = IPv4Address(cls._ip_int_from_prefix(prefixlen))
            cls._netmask_cache[arg] = netmask, prefixlen
        return cls._netmask_cache[arg]

</source>
</class>

<class classid="189" nclones="2" nlines="11" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="1368" endline="1394" pcid="6549">
    def _ip_int_from_string(cls, ip_str):
        """Turn the given IP string into an integer for comparison.

        Args:
            ip_str: A string, the IP ip_str.

        Returns:
            The IP ip_str as an integer.

        Raises:
            AddressValueError: if ip_str isn't a valid IPv4 Address.

        """
        if not ip_str:
            raise AddressValueError("Address cannot be empty")

        octets = ip_str.split(".")
        if len(octets) != 4:
            raise AddressValueError("Expected 4 octets in %r" % ip_str)

        try:
            return _compat_int_from_byte_vals(
                map(cls._parse_octet, octets), "big"
            )
        except ValueError as exc:
            raise AddressValueError("%s in %r" % (exc, ip_str))

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="1300" endline="1325" pcid="6950">
    def _ip_int_from_string(cls, ip_str):
        """Turn the given IP string into an integer for comparison.

        Args:
            ip_str: A string, the IP ip_str.

        Returns:
            The IP ip_str as an integer.

        Raises:
            AddressValueError: if ip_str isn't a valid IPv4 Address.

        """
        if not ip_str:
            raise AddressValueError('Address cannot be empty')

        octets = ip_str.split('.')
        if len(octets) != 4:
            raise AddressValueError("Expected 4 octets in %r" % ip_str)

        try:
            return _compat_int_from_byte_vals(
                map(cls._parse_octet, octets), 'big')
        except ValueError as exc:
            raise AddressValueError("%s in %r" % (exc, ip_str))

</source>
</class>

<class classid="190" nclones="2" nlines="16" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="1396" endline="1431" pcid="6550">
    def _parse_octet(cls, octet_str):
        """Convert a decimal octet into an integer.

        Args:
            octet_str: A string, the number to parse.

        Returns:
            The octet as an integer.

        Raises:
            ValueError: if the octet isn't strictly a decimal from [0..255].

        """
        if not octet_str:
            raise ValueError("Empty octet not permitted")
        # Whitelist the characters, since int() allows a lot of bizarre stuff.
        if not cls._DECIMAL_DIGITS.issuperset(octet_str):
            msg = "Only decimal digits permitted in %r"
            raise ValueError(msg % octet_str)
        # We do the length check second, since the invalid character error
        # is likely to be more informative for the user
        if len(octet_str) > 3:
            msg = "At most 3 characters permitted in %r"
            raise ValueError(msg % octet_str)
        # Convert to integer (we know digits are legal)
        octet_int = int(octet_str, 10)
        # Any octets that look like they *might* be written in octal,
        # and which don't look exactly the same in both octal and
        # decimal are rejected as ambiguous
        if octet_int > 7 and octet_str[0] == "0":
            msg = "Ambiguous (octal/decimal) value in %r not permitted"
            raise ValueError(msg % octet_str)
        if octet_int > 255:
            raise ValueError("Octet %d (> 255) not permitted" % octet_int)
        return octet_int

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="1327" endline="1362" pcid="6951">
    def _parse_octet(cls, octet_str):
        """Convert a decimal octet into an integer.

        Args:
            octet_str: A string, the number to parse.

        Returns:
            The octet as an integer.

        Raises:
            ValueError: if the octet isn't strictly a decimal from [0..255].

        """
        if not octet_str:
            raise ValueError("Empty octet not permitted")
        # Whitelist the characters, since int() allows a lot of bizarre stuff.
        if not cls._DECIMAL_DIGITS.issuperset(octet_str):
            msg = "Only decimal digits permitted in %r"
            raise ValueError(msg % octet_str)
        # We do the length check second, since the invalid character error
        # is likely to be more informative for the user
        if len(octet_str) > 3:
            msg = "At most 3 characters permitted in %r"
            raise ValueError(msg % octet_str)
        # Convert to integer (we know digits are legal)
        octet_int = int(octet_str, 10)
        # Any octets that look like they *might* be written in octal,
        # and which don't look exactly the same in both octal and
        # decimal are rejected as ambiguous
        if octet_int > 7 and octet_str[0] == '0':
            msg = "Ambiguous (octal/decimal) value in %r not permitted"
            raise ValueError(msg % octet_str)
        if octet_int > 255:
            raise ValueError("Octet %d (> 255) not permitted" % octet_int)
        return octet_int

</source>
</class>

<class classid="191" nclones="2" nlines="11" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="1450" endline="1470" pcid="6552">
    def _is_hostmask(self, ip_str):
        """Test if the IP string is a hostmask (rather than a netmask).

        Args:
            ip_str: A string, the potential hostmask.

        Returns:
            A boolean, True if the IP string is a hostmask.

        """
        bits = ip_str.split(".")
        try:
            parts = [x for x in map(int, bits) if x in self._valid_mask_octets]
        except ValueError:
            return False
        if len(parts) != len(bits):
            return False
        if parts[0] < parts[-1]:
            return True
        return False

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="1379" endline="1399" pcid="6953">
    def _is_hostmask(self, ip_str):
        """Test if the IP string is a hostmask (rather than a netmask).

        Args:
            ip_str: A string, the potential hostmask.

        Returns:
            A boolean, True if the IP string is a hostmask.

        """
        bits = ip_str.split('.')
        try:
            parts = [x for x in map(int, bits) if x in self._valid_mask_octets]
        except ValueError:
            return False
        if len(parts) != len(bits):
            return False
        if parts[0] < parts[-1]:
            return True
        return False

</source>
</class>

<class classid="192" nclones="4" nlines="14" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="1495" endline="1530" pcid="6556">
    def __init__(self, address):

        """
        Args:
            address: A string or integer representing the IP

              Additionally, an integer can be passed, so
              IPv4Address('192.0.2.1') == IPv4Address(3221225985).
              or, more generally
              IPv4Address(int(IPv4Address('192.0.2.1'))) ==
                IPv4Address('192.0.2.1')

        Raises:
            AddressValueError: If ipaddress isn't a valid IPv4 address.

        """
        # Efficient constructor from integer.
        if isinstance(address, _compat_int_types):
            self._check_int_address(address)
            self._ip = address
            return

        # Constructing from a packed address
        if isinstance(address, bytes):
            self._check_packed_address(address, 4)
            bvs = _compat_bytes_to_byte_vals(address)
            self._ip = _compat_int_from_byte_vals(bvs, "big")
            return

        # Assume input argument to be string or any object representation
        # which converts into a formatted IP string.
        addr_str = _compat_str(address)
        if "/" in addr_str:
            raise AddressValueError("Unexpected '/' in %r" % address)
        self._ip = self._ip_int_from_string(addr_str)

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="1424" endline="1459" pcid="6957">
    def __init__(self, address):

        """
        Args:
            address: A string or integer representing the IP

              Additionally, an integer can be passed, so
              IPv4Address('192.0.2.1') == IPv4Address(3221225985).
              or, more generally
              IPv4Address(int(IPv4Address('192.0.2.1'))) ==
                IPv4Address('192.0.2.1')

        Raises:
            AddressValueError: If ipaddress isn't a valid IPv4 address.

        """
        # Efficient constructor from integer.
        if isinstance(address, _compat_int_types):
            self._check_int_address(address)
            self._ip = address
            return

        # Constructing from a packed address
        if isinstance(address, bytes):
            self._check_packed_address(address, 4)
            bvs = _compat_bytes_to_byte_vals(address)
            self._ip = _compat_int_from_byte_vals(bvs, 'big')
            return

        # Assume input argument to be string or any object representation
        # which converts into a formatted IP string.
        addr_str = _compat_str(address)
        if '/' in addr_str:
            raise AddressValueError("Unexpected '/' in %r" % address)
        self._ip = self._ip_int_from_string(addr_str)

</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="2144" endline="2180" pcid="6585">
    def __init__(self, address):
        """Instantiate a new IPv6 address object.

        Args:
            address: A string or integer representing the IP

              Additionally, an integer can be passed, so
              IPv6Address('2001:db8::') ==
                IPv6Address(42540766411282592856903984951653826560)
              or, more generally
              IPv6Address(int(IPv6Address('2001:db8::'))) ==
                IPv6Address('2001:db8::')

        Raises:
            AddressValueError: If address isn't a valid IPv6 address.

        """
        # Efficient constructor from integer.
        if isinstance(address, _compat_int_types):
            self._check_int_address(address)
            self._ip = address
            return

        # Constructing from a packed address
        if isinstance(address, bytes):
            self._check_packed_address(address, 16)
            bvs = _compat_bytes_to_byte_vals(address)
            self._ip = _compat_int_from_byte_vals(bvs, "big")
            return

        # Assume input argument to be string or any object representation
        # which converts into a formatted IP string.
        addr_str = _compat_str(address)
        if "/" in addr_str:
            raise AddressValueError("Unexpected '/' in %r" % address)
        self._ip = self._ip_int_from_string(addr_str)

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="2059" endline="2095" pcid="6986">
    def __init__(self, address):
        """Instantiate a new IPv6 address object.

        Args:
            address: A string or integer representing the IP

              Additionally, an integer can be passed, so
              IPv6Address('2001:db8::') ==
                IPv6Address(42540766411282592856903984951653826560)
              or, more generally
              IPv6Address(int(IPv6Address('2001:db8::'))) ==
                IPv6Address('2001:db8::')

        Raises:
            AddressValueError: If address isn't a valid IPv6 address.

        """
        # Efficient constructor from integer.
        if isinstance(address, _compat_int_types):
            self._check_int_address(address)
            self._ip = address
            return

        # Constructing from a packed address
        if isinstance(address, bytes):
            self._check_packed_address(address, 16)
            bvs = _compat_bytes_to_byte_vals(address)
            self._ip = _compat_int_from_byte_vals(bvs, 'big')
            return

        # Assume input argument to be string or any object representation
        # which converts into a formatted IP string.
        addr_str = _compat_str(address)
        if '/' in addr_str:
            raise AddressValueError("Unexpected '/' in %r" % address)
        self._ip = self._ip_int_from_string(addr_str)

</source>
</class>

<class classid="193" nclones="4" nlines="22" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="1608" endline="1635" pcid="6565">
    def __init__(self, address):
        if isinstance(address, (bytes, _compat_int_types)):
            IPv4Address.__init__(self, address)
            self.network = IPv4Network(self._ip)
            self._prefixlen = self._max_prefixlen
            return

        if isinstance(address, tuple):
            IPv4Address.__init__(self, address[0])
            if len(address) > 1:
                self._prefixlen = int(address[1])
            else:
                self._prefixlen = self._max_prefixlen

            self.network = IPv4Network(address, strict=False)
            self.netmask = self.network.netmask
            self.hostmask = self.network.hostmask
            return

        addr = _split_optional_netmask(address)
        IPv4Address.__init__(self, addr[0])

        self.network = IPv4Network(address, strict=False)
        self._prefixlen = self.network._prefixlen

        self.netmask = self.network.netmask
        self.hostmask = self.network.hostmask

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="1538" endline="1565" pcid="6966">
    def __init__(self, address):
        if isinstance(address, (bytes, _compat_int_types)):
            IPv4Address.__init__(self, address)
            self.network = IPv4Network(self._ip)
            self._prefixlen = self._max_prefixlen
            return

        if isinstance(address, tuple):
            IPv4Address.__init__(self, address[0])
            if len(address) > 1:
                self._prefixlen = int(address[1])
            else:
                self._prefixlen = self._max_prefixlen

            self.network = IPv4Network(address, strict=False)
            self.netmask = self.network.netmask
            self.hostmask = self.network.hostmask
            return

        addr = _split_optional_netmask(address)
        IPv4Address.__init__(self, addr[0])

        self.network = IPv4Network(address, strict=False)
        self._prefixlen = self.network._prefixlen

        self.netmask = self.network.netmask
        self.hostmask = self.network.hostmask

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="2235" endline="2258" pcid="6999">
    def __init__(self, address):
        if isinstance(address, (bytes, _compat_int_types)):
            IPv6Address.__init__(self, address)
            self.network = IPv6Network(self._ip)
            self._prefixlen = self._max_prefixlen
            return
        if isinstance(address, tuple):
            IPv6Address.__init__(self, address[0])
            if len(address) > 1:
                self._prefixlen = int(address[1])
            else:
                self._prefixlen = self._max_prefixlen
            self.network = IPv6Network(address, strict=False)
            self.netmask = self.network.netmask
            self.hostmask = self.network.hostmask
            return

        addr = _split_optional_netmask(address)
        IPv6Address.__init__(self, addr[0])
        self.network = IPv6Network(address, strict=False)
        self.netmask = self.network.netmask
        self._prefixlen = self.network._prefixlen
        self.hostmask = self.network.hostmask

</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="2321" endline="2344" pcid="6598">
    def __init__(self, address):
        if isinstance(address, (bytes, _compat_int_types)):
            IPv6Address.__init__(self, address)
            self.network = IPv6Network(self._ip)
            self._prefixlen = self._max_prefixlen
            return
        if isinstance(address, tuple):
            IPv6Address.__init__(self, address[0])
            if len(address) > 1:
                self._prefixlen = int(address[1])
            else:
                self._prefixlen = self._max_prefixlen
            self.network = IPv6Network(address, strict=False)
            self.netmask = self.network.netmask
            self.hostmask = self.network.hostmask
            return

        addr = _split_optional_netmask(address)
        IPv6Address.__init__(self, addr[0])
        self.network = IPv6Network(address, strict=False)
        self.netmask = self.network.netmask
        self._prefixlen = self.network._prefixlen
        self.hostmask = self.network.hostmask

</source>
</class>

<class classid="194" nclones="2" nlines="11" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="1654" endline="1668" pcid="6568">
    def __lt__(self, other):
        address_less = IPv4Address.__lt__(self, other)
        if address_less is NotImplemented:
            return NotImplemented
        try:
            return (
                self.network < other.network
                or self.network == other.network
                and address_less
            )
        except AttributeError:
            # We *do* allow addresses and interfaces to be sorted. The
            # unassociated address is considered less than all interfaces.
            return False

</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="2363" endline="2377" pcid="6601">
    def __lt__(self, other):
        address_less = IPv6Address.__lt__(self, other)
        if address_less is NotImplemented:
            return NotImplemented
        try:
            return (
                self.network < other.network
                or self.network == other.network
                and address_less
            )
        except AttributeError:
            # We *do* allow addresses and interfaces to be sorted. The
            # unassociated address is considered less than all interfaces.
            return False

</source>
</class>

<class classid="195" nclones="4" nlines="38" similarity="78">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="1707" endline="1796" pcid="6574">
    def __init__(self, address, strict=True):

        """Instantiate a new IPv4 network object.

        Args:
            address: A string or integer representing the IP [& network].
              '192.0.2.0/24'
              '192.0.2.0/255.255.255.0'
              '192.0.0.2/0.0.0.255'
              are all functionally the same in IPv4. Similarly,
              '192.0.2.1'
              '192.0.2.1/255.255.255.255'
              '192.0.2.1/32'
              are also functionally equivalent. That is to say, failing to
              provide a subnetmask will create an object with a mask of /32.

              If the mask (portion after the / in the argument) is given in
              dotted quad form, it is treated as a netmask if it starts with a
              non-zero field (e.g. /255.0.0.0 == /8) and as a hostmask if it
              starts with a zero field (e.g. 0.255.255.255 == /8), with the
              single exception of an all-zero mask which is treated as a
              netmask == /0. If no mask is given, a default of /32 is used.

              Additionally, an integer can be passed, so
              IPv4Network('192.0.2.1') == IPv4Network(3221225985)
              or, more generally
              IPv4Interface(int(IPv4Interface('192.0.2.1'))) ==
                IPv4Interface('192.0.2.1')

        Raises:
            AddressValueError: If ipaddress isn't a valid IPv4 address.
            NetmaskValueError: If the netmask isn't valid for
              an IPv4 address.
            ValueError: If strict is True and a network address is not
              supplied.

        """
        _BaseNetwork.__init__(self, address)

        # Constructing from a packed address or integer
        if isinstance(address, (_compat_int_types, bytes)):
            self.network_address = IPv4Address(address)
            self.netmask, self._prefixlen = self._make_netmask(
                self._max_prefixlen
            )
            # fixme: address/network test here.
            return

        if isinstance(address, tuple):
            if len(address) > 1:
                arg = address[1]
            else:
                # We weren't given an address[1]
                arg = self._max_prefixlen
            self.network_address = IPv4Address(address[0])
            self.netmask, self._prefixlen = self._make_netmask(arg)
            packed = int(self.network_address)
            if packed & int(self.netmask) != packed:
                if strict:
                    raise ValueError("%s has host bits set" % self)
                else:
                    self.network_address = IPv4Address(
                        packed & int(self.netmask)
                    )
            return

        # Assume input argument to be string or any object representation
        # which converts into a formatted IP prefix string.
        addr = _split_optional_netmask(address)
        self.network_address = IPv4Address(self._ip_int_from_string(addr[0]))

        if len(addr) == 2:
            arg = addr[1]
        else:
            arg = self._max_prefixlen
        self.netmask, self._prefixlen = self._make_netmask(arg)

        if strict:
            if (
                IPv4Address(int(self.network_address) & int(self.netmask))
                != self.network_address
            ):
                raise ValueError("%s has host bits set" % self)
        self.network_address = IPv4Address(
            int(self.network_address) & int(self.netmask)
        )

        if self._prefixlen == (self._max_prefixlen - 1):
            self.hosts = self.__iter__

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="1634" endline="1718" pcid="6975">
    def __init__(self, address, strict=True):

        """Instantiate a new IPv4 network object.

        Args:
            address: A string or integer representing the IP [& network].
              '192.0.2.0/24'
              '192.0.2.0/255.255.255.0'
              '192.0.0.2/0.0.0.255'
              are all functionally the same in IPv4. Similarly,
              '192.0.2.1'
              '192.0.2.1/255.255.255.255'
              '192.0.2.1/32'
              are also functionally equivalent. That is to say, failing to
              provide a subnetmask will create an object with a mask of /32.

              If the mask (portion after the / in the argument) is given in
              dotted quad form, it is treated as a netmask if it starts with a
              non-zero field (e.g. /255.0.0.0 == /8) and as a hostmask if it
              starts with a zero field (e.g. 0.255.255.255 == /8), with the
              single exception of an all-zero mask which is treated as a
              netmask == /0. If no mask is given, a default of /32 is used.

              Additionally, an integer can be passed, so
              IPv4Network('192.0.2.1') == IPv4Network(3221225985)
              or, more generally
              IPv4Interface(int(IPv4Interface('192.0.2.1'))) ==
                IPv4Interface('192.0.2.1')

        Raises:
            AddressValueError: If ipaddress isn't a valid IPv4 address.
            NetmaskValueError: If the netmask isn't valid for
              an IPv4 address.
            ValueError: If strict is True and a network address is not
              supplied.

        """
        _BaseNetwork.__init__(self, address)

        # Constructing from a packed address or integer
        if isinstance(address, (_compat_int_types, bytes)):
            self.network_address = IPv4Address(address)
            self.netmask, self._prefixlen = self._make_netmask(
                self._max_prefixlen)
            # fixme: address/network test here.
            return

        if isinstance(address, tuple):
            if len(address) > 1:
                arg = address[1]
            else:
                # We weren't given an address[1]
                arg = self._max_prefixlen
            self.network_address = IPv4Address(address[0])
            self.netmask, self._prefixlen = self._make_netmask(arg)
            packed = int(self.network_address)
            if packed & int(self.netmask) != packed:
                if strict:
                    raise ValueError('%s has host bits set' % self)
                else:
                    self.network_address = IPv4Address(packed &
                                                       int(self.netmask))
            return

        # Assume input argument to be string or any object representation
        # which converts into a formatted IP prefix string.
        addr = _split_optional_netmask(address)
        self.network_address = IPv4Address(self._ip_int_from_string(addr[0]))

        if len(addr) == 2:
            arg = addr[1]
        else:
            arg = self._max_prefixlen
        self.netmask, self._prefixlen = self._make_netmask(arg)

        if strict:
            if (IPv4Address(int(self.network_address) & int(self.netmask)) !=
                    self.network_address):
                raise ValueError('%s has host bits set' % self)
        self.network_address = IPv4Address(int(self.network_address) &
                                           int(self.netmask))

        if self._prefixlen == (self._max_prefixlen - 1):
            self.hosts = self.__iter__

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="2336" endline="2414" pcid="7010">
    def __init__(self, address, strict=True):
        """Instantiate a new IPv6 Network object.

        Args:
            address: A string or integer representing the IPv6 network or the
              IP and prefix/netmask.
              '2001:db8::/128'
              '2001:db8:0000:0000:0000:0000:0000:0000/128'
              '2001:db8::'
              are all functionally the same in IPv6.  That is to say,
              failing to provide a subnetmask will create an object with
              a mask of /128.

              Additionally, an integer can be passed, so
              IPv6Network('2001:db8::') ==
                IPv6Network(42540766411282592856903984951653826560)
              or, more generally
              IPv6Network(int(IPv6Network('2001:db8::'))) ==
                IPv6Network('2001:db8::')

            strict: A boolean. If true, ensure that we have been passed
              A true network address, eg, 2001:db8::1000/124 and not an
              IP address on a network, eg, 2001:db8::1/124.

        Raises:
            AddressValueError: If address isn't a valid IPv6 address.
            NetmaskValueError: If the netmask isn't valid for
              an IPv6 address.
            ValueError: If strict was True and a network address was not
              supplied.

        """
        _BaseNetwork.__init__(self, address)

        # Efficient constructor from integer or packed address
        if isinstance(address, (bytes, _compat_int_types)):
            self.network_address = IPv6Address(address)
            self.netmask, self._prefixlen = self._make_netmask(
                self._max_prefixlen)
            return

        if isinstance(address, tuple):
            if len(address) > 1:
                arg = address[1]
            else:
                arg = self._max_prefixlen
            self.netmask, self._prefixlen = self._make_netmask(arg)
            self.network_address = IPv6Address(address[0])
            packed = int(self.network_address)
            if packed & int(self.netmask) != packed:
                if strict:
                    raise ValueError('%s has host bits set' % self)
                else:
                    self.network_address = IPv6Address(packed &
                                                       int(self.netmask))
            return

        # Assume input argument to be string or any object representation
        # which converts into a formatted IP prefix string.
        addr = _split_optional_netmask(address)

        self.network_address = IPv6Address(self._ip_int_from_string(addr[0]))

        if len(addr) == 2:
            arg = addr[1]
        else:
            arg = self._max_prefixlen
        self.netmask, self._prefixlen = self._make_netmask(arg)

        if strict:
            if (IPv6Address(int(self.network_address) & int(self.netmask)) !=
                    self.network_address):
                raise ValueError('%s has host bits set' % self)
        self.network_address = IPv6Address(int(self.network_address) &
                                           int(self.netmask))

        if self._prefixlen == (self._max_prefixlen - 1):
            self.hosts = self.__iter__

</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="2424" endline="2507" pcid="6609">
    def __init__(self, address, strict=True):
        """Instantiate a new IPv6 Network object.

        Args:
            address: A string or integer representing the IPv6 network or the
              IP and prefix/netmask.
              '2001:db8::/128'
              '2001:db8:0000:0000:0000:0000:0000:0000/128'
              '2001:db8::'
              are all functionally the same in IPv6.  That is to say,
              failing to provide a subnetmask will create an object with
              a mask of /128.

              Additionally, an integer can be passed, so
              IPv6Network('2001:db8::') ==
                IPv6Network(42540766411282592856903984951653826560)
              or, more generally
              IPv6Network(int(IPv6Network('2001:db8::'))) ==
                IPv6Network('2001:db8::')

            strict: A boolean. If true, ensure that we have been passed
              A true network address, eg, 2001:db8::1000/124 and not an
              IP address on a network, eg, 2001:db8::1/124.

        Raises:
            AddressValueError: If address isn't a valid IPv6 address.
            NetmaskValueError: If the netmask isn't valid for
              an IPv6 address.
            ValueError: If strict was True and a network address was not
              supplied.

        """
        _BaseNetwork.__init__(self, address)

        # Efficient constructor from integer or packed address
        if isinstance(address, (bytes, _compat_int_types)):
            self.network_address = IPv6Address(address)
            self.netmask, self._prefixlen = self._make_netmask(
                self._max_prefixlen
            )
            return

        if isinstance(address, tuple):
            if len(address) > 1:
                arg = address[1]
            else:
                arg = self._max_prefixlen
            self.netmask, self._prefixlen = self._make_netmask(arg)
            self.network_address = IPv6Address(address[0])
            packed = int(self.network_address)
            if packed & int(self.netmask) != packed:
                if strict:
                    raise ValueError("%s has host bits set" % self)
                else:
                    self.network_address = IPv6Address(
                        packed & int(self.netmask)
                    )
            return

        # Assume input argument to be string or any object representation
        # which converts into a formatted IP prefix string.
        addr = _split_optional_netmask(address)

        self.network_address = IPv6Address(self._ip_int_from_string(addr[0]))

        if len(addr) == 2:
            arg = addr[1]
        else:
            arg = self._max_prefixlen
        self.netmask, self._prefixlen = self._make_netmask(arg)

        if strict:
            if (
                IPv6Address(int(self.network_address) & int(self.netmask))
                != self.network_address
            ):
                raise ValueError("%s has host bits set" % self)
        self.network_address = IPv6Address(
            int(self.network_address) & int(self.netmask)
        )

        if self._prefixlen == (self._max_prefixlen - 1):
            self.hosts = self.__iter__

</source>
</class>

<class classid="196" nclones="2" nlines="70" similarity="95">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="1889" endline="1994" pcid="6577">
    def _ip_int_from_string(cls, ip_str):
        """Turn an IPv6 ip_str into an integer.

        Args:
            ip_str: A string, the IPv6 ip_str.

        Returns:
            An int, the IPv6 address

        Raises:
            AddressValueError: if ip_str isn't a valid IPv6 Address.

        """
        if not ip_str:
            raise AddressValueError("Address cannot be empty")

        parts = ip_str.split(":")

        # An IPv6 address needs at least 2 colons (3 parts).
        _min_parts = 3
        if len(parts) < _min_parts:
            msg = "At least %d parts expected in %r" % (_min_parts, ip_str)
            raise AddressValueError(msg)

        # If the address has an IPv4-style suffix, convert it to hexadecimal.
        if "." in parts[-1]:
            try:
                ipv4_int = IPv4Address(parts.pop())._ip
            except AddressValueError as exc:
                raise AddressValueError("%s in %r" % (exc, ip_str))
            parts.append("%x" % ((ipv4_int >> 16) & 0xFFFF))
            parts.append("%x" % (ipv4_int & 0xFFFF))

        # An IPv6 address can't have more than 8 colons (9 parts).
        # The extra colon comes from using the "::" notation for a single
        # leading or trailing zero part.
        _max_parts = cls._HEXTET_COUNT + 1
        if len(parts) > _max_parts:
            msg = "At most %d colons permitted in %r" % (
                _max_parts - 1,
                ip_str,
            )
            raise AddressValueError(msg)

        # Disregarding the endpoints, find '::' with nothing in between.
        # This indicates that a run of zeroes has been skipped.
        skip_index = None
        for i in _compat_range(1, len(parts) - 1):
            if not parts[i]:
                if skip_index is not None:
                    # Can't have more than one '::'
                    msg = "At most one '::' permitted in %r" % ip_str
                    raise AddressValueError(msg)
                skip_index = i

        # parts_hi is the number of parts to copy from above/before the '::'
        # parts_lo is the number of parts to copy from below/after the '::'
        if skip_index is not None:
            # If we found a '::', then check if it also covers the endpoints.
            parts_hi = skip_index
            parts_lo = len(parts) - skip_index - 1
            if not parts[0]:
                parts_hi -= 1
                if parts_hi:
                    msg = "Leading ':' only permitted as part of '::' in %r"
                    raise AddressValueError(msg % ip_str)  # ^: requires ^::
            if not parts[-1]:
                parts_lo -= 1
                if parts_lo:
                    msg = "Trailing ':' only permitted as part of '::' in %r"
                    raise AddressValueError(msg % ip_str)  # :$ requires ::$
            parts_skipped = cls._HEXTET_COUNT - (parts_hi + parts_lo)
            if parts_skipped < 1:
                msg = "Expected at most %d other parts with '::' in %r"
                raise AddressValueError(msg % (cls._HEXTET_COUNT - 1, ip_str))
        else:
            # Otherwise, allocate the entire address to parts_hi.  The
            # endpoints could still be empty, but _parse_hextet() will check
            # for that.
            if len(parts) != cls._HEXTET_COUNT:
                msg = "Exactly %d parts expected without '::' in %r"
                raise AddressValueError(msg % (cls._HEXTET_COUNT, ip_str))
            if not parts[0]:
                msg = "Leading ':' only permitted as part of '::' in %r"
                raise AddressValueError(msg % ip_str)  # ^: requires ^::
            if not parts[-1]:
                msg = "Trailing ':' only permitted as part of '::' in %r"
                raise AddressValueError(msg % ip_str)  # :$ requires ::$
            parts_hi = len(parts)
            parts_lo = 0
            parts_skipped = 0

        try:
            # Now, parse the hextets into a 128-bit integer.
            ip_int = 0
            for i in range(parts_hi):
                ip_int <<= 16
                ip_int |= cls._parse_hextet(parts[i])
            ip_int <<= 16 * parts_skipped
            for i in range(-parts_lo, 0):
                ip_int <<= 16
                ip_int |= cls._parse_hextet(parts[i])
            return ip_int
        except ValueError as exc:
            raise AddressValueError("%s in %r" % (exc, ip_str))

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="1807" endline="1910" pcid="6978">
    def _ip_int_from_string(cls, ip_str):
        """Turn an IPv6 ip_str into an integer.

        Args:
            ip_str: A string, the IPv6 ip_str.

        Returns:
            An int, the IPv6 address

        Raises:
            AddressValueError: if ip_str isn't a valid IPv6 Address.

        """
        if not ip_str:
            raise AddressValueError('Address cannot be empty')

        parts = ip_str.split(':')

        # An IPv6 address needs at least 2 colons (3 parts).
        _min_parts = 3
        if len(parts) < _min_parts:
            msg = "At least %d parts expected in %r" % (_min_parts, ip_str)
            raise AddressValueError(msg)

        # If the address has an IPv4-style suffix, convert it to hexadecimal.
        if '.' in parts[-1]:
            try:
                ipv4_int = IPv4Address(parts.pop())._ip
            except AddressValueError as exc:
                raise AddressValueError("%s in %r" % (exc, ip_str))
            parts.append('%x' % ((ipv4_int >> 16) & 0xFFFF))
            parts.append('%x' % (ipv4_int & 0xFFFF))

        # An IPv6 address can't have more than 8 colons (9 parts).
        # The extra colon comes from using the "::" notation for a single
        # leading or trailing zero part.
        _max_parts = cls._HEXTET_COUNT + 1
        if len(parts) > _max_parts:
            msg = "At most %d colons permitted in %r" % (
                _max_parts - 1, ip_str)
            raise AddressValueError(msg)

        # Disregarding the endpoints, find '::' with nothing in between.
        # This indicates that a run of zeroes has been skipped.
        skip_index = None
        for i in _compat_range(1, len(parts) - 1):
            if not parts[i]:
                if skip_index is not None:
                    # Can't have more than one '::'
                    msg = "At most one '::' permitted in %r" % ip_str
                    raise AddressValueError(msg)
                skip_index = i

        # parts_hi is the number of parts to copy from above/before the '::'
        # parts_lo is the number of parts to copy from below/after the '::'
        if skip_index is not None:
            # If we found a '::', then check if it also covers the endpoints.
            parts_hi = skip_index
            parts_lo = len(parts) - skip_index - 1
            if not parts[0]:
                parts_hi -= 1
                if parts_hi:
                    msg = "Leading ':' only permitted as part of '::' in %r"
                    raise AddressValueError(msg % ip_str)  # ^: requires ^::
            if not parts[-1]:
                parts_lo -= 1
                if parts_lo:
                    msg = "Trailing ':' only permitted as part of '::' in %r"
                    raise AddressValueError(msg % ip_str)  # :$ requires ::$
            parts_skipped = cls._HEXTET_COUNT - (parts_hi + parts_lo)
            if parts_skipped < 1:
                msg = "Expected at most %d other parts with '::' in %r"
                raise AddressValueError(msg % (cls._HEXTET_COUNT - 1, ip_str))
        else:
            # Otherwise, allocate the entire address to parts_hi.  The
            # endpoints could still be empty, but _parse_hextet() will check
            # for that.
            if len(parts) != cls._HEXTET_COUNT:
                msg = "Exactly %d parts expected without '::' in %r"
                raise AddressValueError(msg % (cls._HEXTET_COUNT, ip_str))
            if not parts[0]:
                msg = "Leading ':' only permitted as part of '::' in %r"
                raise AddressValueError(msg % ip_str)  # ^: requires ^::
            if not parts[-1]:
                msg = "Trailing ':' only permitted as part of '::' in %r"
                raise AddressValueError(msg % ip_str)  # :$ requires ::$
            parts_hi = len(parts)
            parts_lo = 0
            parts_skipped = 0

        try:
            # Now, parse the hextets into a 128-bit integer.
            ip_int = 0
            for i in range(parts_hi):
                ip_int <<= 16
                ip_int |= cls._parse_hextet(parts[i])
            ip_int <<= 16 * parts_skipped
            for i in range(-parts_lo, 0):
                ip_int <<= 16
                ip_int |= cls._parse_hextet(parts[i])
            return ip_int
        except ValueError as exc:
            raise AddressValueError("%s in %r" % (exc, ip_str))

</source>
</class>

<class classid="197" nclones="2" nlines="25" similarity="92">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="2022" endline="2069" pcid="6579">
    def _compress_hextets(cls, hextets):
        """Compresses a list of hextets.

        Compresses a list of strings, replacing the longest continuous
        sequence of "0" in the list with "" and adding empty strings at
        the beginning or at the end of the string such that subsequently
        calling ":".join(hextets) will produce the compressed version of
        the IPv6 address.

        Args:
            hextets: A list of strings, the hextets to compress.

        Returns:
            A list of strings.

        """
        best_doublecolon_start = -1
        best_doublecolon_len = 0
        doublecolon_start = -1
        doublecolon_len = 0
        for index, hextet in enumerate(hextets):
            if hextet == "0":
                doublecolon_len += 1
                if doublecolon_start == -1:
                    # Start of a sequence of zeros.
                    doublecolon_start = index
                if doublecolon_len > best_doublecolon_len:
                    # This is the longest sequence of zeros so far.
                    best_doublecolon_len = doublecolon_len
                    best_doublecolon_start = doublecolon_start
            else:
                doublecolon_len = 0
                doublecolon_start = -1

        if best_doublecolon_len > 1:
            best_doublecolon_end = (
                best_doublecolon_start + best_doublecolon_len
            )
            # For zeros at the end of the address.
            if best_doublecolon_end == len(hextets):
                hextets += [""]
            hextets[best_doublecolon_start:best_doublecolon_end] = [""]
            # For zeros at the beginning of the address.
            if best_doublecolon_start == 0:
                hextets = [""] + hextets

        return hextets

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="1938" endline="1984" pcid="6980">
    def _compress_hextets(cls, hextets):
        """Compresses a list of hextets.

        Compresses a list of strings, replacing the longest continuous
        sequence of "0" in the list with "" and adding empty strings at
        the beginning or at the end of the string such that subsequently
        calling ":".join(hextets) will produce the compressed version of
        the IPv6 address.

        Args:
            hextets: A list of strings, the hextets to compress.

        Returns:
            A list of strings.

        """
        best_doublecolon_start = -1
        best_doublecolon_len = 0
        doublecolon_start = -1
        doublecolon_len = 0
        for index, hextet in enumerate(hextets):
            if hextet == '0':
                doublecolon_len += 1
                if doublecolon_start == -1:
                    # Start of a sequence of zeros.
                    doublecolon_start = index
                if doublecolon_len > best_doublecolon_len:
                    # This is the longest sequence of zeros so far.
                    best_doublecolon_len = doublecolon_len
                    best_doublecolon_start = doublecolon_start
            else:
                doublecolon_len = 0
                doublecolon_start = -1

        if best_doublecolon_len > 1:
            best_doublecolon_end = (best_doublecolon_start +
                                    best_doublecolon_len)
            # For zeros at the end of the address.
            if best_doublecolon_end == len(hextets):
                hextets += ['']
            hextets[best_doublecolon_start:best_doublecolon_end] = ['']
            # For zeros at the beginning of the address.
            if best_doublecolon_start == 0:
                hextets = [''] + hextets

        return hextets

</source>
</class>

<class classid="198" nclones="2" nlines="13" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py" startline="2096" endline="2119" pcid="6581">
    def _explode_shorthand_ip_string(self):
        """Expand a shortened IPv6 address.

        Args:
            ip_str: A string, the IPv6 address.

        Returns:
            A string, the expanded IPv6 address.

        """
        if isinstance(self, IPv6Network):
            ip_str = _compat_str(self.network_address)
        elif isinstance(self, IPv6Interface):
            ip_str = _compat_str(self.ip)
        else:
            ip_str = _compat_str(self)

        ip_int = self._ip_int_from_string(ip_str)
        hex_str = "%032x" % ip_int
        parts = [hex_str[x : x + 4] for x in range(0, 32, 4)]
        if isinstance(self, (_BaseNetwork, IPv6Interface)):
            return "%s/%d" % (":".join(parts), self._prefixlen)
        return ":".join(parts)

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/compat/ipaddress.py" startline="2011" endline="2034" pcid="6982">
    def _explode_shorthand_ip_string(self):
        """Expand a shortened IPv6 address.

        Args:
            ip_str: A string, the IPv6 address.

        Returns:
            A string, the expanded IPv6 address.

        """
        if isinstance(self, IPv6Network):
            ip_str = _compat_str(self.network_address)
        elif isinstance(self, IPv6Interface):
            ip_str = _compat_str(self.ip)
        else:
            ip_str = _compat_str(self)

        ip_int = self._ip_int_from_string(ip_str)
        hex_str = '%032x' % ip_int
        parts = [hex_str[x:x + 4] for x in range(0, 32, 4)]
        if isinstance(self, (_BaseNetwork, IPv6Interface)):
            return '%s/%d' % (':'.join(parts), self._prefixlen)
        return ':'.join(parts)

</source>
</class>

<class classid="199" nclones="2" nlines="27" similarity="82">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/network/common/utils.py" startline="143" endline="178" pcid="6619">
    def __init__(
        self, module, attrs=None, args=None, keys=None, from_argspec=False
    ):
        args = [] if args is None else args

        self._attributes = attrs or {}
        self._module = module

        for arg in args:
            self._attributes[arg] = dict()
            if from_argspec:
                self._attributes[arg]["read_from"] = arg
            if keys and arg in keys:
                self._attributes[arg]["key"] = True

        self.attr_names = frozenset(self._attributes.keys())

        _has_key = False

        for name, attr in iteritems(self._attributes):
            if attr.get("read_from"):
                if attr["read_from"] not in self._module.argument_spec:
                    module.fail_json(
                        msg="argument %s does not exist" % attr["read_from"]
                    )
                spec = self._module.argument_spec.get(attr["read_from"])
                for key, value in iteritems(spec):
                    if key not in attr:
                        attr[key] = value

            if attr.get("key"):
                if _has_key:
                    module.fail_json(msg="only one key value can be specified")
                _has_key = True
                attr["required"] = True

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/network/common/utils.py" startline="130" endline="161" pcid="7069">
    def __init__(self, module, attrs=None, args=None, keys=None, from_argspec=False):
        args = [] if args is None else args

        self._attributes = attrs or {}
        self._module = module

        for arg in args:
            self._attributes[arg] = dict()
            if from_argspec:
                self._attributes[arg]['read_from'] = arg
            if keys and arg in keys:
                self._attributes[arg]['key'] = True

        self.attr_names = frozenset(self._attributes.keys())

        _has_key = False

        for name, attr in iteritems(self._attributes):
            if attr.get('read_from'):
                if attr['read_from'] not in self._module.argument_spec:
                    module.fail_json(msg='argument %s does not exist' % attr['read_from'])
                spec = self._module.argument_spec.get(attr['read_from'])
                for key, value in iteritems(spec):
                    if key not in attr:
                        attr[key] = value

            if attr.get('key'):
                if _has_key:
                    module.fail_json(msg='only one key value can be specified')
                _has_key = True
                attr['required'] = True

</source>
</class>

<class classid="200" nclones="2" nlines="40" similarity="74">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/network/common/utils.py" startline="191" endline="247" pcid="6622">
    def __call__(self, value, strict=True):
        if not isinstance(value, dict):
            value = self.to_dict(value)

        if strict:
            unknown = set(value).difference(self.attr_names)
            if unknown:
                self._module.fail_json(
                    msg="invalid keys: %s" % ",".join(unknown)
                )

        for name, attr in iteritems(self._attributes):
            if value.get(name) is None:
                value[name] = attr.get("default")

            if attr.get("fallback") and not value.get(name):
                fallback = attr.get("fallback", (None,))
                fallback_strategy = fallback[0]
                fallback_args = []
                fallback_kwargs = {}
                if fallback_strategy is not None:
                    for item in fallback[1:]:
                        if isinstance(item, dict):
                            fallback_kwargs = item
                        else:
                            fallback_args = item
                    try:
                        value[name] = fallback_strategy(
                            *fallback_args, **fallback_kwargs
                        )
                    except basic.AnsibleFallbackNotFound:
                        continue

            if attr.get("required") and value.get(name) is None:
                self._module.fail_json(
                    msg="missing required attribute %s" % name
                )

            if "choices" in attr:
                if value[name] not in attr["choices"]:
                    self._module.fail_json(
                        msg="%s must be one of %s, got %s"
                        % (name, ", ".join(attr["choices"]), value[name])
                    )

            if value[name] is not None:
                value_type = attr.get("type", "str")
                type_checker = self._module._CHECK_ARGUMENT_TYPES_DISPATCHER[
                    value_type
                ]
                type_checker(value[name])
            elif value.get(name):
                value[name] = self._module.params[name]

        return value


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/network/common/utils.py" startline="174" endline="219" pcid="7072">
    def __call__(self, value, strict=True):
        if not isinstance(value, dict):
            value = self.to_dict(value)

        if strict:
            unknown = set(value).difference(self.attr_names)
            if unknown:
                self._module.fail_json(msg='invalid keys: %s' % ','.join(unknown))

        for name, attr in iteritems(self._attributes):
            if value.get(name) is None:
                value[name] = attr.get('default')

            if attr.get('fallback') and not value.get(name):
                fallback = attr.get('fallback', (None,))
                fallback_strategy = fallback[0]
                fallback_args = []
                fallback_kwargs = {}
                if fallback_strategy is not None:
                    for item in fallback[1:]:
                        if isinstance(item, dict):
                            fallback_kwargs = item
                        else:
                            fallback_args = item
                    try:
                        value[name] = fallback_strategy(*fallback_args, **fallback_kwargs)
                    except basic.AnsibleFallbackNotFound:
                        continue

            if attr.get('required') and value.get(name) is None:
                self._module.fail_json(msg='missing required attribute %s' % name)

            if 'choices' in attr:
                if value[name] not in attr['choices']:
                    self._module.fail_json(msg='%s must be one of %s, got %s' % (name, ', '.join(attr['choices']), value[name]))

            if value[name] is not None:
                value_type = attr.get('type', 'str')
                type_checker = self._module._CHECK_ARGUMENT_TYPES_DISPATCHER[value_type]
                type_checker(value[name])
            elif value.get(name):
                value[name] = self._module.params[name]

        return value


</source>
</class>

<class classid="201" nclones="2" nlines="24" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/network/common/utils.py" startline="280" endline="323" pcid="6626">
def dict_diff(base, comparable):
    """ Generate a dict object of differences

    This function will compare two dict objects and return the difference
    between them as a dict object.  For scalar values, the key will reflect
    the updated value.  If the key does not exist in `comparable`, then then no
    key will be returned.  For lists, the value in comparable will wholly replace
    the value in base for the key.  For dicts, the returned value will only
    return keys that are different.

    :param base: dict object to base the diff on
    :param comparable: dict object to compare against base

    :returns: new dict object with differences
    """
    if not isinstance(base, dict):
        raise AssertionError("`base` must be of type <dict>")
    if not isinstance(comparable, dict):
        if comparable is None:
            comparable = dict()
        else:
            raise AssertionError("`comparable` must be of type <dict>")

    updates = dict()

    for key, value in iteritems(base):
        if isinstance(value, dict):
            item = comparable.get(key)
            if item is not None:
                sub_diff = dict_diff(value, comparable[key])
                if sub_diff:
                    updates[key] = sub_diff
        else:
            comparable_value = comparable.get(key)
            if comparable_value is not None:
                if sort_list(base[key]) != sort_list(comparable_value):
                    updates[key] = comparable_value

    for key in set(comparable.keys()).difference(base.keys()):
        updates[key] = comparable.get(key)

    return updates


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/network/common/utils.py" startline="245" endline="288" pcid="7076">
def dict_diff(base, comparable):
    """ Generate a dict object of differences

    This function will compare two dict objects and return the difference
    between them as a dict object.  For scalar values, the key will reflect
    the updated value.  If the key does not exist in `comparable`, then then no
    key will be returned.  For lists, the value in comparable will wholly replace
    the value in base for the key.  For dicts, the returned value will only
    return keys that are different.

    :param base: dict object to base the diff on
    :param comparable: dict object to compare against base

    :returns: new dict object with differences
    """
    if not isinstance(base, dict):
        raise AssertionError("`base` must be of type <dict>")
    if not isinstance(comparable, dict):
        if comparable is None:
            comparable = dict()
        else:
            raise AssertionError("`comparable` must be of type <dict>")

    updates = dict()

    for key, value in iteritems(base):
        if isinstance(value, dict):
            item = comparable.get(key)
            if item is not None:
                sub_diff = dict_diff(value, comparable[key])
                if sub_diff:
                    updates[key] = sub_diff
        else:
            comparable_value = comparable.get(key)
            if comparable_value is not None:
                if sort_list(base[key]) != sort_list(comparable_value):
                    updates[key] = comparable_value

    for key in set(comparable.keys()).difference(base.keys()):
        updates[key] = comparable.get(key)

    return updates


</source>
</class>

<class classid="202" nclones="2" nlines="47" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/network/common/utils.py" startline="324" endline="388" pcid="6627">
def dict_merge(base, other):
    """ Return a new dict object that combines base and other

    This will create a new dict object that is a combination of the key/value
    pairs from base and other.  When both keys exist, the value will be
    selected from other.  If the value is a list object, the two lists will
    be combined and duplicate entries removed.

    :param base: dict object to serve as base
    :param other: dict object to combine with base

    :returns: new combined dict object
    """
    if not isinstance(base, dict):
        raise AssertionError("`base` must be of type <dict>")
    if not isinstance(other, dict):
        raise AssertionError("`other` must be of type <dict>")

    combined = dict()

    for key, value in iteritems(base):
        if isinstance(value, dict):
            if key in other:
                item = other.get(key)
                if item is not None:
                    if isinstance(other[key], Mapping):
                        combined[key] = dict_merge(value, other[key])
                    else:
                        combined[key] = other[key]
                else:
                    combined[key] = item
            else:
                combined[key] = value
        elif isinstance(value, list):
            if key in other:
                item = other.get(key)
                if item is not None:
                    try:
                        combined[key] = list(set(chain(value, item)))
                    except TypeError:
                        value.extend([i for i in item if i not in value])
                        combined[key] = value
                else:
                    combined[key] = item
            else:
                combined[key] = value
        else:
            if key in other:
                other_value = other.get(key)
                if other_value is not None:
                    if sort_list(base[key]) != sort_list(other_value):
                        combined[key] = other_value
                    else:
                        combined[key] = value
                else:
                    combined[key] = other_value
            else:
                combined[key] = value

    for key in set(other.keys()).difference(base.keys()):
        combined[key] = other.get(key)

    return combined


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/network/common/utils.py" startline="289" endline="353" pcid="7077">
def dict_merge(base, other):
    """ Return a new dict object that combines base and other

    This will create a new dict object that is a combination of the key/value
    pairs from base and other.  When both keys exist, the value will be
    selected from other.  If the value is a list object, the two lists will
    be combined and duplicate entries removed.

    :param base: dict object to serve as base
    :param other: dict object to combine with base

    :returns: new combined dict object
    """
    if not isinstance(base, dict):
        raise AssertionError("`base` must be of type <dict>")
    if not isinstance(other, dict):
        raise AssertionError("`other` must be of type <dict>")

    combined = dict()

    for key, value in iteritems(base):
        if isinstance(value, dict):
            if key in other:
                item = other.get(key)
                if item is not None:
                    if isinstance(other[key], Mapping):
                        combined[key] = dict_merge(value, other[key])
                    else:
                        combined[key] = other[key]
                else:
                    combined[key] = item
            else:
                combined[key] = value
        elif isinstance(value, list):
            if key in other:
                item = other.get(key)
                if item is not None:
                    try:
                        combined[key] = list(set(chain(value, item)))
                    except TypeError:
                        value.extend([i for i in item if i not in value])
                        combined[key] = value
                else:
                    combined[key] = item
            else:
                combined[key] = value
        else:
            if key in other:
                other_value = other.get(key)
                if other_value is not None:
                    if sort_list(base[key]) != sort_list(other_value):
                        combined[key] = other_value
                    else:
                        combined[key] = value
                else:
                    combined[key] = other_value
            else:
                combined[key] = value

    for key in set(other.keys()).difference(base.keys()):
        combined[key] = other.get(key)

    return combined


</source>
</class>

<class classid="203" nclones="2" nlines="10" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/network/common/utils.py" startline="389" endline="408" pcid="6628">
def param_list_to_dict(param_list, unique_key="name", remove_key=True):
    """Rotates a list of dictionaries to be a dictionary of dictionaries.

    :param param_list: The aforementioned list of dictionaries
    :param unique_key: The name of a key which is present and unique in all of param_list's dictionaries. The value
    behind this key will be the key each dictionary can be found at in the new root dictionary
    :param remove_key: If True, remove unique_key from the individual dictionaries before returning.
    """
    param_dict = {}
    for params in param_list:
        params = params.copy()
        if remove_key:
            name = params.pop(unique_key)
        else:
            name = params.get(unique_key)
        param_dict[name] = params

    return param_dict


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/network/common/utils.py" startline="354" endline="373" pcid="7078">
def param_list_to_dict(param_list, unique_key="name", remove_key=True):
    """Rotates a list of dictionaries to be a dictionary of dictionaries.

    :param param_list: The aforementioned list of dictionaries
    :param unique_key: The name of a key which is present and unique in all of param_list's dictionaries. The value
    behind this key will be the key each dictionary can be found at in the new root dictionary
    :param remove_key: If True, remove unique_key from the individual dictionaries before returning.
    """
    param_dict = {}
    for params in param_list:
        params = params.copy()
        if remove_key:
            name = params.pop(unique_key)
        else:
            name = params.get(unique_key)
        param_dict[name] = params

    return param_dict


</source>
</class>

<class classid="204" nclones="2" nlines="19" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/network/common/utils.py" startline="409" endline="433" pcid="6629">
def conditional(expr, val, cast=None):
    match = re.match(r"^(.+)\((.+)\)$", str(expr), re.I)
    if match:
        op, arg = match.groups()
    else:
        op = "eq"
        if " " in str(expr):
            raise AssertionError("invalid expression: cannot contain spaces")
        arg = expr

    if cast is None and val is not None:
        arg = type(val)(arg)
    elif callable(cast):
        arg = cast(arg)
        val = cast(val)

    op = next((oper for alias, oper in ALIASES if op == alias), op)

    if not hasattr(operator, op) and op not in OPERATORS:
        raise ValueError("unknown operator: %s" % op)

    func = getattr(operator, op)
    return func(val, arg)


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/network/common/utils.py" startline="374" endline="398" pcid="7079">
def conditional(expr, val, cast=None):
    match = re.match(r'^(.+)\((.+)\)$', str(expr), re.I)
    if match:
        op, arg = match.groups()
    else:
        op = 'eq'
        if ' ' in str(expr):
            raise AssertionError('invalid expression: cannot contain spaces')
        arg = expr

    if cast is None and val is not None:
        arg = type(val)(arg)
    elif callable(cast):
        arg = cast(arg)
        val = cast(val)

    op = next((oper for alias, oper in ALIASES if op == alias), op)

    if not hasattr(operator, op) and op not in OPERATORS:
        raise ValueError('unknown operator: %s' % op)

    func = getattr(operator, op)
    return func(val, arg)


</source>
</class>

<class classid="205" nclones="2" nlines="14" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/network/common/utils.py" startline="470" endline="486" pcid="6635">
def load_provider(spec, args):
    provider = args.get("provider") or {}
    for key, value in iteritems(spec):
        if key not in provider:
            if "fallback" in value:
                provider[key] = _fallback(value["fallback"])
            elif "default" in value:
                provider[key] = value["default"]
            else:
                provider[key] = None
    if "authorize" in provider:
        # Coerce authorize to provider if a string has somehow snuck in.
        provider["authorize"] = boolean(provider["authorize"] or False)
    args["provider"] = provider
    return provider


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/network/common/utils.py" startline="435" endline="451" pcid="7085">
def load_provider(spec, args):
    provider = args.get('provider') or {}
    for key, value in iteritems(spec):
        if key not in provider:
            if 'fallback' in value:
                provider[key] = _fallback(value['fallback'])
            elif 'default' in value:
                provider[key] = value['default']
            else:
                provider[key] = None
    if 'authorize' in provider:
        # Coerce authorize to provider if a string has somehow snuck in.
        provider['authorize'] = boolean(provider['authorize'] or False)
    args['provider'] = provider
    return provider


</source>
</class>

<class classid="206" nclones="2" nlines="13" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/network/common/utils.py" startline="487" endline="502" pcid="6636">
def _fallback(fallback):
    strategy = fallback[0]
    args = []
    kwargs = {}

    for item in fallback[1:]:
        if isinstance(item, dict):
            kwargs = item
        else:
            args = item
    try:
        return strategy(*args, **kwargs)
    except basic.AnsibleFallbackNotFound:
        pass


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/network/common/utils.py" startline="452" endline="467" pcid="7086">
def _fallback(fallback):
    strategy = fallback[0]
    args = []
    kwargs = {}

    for item in fallback[1:]:
        if isinstance(item, dict):
            kwargs = item
        else:
            args = item
    try:
        return strategy(*args, **kwargs)
    except basic.AnsibleFallbackNotFound:
        pass


</source>
</class>

<class classid="207" nclones="2" nlines="13" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/network/common/utils.py" startline="503" endline="525" pcid="6637">
def generate_dict(spec):
    """
    Generate dictionary which is in sync with argspec

    :param spec: A dictionary that is the argspec of the module
    :rtype: A dictionary
    :returns: A dictionary in sync with argspec with default value
    """
    obj = {}
    if not spec:
        return obj

    for key, val in iteritems(spec):
        if "default" in val:
            dct = {key: val["default"]}
        elif "type" in val and val["type"] == "dict":
            dct = {key: generate_dict(val["options"])}
        else:
            dct = {key: None}
        obj.update(dct)
    return obj


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/network/common/utils.py" startline="468" endline="490" pcid="7087">
def generate_dict(spec):
    """
    Generate dictionary which is in sync with argspec

    :param spec: A dictionary that is the argspec of the module
    :rtype: A dictionary
    :returns: A dictionary in sync with argspec with default value
    """
    obj = {}
    if not spec:
        return obj

    for key, val in iteritems(spec):
        if 'default' in val:
            dct = {key: val['default']}
        elif 'type' in val and val['type'] == 'dict':
            dct = {key: generate_dict(val['options'])}
        else:
            dct = {key: None}
        obj.update(dct)
    return obj


</source>
</class>

<class classid="208" nclones="2" nlines="12" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/network/common/utils.py" startline="567" endline="588" pcid="6640">
def get_xml_conf_arg(cfg, path, data="text"):
    """
    :param cfg: The top level configuration lxml Element tree object
    :param path: The relative xpath w.r.t to top level element (cfg)
           to be searched in the xml hierarchy
    :param data: The type of data to be returned for the matched xml node.
        Valid values are text, tag, attrib, with default as text.
    :return: Returns the required type for the matched xml node or else None
    """
    match = cfg.xpath(path)
    if len(match):
        if data == "tag":
            result = getattr(match[0], "tag")
        elif data == "attrib":
            result = getattr(match[0], "attrib")
        else:
            result = getattr(match[0], "text")
    else:
        result = None
    return result


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/network/common/utils.py" startline="532" endline="553" pcid="7090">
def get_xml_conf_arg(cfg, path, data='text'):
    """
    :param cfg: The top level configuration lxml Element tree object
    :param path: The relative xpath w.r.t to top level element (cfg)
           to be searched in the xml hierarchy
    :param data: The type of data to be returned for the matched xml node.
        Valid values are text, tag, attrib, with default as text.
    :return: Returns the required type for the matched xml node or else None
    """
    match = cfg.xpath(path)
    if len(match):
        if data == 'tag':
            result = getattr(match[0], 'tag')
        elif data == 'attrib':
            result = getattr(match[0], 'attrib')
        else:
            result = getattr(match[0], 'text')
    else:
        result = None
    return result


</source>
</class>

<class classid="209" nclones="2" nlines="21" similarity="86">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/network/common/utils.py" startline="589" endline="621" pcid="6641">
def remove_empties(cfg_dict):
    """
    Generate final config dictionary

    :param cfg_dict: A dictionary parsed in the facts system
    :rtype: A dictionary
    :returns: A dictionary by eliminating keys that have null values
    """
    final_cfg = {}
    if not cfg_dict:
        return final_cfg

    for key, val in iteritems(cfg_dict):
        dct = None
        if isinstance(val, dict):
            child_val = remove_empties(val)
            if child_val:
                dct = {key: child_val}
        elif (
            isinstance(val, list)
            and val
            and all([isinstance(x, dict) for x in val])
        ):
            child_val = [remove_empties(x) for x in val]
            if child_val:
                dct = {key: child_val}
        elif val not in [None, [], {}, (), ""]:
            dct = {key: val}
        if dct:
            final_cfg.update(dct)
    return final_cfg


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/network/common/utils.py" startline="554" endline="583" pcid="7091">
def remove_empties(cfg_dict):
    """
    Generate final config dictionary

    :param cfg_dict: A dictionary parsed in the facts system
    :rtype: A dictionary
    :returns: A dictionary by eliminating keys that have null values
    """
    final_cfg = {}
    if not cfg_dict:
        return final_cfg

    for key, val in iteritems(cfg_dict):
        dct = None
        if isinstance(val, dict):
            child_val = remove_empties(val)
            if child_val:
                dct = {key: child_val}
        elif (isinstance(val, list) and val
              and all([isinstance(x, dict) for x in val])):
            child_val = [remove_empties(x) for x in val]
            if child_val:
                dct = {key: child_val}
        elif val not in [None, [], {}, (), '']:
            dct = {key: val}
        if dct:
            final_cfg.update(dct)
    return final_cfg


</source>
</class>

<class classid="210" nclones="2" nlines="17" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/network/common/utils.py" startline="656" endline="676" pcid="6645">
    def __call__(self, value, variables=None, fail_on_undefined=True):
        variables = variables or {}

        if not self.contains_vars(value):
            return value

        try:
            value = self.env.from_string(value).render(variables)
        except UndefinedError:
            if not fail_on_undefined:
                return None
            raise

        if value:
            try:
                return ast.literal_eval(value)
            except Exception:
                return str(value)
        else:
            return None

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/network/common/utils.py" startline="617" endline="637" pcid="7095">
    def __call__(self, value, variables=None, fail_on_undefined=True):
        variables = variables or {}

        if not self.contains_vars(value):
            return value

        try:
            value = self.env.from_string(value).render(variables)
        except UndefinedError:
            if not fail_on_undefined:
                return None
            raise

        if value:
            try:
                return ast.literal_eval(value)
            except Exception:
                return str(value)
        else:
            return None

</source>
</class>

<class classid="211" nclones="2" nlines="15" similarity="73">
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/network/netconf/netconf.py" startline="81" endline="101" pcid="6765">
def get_config(module, source, filter=None, lock=False):
    conn = get_connection(module)
    try:
        locked = False
        if lock:
            conn.lock(target=source)
            locked = True
        response = conn.get_config(source=source, filter=filter)

    except ConnectionError as e:
        module.fail_json(
            msg=to_text(e, errors="surrogate_then_replace").strip()
        )

    finally:
        if locked:
            conn.unlock(target=source)

    return response


</source>
<source file="systems/ansible-2.12.4rc1/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/network/netconf/netconf.py" startline="102" endline="123" pcid="6766">
def get(module, filter, lock=False):
    conn = get_connection(module)
    try:
        locked = False
        if lock:
            conn.lock(target="running")
            locked = True

        response = conn.get(filter=filter)

    except ConnectionError as e:
        module.fail_json(
            msg=to_text(e, errors="surrogate_then_replace").strip()
        )

    finally:
        if locked:
            conn.unlock(target="running")

    return response


</source>
</class>

<class classid="212" nclones="2" nlines="60" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/inventory/docker_swarm.py" startline="176" endline="250" pcid="6826">
def get_connect_params(auth, fail_function):
    if auth['tls'] or auth['tls_verify']:
        auth['docker_host'] = auth['docker_host'].replace('tcp://', 'https://')

    if auth['tls_verify'] and auth['cert_path'] and auth['key_path']:
        # TLS with certs and host verification
        if auth['cacert_path']:
            tls_config = _get_tls_config(client_cert=(auth['cert_path'], auth['key_path']),
                                         ca_cert=auth['cacert_path'],
                                         verify=True,
                                         assert_hostname=auth['tls_hostname'],
                                         ssl_version=auth['ssl_version'],
                                         fail_function=fail_function)
        else:
            tls_config = _get_tls_config(client_cert=(auth['cert_path'], auth['key_path']),
                                         verify=True,
                                         assert_hostname=auth['tls_hostname'],
                                         ssl_version=auth['ssl_version'],
                                         fail_function=fail_function)

        return dict(base_url=auth['docker_host'],
                    tls=tls_config,
                    version=auth['api_version'],
                    timeout=auth['timeout'])

    if auth['tls_verify'] and auth['cacert_path']:
        # TLS with cacert only
        tls_config = _get_tls_config(ca_cert=auth['cacert_path'],
                                     assert_hostname=auth['tls_hostname'],
                                     verify=True,
                                     ssl_version=auth['ssl_version'],
                                     fail_function=fail_function)
        return dict(base_url=auth['docker_host'],
                    tls=tls_config,
                    version=auth['api_version'],
                    timeout=auth['timeout'])

    if auth['tls_verify']:
        # TLS with verify and no certs
        tls_config = _get_tls_config(verify=True,
                                     assert_hostname=auth['tls_hostname'],
                                     ssl_version=auth['ssl_version'],
                                     fail_function=fail_function)
        return dict(base_url=auth['docker_host'],
                    tls=tls_config,
                    version=auth['api_version'],
                    timeout=auth['timeout'])

    if auth['tls'] and auth['cert_path'] and auth['key_path']:
        # TLS with certs and no host verification
        tls_config = _get_tls_config(client_cert=(auth['cert_path'], auth['key_path']),
                                     verify=False,
                                     ssl_version=auth['ssl_version'],
                                     fail_function=fail_function)
        return dict(base_url=auth['docker_host'],
                    tls=tls_config,
                    version=auth['api_version'],
                    timeout=auth['timeout'])

    if auth['tls']:
        # TLS with no certs and not host verification
        tls_config = _get_tls_config(verify=False,
                                     ssl_version=auth['ssl_version'],
                                     fail_function=fail_function)
        return dict(base_url=auth['docker_host'],
                    tls=tls_config,
                    version=auth['api_version'],
                    timeout=auth['timeout'])

    # No TLS
    return dict(base_url=auth['docker_host'],
                version=auth['api_version'],
                timeout=auth['timeout'])


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/docker/common.py" startline="207" endline="281" pcid="7021">
def get_connect_params(auth, fail_function):
    if auth['tls'] or auth['tls_verify']:
        auth['docker_host'] = auth['docker_host'].replace('tcp://', 'https://')

    if auth['tls_verify'] and auth['cert_path'] and auth['key_path']:
        # TLS with certs and host verification
        if auth['cacert_path']:
            tls_config = _get_tls_config(client_cert=(auth['cert_path'], auth['key_path']),
                                         ca_cert=auth['cacert_path'],
                                         verify=True,
                                         assert_hostname=auth['tls_hostname'],
                                         ssl_version=auth['ssl_version'],
                                         fail_function=fail_function)
        else:
            tls_config = _get_tls_config(client_cert=(auth['cert_path'], auth['key_path']),
                                         verify=True,
                                         assert_hostname=auth['tls_hostname'],
                                         ssl_version=auth['ssl_version'],
                                         fail_function=fail_function)

        return dict(base_url=auth['docker_host'],
                    tls=tls_config,
                    version=auth['api_version'],
                    timeout=auth['timeout'])

    if auth['tls_verify'] and auth['cacert_path']:
        # TLS with cacert only
        tls_config = _get_tls_config(ca_cert=auth['cacert_path'],
                                     assert_hostname=auth['tls_hostname'],
                                     verify=True,
                                     ssl_version=auth['ssl_version'],
                                     fail_function=fail_function)
        return dict(base_url=auth['docker_host'],
                    tls=tls_config,
                    version=auth['api_version'],
                    timeout=auth['timeout'])

    if auth['tls_verify']:
        # TLS with verify and no certs
        tls_config = _get_tls_config(verify=True,
                                     assert_hostname=auth['tls_hostname'],
                                     ssl_version=auth['ssl_version'],
                                     fail_function=fail_function)
        return dict(base_url=auth['docker_host'],
                    tls=tls_config,
                    version=auth['api_version'],
                    timeout=auth['timeout'])

    if auth['tls'] and auth['cert_path'] and auth['key_path']:
        # TLS with certs and no host verification
        tls_config = _get_tls_config(client_cert=(auth['cert_path'], auth['key_path']),
                                     verify=False,
                                     ssl_version=auth['ssl_version'],
                                     fail_function=fail_function)
        return dict(base_url=auth['docker_host'],
                    tls=tls_config,
                    version=auth['api_version'],
                    timeout=auth['timeout'])

    if auth['tls']:
        # TLS with no certs and not host verification
        tls_config = _get_tls_config(verify=False,
                                     ssl_version=auth['ssl_version'],
                                     fail_function=fail_function)
        return dict(base_url=auth['docker_host'],
                    tls=tls_config,
                    version=auth['api_version'],
                    timeout=auth['timeout'])

    # No TLS
    return dict(base_url=auth['docker_host'],
                version=auth['api_version'],
                timeout=auth['timeout'])


</source>
</class>

<class classid="213" nclones="2" nlines="10" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/inventory/aws_ec2.py" startline="691" endline="726" pcid="6861">
def ansible_dict_to_boto3_filter_list(filters_dict):

    """ Convert an Ansible dict of filters to list of dicts that boto3 can use
    Args:
        filters_dict (dict): Dict of AWS filters.
    Basic Usage:
        >>> filters = {'some-aws-id': 'i-01234567'}
        >>> ansible_dict_to_boto3_filter_list(filters)
        {
            'some-aws-id': 'i-01234567'
        }
    Returns:
        List: List of AWS filters and their values
        [
            {
                'Name': 'some-aws-id',
                'Values': [
                    'i-01234567',
                ]
            }
        ]
    """

    filters_list = []
    for k, v in filters_dict.items():
        filter_dict = {'Name': k}
        if isinstance(v, string_types):
            filter_dict['Values'] = [v]
        else:
            filter_dict['Values'] = v

        filters_list.append(filter_dict)

    return filters_list


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/ec2.py" startline="394" endline="429" pcid="7141">
def ansible_dict_to_boto3_filter_list(filters_dict):

    """ Convert an Ansible dict of filters to list of dicts that boto3 can use
    Args:
        filters_dict (dict): Dict of AWS filters.
    Basic Usage:
        >>> filters = {'some-aws-id': 'i-01234567'}
        >>> ansible_dict_to_boto3_filter_list(filters)
        {
            'some-aws-id': 'i-01234567'
        }
    Returns:
        List: List of AWS filters and their values
        [
            {
                'Name': 'some-aws-id',
                'Values': [
                    'i-01234567',
                ]
            }
        ]
    """

    filters_list = []
    for k, v in filters_dict.items():
        filter_dict = {'Name': k}
        if isinstance(v, string_types):
            filter_dict['Values'] = [v]
        else:
            filter_dict['Values'] = v

        filters_list.append(filter_dict)

    return filters_list


</source>
</class>

<class classid="214" nclones="2" nlines="11" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/inventory/aws_ec2.py" startline="727" endline="760" pcid="6862">
def boto3_tag_list_to_ansible_dict(tags_list, tag_name_key_name=None, tag_value_key_name=None):

    """ Convert a boto3 list of resource tags to a flat dict of key:value pairs
    Args:
        tags_list (list): List of dicts representing AWS tags.
        tag_name_key_name (str): Value to use as the key for all tag keys (useful because boto3 doesn't always use "Key")
        tag_value_key_name (str): Value to use as the key for all tag values (useful because boto3 doesn't always use "Value")
    Basic Usage:
        >>> tags_list = [{'Key': 'MyTagKey', 'Value': 'MyTagValue'}]
        >>> boto3_tag_list_to_ansible_dict(tags_list)
        [
            {
                'Key': 'MyTagKey',
                'Value': 'MyTagValue'
            }
        ]
    Returns:
        Dict: Dict of key:value pairs representing AWS tags
         {
            'MyTagKey': 'MyTagValue',
        }
    """

    if tag_name_key_name and tag_value_key_name:
        tag_candidates = {tag_name_key_name: tag_value_key_name}
    else:
        tag_candidates = {'key': 'value', 'Key': 'Value'}

    if not tags_list:
        return {}
    for k, v in tag_candidates.items():
        if k in tags_list[0] and v in tags_list[0]:
            return dict((tag[k], tag[v]) for tag in tags_list)
    raise ValueError("Couldn't find tag key (candidates %s) in tag list %s" % (str(tag_candidates), str(tags_list)))
</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/ec2.py" startline="430" endline="465" pcid="7142">
def boto3_tag_list_to_ansible_dict(tags_list, tag_name_key_name=None, tag_value_key_name=None):

    """ Convert a boto3 list of resource tags to a flat dict of key:value pairs
    Args:
        tags_list (list): List of dicts representing AWS tags.
        tag_name_key_name (str): Value to use as the key for all tag keys (useful because boto3 doesn't always use "Key")
        tag_value_key_name (str): Value to use as the key for all tag values (useful because boto3 doesn't always use "Value")
    Basic Usage:
        >>> tags_list = [{'Key': 'MyTagKey', 'Value': 'MyTagValue'}]
        >>> boto3_tag_list_to_ansible_dict(tags_list)
        [
            {
                'Key': 'MyTagKey',
                'Value': 'MyTagValue'
            }
        ]
    Returns:
        Dict: Dict of key:value pairs representing AWS tags
         {
            'MyTagKey': 'MyTagValue',
        }
    """

    if tag_name_key_name and tag_value_key_name:
        tag_candidates = {tag_name_key_name: tag_value_key_name}
    else:
        tag_candidates = {'key': 'value', 'Key': 'Value'}

    if not tags_list:
        return {}
    for k, v in tag_candidates.items():
        if k in tags_list[0] and v in tags_list[0]:
            return dict((tag[k], tag[v]) for tag in tags_list)
    raise ValueError("Couldn't find tag key (candidates %s) in tag list %s" % (str(tag_candidates), str(tags_list)))


</source>
</class>

<class classid="215" nclones="2" nlines="11" similarity="90">
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/postgres.py" startline="239" endline="255" pcid="7160">
    def grant(self):
        for group in self.groups:
            self.granted[group] = []

            for role in self.target_roles:
                # If role is in a group now, pass:
                if self.__check_membership(group, role):
                    continue

                query = 'GRANT "%s" TO "%s"' % (group, role)
                self.changed = exec_sql(self, query, ddl=True)

                if self.changed:
                    self.granted[group].append(role)

        return self.changed

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/postgres.py" startline="256" endline="272" pcid="7161">
    def revoke(self):
        for group in self.groups:
            self.revoked[group] = []

            for role in self.target_roles:
                # If role is not in a group now, pass:
                if not self.__check_membership(group, role):
                    continue

                query = 'REVOKE "%s" FROM "%s"' % (group, role)
                self.changed = exec_sql(self, query, ddl=True)

                if self.changed:
                    self.revoked[group].append(role)

        return self.changed

</source>
</class>

<class classid="216" nclones="2" nlines="13" similarity="84">
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/crypto.py" startline="290" endline="306" pcid="7170">
def load_certificate(path, content=None, backend='pyopenssl'):
    """Load the specified certificate."""

    try:
        if content is None:
            with open(path, 'rb') as cert_fh:
                cert_content = cert_fh.read()
        else:
            cert_content = content
        if backend == 'pyopenssl':
            return crypto.load_certificate(crypto.FILETYPE_PEM, cert_content)
        elif backend == 'cryptography':
            return x509.load_pem_x509_certificate(cert_content, cryptography_backend())
    except (IOError, OSError) as exc:
        raise OpenSSLObjectError(exc)


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/crypto.py" startline="307" endline="322" pcid="7171">
def load_certificate_request(path, content=None, backend='pyopenssl'):
    """Load the specified certificate signing request."""
    try:
        if content is None:
            with open(path, 'rb') as csr_fh:
                csr_content = csr_fh.read()
        else:
            csr_content = content
    except (IOError, OSError) as exc:
        raise OpenSSLObjectError(exc)
    if backend == 'pyopenssl':
        return crypto.load_certificate_request(crypto.FILETYPE_PEM, csr_content)
    elif backend == 'cryptography':
        return x509.load_pem_x509_csr(csr_content, cryptography_backend())


</source>
</class>

<class classid="217" nclones="2" nlines="22" similarity="75">
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/crypto.py" startline="1698" endline="1722" pcid="7186">
def cryptography_get_extensions_from_cert(cert):
    # Since cryptography won't give us the DER value for an extension
    # (that is only stored for unrecognized extensions), we have to re-do
    # the extension parsing outselves.
    result = dict()
    backend = cert._backend
    x509_obj = cert._x509

    for i in range(backend._lib.X509_get_ext_count(x509_obj)):
        ext = backend._lib.X509_get_ext(x509_obj, i)
        if ext == backend._ffi.NULL:
            continue
        crit = backend._lib.X509_EXTENSION_get_critical(ext)
        data = backend._lib.X509_EXTENSION_get_data(ext)
        backend.openssl_assert(data != backend._ffi.NULL)
        der = backend._ffi.buffer(data.data, data.length)[:]
        entry = dict(
            critical=(crit == 1),
            value=base64.b64encode(der),
        )
        oid = _obj2txt(backend._lib, backend._ffi, backend._lib.X509_EXTENSION_get_object(ext))
        result[oid] = entry
    return result


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/crypto.py" startline="1723" endline="1755" pcid="7187">
def cryptography_get_extensions_from_csr(csr):
    # Since cryptography won't give us the DER value for an extension
    # (that is only stored for unrecognized extensions), we have to re-do
    # the extension parsing outselves.
    result = dict()
    backend = csr._backend

    extensions = backend._lib.X509_REQ_get_extensions(csr._x509_req)
    extensions = backend._ffi.gc(
        extensions,
        lambda ext: backend._lib.sk_X509_EXTENSION_pop_free(
            ext,
            backend._ffi.addressof(backend._lib._original_lib, "X509_EXTENSION_free")
        )
    )

    for i in range(backend._lib.sk_X509_EXTENSION_num(extensions)):
        ext = backend._lib.sk_X509_EXTENSION_value(extensions, i)
        if ext == backend._ffi.NULL:
            continue
        crit = backend._lib.X509_EXTENSION_get_critical(ext)
        data = backend._lib.X509_EXTENSION_get_data(ext)
        backend.openssl_assert(data != backend._ffi.NULL)
        der = backend._ffi.buffer(data.data, data.length)[:]
        entry = dict(
            critical=(crit == 1),
            value=base64.b64encode(der),
        )
        oid = _obj2txt(backend._lib, backend._ffi, backend._lib.X509_EXTENSION_get_object(ext))
        result[oid] = entry
    return result


</source>
</class>

<class classid="218" nclones="2" nlines="14" similarity="80">
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/crypto.py" startline="1756" endline="1783" pcid="7188">
def pyopenssl_get_extensions_from_cert(cert):
    # While pyOpenSSL allows us to get an extension's DER value, it won't
    # give us the dotted string for an OID. So we have to do some magic to
    # get hold of it.
    result = dict()
    ext_count = cert.get_extension_count()
    for i in range(0, ext_count):
        ext = cert.get_extension(i)
        entry = dict(
            critical=bool(ext.get_critical()),
            value=base64.b64encode(ext.get_data()),
        )
        oid = _obj2txt(
            OpenSSL._util.lib,
            OpenSSL._util.ffi,
            OpenSSL._util.lib.X509_EXTENSION_get_object(ext._extension)
        )
        # This could also be done a bit simpler:
        #
        #   oid = _obj2txt(OpenSSL._util.lib, OpenSSL._util.ffi, OpenSSL._util.lib.OBJ_nid2obj(ext._nid))
        #
        # Unfortunately this gives the wrong result in case the linked OpenSSL
        # doesn't know the OID. That's why we have to get the OID dotted string
        # similarly to how cryptography does it.
        result[oid] = entry
    return result


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/module_utils/crypto.py" startline="1784" endline="1809" pcid="7189">
def pyopenssl_get_extensions_from_csr(csr):
    # While pyOpenSSL allows us to get an extension's DER value, it won't
    # give us the dotted string for an OID. So we have to do some magic to
    # get hold of it.
    result = dict()
    for ext in csr.get_extensions():
        entry = dict(
            critical=bool(ext.get_critical()),
            value=base64.b64encode(ext.get_data()),
        )
        oid = _obj2txt(
            OpenSSL._util.lib,
            OpenSSL._util.ffi,
            OpenSSL._util.lib.X509_EXTENSION_get_object(ext._extension)
        )
        # This could also be done a bit simpler:
        #
        #   oid = _obj2txt(OpenSSL._util.lib, OpenSSL._util.ffi, OpenSSL._util.lib.OBJ_nid2obj(ext._nid))
        #
        # Unfortunately this gives the wrong result in case the linked OpenSSL
        # doesn't know the OID. That's why we have to get the OID dotted string
        # similarly to how cryptography does it.
        result[oid] = entry
    return result


</source>
</class>

<class classid="219" nclones="2" nlines="11" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/modules/mongodb_parameter.py" startline="129" endline="148" pcid="7387">
def load_mongocnf():
    config = configparser.RawConfigParser()
    mongocnf = os.path.expanduser('~/.mongodb.cnf')

    try:
        config.readfp(open(mongocnf))
        creds = dict(
            user=config.get('client', 'user'),
            password=config.get('client', 'pass')
        )
    except (configparser.NoOptionError, IOError):
        return False

    return creds


# =========================================
# Module execution.
#

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/modules/mongodb_user.py" startline="300" endline="315" pcid="7397">
def load_mongocnf():
    config = configparser.RawConfigParser()
    mongocnf = os.path.expanduser('~/.mongodb.cnf')

    try:
        config.readfp(open(mongocnf))
        creds = dict(
            user=config.get('client', 'user'),
            password=config.get('client', 'pass')
        )
    except (configparser.NoOptionError, IOError):
        return False

    return creds


</source>
</class>

<class classid="220" nclones="2" nlines="10" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/modules/postgresql_user.py" startline="615" endline="628" pcid="7499">
def grant_database_privileges(cursor, user, db, privs):
    # Note: priv escaped by parse_privs
    privs = ', '.join(privs)
    if user == "PUBLIC":
        query = 'GRANT %s ON DATABASE %s TO PUBLIC' % (
                privs, pg_quote_identifier(db, 'database'))
    else:
        query = 'GRANT %s ON DATABASE %s TO "%s"' % (
                privs, pg_quote_identifier(db, 'database'), user)

    executed_queries.append(query)
    cursor.execute(query)


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/modules/postgresql_user.py" startline="629" endline="642" pcid="7500">
def revoke_database_privileges(cursor, user, db, privs):
    # Note: priv escaped by parse_privs
    privs = ', '.join(privs)
    if user == "PUBLIC":
        query = 'REVOKE %s ON DATABASE %s FROM PUBLIC' % (
                privs, pg_quote_identifier(db, 'database'))
    else:
        query = 'REVOKE %s ON DATABASE %s FROM "%s"' % (
                privs, pg_quote_identifier(db, 'database'), user)

    executed_queries.append(query)
    cursor.execute(query)


</source>
</class>

<class classid="221" nclones="2" nlines="15" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/modules/postgresql_user.py" startline="643" endline="663" pcid="7501">
def revoke_privileges(cursor, user, privs):
    if privs is None:
        return False

    revoke_funcs = dict(table=revoke_table_privileges,
                        database=revoke_database_privileges)
    check_funcs = dict(table=has_table_privileges,
                       database=has_database_privileges)

    changed = False
    for type_ in privs:
        for name, privileges in iteritems(privs[type_]):
            # Check that any of the privileges requested to be removed are
            # currently granted to the user
            differences = check_funcs[type_](cursor, user, name, privileges)
            if differences[0]:
                revoke_funcs[type_](cursor, user, name, privileges)
                changed = True
    return changed


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/modules/postgresql_user.py" startline="664" endline="684" pcid="7502">
def grant_privileges(cursor, user, privs):
    if privs is None:
        return False

    grant_funcs = dict(table=grant_table_privileges,
                       database=grant_database_privileges)
    check_funcs = dict(table=has_table_privileges,
                       database=has_database_privileges)

    changed = False
    for type_ in privs:
        for name, privileges in iteritems(privs[type_]):
            # Check that any of the privileges requested for the user are
            # currently missing
            differences = check_funcs[type_](cursor, user, name, privileges)
            if differences[2]:
                grant_funcs[type_](cursor, user, name, privileges)
                changed = True
    return changed


</source>
</class>

<class classid="222" nclones="2" nlines="18" similarity="72">
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/modules/aws_s3.py" startline="319" endline="340" pcid="7510">
def key_check(module, s3, bucket, obj, version=None, validate=True):
    exists = True
    try:
        if version:
            s3.head_object(Bucket=bucket, Key=obj, VersionId=version)
        else:
            s3.head_object(Bucket=bucket, Key=obj)
    except botocore.exceptions.ClientError as e:
        # if a client error is thrown, check if it's a 404 error
        # if it's a 404 error, then the object does not exist
        error_code = int(e.response['Error']['Code'])
        if error_code == 404:
            exists = False
        elif error_code == 403 and validate is False:
            pass
        else:
            module.fail_json_aws(e, msg="Failed while looking up object (during key check) %s." % obj)
    except botocore.exceptions.BotoCoreError as e:
        module.fail_json_aws(e, msg="Failed while looking up object (during key check) %s." % obj)
    return exists


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/modules/aws_s3.py" startline="358" endline="378" pcid="7513">
def bucket_check(module, s3, bucket, validate=True):
    exists = True
    try:
        s3.head_bucket(Bucket=bucket)
    except botocore.exceptions.ClientError as e:
        # If a client error is thrown, then check that it was a 404 error.
        # If it was a 404 error, then the bucket does not exist.
        error_code = int(e.response['Error']['Code'])
        if error_code == 404:
            exists = False
        elif error_code == 403 and validate is False:
            pass
        else:
            module.fail_json_aws(e, msg="Failed while looking up bucket (during bucket_check) %s." % bucket)
    except botocore.exceptions.EndpointConnectionError as e:
        module.fail_json_aws(e, msg="Invalid endpoint provided")
    except botocore.exceptions.BotoCoreError as e:
        module.fail_json_aws(e, msg="Failed while looking up bucket (during bucket_check) %s." % bucket)
    return exists


</source>
</class>

<class classid="223" nclones="2" nlines="15" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/modules/x509_crl.py" startline="625" endline="640" pcid="7542">
    def _dump_revoked(self, entry):
        return {
            'serial_number': entry['serial_number'],
            'revocation_date': entry['revocation_date'].strftime(TIMESTAMP_FORMAT),
            'issuer':
                [crypto_utils.cryptography_decode_name(issuer) for issuer in entry['issuer']]
                if entry['issuer'] is not None else None,
            'issuer_critical': entry['issuer_critical'],
            'reason': crypto_utils.REVOCATION_REASON_MAP_INVERSE.get(entry['reason']) if entry['reason'] is not None else None,
            'reason_critical': entry['reason_critical'],
            'invalidity_date':
                entry['invalidity_date'].strftime(TIMESTAMP_FORMAT)
                if entry['invalidity_date'] is not None else None,
            'invalidity_date_critical': entry['invalidity_date_critical'],
        }

</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/modules/x509_crl_info.py" startline="190" endline="205" pcid="7587">
    def _dump_revoked(self, entry):
        return {
            'serial_number': entry['serial_number'],
            'revocation_date': entry['revocation_date'].strftime(TIMESTAMP_FORMAT),
            'issuer':
                [crypto_utils.cryptography_decode_name(issuer) for issuer in entry['issuer']]
                if entry['issuer'] is not None else None,
            'issuer_critical': entry['issuer_critical'],
            'reason': crypto_utils.REVOCATION_REASON_MAP_INVERSE.get(entry['reason']) if entry['reason'] is not None else None,
            'reason_critical': entry['reason_critical'],
            'invalidity_date':
                entry['invalidity_date'].strftime(TIMESTAMP_FORMAT)
                if entry['invalidity_date'] is not None else None,
            'invalidity_date_critical': entry['invalidity_date_critical'],
        }

</source>
</class>

<class classid="224" nclones="5" nlines="13" similarity="71">
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/modules/s3_bucket.py" startline="489" endline="505" pcid="7561">
def wait_policy_is_applied(module, s3_client, bucket_name, expected_policy, should_fail=True):
    for dummy in range(0, 12):
        try:
            current_policy = get_bucket_policy(s3_client, bucket_name)
        except (ClientError, BotoCoreError) as e:
            module.fail_json_aws(e, msg="Failed to get bucket policy")

        if compare_policies(current_policy, expected_policy):
            time.sleep(5)
        else:
            return current_policy
    if should_fail:
        module.fail_json(msg="Bucket policy failed to apply in the expected time")
    else:
        return None


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/modules/s3_bucket.py" startline="506" endline="521" pcid="7562">
def wait_payer_is_applied(module, s3_client, bucket_name, expected_payer, should_fail=True):
    for dummy in range(0, 12):
        try:
            requester_pays_status = get_bucket_request_payment(s3_client, bucket_name)
        except (BotoCoreError, ClientError) as e:
            module.fail_json_aws(e, msg="Failed to get bucket request payment")
        if requester_pays_status != expected_payer:
            time.sleep(5)
        else:
            return requester_pays_status
    if should_fail:
        module.fail_json(msg="Bucket request payment failed to apply in the expected time")
    else:
        return None


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/modules/s3_bucket.py" startline="522" endline="534" pcid="7563">
def wait_encryption_is_applied(module, s3_client, bucket_name, expected_encryption):
    for dummy in range(0, 12):
        try:
            encryption = get_bucket_encryption(s3_client, bucket_name)
        except (BotoCoreError, ClientError) as e:
            module.fail_json_aws(e, msg="Failed to get updated encryption for bucket")
        if encryption != expected_encryption:
            time.sleep(5)
        else:
            return encryption
    module.fail_json(msg="Bucket encryption failed to apply in the expected time")


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/modules/s3_bucket.py" startline="548" endline="560" pcid="7565">
def wait_tags_are_applied(module, s3_client, bucket_name, expected_tags_dict):
    for dummy in range(0, 12):
        try:
            current_tags_dict = get_current_bucket_tags_dict(s3_client, bucket_name)
        except (ClientError, BotoCoreError) as e:
            module.fail_json_aws(e, msg="Failed to get bucket policy")
        if current_tags_dict != expected_tags_dict:
            time.sleep(5)
        else:
            return current_tags_dict
    module.fail_json(msg="Bucket tags failed to apply in the expected time")


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/modules/s3_bucket.py" startline="535" endline="547" pcid="7564">
def wait_versioning_is_applied(module, s3_client, bucket_name, required_versioning):
    for dummy in range(0, 24):
        try:
            versioning_status = get_bucket_versioning(s3_client, bucket_name)
        except (BotoCoreError, ClientError) as e:
            module.fail_json_aws(e, msg="Failed to get updated versioning for bucket")
        if versioning_status.get('Status') != required_versioning:
            time.sleep(8)
        else:
            return versioning_status
    module.fail_json(msg="Bucket versioning failed to apply in the expected time")


</source>
</class>

<class classid="225" nclones="2" nlines="10" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/modules/ec2_group.py" startline="801" endline="812" pcid="7615">
def revoke(client, module, ip_permissions, group_id, rule_type):
    if not module.check_mode:
        try:
            if rule_type == 'in':
                client.revoke_security_group_ingress(GroupId=group_id, IpPermissions=ip_permissions)
            elif rule_type == 'out':
                client.revoke_security_group_egress(GroupId=group_id, IpPermissions=ip_permissions)
        except (BotoCoreError, ClientError) as e:
            rules = 'ingress rules' if rule_type == 'in' else 'egress rules'
            module.fail_json_aws(e, "Unable to revoke {0}: {1}".format(rules, ip_permissions))


</source>
<source file="systems/ansible-2.12.4rc1/test/support/integration/plugins/modules/ec2_group.py" startline="821" endline="832" pcid="7617">
def authorize(client, module, ip_permissions, group_id, rule_type):
    if not module.check_mode:
        try:
            if rule_type == 'in':
                client.authorize_security_group_ingress(GroupId=group_id, IpPermissions=ip_permissions)
            elif rule_type == 'out':
                client.authorize_security_group_egress(GroupId=group_id, IpPermissions=ip_permissions)
        except (BotoCoreError, ClientError) as e:
            rules = 'ingress rules' if rule_type == 'in' else 'egress rules'
            module.fail_json_aws(e, "Unable to authorize {0}: {1}".format(rules, ip_permissions))


</source>
</class>

<class classid="226" nclones="2" nlines="11" similarity="90">
<source file="systems/ansible-2.12.4rc1/test/integration/targets/old_style_cache_plugins/plugins/cache/legacy_redis.py" startline="93" endline="106" pcid="7641">
    def set(self, key, value):

        value2 = json.dumps(value)
        if self._timeout > 0:  # a timeout of 0 is handled as meaning 'never expire'
            self._db.setex(self._make_key(key), int(self._timeout), value2)
        else:
            self._db.set(self._make_key(key), value2)

        if VERSION[0] == 2:
            self._db.zadd(self._keys_set, time.time(), key)
        else:
            self._db.zadd(self._keys_set, {key: time.time()})
        self._cache[key] = value

</source>
<source file="systems/ansible-2.12.4rc1/test/integration/targets/old_style_cache_plugins/plugins/cache/configurable_redis.py" startline="99" endline="112" pcid="7653">
    def set(self, key, value):

        value2 = json.dumps(value, cls=AnsibleJSONEncoder, sort_keys=True, indent=4)
        if self._timeout > 0:  # a timeout of 0 is handled as meaning 'never expire'
            self._db.setex(self._make_key(key), int(self._timeout), value2)
        else:
            self._db.set(self._make_key(key), value2)

        if VERSION[0] == 2:
            self._db.zadd(self._keys_set, time.time(), key)
        else:
            self._db.zadd(self._keys_set, {key: time.time()})
        self._cache[key] = value

</source>
</class>

<class classid="227" nclones="2" nlines="33" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/integration/targets/service_facts/files/ansible_test_service.py" startline="24" endline="65" pcid="7729">
def createDaemon():
    try:
        pid = os.fork()
    except OSError as e:
        raise Exception("%s [%d]" % (e.strerror, e.errno))

    if (pid == 0):
        os.setsid()

        try:
            pid = os.fork()
        except OSError as e:
            raise Exception("%s [%d]" % (e.strerror, e.errno))

        if (pid == 0):
            os.chdir(WORKDIR)
            os.umask(UMASK)
        else:
            f = open('/var/run/ansible_test_service.pid', 'w')
            f.write("%d\n" % pid)
            f.close()
            os._exit(0)
    else:
        os._exit(0)

    maxfd = resource.getrlimit(resource.RLIMIT_NOFILE)[1]
    if (maxfd == resource.RLIM_INFINITY):
        maxfd = MAXFD

    for fd in range(0, maxfd):
        try:
            os.close(fd)
        except OSError:  # ERROR, fd wasn't open to begin with (ignored)
            pass

    os.open(REDIRECT_TO, os.O_RDWR)
    os.dup2(0, 1)
    os.dup2(0, 2)

    return (0)


</source>
<source file="systems/ansible-2.12.4rc1/test/integration/targets/service/files/ansible_test_service.py" startline="25" endline="66" pcid="7936">
def createDaemon():
    try:
        pid = os.fork()
    except OSError as e:
        raise Exception("%s [%d]" % (e.strerror, e.errno))

    if (pid == 0):
        os.setsid()

        try:
            pid = os.fork()
        except OSError as e:
            raise Exception("%s [%d]" % (e.strerror, e.errno))

        if (pid == 0):
            os.chdir(WORKDIR)
            os.umask(UMASK)
        else:
            f = open('/var/run/ansible_test_service.pid', 'w')
            f.write("%d\n" % pid)
            f.close()
            os._exit(0)
    else:
        os._exit(0)

    maxfd = resource.getrlimit(resource.RLIMIT_NOFILE)[1]
    if (maxfd == resource.RLIM_INFINITY):
        maxfd = MAXFD

    for fd in range(0, maxfd):
        try:
            os.close(fd)
        except OSError:  # ERROR, fd wasn't open to begin with (ignored)
            pass

    os.open(REDIRECT_TO, os.O_RDWR)
    os.dup2(0, 1)
    os.dup2(0, 2)

    return (0)


</source>
</class>

<class classid="228" nclones="2" nlines="25" similarity="92">
<source file="systems/ansible-2.12.4rc1/test/integration/targets/async/library/async_test.py" startline="10" endline="48" pcid="7760">
def main():
    if "--interactive" in sys.argv:
        import ansible.module_utils.basic
        ansible.module_utils.basic._ANSIBLE_ARGS = json.dumps(dict(
            ANSIBLE_MODULE_ARGS=dict(
                fail_mode="graceful"
            )
        ))

    module = AnsibleModule(
        argument_spec=dict(
            fail_mode=dict(type='list', default=['success'])
        )
    )

    result = dict(changed=True)

    fail_mode = module.params['fail_mode']

    try:
        if 'leading_junk' in fail_mode:
            print("leading junk before module output")

        if 'graceful' in fail_mode:
            module.fail_json(msg="failed gracefully")

        if 'exception' in fail_mode:
            raise Exception('failing via exception')

        if 'stderr' in fail_mode:
            print('printed to stderr', file=sys.stderr)

        module.exit_json(**result)

    finally:
        if 'trailing_junk' in fail_mode:
            print("trailing junk after module output")


</source>
<source file="systems/ansible-2.12.4rc1/test/integration/targets/async_fail/library/async_test.py" startline="11" endline="52" pcid="7874">
def main():
    if "--interactive" in sys.argv:
        import ansible.module_utils.basic
        ansible.module_utils.basic._ANSIBLE_ARGS = json.dumps(dict(
            ANSIBLE_MODULE_ARGS=dict(
                fail_mode="graceful"
            )
        ))

    module = AnsibleModule(
        argument_spec=dict(
            fail_mode=dict(type='list', default=['success'])
        )
    )

    result = dict(changed=True)

    fail_mode = module.params['fail_mode']

    try:
        if 'leading_junk' in fail_mode:
            print("leading junk before module output")

        if 'graceful' in fail_mode:
            module.fail_json(msg="failed gracefully")

        if 'exception' in fail_mode:
            raise Exception('failing via exception')

        if 'recovered_fail' in fail_mode:
            result = {"msg": "succeeded", "failed": False, "changed": True}
            # Wait in the middle to setup a race where the controller reads incomplete data from our
            # special async_status the first poll
            time.sleep(5)

        module.exit_json(**result)

    finally:
        if 'trailing_junk' in fail_mode:
            print("trailing junk after module output")


</source>
</class>

<class classid="229" nclones="2" nlines="16" similarity="76">
<source file="systems/ansible-2.12.4rc1/test/integration/targets/collections/collections/ansible_collections/testns/content_adj/plugins/inventory/statichost.py" startline="43" endline="68" pcid="7830">
    def parse(self, inventory, loader, path, cache=None):

        super(InventoryModule, self).parse(inventory, loader, path)

        # Initialize and validate options
        self._read_config_data(path)

        # Exercise cache
        cache_key = self.get_cache_key(path)
        attempt_to_read_cache = self.get_option('cache') and cache
        cache_needs_update = self.get_option('cache') and not cache
        if attempt_to_read_cache:
            try:
                host_to_add = self._cache[cache_key]
            except KeyError:
                cache_needs_update = True
        if not attempt_to_read_cache or cache_needs_update:
            host_to_add = self.get_option('hostname')

        # this is where the magic happens
        self.inventory.add_host(host_to_add, 'all')
        self._cache[cache_key] = host_to_add

        # self.inventory.add_group()...
        # self.inventory.add_child()...
        # self.inventory.set_variable()..
</source>
<source file="systems/ansible-2.12.4rc1/test/integration/targets/inventory_cache/plugins/inventory/cache_host.py" startline="32" endline="56" pcid="7977">
    def parse(self, inventory, loader, path, cache=None):
        super(InventoryModule, self).parse(inventory, loader, path)
        self._read_config_data(path)

        cache_key = self.get_cache_key(path)
        # user has enabled cache and the cache is not being flushed
        read_cache = self.get_option('cache') and cache
        # user has enabled cache and the cache is being flushed
        update_cache = self.get_option('cache') and not cache

        host = None
        if read_cache:
            try:
                host = self._cache[cache_key]
            except KeyError:
                # cache expired
                update_cache = True

        if host is None:
            host = 'testhost{0}'.format(random.randint(0, 50))

        self.inventory.add_host(host, 'all')

        if update_cache:
            self._cache[cache_key] = host
</source>
</class>

<class classid="230" nclones="2" nlines="12" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/integration/targets/collections_runtime_pythonpath/ansible-collection-python-dist-foo/ansible_collections/python/dist/plugins/modules/boo.py" startline="12" endline="26" pcid="7871">
def main():
    module = AnsibleModule(
        argument_spec={
            'name': {'default': ''},
        },
    )
    name = module.params['name']

    module.exit_json(
        msg='Greeting {name} completed.'.
        format(name=name.title()),
        greeting=', {name}!'.format(name=name),
    )


</source>
<source file="systems/ansible-2.12.4rc1/test/integration/targets/collections_runtime_pythonpath/ansible-collection-python-dist-boo/ansible_collections/python/dist/plugins/modules/boo.py" startline="12" endline="26" pcid="7872">
def main():
    module = AnsibleModule(
        argument_spec={
            'name': {'default': 'world'},
        },
    )
    name = module.params['name']

    module.exit_json(
        msg='Greeting {name} completed.'.
        format(name=name.title()),
        greeting='Hello, {name}!'.format(name=name),
    )


</source>
</class>

<class classid="231" nclones="2" nlines="12" similarity="84">
<source file="systems/ansible-2.12.4rc1/test/integration/targets/dict_transformations/library/convert_snake_case.py" startline="36" endline="53" pcid="7911">
def main():
    module = AnsibleModule(
        argument_spec=dict(
            data=dict(type='dict', required=True),
            reversible=dict(type='bool', default=False),
            ignore_list=dict(type='list', default=[]),
        ),
    )

    result = camel_dict_to_snake_dict(
        module.params['data'],
        module.params['reversible'],
        module.params['ignore_list']
    )

    module.exit_json(data=result)


</source>
<source file="systems/ansible-2.12.4rc1/test/integration/targets/dict_transformations/library/convert_camelCase.py" startline="31" endline="46" pcid="7912">
def main():
    module = AnsibleModule(
        argument_spec=dict(
            data=dict(type='dict', required=True),
            capitalize_first=dict(type='bool', default=False),
        ),
    )

    result = snake_dict_to_camel_dict(
        module.params['data'],
        module.params['capitalize_first']
    )

    module.exit_json(data=result)


</source>
</class>

<class classid="232" nclones="4" nlines="13" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/integration/targets/module_precedence/lib_with_extension/ping.py" startline="54" endline="69" pcid="7961">
def main():
    module = AnsibleModule(
        argument_spec=dict(
            data=dict(required=False, default=None),
        ),
        supports_check_mode=True
    )
    result = dict(ping='pong')
    if module.params['data']:
        if module.params['data'] == 'crash':
            raise Exception("boom")
        result['ping'] = module.params['data']
    result['location'] = 'library'
    module.exit_json(**result)


</source>
<source file="systems/ansible-2.12.4rc1/test/integration/targets/module_precedence/multiple_roles/bar/library/ping.py" startline="54" endline="69" pcid="7964">
def main():
    module = AnsibleModule(
        argument_spec=dict(
            data=dict(required=False, default=None),
        ),
        supports_check_mode=True
    )
    result = dict(ping='pong')
    if module.params['data']:
        if module.params['data'] == 'crash':
            raise Exception("boom")
        result['ping'] = module.params['data']
    result['location'] = 'role: bar'
    module.exit_json(**result)


</source>
<source file="systems/ansible-2.12.4rc1/test/integration/targets/module_precedence/multiple_roles/foo/library/ping.py" startline="54" endline="69" pcid="7965">
def main():
    module = AnsibleModule(
        argument_spec=dict(
            data=dict(required=False, default=None),
        ),
        supports_check_mode=True
    )
    result = dict(ping='pong')
    if module.params['data']:
        if module.params['data'] == 'crash':
            raise Exception("boom")
        result['ping'] = module.params['data']
    result['location'] = 'role: foo'
    module.exit_json(**result)


</source>
<source file="systems/ansible-2.12.4rc1/test/integration/targets/module_precedence/roles_with_extension/foo/library/ping.py" startline="54" endline="69" pcid="7963">
def main():
    module = AnsibleModule(
        argument_spec=dict(
            data=dict(required=False, default=None),
        ),
        supports_check_mode=True
    )
    result = dict(ping='pong')
    if module.params['data']:
        if module.params['data'] == 'crash':
            raise Exception("boom")
        result['ping'] = module.params['data']
    result['location'] = 'role: foo'
    module.exit_json(**result)


</source>
</class>

<class classid="233" nclones="2" nlines="11" similarity="72">
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/controller/sanity/validate-modules/validate_modules/main.py" startline="469" endline="483" pcid="8230">
    def _check_type_instead_of_isinstance(self, powershell=False):
        if powershell:
            return
        for line_no, line in enumerate(self.text.splitlines()):
            typekeyword = TYPE_REGEX.match(line)
            if typekeyword:
                # TODO: add column
                self.reporter.error(
                    path=self.object_path,
                    code='unidiomatic-typecheck',
                    msg=('Type comparison using type() found. '
                         'Use isinstance() instead'),
                    line=line_no + 1
                )

</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/controller/sanity/validate-modules/validate_modules/main.py" startline="484" endline="499" pcid="8231">
    def _check_for_sys_exit(self):
        # Optimize out the happy path
        if 'sys.exit' not in self.text:
            return

        for line_no, line in enumerate(self.text.splitlines()):
            sys_exit_usage = SYS_EXIT_REGEX.match(line)
            if sys_exit_usage:
                # TODO: add column
                self.reporter.error(
                    path=self.object_path,
                    code='use-fail-json-not-sys-exit',
                    msg='sys.exit() call found. Should be exit_json/fail_json',
                    line=line_no + 1
                )

</source>
</class>

<class classid="234" nclones="2" nlines="12" similarity="76">
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/controller/sanity/validate-modules/validate_modules/main.py" startline="519" endline="533" pcid="8233">
    def _check_for_subprocess(self):
        for child in self.ast.body:
            if isinstance(child, ast.Import):
                if child.names[0].name == 'subprocess':
                    for line_no, line in enumerate(self.text.splitlines()):
                        sp_match = SUBPROCESS_REGEX.search(line)
                        if sp_match:
                            self.reporter.error(
                                path=self.object_path,
                                code='use-run-command-not-popen',
                                msg=('subprocess.Popen call found. Should be module.run_command'),
                                line=(line_no + 1),
                                column=(sp_match.span()[0] + 1)
                            )

</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/controller/sanity/validate-modules/validate_modules/main.py" startline="534" endline="546" pcid="8234">
    def _check_for_os_call(self):
        if 'os.call' in self.text:
            for line_no, line in enumerate(self.text.splitlines()):
                os_call_match = OS_CALL_REGEX.search(line)
                if os_call_match:
                    self.reporter.error(
                        path=self.object_path,
                        code='use-run-command-not-os-call',
                        msg=('os.call() call found. Should be module.run_command'),
                        line=(line_no + 1),
                        column=(os_call_match.span()[0] + 1)
                    )

</source>
</class>

<class classid="235" nclones="2" nlines="10" similarity="80">
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/controller/sanity/validate-modules/validate_modules/main.py" startline="803" endline="814" pcid="8241">
    def _find_ps_docs_py_file(self):
        if self.object_name in self.PS_DOC_REJECTLIST:
            return
        py_path = self.path.replace('.ps1', '.py')
        if not os.path.isfile(py_path):
            self.reporter.error(
                path=self.object_path,
                code='missing-python-doc',
                msg='Missing python documentation file'
            )
        return py_path

</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/controller/sanity/validate-modules/validate_modules/main.py" startline="2249" endline="2263" pcid="8257">
    def object_path(self):
        return self.path

    def validate(self):
        super(PythonPackageValidator, self).validate()

        if self.basename in self.REJECTLIST_FILES:
            return

        init_file = os.path.join(self.path, '__init__.py')
        if not os.path.exists(init_file):
            self.reporter.error(
                path=self.object_path,
                code='subdirectory-missing-init',
                msg='Ansible module subdirectories must contain an __init__.py'
</source>
</class>

<class classid="236" nclones="2" nlines="15" similarity="93">
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/controller/tools/collection_detail.py" startline="36" endline="58" pcid="8303">
def read_manifest_json(collection_path):
    """Return collection information from the MANIFEST.json file."""
    manifest_path = os.path.join(collection_path, 'MANIFEST.json')

    if not os.path.exists(manifest_path):
        return None

    try:
        with open(manifest_path) as manifest_file:
            manifest = json.load(manifest_file)

        collection_info = manifest.get('collection_info') or dict()

        result = dict(
            version=collection_info.get('version'),
        )
        validate_version(result['version'])
    except Exception as ex:  # pylint: disable=broad-except
        raise Exception('{0}: {1}'.format(os.path.basename(manifest_path), ex))

    return result


</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_util/controller/tools/collection_detail.py" startline="59" endline="79" pcid="8304">
def read_galaxy_yml(collection_path):
    """Return collection information from the galaxy.yml file."""
    galaxy_path = os.path.join(collection_path, 'galaxy.yml')

    if not os.path.exists(galaxy_path):
        return None

    try:
        with open(galaxy_path) as galaxy_file:
            galaxy = yaml.safe_load(galaxy_file)

        result = dict(
            version=galaxy.get('version'),
        )
        validate_version(result['version'])
    except Exception as ex:  # pylint: disable=broad-except
        raise Exception('{0}: {1}'.format(os.path.basename(galaxy_path), ex))

    return result


</source>
</class>

<class classid="237" nclones="2" nlines="30" similarity="73">
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/provider/layout/__init__.py" startline="77" endline="113" pcid="8327">
    def __init__(self,
                 root,  # type: str
                 paths,  # type: t.List[str]
                 plugin_paths,  # type: t.Dict[str, str]
                 collection,  # type: t.Optional[CollectionDetail]
                 test_path,  # type: str
                 results_path,  # type: str
                 sanity_path,  # type: str
                 sanity_messages,  # type: t.Optional[LayoutMessages]
                 integration_path,  # type: str
                 integration_targets_path,  # type: str
                 integration_vars_path,  # type: str
                 integration_messages,  # type: t.Optional[LayoutMessages]
                 unit_path,  # type: str
                 unit_module_path,  # type: str
                 unit_module_utils_path,  # type: str
                 unit_messages,  # type: t.Optional[LayoutMessages]
                 ):  # type: (...) -> None
        super().__init__(root, paths)

        self.plugin_paths = plugin_paths
        self.collection = collection
        self.test_path = test_path
        self.results_path = results_path
        self.sanity_path = sanity_path
        self.sanity_messages = sanity_messages
        self.integration_path = integration_path
        self.integration_targets_path = integration_targets_path
        self.integration_vars_path = integration_vars_path
        self.integration_messages = integration_messages
        self.unit_path = unit_path
        self.unit_module_path = unit_module_path
        self.unit_module_utils_path = unit_module_utils_path
        self.unit_messages = unit_messages

        self.is_ansible = root == ANSIBLE_SOURCE_ROOT

</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/containers.py" startline="542" endline="567" pcid="8534">
    def __init__(self,
                 image,  # type: str
                 context,  # type: str
                 name,  # type: str
                 container_id,  # type: str
                 ports,  # type: t.List[int]
                 aliases,  # type: t.List[str]
                 publish_ports,  # type: bool
                 running,  # type: bool
                 existing,  # type: bool
                 cleanup,  # type: CleanupMode
                 env,  # type: t.Optional[t.Dict[str, str]]
                 ):  # type: (...) -> None
        self.image = image
        self.context = context
        self.name = name
        self.container_id = container_id
        self.ports = ports
        self.aliases = aliases
        self.publish_ports = publish_ports
        self.running = running
        self.existing = existing
        self.cleanup = cleanup
        self.env = env
        self.details = None  # type: t.Optional[SupportContainer]

</source>
</class>

<class classid="238" nclones="2" nlines="12" similarity="76">
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/parsers/__init__.py" startline="74" endline="87" pcid="8408">
    def get_stateless_parsers(self):  # type: () -> t.Dict[str, Parser]
        """Return a dictionary of type names and type parsers."""
        parsers = dict(
            origin=OriginParser(),
            docker=DockerParser(controller=True),
        )

        if get_ci_provider().supports_core_ci_auth():
            parsers.update(
                remote=PosixRemoteParser(controller=True),
            )

        return parsers

</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/parsers/__init__.py" startline="100" endline="117" pcid="8410">
    def get_stateless_parsers(self):  # type: () -> t.Dict[str, Parser]
        """Return a dictionary of type names and type parsers."""
        parsers = dict(
            controller=ControllerParser(),
            docker=DockerParser(controller=False),
        )

        if get_ci_provider().supports_core_ci_auth():
            parsers.update(
                remote=PosixRemoteParser(controller=False),
            )

        parsers.update(
            ssh=PosixSshParser(),
        )

        return parsers

</source>
</class>

<class classid="239" nclones="2" nlines="12" similarity="100">
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/parsers/__init__.py" startline="143" endline="159" pcid="8415">
    def get_internal_parsers(self, targets):  # type: (t.List[WindowsConfig]) -> t.Dict[str, Parser]
        """Return a dictionary of type names and type parsers."""
        parsers = {}

        if self.allow_inventory and not targets:
            parsers.update(
                inventory=WindowsInventoryParser(),
            )

        if not targets or not any(isinstance(target, WindowsInventoryConfig) for target in targets):
            if get_ci_provider().supports_core_ci_auth():
                parsers.update(
                    remote=WindowsRemoteParser(),
                )

        return parsers

</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/parsers/__init__.py" startline="185" endline="201" pcid="8420">
    def get_internal_parsers(self, targets):  # type: (t.List[NetworkConfig]) -> t.Dict[str, Parser]
        """Return a dictionary of type names and type parsers."""
        parsers = {}

        if self.allow_inventory and not targets:
            parsers.update(
                inventory=NetworkInventoryParser(),
            )

        if not targets or not any(isinstance(target, NetworkInventoryConfig) for target in targets):
            if get_ci_provider().supports_core_ci_auth():
                parsers.update(
                    remote=NetworkRemoteParser(),
                )

        return parsers

</source>
</class>

<class classid="240" nclones="19" nlines="26" similarity="71">
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/commands/shell.py" startline="22" endline="47" pcid="8457">
def do_shell(
        subparsers,
        parent,  # type: argparse.ArgumentParser
        completer,  # type: CompositeActionCompletionFinder
):
    """Command line parsing for the `shell` command."""
    parser = subparsers.add_parser(
        'shell',
        parents=[parent],
        help='open an interactive shell',
    )  # type: argparse.ArgumentParser

    parser.set_defaults(
        func=command_shell,
        config=ShellConfig,
    )

    shell = parser.add_argument_group(title='shell arguments')

    shell.add_argument(
        '--raw',
        action='store_true',
        help='direct to shell with no setup',
    )

    add_environments(parser, completer, ControllerMode.DELEGATED, TargetMode.SHELL)  # shell
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/commands/integration/posix.py" startline="27" endline="50" pcid="8459">
def do_posix_integration(
        subparsers,
        parent,  # type: argparse.ArgumentParser
        add_integration_common,  # type: t.Callable[[argparse.ArgumentParser], None]
        completer,  # type: CompositeActionCompletionFinder
):
    """Command line parsing for the `integration` command."""
    parser = subparsers.add_parser(
        'integration',
        parents=[parent],
        help='posix integration tests',
    )  # type: argparse.ArgumentParser

    parser.set_defaults(
        func=command_posix_integration,
        targets_func=walk_posix_integration_targets,
        config=PosixIntegrationConfig,
    )

    posix_integration = t.cast(argparse.ArgumentParser, parser.add_argument_group(title='integration test arguments'))

    add_integration_common(posix_integration)

    add_environments(parser, completer, ControllerMode.DELEGATED, TargetMode.POSIX_INTEGRATION)  # integration
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/commands/integration/windows.py" startline="27" endline="50" pcid="8462">
def do_windows_integration(
        subparsers,
        parent,  # type: argparse.ArgumentParser
        add_integration_common,  # type: t.Callable[[argparse.ArgumentParser], None]
        completer,  # type: CompositeActionCompletionFinder
):
    """Command line parsing for the `windows-integration` command."""
    parser = subparsers.add_parser(
        'windows-integration',
        parents=[parent],
        help='windows integration tests',
    )  # type: argparse.ArgumentParser

    parser.set_defaults(
        func=command_windows_integration,
        targets_func=walk_windows_integration_targets,
        config=WindowsIntegrationConfig,
    )

    windows_integration = t.cast(argparse.ArgumentParser, parser.add_argument_group(title='windows integration test arguments'))

    add_integration_common(windows_integration)

    add_environments(parser, completer, ControllerMode.DELEGATED, TargetMode.WINDOWS_INTEGRATION)  # windows-integration
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/commands/coverage/analyze/targets/expand.py" startline="19" endline="48" pcid="8471">
def do_expand(
        subparsers,
        parent,  # type: argparse.ArgumentParser
        completer,  # type: CompositeActionCompletionFinder
):
    """Command line parsing for the `coverage analyze targets expand` command."""
    parser = subparsers.add_parser(
        'expand',
        parents=[parent],
        help='expand target names from integers in aggregated coverage',
    )  # type: argparse.ArgumentParser

    parser.set_defaults(
        func=command_coverage_analyze_targets_expand,
        config=CoverageAnalyzeTargetsExpandConfig,
    )

    targets_expand = parser.add_argument_group(title='coverage arguments')

    targets_expand.add_argument(
        'input_file',
        help='input file to read aggregated coverage from',
    )

    targets_expand.add_argument(
        'output_file',
        help='output file to write expanded coverage to',
    )

    add_environments(parser, completer, ControllerMode.ORIGIN, TargetMode.NO_TARGETS)  # coverage analyze targets expand
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/commands/coverage/analyze/targets/combine.py" startline="19" endline="49" pcid="8470">
def do_combine(
        subparsers,
        parent,  # type: argparse.ArgumentParser
        completer,  # type: CompositeActionCompletionFinder
):
    """Command line parsing for the `coverage analyze targets combine` command."""
    parser = subparsers.add_parser(
        'combine',
        parents=[parent],
        help='combine multiple aggregated coverage files',
    )  # type: argparse.ArgumentParser

    parser.set_defaults(
        func=command_coverage_analyze_targets_combine,
        config=CoverageAnalyzeTargetsCombineConfig,
    )

    targets_combine = parser.add_argument_group('coverage arguments')

    targets_combine.add_argument(
        'input_file',
        nargs='+',
        help='input file to read aggregated coverage from',
    )

    targets_combine.add_argument(
        'output_file',
        help='output file to write aggregated coverage to',
    )

    add_environments(parser, completer, ControllerMode.ORIGIN, TargetMode.NO_TARGETS)  # coverage analyze targets combine
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/commands/coverage/analyze/targets/generate.py" startline="19" endline="49" pcid="8468">
def do_generate(
        subparsers,
        parent,  # type: argparse.ArgumentParser
        completer,  # type: CompositeActionCompletionFinder
):
    """Command line parsing for the `coverage analyze targets generate` command."""
    parser = subparsers.add_parser(
        'generate',
        parents=[parent],
        help='aggregate coverage by integration test target',
    )  # type: argparse.ArgumentParser

    parser.set_defaults(
        func=command_coverage_analyze_targets_generate,
        config=CoverageAnalyzeTargetsGenerateConfig,
    )

    targets_generate = parser.add_argument_group(title='coverage arguments')

    targets_generate.add_argument(
        'input_dir',
        nargs='?',
        help='directory to read coverage from',
    )

    targets_generate.add_argument(
        'output_file',
        help='output file for aggregated coverage',
    )

    add_environments(parser, completer, ControllerMode.ORIGIN, TargetMode.NO_TARGETS)  # coverage analyze targets generate
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/commands/integration/network.py" startline="32" endline="62" pcid="8460">
def do_network_integration(
        subparsers,
        parent,  # type: argparse.ArgumentParser
        add_integration_common,  # type: t.Callable[[argparse.ArgumentParser], None]
        completer,  # type: CompositeActionCompletionFinder
):
    """Command line parsing for the `network-integration` command."""
    parser = subparsers.add_parser(
        'network-integration',
        parents=[parent],
        help='network integration tests',
    )  # type: argparse.ArgumentParser

    parser.set_defaults(
        func=command_network_integration,
        targets_func=walk_network_integration_targets,
        config=NetworkIntegrationConfig)

    network_integration = t.cast(argparse.ArgumentParser, parser.add_argument_group(title='network integration test arguments'))

    add_integration_common(network_integration)

    network_integration.add_argument(
        '--testcase',
        metavar='TESTCASE',
        help='limit a test to a specified testcase',
    ).completer = complete_network_testcase

    add_environments(parser, completer, ControllerMode.DELEGATED, TargetMode.NETWORK_INTEGRATION)  # network-integration


</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/commands/coverage/html.py" startline="20" endline="42" pcid="8466">
def do_html(
        subparsers,
        parent,  # type: argparse.ArgumentParser
        add_coverage_common,  # type: t.Callable[[argparse.ArgumentParser], None]
        completer,  # type: CompositeActionCompletionFinder
):  # type: (...) -> None
    """Command line parsing for the `coverage html` command."""
    parser = subparsers.add_parser(
        'html',
        parents=[parent],
        help='generate html coverage report',
    )  # type: argparse.ArgumentParser

    parser.set_defaults(
        func=command_coverage_html,
        config=CoverageHtmlConfig,
    )

    coverage_combine = t.cast(argparse.ArgumentParser, parser.add_argument_group(title='coverage arguments'))

    add_coverage_common(coverage_combine)

    add_environments(parser, completer, ControllerMode.DELEGATED, TargetMode.NO_TARGETS)  # coverage html
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/commands/coverage/combine.py" startline="20" endline="48" pcid="8477">
def do_combine(
        subparsers,
        parent,  # type: argparse.ArgumentParser
        add_coverage_common,  # type: t.Callable[[argparse.ArgumentParser], None]
        completer,  # type: CompositeActionCompletionFinder
):  # type: (...) -> None
    """Command line parsing for the `coverage combine` command."""
    parser = subparsers.add_parser(
        'combine',
        parents=[parent],
        help='combine coverage data and rewrite remote paths',
    )  # type: argparse.ArgumentParser

    parser.set_defaults(
        func=command_coverage_combine,
        config=CoverageCombineConfig,
    )

    coverage_combine = t.cast(argparse.ArgumentParser, parser.add_argument_group(title='coverage arguments'))

    add_coverage_common(coverage_combine)

    coverage_combine.add_argument(
        '--export',
        metavar='DIR',
        help='directory to export combined coverage files to',
    )

    add_environments(parser, completer, ControllerMode.DELEGATED, TargetMode.NO_TARGETS)  # coverage combine
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/commands/coverage/erase.py" startline="19" endline="36" pcid="8475">
def do_erase(
        subparsers,
        parent,  # type: argparse.ArgumentParser
        completer,  # type: CompositeActionCompletionFinder
):  # type: (...) -> None
    """Command line parsing for the `coverage erase` command."""
    parser = subparsers.add_parser(
        'erase',
        parents=[parent],
        help='erase coverage data files',
    )  # type: argparse.ArgumentParser

    parser.set_defaults(
        func=command_coverage_erase,
        config=CoverageEraseConfig,
    )

    add_environments(parser, completer, ControllerMode.ORIGIN, TargetMode.NO_TARGETS)  # coverage erase
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/commands/coverage/xml.py" startline="20" endline="42" pcid="8476">
def do_xml(
        subparsers,
        parent,  # type: argparse.ArgumentParser
        add_coverage_common,  # type: t.Callable[[argparse.ArgumentParser], None]
        completer,  # type: CompositeActionCompletionFinder
):  # type: (...) -> None
    """Command line parsing for the `coverage xml` command."""
    parser = subparsers.add_parser(
        'xml',
        parents=[parent],
        help='generate xml coverage report',
    )  # type: argparse.ArgumentParser

    parser.set_defaults(
        func=command_coverage_xml,
        config=CoverageXmlConfig,
    )

    coverage_combine = t.cast(argparse.ArgumentParser, parser.add_argument_group(title='coverage arguments'))

    add_coverage_common(coverage_combine)

    add_environments(parser, completer, ControllerMode.DELEGATED, TargetMode.NO_TARGETS)  # coverage xml
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/commands/units.py" startline="26" endline="65" pcid="8458">
def do_units(
        subparsers,
        parent,  # type: argparse.ArgumentParser
        completer,  # type: CompositeActionCompletionFinder
):
    """Command line parsing for the `units` command."""
    parser = subparsers.add_parser(
        'units',
        parents=[parent],
        help='unit tests',
    )  # type: argparse.ArgumentParser

    parser.set_defaults(
        func=command_units,
        targets_func=walk_units_targets,
        config=UnitsConfig,
    )

    units = parser.add_argument_group(title='unit test arguments')

    units.add_argument(
        '--collect-only',
        action='store_true',
        help='collect tests but do not execute them',
    )

    units.add_argument(
        '--num-workers',
        metavar='INT',
        type=int,
        help='number of workers to use (default: auto)',
    )

    units.add_argument(
        '--requirements-mode',
        choices=('only', 'skip'),
        help=argparse.SUPPRESS,
    )

    add_environments(parser, completer, ControllerMode.DELEGATED, TargetMode.UNITS)  # units
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/commands/coverage/report.py" startline="20" endline="60" pcid="8474">
def do_report(
        subparsers,
        parent,  # type: argparse.ArgumentParser
        add_coverage_common,  # type: t.Callable[[argparse.ArgumentParser], None]
        completer,  # type: CompositeActionCompletionFinder
):  # type: (...) -> None
    """Command line parsing for the `coverage report` command."""
    parser = subparsers.add_parser(
        'report',
        parents=[parent],
        help='generate console coverage report',
    )  # type: argparse.ArgumentParser

    parser.set_defaults(
        func=command_coverage_report,
        config=CoverageReportConfig,
    )

    coverage_report = t.cast(argparse.ArgumentParser, parser.add_argument_group('coverage arguments'))

    add_coverage_common(coverage_report)

    coverage_report.add_argument(
        '--show-missing',
        action='store_true',
        help='show line numbers of statements not executed',
    )

    coverage_report.add_argument(
        '--include',
        metavar='PAT[,...]',
        help='only include paths that match a pattern (accepts quoted shell wildcards)',
    )

    coverage_report.add_argument(
        '--omit',
        metavar='PAT[,...]',
        help='omit paths that match a pattern (accepts quoted shell wildcards)',
    )

    add_environments(parser, completer, ControllerMode.DELEGATED, TargetMode.NO_TARGETS)  # coverage report
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/commands/env.py" startline="19" endline="63" pcid="8465">
def do_env(
        subparsers,
        parent,  # type: argparse.ArgumentParser
        completer,  # type: CompositeActionCompletionFinder
):
    """Command line parsing for the `env` command."""
    parser = subparsers.add_parser(
        'env',
        parents=[parent],
        help='show information about the test environment',
    )  # type: argparse.ArgumentParser

    parser.set_defaults(
        func=command_env,
        config=EnvConfig,
    )

    env = parser.add_argument_group(title='env arguments')

    env.add_argument(
        '--show',
        action='store_true',
        help='show environment on stdout',
    )

    env.add_argument(
        '--dump',
        action='store_true',
        help='dump environment to disk',
    )

    env.add_argument(
        '--list-files',
        action='store_true',
        help='list files on stdout',
    )

    env.add_argument(
        '--timeout',
        type=int,
        metavar='MINUTES',
        help='timeout for future ansible-test commands (0 clears)',
    )

    add_environments(parser, completer, ControllerMode.NO_DELEGATION, TargetMode.NO_TARGETS)  # env
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/commands/coverage/analyze/targets/missing.py" startline="19" endline="65" pcid="8469">
def do_missing(
        subparsers,
        parent,  # type: argparse.ArgumentParser
        completer,  # type: CompositeActionCompletionFinder
):
    """Command line parsing for the `coverage analyze targets missing` command."""
    parser = subparsers.add_parser(
        'missing',
        parents=[parent],
        help='identify coverage in one file missing in another',
    )  # type: argparse.ArgumentParser

    parser.set_defaults(
        func=command_coverage_analyze_targets_missing,
        config=CoverageAnalyzeTargetsMissingConfig,
    )

    targets_missing = parser.add_argument_group(title='coverage arguments')

    targets_missing.add_argument(
        'from_file',
        help='input file containing aggregated coverage',
    )

    targets_missing.add_argument(
        'to_file',
        help='input file containing aggregated coverage',
    )

    targets_missing.add_argument(
        'output_file',
        help='output file to write aggregated coverage to',
    )

    targets_missing.add_argument(
        '--only-gaps',
        action='store_true',
        help='report only arcs/lines not hit by any target',
    )

    targets_missing.add_argument(
        '--only-exists',
        action='store_true',
        help='limit results to files that exist',
    )

    add_environments(parser, completer, ControllerMode.ORIGIN, TargetMode.NO_TARGETS)  # coverage analyze targets missing
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/commands/coverage/analyze/targets/filter.py" startline="19" endline="76" pcid="8467">
def do_filter(
        subparsers,
        parent,  # type: argparse.ArgumentParser
        completer,  # type: CompositeActionCompletionFinder
):
    """Command line parsing for the `coverage analyze targets filter` command."""
    parser = subparsers.add_parser(
        'filter',
        parents=[parent],
        help='filter aggregated coverage data',
    )  # type: argparse.ArgumentParser

    parser.set_defaults(
        func=command_coverage_analyze_targets_filter,
        config=CoverageAnalyzeTargetsFilterConfig,
    )

    targets_filter = parser.add_argument_group(title='coverage arguments')

    targets_filter.add_argument(
        'input_file',
        help='input file to read aggregated coverage from',
    )

    targets_filter.add_argument(
        'output_file',
        help='output file to write expanded coverage to',
    )

    targets_filter.add_argument(
        '--include-target',
        metavar='TGT',
        dest='include_targets',
        action='append',
        help='include the specified targets',
    )

    targets_filter.add_argument(
        '--exclude-target',
        metavar='TGT',
        dest='exclude_targets',
        action='append',
        help='exclude the specified targets',
    )

    targets_filter.add_argument(
        '--include-path',
        metavar='REGEX',
        help='include paths matching the given regex',
    )

    targets_filter.add_argument(
        '--exclude-path',
        metavar='REGEX',
        help='exclude paths matching the given regex',
    )

    add_environments(parser, completer, ControllerMode.ORIGIN, TargetMode.NO_TARGETS)  # coverage analyze targets filter
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/environments.py" startline="378" endline="420" pcid="8493">
def add_global_docker(
        parser,  # type: argparse.ArgumentParser
        controller_mode,  # type: ControllerMode
):  # type: (...) -> None
    """Add global options for Docker."""
    if controller_mode != ControllerMode.DELEGATED:
        parser.set_defaults(
            docker_no_pull=False,
            docker_network=None,
            docker_terminate=None,
            prime_containers=False,
        )

        return

    parser.add_argument(
        '--docker-no-pull',
        action='store_true',
        help=argparse.SUPPRESS,  # deprecated, kept for now (with a warning) for backwards compatibility
    )

    parser.add_argument(
        '--docker-network',
        metavar='NET',
        help='run using the specified network',
    )

    parser.add_argument(
        '--docker-terminate',
        metavar='T',
        default=TerminateMode.ALWAYS,
        type=TerminateMode,
        action=EnumAction,
        help='terminate the container: %(choices)s (default: %(default)s)',
    )

    parser.add_argument(
        '--prime-containers',
        action='store_true',
        help='download containers without running tests',
    )


</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/environments.py" startline="461" endline="499" pcid="8495">
def add_global_remote(
        parser,  # type: argparse.ArgumentParser
        controller_mode,  # type: ControllerMode
):  # type: (...) -> None
    """Add global options for remote instances."""
    if controller_mode != ControllerMode.DELEGATED:
        parser.set_defaults(
            remote_stage=None,
            remote_endpoint=None,
            remote_terminate=None,
        )

        return

    suppress = None if get_ci_provider().supports_core_ci_auth() else argparse.SUPPRESS

    parser.add_argument(
        '--remote-stage',
        metavar='STAGE',
        default='prod',
        help=suppress or 'remote stage to use: prod, dev',
    ).completer = complete_remote_stage

    parser.add_argument(
        '--remote-endpoint',
        metavar='EP',
        help=suppress or 'remote provisioning endpoint to use',
    )

    parser.add_argument(
        '--remote-terminate',
        metavar='T',
        default=TerminateMode.NEVER,
        type=TerminateMode,
        action=EnumAction,
        help=suppress or 'terminate the remote instance: %(choices)s (default: %(default)s)',
    )


</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/environments.py" startline="105" endline="146" pcid="8483">
def add_global_options(
        parser,  # type: argparse.ArgumentParser
        controller_mode,  # type: ControllerMode
):
    """Add global options for controlling the test environment that work with both the legacy and composite options."""
    global_parser = t.cast(argparse.ArgumentParser, parser.add_argument_group(title='global environment arguments'))

    global_parser.add_argument(
        '--containers',
        metavar='JSON',
        help=argparse.SUPPRESS,
    )

    global_parser.add_argument(
        '--pypi-proxy',
        action='store_true',
        help=argparse.SUPPRESS,
    )

    global_parser.add_argument(
        '--pypi-endpoint',
        metavar='URI',
        help=argparse.SUPPRESS,
    )

    global_parser.add_argument(
        '--requirements',
        action='store_true',
        default=False,
        help='install command requirements',
    )

    global_parser.add_argument(
        '--no-pip-check',
        action='store_true',
        help=argparse.SUPPRESS,  # deprecated, kept for now (with a warning) for backwards compatibility
    )

    add_global_remote(global_parser, controller_mode)
    add_global_docker(global_parser, controller_mode)


</source>
</class>

<class classid="241" nclones="3" nlines="14" similarity="70">
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/commands/coverage/analyze/targets/__init__.py" startline="31" endline="48" pcid="8472">
def do_targets(
        subparsers,
        parent,  # type: argparse.ArgumentParser
        completer,  # type: CompositeActionCompletionFinder
):  # type: (...) -> None
    """Command line parsing for all `coverage analyze targets` commands."""
    targets = subparsers.add_parser(
        'targets',
        help='analyze integration test target coverage',
    )

    targets_subparsers = targets.add_subparsers(metavar='COMMAND', required=True)

    do_generate(targets_subparsers, parent, completer)
    do_expand(targets_subparsers, parent, completer)
    do_filter(targets_subparsers, parent, completer)
    do_combine(targets_subparsers, parent, completer)
    do_missing(targets_subparsers, parent, completer)
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/commands/coverage/analyze/__init__.py" startline="15" endline="28" pcid="8473">
def do_analyze(
        subparsers,
        parent,  # type: argparse.ArgumentParser
        completer,  # type: CompositeActionCompletionFinder
):  # type: (...) -> None
    """Command line parsing for all `coverage analyze` commands."""
    parser = subparsers.add_parser(
        'analyze',
        help='analyze collected coverage data',
    )  # type: argparse.ArgumentParser

    analyze_subparsers = parser.add_subparsers(metavar='COMMAND', required=True)

    do_targets(analyze_subparsers, parent, completer)
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/commands/coverage/__init__.py" startline="39" endline="62" pcid="8478">
def do_coverage(
        subparsers,
        parent,  # type: argparse.ArgumentParser
        completer,  # type: CompositeActionCompletionFinder
):  # type: (...) -> None
    """Command line parsing for all `coverage` commands."""
    coverage_common = argparse.ArgumentParser(add_help=False, parents=[parent])

    parser = subparsers.add_parser(
        'coverage',
        help='code coverage management and reporting',
    )

    coverage_subparsers = parser.add_subparsers(metavar='COMMAND', required=True)

    do_analyze(coverage_subparsers, coverage_common, completer)
    do_erase(coverage_subparsers, coverage_common, completer)

    do_combine(coverage_subparsers, parent, add_coverage_common, completer)
    do_report(coverage_subparsers, parent, add_coverage_common, completer)
    do_html(coverage_subparsers, parent, add_coverage_common, completer)
    do_xml(coverage_subparsers, parent, add_coverage_common, completer)


</source>
</class>

<class classid="242" nclones="2" nlines="14" similarity="71">
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/environments.py" startline="332" endline="349" pcid="8490">
def add_environment_windows(
        environments_parser,  # type: argparse.ArgumentParser
):  # type: (...) -> None
    """Add environment arguments for running on a windows host."""
    environments_parser.add_argument(
        '--windows',
        metavar='VERSION',
        action='append',
        help='windows version',
    ).completer = complete_windows

    environments_parser.add_argument(
        '--inventory',
        metavar='PATH',
        help='path to inventory used for tests',
    )


</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/cli/environments.py" startline="361" endline="377" pcid="8492">
def add_environment_venv(
        exclusive_parser,  # type: argparse.ArgumentParser
        environments_parser,  # type: argparse.ArgumentParser
):  # type: (...) -> None
    """Add environment arguments for running in ansible-test managed virtual environments."""
    exclusive_parser.add_argument(
        '--venv',
        action='store_true',
        help='run from a virtual environment',
    )

    environments_parser.add_argument(
        '--venv-system-site-packages',
        action='store_true',
        help='enable system site packages')


</source>
</class>

<class classid="243" nclones="2" nlines="22" similarity="82">
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/venv.py" startline="185" endline="214" pcid="8819">
def run_venv(args,  # type: EnvironmentConfig
             run_python,  # type: str
             system_site_packages,  # type: bool
             pip,  # type: bool
             path,  # type: str
             ):  # type: (...) -> bool
    """Create a virtual environment using the 'venv' module. Not available on Python 2.x."""
    cmd = [run_python, '-m', 'venv']

    if system_site_packages:
        cmd.append('--system-site-packages')

    if not pip:
        cmd.append('--without-pip')

    cmd.append(path)

    try:
        run_command(args, cmd, capture=True)
    except SubprocessError as ex:
        remove_tree(path)

        if args.verbosity > 1:
            display.error(ex)

        return False

    return True


</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/venv.py" startline="215" endline="250" pcid="8820">
def run_virtualenv(args,  # type: EnvironmentConfig
                   run_python,  # type: str
                   env_python,  # type: str
                   system_site_packages,  # type: bool
                   pip,  # type: bool
                   path,  # type: str
                   ):  # type: (...) -> bool
    """Create a virtual environment using the 'virtualenv' module."""
    # always specify which interpreter to use to guarantee the desired interpreter is provided
    # otherwise virtualenv may select a different interpreter than the one running virtualenv
    cmd = [run_python, '-m', 'virtualenv', '--python', env_python]

    if system_site_packages:
        cmd.append('--system-site-packages')

    if not pip:
        cmd.append('--no-pip')
        # these options provide consistency with venv, which does not install them without pip
        cmd.append('--no-setuptools')
        cmd.append('--no-wheel')

    cmd.append(path)

    try:
        run_command(args, cmd, capture=True)
    except SubprocessError as ex:
        remove_tree(path)

        if args.verbosity > 1:
            display.error(ex)

        return False

    return True


</source>
</class>

<class classid="244" nclones="6" nlines="14" similarity="72">
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/commands/integration/cloud/digitalocean.py" startline="37" endline="55" pcid="8878">
    def get_environment_config(self):  # type: () -> CloudEnvironmentConfig
        """Return environment configuration for use in the test environment after delegation."""
        parser = configparser.ConfigParser()
        parser.read(self.config_path)

        env_vars = dict(
            DO_API_KEY=parser.get('default', 'key'),
        )

        display.sensitive.add(env_vars['DO_API_KEY'])

        ansible_vars = dict(
            resource_prefix=self.resource_prefix,
        )

        return CloudEnvironmentConfig(
            env_vars=env_vars,
            ansible_vars=ansible_vars,
        )
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/commands/integration/cloud/cloudscale.py" startline="42" endline="62" pcid="8910">
    def get_environment_config(self):  # type: () -> CloudEnvironmentConfig
        """Return environment configuration for use in the test environment after delegation."""
        parser = configparser.ConfigParser()
        parser.read(self.config_path)

        env_vars = dict(
            CLOUDSCALE_API_TOKEN=parser.get('default', 'cloudscale_api_token'),
        )

        display.sensitive.add(env_vars['CLOUDSCALE_API_TOKEN'])

        ansible_vars = dict(
            cloudscale_resource_prefix=self.resource_prefix,
        )

        ansible_vars.update(dict((key.lower(), value) for key, value in env_vars.items()))

        return CloudEnvironmentConfig(
            env_vars=env_vars,
            ansible_vars=ansible_vars,
        )
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/commands/integration/cloud/cs.py" startline="151" endline="174" pcid="8893">
    def get_environment_config(self):  # type: () -> CloudEnvironmentConfig
        """Return environment configuration for use in the test environment after delegation."""
        parser = configparser.ConfigParser()
        parser.read(self.config_path)

        config = dict(parser.items('default'))

        env_vars = dict(
            CLOUDSTACK_ENDPOINT=config['endpoint'],
            CLOUDSTACK_KEY=config['key'],
            CLOUDSTACK_SECRET=config['secret'],
            CLOUDSTACK_TIMEOUT=config['timeout'],
        )

        display.sensitive.add(env_vars['CLOUDSTACK_SECRET'])

        ansible_vars = dict(
            cs_resource_prefix=self.resource_prefix,
        )

        return CloudEnvironmentConfig(
            env_vars=env_vars,
            ansible_vars=ansible_vars,
        )
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/commands/integration/cloud/vultr.py" startline="37" endline="55" pcid="8924">
    def get_environment_config(self):  # type: () -> CloudEnvironmentConfig
        """Return environment configuration for use in the test environment after delegation."""
        parser = configparser.ConfigParser()
        parser.read(self.config_path)

        env_vars = dict(
            VULTR_API_KEY=parser.get('default', 'key'),
        )

        display.sensitive.add(env_vars['VULTR_API_KEY'])

        ansible_vars = dict(
            vultr_resource_prefix=self.resource_prefix,
        )

        return CloudEnvironmentConfig(
            env_vars=env_vars,
            ansible_vars=ansible_vars,
        )
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/commands/integration/cloud/scaleway.py" startline="37" endline="56" pcid="8948">
    def get_environment_config(self):  # type: () -> CloudEnvironmentConfig
        """Return environment configuration for use in the test environment after delegation."""
        parser = configparser.ConfigParser()
        parser.read(self.config_path)

        env_vars = dict(
            SCW_API_KEY=parser.get('default', 'key'),
            SCW_ORG=parser.get('default', 'org')
        )

        display.sensitive.add(env_vars['SCW_API_KEY'])

        ansible_vars = dict(
            scw_org=parser.get('default', 'org'),
        )

        return CloudEnvironmentConfig(
            env_vars=env_vars,
            ansible_vars=ansible_vars,
        )
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/commands/integration/cloud/hcloud.py" startline="86" endline="106" pcid="8921">
    def get_environment_config(self):  # type: () -> CloudEnvironmentConfig
        """Return environment configuration for use in the test environment after delegation."""
        parser = configparser.ConfigParser()
        parser.read(self.config_path)

        env_vars = dict(
            HCLOUD_TOKEN=parser.get('default', 'hcloud_api_token'),
        )

        display.sensitive.add(env_vars['HCLOUD_TOKEN'])

        ansible_vars = dict(
            hcloud_prefix=self.resource_prefix,
        )

        ansible_vars.update(dict((key.lower(), value) for key, value in env_vars.items()))

        return CloudEnvironmentConfig(
            env_vars=env_vars,
            ansible_vars=ansible_vars,
        )
</source>
</class>

<class classid="245" nclones="4" nlines="16" similarity="76">
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/commands/integration/cloud/vcenter.py" startline="67" endline="87" pcid="8884">
    def _setup_dynamic_simulator(self):  # type: () -> None
        """Create a vcenter simulator using docker."""
        ports = [
            443,
            8080,
            8989,
            5000,  # control port for flask app in simulator
        ]

        run_support_container(
            self.args,
            self.platform,
            self.image,
            self.DOCKER_SIMULATOR_NAME,
            ports,
            allow_existing=True,
            cleanup=CleanupMode.YES,
        )

        self._set_cloud_config('vcenter_hostname', self.DOCKER_SIMULATOR_NAME)

</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/commands/integration/cloud/nios.py" startline="59" endline="78" pcid="8896">
    def _setup_dynamic(self):  # type: () -> None
        """Spawn a NIOS simulator within docker container."""
        nios_port = 443

        ports = [
            nios_port,
        ]

        run_support_container(
            self.args,
            self.platform,
            self.image,
            self.DOCKER_SIMULATOR_NAME,
            ports,
            allow_existing=True,
            cleanup=CleanupMode.YES,
        )

        self._set_cloud_config('NIOS_HOST', self.DOCKER_SIMULATOR_NAME)

</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/commands/integration/cloud/foreman.py" startline="58" endline="78" pcid="8943">
    def _setup_dynamic(self):  # type: () -> None
        """Spawn a Foreman stub within docker container."""
        foreman_port = 8080

        ports = [
            foreman_port,
        ]

        run_support_container(
            self.args,
            self.platform,
            self.image,
            self.DOCKER_SIMULATOR_NAME,
            ports,
            allow_existing=True,
            cleanup=CleanupMode.YES,
        )

        self._set_cloud_config('FOREMAN_HOST', self.DOCKER_SIMULATOR_NAME)
        self._set_cloud_config('FOREMAN_PORT', str(foreman_port))

</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/commands/integration/cloud/acme.py" startline="46" endline="64" pcid="8913">
    def _setup_dynamic(self):  # type: () -> None
        """Create a ACME test container using docker."""
        ports = [
            5000,  # control port for flask app in container
            14000,  # Pebble ACME CA
        ]

        run_support_container(
            self.args,
            self.platform,
            self.image,
            self.DOCKER_SIMULATOR_NAME,
            ports,
            allow_existing=True,
            cleanup=CleanupMode.YES,
        )

        self._set_cloud_config('acme_host', self.DOCKER_SIMULATOR_NAME)

</source>
</class>

<class classid="246" nclones="2" nlines="11" similarity="90">
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/commands/integration/cloud/gcp.py" startline="42" endline="55" pcid="8907">
    def get_environment_config(self):  # type: () -> CloudEnvironmentConfig
        """Return environment configuration for use in the test environment after delegation."""
        parser = configparser.ConfigParser()
        parser.read(self.config_path)

        ansible_vars = dict(
            resource_prefix=self.resource_prefix,
        )

        ansible_vars.update(dict(parser.items('default')))

        return CloudEnvironmentConfig(
            ansible_vars=ansible_vars,
        )
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/commands/integration/cloud/opennebula.py" startline="45" endline="60" pcid="8954">
    def get_environment_config(self):  # type: () -> CloudEnvironmentConfig
        """Return environment configuration for use in the test environment after delegation."""
        parser = configparser.ConfigParser()
        parser.read(self.config_path)

        ansible_vars = dict(
            resource_prefix=self.resource_prefix,
        )

        ansible_vars.update(dict(parser.items('default')))

        display.sensitive.add(ansible_vars.get('opennebula_password'))

        return CloudEnvironmentConfig(
            ansible_vars=ansible_vars,
        )
</source>
</class>

<class classid="247" nclones="2" nlines="16" similarity="70">
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/commands/integration/cloud/hcloud.py" startline="53" endline="78" pcid="8919">
    def _setup_dynamic(self):  # type: () -> None
        """Request Hetzner credentials through the Ansible Core CI service."""
        display.info('Provisioning %s cloud environment.' % self.platform, verbosity=1)

        config = self._read_config_template()

        aci = self._create_ansible_core_ci()

        response = aci.start()

        if not self.args.explain:
            token = response['hetzner']['token']

            display.sensitive.add(token)
            display.info('Hetzner Cloud Token: %s' % token, verbosity=1)

            values = dict(
                TOKEN=token,
            )

            display.sensitive.add(values['TOKEN'])

            config = self._populate_config_template(config, values)

        self._write_config(config)

</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/commands/integration/cloud/aws.py" startline="65" endline="91" pcid="8928">
    def _setup_dynamic(self):  # type: () -> None
        """Request AWS credentials through the Ansible Core CI service."""
        display.info('Provisioning %s cloud environment.' % self.platform, verbosity=1)

        config = self._read_config_template()

        aci = self._create_ansible_core_ci()

        response = aci.start()

        if not self.args.explain:
            credentials = response['aws']['credentials']

            values = dict(
                ACCESS_KEY=credentials['access_key'],
                SECRET_KEY=credentials['secret_key'],
                SECURITY_TOKEN=credentials['session_token'],
                REGION='us-east-1',
            )

            display.sensitive.add(values['SECRET_KEY'])
            display.sensitive.add(values['SECURITY_TOKEN'])

            config = self._populate_config_template(config, values)

        self._write_config(config)

</source>
</class>

<class classid="248" nclones="2" nlines="23" similarity="73">
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/commands/integration/network.py" startline="42" endline="77" pcid="8956">
def command_network_integration(args):  # type: (NetworkIntegrationConfig) -> None
    """Entry point for the `network-integration` command."""
    handle_layout_messages(data_context().content.integration_messages)

    inventory_relative_path = get_inventory_relative_path(args)
    template_path = os.path.join(ANSIBLE_TEST_CONFIG_ROOT, os.path.basename(inventory_relative_path)) + '.template'

    if issubclass(args.target_type, NetworkInventoryConfig):
        target = args.only_target(NetworkInventoryConfig)
        inventory_path = get_inventory_absolute_path(args, target)

        if args.delegate or not target.path:
            target.path = inventory_relative_path
    else:
        inventory_path = os.path.join(data_context().content.root, inventory_relative_path)

    if args.no_temp_workdir:
        # temporary solution to keep DCI tests working
        inventory_exists = os.path.exists(inventory_path)
    else:
        inventory_exists = os.path.isfile(inventory_path)

    if not args.explain and not issubclass(args.target_type, NetworkRemoteConfig) and not inventory_exists:
        raise ApplicationError(
            'Inventory not found: %s\n'
            'Use --inventory to specify the inventory path.\n'
            'Use --platform to provision resources and generate an inventory file.\n'
            'See also inventory template: %s' % (inventory_path, template_path)
        )

    check_inventory(args, inventory_path)
    delegate_inventory(args, inventory_path)

    all_targets = tuple(walk_network_integration_targets(include_hidden=True))
    host_state, internal_targets = command_integration_filter(args, all_targets)
    command_integration_filtered(args, host_state, internal_targets, all_targets, inventory_path)
</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/commands/integration/windows.py" startline="48" endline="81" pcid="8957">
def command_windows_integration(args):  # type: (WindowsIntegrationConfig) -> None
    """Entry point for the `windows-integration` command."""
    handle_layout_messages(data_context().content.integration_messages)

    inventory_relative_path = get_inventory_relative_path(args)
    template_path = os.path.join(ANSIBLE_TEST_CONFIG_ROOT, os.path.basename(inventory_relative_path)) + '.template'

    if issubclass(args.target_type, WindowsInventoryConfig):
        target = args.only_target(WindowsInventoryConfig)
        inventory_path = get_inventory_absolute_path(args, target)

        if args.delegate or not target.path:
            target.path = inventory_relative_path
    else:
        inventory_path = os.path.join(data_context().content.root, inventory_relative_path)

    if not args.explain and not issubclass(args.target_type, WindowsRemoteConfig) and not os.path.isfile(inventory_path):
        raise ApplicationError(
            'Inventory not found: %s\n'
            'Use --inventory to specify the inventory path.\n'
            'Use --windows to provision resources and generate an inventory file.\n'
            'See also inventory template: %s' % (inventory_path, template_path)
        )

    check_inventory(args, inventory_path)
    delegate_inventory(args, inventory_path)

    all_targets = tuple(walk_windows_integration_targets(include_hidden=True))
    host_state, internal_targets = command_integration_filter(args, all_targets)
    control_connections = [local_ssh(args, host_state.controller_profile.python)]
    managed_connections = [root_ssh(ssh) for ssh in host_state.get_controller_target_connections()]
    pre_target, post_target = create_container_hooks(args, control_connections, managed_connections)

    command_integration_filtered(args, host_state, internal_targets, all_targets, inventory_path, pre_target=pre_target, post_target=post_target)
</source>
</class>

<class classid="249" nclones="2" nlines="22" similarity="78">
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/commands/coverage/analyze/targets/generate.py" startline="78" endline="109" pcid="8989">
def analyze_python_coverage(
        args,  # type: CoverageAnalyzeTargetsGenerateConfig
        host_state,  # type: HostState
        path,  # type: str
        target_indexes,  # type: TargetIndexes
):  # type: (...) -> Arcs
    """Analyze Python code coverage."""
    results = {}  # type: Arcs
    collection_search_re, collection_sub_re = get_collection_path_regexes()
    modules = get_python_modules()
    python_files = get_python_coverage_files(path)
    coverage = initialize_coverage(args, host_state)

    for python_file in python_files:
        if not is_integration_coverage_file(python_file):
            continue

        target_name = get_target_name(python_file)
        target_index = get_target_index(target_name, target_indexes)

        for filename, covered_arcs in enumerate_python_arcs(python_file, coverage, modules, collection_search_re, collection_sub_re):
            arcs = results.setdefault(filename, {})

            for covered_arc in covered_arcs:
                arc = arcs.setdefault(covered_arc, set())
                arc.add(target_index)

    prune_invalid_filenames(args, results, collection_search_re=collection_search_re)

    return results


</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/commands/coverage/analyze/targets/generate.py" startline="110" endline="138" pcid="8990">
def analyze_powershell_coverage(
        args,  # type: CoverageAnalyzeTargetsGenerateConfig
        path,  # type: str
        target_indexes,  # type: TargetIndexes
):  # type: (...) -> Lines
    """Analyze PowerShell code coverage"""
    results = {}  # type: Lines
    collection_search_re, collection_sub_re = get_collection_path_regexes()
    powershell_files = get_powershell_coverage_files(path)

    for powershell_file in powershell_files:
        if not is_integration_coverage_file(powershell_file):
            continue

        target_name = get_target_name(powershell_file)
        target_index = get_target_index(target_name, target_indexes)

        for filename, hits in enumerate_powershell_lines(powershell_file, collection_search_re, collection_sub_re):
            lines = results.setdefault(filename, {})

            for covered_line in hits:
                line = lines.setdefault(covered_line, set())
                line.add(target_index)

    prune_invalid_filenames(args, results)

    return results


</source>
</class>

<class classid="250" nclones="2" nlines="19" similarity="70">
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/commands/coverage/analyze/targets/missing.py" startline="69" endline="93" pcid="8996">
def find_gaps(
        from_data,  # type: IndexedPoints
        from_index,  # type: t.List[str]
        to_data,  # type: IndexedPoints
        target_indexes,  # type: TargetIndexes
        only_exists,  # type: bool
):  # type: (...) -> IndexedPoints
    """Find gaps in coverage between the from and to data sets."""
    target_data = {}

    for from_path, from_points in from_data.items():
        if only_exists and not os.path.isfile(to_bytes(from_path)):
            continue

        to_points = to_data.get(from_path, {})

        gaps = set(from_points.keys()) - set(to_points.keys())

        if gaps:
            gap_points = dict((key, value) for key, value in from_points.items() if key in gaps)
            target_data[from_path] = dict((gap, set(get_target_index(from_index[i], target_indexes) for i in indexes)) for gap, indexes in gap_points.items())

    return target_data


</source>
<source file="systems/ansible-2.12.4rc1/test/lib/ansible_test/_internal/commands/coverage/analyze/targets/missing.py" startline="94" endline="120" pcid="8997">
def find_missing(
        from_data,  # type: IndexedPoints
        from_index,  # type: t.List[str]
        to_data,  # type: IndexedPoints
        to_index,  # type: t.List[str]
        target_indexes,  # type: TargetIndexes
        only_exists,  # type: bool
):  # type: (...) -> IndexedPoints
    """Find coverage in from_data not present in to_data (arcs or lines)."""
    target_data = {}

    for from_path, from_points in from_data.items():
        if only_exists and not os.path.isfile(to_bytes(from_path)):
            continue

        to_points = to_data.get(from_path, {})

        for from_point, from_target_indexes in from_points.items():
            to_target_indexes = to_points.get(from_point, set())

            remaining_targets = set(from_index[i] for i in from_target_indexes) - set(to_index[i] for i in to_target_indexes)

            if remaining_targets:
                target_index = target_data.setdefault(from_path, {}).setdefault(from_point, set())
                target_index.update(get_target_index(name, target_indexes) for name in remaining_targets)

    return target_data
</source>
</class>

</clones>
