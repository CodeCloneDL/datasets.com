<html>
<head>
    <title>NiCad6 Clone Report</title>
    <style type="text/css">
        body {font-family:sans-serif;}
        table {background-color:white; border:0px; padding:0px; border-spacing:4px; width:auto; margin-left:30px; margin-right:auto;}
        td {background-color:rgba(192,212,238,0.8); border:0px; padding:8px; width:auto; vertical-align:top; border-radius:8px}
        pre {background-color:white; padding:4px;}
        a {color:darkblue;}
    </style>
</head>
<body>
<h2>NiCad6 Clone Report</h2>
<table>
<tr style="font-size:14pt">
<td><b>System:</b> &nbsp; ludwig-0.5rc2</td>
<td><b>Clone pairs:</b> &nbsp; 587</td>
<td><b>Clone classes:</b> &nbsp; 29</td>
</tr>
<tr style="font-size:12pt">
<td style="background-color:white">Clone type: &nbsp; 3-2</td>
<td style="background-color:white">Granularity: &nbsp; functions-blind</td>
<td style="background-color:white">Max diff threshold: &nbsp; 30%</td>
<td style="background-color:white">Clone size: &nbsp; 10 - 2500 lines</td>
<td style="background-color:white">Total functions-blind: &nbsp; 1475</td>
</tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 1:</b> &nbsp; 3 fragments, nominal size 20 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_kfold_cv.py: 136-177
</a>
<div class="mid" id="frag2" style="display:none"><pre>
def test_kfold_cv_api_from_file():
    # k-fold_cross_validate api with config file
    num_folds = 3

    # setup temporary directory to run test
    with tempfile.TemporaryDirectory() as tmpdir:

        # setup required data structures for test
        training_data_fp = os.path.join(tmpdir, "train.csv")
        config_fp = os.path.join(tmpdir, "config.yaml")

        # generate synthetic data for the test
        input_features = [number_feature(normalization="zscore"), number_feature(normalization="zscore")]

        output_features = [category_feature(vocab_size=3, reduce_input="sum")]

        generate_data(input_features, output_features, training_data_fp)

        # generate config file
        config = {
            "input_features": input_features,
            "output_features": output_features,
            "combiner": {"type": "concat", "output_size": 14},
            TRAINER: {"epochs": 2},
        }

        with open(config_fp, "w") as f:
            yaml.dump(config, f)

        # test kfold_cross_validate api with config file

        # execute k-fold cross validation run
        (kfold_cv_stats, kfold_split_indices) = kfold_cross_validate(3, config=config_fp, dataset=training_data_fp)

        # correct structure for results from kfold cv
        for key in ["fold_" + str(i + 1) for i in range(num_folds)] + ["overall"]:
            assert key in kfold_cv_stats

        for key in ["fold_" + str(i + 1) for i in range(num_folds)]:
            assert key in kfold_split_indices


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag4')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_kfold_cv.py: 236-272
</a>
<div class="mid" id="frag4" style="display:none"><pre>
def test_kfold_cv_dataset_formats(data_format):
    # k-fold_cross_validate api with in-memory config
    num_folds = 3

    # setup temporary directory to run test
    with tempfile.TemporaryDirectory() as tmpdir:

        # setup required data structures for test
        training_data_fp = os.path.join(tmpdir, "train.csv")

        # generate synthetic data for the test
        input_features = [number_feature(normalization="zscore"), number_feature(normalization="zscore")]

        output_features = [number_feature()]

        generate_data(input_features, output_features, training_data_fp)
        dataset_to_use = create_data_set_to_use(data_format, training_data_fp)

        # generate config file
        config = {
            "input_features": input_features,
            "output_features": output_features,
            "combiner": {"type": "concat", "output_size": 14},
            TRAINER: {"epochs": 2},
        }

        # test kfold_cross_validate api with config in-memory

        # execute k-fold cross validation run
        (kfold_cv_stats, kfold_split_indices) = kfold_cross_validate(3, config=config, dataset=dataset_to_use)

        # correct structure for results from kfold cv
        for key in ["fold_" + str(i + 1) for i in range(num_folds)] + ["overall"]:
            assert key in kfold_cv_stats

        for key in ["fold_" + str(i + 1) for i in range(num_folds)]:
            assert key in kfold_split_indices
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag3')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_kfold_cv.py: 179-216
</a>
<div class="mid" id="frag3" style="display:none"><pre>
def test_kfold_cv_api_in_memory():
    # k-fold_cross_validate api with in-memory config
    num_folds = 3

    # setup temporary directory to run test
    with tempfile.TemporaryDirectory() as tmpdir:

        # setup required data structures for test
        training_data_fp = os.path.join(tmpdir, "train.csv")

        # generate synthetic data for the test
        input_features = [number_feature(normalization="zscore"), number_feature(normalization="zscore")]

        output_features = [number_feature()]

        generate_data(input_features, output_features, training_data_fp)

        # generate config file
        config = {
            "input_features": input_features,
            "output_features": output_features,
            "combiner": {"type": "concat", "output_size": 14},
            TRAINER: {"epochs": 2},
        }

        # test kfold_cross_validate api with config in-memory

        # execute k-fold cross validation run
        (kfold_cv_stats, kfold_split_indices) = kfold_cross_validate(3, config=config, dataset=training_data_fp)

        # correct structure for results from kfold cv
        for key in ["fold_" + str(i + 1) for i in range(num_folds)] + ["overall"]:
            assert key in kfold_cv_stats

        for key in ["fold_" + str(i + 1) for i in range(num_folds)]:
            assert key in kfold_split_indices


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 2:</b> &nbsp; 25 fragments, nominal size 40 lines, similarity 73%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag7')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization.py: 87-129
</a>
<div class="mid" id="frag7" style="display:none"><pre>
def test_visualization_learning_curves_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [text_feature(encoder="parallel_cnn")]
    output_features = [category_feature()]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    input_features[0]["encoder"] = "parallel_cnn"
    exp_dir_name = run_experiment_with_visualization(input_features, output_features, dataset=rel_path)

    vis_output_pattern_pdf = os.path.join(exp_dir_name, "*.pdf")
    vis_output_pattern_png = os.path.join(exp_dir_name, "*.png")
    train_stats = os.path.join(exp_dir_name, "training_statistics.json")
    test_cmd_pdf = [
        "python",
        "-m",
        "ludwig.visualize",
        "--visualization",
        "learning_curves",
        "--training_statistics",
        train_stats,
        "-od",
        exp_dir_name,
    ]
    test_cmd_png = test_cmd_pdf.copy() + ["-ff", "png"]

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(
            command,
        )
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 4 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag9')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization.py: 173-220
</a>
<div class="mid" id="frag9" style="display:none"><pre>
def test_visualization_compare_performance_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    Compare performance between two models. To reduce test complexity
    one model is compared to it self.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [text_feature(encoder="parallel_cnn")]
    output_features = [category_feature()]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    input_features[0]["encoder"] = "parallel_cnn"
    exp_dir_name = run_experiment_with_visualization(input_features, output_features, dataset=rel_path)
    vis_output_pattern_pdf = os.path.join(exp_dir_name, "*.pdf")
    vis_output_pattern_png = os.path.join(exp_dir_name, "*.png")
    test_stats = os.path.join(exp_dir_name, TEST_STATISTICS_FILE_NAME)

    test_cmd_pdf = [
        "python",
        "-m",
        "ludwig.visualize",
        "--visualization",
        "compare_performance",
        "--test_statistics",
        test_stats,
        test_stats,
        "-m",
        "Model1",
        "Model2",
        "-od",
        exp_dir_name,
    ]
    test_cmd_png = test_cmd_pdf.copy() + ["-ff", "png"]

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag28')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization.py: 1254-1297
</a>
<div class="mid" id="frag28" style="display:none"><pre>
def test_visualization_roc_curves_from_test_statistics_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [binary_feature(), bag_feature()]
    output_features = [binary_feature()]
    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)

    exp_dir_name = run_experiment_with_visualization(input_features, output_features, dataset=rel_path)
    vis_output_pattern_pdf = os.path.join(exp_dir_name, "*.pdf")
    vis_output_pattern_png = os.path.join(exp_dir_name, "*.png")
    output_feature_name = get_output_feature_name(exp_dir_name)
    test_stats = os.path.join(exp_dir_name, TEST_STATISTICS_FILE_NAME)
    test_cmd_pdf = [
        "python",
        "-m",
        "ludwig.visualize",
        "--visualization",
        "roc_curves_from_test_statistics",
        "--output_feature_name",
        output_feature_name,
        "--test_statistics",
        test_stats,
        "--model_names",
        "Model1",
        "-od",
        exp_dir_name,
    ]
    test_cmd_png = test_cmd_pdf.copy() + ["-ff", "png"]

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag8')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization.py: 130-172
</a>
<div class="mid" id="frag8" style="display:none"><pre>
def test_visualization_confusion_matrix_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [text_feature(encoder="parallel_cnn")]
    output_features = [category_feature()]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    input_features[0]["encoder"] = "parallel_cnn"
    exp_dir_name = run_experiment_with_visualization(input_features, output_features, dataset=rel_path)
    vis_output_pattern_pdf = os.path.join(exp_dir_name, "*.pdf")
    vis_output_pattern_png = os.path.join(exp_dir_name, "*.png")
    experiment_source_data_name = csv_filename.split(".")[0]
    ground_truth_metadata = experiment_source_data_name + ".meta.json"
    test_stats = os.path.join(exp_dir_name, TEST_STATISTICS_FILE_NAME)
    test_cmd_pdf = [
        "python",
        "-m",
        "ludwig.visualize",
        "--visualization",
        "confusion_matrix",
        "--test_statistics",
        test_stats,
        "--ground_truth_metadata",
        ground_truth_metadata,
        "-od",
        exp_dir_name,
    ]
    test_cmd_png = test_cmd_pdf.copy() + ["-ff", "png"]
    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 2 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag31')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization.py: 1412-1461
</a>
<div class="mid" id="frag31" style="display:none"><pre>
def test_visualization_frequency_vs_f1_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [category_feature(vocab_size=10)]
    output_features = [category_feature(vocab_size=2, reduce_input="sum")]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment_with_visualization(input_features, output_features, dataset=rel_path)
    vis_output_pattern_pdf = os.path.join(exp_dir_name, "*.pdf")
    vis_output_pattern_png = os.path.join(exp_dir_name, "*.png")
    output_feature_name = get_output_feature_name(exp_dir_name)
    test_stats = os.path.join(exp_dir_name, TEST_STATISTICS_FILE_NAME)
    experiment_source_data_name = csv_filename.split(".")[0]
    ground_truth_metadata = experiment_source_data_name + ".meta.json"
    test_cmd_pdf = [
        "python",
        "-m",
        "ludwig.visualize",
        "--visualization",
        "frequency_vs_f1",
        "--ground_truth_metadata",
        ground_truth_metadata,
        "--output_feature_name",
        output_feature_name,
        "--test_statistics",
        test_stats,
        test_stats,
        "--model_names",
        "Model1",
        "Model2",
        "-od",
        exp_dir_name,
    ]
    test_cmd_png = test_cmd_pdf.copy() + ["-ff", "png"]

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 2 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag16')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization.py: 559-605
</a>
<div class="mid" id="frag16" style="display:none"><pre>
def test_visualization_compare_classifiers_multiclass_multimetric_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [category_feature(vocab_size=10)]
    output_features = [category_feature(vocab_size=2, reduce_input="sum")]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment_with_visualization(input_features, output_features, dataset=rel_path)
    vis_output_pattern_pdf = os.path.join(exp_dir_name, "*.pdf")
    vis_output_pattern_png = os.path.join(exp_dir_name, "*.png")
    output_feature_name = get_output_feature_name(exp_dir_name)
    test_stats = os.path.join(exp_dir_name, TEST_STATISTICS_FILE_NAME)
    experiment_source_data_name = csv_filename.split(".")[0]
    ground_truth_metadata = experiment_source_data_name + ".meta.json"
    test_cmd_pdf = [
        "python",
        "-m",
        "ludwig.visualize",
        "--visualization",
        "compare_classifiers_multiclass_multimetric",
        "--output_feature_name",
        output_feature_name,
        "--test_statistics",
        test_stats,
        test_stats,
        "--ground_truth_metadata",
        ground_truth_metadata,
        "-od",
        exp_dir_name,
    ]
    test_cmd_png = test_cmd_pdf.copy() + ["-ff", "png"]

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 4 == len(figure_cnt)


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag15')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization.py: 506-558
</a>
<div class="mid" id="frag15" style="display:none"><pre>
def test_visualization_compare_classifiers_changing_k_output_pdf(csv_filename):
    """It should be possible to save figures as pdf in the specified directory."""
    input_features = [category_feature(vocab_size=10)]
    output_features = [category_feature(vocab_size=2, reduce_input="sum")]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment_with_visualization(input_features, output_features, dataset=rel_path)
    vis_output_pattern_pdf = os.path.join(exp_dir_name, "*.pdf")
    vis_output_pattern_png = os.path.join(exp_dir_name, "*.png")
    output_feature_name = get_output_feature_name(exp_dir_name)
    probability = os.path.join(exp_dir_name, PREDICTIONS_PARQUET_FILE_NAME)
    experiment_source_data_name = csv_filename.split(".")[0]
    ground_truth = experiment_source_data_name + ".csv"
    split_file = experiment_source_data_name + ".split.csv"
    ground_truth_metadata = exp_dir_name + "/model/training_set_metadata.json"
    test_cmd_pdf = [
        "python",
        "-m",
        "ludwig.visualize",
        "--visualization",
        "compare_classifiers_performance_changing_k",
        "--output_feature_name",
        output_feature_name,
        "--split_file",
        split_file,
        "--ground_truth_metadata",
        ground_truth_metadata,
        "--probabilities",
        probability,
        probability,
        "--model_names",
        "Model1",
        "Model2",
        "--ground_truth",
        ground_truth,
        "--top_n_classes",
        "6",
        "-od",
        exp_dir_name,
    ]
    test_cmd_png = test_cmd_pdf.copy() + ["-ff", "png"]

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]
    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag14')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization.py: 449-505
</a>
<div class="mid" id="frag14" style="display:none"><pre>
def test_visualization_compare_classifiers_subset_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [category_feature(vocab_size=10)]
    output_features = [category_feature(vocab_size=2, reduce_input="sum")]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment_with_visualization(input_features, output_features, dataset=rel_path)
    vis_output_pattern_pdf = os.path.join(exp_dir_name, "*.pdf")
    vis_output_pattern_png = os.path.join(exp_dir_name, "*.png")
    output_feature_name = get_output_feature_name(exp_dir_name)
    probability = os.path.join(exp_dir_name, PREDICTIONS_PARQUET_FILE_NAME)
    experiment_source_data_name = csv_filename.split(".")[0]
    ground_truth = experiment_source_data_name + ".csv"
    split_file = experiment_source_data_name + ".split.csv"
    test_cmd_pdf = [
        "python",
        "-m",
        "ludwig.visualize",
        "--visualization",
        "compare_classifiers_performance_subset",
        "--output_feature_name",
        output_feature_name,
        "--split_file",
        split_file,
        "--ground_truth_metadata",
        exp_dir_name + "/model/training_set_metadata.json",
        "--probabilities",
        probability,
        probability,
        "--model_names",
        "Model1",
        "Model2",
        "--ground_truth",
        ground_truth,
        "--top_n_classes",
        "6",
        "-od",
        exp_dir_name,
    ]
    test_cmd_png = test_cmd_pdf.copy() + ["-ff", "png"]

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag23')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization.py: 940-998
</a>
<div class="mid" id="frag23" style="display:none"><pre>
def test_vis_confidence_thresholding_data_vs_acc_subset_per_class_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [category_feature(vocab_size=10)]
    output_features = [category_feature(vocab_size=5, reduce_input="sum")]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment_with_visualization(input_features, output_features, dataset=rel_path)
    vis_output_pattern_pdf = os.path.join(exp_dir_name, "*.pdf")
    vis_output_pattern_png = os.path.join(exp_dir_name, "*.png")
    output_feature_name = get_output_feature_name(exp_dir_name)
    probability = os.path.join(exp_dir_name, PREDICTIONS_PARQUET_FILE_NAME)
    experiment_source_data_name = csv_filename.split(".")[0]
    ground_truth = experiment_source_data_name + ".csv"
    split_file = experiment_source_data_name + ".split.csv"
    test_cmd_pdf = [
        "python",
        "-m",
        "ludwig.visualize",
        "--visualization",
        "confidence_thresholding_data_vs_acc_subset_per_class",
        "--ground_truth",
        ground_truth,
        "--output_feature_name",
        output_feature_name,
        "--split_file",
        split_file,
        "--ground_truth_metadata",
        exp_dir_name + "/model/training_set_metadata.json",
        "--probabilities",
        probability,
        probability,
        "--model_names",
        "Model1",
        "Model2",
        "--top_n_classes",
        "3",
        "-od",
        exp_dir_name,
    ]
    test_cmd_png = test_cmd_pdf.copy() + ["-ff", "png"]

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        # 3 figures should be saved because experiment setting top_n_classes = 3
        # hence one figure per class
        assert 3 == len(figure_cnt)


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag13')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization.py: 392-448
</a>
<div class="mid" id="frag13" style="display:none"><pre>
def test_visualization_compare_classifiers_from_pred_csv_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    Predictions are loaded from csv file.
    :param csv_filename: csv fixture from tests.fixtures.filenames.csv_filename
    :return: None
    """
    input_features = [category_feature(vocab_size=10)]
    output_features = [category_feature(vocab_size=2, reduce_input="sum")]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment_with_visualization(input_features, output_features, dataset=rel_path)
    vis_output_pattern_pdf = os.path.join(exp_dir_name, "*.pdf")
    vis_output_pattern_png = os.path.join(exp_dir_name, "*.png")
    output_feature_name = get_output_feature_name(exp_dir_name)
    prediction = os.path.join(exp_dir_name, PREDICTIONS_PARQUET_FILE_NAME)
    experiment_source_data_name = csv_filename.split(".")[0]
    ground_truth = experiment_source_data_name + ".csv"
    split_file = experiment_source_data_name + ".split.csv"
    ground_truth_metadata = experiment_source_data_name + ".meta.json"
    test_cmd_pdf = [
        "python",
        "-m",
        "ludwig.visualize",
        "--visualization",
        "compare_classifiers_performance_from_pred",
        "--ground_truth_metadata",
        ground_truth_metadata,
        "--ground_truth",
        ground_truth,
        "--output_feature_name",
        output_feature_name,
        "--split_file",
        split_file,
        "--predictions",
        prediction,
        prediction,
        "--model_names",
        "Model1",
        "Model2",
        "-od",
        exp_dir_name,
    ]
    test_cmd_png = test_cmd_pdf.copy() + ["-ff", "png"]

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag22')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization.py: 883-939
</a>
<div class="mid" id="frag22" style="display:none"><pre>
def test_visualization_confidence_thresholding_data_vs_acc_subset_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [category_feature(vocab_size=10)]
    output_features = [category_feature(vocab_size=2, reduce_input="sum")]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment_with_visualization(input_features, output_features, dataset=rel_path)
    vis_output_pattern_pdf = os.path.join(exp_dir_name, "*.pdf")
    vis_output_pattern_png = os.path.join(exp_dir_name, "*.png")
    output_feature_name = get_output_feature_name(exp_dir_name)
    probability = os.path.join(exp_dir_name, PREDICTIONS_PARQUET_FILE_NAME)
    experiment_source_data_name = csv_filename.split(".")[0]
    ground_truth = experiment_source_data_name + ".csv"
    split_file = experiment_source_data_name + ".split.csv"
    test_cmd_pdf = [
        "python",
        "-m",
        "ludwig.visualize",
        "--visualization",
        "confidence_thresholding_data_vs_acc_subset",
        "--ground_truth",
        ground_truth,
        "--output_feature_name",
        output_feature_name,
        "--split_file",
        split_file,
        "--ground_truth_metadata",
        exp_dir_name + "/model/training_set_metadata.json",
        "--probabilities",
        probability,
        probability,
        "--model_names",
        "Model1",
        "Model2",
        "--top_n_classes",
        "3",
        "-od",
        exp_dir_name,
    ]
    test_cmd_png = test_cmd_pdf.copy() + ["-ff", "png"]

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag11')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization.py: 278-334
</a>
<div class="mid" id="frag11" style="display:none"><pre>
def test_visualization_compare_classifiers_from_prob_npy_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    Probabilities are loaded from npy file.
    :param csv_filename: csv fixture from tests.fixtures.filenames.csv_filename
    :return: None
    """
    input_features = [category_feature(vocab_size=10)]
    output_features = [category_feature(vocab_size=2, reduce_input="sum")]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment_with_visualization(input_features, output_features, dataset=rel_path)

    vis_output_pattern_pdf = os.path.join(exp_dir_name, "*.pdf")
    vis_output_pattern_png = os.path.join(exp_dir_name, "*.png")
    output_feature_name = get_output_feature_name(exp_dir_name)
    probability = os.path.join(exp_dir_name, PREDICTIONS_PARQUET_FILE_NAME)
    experiment_source_data_name = csv_filename.split(".")[0]
    ground_truth = experiment_source_data_name + ".csv"
    split_file = experiment_source_data_name + ".split.csv"
    test_cmd_pdf = [
        "python",
        "-m",
        "ludwig.visualize",
        "--visualization",
        "compare_classifiers_performance_from_prob",
        "--ground_truth",
        ground_truth,
        "--output_feature_name",
        output_feature_name,
        "--split_file",
        split_file,
        "--ground_truth_metadata",
        exp_dir_name + "/model/training_set_metadata.json",
        "--probabilities",
        probability,
        probability,
        "--model_names",
        "Model1",
        "Model2",
        "-od",
        exp_dir_name,
    ]
    test_cmd_png = test_cmd_pdf.copy() + ["-ff", "png"]

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag30')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization.py: 1357-1411
</a>
<div class="mid" id="frag30" style="display:none"><pre>
def test_visualization_calibration_multiclass_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [category_feature(vocab_size=10)]
    output_features = [category_feature(vocab_size=2, reduce_input="sum")]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment_with_visualization(input_features, output_features, dataset=rel_path)
    vis_output_pattern_pdf = os.path.join(exp_dir_name, "*.pdf")
    vis_output_pattern_png = os.path.join(exp_dir_name, "*.png")
    output_feature_name = get_output_feature_name(exp_dir_name)
    probability = os.path.join(exp_dir_name, PREDICTIONS_PARQUET_FILE_NAME)
    experiment_source_data_name = csv_filename.split(".")[0]
    ground_truth = experiment_source_data_name + ".csv"
    split_file = experiment_source_data_name + ".split.csv"
    test_cmd_pdf = [
        "python",
        "-m",
        "ludwig.visualize",
        "--visualization",
        "calibration_multiclass",
        "--ground_truth",
        ground_truth,
        "--output_feature_name",
        output_feature_name,
        "--split_file",
        split_file,
        "--ground_truth_metadata",
        exp_dir_name + "/model/training_set_metadata.json",
        "--probabilities",
        probability,
        probability,
        "--model_names",
        "Model1",
        "Model2",
        "-od",
        exp_dir_name,
    ]
    test_cmd_png = test_cmd_pdf.copy() + ["-ff", "png"]

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 2 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag12')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization.py: 335-391
</a>
<div class="mid" id="frag12" style="display:none"><pre>
def test_visualization_compare_classifiers_from_pred_npy_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    Predictions are loaded from npy file.
    :param csv_filename: csv fixture from tests.fixtures.filenames.csv_filename
    :return: None
    """
    input_features = [category_feature(vocab_size=10)]
    output_features = [category_feature(vocab_size=2, reduce_input="sum")]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment_with_visualization(input_features, output_features, dataset=rel_path)
    vis_output_pattern_pdf = os.path.join(exp_dir_name, "*.pdf")
    vis_output_pattern_png = os.path.join(exp_dir_name, "*.png")
    output_feature_name = get_output_feature_name(exp_dir_name)
    prediction = os.path.join(exp_dir_name, PREDICTIONS_PARQUET_FILE_NAME)
    experiment_source_data_name = csv_filename.split(".")[0]
    ground_truth = experiment_source_data_name + ".csv"
    split_file = experiment_source_data_name + ".split.csv"
    ground_truth_metadata = experiment_source_data_name + ".meta.json"
    test_cmd_pdf = [
        "python",
        "-m",
        "ludwig.visualize",
        "--visualization",
        "compare_classifiers_performance_from_pred",
        "--ground_truth_metadata",
        ground_truth_metadata,
        "--ground_truth",
        ground_truth,
        "--output_feature_name",
        output_feature_name,
        "--split_file",
        split_file,
        "--predictions",
        prediction,
        prediction,
        "--model_names",
        "Model1",
        "Model2",
        "-od",
        exp_dir_name,
    ]
    test_cmd_png = test_cmd_pdf.copy() + ["-ff", "png"]

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag19')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization.py: 718-772
</a>
<div class="mid" id="frag19" style="display:none"><pre>
def test_visualization_cmp_classifiers_predictions_distribution_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [category_feature(vocab_size=10)]
    output_features = [category_feature(vocab_size=2, reduce_input="sum")]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment_with_visualization(input_features, output_features, dataset=rel_path)
    vis_output_pattern_pdf = os.path.join(exp_dir_name, "*.pdf")
    vis_output_pattern_png = os.path.join(exp_dir_name, "*.png")
    output_feature_name = get_output_feature_name(exp_dir_name)
    prediction = os.path.join(exp_dir_name, PREDICTIONS_PARQUET_FILE_NAME)
    experiment_source_data_name = csv_filename.split(".")[0]
    ground_truth = experiment_source_data_name + ".csv"
    split_file = experiment_source_data_name + ".split.csv"
    test_cmd_pdf = [
        "python",
        "-m",
        "ludwig.visualize",
        "--visualization",
        "compare_classifiers_predictions_distribution",
        "--ground_truth",
        ground_truth,
        "--output_feature_name",
        output_feature_name,
        "--split_file",
        split_file,
        "--ground_truth_metadata",
        exp_dir_name + "/model/training_set_metadata.json",
        "--predictions",
        prediction,
        prediction,
        "--model_names",
        "Model1",
        "Model2",
        "-od",
        exp_dir_name,
    ]
    test_cmd_png = test_cmd_pdf.copy() + ["-ff", "png"]

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag20')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization.py: 773-827
</a>
<div class="mid" id="frag20" style="display:none"><pre>
def test_visualization_cconfidence_thresholding_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [category_feature(vocab_size=10)]
    output_features = [category_feature(vocab_size=2, reduce_input="sum")]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment_with_visualization(input_features, output_features, dataset=rel_path)
    vis_output_pattern_pdf = os.path.join(exp_dir_name, "*.pdf")
    vis_output_pattern_png = os.path.join(exp_dir_name, "*.png")
    output_feature_name = get_output_feature_name(exp_dir_name)
    probability = os.path.join(exp_dir_name, PREDICTIONS_PARQUET_FILE_NAME)
    experiment_source_data_name = csv_filename.split(".")[0]
    ground_truth = experiment_source_data_name + ".csv"
    split_file = experiment_source_data_name + ".split.csv"
    test_cmd_pdf = [
        "python",
        "-m",
        "ludwig.visualize",
        "--visualization",
        "confidence_thresholding",
        "--ground_truth",
        ground_truth,
        "--output_feature_name",
        output_feature_name,
        "--split_file",
        split_file,
        "--ground_truth_metadata",
        exp_dir_name + "/model/training_set_metadata.json",
        "--probabilities",
        probability,
        probability,
        "--model_names",
        "Model1",
        "Model2",
        "-od",
        exp_dir_name,
    ]
    test_cmd_png = test_cmd_pdf.copy() + ["-ff", "png"]

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag17')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization.py: 606-661
</a>
<div class="mid" id="frag17" style="display:none"><pre>
def test_visualization_compare_classifiers_predictions_npy_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    Predictions are loaded form npy file.
    :param csv_filename: csv fixture from tests.fixtures.filenames.csv_filename
    :return: None
    """
    input_features = [category_feature(vocab_size=10)]
    output_features = [category_feature(vocab_size=2, reduce_input="sum")]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment_with_visualization(input_features, output_features, dataset=rel_path)
    vis_output_pattern_pdf = os.path.join(exp_dir_name, "*.pdf")
    vis_output_pattern_png = os.path.join(exp_dir_name, "*.png")
    output_feature_name = get_output_feature_name(exp_dir_name)
    prediction = os.path.join(exp_dir_name, PREDICTIONS_PARQUET_FILE_NAME)
    experiment_source_data_name = csv_filename.split(".")[0]
    ground_truth = experiment_source_data_name + ".csv"
    split_file = experiment_source_data_name + ".split.csv"
    test_cmd_pdf = [
        "python",
        "-m",
        "ludwig.visualize",
        "--visualization",
        "compare_classifiers_predictions",
        "--ground_truth",
        ground_truth,
        "--output_feature_name",
        output_feature_name,
        "--split_file",
        split_file,
        "--ground_truth_metadata",
        exp_dir_name + "/model/training_set_metadata.json",
        "--predictions",
        prediction,
        prediction,
        "--model_names",
        "Model1",
        "Model2",
        "-od",
        exp_dir_name,
    ]
    test_cmd_png = test_cmd_pdf.copy() + ["-ff", "png"]

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag29')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization.py: 1298-1356
</a>
<div class="mid" id="frag29" style="display:none"><pre>
def test_visualization_calibration_1_vs_all_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [category_feature(vocab_size=10)]
    output_features = [category_feature(vocab_size=2, reduce_input="sum")]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment_with_visualization(input_features, output_features, dataset=rel_path)
    vis_output_pattern_pdf = os.path.join(exp_dir_name, "*.pdf")
    vis_output_pattern_png = os.path.join(exp_dir_name, "*.png")
    output_feature_name = get_output_feature_name(exp_dir_name)
    probability = os.path.join(exp_dir_name, PREDICTIONS_PARQUET_FILE_NAME)
    experiment_source_data_name = csv_filename.split(".")[0]
    ground_truth = experiment_source_data_name + ".csv"
    split_file = experiment_source_data_name + ".split.csv"
    test_cmd_pdf = [
        "python",
        "-m",
        "ludwig.visualize",
        "--visualization",
        "calibration_1_vs_all",
        "--metrics",
        "accuracy",
        "--ground_truth",
        ground_truth,
        "--output_feature_name",
        output_feature_name,
        "--split_file",
        split_file,
        "--ground_truth_metadata",
        exp_dir_name + "/model/training_set_metadata.json",
        "--probabilities",
        probability,
        probability,
        "--model_names",
        "Model1",
        "Model2",
        "--top_k",
        "6",
        "-od",
        exp_dir_name,
    ]
    test_cmd_png = test_cmd_pdf.copy() + ["-ff", "png"]

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 5 == len(figure_cnt)


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag10')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization.py: 221-277
</a>
<div class="mid" id="frag10" style="display:none"><pre>
def test_visualization_compare_classifiers_from_prob_csv_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    Probabilities are loaded from csv file.
    :param csv_filename: csv fixture from tests.fixtures.filenames.csv_filename
    :return: None
    """
    input_features = [category_feature(vocab_size=10)]
    output_features = [category_feature(vocab_size=2, reduce_input="sum")]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment_with_visualization(input_features, output_features, dataset=rel_path)

    vis_output_pattern_pdf = os.path.join(exp_dir_name, "*.pdf")
    vis_output_pattern_png = os.path.join(exp_dir_name, "*.png")
    output_feature_name = get_output_feature_name(exp_dir_name)
    probability = os.path.join(exp_dir_name, PREDICTIONS_PARQUET_FILE_NAME)
    experiment_source_data_name = csv_filename.split(".")[0]
    ground_truth = experiment_source_data_name + ".csv"
    split_file = get_split_path(csv_filename)
    test_cmd_pdf = [
        "python",
        "-m",
        "ludwig.visualize",
        "--visualization",
        "compare_classifiers_performance_from_prob",
        "--ground_truth",
        ground_truth,
        "--output_feature_name",
        output_feature_name,
        "--split_file",
        split_file,
        "--ground_truth_metadata",
        exp_dir_name + "/model/training_set_metadata.json",
        "--probabilities",
        probability,
        probability,
        "--model_names",
        "Model1",
        "Model2",
        "-od",
        exp_dir_name,
    ]
    test_cmd_png = test_cmd_pdf.copy() + ["-ff", "png"]

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag27')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization.py: 1195-1253
</a>
<div class="mid" id="frag27" style="display:none"><pre>
def test_visualization_roc_curves_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [category_feature(vocab_size=10)]
    output_features = [category_feature(vocab_size=2, reduce_input="sum")]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment_with_visualization(input_features, output_features, dataset=rel_path)
    vis_output_pattern_pdf = os.path.join(exp_dir_name, "*.pdf")
    vis_output_pattern_png = os.path.join(exp_dir_name, "*.png")
    output_feature_name = get_output_feature_name(exp_dir_name)
    probability = os.path.join(exp_dir_name, PREDICTIONS_PARQUET_FILE_NAME)
    experiment_source_data_name = csv_filename.split(".")[0]
    ground_truth = experiment_source_data_name + ".csv"
    split_file = experiment_source_data_name + ".split.csv"
    test_cmd_pdf = [
        "python",
        "-m",
        "ludwig.visualize",
        "--visualization",
        "roc_curves",
        "--positive_label",
        "2",
        "--metrics",
        "accuracy",
        "--ground_truth",
        ground_truth,
        "--output_feature_name",
        output_feature_name,
        "--split_file",
        split_file,
        "--ground_truth_metadata",
        exp_dir_name + "/model/training_set_metadata.json",
        "--probabilities",
        probability,
        probability,
        "--model_names",
        "Model1",
        "Model2",
        "-od",
        exp_dir_name,
    ]
    test_cmd_png = test_cmd_pdf.copy() + ["-ff", "png"]

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag18')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization.py: 662-717
</a>
<div class="mid" id="frag18" style="display:none"><pre>
def test_visualization_compare_classifiers_predictions_csv_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    Predictions are loaded form csv file.
    :param csv_filename: csv fixture from tests.fixtures.filenames.csv_filename
    :return: None
    """
    input_features = [category_feature(vocab_size=10)]
    output_features = [category_feature(vocab_size=2, reduce_input="sum")]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment_with_visualization(input_features, output_features, dataset=rel_path)
    vis_output_pattern_pdf = os.path.join(exp_dir_name, "*.pdf")
    vis_output_pattern_png = os.path.join(exp_dir_name, "*.png")
    output_feature_name = get_output_feature_name(exp_dir_name)
    prediction = os.path.join(exp_dir_name, PREDICTIONS_PARQUET_FILE_NAME)
    experiment_source_data_name = csv_filename.split(".")[0]
    ground_truth = experiment_source_data_name + ".csv"
    split_file = experiment_source_data_name + ".split.csv"
    test_cmd_pdf = [
        "python",
        "-m",
        "ludwig.visualize",
        "--visualization",
        "compare_classifiers_predictions",
        "--ground_truth",
        ground_truth,
        "--output_feature_name",
        output_feature_name,
        "--split_file",
        split_file,
        "--ground_truth_metadata",
        exp_dir_name + "/model/training_set_metadata.json",
        "--predictions",
        prediction,
        prediction,
        "--model_names",
        "Model1",
        "Model2",
        "-od",
        exp_dir_name,
    ]
    test_cmd_png = test_cmd_pdf.copy() + ["-ff", "png"]

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag21')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization.py: 828-882
</a>
<div class="mid" id="frag21" style="display:none"><pre>
def test_visualization_confidence_thresholding_data_vs_acc_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [category_feature(vocab_size=10)]
    output_features = [category_feature(vocab_size=2, reduce_input="sum")]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment_with_visualization(input_features, output_features, dataset=rel_path)
    vis_output_pattern_pdf = os.path.join(exp_dir_name, "*.pdf")
    vis_output_pattern_png = os.path.join(exp_dir_name, "*.png")
    output_feature_name = get_output_feature_name(exp_dir_name)
    probability = os.path.join(exp_dir_name, PREDICTIONS_PARQUET_FILE_NAME)
    experiment_source_data_name = csv_filename.split(".")[0]
    ground_truth = experiment_source_data_name + ".csv"
    split_file = experiment_source_data_name + ".split.csv"
    test_cmd_pdf = [
        "python",
        "-m",
        "ludwig.visualize",
        "--visualization",
        "confidence_thresholding_data_vs_acc",
        "--ground_truth",
        ground_truth,
        "--output_feature_name",
        output_feature_name,
        "--split_file",
        split_file,
        "--ground_truth_metadata",
        exp_dir_name + "/model/training_set_metadata.json",
        "--probabilities",
        probability,
        probability,
        "--model_names",
        "Model1",
        "Model2",
        "-od",
        exp_dir_name,
    ]
    test_cmd_png = test_cmd_pdf.copy() + ["-ff", "png"]

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag26')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization.py: 1129-1194
</a>
<div class="mid" id="frag26" style="display:none"><pre>
def test_visualization_binary_threshold_vs_metric_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [
        text_feature(vocab_size=10, min_len=1, encoder="stacked_cnn"),
        number_feature(),
        category_feature(vocab_size=10, embedding_size=5),
        set_feature(),
        sequence_feature(vocab_size=10, max_len=10, encoder="embed"),
    ]
    output_features = [category_feature(vocab_size=4, reduce_input="sum")]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    input_features[0]["encoder"] = "parallel_cnn"
    exp_dir_name = run_experiment_with_visualization(input_features, output_features, dataset=rel_path)
    vis_output_pattern_pdf = os.path.join(exp_dir_name, "*.pdf")
    vis_output_pattern_png = os.path.join(exp_dir_name, "*.png")
    output_feature_name = get_output_feature_name(exp_dir_name)
    probability = os.path.join(exp_dir_name, PREDICTIONS_PARQUET_FILE_NAME)
    experiment_source_data_name = csv_filename.split(".")[0]
    ground_truth = experiment_source_data_name + ".csv"
    split_file = experiment_source_data_name + ".split.csv"
    test_cmd_pdf = [
        "python",
        "-m",
        "ludwig.visualize",
        "--visualization",
        "binary_threshold_vs_metric",
        "--positive_label",
        "2",
        "--metrics",
        "accuracy",
        "--ground_truth",
        ground_truth,
        "--output_feature_name",
        output_feature_name,
        "--split_file",
        split_file,
        "--ground_truth_metadata",
        exp_dir_name + "/model/training_set_metadata.json",
        "--probabilities",
        probability,
        probability,
        "--model_names",
        "Model1",
        "Model2",
        "-od",
        exp_dir_name,
    ]
    test_cmd_png = test_cmd_pdf.copy() + ["-ff", "png"]

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag25')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization.py: 1065-1128
</a>
<div class="mid" id="frag25" style="display:none"><pre>
def test_vis_confidence_thresholding_2thresholds_3d_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [
        text_feature(vocab_size=10, min_len=1, encoder="stacked_cnn"),
        number_feature(),
        category_feature(vocab_size=10, embedding_size=5),
        set_feature(),
        sequence_feature(vocab_size=10, max_len=10, encoder="embed"),
    ]
    output_features = [
        category_feature(vocab_size=2, reduce_input="sum"),
        category_feature(vocab_size=2, reduce_input="sum"),
    ]
    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    input_features[0]["encoder"] = "parallel_cnn"
    exp_dir_name = run_experiment_with_visualization(input_features, output_features, dataset=rel_path)
    vis_output_pattern_pdf = os.path.join(exp_dir_name, "*.pdf")
    vis_output_pattern_png = os.path.join(exp_dir_name, "*.png")
    threshold_output_feature_name1 = get_output_feature_name(exp_dir_name)
    threshold_output_feature_name2 = get_output_feature_name(exp_dir_name, output_feature=1)
    probability = os.path.join(exp_dir_name, PREDICTIONS_PARQUET_FILE_NAME)
    experiment_source_data_name = csv_filename.split(".")[0]
    ground_truth = experiment_source_data_name + ".csv"
    split_file = experiment_source_data_name + ".split.csv"
    test_cmd_pdf = [
        "python",
        "-m",
        "ludwig.visualize",
        "--visualization",
        "confidence_thresholding_2thresholds_3d",
        "--ground_truth",
        ground_truth,
        "--split_file",
        split_file,
        "--ground_truth_metadata",
        exp_dir_name + "/model/training_set_metadata.json",
        "--probabilities",
        probability,
        "--threshold_output_feature_names",
        threshold_output_feature_name1,
        threshold_output_feature_name2,
        "-od",
        exp_dir_name,
    ]
    test_cmd_png = test_cmd_pdf.copy() + ["-ff", "png"]

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(
            command,
        )
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag24')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization.py: 999-1064
</a>
<div class="mid" id="frag24" style="display:none"><pre>
def test_vis_confidence_thresholding_2thresholds_2d_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [
        text_feature(vocab_size=10, min_len=1, encoder="stacked_cnn"),
        number_feature(),
        category_feature(vocab_size=10, embedding_size=5),
        set_feature(),
        sequence_feature(vocab_size=10, max_len=10, encoder="embed"),
    ]
    output_features = [
        category_feature(vocab_size=2, reduce_input="sum"),
        category_feature(vocab_size=2, reduce_input="sum"),
    ]
    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    input_features[0]["encoder"] = "parallel_cnn"
    exp_dir_name = run_experiment_with_visualization(input_features, output_features, dataset=rel_path)
    vis_output_pattern_pdf = os.path.join(exp_dir_name, "*.pdf")
    vis_output_pattern_png = os.path.join(exp_dir_name, "*.png")
    threshold_output_feature_name1 = get_output_feature_name(exp_dir_name)
    threshold_output_feature_name2 = get_output_feature_name(exp_dir_name, output_feature=1)
    probability = os.path.join(exp_dir_name, PREDICTIONS_PARQUET_FILE_NAME)
    experiment_source_data_name = csv_filename.split(".")[0]
    ground_truth = experiment_source_data_name + ".csv"
    split_file = experiment_source_data_name + ".split.csv"
    test_cmd_pdf = [
        "python",
        "-m",
        "ludwig.visualize",
        "--visualization",
        "confidence_thresholding_2thresholds_2d",
        "--ground_truth",
        ground_truth,
        "--split_file",
        split_file,
        "--ground_truth_metadata",
        exp_dir_name + "/model/training_set_metadata.json",
        "--probabilities",
        probability,
        "--threshold_output_feature_names",
        threshold_output_feature_name1,
        threshold_output_feature_name2,
        "--model_names",
        "Model1",
        "-od",
        exp_dir_name,
    ]
    test_cmd_png = test_cmd_pdf.copy() + ["-ff", "png"]

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(
            command,
        )
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 3 == len(figure_cnt)


</pre></div>
</td>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 3:</b> &nbsp; 5 fragments, nominal size 10 lines, similarity 83%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag42')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_cli.py: 162-174
</a>
<div class="mid" id="frag42" style="display:none"><pre>
def test_export_savedmodel_cli(csv_filename):
    """Test exporting Ludwig model to Tensorflows savedmodel format."""
    with tempfile.TemporaryDirectory() as tmpdir:
        config_filename = os.path.join(tmpdir, "config.yaml")
        dataset_filename = _prepare_data(csv_filename, config_filename)
        _run_ludwig("train", dataset=dataset_filename, config=config_filename, output_directory=tmpdir)
        _run_ludwig(
            "export_savedmodel",
            model=os.path.join(tmpdir, "experiment_run", "model"),
            output_path=os.path.join(tmpdir, "savedmodel"),
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag46')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_cli.py: 215-228
</a>
<div class="mid" id="frag46" style="display:none"><pre>
def test_evaluate_cli(csv_filename):
    """Test evaluate cli."""
    with tempfile.TemporaryDirectory() as tmpdir:
        config_filename = os.path.join(tmpdir, "config.yaml")
        dataset_filename = _prepare_data(csv_filename, config_filename)
        _run_ludwig("train", dataset=dataset_filename, config=config_filename, output_directory=tmpdir)
        _run_ludwig(
            "evaluate",
            dataset=dataset_filename,
            model=os.path.join(tmpdir, "experiment_run", "model"),
            output_directory=os.path.join(tmpdir, "predictions"),
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag45')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_cli.py: 200-213
</a>
<div class="mid" id="frag45" style="display:none"><pre>
def test_predict_cli(csv_filename):
    """Test predict cli."""
    with tempfile.TemporaryDirectory() as tmpdir:
        config_filename = os.path.join(tmpdir, "config.yaml")
        dataset_filename = _prepare_data(csv_filename, config_filename)
        _run_ludwig("train", dataset=dataset_filename, config=config_filename, output_directory=tmpdir)
        _run_ludwig(
            "predict",
            dataset=dataset_filename,
            model=os.path.join(tmpdir, "experiment_run", "model"),
            output_directory=os.path.join(tmpdir, "predictions"),
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag43')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_cli.py: 177-189
</a>
<div class="mid" id="frag43" style="display:none"><pre>
def test_export_neuropod_cli(csv_filename):
    """Test exporting Ludwig model to neuropod format."""
    with tempfile.TemporaryDirectory() as tmpdir:
        config_filename = os.path.join(tmpdir, "config.yaml")
        dataset_filename = _prepare_data(csv_filename, config_filename)
        _run_ludwig("train", dataset=dataset_filename, config=config_filename, output_directory=tmpdir)
        _run_ludwig(
            "export_neuropod",
            model=os.path.join(tmpdir, "experiment_run", "model"),
            output_path=os.path.join(tmpdir, "neuropod"),
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag48')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_cli.py: 239-253
</a>
<div class="mid" id="frag48" style="display:none"><pre>
def test_visualize_cli(csv_filename):
    """Test Ludwig 'visualize' cli."""
    with tempfile.TemporaryDirectory() as tmpdir:
        config_filename = os.path.join(tmpdir, "config.yaml")
        dataset_filename = _prepare_data(csv_filename, config_filename)
        _run_ludwig("train", dataset=dataset_filename, config=config_filename, output_directory=tmpdir)
        _run_ludwig(
            "visualize",
            visualization="learning_curves",
            model_names="run",
            training_statistics=os.path.join(tmpdir, "experiment_run", "training_statistics.json"),
            output_directory=os.path.join(tmpdir, "visualizations"),
        )


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 4:</b> &nbsp; 2 fragments, nominal size 44 lines, similarity 88%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag60')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_server.py: 120-183
</a>
<div class="mid" id="frag60" style="display:none"><pre>
def test_server_integration_with_images(tmpdir):
    # Image Inputs
    image_dest_folder = os.path.join(tmpdir, "generated_images")

    # Resnet encoder
    input_features = [
        image_feature(
            folder=image_dest_folder,
            preprocessing={"in_memory": True, "height": 8, "width": 8, "num_channels": 3},
            output_size=16,
            num_filters=8,
        ),
        text_feature(encoder="embed", min_len=1),
        number_feature(normalization="zscore"),
    ]
    output_features = [category_feature(vocab_size=4), number_feature()]

    np.random.seed(123)  # reproducible synthetic data
    rel_path = generate_data(input_features, output_features, os.path.join(tmpdir, "dataset.csv"))

    model = train_and_predict_model(input_features, output_features, data_csv=rel_path, output_directory=tmpdir)

    app = server(model)
    client = TestClient(app)
    response = client.get("/")
    assert response.status_code == 200

    response = client.post("/predict")
    # expect the HTTP 400 error code for this situation
    assert response.status_code == 400
    assert response.json() == ALL_FEATURES_PRESENT_ERROR

    data_df = read_csv(rel_path)

    # One-off prediction
    first_entry = data_df.T.to_dict()[0]
    data, files = convert_to_form(first_entry)
    server_response = client.post("/predict", data=data, files=files)
    assert server_response.status_code == 200
    server_response = server_response.json()

    server_response_keys = sorted(list(server_response.keys()))
    assert server_response_keys == sorted(output_keys_for(output_features))

    model_output, _ = model.predict(dataset=[first_entry], data_format=dict)
    model_output = model_output.to_dict("records")[0]
    assert model_output == server_response

    # Batch prediction
    assert len(data_df) &gt; 1
    files = convert_to_batch_form(data_df)
    server_response = client.post("/batch_predict", files=files)
    assert server_response.status_code == 200
    server_response = server_response.json()

    server_response_keys = sorted(server_response["columns"])
    assert server_response_keys == sorted(output_keys_for(output_features))
    assert len(data_df) == len(server_response["data"])

    model_output, _ = model.predict(dataset=data_df)
    model_output = model_output.to_dict("split")
    assert model_output == server_response


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag61')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_server.py: 185-243
</a>
<div class="mid" id="frag61" style="display:none"><pre>
def test_server_integration_with_audio(single_record, tmpdir):
    # Audio Inputs
    audio_dest_folder = os.path.join(tmpdir, "generated_audio")

    # Resnet encoder
    input_features = [
        audio_feature(
            folder=audio_dest_folder,
        ),
        text_feature(encoder="embed", min_len=1),
        number_feature(normalization="zscore"),
    ]
    output_features = [category_feature(vocab_size=4), number_feature()]

    rel_path = generate_data(input_features, output_features, os.path.join(tmpdir, "dataset.csv"))

    model = train_and_predict_model(input_features, output_features, data_csv=rel_path, output_directory=tmpdir)

    app = server(model)
    client = TestClient(app)
    response = client.get("/")
    assert response.status_code == 200

    response = client.post("/predict")
    # expect the HTTP 400 error code for this situation
    assert response.status_code == 400
    assert response.json() == ALL_FEATURES_PRESENT_ERROR

    data_df = read_csv(rel_path)

    if single_record:
        # Single record prediction
        first_entry = data_df.T.to_dict()[0]
        data, files = convert_to_form(first_entry)
        server_response = client.post("/predict", data=data, files=files)
        assert server_response.status_code == 200
        server_response = server_response.json()

        server_response_keys = sorted(list(server_response.keys()))
        assert server_response_keys == sorted(output_keys_for(output_features))

        model_output, _ = model.predict(dataset=[first_entry], data_format=dict)
        model_output = model_output.to_dict("records")[0]
        assert model_output == server_response
    else:
        # Batch prediction
        assert len(data_df) &gt; 1
        files = convert_to_batch_form(data_df)
        server_response = client.post("/batch_predict", files=files)
        assert server_response.status_code == 200
        server_response = server_response.json()

        server_response_keys = sorted(server_response["columns"])
        assert server_response_keys == sorted(output_keys_for(output_features))
        assert len(data_df) == len(server_response["data"])

        model_output, _ = model.predict(dataset=data_df)
        model_output = model_output.to_dict("split")
        assert model_output == server_response
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 5:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag80')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_graph_execution.py: 57-68
</a>
<div class="mid" id="frag80" style="display:none"><pre>
def test_experiment_multiple_seq_seq(csv_filename, output_features):
    input_features = [
        text_feature(vocab_size=100, min_len=1, encoder="stacked_cnn"),
        number_feature(normalization="zscore"),
        category_feature(vocab_size=10, embedding_size=5),
        set_feature(),
        sequence_feature(vocab_size=10, max_len=10, encoder="embed"),
    ]
    output_features = output_features

    rel_path = generate_data(input_features, output_features, csv_filename)
    run_experiment(input_features, output_features, dataset=rel_path)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag161')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_experiment.py: 245-258
</a>
<div class="mid" id="frag161" style="display:none"><pre>
def test_experiment_multiple_seq_seq(csv_filename, output_features):
    input_features = [
        text_feature(vocab_size=100, min_len=1, encoder="stacked_cnn"),
        number_feature(normalization="zscore"),
        category_feature(vocab_size=10, embedding_size=5),
        set_feature(),
        sequence_feature(vocab_size=10, max_len=10, encoder="embed"),
    ]
    output_features = output_features

    rel_path = generate_data(input_features, output_features, csv_filename)
    run_experiment(input_features, output_features, dataset=rel_path)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 6:</b> &nbsp; 18 fragments, nominal size 18 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag101')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization_api.py: 153-177
</a>
<div class="mid" id="frag101" style="display:none"><pre>
def test_compare_performance_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    # extract test stats only
    test_stats = experiment.test_stats_full
    viz_outputs = ("pdf", "png")
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + f"/*.{viz_output}"
            visualize.compare_performance(
                [test_stats, test_stats],
                output_feature_name=None,
                model_names=["Model1", "Model2"],
                output_directory=tmpvizdir,
                file_format=viz_output,
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 1 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag107')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization_api.py: 317-343
</a>
<div class="mid" id="frag107" style="display:none"><pre>
def test_compare_classifiers_predictions_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    predictions = experiment.predictions
    viz_outputs = ("pdf", "png")
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + f"/*.{viz_output}"
            visualize.compare_classifiers_predictions(
                [predictions, predictions],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                labels_limit=0,
                model_names=["Model1", "Model2"],
                output_directory=tmpvizdir,
                file_format=viz_output,
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 1 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag121')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization_api.py: 805-831
</a>
<div class="mid" id="frag121" style="display:none"><pre>
def test_frequency_vs_f1_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    # extract test stats
    test_stats = experiment.test_stats_full
    viz_outputs = ("pdf", "png")
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + f"/*.{viz_output}"
            visualize.frequency_vs_f1(
                [test_stats, test_stats],
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                top_n_classes=[0],
                model_names=["Model1", "Model2"],
                output_directory=tmpvizdir,
                file_format=viz_output,
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 2 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag120')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization_api.py: 777-804
</a>
<div class="mid" id="frag120" style="display:none"><pre>
def test_confusion_matrix_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    # extract test stats only
    test_stats = experiment.test_stats_full
    viz_outputs = ("pdf", "png")
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + f"/*.{viz_output}"
            visualize.confusion_matrix(
                [test_stats, test_stats],
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                top_n_classes=[0],
                normalize=False,
                model_names=["Model1", "Model2"],
                output_directory=tmpvizdir,
                file_format=viz_output,
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 4 == len(figure_cnt)


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag118')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization_api.py: 722-749
</a>
<div class="mid" id="frag118" style="display:none"><pre>
def test_calibration_1_vs_all_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    probabilities = experiment.probabilities
    viz_outputs = ("pdf", "png")
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = os.path.join(tmpvizdir, f"*.{viz_output}")
            visualize.calibration_1_vs_all(
                [probabilities, probabilities],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                top_n_classes=[6],
                labels_limit=0,
                model_namess=["Model1", "Model2"],
                output_directory=tmpvizdir,
                file_format=viz_output,
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 5 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag116')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization_api.py: 660-687
</a>
<div class="mid" id="frag116" style="display:none"><pre>
def test_roc_curves_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    probabilities = experiment.probabilities
    viz_outputs = ("pdf", "png")
    positive_label = 2
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + f"/*.{viz_output}"
            visualize.roc_curves(
                [probabilities, probabilities],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                positive_label,
                model_names=["Model1", "Model2"],
                output_directory=tmpvizdir,
                file_format=viz_output,
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 1 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag106')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization_api.py: 290-316
</a>
<div class="mid" id="frag106" style="display:none"><pre>
def test_compare_classifiers_multiclass_multimetric_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    # extract test stats only
    test_stats = experiment.test_stats_full
    viz_outputs = ("pdf", "png")
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + f"/*.{viz_output}"
            visualize.compare_classifiers_multiclass_multimetric(
                [test_stats, test_stats],
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                top_n_classes=[6],
                model_namess=["Model1", "Model2"],
                output_directory=tmpvizdir,
                file_format=viz_output,
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 4 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag103')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization_api.py: 206-232
</a>
<div class="mid" id="frag103" style="display:none"><pre>
def test_compare_classifier_performance_from_pred_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    prediction = experiment.predictions
    viz_outputs = ("pdf", "png")
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + f"/*.{viz_output}"
            visualize.compare_classifiers_performance_from_pred(
                [prediction, prediction],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                labels_limit=0,
                model_namess=["Model1", "Model2"],
                output_directory=tmpvizdir,
                file_format=viz_output,
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 1 == len(figure_cnt)


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag104')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization_api.py: 233-261
</a>
<div class="mid" id="frag104" style="display:none"><pre>
def test_compare_classifiers_performance_subset_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    probabilities = experiment.probabilities
    viz_outputs = ("pdf", "png")
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + f"/*.{viz_output}"
            visualize.compare_classifiers_performance_subset(
                [probabilities, probabilities],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                top_n_classes=[6],
                labels_limit=0,
                subset="ground_truth",
                model_namess=["Model1", "Model2"],
                output_directory=tmpvizdir,
                file_format=viz_output,
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 1 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag105')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization_api.py: 262-289
</a>
<div class="mid" id="frag105" style="display:none"><pre>
def test_compare_classifiers_performance_changing_k_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    probabilities = experiment.probabilities
    viz_outputs = ("pdf", "png")
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + f"/*.{viz_output}"
            visualize.compare_classifiers_performance_changing_k(
                [probabilities, probabilities],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                top_k=3,
                labels_limit=0,
                model_namess=["Model1", "Model2"],
                output_directory=tmpvizdir,
                file_format=viz_output,
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 1 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag110')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization_api.py: 398-424
</a>
<div class="mid" id="frag110" style="display:none"><pre>
def test_confidence_thresholding_data_vs_acc_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    probabilities = experiment.probabilities
    viz_outputs = ("pdf", "png")
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + f"/*.{viz_output}"
            visualize.confidence_thresholding_data_vs_acc(
                [probabilities, probabilities],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                labels_limit=0,
                model_names=["Model1", "Model2"],
                output_directory=tmpvizdir,
                file_format=viz_output,
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 1 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag111')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization_api.py: 425-453
</a>
<div class="mid" id="frag111" style="display:none"><pre>
def test_confidence_thresholding_data_vs_acc_subset_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    probabilities = experiment.probabilities
    viz_outputs = ("pdf", "png")
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + f"/*.{viz_output}"
            visualize.confidence_thresholding_data_vs_acc_subset(
                [probabilities, probabilities],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                top_n_classes=[3],
                labels_limit=0,
                subset="ground_truth",
                model_names=["Model1", "Model2"],
                output_directory=tmpvizdir,
                file_format=viz_output,
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 1 == len(figure_cnt)


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag112')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization_api.py: 454-484
</a>
<div class="mid" id="frag112" style="display:none"><pre>
def test_confidence_thresholding_data_vs_acc_subset_per_class_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    probabilities = experiment.probabilities
    viz_outputs = ("pdf", "png")
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + f"/*.{viz_output}"
            visualize.confidence_thresholding_data_vs_acc_subset_per_class(
                [probabilities, probabilities],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                top_n_classes=[3],
                labels_limit=0,
                subset="ground_truth",
                model_names=["Model1", "Model2"],
                output_directory=tmpvizdir,
                file_format=viz_output,
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            # 3 figures should be saved because experiment setting top_n_classes = 3
            # hence one figure per class
            assert 3 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag102')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization_api.py: 178-205
</a>
<div class="mid" id="frag102" style="display:none"><pre>
def test_compare_classifier_performance_from_prob_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    probability = experiment.probabilities
    viz_outputs = ("pdf", "png")
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + f"/*.{viz_output}"
            visualize.compare_classifiers_performance_from_prob(
                [probability, probability],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                top_n_classes=[0],
                labels_limit=0,
                model_namess=["Model1", "Model2"],
                output_directory=tmpvizdir,
                file_format=viz_output,
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 1 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag109')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization_api.py: 371-397
</a>
<div class="mid" id="frag109" style="display:none"><pre>
def test_confidence_thresholding_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    probabilities = experiment.probabilities
    viz_outputs = ("pdf", "png")
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + f"/*.{viz_output}"
            visualize.confidence_thresholding(
                [probabilities, probabilities],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                labels_limit=0,
                model_names=["Model1", "Model2"],
                output_directory=tmpvizdir,
                file_format=viz_output,
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 1 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag119')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization_api.py: 750-776
</a>
<div class="mid" id="frag119" style="display:none"><pre>
def test_calibration_multiclass_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    probabilities = experiment.probabilities
    viz_outputs = ("pdf", "png")
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + f"/*.{viz_output}"
            visualize.calibration_multiclass(
                [probabilities, probabilities],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                labels_limit=0,
                model_names=["Model1", "Model2"],
                output_directory=tmpvizdir,
                file_format=viz_output,
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 2 == len(figure_cnt)


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag108')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization_api.py: 344-370
</a>
<div class="mid" id="frag108" style="display:none"><pre>
def test_compare_classifiers_predictions_distribution_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    predictions = experiment.predictions_num
    viz_outputs = ("pdf", "png")
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + f"/*.{viz_output}"
            visualize.compare_classifiers_predictions_distribution(
                [predictions, predictions],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                labels_limit=0,
                model_names=["Model1", "Model2"],
                output_directory=tmpvizdir,
                file_format=viz_output,
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 1 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag115')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization_api.py: 630-659
</a>
<div class="mid" id="frag115" style="display:none"><pre>
def test_binary_threshold_vs_metric_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    probabilities = experiment.probabilities
    viz_outputs = ("pdf", "png")
    metrics = ["accuracy"]
    positive_label = 2
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + f"/*.{viz_output}"
            visualize.binary_threshold_vs_metric(
                [probabilities, probabilities],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                metrics,
                positive_label,
                model_names=["Model1", "Model2"],
                output_directory=tmpvizdir,
                file_format=viz_output,
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 1 == len(figure_cnt)


</pre></div>
</td>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 7:</b> &nbsp; 2 fragments, nominal size 53 lines, similarity 94%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag113')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization_api.py: 485-556
</a>
<div class="mid" id="frag113" style="display:none"><pre>
def test_confidence_thresholding_2thresholds_2d_vis_api(csv_filename):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param csv_filename: csv fixture from tests.fixtures.filenames.csv_filename
    :return: None
    """
    input_features = [
        text_feature(vocab_size=10, min_len=1, encoder="stacked_cnn"),
        number_feature(),
        category_feature(vocab_size=10, embedding_size=5),
        set_feature(),
        sequence_feature(vocab_size=10, max_len=10, encoder="embed"),
    ]
    output_features = [
        category_feature(vocab_size=2, reduce_input="sum"),
        category_feature(vocab_size=2, reduce_input="sum"),
    ]
    encoder = "parallel_cnn"
    with TemporaryDirectory() as tmpvizdir:
        # Generate test data
        data_csv = generate_data(input_features, output_features, os.path.join(tmpvizdir, csv_filename))
        input_features[0]["encoder"] = encoder
        model = run_api_experiment(input_features, output_features)
        test_df, train_df, val_df = obtain_df_splits(data_csv)
        _, _, output_dir = model.train(
            training_set=train_df, validation_set=val_df, output_directory=os.path.join(tmpvizdir, "results")
        )
        test_stats, predictions, _ = model.evaluate(dataset=test_df, collect_predictions=True, output_dir=output_dir)

        output_feature_name1 = output_features[0]["name"]
        output_feature_name2 = output_features[1]["name"]

        ground_truth_metadata = model.training_set_metadata
        feature1_cols = [
            f"{output_feature_name1}_probabilities_{label}"
            for label in ground_truth_metadata[output_feature_name1]["idx2str"]
        ]
        feature2_cols = [
            f"{output_feature_name2}_probabilities_{label}"
            for label in ground_truth_metadata[output_feature_name2]["idx2str"]
        ]

        # probabilities need to be list of lists containing each row data from the
        # probability columns ref: https://ludwig-ai.github.io/ludwig-docs/api/#test - Return
        probability1 = predictions.loc[:, feature1_cols].values
        probability2 = predictions.loc[:, feature2_cols].values

        target_predictions1 = test_df[output_feature_name1]
        target_predictions2 = test_df[output_feature_name2]
        ground_truth1 = np.asarray(
            [ground_truth_metadata[output_feature_name1]["str2idx"][prediction] for prediction in target_predictions1]
        )
        ground_truth2 = np.asarray(
            [ground_truth_metadata[output_feature_name2]["str2idx"][prediction] for prediction in target_predictions2]
        )
        viz_outputs = ("pdf", "png")
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = os.path.join(output_dir, "*.{}").format(viz_output)
            visualize.confidence_thresholding_2thresholds_2d(
                [probability1, probability2],
                [ground_truth1, ground_truth2],
                model.training_set_metadata,
                [output_feature_name1, output_feature_name2],
                labels_limit=0,
                model_names=["Model1"],
                output_directory=output_dir,
                file_format=viz_output,
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 3 == len(figure_cnt)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag114')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_visualization_api.py: 557-629
</a>
<div class="mid" id="frag114" style="display:none"><pre>
def test_confidence_thresholding_2thresholds_3d_vis_api(csv_filename):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param csv_filename: csv fixture from tests.fixtures.filenames.csv_filename
    :return: None
    """
    input_features = [
        text_feature(vocab_size=10, min_len=1, encoder="stacked_cnn"),
        number_feature(),
        category_feature(vocab_size=10, embedding_size=5),
        set_feature(),
        sequence_feature(vocab_size=10, max_len=10, encoder="embed"),
    ]
    output_features = [
        category_feature(vocab_size=2, reduce_input="sum"),
        category_feature(vocab_size=2, reduce_input="sum"),
    ]
    encoder = "parallel_cnn"
    with TemporaryDirectory() as tmpvizdir:
        # Generate test data
        data_csv = generate_data(input_features, output_features, os.path.join(tmpvizdir, csv_filename))
        input_features[0]["encoder"] = encoder
        model = run_api_experiment(input_features, output_features)
        test_df, train_df, val_df = obtain_df_splits(data_csv)
        _, _, output_dir = model.train(
            training_set=train_df, validation_set=val_df, output_directory=os.path.join(tmpvizdir, "results")
        )
        test_stats, predictions, _ = model.evaluate(
            dataset=test_df, collect_predictions=True, output_directory=output_dir
        )

        output_feature_name1 = output_features[0]["name"]
        output_feature_name2 = output_features[1]["name"]

        ground_truth_metadata = model.training_set_metadata
        feature1_cols = [
            f"{output_feature_name1}_probabilities_{label}"
            for label in ground_truth_metadata[output_feature_name1]["idx2str"]
        ]
        feature2_cols = [
            f"{output_feature_name2}_probabilities_{label}"
            for label in ground_truth_metadata[output_feature_name2]["idx2str"]
        ]

        # probabilities need to be list of lists containing each row data from the
        # probability columns ref: https://ludwig-ai.github.io/ludwig-docs/api/#test - Return
        probability1 = predictions.loc[:, feature1_cols].values
        probability2 = predictions.loc[:, feature2_cols].values

        target_predictions1 = test_df[output_feature_name1]
        target_predictions2 = test_df[output_feature_name2]
        ground_truth1 = np.asarray(
            [ground_truth_metadata[output_feature_name1]["str2idx"][prediction] for prediction in target_predictions1]
        )
        ground_truth2 = np.asarray(
            [ground_truth_metadata[output_feature_name2]["str2idx"][prediction] for prediction in target_predictions2]
        )
        viz_outputs = ("pdf", "png")
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = os.path.join(output_dir, f"*.{viz_output}")
            visualize.confidence_thresholding_2thresholds_3d(
                [probability1, probability2],
                [ground_truth1, ground_truth2],
                model.training_set_metadata,
                [output_feature_name1, output_feature_name2],
                labels_limit=0,
                output_directory=output_dir,
                file_format=viz_output,
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 1 == len(figure_cnt)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 8:</b> &nbsp; 3 fragments, nominal size 22 lines, similarity 73%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag144')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_api.py: 337-366
</a>
<div class="mid" id="frag144" style="display:none"><pre>
def test_api_skip_parameters_train(
    csv_filename,
    skip_save_training_description,
    skip_save_training_statistics,
    skip_save_model,
    skip_save_progress,
    skip_save_log,
    skip_save_processed_input,
):
    # Single sequence input, single category output
    input_features = [category_feature(vocab_size=5)]
    output_features = [category_feature(vocab_size=5)]

    with tempfile.TemporaryDirectory() as output_dir:
        # Generate test data
        rel_path = generate_data(input_features, output_features, os.path.join(output_dir, csv_filename))
        run_api_commands(
            input_features,
            output_features,
            data_csv=rel_path,
            output_dir=output_dir,
            skip_save_training_description=skip_save_training_description,
            skip_save_training_statistics=skip_save_training_statistics,
            skip_save_model=skip_save_model,
            skip_save_progress=skip_save_progress,
            skip_save_log=skip_save_log,
            skip_save_processed_input=skip_save_processed_input,
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag146')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_api.py: 396-423
</a>
<div class="mid" id="frag146" style="display:none"><pre>
def test_api_skip_parameters_evaluate(
    csv_filename,
    skip_save_unprocessed_output,
    skip_save_predictions,
    skip_save_eval_stats,
    skip_collect_predictions,
    skip_collect_overall_stats,
):
    # Single sequence input, single category output
    input_features = [category_feature(vocab_size=5)]
    output_features = [category_feature(vocab_size=5)]

    with tempfile.TemporaryDirectory() as output_dir:
        # Generate test data
        rel_path = generate_data(input_features, output_features, os.path.join(output_dir, csv_filename))
        run_api_commands(
            input_features,
            output_features,
            data_csv=rel_path,
            output_dir=output_dir,
            skip_save_unprocessed_output=skip_save_unprocessed_output,
            skip_save_predictions=skip_save_predictions,
            skip_save_eval_stats=skip_save_eval_stats,
            skip_collect_predictions=skip_collect_predictions,
            skip_collect_overall_stats=skip_collect_overall_stats,
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag145')" href="javascript:;">
ludwig-0.5rc2/tests/integration_tests/test_api.py: 369-390
</a>
<div class="mid" id="frag145" style="display:none"><pre>
def test_api_skip_parameters_predict(
    csv_filename,
    skip_save_unprocessed_output,
    skip_save_predictions,
):
    # Single sequence input, single category output
    input_features = [category_feature(vocab_size=5)]
    output_features = [category_feature(vocab_size=5)]

    with tempfile.TemporaryDirectory() as output_dir:
        # Generate test data
        rel_path = generate_data(input_features, output_features, os.path.join(output_dir, csv_filename))
        run_api_commands(
            input_features,
            output_features,
            data_csv=rel_path,
            output_dir=output_dir,
            skip_save_unprocessed_output=skip_save_unprocessed_output,
            skip_save_predictions=skip_save_predictions,
        )


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 9:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag189')" href="javascript:;">
ludwig-0.5rc2/tests/ludwig/decoders/test_sequence_decoder_utils.py: 10-25
</a>
<div class="mid" id="frag189" style="display:none"><pre>
def test_get_rnn_init_state_uses_hidden(num_layers):
    batch_size = 16
    sequence_length = 32
    state_size = 64
    combiner_outputs = {}
    combiner_outputs[HIDDEN] = torch.rand([batch_size, sequence_length, state_size])

    # With sequence reduction.
    result = sequence_decoder_utils.get_rnn_init_state(combiner_outputs, SequenceReducer(reduce_mode="sum"), num_layers)
    assert list(result.size()) == [num_layers, batch_size, state_size]

    # Without sequence reduction.
    with pytest.raises(ValueError):
        sequence_decoder_utils.get_rnn_init_state(combiner_outputs, SequenceReducer(reduce_mode="none"), num_layers)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag191')" href="javascript:;">
ludwig-0.5rc2/tests/ludwig/decoders/test_sequence_decoder_utils.py: 40-58
</a>
<div class="mid" id="frag191" style="display:none"><pre>
def test_get_lstm_init_state_uses_hidden(num_layers):
    batch_size = 16
    sequence_length = 32
    state_size = 64
    combiner_outputs = {}
    combiner_outputs[HIDDEN] = torch.rand([batch_size, sequence_length, state_size])

    # With sequence reduction.
    decoder_hidden_state, decoder_cell_state = sequence_decoder_utils.get_lstm_init_state(
        combiner_outputs, SequenceReducer(reduce_mode="sum"), num_layers
    )
    assert list(decoder_hidden_state.size()) == [num_layers, batch_size, state_size]
    assert list(decoder_cell_state.size()) == [num_layers, batch_size, state_size]

    # Without sequence reduction.
    with pytest.raises(ValueError):
        sequence_decoder_utils.get_lstm_init_state(combiner_outputs, SequenceReducer(reduce_mode="none"), num_layers)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 10:</b> &nbsp; 3 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag231')" href="javascript:;">
ludwig-0.5rc2/tests/ludwig/encoders/test_h3_encoders.py: 11-23
</a>
<div class="mid" id="frag231" style="display:none"><pre>
def test_h3_embed():
    embed = h3_encoders.H3Embed().to(DEVICE)
    inputs = torch.tensor(
        [
            [2, 0, 14, 102, 7, 0, 3, 5, 0, 5, 5, 0, 5, 7, 7, 7, 7, 7, 7],
            [2, 0, 14, 102, 7, 0, 3, 5, 0, 5, 5, 0, 5, 7, 7, 7, 7, 7, 7],
        ],
        dtype=torch.int32,
    ).to(DEVICE)
    outputs = embed(inputs)
    assert outputs["encoder_output"].size()[1:] == embed.output_shape


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag232')" href="javascript:;">
ludwig-0.5rc2/tests/ludwig/encoders/test_h3_encoders.py: 24-36
</a>
<div class="mid" id="frag232" style="display:none"><pre>
def test_h3_weighted_sum():
    embed = h3_encoders.H3WeightedSum().to(DEVICE)
    inputs = torch.tensor(
        [
            [2, 0, 14, 102, 7, 0, 3, 5, 0, 5, 5, 0, 5, 7, 7, 7, 7, 7, 7],
            [2, 0, 14, 102, 7, 0, 3, 5, 0, 5, 5, 0, 5, 7, 7, 7, 7, 7, 7],
        ],
        dtype=torch.int32,
    ).to(DEVICE)
    outputs = embed(inputs)
    assert outputs["encoder_output"].size()[1:] == embed.output_shape


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag233')" href="javascript:;">
ludwig-0.5rc2/tests/ludwig/encoders/test_h3_encoders.py: 37-47
</a>
<div class="mid" id="frag233" style="display:none"><pre>
def test_h3_rnn_embed():
    embed = h3_encoders.H3RNN().to(DEVICE)
    inputs = torch.tensor(
        [
            [2, 0, 14, 102, 7, 0, 3, 5, 0, 5, 5, 0, 5, 7, 7, 7, 7, 7, 7],
            [2, 0, 14, 102, 7, 0, 3, 5, 0, 5, 5, 0, 5, 7, 7, 7, 7, 7, 7],
        ],
        dtype=torch.int32,
    ).to(DEVICE)
    outputs = embed(inputs)
    assert outputs["encoder_output"].size()[1:] == embed.output_shape
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 11:</b> &nbsp; 2 fragments, nominal size 23 lines, similarity 79%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag238')" href="javascript:;">
ludwig-0.5rc2/tests/ludwig/utils/test_class_balancing.py: 54-79
</a>
<div class="mid" id="frag238" style="display:none"><pre>
def test_non_binary_failure():
    config = {
        "input_features": [
            {"name": "Index", "proc_column": "Index", "type": "number"},
            {"name": "random_1", "proc_column": "random_1", "type": "number"},
            {"name": "random_2", "proc_column": "random_2", "type": "number"},
        ],
        "output_features": [{"name": "Label", "proc_column": "Label", "type": "number"}],
        "preprocessing": {},
    }
    input_df = pd.DataFrame(
        {
            "Index": np.arange(0, 200, 1),
            "random_1": np.random.randint(0, 50, 200),
            "random_2": np.random.choice(["Type A", "Type B", "Type C", "Type D"], 200),
            "Label": np.concatenate((np.zeros(180), np.ones(20))),
            "split": np.zeros(200),
        }
    )

    backend = LocalBackend()

    with pytest.raises(ValueError):
        balance_data(input_df, config["output_features"], config["preprocessing"], backend)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag239')" href="javascript:;">
ludwig-0.5rc2/tests/ludwig/utils/test_class_balancing.py: 80-107
</a>
<div class="mid" id="frag239" style="display:none"><pre>
def test_multiple_class_failure():
    config = {
        "input_features": [
            {"name": "Index", "proc_column": "Index", "type": "number"},
            {"name": "random_1", "proc_column": "random_1", "type": "number"},
            {"name": "random_2", "proc_column": "random_2", "type": "number"},
        ],
        "output_features": [
            {"name": "Label", "proc_column": "Label", "type": "binary"},
            {"name": "Label2", "proc_column": "Label2", "type": "binary"},
        ],
        "preprocessing": {},
    }
    input_df = pd.DataFrame(
        {
            "Index": np.arange(0, 200, 1),
            "random_1": np.random.randint(0, 50, 200),
            "random_2": np.random.choice(["Type A", "Type B", "Type C", "Type D"], 200),
            "Label": np.concatenate((np.zeros(180), np.ones(20))),
            "Label2": np.concatenate((np.zeros(180), np.ones(20))),
            "split": np.zeros(200),
        }
    )

    backend = LocalBackend()

    with pytest.raises(ValueError):
        balance_data(input_df, config["output_features"], config["preprocessing"], backend)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 12:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag248')" href="javascript:;">
ludwig-0.5rc2/tests/ludwig/utils/test_torch_utils.py: 109-123
</a>
<div class="mid" id="frag248" style="display:none"><pre>
def test_initialize_pytorch_with_horovod(mock_torch):
    mock_torch.cuda.is_available.return_value = True
    mock_torch.cuda.device_count.return_value = 4

    mock_hvd = Mock()
    mock_hvd.local_rank.return_value = 1
    mock_hvd.local_size.return_value = 4

    with clean_params():
        initialize_pytorch(horovod=mock_hvd)

    mock_torch.cuda.set_device.assert_called_with(1)
    assert "CUDA_VISIBLE_DEVICES" not in os.environ


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag249')" href="javascript:;">
ludwig-0.5rc2/tests/ludwig/utils/test_torch_utils.py: 126-141
</a>
<div class="mid" id="frag249" style="display:none"><pre>
def test_initialize_pytorch_with_horovod_bad_local_rank(mock_torch, mock_warnings):
    """In this scenario, the local_size 5 is out of the bounds of the GPU indices."""
    mock_torch.cuda.is_available.return_value = True
    mock_torch.cuda.device_count.return_value = 4

    mock_hvd = Mock()
    mock_hvd.local_rank.return_value = 1
    mock_hvd.local_size.return_value = 5

    with clean_params():
        initialize_pytorch(horovod=mock_hvd)

    assert os.environ["CUDA_VISIBLE_DEVICES"] == ""
    mock_warnings.warn.assert_called()


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 13:</b> &nbsp; 4 fragments, nominal size 18 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag286')" href="javascript:;">
ludwig-0.5rc2/tests/ludwig/utils/test_strings_utils.py: 55-76
</a>
<div class="mid" id="frag286" style="display:none"><pre>
def test_create_vocabulary_chars():
    data = pd.DataFrame(["Hello, I'm a single sentence!", "And another sentence", "And the very very last one"])
    column = data[0]
    preprocessing_parameters = TextFeatureMixin.preprocessing_defaults()

    vocabulary_output = strings_utils.create_vocabulary(
        column,
        tokenizer_type="characters",
        num_most_frequent=preprocessing_parameters["char_most_common"],
        lowercase=preprocessing_parameters["lowercase"],
        unknown_symbol=preprocessing_parameters["unknown_symbol"],
        padding_symbol=preprocessing_parameters["padding_symbol"],
        pretrained_model_name_or_path=preprocessing_parameters["pretrained_model_name_or_path"],
    )

    assert len(vocabulary_output[0]) == 24
    assert vocabulary_output[0][strings_utils.SpecialSymbol.START.value] == strings_utils.START_SYMBOL
    assert vocabulary_output[0][strings_utils.SpecialSymbol.STOP.value] == strings_utils.STOP_SYMBOL
    assert vocabulary_output[0][strings_utils.SpecialSymbol.PADDING.value] == strings_utils.PADDING_SYMBOL
    assert vocabulary_output[0][strings_utils.SpecialSymbol.UNKNOWN.value] == strings_utils.UNKNOWN_SYMBOL


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag287')" href="javascript:;">
ludwig-0.5rc2/tests/ludwig/utils/test_strings_utils.py: 77-99
</a>
<div class="mid" id="frag287" style="display:none"><pre>
def test_create_vocabulary_word():
    data = pd.DataFrame(["Hello, I'm a single sentence!", "And another sentence", "And the very very last one"])
    column = data[0]
    preprocessing_parameters = TextFeatureMixin.preprocessing_defaults()

    vocabulary_output = strings_utils.create_vocabulary(
        column,
        tokenizer_type=preprocessing_parameters["word_tokenizer"],
        num_most_frequent=preprocessing_parameters["word_most_common"],
        lowercase=preprocessing_parameters["lowercase"],
        vocab_file=preprocessing_parameters["word_vocab_file"],
        unknown_symbol=preprocessing_parameters["unknown_symbol"],
        padding_symbol=preprocessing_parameters["padding_symbol"],
        pretrained_model_name_or_path=preprocessing_parameters["pretrained_model_name_or_path"],
    )

    assert len(vocabulary_output[0]) == 19
    assert vocabulary_output[0][strings_utils.SpecialSymbol.UNKNOWN.value] == strings_utils.UNKNOWN_SYMBOL
    assert vocabulary_output[0][strings_utils.SpecialSymbol.STOP.value] == strings_utils.STOP_SYMBOL
    assert vocabulary_output[0][strings_utils.SpecialSymbol.PADDING.value] == strings_utils.PADDING_SYMBOL
    assert vocabulary_output[0][strings_utils.SpecialSymbol.UNKNOWN.value] == strings_utils.UNKNOWN_SYMBOL


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag289')" href="javascript:;">
ludwig-0.5rc2/tests/ludwig/utils/test_strings_utils.py: 121-138
</a>
<div class="mid" id="frag289" style="display:none"><pre>
def test_create_vocabulary_from_hf():
    data = pd.DataFrame(["Hello, I'm a single sentence!", "And another sentence", "And the very very last one"])
    column = data[0]
    preprocessing_parameters = TextFeatureMixin.preprocessing_defaults()

    vocabulary_output = strings_utils.create_vocabulary(
        column,
        tokenizer_type="hf_tokenizer",
        num_most_frequent=preprocessing_parameters["char_most_common"],
        lowercase=preprocessing_parameters["lowercase"],
        unknown_symbol=preprocessing_parameters["unknown_symbol"],
        padding_symbol=preprocessing_parameters["padding_symbol"],
        pretrained_model_name_or_path="albert-base-v2",
    )

    assert len(vocabulary_output[0]) == 30000


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag288')" href="javascript:;">
ludwig-0.5rc2/tests/ludwig/utils/test_strings_utils.py: 100-120
</a>
<div class="mid" id="frag288" style="display:none"><pre>
def test_create_vocabulary_no_special_symbols():
    data = pd.DataFrame(["Hello, I'm a single sentence!", "And another sentence", "And the very very last one"])
    column = data[0]
    preprocessing_parameters = TextFeatureMixin.preprocessing_defaults()

    vocabulary_output = strings_utils.create_vocabulary(
        column,
        tokenizer_type=preprocessing_parameters["word_tokenizer"],
        num_most_frequent=preprocessing_parameters["word_most_common"],
        lowercase=preprocessing_parameters["lowercase"],
        vocab_file=preprocessing_parameters["word_vocab_file"],
        unknown_symbol=preprocessing_parameters["unknown_symbol"],
        padding_symbol=preprocessing_parameters["padding_symbol"],
        pretrained_model_name_or_path=preprocessing_parameters["pretrained_model_name_or_path"],
        add_special_symbols=False,
    )

    assert len(vocabulary_output[0]) == 16
    assert vocabulary_output[0][strings_utils.SpecialSymbol.UNKNOWN.value] == strings_utils.UNKNOWN_SYMBOL


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 14:</b> &nbsp; 3 fragments, nominal size 20 lines, similarity 78%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag291')" href="javascript:;">
ludwig-0.5rc2/tests/ludwig/utils/test_hyperopt_utils.py: 52-77
</a>
<div class="mid" id="frag291" style="display:none"><pre>
def test_grid_strategy(key):
    hyperopt_test_params = HYPEROPT_PARAMS[key]
    goal = hyperopt_test_params["goal"]
    grid_sampler_params = hyperopt_test_params["parameters"]

    grid_sampler = GridSampler(goal=goal, parameters=grid_sampler_params)

    actual_params_keys = grid_sampler.sample().keys()
    expected_params_keys = grid_sampler_params.keys()

    for sample in grid_sampler.samples:
        for param in actual_params_keys:
            value = sample[param]
            param_type = grid_sampler_params[param]["type"]
            if param_type == "int" or param_type == "float":
                low = grid_sampler_params[param]["low"]
                high = grid_sampler_params[param]["high"]
                assert value &gt;= low and value &lt;= high
            else:
                assert value in set(grid_sampler_params[param]["values"])

    assert actual_params_keys == expected_params_keys
    assert grid_sampler.search_space == hyperopt_test_params["expected_search_space"]
    assert len(grid_sampler.samples) == hyperopt_test_params["expected_len_grids"]


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag292')" href="javascript:;">
ludwig-0.5rc2/tests/ludwig/utils/test_hyperopt_utils.py: 79-104
</a>
<div class="mid" id="frag292" style="display:none"><pre>
def test_random_sampler(key):
    hyperopt_test_params = HYPEROPT_PARAMS[key]
    goal = hyperopt_test_params["goal"]
    random_sampler_params = hyperopt_test_params["parameters"]
    num_samples = hyperopt_test_params["num_samples"]

    random_sampler = RandomSampler(goal=goal, parameters=random_sampler_params, num_samples=num_samples)

    actual_params_keys = random_sampler.sample().keys()
    expected_params_keys = random_sampler_params.keys()

    for sample in random_sampler.samples:
        for param in actual_params_keys:
            value = sample[param]
            param_type = random_sampler_params[param]["type"]
            if param_type == "int" or param_type == "float":
                low = random_sampler_params[param]["low"]
                high = random_sampler_params[param]["high"]
                assert value &gt;= low and value &lt;= high
            else:
                assert value in set(random_sampler_params[param]["values"])

    assert actual_params_keys == expected_params_keys
    assert len(random_sampler.samples) == num_samples


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag293')" href="javascript:;">
ludwig-0.5rc2/tests/ludwig/utils/test_hyperopt_utils.py: 106-133
</a>
<div class="mid" id="frag293" style="display:none"><pre>
def test_pysot_sampler(key):
    hyperopt_test_params = HYPEROPT_PARAMS[key]
    goal = hyperopt_test_params["goal"]
    pysot_sampler_params = hyperopt_test_params["parameters"]
    num_samples = hyperopt_test_params["num_samples"]

    pysot_sampler = PySOTSampler(goal=goal, parameters=pysot_sampler_params, num_samples=num_samples)

    actual_params_keys = pysot_sampler.sample().keys()
    expected_params_keys = pysot_sampler_params.keys()

    pysot_sampler_samples = 1

    for _ in range(num_samples - 1):
        sample = pysot_sampler.sample()
        for param in actual_params_keys:
            value = sample[param]
            param_type = pysot_sampler_params[param]["type"]
            if param_type == "int" or param_type == "float":
                low = pysot_sampler_params[param]["low"]
                high = pysot_sampler_params[param]["high"]
                assert value &gt;= low and value &lt;= high
            else:
                assert value in set(pysot_sampler_params[param]["values"])
        pysot_sampler_samples += 1

    assert actual_params_keys == expected_params_keys
    assert pysot_sampler_samples == num_samples
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 15:</b> &nbsp; 2 fragments, nominal size 20 lines, similarity 95%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag310')" href="javascript:;">
ludwig-0.5rc2/tests/ludwig/features/test_binary_feature.py: 32-55
</a>
<div class="mid" id="frag310" style="display:none"><pre>
def test_binary_output_feature():
    binary_output_feature = BinaryOutputFeature(
        {
            "name": "binary_feature",
            "type": "binary",
            "input_size": 1,
            "loss": {
                "positive_class_weight": 1,
                "robust_lambda": 0,
                "confidence_penalty": 0,
            },
        },
        {},
    ).to(DEVICE)
    combiner_outputs = {}
    combiner_outputs["combiner_output"] = torch.randn([BATCH_SIZE, BINARY_W_SIZE], dtype=torch.float32).to(DEVICE)

    binary_output = binary_output_feature(combiner_outputs, {})

    assert "last_hidden" in binary_output
    assert "logits" in binary_output
    assert binary_output["logits"].size() == torch.Size([BATCH_SIZE])


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag311')" href="javascript:;">
ludwig-0.5rc2/tests/ludwig/features/test_binary_feature.py: 56-77
</a>
<div class="mid" id="frag311" style="display:none"><pre>
def test_binary_output_feature_without_positive_class_weight():
    binary_output_feature = BinaryOutputFeature(
        {
            "name": "binary_feature",
            "type": "binary",
            "input_size": 1,
            "loss": {
                "positive_class_weight": None,
                "robust_lambda": 0,
                "confidence_penalty": 0,
            },
        },
        {},
    ).to(DEVICE)
    combiner_outputs = {}
    combiner_outputs["combiner_output"] = torch.randn([BATCH_SIZE, BINARY_W_SIZE], dtype=torch.float32).to(DEVICE)

    binary_output = binary_output_feature(combiner_outputs, {})

    assert "last_hidden" in binary_output
    assert "logits" in binary_output
    assert binary_output["logits"].size() == torch.Size([BATCH_SIZE])
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 16:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag312')" href="javascript:;">
ludwig-0.5rc2/tests/ludwig/features/test_timeseries_feature.py: 16-29
</a>
<div class="mid" id="frag312" style="display:none"><pre>
def timeseries_config():
    return {
        "name": "timeseries_12",
        "type": "timeseries",
        "max_len": MAX_LEN,
        "embedding_size": EMBEDDING_SIZE,
        "max_sequence_length": SEQ_SIZE,
        "output_size": 8,
        "state_size": 8,
        "num_filters": 8,
        "hidden_size": 8,
    }


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1351')" href="javascript:;">
ludwig-0.5rc2/ludwig/features/image_feature.py: 80-93
</a>
<div class="mid" id="frag1351" style="display:none"><pre>
    def preprocessing_defaults():
        return {
            "missing_value_strategy": BACKFILL,
            "in_memory": True,
            "resize_method": "interpolate",
            "scaling": "pixel_normalization",
            "num_processes": 1,
            "infer_image_num_channels": True,
            "infer_image_dimensions": True,
            "infer_image_max_height": 256,
            "infer_image_max_width": 256,
            "infer_image_sample_size": 100,
        }

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 17:</b> &nbsp; 4 fragments, nominal size 13 lines, similarity 85%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag359')" href="javascript:;">
ludwig-0.5rc2/tests/ludwig/modules/test_embedding_modules.py: 14-28
</a>
<div class="mid" id="frag359" style="display:none"><pre>
def test_embed(
    vocab: List[str],
    embedding_size: int,
    representation: str,
):
    embed = Embed(
        vocab=vocab,
        embedding_size=embedding_size,
        representation=representation,
    ).to(DEVICE)
    inputs = torch.randint(0, 2, size=(2, 1)).bool().to(DEVICE)
    outputs = embed(inputs)
    assert outputs.shape[1:] == embed.output_shape


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag362')" href="javascript:;">
ludwig-0.5rc2/tests/ludwig/modules/test_embedding_modules.py: 64-79
</a>
<div class="mid" id="frag362" style="display:none"><pre>
def test_embed_sequence(
    vocab: List[str],
    embedding_size: int,
    representation: str,
):
    embed = EmbedSequence(
        vocab=vocab,
        embedding_size=embedding_size,
        max_sequence_length=10,
        representation=representation,
    ).to(DEVICE)
    inputs = torch.randint(0, 2, size=(2, 10)).to(DEVICE)
    outputs = embed(inputs)
    assert outputs.shape[1:] == embed.output_shape


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag360')" href="javascript:;">
ludwig-0.5rc2/tests/ludwig/modules/test_embedding_modules.py: 32-46
</a>
<div class="mid" id="frag360" style="display:none"><pre>
def test_embed_set(
    vocab: List[str],
    embedding_size: int,
    representation: str,
):
    embed = EmbedSet(
        vocab=vocab,
        embedding_size=embedding_size,
        representation=representation,
    ).to(DEVICE)
    inputs = torch.randint(0, 2, size=(2, len(vocab))).bool().to(DEVICE)
    outputs = embed(inputs)
    assert outputs.shape[1:] == embed.output_shape


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag363')" href="javascript:;">
ludwig-0.5rc2/tests/ludwig/modules/test_embedding_modules.py: 83-96
</a>
<div class="mid" id="frag363" style="display:none"><pre>
def test_token_and_position_embedding(
    vocab: List[str],
    embedding_size: int,
    representation: str,
):
    embed = TokenAndPositionEmbedding(
        vocab=vocab,
        embedding_size=embedding_size,
        max_sequence_length=10,
        representation=representation,
    ).to(DEVICE)
    inputs = torch.randint(0, 2, size=(2, 10)).to(DEVICE)
    outputs = embed(inputs)
    assert outputs.shape[1:] == embed.output_shape
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 18:</b> &nbsp; 3 fragments, nominal size 12 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag373')" href="javascript:;">
ludwig-0.5rc2/ludwig/decoders/registry.py: 9-25
</a>
<div class="mid" id="frag373" style="display:none"><pre>
def register_decoder(name: str, features: Union[str, List[str]], default=False):
    if isinstance(features, str):
        features = [features]

    def wrap(cls):
        for feature in features:
            feature_registry = decoder_registry.get(feature, {})
            feature_registry[name] = cls
            if default:
                for key in DEFAULT_KEYS:
                    feature_registry[key] = cls
            decoder_registry[feature] = feature_registry
        return cls

    return wrap


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1460')" href="javascript:;">
ludwig-0.5rc2/ludwig/modules/metric_registry.py: 9-23
</a>
<div class="mid" id="frag1460" style="display:none"><pre>
def register_metric(name: str, features: Union[str, List[str]]):
    if isinstance(features, str):
        features = [features]

    def wrap(cls):
        for feature in features:
            feature_registry = metric_feature_registry.get(feature, {})
            feature_registry[name] = cls
            metric_feature_registry[feature] = feature_registry
        metric_registry[name] = cls
        return cls

    return wrap


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag466')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/registry.py: 9-25
</a>
<div class="mid" id="frag466" style="display:none"><pre>
def register_encoder(name: str, features: Union[str, List[str]], default=False):
    if isinstance(features, str):
        features = [features]

    def wrap(cls):
        for feature in features:
            feature_registry = encoder_registry.get(feature, {})
            feature_registry[name] = cls
            if default:
                for key in DEFAULT_KEYS:
                    feature_registry[key] = cls
            encoder_registry[feature] = feature_registry
        return cls

    return wrap


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 19:</b> &nbsp; 14 fragments, nominal size 67 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag474')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 41-117
</a>
<div class="mid" id="frag474" style="display:none"><pre>
    def __init__(
        self,
        max_sequence_length,
        use_pretrained: bool = True,
        pretrained_model_name_or_path: str = "albert-base-v2",
        trainable: bool = True,
        reduce_output: str = "cls_pooled",
        vocab_size: int = 30000,
        embedding_size: int = 128,
        hidden_size: int = 4096,
        num_hidden_layers: int = 12,
        num_hidden_groups: int = 1,
        num_attention_heads: int = 64,
        intermediate_size: int = 16384,
        inner_group_num: int = 1,
        hidden_act: str = "gelu_new",
        hidden_dropout_prob: float = 0,
        attention_probs_dropout_prob: float = 0,
        max_position_embeddings: int = 512,
        type_vocab_size: int = 2,
        initializer_range: float = 0.02,
        layer_norm_eps: float = 1e-12,
        classifier_dropout_prob: float = 0.1,
        position_embedding_type: str = "absolute",
        pad_token_id: int = 0,
        bos_token_id: int = 2,
        eos_token_id: int = 3,
        pretrained_kwargs: Dict = None,
        **kwargs
    ):
        super().__init__()
        try:
            from transformers import AlbertConfig, AlbertModel
        except ModuleNotFoundError:
            logger.error(
                " transformers is not installed. "
                "In order to install all text feature dependencies run "
                "pip install ludwig[text]"
            )
            sys.exit(-1)

        if use_pretrained:
            pretrained_kwargs = pretrained_kwargs or {}
            self.transformer = AlbertModel.from_pretrained(pretrained_model_name_or_path, **pretrained_kwargs)
        else:
            config = AlbertConfig(
                vocab_size=vocab_size,
                embedding_size=embedding_size,
                hidden_size=hidden_size,
                num_hidden_layers=num_hidden_layers,
                num_hidden_groups=num_hidden_groups,
                num_attention_heads=num_attention_heads,
                intermediate_size=intermediate_size,
                inner_group_num=inner_group_num,
                hidden_act=hidden_act,
                hidden_dropout_prob=hidden_dropout_prob,
                attention_probs_dropout_prob=attention_probs_dropout_prob,
                max_position_embeddings=max_position_embeddings,
                type_vocab_size=type_vocab_size,
                initializer_range=initializer_range,
                layer_norm_eps=layer_norm_eps,
                classifier_dropout_prob=classifier_dropout_prob,
                position_embedding_type=position_embedding_type,
                pad_token_id=pad_token_id,
                bos_token_id=bos_token_id,
                eos_token_id=eos_token_id,
            )
            self.transformer = AlbertModel(config)

        self.reduce_output = reduce_output
        if not self.reduce_output == "cls_pooled":
            self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        if trainable:
            self.transformer.train()
        self.transformer.resize_token_embeddings(vocab_size)
        self.max_sequence_length = max_sequence_length

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag534')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 1370-1438
</a>
<div class="mid" id="frag534" style="display:none"><pre>
    def __init__(
        self,
        max_sequence_length: int,
        use_pretrained: bool = True,
        pretrained_model_name_or_path: str = "ctrl",
        reduce_output: str = "cls-pooled",
        trainable: bool = True,
        vocab_size: int = 30522,
        hidden_size: int = 768,
        num_hidden_layers: int = 12,
        num_attention_heads: int = 12,
        intermediate_size: int = 3072,
        hidden_act: Union[str, Callable] = "gelu",
        hidden_dropout_prob: float = 0.1,
        attention_probs_dropout_prob: float = 0.1,
        max_position_embeddings: int = 512,
        type_vocab_size: int = 2,
        initializer_range: float = 0.02,
        layer_norm_eps: float = 1e-12,
        pad_token_id: int = 0,
        gradient_checkpointing: bool = False,
        position_embedding_type: str = "absolute",
        classifier_dropout: float = None,
        pretrained_kwargs: Dict = None,
        **kwargs
    ):
        super().__init__()
        try:
            from transformers import CamembertConfig, CamembertModel
        except ModuleNotFoundError:
            logger.error(
                " transformers is not installed. "
                "In order to install all text feature dependencies run "
                "pip install ludwig[text]"
            )
            sys.exit(-1)

        if use_pretrained:
            pretrained_kwargs = pretrained_kwargs or {}
            self.transformer = CamembertModel.from_pretrained(pretrained_model_name_or_path, **pretrained_kwargs)
        else:
            config = CamembertConfig(
                vocab_size=vocab_size,
                hidden_size=hidden_size,
                num_hidden_layers=num_hidden_layers,
                num_attention_heads=num_attention_heads,
                intermediate_size=intermediate_size,
                hidden_act=hidden_act,
                hidden_dropout_prob=hidden_dropout_prob,
                attention_probs_dropout_prob=attention_probs_dropout_prob,
                max_position_embeddings=max_position_embeddings,
                type_vocab_size=type_vocab_size,
                initializer_range=initializer_range,
                layer_norm_eps=layer_norm_eps,
                pad_token_id=pad_token_id,
                gradient_checkpointing=gradient_checkpointing,
                position_embedding_type=position_embedding_type,
                classifier_dropout=classifier_dropout,
            )
            self.transformer = CamembertModel(config)

        if trainable:
            self.transformer.train()
        self.reduce_output = reduce_output
        if not self.reduce_output == "cls_pooled":
            self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.transformer.resize_token_embeddings(vocab_size)
        self.max_sequence_length = max_sequence_length

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag479')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 166-240
</a>
<div class="mid" id="frag479" style="display:none"><pre>
    def __init__(
        self,
        max_sequence_length: int,
        use_pretrained: bool = True,
        pretrained_model_name_or_path: str = "google/mt5-base",
        trainable: bool = True,
        reduce_output: str = "cls_pooled",
        vocab_size: int = 250112,
        d_model: int = 512,
        d_kv: int = 64,
        d_ff: int = 1024,
        num_layers: int = 8,
        num_decoder_layers: int = None,
        num_heads: int = 6,
        relative_attention_num_buckets: int = 32,
        dropout_rate: float = 0.1,
        layer_norm_epsilon: float = 1e-06,
        initializer_factor: float = 1.0,
        feed_forward_proj: str = "gated-gelu",
        is_encoder_decoder: bool = True,
        use_cache: bool = True,
        tokenizer_class: str = "T5Tokenizer",
        tie_word_embeddings: bool = False,
        pad_token_id: int = 0,
        eos_token_id: int = 1,
        decoder_start_token_id: int = 0,
        pretrained_kwargs: Dict = None,
        **kwargs
    ):
        super().__init__()
        try:
            from transformers import MT5Config, MT5EncoderModel
        except ModuleNotFoundError:
            logger.error(
                " transformers is not installed. "
                "In order to install all text feature dependencies run "
                "pip install ludwig[text]"
            )
            sys.exit(-1)

        if use_pretrained:
            pretrained_kwargs = pretrained_kwargs or {}
            self.transformer = MT5EncoderModel.from_pretrained(pretrained_model_name_or_path, **pretrained_kwargs)
        else:
            config = MT5Config(
                vocab_size=vocab_size,
                d_model=d_model,
                d_kv=d_kv,
                d_ff=d_ff,
                num_layers=num_layers,
                num_decoder_layers=num_decoder_layers,
                num_heads=num_heads,
                relative_attention_num_buckets=relative_attention_num_buckets,
                dropout_rate=dropout_rate,
                layer_norm_epsilon=layer_norm_epsilon,
                initializer_factor=initializer_factor,
                feed_forward_proj=feed_forward_proj,
                is_encoder_decoder=is_encoder_decoder,
                use_cache=use_cache,
                tokenizer_class=tokenizer_class,
                tie_word_embeddings=tie_word_embeddings,
                pad_token_id=pad_token_id,
                eos_token_id=eos_token_id,
                decoder_start_token_id=decoder_start_token_id,
            )
            self.transformer = MT5EncoderModel(config)

        self.reduce_output = reduce_output
        if not self.reduce_output == "cls_pooled":
            self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        if trainable:
            self.transformer.train()
        self.transformer.resize_token_embeddings(vocab_size)
        self.max_sequence_length = max_sequence_length

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag489')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 383-451
</a>
<div class="mid" id="frag489" style="display:none"><pre>
    def __init__(
        self,
        max_sequence_length: int,
        use_pretrained: bool = True,
        pretrained_model_name_or_path: str = "bert-base-uncased",
        trainable: bool = True,
        reduce_output: str = "cls_pooled",
        vocab_size: int = 30522,
        hidden_size: int = 768,
        num_hidden_layers: int = 12,
        num_attention_heads: int = 12,
        intermediate_size: int = 3072,
        hidden_act: Union[str, Callable] = "gelu",
        hidden_dropout_prob: float = 0.1,
        attention_probs_dropout_prob: float = 0.1,
        max_position_embeddings: int = 512,
        type_vocab_size: int = 2,
        initializer_range: float = 0.02,
        layer_norm_eps: float = 1e-12,
        pad_token_id: int = 0,
        gradient_checkpointing: bool = False,
        position_embedding_type: str = "absolute",
        classifier_dropout: float = None,
        pretrained_kwargs: Dict = None,
        **kwargs
    ):
        super().__init__()
        try:
            from transformers import BertConfig, BertModel
        except ModuleNotFoundError:
            logger.error(
                " transformers is not installed. "
                "In order to install all text feature dependencies run "
                "pip install ludwig[text]"
            )
            sys.exit(-1)

        if use_pretrained:
            pretrained_kwargs = pretrained_kwargs or {}
            self.transformer = BertModel.from_pretrained(pretrained_model_name_or_path, **pretrained_kwargs)
        else:
            config = BertConfig(
                vocab_size=vocab_size,
                hidden_size=hidden_size,
                num_hidden_layers=num_hidden_layers,
                num_attention_heads=num_attention_heads,
                intermediate_size=intermediate_size,
                hidden_act=hidden_act,
                hidden_dropout_prob=hidden_dropout_prob,
                attention_probs_dropout_prob=attention_probs_dropout_prob,
                max_position_embeddings=max_position_embeddings,
                type_vocab_size=type_vocab_size,
                initializer_range=initializer_range,
                layer_norm_eps=layer_norm_eps,
                pad_token_id=pad_token_id,
                gradient_checkpointing=gradient_checkpointing,
                position_embedding_type=position_embedding_type,
                classifier_dropout=classifier_dropout,
            )
            self.transformer = BertModel(config)

        self.reduce_output = reduce_output
        if not self.reduce_output == "cls_pooled":
            self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        if trainable:
            self.transformer.train()
        self.transformer.resize_token_embeddings(vocab_size)
        self.max_sequence_length = max_sequence_length

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag549')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 1723-1788
</a>
<div class="mid" id="frag549" style="display:none"><pre>
    def __init__(
        self,
        max_sequence_length: int,
        use_pretrained: bool = True,
        pretrained_model_name_or_path: str = "google/electra-small-discriminator",
        reduce_output: str = "sum",
        trainable: bool = True,
        vocab_size: int = 30522,
        embedding_size: int = 128,
        hidden_size: int = 256,
        num_hidden_layers: int = 12,
        num_attention_heads: int = 4,
        intermediate_size: int = 1024,
        hidden_act: Union[str, Callable] = "gelu",
        hidden_dropout_prob: float = 0.1,
        attention_probs_dropout_prob: float = 0.1,
        max_position_embeddings: int = 512,
        type_vocab_size: int = 2,
        initializer_range: float = 0.02,
        layer_norm_eps: float = 1e-12,
        position_embedding_type: str = "absolute",
        classifier_dropout: Optional[float] = None,
        pretrained_kwargs: Dict = None,
        **kwargs
    ):
        super().__init__()
        try:
            from transformers import ElectraConfig, ElectraModel
        except ModuleNotFoundError:
            logger.error(
                " transformers is not installed. "
                "In order to install all text feature dependencies run "
                "pip install ludwig[text]"
            )
            sys.exit(-1)

        if use_pretrained:
            pretrained_kwargs = pretrained_kwargs or {}
            self.transformer = ElectraModel.from_pretrained(pretrained_model_name_or_path, **pretrained_kwargs)
        else:
            config = ElectraConfig(
                vocab_size=vocab_size,
                embedding_size=embedding_size,
                hidden_size=hidden_size,
                num_hidden_layers=num_hidden_layers,
                num_attention_heads=num_attention_heads,
                intermediate_size=intermediate_size,
                hidden_act=hidden_act,
                hidden_dropout_prob=hidden_dropout_prob,
                attention_probs_dropout_prob=attention_probs_dropout_prob,
                max_position_embeddings=max_position_embeddings,
                type_vocab_size=type_vocab_size,
                initializer_range=initializer_range,
                layer_norm_eps=layer_norm_eps,
                position_embedding_type=position_embedding_type,
                classifier_dropout=classifier_dropout,
            )
            self.transformer = ElectraModel(config)

        self.max_sequence_length = max_sequence_length
        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        if trainable:
            self.transformer.train()
        self.transformer.resize_token_embeddings(vocab_size)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag494')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 501-592
</a>
<div class="mid" id="frag494" style="display:none"><pre>
    def __init__(
        self,
        max_sequence_length: int,
        use_pretrained: bool = True,
        pretrained_model_name_or_path: str = "xlm-mlm-en-2048",
        trainable: bool = True,
        reduce_output: str = "cls_pooled",
        vocab_size: int = 30145,
        emb_dim: int = 2048,
        n_layers: int = 12,
        n_heads: int = 16,
        dropout: float = 0.1,
        attention_dropout: float = 0.1,
        gelu_activation: bool = True,
        sinusoidal_embeddings: bool = False,
        causal: bool = False,
        asm: bool = False,
        n_langs: int = 1,
        use_lang_emb: bool = True,
        max_position_embeddings: int = 512,
        embed_init_std: float = 2048**-0.5,
        layer_norm_eps: float = 1e-12,
        init_std: float = 0.02,
        bos_index: int = 0,
        eos_index: int = 1,
        pad_index: int = 2,
        unk_index: int = 3,
        mask_index: int = 5,
        is_encoder: bool = True,
        start_n_top: int = 5,
        end_n_top: int = 5,
        mask_token_id: int = 0,
        lang_id: int = 0,
        pad_token_id: int = 2,
        bos_token_id: int = 0,
        pretrained_kwargs: Dict = None,
        **kwargs
    ):
        super().__init__()
        try:
            from transformers import XLMConfig, XLMModel
        except ModuleNotFoundError:
            logger.error(
                " transformers is not installed. "
                "In order to install all text feature dependencies run "
                "pip install ludwig[text]"
            )
            sys.exit(-1)

        if use_pretrained:
            pretrained_kwargs = pretrained_kwargs or {}
            self.transformer = XLMModel.from_pretrained(pretrained_model_name_or_path, **pretrained_kwargs)
            if trainable:
                self.transformer.train()
        else:
            config = XLMConfig(
                vocab_size=vocab_size,
                emb_dim=emb_dim,
                n_layers=n_layers,
                n_heads=n_heads,
                dropout=dropout,
                attention_dropout=attention_dropout,
                gelu_activation=gelu_activation,
                sinusoidal_embeddings=sinusoidal_embeddings,
                causal=causal,
                asm=asm,
                n_langs=n_langs,
                use_lang_emb=use_lang_emb,
                max_position_embeddings=max_position_embeddings,
                embed_init_std=embed_init_std,
                layer_norm_eps=layer_norm_eps,
                init_std=init_std,
                bos_index=bos_index,
                eos_index=eos_index,
                pad_index=pad_index,
                unk_index=unk_index,
                mask_index=mask_index,
                is_encoder=is_encoder,
                start_n_top=start_n_top,
                end_n_top=end_n_top,
                mask_token_id=mask_token_id,
                lang_id=lang_id,
                pad_token_id=pad_token_id,
                bos_token_id=bos_token_id,
            )
            self.transformer = XLMModel(config)

        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.transformer.resize_token_embeddings(vocab_size)
        self.max_sequence_length = max_sequence_length

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag499')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 639-698
</a>
<div class="mid" id="frag499" style="display:none"><pre>
    def __init__(
        self,
        max_sequence_length: int,
        reduce_output: str = "sum",
        use_pretrained: bool = True,
        pretrained_model_name_or_path: str = "openai-gpt",
        trainable: bool = True,
        vocab_size: int = 30522,
        n_positions: int = 40478,
        n_ctx: int = 512,
        n_embd: int = 768,
        n_layer: int = 12,
        n_head: int = 12,
        afn: str = "gelu",
        resid_pdrop: float = 0.1,
        embd_pdrop: float = 0.1,
        attn_pdrop: float = 0.1,
        layer_norm_epsilon: float = 1e-5,
        initializer_range: float = 0.02,
        pretrained_kwargs: Dict = None,
        **kwargs
    ):
        super().__init__()
        try:
            from transformers import OpenAIGPTConfig, OpenAIGPTModel
        except ModuleNotFoundError:
            logger.error(
                " transformers is not installed. "
                "In order to install all text feature dependencies run "
                "pip install ludwig[text]"
            )
            sys.exit(-1)

        if use_pretrained:
            pretrained_kwargs = pretrained_kwargs or {}
            self.transformer = OpenAIGPTModel.from_pretrained(pretrained_model_name_or_path, **pretrained_kwargs)
        else:
            config = OpenAIGPTConfig(
                vocab_size=vocab_size,
                n_positions=n_positions,
                n_ctx=n_ctx,
                n_embd=n_embd,
                n_layer=n_layer,
                n_head=n_head,
                afn=afn,
                resid_pdrop=resid_pdrop,
                embd_pdrop=embd_pdrop,
                attn_pdrop=attn_pdrop,
                layer_norm_epsilon=layer_norm_epsilon,
                initializer_range=initializer_range,
            )
            self.transformer = OpenAIGPTModel(config)

        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        if trainable:
            self.transformer.train()
        self.transformer.resize_token_embeddings(vocab_size)
        self.max_sequence_length = max_sequence_length

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag514')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 923-1008
</a>
<div class="mid" id="frag514" style="display:none"><pre>
    def __init__(
        self,
        max_sequence_length: int,
        use_pretrained: bool = True,
        pretrained_model_name_or_path: str = "transfo-xl-wt103",
        reduce_output: str = "sum",
        trainable: bool = True,
        vocab_size: int = 267735,
        cutoffs: List[int] = [20000, 40000, 200000],
        d_model: int = 1024,
        d_embed: int = 1024,
        n_head: int = 16,
        d_head: int = 64,
        d_inner: int = 4096,
        div_val: int = 4,
        pre_lnorm: bool = False,
        n_layer: int = 18,
        mem_len: int = 1600,
        clamp_len: int = 1000,
        same_length: bool = True,
        proj_share_all_but_first: bool = True,
        attn_type: int = 0,
        sample_softmax: int = -1,
        adaptive: bool = True,
        dropout: float = 0.1,
        dropatt: float = 0.0,
        untie_r: bool = True,
        init: str = "normal",
        init_range: float = 0.01,
        proj_init_std: float = 0.01,
        init_std: float = 0.02,
        layer_norm_epsilon: float = 1e-5,
        eos_token_id: int = 0,
        pretrained_kwargs: Dict = None,
        **kwargs
    ):
        super().__init__()
        try:
            from transformers import TransfoXLConfig, TransfoXLModel
        except ModuleNotFoundError:
            logger.error(
                " transformers is not installed. "
                "In order to install all text feature dependencies run "
                "pip install ludwig[text]"
            )
            sys.exit(-1)

        if use_pretrained:
            pretrained_kwargs = pretrained_kwargs or {}
            self.transformer = TransfoXLModel.from_pretrained(pretrained_model_name_or_path, **pretrained_kwargs)
        else:
            config = TransfoXLConfig(
                vocab_size=vocab_size,
                cutoffs=cutoffs,
                d_model=d_model,
                d_embed=d_embed,
                n_head=n_head,
                d_head=d_head,
                d_inner=d_inner,
                div_val=div_val,
                pre_lnorm=pre_lnorm,
                n_layer=n_layer,
                mem_len=mem_len,
                clamp_len=clamp_len,
                same_length=same_length,
                proj_share_all_but_first=proj_share_all_but_first,
                attn_type=attn_type,
                sample_softmax=sample_softmax,
                adaptive=adaptive,
                dropout=dropout,
                dropatt=dropatt,
                untie_r=untie_r,
                init=init,
                init_range=init_range,
                proj_init_std=proj_init_std,
                init_std=init_std,
                layer_norm_epsilon=layer_norm_epsilon,
                eos_token_id=eos_token_id,
            )
            self.transformer = TransfoXLModel(config)
        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        if trainable:
            self.transformer.train()
        self.max_sequence_length = max_sequence_length

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag519')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 1043-1131
</a>
<div class="mid" id="frag519" style="display:none"><pre>
    def __init__(
        self,
        max_sequence_length: int,
        use_pretrained: bool = True,
        pretrained_model_name_or_path: str = "xlnet-base-cased",
        reduce_output: str = "sum",
        trainable: bool = True,
        vocab_size: int = 32000,
        d_model: int = 1024,
        n_layer: int = 24,
        n_head: int = 16,
        d_inner: int = 4096,
        ff_activation: str = "gelu",
        untie_r: bool = True,
        attn_type: str = "bi",
        initializer_range: float = 0.02,
        layer_norm_eps: float = 1e-12,
        dropout: float = 0.1,
        mem_len: Optional[int] = 512,
        reuse_len: Optional[int] = None,
        use_mems_eval: bool = True,
        use_mems_train: bool = False,
        bi_data: bool = False,
        clamp_len: int = -1,
        same_length: bool = False,
        summary_type: str = "last",
        summary_use_proj: bool = True,
        summary_activation: str = "tanh",
        summary_last_dropout: float = 0.1,
        start_n_top: int = 5,
        end_n_top: int = 5,
        pad_token_id: int = 5,
        bos_token_id: int = 1,
        eos_token_id: int = 2,
        pretrained_kwargs: Dict = None,
        **kwargs
    ):
        super().__init__()
        try:
            from transformers import XLNetConfig, XLNetModel
        except ModuleNotFoundError:
            logger.error(
                " transformers is not installed. "
                "In order to install all text feature dependencies run "
                "pip install ludwig[text]"
            )
            sys.exit(-1)

        if use_pretrained:
            pretrained_kwargs = pretrained_kwargs or {}
            self.transformer = XLNetModel.from_pretrained(pretrained_model_name_or_path, **pretrained_kwargs)
        else:
            config = XLNetConfig(
                vocab_size=vocab_size,
                d_model=d_model,
                n_layer=n_layer,
                n_head=n_head,
                d_inner=d_inner,
                ff_activation=ff_activation,
                untie_r=untie_r,
                attn_type=attn_type,
                initializer_range=initializer_range,
                layer_norm_eps=layer_norm_eps,
                dropout=dropout,
                mem_len=mem_len,
                reuse_len=reuse_len,
                use_mems_eval=use_mems_eval,
                use_mems_train=use_mems_train,
                bi_data=bi_data,
                clamp_len=clamp_len,
                same_length=same_length,
                summary_type=summary_type,
                summary_use_proj=summary_use_proj,
                summary_activation=summary_activation,
                summary_last_dropout=summary_last_dropout,
                start_n_top=start_n_top,
                end_n_top=end_n_top,
                pad_token_id=pad_token_id,
                bos_token_id=bos_token_id,
                eos_token_id=eos_token_id,
            )
            self.transformer = XLNetModel(config)
        self.max_sequence_length = max_sequence_length
        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        if trainable:
            self.transformer.train()
        self.transformer.resize_token_embeddings(vocab_size)

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag544')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 1591-1678
</a>
<div class="mid" id="frag544" style="display:none"><pre>
    def __init__(
        self,
        max_sequence_length: int,
        use_pretrained: bool,
        pretrained_model_name_or_path: str = "flaubert/flaubert_small_cased",
        reduce_output: str = "sum",
        trainable: bool = True,
        vocab_size: int = 30145,
        pre_norm: bool = False,
        layerdrop: float = 0.0,
        emb_dim: int = 2048,
        n_layer: int = 12,
        n_head: int = 16,
        dropout: float = 0.1,
        attention_dropout: float = 0.1,
        gelu_activation: bool = True,
        sinusoidal_embeddings: bool = False,
        causal: bool = False,
        asm: bool = False,
        n_langs: int = 1,
        use_lang_emb: bool = True,
        max_position_embeddings: int = 512,
        embed_init_std: float = 2048**-0.5,
        init_std: int = 50257,
        layer_norm_eps: float = 1e-12,
        bos_index: int = 0,
        eos_index: int = 1,
        pad_index: int = 2,
        unk_index: int = 3,
        mask_index: int = 5,
        is_encoder: bool = True,
        mask_token_id: int = 0,
        lang_id: int = 1,
        pretrained_kwargs: Dict = None,
        **kwargs
    ):
        super().__init__()
        try:
            from transformers import FlaubertConfig, FlaubertModel
        except ModuleNotFoundError:
            logger.error(
                " transformers is not installed. "
                "In order to install all text feature dependencies run "
                "pip install ludwig[text]"
            )
            sys.exit(-1)

        if use_pretrained:
            pretrained_kwargs = pretrained_kwargs or {}
            self.transformer = FlaubertModel.from_pretrained(pretrained_model_name_or_path, **pretrained_kwargs)
        else:
            config = FlaubertConfig(
                vocab_size=vocab_size,
                pre_norm=pre_norm,
                layerdrop=layerdrop,
                emb_dim=emb_dim,
                n_layer=n_layer,
                n_head=n_head,
                dropout=dropout,
                attention_dropout=dropout,
                gelu_activation=gelu_activation,
                sinusoidal_embeddings=sinusoidal_embeddings,
                causal=causal,
                asm=asm,
                n_langs=n_langs,
                use_lang_emb=use_lang_emb,
                max_position_embeddings=max_position_embeddings,
                embed_init_std=embed_init_std,
                init_std=init_std,
                layer_norm_eps=layer_norm_eps,
                bos_index=bos_index,
                eos_index=eos_index,
                pad_index=pad_index,
                unk_index=unk_index,
                mask_index=mask_index,
                is_encoder=is_encoder,
                mask_token_id=mask_token_id,
                lang_id=lang_id,
            )
            self.transformer = FlaubertModel(config)

        self.max_sequence_length = max_sequence_length
        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        if trainable:
            self.transformer.train()
        self.transformer.resize_token_embeddings(vocab_size)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag529')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 1271-1331
</a>
<div class="mid" id="frag529" style="display:none"><pre>
    def __init__(
        self,
        max_sequence_length: int,
        use_pretrained: bool = True,
        pretrained_model_name_or_path: str = "ctrl",
        reduce_output: str = "sum",
        trainable: bool = True,
        vocab_size: int = 246534,
        n_positions: int = 256,
        n_ctx: int = 256,
        n_embd: int = 1280,
        dff: int = 8192,
        n_layer: int = 48,
        n_head: int = 16,
        resid_pdrop: float = 0.1,
        embd_pdrop: float = 0.1,
        attn_pdrop: float = 0.1,
        layer_norm_epsilon: float = 1e-6,
        initializer_range: float = 0.02,
        pretrained_kwargs: Dict = None,
        **kwargs
    ):
        super().__init__()
        try:
            from transformers import CTRLConfig, CTRLModel
        except ModuleNotFoundError:
            logger.error(
                " transformers is not installed. "
                "In order to install all text feature dependencies run "
                "pip install ludwig[text]"
            )
            sys.exit(-1)

        if use_pretrained:
            pretrained_kwargs = pretrained_kwargs or {}
            self.transformer = CTRLModel.from_pretrained(pretrained_model_name_or_path, **pretrained_kwargs)
        else:
            config = CTRLConfig(
                vocab_size=vocab_size,
                n_positions=n_positions,
                n_ctx=n_ctx,
                n_embd=n_embd,
                dff=dff,
                n_layer=n_layer,
                n_head=n_head,
                resid_pdrop=resid_pdrop,
                embd_pdrop=embd_pdrop,
                attn_pdrop=attn_pdrop,
                layer_norm_epsilon=layer_norm_epsilon,
                initializer_range=initializer_range,
            )
            self.transformer = CTRLModel(config)

        self.vocab_size = vocab_size
        self.max_sequence_length = max_sequence_length
        if trainable:
            self.transformer.train()
        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.transformer.resize_token_embeddings(self.vocab_size)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag524')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 1171-1232
</a>
<div class="mid" id="frag524" style="display:none"><pre>
    def __init__(
        self,
        max_sequence_length: int,
        pretrained_model_name_or_path: str = "distilbert-base-uncased",
        reduce_output: str = "sum",
        trainable: bool = True,
        use_pretrained: bool = True,
        vocab_size: int = 30522,
        max_position_embeddings: int = 512,
        sinusoidal_pos_embds: bool = False,
        n_layers: int = 6,
        n_heads: int = 12,
        dim: int = 768,
        hidden_dim: int = 3072,
        dropout: float = 0.1,
        attention_dropout: float = 0.1,
        activation: Union[str, Callable] = "gelu",
        initializer_range: float = 0.02,
        qa_dropout: float = 0.1,
        seq_classif_dropout: float = 0.2,
        pretrained_kwargs: Dict = None,
        **kwargs
    ):
        super().__init__()
        try:
            from transformers import DistilBertConfig, DistilBertModel
        except ModuleNotFoundError:
            logger.error(
                " transformers is not installed. "
                "In order to install all text feature dependencies run "
                "pip install ludwig[text]"
            )
            sys.exit(-1)

        if use_pretrained:
            pretrained_kwargs = pretrained_kwargs or {}
            self.transformer = DistilBertModel.from_pretrained(pretrained_model_name_or_path, **pretrained_kwargs)
        else:
            config = DistilBertConfig(
                vocab_size=vocab_size,
                max_position_embeddings=max_position_embeddings,
                sinusoidal_pos_embds=sinusoidal_pos_embds,
                n_layers=n_layers,
                n_heads=n_heads,
                dim=dim,
                hidden_dim=hidden_dim,
                dropout=dropout,
                attention_dropout=attention_dropout,
                activation=activation,
                initializer_range=initializer_range,
                qa_dropout=qa_dropout,
                seq_classif_dropout=seq_classif_dropout,
            )
            self.transformer = DistilBertModel(config)

        if trainable:
            self.transformer.train()
        self.reduce_output = reduce_output
        self.max_sequence_length = max_sequence_length
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.transformer.resize_token_embeddings(vocab_size)

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag539')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 1487-1546
</a>
<div class="mid" id="frag539" style="display:none"><pre>
    def __init__(
        self,
        max_sequence_length: int,
        use_pretrained: bool = True,
        pretrained_model_name_or_path: str = "t5-small",
        reduce_output: str = "sum",
        trainable: bool = True,
        vocab_size: int = 32128,
        d_model: int = 512,
        d_kv: int = 64,
        d_ff: int = 2048,
        num_layers: int = 6,
        num_decoder_layers: Optional[int] = None,
        num_heads: int = 8,
        relative_attention_num_buckets: int = 32,
        dropout_rate: float = 0.1,
        layer_norm_eps: float = 1e-6,
        initializer_factor: float = 1,
        feed_forward_proj: str = "relu",
        pretrained_kwargs: Dict = None,
        **kwargs
    ):
        super().__init__()
        try:
            from transformers import T5Config, T5Model
        except ModuleNotFoundError:
            logger.error(
                " transformers is not installed. "
                "In order to install all text feature dependencies run "
                "pip install ludwig[text]"
            )
            sys.exit(-1)

        if use_pretrained:
            pretrained_kwargs = pretrained_kwargs or {}
            self.transformer = T5Model.from_pretrained(pretrained_model_name_or_path, **pretrained_kwargs)
        else:
            config = T5Config(
                vocab_size=vocab_size,
                d_model=d_model,
                d_kv=d_kv,
                d_ff=d_ff,
                num_layers=num_layers,
                num_decoder_layers=num_decoder_layers,
                num_heads=num_heads,
                relative_attention_num_buckets=relative_attention_num_buckets,
                dropout_rate=dropout_rate,
                layer_norm_eps=layer_norm_eps,
                initializer_factor=initializer_factor,
                feed_forward_proj=feed_forward_proj,
            )
            self.transformer = T5Model(config)

        self.max_sequence_length = max_sequence_length
        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        if trainable:
            self.transformer.train()
        self.transformer.resize_token_embeddings(vocab_size)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag504')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 737-800
</a>
<div class="mid" id="frag504" style="display:none"><pre>
    def __init__(
        self,
        max_sequence_length: int,
        use_pretrained: bool = True,
        pretrained_model_name_or_path: str = "gpt2",
        reduce_output: str = "sum",
        trainable: bool = True,
        vocab_size: int = 50257,
        n_positions: int = 1024,
        n_ctx: int = 1024,
        n_embd: int = 768,
        n_layer: int = 12,
        n_head: int = 12,
        n_inner: Optional[int] = None,
        activation_function: str = "gelu",
        resid_pdrop: float = 0.1,
        embd_pdrop: float = 0.1,
        attn_pdrop: float = 0.1,
        layer_norm_epsilon: float = 1e-5,
        initializer_range: float = 0.02,
        scale_attn_weights: bool = True,
        pretrained_kwargs: Dict = None,
        **kwargs
    ):
        super().__init__()
        try:
            from transformers import GPT2Config, GPT2Model
        except ModuleNotFoundError:
            logger.error(
                " transformers is not installed. "
                "In order to install all text feature dependencies run "
                "pip install ludwig[text]"
            )
            sys.exit(-1)

        if use_pretrained:
            pretrained_kwargs = pretrained_kwargs or {}
            self.transformer = GPT2Model.from_pretrained(pretrained_model_name_or_path, **pretrained_kwargs)
        else:
            config = GPT2Config(
                vocab_size=vocab_size,
                n_positions=n_positions,
                n_ctx=n_ctx,
                n_embd=n_embd,
                n_layer=n_layer,
                n_head=n_head,
                n_inner=n_inner,
                activation_function=activation_function,
                resid_pdrop=resid_pdrop,
                embd_pdrop=embd_pdrop,
                attn_pdrop=attn_pdrop,
                layer_norm_epsilon=layer_norm_epsilon,
                initializer_range=initializer_range,
                scale_attn_weights=scale_attn_weights,
            )
            self.transformer = GPT2Model(config)

        if trainable:
            self.transformer.train()
        self.max_sequence_length = max_sequence_length
        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.transformer.resize_token_embeddings(vocab_size)

</pre></div>
</td>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 20:</b> &nbsp; 17 fragments, nominal size 13 lines, similarity 71%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag475')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 118-133
</a>
<div class="mid" id="frag475" style="display:none"><pre>
    def forward(self, inputs: torch.Tensor, mask: Optional[torch.Tensor] = None) -&gt; Dict[str, torch.Tensor]:
        if mask is not None:
            mask = mask.to(torch.int32)
        transformer_outputs = self.transformer(
            input_ids=inputs,
            attention_mask=mask,
            token_type_ids=torch.zeros_like(inputs),
        )
        if self.reduce_output == "cls_pooled":
            hidden = transformer_outputs[1]
        else:
            hidden = transformer_outputs[0][:, 1:-1, :]
            hidden = self.reduce_sequence(hidden, self.reduce_output)

        return {"encoder_output": hidden}

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag535')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 1439-1454
</a>
<div class="mid" id="frag535" style="display:none"><pre>
    def forward(self, inputs: torch.Tensor, mask: Optional[torch.Tensor] = None) -&gt; Dict[str, torch.Tensor]:
        if mask is not None:
            mask = mask.to(torch.int32)
        transformer_outputs = self.transformer(
            input_ids=inputs,
            attention_mask=mask,
            token_type_ids=torch.zeros_like(inputs),
        )
        if self.reduce_output == "cls_pooled":
            hidden = transformer_outputs[1]
        else:
            hidden = transformer_outputs[0][:, 1:-1, :]
            hidden = self.reduce_sequence(hidden, self.reduce_output)

        return {"encoder_output": hidden}

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag510')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 882-896
</a>
<div class="mid" id="frag510" style="display:none"><pre>
    def forward(self, inputs: torch.Tensor, mask: Optional[torch.Tensor] = None) -&gt; Dict[str, torch.Tensor]:
        if mask is not None:
            mask = mask.to(torch.int32)
        transformer_outputs = self.transformer(
            input_ids=inputs,
            attention_mask=mask,
            token_type_ids=torch.zeros_like(inputs),
        )
        if self.reduce_output == "cls_pooled":
            hidden = transformer_outputs[1]
        else:
            hidden = transformer_outputs[0][:, 1:-1, :]  # bos + [sent] + sep
            hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {"encoder_output": hidden}

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag490')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 452-467
</a>
<div class="mid" id="frag490" style="display:none"><pre>
    def forward(self, inputs: torch.Tensor, mask: Optional[torch.Tensor] = None) -&gt; Dict[str, torch.Tensor]:
        if mask is not None:
            mask = mask.to(torch.int32)
        transformer_outputs = self.transformer(
            input_ids=inputs,
            attention_mask=mask,
            token_type_ids=torch.zeros_like(inputs),
        )
        if self.reduce_output == "cls_pooled":
            hidden = transformer_outputs[1]
        else:
            hidden = transformer_outputs[0][:, 1:-1, :]
            hidden = self.reduce_sequence(hidden, self.reduce_output)

        return {"encoder_output": hidden}

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag560')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 1946-1963
</a>
<div class="mid" id="frag560" style="display:none"><pre>
    def forward(self, inputs: torch.Tensor, mask: Optional[torch.Tensor] = None):
        if mask is not None:
            mask = mask.to(torch.int32)
        transformer_outputs = self.transformer(
            input_ids=inputs,
            attention_mask=mask,
            token_type_ids=torch.zeros_like(inputs),
        )
        if self.reduce_output == "cls_pooled":
            # this works only if the user know that the specific model
            # they want to use has the same outputs of
            # the BERT base class call() function
            hidden = transformer_outputs["pooler_output"]
        else:
            hidden = transformer_outputs["last_hidden_state"]
            hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {"encoder_output": hidden}

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag520')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 1132-1143
</a>
<div class="mid" id="frag520" style="display:none"><pre>
    def forward(self, inputs: torch.Tensor, mask: torch.Tensor = None) -&gt; Dict[str, torch.Tensor]:
        if mask is not None:
            mask = mask.to(torch.int32)
        transformer_outputs = self.transformer(
            input_ids=inputs,
            attention_mask=mask,
            token_type_ids=torch.zeros_like(inputs),
        )
        hidden = transformer_outputs[0]
        hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {"encoder_output": hidden}

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag555')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 1871-1885
</a>
<div class="mid" id="frag555" style="display:none"><pre>
    def forward(self, inputs: torch.Tensor, mask: Optional[torch.Tensor] = None):
        if mask is not None:
            mask = mask.to(torch.int32)
        transformer_outputs = self.transformer(
            input_ids=inputs,
            attention_mask=mask,
            token_type_ids=torch.zeros_like(inputs),
        )
        if self.reduce_output == "cls_pooled":
            hidden = transformer_outputs[1]
        else:
            hidden = transformer_outputs[0][:, 1:-1, :]  # bos + [sent] + sep
            hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {"encoder_output": hidden}

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag525')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 1233-1243
</a>
<div class="mid" id="frag525" style="display:none"><pre>
    def forward(self, inputs: torch.Tensor, mask: Optional[torch.Tensor] = None) -&gt; Dict[str, torch.Tensor]:
        if mask is not None:
            mask = mask.to(torch.int32)
        transformer_outputs = self.transformer(
            input_ids=inputs,
            attention_mask=mask,
        )
        hidden = transformer_outputs[0][:, 1:-1, :]
        hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {"encoder_output": hidden}

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag530')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 1332-1343
</a>
<div class="mid" id="frag530" style="display:none"><pre>
    def forward(self, inputs: torch.Tensor, mask: Optional[torch.Tensor] = None) -&gt; Dict[str, torch.Tensor]:
        if mask is not None:
            mask = mask.to(torch.int32)
        transformer_outputs = self.transformer(
            input_ids=inputs,
            attention_mask=mask,
            token_type_ids=torch.zeros_like(inputs),
        )
        hidden = transformer_outputs[0]
        hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {"encoder_output": hidden}

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag540')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 1547-1558
</a>
<div class="mid" id="frag540" style="display:none"><pre>
    def forward(self, inputs: torch.Tensor, mask: Optional[torch.Tensor] = None) -&gt; Dict[str, torch.Tensor]:
        if mask is not None:
            mask = mask.to(torch.int32)
        transformer_outputs = self.transformer(
            inputs,
            decoder_input_ids=inputs,
            attention_mask=mask,
        )
        hidden = transformer_outputs[0][:, 0:-1, :]  # [eos token]
        hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {"encoder_output": hidden}

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag545')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 1679-1690
</a>
<div class="mid" id="frag545" style="display:none"><pre>
    def forward(self, inputs: torch.Tensor, mask: Optional[torch.Tensor] = None) -&gt; Dict[str, torch.Tensor]:
        if mask is not None:
            mask = mask.to(torch.int32)
        transformer_outputs = self.transformer(
            input_ids=inputs,
            attention_mask=mask,
            token_type_ids=torch.zeros_like(inputs),
        )
        hidden = transformer_outputs[0][:, 1:-1, :]
        hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {"encoder_output": hidden}

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag550')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 1789-1800
</a>
<div class="mid" id="frag550" style="display:none"><pre>
    def forward(self, inputs: torch.Tensor, mask: Optional[torch.Tensor] = None) -&gt; Dict[str, torch.Tensor]:
        if mask is not None:
            mask = mask.to(torch.int32)
        transformer_outputs = self.transformer(
            input_ids=inputs,
            attention_mask=mask,
            token_type_ids=torch.zeros_like(inputs),
        )
        hidden = transformer_outputs[0][:, 1:-1, :]
        hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {"encoder_output": hidden}

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag485')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 334-349
</a>
<div class="mid" id="frag485" style="display:none"><pre>
    def forward(self, inputs: torch.Tensor, mask: Optional[torch.Tensor] = None) -&gt; Dict[str, torch.Tensor]:
        if mask is not None:
            mask = mask.to(torch.int32)
        transformer_outputs = self.transformer(
            input_ids=inputs,
            attention_mask=mask,
            token_type_ids=torch.zeros_like(inputs),
        )
        if self.reduce_output == "cls_pooled":
            hidden = transformer_outputs[1]
        else:
            hidden = transformer_outputs[0][:, 1:-1, :]
            hidden = self.reduce_sequence(hidden, self.reduce_output)

        return {"encoder_output": hidden}

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag500')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 699-710
</a>
<div class="mid" id="frag500" style="display:none"><pre>
    def forward(self, inputs: torch.Tensor, mask: Optional[torch.Tensor] = None) -&gt; Dict[str, torch.Tensor]:
        if mask is not None:
            mask = mask.to(torch.int32)
        transformer_outputs = self.transformer(
            input_ids=inputs,
            attention_mask=mask,
            token_type_ids=torch.zeros_like(inputs),
        )
        hidden = transformer_outputs[0]
        hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {"encoder_output": hidden}

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag480')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 241-255
</a>
<div class="mid" id="frag480" style="display:none"><pre>
    def forward(self, inputs: torch.Tensor, mask: Optional[torch.Tensor] = None) -&gt; Dict[str, torch.Tensor]:
        if mask is not None:
            mask = mask.to(torch.int32)
        transformer_outputs = self.transformer(
            input_ids=inputs,
            attention_mask=mask,
        )
        if self.reduce_output == "cls_pooled":
            hidden = transformer_outputs[1]
        else:
            hidden = transformer_outputs[0][:, 1:-1, :]
            hidden = self.reduce_sequence(hidden, self.reduce_output)

        return {"encoder_output": hidden}

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag505')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 801-812
</a>
<div class="mid" id="frag505" style="display:none"><pre>
    def forward(self, inputs: torch.Tensor, mask: Optional[torch.Tensor] = None) -&gt; Dict[str, torch.Tensor]:
        if mask is not None:
            mask = mask.to(torch.int32)
        transformer_outputs = self.transformer(
            input_ids=inputs,
            attention_mask=mask,
            token_type_ids=torch.zeros_like(inputs),
        )
        hidden = transformer_outputs[0]
        hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {"encoder_output": hidden}

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag495')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 593-605
</a>
<div class="mid" id="frag495" style="display:none"><pre>
    def forward(self, inputs: torch.Tensor, mask: Optional[torch.Tensor] = None) -&gt; Dict[str, torch.Tensor]:

        if mask is not None:
            mask = mask.to(torch.int32)
        transformer_outputs = self.transformer(
            input_ids=inputs,
            attention_mask=mask,
            token_type_ids=torch.zeros_like(inputs),
        )
        hidden = transformer_outputs[0]
        hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {"encoder_output": hidden}

</pre></div>
</td>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 21:</b> &nbsp; 2 fragments, nominal size 39 lines, similarity 84%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag484')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 288-333
</a>
<div class="mid" id="frag484" style="display:none"><pre>
    def __init__(
        self,
        max_sequence_length: int,
        use_pretrained: bool = True,
        pretrained_model_name_or_path: str = "xlm-roberta-base",
        reduce_output: str = "cls_pooled",
        trainable: bool = True,
        vocab_size: int = None,
        pad_token_id: int = 1,
        bos_token_id: int = 0,
        eos_token_id: int = 2,
        add_pooling_layer: bool = True,
        pretrained_kwargs: Dict = None,
        **kwargs
    ):
        super().__init__()
        try:
            from transformers import XLMRobertaConfig, XLMRobertaModel
        except ModuleNotFoundError:
            logger.error(
                " transformers is not installed. "
                "In order to install all text feature dependencies run "
                "pip install ludwig[text]"
            )
            sys.exit(-1)

        if use_pretrained:
            pretrained_kwargs = pretrained_kwargs or {}
            self.transformer = XLMRobertaModel.from_pretrained(pretrained_model_name_or_path, **pretrained_kwargs)
        else:
            config = XLMRobertaConfig(
                pad_token_id=pad_token_id,
                bos_token_id=bos_token_id,
                eos_token_id=eos_token_id,
            )

            self.transformer = XLMRobertaModel(config, add_pooling_layer)

        self.reduce_output = reduce_output
        if not self.reduce_output == "cls_pooled":
            self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        if trainable:
            self.transformer.train()
        self.transformer.resize_token_embeddings(vocab_size)
        self.max_sequence_length = max_sequence_length

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag509')" href="javascript:;">
ludwig-0.5rc2/ludwig/encoders/text_encoders.py: 839-881
</a>
<div class="mid" id="frag509" style="display:none"><pre>
    def __init__(
        self,
        max_sequence_length,
        use_pretrained: bool = True,
        pretrained_model_name_or_path: str = "roberta-base",
        reduce_output: str = "cls_pooled",
        trainable: bool = True,
        vocab_size: int = None,
        pad_token_id: int = 1,
        bos_token_id: int = 0,
        eos_token_id: int = 2,
        pretrained_kwargs: Dict = None,
        **kwargs
    ):
        super().__init__()
        try:
            from transformers import RobertaConfig, RobertaModel
        except ModuleNotFoundError:
            logger.error(
                " transformers is not installed. "
                "In order to install all text feature dependencies run "
                "pip install ludwig[text]"
            )
            sys.exit(-1)

        if use_pretrained:
            pretrained_kwargs = pretrained_kwargs or {}
            self.transformer = RobertaModel.from_pretrained(pretrained_model_name_or_path, **pretrained_kwargs)
        else:
            config = RobertaConfig(
                pad_token_id=pad_token_id,
                bos_token_id=bos_token_id,
                eos_token_id=eos_token_id,
            )
            self.transformer = RobertaModel(config)
        if trainable:
            self.transformer.train()
        self.reduce_output = reduce_output
        if not self.reduce_output == "cls_pooled":
            self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.transformer.trainable = trainable
        self.transformer.resize_token_embeddings(vocab_size)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 22:</b> &nbsp; 4 fragments, nominal size 25 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag677')" href="javascript:;">
ludwig-0.5rc2/ludwig/data/dataset_synthesizer.py: 464-524
</a>
<div class="mid" id="frag677" style="display:none"><pre>
def cli(sys_argv):
    parser = argparse.ArgumentParser(
        description="This script generates a synthetic dataset.",
        prog="ludwig synthesize_dataset",
        usage="%(prog)s [options]",
    )
    parser.add_argument("-od", "--output_path", type=str, help="output CSV file path")
    parser.add_argument("-d", "--dataset_size", help="size of the dataset", type=int, default=100)
    parser.add_argument(
        "-f",
        "--features",
        default="[\
          {name: text_1, type: text, vocab_size: 20, max_len: 20}, \
          {name: text_2, type: text, vocab_size: 20, max_len: 20}, \
          {name: category_1, type: category, vocab_size: 10}, \
          {name: category_2, type: category, vocab_size: 15}, \
          {name: number_1, type: number}, \
          {name: number_2, type: number}, \
          {name: binary_1, type: binary}, \
          {name: binary_2, type: binary}, \
          {name: set_1, type: set, vocab_size: 20, max_len: 20}, \
          {name: set_2, type: set, vocab_size: 20, max_len: 20}, \
          {name: bag_1, type: bag, vocab_size: 20, max_len: 10}, \
          {name: bag_2, type: bag, vocab_size: 20, max_len: 10}, \
          {name: sequence_1, type: sequence, vocab_size: 20, max_len: 20}, \
          {name: sequence_2, type: sequence, vocab_size: 20, max_len: 20}, \
          {name: timeseries_1, type: timeseries, max_len: 20}, \
          {name: timeseries_2, type: timeseries, max_len: 20}, \
          {name: date_1, type: date}, \
          {name: date_2, type: date}, \
          {name: h3_1, type: h3}, \
          {name: h3_2, type: h3}, \
          {name: vector_1, type: vector}, \
          {name: vector_2, type: vector}, \
        ]",
        type=yaml.safe_load,
        help="list of features to generate in YAML format. "
        "Provide a list containing one dictionary for each feature, "
        "each dictionary must include a name, a type "
        "and can include some generation parameters depending on the type",
    )
    add_contrib_callback_args(parser)
    args = parser.parse_args(sys_argv)

    args.callbacks = args.callbacks or []
    for callback in args.callbacks:
        callback.on_cmdline("synthesize_dataset", *sys_argv)

    # No log level parameter this is placeholder if we add at later date
    # args.logging_level = logging_level_registry[args.logging_level]
    # logging.getLogger('ludwig').setLevel(
    #     args.logging_level
    # )
    # global logger
    # logger = logging.getLogger('ludwig.data.dataset_synthesizer')

    print_ludwig("Synthesize Dataset", LUDWIG_VERSION)

    cli_synthesize_dataset(**vars(args))


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1423')" href="javascript:;">
ludwig-0.5rc2/ludwig/export.py: 147-192
</a>
<div class="mid" id="frag1423" style="display:none"><pre>
def cli_export_neuropod(sys_argv):
    parser = argparse.ArgumentParser(
        description="This script loads a pretrained model " "and saves it as a Neuropod.",
        prog="ludwig export_neuropod",
        usage="%(prog)s [options]",
    )

    # ----------------
    # Model parameters
    # ----------------
    parser.add_argument("-m", "--model_path", help="model to load", required=True)
    parser.add_argument("-mn", "--model_name", help="model name", default="neuropod")

    # -----------------
    # Output parameters
    # -----------------
    parser.add_argument("-od", "--output_path", type=str, help="path where to save the export model", required=True)

    # ------------------
    # Runtime parameters
    # ------------------
    parser.add_argument(
        "-l",
        "--logging_level",
        default="info",
        help="the level of logging to use",
        choices=["critical", "error", "warning", "info", "debug", "notset"],
    )

    add_contrib_callback_args(parser)
    args = parser.parse_args(sys_argv)

    args.callbacks = args.callbacks or []
    for callback in args.callbacks:
        callback.on_cmdline("export_neuropod", *sys_argv)

    args.logging_level = logging_level_registry[args.logging_level]
    logging.getLogger("ludwig").setLevel(args.logging_level)
    global logger
    logger = logging.getLogger("ludwig.export")

    print_ludwig("Export Neuropod", LUDWIG_VERSION)

    export_neuropod(**vars(args))


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1422')" href="javascript:;">
ludwig-0.5rc2/ludwig/export.py: 102-146
</a>
<div class="mid" id="frag1422" style="display:none"><pre>
def cli_export_torchscript(sys_argv):
    parser = argparse.ArgumentParser(
        description="This script loads a pretrained model " "and saves it as torchscript.",
        prog="ludwig export_torchscript",
        usage="%(prog)s [options]",
    )

    # ----------------
    # Model parameters
    # ----------------
    parser.add_argument("-m", "--model_path", help="model to load", required=True)

    # -----------------
    # Output parameters
    # -----------------
    parser.add_argument("-od", "--output_path", type=str, help="path where to save the export model", required=True)

    # ------------------
    # Runtime parameters
    # ------------------
    parser.add_argument(
        "-l",
        "--logging_level",
        default="info",
        help="the level of logging to use",
        choices=["critical", "error", "warning", "info", "debug", "notset"],
    )

    add_contrib_callback_args(parser)
    args = parser.parse_args(sys_argv)

    args.callbacks = args.callbacks or []
    for callback in args.callbacks:
        callback.on_cmdline("export_torchscript", *sys_argv)

    args.logging_level = logging_level_registry[args.logging_level]
    logging.getLogger("ludwig").setLevel(args.logging_level)
    global logger
    logger = logging.getLogger("ludwig.export")

    print_ludwig("Export Torchscript", LUDWIG_VERSION)

    export_torchscript(**vars(args))


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1424')" href="javascript:;">
ludwig-0.5rc2/ludwig/export.py: 193-240
</a>
<div class="mid" id="frag1424" style="display:none"><pre>
def cli_export_mlflow(sys_argv):
    parser = argparse.ArgumentParser(
        description="This script loads a pretrained model " "and saves it as an MLFlow model.",
        prog="ludwig export_mlflow",
        usage="%(prog)s [options]",
    )

    # ----------------
    # Model parameters
    # ----------------
    parser.add_argument("-m", "--model_path", help="model to load", required=True)
    parser.add_argument(
        "-mn", "--registered_model_name", help="model name to upload to in MLflow model registry", default="mlflow"
    )

    # -----------------
    # Output parameters
    # -----------------
    parser.add_argument("-od", "--output_path", type=str, help="path where to save the exported model", required=True)

    # ------------------
    # Runtime parameters
    # ------------------
    parser.add_argument(
        "-l",
        "--logging_level",
        default="info",
        help="the level of logging to use",
        choices=["critical", "error", "warning", "info", "debug", "notset"],
    )

    add_contrib_callback_args(parser)
    args = parser.parse_args(sys_argv)

    args.callbacks = args.callbacks or []
    for callback in args.callbacks:
        callback.on_cmdline("export_mlflow", *sys_argv)

    args.logging_level = logging_level_registry[args.logging_level]
    logging.getLogger("ludwig").setLevel(args.logging_level)
    global logger
    logger = logging.getLogger("ludwig.export")

    print_ludwig("Export MLFlow", LUDWIG_VERSION)

    export_mlflow(**vars(args))


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 23:</b> &nbsp; 5 fragments, nominal size 30 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag814')" href="javascript:;">
ludwig-0.5rc2/ludwig/utils/visualization_utils.py: 796-843
</a>
<div class="mid" id="frag814" style="display:none"><pre>
def threshold_vs_metric_plot(
    thresholds,
    scores,
    algorithm_names=None,
    title=None,
    filename=None,
    callbacks=None,
):
    sns.set_style("whitegrid")

    colors = plt.get_cmap("tab10").colors

    # y_ticks_minor = np.linspace(0.0, 1.0, num=21)
    # y_ticks_major = np.linspace(0.0, 1.0, num=11)
    # y_ticks_major_labels = ['{:3.0f}%'.format(y * 100) for y in y_ticks_major]

    fig, ax1 = plt.subplots()

    if title is not None:
        ax1.set_title(title)

    ax1.grid(which="both")
    ax1.grid(which="minor", alpha=0.5)
    ax1.grid(which="major", alpha=0.75)
    ax1.set_xticks([x for idx, x in enumerate(thresholds) if idx % 2 == 0])
    ax1.set_xticks(thresholds, minor=True)

    # ax1.set_xlim(0, 1)
    ax1.set_xlabel("confidence threshold")

    # ax1.set_ylim(0, 1)
    # ax1.set_yticks(y_ticks_major)
    # ax1.set_yticklabels(y_ticks_major_labels)
    # ax1.set_yticks(y_ticks_minor, minor=True)

    for i in range(len(scores)):
        algorithm_name = algorithm_names[i] + " " if algorithm_names is not None and i &lt; len(algorithm_names) else ""
        ax1.plot(thresholds, scores[i], label=algorithm_name, color=colors[i], linewidth=3, marker="o")

    ax1.legend(frameon=True)
    plt.tight_layout()
    visualize_callbacks(callbacks, plt.gcf())
    if filename:
        plt.savefig(filename)
    else:
        plt.show()


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag822')" href="javascript:;">
ludwig-0.5rc2/ludwig/utils/visualization_utils.py: 1130-1171
</a>
<div class="mid" id="frag822" style="display:none"><pre>
def plot_distributions(
    distributions,
    labels=None,
    title=None,
    filename=None,
    callbacks=None,
):
    sns.set_style("whitegrid")

    colors = plt.get_cmap("tab10").colors

    fig, ax1 = plt.subplots()

    if title is not None:
        ax1.set_title(title)

    ax1.grid(which="both")
    ax1.grid(which="minor", alpha=0.5)
    ax1.grid(which="major", alpha=0.75)

    ax1.set_xlabel("class")

    ax1.set_ylabel("p")
    ax1.tick_params("y")

    for i, distribution in enumerate(distributions):
        ax1.plot(
            distribution,
            color=colors[i],
            alpha=0.6,
            label=labels[i] if labels is not None and i &lt; len(labels) else f"Distribution {i}",
        )

    ax1.legend(frameon=True)
    fig.tight_layout()
    visualize_callbacks(callbacks, plt.gcf())
    if filename:
        plt.savefig(filename)
    else:
        plt.show()


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag823')" href="javascript:;">
ludwig-0.5rc2/ludwig/utils/visualization_utils.py: 1172-1206
</a>
<div class="mid" id="frag823" style="display:none"><pre>
def plot_distributions_difference(
    distribution,
    labels=None,
    title=None,
    filename=None,
    callbacks=None,
):
    sns.set_style("whitegrid")

    colors = plt.get_cmap("tab10").colors

    fig, ax1 = plt.subplots()

    if title is not None:
        ax1.set_title(title)

    ax1.grid(which="both")
    ax1.grid(which="minor", alpha=0.5)
    ax1.grid(which="major", alpha=0.75)

    ax1.set_xlabel("class")

    ax1.set_ylabel("p")
    ax1.tick_params("y")

    ax1.plot(distribution, color=colors[0])

    fig.tight_layout()
    visualize_callbacks(callbacks, plt.gcf())
    if filename:
        plt.savefig(filename)
    else:
        plt.show()


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag815')" href="javascript:;">
ludwig-0.5rc2/ludwig/utils/visualization_utils.py: 844-892
</a>
<div class="mid" id="frag815" style="display:none"><pre>
def roc_curves(
    fpr_tprs,
    algorithm_names=None,
    title=None,
    graded_color=False,
    filename=None,
    callbacks=None,
):
    sns.set_style("whitegrid")

    colors = plt.get_cmap("tab10").colors
    colormap = plt.get_cmap("RdYlGn")

    y_ticks_minor = np.linspace(0.0, 1.0, num=21)
    y_ticks_major = np.linspace(0.0, 1.0, num=11)

    fig, ax = plt.subplots()

    if title is not None:
        ax.set_title(title)

    ax.grid(which="both")
    ax.grid(which="minor", alpha=0.5)
    ax.grid(which="major", alpha=0.75)

    ax.set_xlim(0, 1)
    ax.set_xlabel("False positive rate")

    ax.set_ylim(0, 1)
    ax.set_yticks(y_ticks_major)
    ax.set_yticks(y_ticks_minor, minor=True)
    ax.set_ylabel("True positive rate")

    plt.plot([0, 1], [0, 1], color="black", linewidth=3, linestyle="--")

    for i in range(len(fpr_tprs)):
        algorithm_name = algorithm_names[i] + " " if algorithm_names is not None and i &lt; len(algorithm_names) else ""
        color = colormap(i / len(fpr_tprs)) if graded_color else colors[i]
        ax.plot(fpr_tprs[i][0], fpr_tprs[i][1], label=algorithm_name, color=color, linewidth=3)

    ax.legend(frameon=True)
    plt.tight_layout()
    visualize_callbacks(callbacks, plt.gcf())
    if filename:
        plt.savefig(filename)
    else:
        plt.show()


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag817')" href="javascript:;">
ludwig-0.5rc2/ludwig/utils/visualization_utils.py: 953-989
</a>
<div class="mid" id="frag817" style="display:none"><pre>
def brier_plot(
    brier_scores,
    algorithm_names=None,
    title=None,
    filename=None,
    callbacks=None,
):
    sns.set_style("whitegrid")

    if title is not None:
        plt.title(title)

    colors = plt.get_cmap("tab10").colors

    plt.grid(which="both")
    plt.grid(which="minor", alpha=0.5)
    plt.grid(which="major", alpha=0.75)
    plt.xlabel("class")
    plt.ylabel("brier")

    for i in range(brier_scores.shape[1]):
        plt.plot(
            brier_scores[:, i],
            label=algorithm_names[i] + " " if algorithm_names is not None and i &lt; len(algorithm_names) else "",
            color=colors[i],
            linewidth=3,
        )

    plt.legend()
    plt.tight_layout()
    visualize_callbacks(callbacks, plt.gcf())
    if filename:
        plt.savefig(filename)
    else:
        plt.show()


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 24:</b> &nbsp; 2 fragments, nominal size 16 lines, similarity 82%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag826')" href="javascript:;">
ludwig-0.5rc2/ludwig/utils/visualization_utils.py: 1321-1339
</a>
<div class="mid" id="frag826" style="display:none"><pre>
def hyperopt_int_plot(hyperopt_results_df, hp_name, metric, title, filename, log_scale_x=False, log_scale_y=True):
    sns.set_style("whitegrid")
    plt.figure()
    seaborn_figure = sns.scatterplot(x=hp_name, y=metric, data=hyperopt_results_df)
    seaborn_figure.set_title(title)
    if log_scale_x:
        seaborn_figure.set(xscale="log")
    if log_scale_y:
        seaborn_figure.set(yscale="log")
    seaborn_figure.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))
    seaborn_figure.xaxis.set_major_formatter(ticker.ScalarFormatter())
    seaborn_figure.xaxis.set_minor_formatter(ticker.NullFormatter())
    seaborn_figure.figure.tight_layout()
    if filename:
        seaborn_figure.figure.savefig(filename)
    else:
        seaborn_figure.figure.show()


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag827')" href="javascript:;">
ludwig-0.5rc2/ludwig/utils/visualization_utils.py: 1340-1356
</a>
<div class="mid" id="frag827" style="display:none"><pre>
def hyperopt_float_plot(hyperopt_results_df, hp_name, metric, title, filename, log_scale_x=False, log_scale_y=True):
    sns.set_style("whitegrid")
    plt.figure()
    seaborn_figure = sns.scatterplot(x=hp_name, y=metric, data=hyperopt_results_df)
    seaborn_figure.set_title(title)
    seaborn_figure.set(ylabel=metric)
    if log_scale_x:
        seaborn_figure.set(xscale="log")
    if log_scale_y:
        seaborn_figure.set(yscale="log")
    seaborn_figure.figure.tight_layout()
    if filename:
        seaborn_figure.figure.savefig(filename)
    else:
        seaborn_figure.figure.show()


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 25:</b> &nbsp; 2 fragments, nominal size 29 lines, similarity 74%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1105')" href="javascript:;">
ludwig-0.5rc2/ludwig/datasets/mushroom_edibility/__init__.py: 44-74
</a>
<div class="mid" id="frag1105" style="display:none"><pre>
    def process_downloaded_dataset(self):
        super().process_downloaded_dataset(header=None)
        processed_df = pd.read_csv(os.path.join(self.processed_dataset_path, self.csv_filename))
        columns = [
            "class",
            "cap-shape",
            "cap-surface",
            "cap-color",
            "bruises?",
            "odor",
            "gill-attachment",
            "gill-spacing",
            "gill-size",
            "gill-color",
            "stalk-shape",
            "stalk-root",
            "stalk-surface-above-ring",
            "stalk-surface-below-ring",
            "stalk-color-above-ring",
            "stalk-color-below-ring",
            "veil-type",
            "veil-color",
            "ring-number",
            "ring-type",
            "spore-print-color",
            "population",
            "habitat",
            "split",
        ]
        processed_df.columns = columns
        processed_df.to_csv(os.path.join(self.processed_dataset_path, self.csv_filename), index=False)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1193')" href="javascript:;">
ludwig-0.5rc2/ludwig/datasets/naval/__init__.py: 44-71
</a>
<div class="mid" id="frag1193" style="display:none"><pre>
    def process_downloaded_dataset(self):
        df = pd.read_csv(os.path.join(self.raw_dataset_path, "UCI CBM Dataset", "data.txt"), header=None, sep="   ")

        columns = [
            "lp",
            "v",
            "gtt",
            "gtn",
            "ggn",
            "ts",
            "tp",
            "t48",
            "t1",
            "t2",
            "p48",
            "p1",
            "p2",
            "pexh",
            "tic",
            "mf",
            "gtcdsc",
            "gttdsc",
        ]
        df.columns = columns

        makedirs(self.processed_temp_path, exist_ok=True)
        df.to_csv(os.path.join(self.processed_temp_path, self.csv_filename), index=False)
        rename(self.processed_temp_path, self.processed_dataset_path)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 26:</b> &nbsp; 4 fragments, nominal size 14 lines, similarity 78%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1125')" href="javascript:;">
ludwig-0.5rc2/ludwig/datasets/sst3/__init__.py: 43-57
</a>
<div class="mid" id="frag1125" style="display:none"><pre>
    def __init__(
        self,
        cache_dir=DEFAULT_CACHE_LOCATION,
        include_subtrees=False,
        convert_parentheses=True,
        remove_duplicates=False,
    ):
        super().__init__(
            dataset_name="sst3",
            cache_dir=cache_dir,
            include_subtrees=include_subtrees,
            convert_parentheses=convert_parentheses,
            remove_duplicates=False,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1168')" href="javascript:;">
ludwig-0.5rc2/ludwig/datasets/sst5/__init__.py: 43-57
</a>
<div class="mid" id="frag1168" style="display:none"><pre>
    def __init__(
        self,
        cache_dir=DEFAULT_CACHE_LOCATION,
        include_subtrees=False,
        convert_parentheses=True,
        remove_duplicates=False,
    ):
        super().__init__(
            dataset_name="sst5",
            cache_dir=cache_dir,
            include_subtrees=include_subtrees,
            convert_parentheses=convert_parentheses,
            remove_duplicates=False,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1186')" href="javascript:;">
ludwig-0.5rc2/ludwig/datasets/sst2/__init__.py: 59-74
</a>
<div class="mid" id="frag1186" style="display:none"><pre>
    def __init__(
        self,
        cache_dir=DEFAULT_CACHE_LOCATION,
        include_subtrees=False,
        convert_parentheses=True,
        remove_duplicates=False,
    ):
        super().__init__(
            dataset_name="sst2",
            cache_dir=cache_dir,
            include_subtrees=include_subtrees,
            discard_neutral=True,
            convert_parentheses=convert_parentheses,
            remove_duplicates=remove_duplicates,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1185')" href="javascript:;">
ludwig-0.5rc2/ludwig/datasets/sst2/__init__.py: 21-36
</a>
<div class="mid" id="frag1185" style="display:none"><pre>
def load(
    cache_dir=DEFAULT_CACHE_LOCATION,
    split=False,
    include_subtrees=False,
    convert_parentheses=True,
    remove_duplicates=False,
):
    dataset = SST2(
        cache_dir=cache_dir,
        include_subtrees=include_subtrees,
        convert_parentheses=convert_parentheses,
        remove_duplicates=remove_duplicates,
    )
    return dataset.load(split=split)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 27:</b> &nbsp; 4 fragments, nominal size 11 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1246')" href="javascript:;">
ludwig-0.5rc2/ludwig/features/text_feature.py: 240-253
</a>
<div class="mid" id="frag1246" style="display:none"><pre>
    def add_feature_data(
        feature_config, input_df, proc_df, metadata, preprocessing_parameters, backend, skip_save_processed_input
    ):
        chars_data, words_data = TextFeatureMixin.feature_data(
            input_df[feature_config[COLUMN]].astype(str),
            metadata[feature_config[NAME]],
            preprocessing_parameters,
            backend,
        )
        proc_df[f"{feature_config[PROC_COLUMN]}_char"] = chars_data
        proc_df[f"{feature_config[PROC_COLUMN]}_word"] = words_data
        return proc_df


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1321')" href="javascript:;">
ludwig-0.5rc2/ludwig/features/bag_feature.py: 91-102
</a>
<div class="mid" id="frag1321" style="display:none"><pre>
    def add_feature_data(
        feature_config, input_df, proc_df, metadata, preprocessing_parameters, backend, skip_save_processed_input
    ):
        proc_df[feature_config[PROC_COLUMN]] = BagFeatureMixin.feature_data(
            input_df[feature_config[COLUMN]].astype(str),
            metadata[feature_config[NAME]],
            preprocessing_parameters,
            backend,
        )
        return proc_df


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1374')" href="javascript:;">
ludwig-0.5rc2/ludwig/features/timeseries_feature.py: 117-128
</a>
<div class="mid" id="frag1374" style="display:none"><pre>
    def add_feature_data(
        feature_config, input_df, proc_df, metadata, preprocessing_parameters, backend, skip_save_processed_input
    ):
        proc_df[feature_config[PROC_COLUMN]] = TimeseriesFeatureMixin.feature_data(
            input_df[feature_config[COLUMN]].astype(str),
            metadata[feature_config[NAME]],
            preprocessing_parameters,
            backend,
        )
        return proc_df


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1274')" href="javascript:;">
ludwig-0.5rc2/ludwig/features/sequence_feature.py: 153-165
</a>
<div class="mid" id="frag1274" style="display:none"><pre>
    def add_feature_data(
        feature_config, input_df, proc_df, metadata, preprocessing_parameters, backend, skip_save_processed_input
    ):
        sequence_data = SequenceInputFeature.feature_data(
            input_df[feature_config[COLUMN]].astype(str),
            metadata[feature_config[NAME]],
            preprocessing_parameters,
            backend,
        )
        proc_df[feature_config[PROC_COLUMN]] = sequence_data
        return proc_df


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 28:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 73%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1272')" href="javascript:;">
ludwig-0.5rc2/ludwig/features/sequence_feature.py: 115-135
</a>
<div class="mid" id="frag1272" style="display:none"><pre>
    def get_feature_meta(column, preprocessing_parameters, backend):
        column = column.astype(str)
        idx2str, str2idx, str2freq, max_length, _, _, _ = create_vocabulary(
            column,
            preprocessing_parameters["tokenizer"],
            lowercase=preprocessing_parameters["lowercase"],
            num_most_frequent=preprocessing_parameters["most_common"],
            vocab_file=preprocessing_parameters["vocab_file"],
            unknown_symbol=preprocessing_parameters["unknown_symbol"],
            padding_symbol=preprocessing_parameters["padding_symbol"],
            processor=backend.df_engine,
        )
        max_length = min(preprocessing_parameters["sequence_length_limit"], max_length)
        return {
            "idx2str": idx2str,
            "str2idx": str2idx,
            "str2freq": str2freq,
            "vocab_size": len(idx2str),
            "max_sequence_length": max_length + 2,  # For start and end symbol.
        }

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1318')" href="javascript:;">
ludwig-0.5rc2/ludwig/features/bag_feature.py: 62-78
</a>
<div class="mid" id="frag1318" style="display:none"><pre>
    def get_feature_meta(column, preprocessing_parameters, backend):
        column = column.astype(str)
        idx2str, str2idx, str2freq, max_size, _, _, _ = create_vocabulary(
            column,
            preprocessing_parameters["tokenizer"],
            num_most_frequent=preprocessing_parameters["most_common"],
            lowercase=preprocessing_parameters["lowercase"],
            processor=backend.df_engine,
        )
        return {
            "idx2str": idx2str,
            "str2idx": str2idx,
            "str2freq": str2freq,
            "vocab_size": len(str2idx),
            "max_set_size": max_size,
        }

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 29:</b> &nbsp; 4 fragments, nominal size 31 lines, similarity 78%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1433')" href="javascript:;">
ludwig-0.5rc2/ludwig/modules/embedding_modules.py: 117-148
</a>
<div class="mid" id="frag1433" style="display:none"><pre>
    def __init__(
        self,
        vocab: List[str],
        embedding_size: int,
        representation: str = "dense",
        embeddings_trainable: bool = True,
        pretrained_embeddings: Optional[str] = None,
        force_embedding_size: bool = False,
        embeddings_on_cpu: bool = False,
        dropout: float = 0.0,
        embedding_initializer: Optional[Union[str, Dict]] = None,
    ):
        super().__init__()
        self.supports_masking = True

        self.vocab_size = len(vocab)
        self.embeddings, self.embedding_size = embedding_matrix_on_device(
            vocab,
            embedding_size,
            representation=representation,
            embeddings_trainable=embeddings_trainable,
            pretrained_embeddings=pretrained_embeddings,
            force_embedding_size=force_embedding_size,
            embeddings_on_cpu=embeddings_on_cpu,
            embedding_initializer=embedding_initializer,
        )

        if dropout &gt; 0:
            self.dropout = torch.nn.Dropout(p=dropout)
        else:
            self.dropout = None

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1437')" href="javascript:;">
ludwig-0.5rc2/ludwig/modules/embedding_modules.py: 172-213
</a>
<div class="mid" id="frag1437" style="display:none"><pre>
    def __init__(
        self,
        vocab: List[str],
        embedding_size: int,
        representation: str = "dense",
        embeddings_trainable: bool = True,
        pretrained_embeddings: Optional[str] = None,
        force_embedding_size: bool = False,
        embeddings_on_cpu: bool = False,
        dropout: float = 0.0,
        embedding_initializer: Optional[Union[str, Dict]] = None,
        aggregation_function: str = "sum",
    ):
        super().__init__()
        self.supports_masking = True

        self.vocab_size = len(vocab)
        self.embeddings, self.embedding_size = embedding_matrix_on_device(
            vocab,
            embedding_size,
            representation=representation,
            embeddings_trainable=embeddings_trainable,
            pretrained_embeddings=pretrained_embeddings,
            force_embedding_size=force_embedding_size,
            embeddings_on_cpu=embeddings_on_cpu,
            embedding_initializer=embedding_initializer,
        )

        if dropout &gt; 0:
            self.dropout = torch.nn.Dropout(p=dropout)
        else:
            self.dropout = None

        if aggregation_function == "sum":
            self.aggregation_function = torch.sum
        elif aggregation_function == "avg":
            self.aggregation_function = torch.mean
        else:
            raise ValueError(f"Unsupported aggregation function {aggregation_function}")

        self.register_buffer("vocab_indices", torch.arange(self.vocab_size))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1442')" href="javascript:;">
ludwig-0.5rc2/ludwig/modules/embedding_modules.py: 248-280
</a>
<div class="mid" id="frag1442" style="display:none"><pre>
    def __init__(
        self,
        vocab: List[str],
        embedding_size: int,
        representation: str = "dense",
        embeddings_trainable: bool = True,
        pretrained_embeddings: Optional[str] = None,
        force_embedding_size: bool = False,
        embeddings_on_cpu: bool = False,
        dropout: float = 0.0,
        embedding_initializer: Optional[str] = None,
    ):
        super().__init__()

        self.embeddings, self.embedding_size = embedding_matrix_on_device(
            vocab,
            embedding_size,
            representation=representation,
            embeddings_trainable=embeddings_trainable,
            pretrained_embeddings=pretrained_embeddings,
            force_embedding_size=force_embedding_size,
            embeddings_on_cpu=embeddings_on_cpu,
            embedding_initializer=embedding_initializer,
        )
        self.vocab_size = len(vocab)

        if dropout &gt; 0:
            self.dropout = nn.Dropout(dropout)
        else:
            self.dropout = None

        self.register_buffer("vocab_indices", torch.arange(self.vocab_size, dtype=torch.int32))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1446')" href="javascript:;">
ludwig-0.5rc2/ludwig/modules/embedding_modules.py: 374-407
</a>
<div class="mid" id="frag1446" style="display:none"><pre>
    def __init__(
        self,
        vocab: List[str],
        embedding_size: int,
        max_sequence_length: int,
        representation: str = "dense",
        embeddings_trainable: bool = True,
        pretrained_embeddings: Optional[str] = None,
        force_embedding_size: bool = False,
        embeddings_on_cpu: bool = False,
        dropout: float = 0.0,
        embedding_initializer: Optional[str] = None,
    ):
        super().__init__()
        self.supports_masking = True

        self.vocab_size = len(vocab)
        self.max_sequence_length = max_sequence_length
        self.embeddings, self.embedding_size = embedding_matrix_on_device(
            vocab,
            embedding_size,
            representation=representation,
            embeddings_trainable=embeddings_trainable,
            pretrained_embeddings=pretrained_embeddings,
            force_embedding_size=force_embedding_size,
            embeddings_on_cpu=embeddings_on_cpu,
            embedding_initializer=embedding_initializer,
        )

        if dropout &gt; 0:
            self.dropout = nn.Dropout(dropout)
        else:
            self.dropout = None

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<script language="JavaScript">
function ShowHide(divId) { 
    if(document.getElementById(divId).style.display == 'none') {
        document.getElementById(divId).style.display='block';
    } else { 
        document.getElementById(divId).style.display = 'none';
    } 
}
</script>
</body>
</html>
