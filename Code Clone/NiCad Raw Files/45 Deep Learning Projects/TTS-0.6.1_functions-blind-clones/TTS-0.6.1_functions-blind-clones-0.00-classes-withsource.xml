<clones>
<systeminfo processor="nicad6" system="TTS-0.6.1" granularity="functions-blind" threshold="0%" minlines="10" maxlines="2500"/>
<cloneinfo npcs="936" npairs="28"/>
<runinfo ncompares="3450" cputime="42228"/>
<classinfo nclasses="6"/>

<class classid="1" nclones="2" nlines="19" similarity="100">
<source file="systems/TTS-0.6.1/tests/aux_tests/test_find_unique_phonemes.py" startline="33" endline="55" pcid="21">
    def test_espeak_phonemes():
        # prepare the config
        config = VitsConfig(
            batch_size=2,
            eval_batch_size=2,
            num_loader_workers=0,
            num_eval_loader_workers=0,
            text_cleaner="english_cleaners",
            use_phonemes=True,
            phoneme_language="en-us",
            phoneme_cache_path="tests/data/ljspeech/phoneme_cache/",
            run_eval=True,
            test_delay_epochs=-1,
            epochs=1,
            print_step=1,
            print_eval=True,
            datasets=[dataset_config_en, dataset_config_pt],
        )
        config.save_json(config_path)

        # run test
        run_cli(f'CUDA_VISIBLE_DEVICES="" python TTS/bin/find_unique_phonemes.py --config_path "{config_path}"')

</source>
<source file="systems/TTS-0.6.1/tests/aux_tests/test_find_unique_phonemes.py" startline="57" endline="78" pcid="22">
    def test_no_espeak_phonemes():
        # prepare the config
        config = VitsConfig(
            batch_size=2,
            eval_batch_size=2,
            num_loader_workers=0,
            num_eval_loader_workers=0,
            text_cleaner="english_cleaners",
            use_phonemes=True,
            phoneme_language="en-us",
            phoneme_cache_path="tests/data/ljspeech/phoneme_cache/",
            run_eval=True,
            test_delay_epochs=-1,
            epochs=1,
            print_step=1,
            print_eval=True,
            datasets=[dataset_config_en, dataset_config_pt],
        )
        config.save_json(config_path)

        # run test
        run_cli(f'CUDA_VISIBLE_DEVICES="" python TTS/bin/find_unique_phonemes.py --config_path "{config_path}"')
</source>
</class>

<class classid="2" nclones="3" nlines="10" similarity="100">
<source file="systems/TTS-0.6.1/tests/aux_tests/test_extract_tts_spectrograms.py" startline="15" endline="31" pcid="23">
    def test_GlowTTS():
        # set paths
        config_path = os.path.join(get_tests_input_path(), "test_glow_tts.json")
        checkpoint_path = os.path.join(get_tests_output_path(), "checkpoint_test.pth.tar")
        output_path = os.path.join(get_tests_output_path(), "output_extract_tts_spectrograms/")
        # load config
        c = load_config(config_path)
        # create model
        model = setup_model(c)
        # save model
        torch.save({"model": model.state_dict()}, checkpoint_path)
        # run test
        run_cli(
            f'CUDA_VISIBLE_DEVICES="" python TTS/bin/extract_tts_spectrograms.py --config_path "{config_path}" --checkpoint_path "{checkpoint_path}" --output_path "{output_path}"'
        )
        run_cli(f'rm -rf "{output_path}" "{checkpoint_path}"')

</source>
<source file="systems/TTS-0.6.1/tests/aux_tests/test_extract_tts_spectrograms.py" startline="33" endline="49" pcid="24">
    def test_Tacotron2():
        # set paths
        config_path = os.path.join(get_tests_input_path(), "test_tacotron2_config.json")
        checkpoint_path = os.path.join(get_tests_output_path(), "checkpoint_test.pth.tar")
        output_path = os.path.join(get_tests_output_path(), "output_extract_tts_spectrograms/")
        # load config
        c = load_config(config_path)
        # create model
        model = setup_model(c)
        # save model
        torch.save({"model": model.state_dict()}, checkpoint_path)
        # run test
        run_cli(
            f'CUDA_VISIBLE_DEVICES="" python TTS/bin/extract_tts_spectrograms.py --config_path "{config_path}" --checkpoint_path "{checkpoint_path}" --output_path "{output_path}"'
        )
        run_cli(f'rm -rf "{output_path}" "{checkpoint_path}"')

</source>
<source file="systems/TTS-0.6.1/tests/aux_tests/test_extract_tts_spectrograms.py" startline="51" endline="66" pcid="25">
    def test_Tacotron():
        # set paths
        config_path = os.path.join(get_tests_input_path(), "test_tacotron_config.json")
        checkpoint_path = os.path.join(get_tests_output_path(), "checkpoint_test.pth.tar")
        output_path = os.path.join(get_tests_output_path(), "output_extract_tts_spectrograms/")
        # load config
        c = load_config(config_path)
        # create model
        model = setup_model(c)
        # save model
        torch.save({"model": model.state_dict()}, checkpoint_path)
        # run test
        run_cli(
            f'CUDA_VISIBLE_DEVICES="" python TTS/bin/extract_tts_spectrograms.py --config_path "{config_path}" --checkpoint_path "{checkpoint_path}" --output_path "{output_path}"'
        )
        run_cli(f'rm -rf "{output_path}" "{checkpoint_path}"')
</source>
</class>

<class classid="3" nclones="2" nlines="11" similarity="100">
<source file="systems/TTS-0.6.1/tests/text_tests/test_characters.py" startline="68" endline="81" pcid="110">
    def test_unique(self):
        """Test if the unique option works"""
        self.characters_empty.characters = "abcc"
        self.characters_empty.punctuations = ".,;:!? "
        self.characters_empty.pad = "[PAD]"
        self.characters_empty.eos = "[EOS]"
        self.characters_empty.bos = "[BOS]"
        self.characters_empty.blank = "[BLANK]"

        self.assertEqual(
            self.characters_empty.num_chars,
            len(["[PAD]", "[EOS]", "[BOS]", "[BLANK]", "a", "b", "c", ".", ",", ";", ":", "!", "?", " "]),
        )

</source>
<source file="systems/TTS-0.6.1/tests/text_tests/test_characters.py" startline="82" endline="95" pcid="111">
    def test_unique_sorted(self):
        """Test if the unique and sorted option works"""
        self.characters_empty.characters = "cba"
        self.characters_empty.punctuations = ".,;:!? "
        self.characters_empty.pad = "[PAD]"
        self.characters_empty.eos = "[EOS]"
        self.characters_empty.bos = "[BOS]"
        self.characters_empty.blank = "[BLANK]"

        self.assertEqual(
            self.characters_empty.num_chars,
            len(["[PAD]", "[EOS]", "[BOS]", "[BLANK]", "a", "b", "c", ".", ",", ";", ":", "!", "?", " "]),
        )

</source>
</class>

<class classid="4" nclones="2" nlines="18" similarity="100">
<source file="systems/TTS-0.6.1/tests/text_tests/test_phonemizer.py" startline="30" endline="55" pcid="121">
    def setUp(self):
        self.phonemizer = ESpeak(language="en-us", backend="espeak")

        for text, ph in zip(EXAMPLE_TEXTs, EXPECTED_ESPEAK_PHONEMES):
            phonemes = self.phonemizer.phonemize(text)
            self.assertEqual(phonemes, ph)

        # multiple punctuations
        text = "Be a voice, not an! echo?"
        gt = "biː ɐ vˈɔɪs, nˈɑːt ɐn! ˈɛkoʊ?"
        output = self.phonemizer.phonemize(text, separator="|")
        output = output.replace("|", "")
        self.assertEqual(output, gt)

        # not ending with punctuation
        text = "Be a voice, not an! echo"
        gt = "biː ɐ vˈɔɪs, nˈɑːt ɐn! ˈɛkoʊ"
        output = self.phonemizer.phonemize(text, separator="")
        self.assertEqual(output, gt)

        # extra space after the sentence
        text = "Be a voice, not an! echo.  "
        gt = "biː ɐ vˈɔɪs, nˈɑːt ɐn! ˈɛkoʊ."
        output = self.phonemizer.phonemize(text, separator="")
        self.assertEqual(output, gt)

</source>
<source file="systems/TTS-0.6.1/tests/text_tests/test_phonemizer.py" startline="70" endline="95" pcid="126">
    def setUp(self):
        self.phonemizer = ESpeak(language="en-us", backend="espeak-ng")

        for text, ph in zip(EXAMPLE_TEXTs, EXPECTED_ESPEAKNG_PHONEMES):
            phonemes = self.phonemizer.phonemize(text)
            self.assertEqual(phonemes, ph)

        # multiple punctuations
        text = "Be a voice, not an! echo?"
        gt = "biː ɐ vˈɔɪs, nˈɑːt æn! ˈɛkoʊ?"
        output = self.phonemizer.phonemize(text, separator="|")
        output = output.replace("|", "")
        self.assertEqual(output, gt)

        # not ending with punctuation
        text = "Be a voice, not an! echo"
        gt = "biː ɐ vˈɔɪs, nˈɑːt æn! ˈɛkoʊ"
        output = self.phonemizer.phonemize(text, separator="")
        self.assertEqual(output, gt)

        # extra space after the sentence
        text = "Be a voice, not an! echo.  "
        gt = "biː ɐ vˈɔɪs, nˈɑːt æn! ˈɛkoʊ."
        output = self.phonemizer.phonemize(text, separator="")
        self.assertEqual(output, gt)

</source>
</class>

<class classid="5" nclones="2" nlines="14" similarity="100">
<source file="systems/TTS-0.6.1/TTS/tts/layers/losses.py" startline="21" endline="54" pcid="606">
    def forward(self, x, target, length):
        """
        Args:
            x: A Variable containing a FloatTensor of size
                (batch, max_len, dim) which contains the
                unnormalized probability for each class.
            target: A Variable containing a LongTensor of size
                (batch, max_len, dim) which contains the index of the true
                class for each corresponding step.
            length: A Variable containing a LongTensor of size (batch,)
                which contains the length of each data in a batch.
        Shapes:
            x: B x T X D
            target: B x T x D
            length: B
        Returns:
            loss: An average loss value in range [0, 1] masked by the length.
        """
        # mask: (batch, max_len, 1)
        target.requires_grad = False
        mask = sequence_mask(sequence_length=length, max_len=target.size(1)).unsqueeze(2).float()
        if self.seq_len_norm:
            norm_w = mask / mask.sum(dim=1, keepdim=True)
            out_weights = norm_w.div(target.shape[0] * target.shape[2])
            mask = mask.expand_as(x)
            loss = functional.l1_loss(x * mask, target * mask, reduction="none")
            loss = loss.mul(out_weights.to(loss.device)).sum()
        else:
            mask = mask.expand_as(x)
            loss = functional.l1_loss(x * mask, target * mask, reduction="sum")
            loss = loss / mask.sum()
        return loss


</source>
<source file="systems/TTS-0.6.1/TTS/tts/layers/losses.py" startline="60" endline="93" pcid="608">
    def forward(self, x, target, length):
        """
        Args:
            x: A Variable containing a FloatTensor of size
                (batch, max_len, dim) which contains the
                unnormalized probability for each class.
            target: A Variable containing a LongTensor of size
                (batch, max_len, dim) which contains the index of the true
                class for each corresponding step.
            length: A Variable containing a LongTensor of size (batch,)
                which contains the length of each data in a batch.
        Shapes:
            - x: :math:`[B, T, D]`
            - target: :math:`[B, T, D]`
            - length: :math:`B`
        Returns:
            loss: An average loss value in range [0, 1] masked by the length.
        """
        # mask: (batch, max_len, 1)
        target.requires_grad = False
        mask = sequence_mask(sequence_length=length, max_len=target.size(1)).unsqueeze(2).float()
        if self.seq_len_norm:
            norm_w = mask / mask.sum(dim=1, keepdim=True)
            out_weights = norm_w.div(target.shape[0] * target.shape[2])
            mask = mask.expand_as(x)
            loss = functional.mse_loss(x * mask, target * mask, reduction="none")
            loss = loss.mul(out_weights.to(loss.device)).sum()
        else:
            mask = mask.expand_as(x)
            loss = functional.mse_loss(x * mask, target * mask, reduction="sum")
            loss = loss / mask.sum()
        return loss


</source>
</class>

<class classid="6" nclones="7" nlines="11" similarity="100">
<source file="systems/TTS-0.6.1/TTS/utils/callbacks.py" startline="3" endline="16" pcid="667">
    def on_init_start(trainer) -> None:
        if hasattr(trainer.model, "module"):
            if hasattr(trainer.model.module, "on_init_start"):
                trainer.model.module.on_init_start(trainer)
        else:
            if hasattr(trainer.model, "on_init_start"):
                trainer.model.on_init_start(trainer)

        if hasattr(trainer.criterion, "on_init_start"):
            trainer.criterion.on_init_start(trainer)

        if hasattr(trainer.optimizer, "on_init_start"):
            trainer.optimizer.on_init_start(trainer)

</source>
<source file="systems/TTS-0.6.1/TTS/utils/callbacks.py" startline="63" endline="76" pcid="671">
    def on_train_step_start(trainer) -> None:
        if hasattr(trainer.model, "module"):
            if hasattr(trainer.model.module, "on_train_step_start"):
                trainer.model.module.on_train_step_start(trainer)
        else:
            if hasattr(trainer.model, "on_train_step_start"):
                trainer.model.on_train_step_start(trainer)

        if hasattr(trainer.criterion, "on_train_step_start"):
            trainer.criterion.on_train_step_start(trainer)

        if hasattr(trainer.optimizer, "on_train_step_start"):
            trainer.optimizer.on_train_step_start(trainer)

</source>
<source file="systems/TTS-0.6.1/TTS/utils/callbacks.py" startline="18" endline="31" pcid="668">
    def on_init_end(trainer) -> None:
        if hasattr(trainer.model, "module"):
            if hasattr(trainer.model.module, "on_init_end"):
                trainer.model.module.on_init_end(trainer)
        else:
            if hasattr(trainer.model, "on_init_end"):
                trainer.model.on_init_end(trainer)

        if hasattr(trainer.criterion, "on_init_end"):
            trainer.criterion.on_init_end(trainer)

        if hasattr(trainer.optimizer, "on_init_end"):
            trainer.optimizer.on_init_end(trainer)

</source>
<source file="systems/TTS-0.6.1/TTS/utils/callbacks.py" startline="48" endline="61" pcid="670">
    def on_epoch_end(trainer) -> None:
        if hasattr(trainer.model, "module"):
            if hasattr(trainer.model.module, "on_epoch_end"):
                trainer.model.module.on_epoch_end(trainer)
        else:
            if hasattr(trainer.model, "on_epoch_end"):
                trainer.model.on_epoch_end(trainer)

        if hasattr(trainer.criterion, "on_epoch_end"):
            trainer.criterion.on_epoch_end(trainer)

        if hasattr(trainer.optimizer, "on_epoch_end"):
            trainer.optimizer.on_epoch_end(trainer)

</source>
<source file="systems/TTS-0.6.1/TTS/utils/callbacks.py" startline="33" endline="46" pcid="669">
    def on_epoch_start(trainer) -> None:
        if hasattr(trainer.model, "module"):
            if hasattr(trainer.model.module, "on_epoch_start"):
                trainer.model.module.on_epoch_start(trainer)
        else:
            if hasattr(trainer.model, "on_epoch_start"):
                trainer.model.on_epoch_start(trainer)

        if hasattr(trainer.criterion, "on_epoch_start"):
            trainer.criterion.on_epoch_start(trainer)

        if hasattr(trainer.optimizer, "on_epoch_start"):
            trainer.optimizer.on_epoch_start(trainer)

</source>
<source file="systems/TTS-0.6.1/TTS/utils/callbacks.py" startline="93" endline="105" pcid="673">
    def on_keyboard_interrupt(trainer) -> None:
        if hasattr(trainer.model, "module"):
            if hasattr(trainer.model.module, "on_keyboard_interrupt"):
                trainer.model.module.on_keyboard_interrupt(trainer)
        else:
            if hasattr(trainer.model, "on_keyboard_interrupt"):
                trainer.model.on_keyboard_interrupt(trainer)

        if hasattr(trainer.criterion, "on_keyboard_interrupt"):
            trainer.criterion.on_keyboard_interrupt(trainer)

        if hasattr(trainer.optimizer, "on_keyboard_interrupt"):
            trainer.optimizer.on_keyboard_interrupt(trainer)
</source>
<source file="systems/TTS-0.6.1/TTS/utils/callbacks.py" startline="78" endline="91" pcid="672">
    def on_train_step_end(trainer) -> None:
        if hasattr(trainer.model, "module"):
            if hasattr(trainer.model.module, "on_train_step_end"):
                trainer.model.module.on_train_step_end(trainer)
        else:
            if hasattr(trainer.model, "on_train_step_end"):
                trainer.model.on_train_step_end(trainer)

        if hasattr(trainer.criterion, "on_train_step_end"):
            trainer.criterion.on_train_step_end(trainer)

        if hasattr(trainer.optimizer, "on_train_step_end"):
            trainer.optimizer.on_train_step_end(trainer)

</source>
</class>

</clones>
