<clones>
<systeminfo processor="nicad6" system="deepvariant-1.0.0" granularity="functions-blind" threshold="30%" minlines="10" maxlines="2500"/>
<cloneinfo npcs="742" npairs="18"/>
<runinfo ncompares="8270" cputime="52412"/>
<classinfo nclasses="14"/>

<class classid="1" nclones="2" nlines="13" similarity="78">
<source file="systems/deepvariant-1.0.0/deepvariant/vcf_stats_vis.py" startline="166" endline="185" pcid="24">
  return qual_histogram


def _build_gq_histogram(data):
  """Create the Genotype quality (GQ) histogram."""
  # gq = genotype quality, found at :GQ: in FORMAT column of VCF
  width = 200
  height = 200
  title = 'Genotype quality'
  gq_data = _integer_counts_to_histogram(data)
  gq_histogram = _placeholder_for_empty_chart(
      'No entries in VCF with GQ', width=width, height=height, title=title)
  if not gq_data.empty:
    # standardize x-axis limits across reports
    domain = [min(0, data[0][0]), max(150, data[-1][0])]
    # s = bin_start, e = bin_end, c = count
    gq_histogram = alt.Chart(gq_data).mark_bar(color=BAR_COLOR_GQ) \
        .encode(
            x=alt.X('s', title='GQ', scale=alt.Scale(domain=domain)),
            x2='e',
</source>
<source file="systems/deepvariant-1.0.0/deepvariant/vcf_stats_vis.py" startline="325" endline="340" pcid="30">
                  title=title) \
      .interactive(bind_y=False)

    indel_log = alt.Chart(indel_size_data).mark_bar().encode(
        x=alt.X('s', title='size'),
        x2='e',
        y=alt.Y(
            'c',
            title='Count',
            axis=alt.Axis(format='s'),
            scale=alt.Scale(type='log', base=10)),
        color=alt.Color('type', sort=ordered_labels,
                        scale=alt.Scale(scheme='set1'))) \
      .properties(width=400, height=100) \
      .interactive(bind_y=False)

</source>
</class>

<class classid="2" nclones="2" nlines="11" similarity="81">
<source file="systems/deepvariant-1.0.0/deepvariant/variant_caller.py" startline="114" endline="129" pcid="87">
  def __init__(self, options, use_cache_table, max_cache_coverage):
    self.options = options
    self.cpp_variant_caller = variant_calling.VariantCaller(self.options)

    self.max_cache_coverage = max_cache_coverage
    # pylint: disable=g-complex-comprehension
    if use_cache_table:
      self.table = [[
          self._calc_reference_confidence(n_ref, n_total)
          for n_ref in range(n_total + 1)
      ]
                    for n_total in range(self.max_cache_coverage + 1)]
    else:
      self.table = None
    # pylint: enable=g-complex-comprehension

</source>
<source file="systems/deepvariant-1.0.0/deeptrio/variant_caller.py" startline="115" endline="131" pcid="346">
  def __init__(self, options, use_cache_table, max_cache_coverage):
    self.options = options
    self.cpp_variant_caller = variant_calling_deeptrio.VariantCaller(
        self.options)

    self.max_cache_coverage = max_cache_coverage
    # pylint: disable=g-complex-comprehension
    if use_cache_table:
      self.table = [[
          self._calc_reference_confidence(n_ref, n_total)
          for n_ref in range(n_total + 1)
      ]
                    for n_total in range(self.max_cache_coverage + 1)]
    else:
      self.table = None
    # pylint: enable=g-complex-comprehension

</source>
</class>

<class classid="3" nclones="2" nlines="22" similarity="100">
<source file="systems/deepvariant-1.0.0/deepvariant/variant_caller.py" startline="192" endline="218" pcid="89">
  def _calc_reference_confidence(self, n_ref, n_total):
    """Performs the calculation described in reference_confidence()."""
    if n_ref < 0:
      raise ValueError('n_ref={} must be >= 0'.format(n_ref))
    if n_total < n_ref:
      raise ValueError('n_total={} must be >= n_ref={}'.format(n_total, n_ref))
    if self.options.ploidy != 2:
      raise ValueError('ploidy={} but we only support ploidy=2'.format(
          self.options.ploidy))

    if n_total == 0:
      # No coverage case - all likelihoods are log10 of 1/3, 1/3, 1/3.
      log10_probs = genomics_math.normalize_log10_probs([-1.0, -1.0, -1.0])
    else:
      n_alts = n_total - n_ref
      logp = math.log(self.options.p_error) / LOG_10
      log1p = math.log1p(-self.options.p_error) / LOG_10
      log10_p_ref = n_ref * log1p + n_alts * logp
      log10_p_het = -n_total * math.log(self.options.ploidy) / LOG_10
      log10_p_hom_alt = n_ref * logp + n_alts * log1p
      log10_probs = genomics_math.normalize_log10_probs(
          [log10_p_ref, log10_p_het, log10_p_hom_alt])

    gq = genomics_math.log10_ptrue_to_phred(log10_probs[0], self.options.max_gq)
    gq = int(min(np.floor(gq), self.options.max_gq))
    return gq, log10_probs

</source>
<source file="systems/deepvariant-1.0.0/deeptrio/variant_caller.py" startline="194" endline="220" pcid="348">
  def _calc_reference_confidence(self, n_ref, n_total):
    """Performs the calculation described in reference_confidence()."""
    if n_ref < 0:
      raise ValueError('n_ref={} must be >= 0'.format(n_ref))
    if n_total < n_ref:
      raise ValueError('n_total={} must be >= n_ref={}'.format(n_total, n_ref))
    if self.options.ploidy != 2:
      raise ValueError('ploidy={} but we only support ploidy=2'.format(
          self.options.ploidy))

    if n_total == 0:
      # No coverage case - all likelihoods are log10 of 1/3, 1/3, 1/3.
      log10_probs = genomics_math.normalize_log10_probs([-1.0, -1.0, -1.0])
    else:
      n_alts = n_total - n_ref
      logp = math.log(self.options.p_error) / LOG_10
      log1p = math.log1p(-self.options.p_error) / LOG_10
      log10_p_ref = n_ref * log1p + n_alts * logp
      log10_p_het = -n_total * math.log(self.options.ploidy) / LOG_10
      log10_p_hom_alt = n_ref * logp + n_alts * log1p
      log10_probs = genomics_math.normalize_log10_probs(
          [log10_p_ref, log10_p_het, log10_p_hom_alt])

    gq = genomics_math.log10_ptrue_to_phred(log10_probs[0], self.options.max_gq)
    gq = int(min(np.floor(gq), self.options.max_gq))
    return gq, log10_probs

</source>
</class>

<class classid="4" nclones="2" nlines="62" similarity="100">
<source file="systems/deepvariant-1.0.0/deepvariant/variant_caller.py" startline="219" endline="338" pcid="90">
  def make_gvcfs(self, allele_count_summaries):
    """Primary interface function for computing gVCF confidence at a site.

    Looks at the counts in the provided list of AlleleCountSummary protos and
    returns properly-formatted Variant protos containing gVCF reference
    blocks for all sites in allele_count_summaries. The returned Variant has
    reference_name, start, end are set and contains a single VariantCall in the
    calls field with call_set_name of options.sample_name, genotypes set to 0/0
    (diploid reference), a GQ value bound in the info field appropriate to the
    data in allele_count, and a MIN_DP value which is the minimum read coverage
    seen in the block.

    The provided allele count must have either a canonical DNA sequence base (
    A, C, G, T) or be "N".

    Args:
      allele_count_summaries: iterable of AlleleCountSummary protos in
        coordinate-sorted order. Each proto is used to get the read counts for
        reference and alternate alleles, the reference position, and reference
        base.

    Yields:
      third_party.nucleus.protos.Variant proto in
      coordinate-sorted order containing gVCF records.
    """

    def with_gq_and_likelihoods(summary_counts):
      """Returns summary_counts along with GQ and genotype likelihoods.

      If the reference base is not in CANONICAL_DNA_BASES, both GQ and genotype
      likelihoods are set to None.

      Args:
        summary_counts: A single AlleleCountSummary.

      Returns:
        A tuple of summary_counts, quantized GQ, raw GQ, and genotype
        likelihoods for summary_counts where raw GQ and genotype_likelihood are
        calculated by self.reference_confidence.

      Raises:
        ValueError: The reference base is not a valid DNA or IUPAC base.
      """
      if summary_counts.ref_base not in CANONICAL_DNA_BASES:
        if summary_counts.ref_base in EXTENDED_IUPAC_CODES:
          # Skip calculating gq and likelihoods, since this is an ambiguous
          # reference base.
          quantized_gq, raw_gq, likelihoods = None, None, None
          has_valid_gl = True
          n_total = summary_counts.total_read_count
        else:
          raise ValueError('Invalid reference base={} found during gvcf '
                           'calculation'.format(summary_counts.ref_base))
      else:
        n_ref = summary_counts.ref_supporting_read_count
        n_total = summary_counts.total_read_count
        raw_gq, likelihoods = self.reference_confidence(n_ref, n_total)
        quantized_gq = _quantize_gq(raw_gq, self.options.gq_resolution)
        has_valid_gl = (np.amax(likelihoods) == likelihoods[0])
      return _GVCF(
          summary_counts=summary_counts,
          quantized_gq=quantized_gq,
          raw_gq=raw_gq,
          likelihoods=likelihoods,
          read_depth=n_total,
          has_valid_gl=has_valid_gl)

    # Combines contiguous, compatible single-bp blocks into larger gVCF blocks,
    # respecting non-reference variants interspersed among them. Yields each
    # combined gVCF Variant proto, in order. Compatible right now means that the
    # blocks to be merged have the same non-None GQ value.
    for key, combinable in itertools.groupby(
        (with_gq_and_likelihoods(sc) for sc in allele_count_summaries),
        key=operator.attrgetter('quantized_gq', 'has_valid_gl')):
      quantized_gq_val, gl_is_valid = key
      if quantized_gq_val is None:
        # A None key indicates that a non-DNA reference base was encountered, so
        # skip this group.
        continue

      if gl_is_valid:
        combinable = list(combinable)
        min_gq = min(elt.raw_gq for elt in combinable)
        min_dp = min(elt.read_depth for elt in combinable)
        first_record, last_record = combinable[0], combinable[-1]
        call = variants_pb2.VariantCall(
            call_set_name=self.options.sample_name,
            genotype=[0, 0],
            genotype_likelihood=first_record.likelihoods)
        variantcall_utils.set_gq(call, min_gq)
        variantcall_utils.set_min_dp(call, min_dp)
        yield variants_pb2.Variant(
            reference_name=first_record.summary_counts.reference_name,
            reference_bases=first_record.summary_counts.ref_base,
            alternate_bases=[vcf_constants.GVCF_ALT_ALLELE],
            start=first_record.summary_counts.position,
            end=last_record.summary_counts.position + 1,
            calls=[call])
      else:
        # After evaluating the effect of including sites with contradictory GL
        # (where the value for hom_ref is not maximal), we concluded that
        # un-calling these sites (by setting its genotype "./.") is better
        # for cohort merging.
        # See internal for detail.
        for elt in combinable:
          uncalled_gt = [-1, -1]
          call = variants_pb2.VariantCall(
              call_set_name=self.options.sample_name,
              genotype=uncalled_gt,
              genotype_likelihood=elt.likelihoods)
          variantcall_utils.set_gq(call, elt.raw_gq)
          variantcall_utils.set_min_dp(call, elt.read_depth)
          yield variants_pb2.Variant(
              reference_name=elt.summary_counts.reference_name,
              reference_bases=elt.summary_counts.ref_base,
              alternate_bases=[vcf_constants.GVCF_ALT_ALLELE],
              start=elt.summary_counts.position,
              end=elt.summary_counts.position + 1,
              calls=[call])

</source>
<source file="systems/deepvariant-1.0.0/deeptrio/variant_caller.py" startline="221" endline="340" pcid="349">
  def make_gvcfs(self, allele_count_summaries):
    """Primary interface function for computing gVCF confidence at a site.

    Looks at the counts in the provided list of AlleleCountSummary protos and
    returns properly-formatted Variant protos containing gVCF reference
    blocks for all sites in allele_count_summaries. The returned Variant has
    reference_name, start, end are set and contains a single VariantCall in the
    calls field with call_set_name of options.sample_name, genotypes set to 0/0
    (diploid reference), a GQ value bound in the info field appropriate to the
    data in allele_count, and a MIN_DP value which is the minimum read coverage
    seen in the block.

    The provided allele count must have either a canonical DNA sequence base (
    A, C, G, T) or be "N".

    Args:
      allele_count_summaries: iterable of AlleleCountSummary protos in
        coordinate-sorted order. Each proto is used to get the read counts for
        reference and alternate alleles, the reference position, and reference
        base.

    Yields:
      third_party.nucleus.protos.Variant proto in
      coordinate-sorted order containing gVCF records.
    """

    def with_gq_and_likelihoods(summary_counts):
      """Returns summary_counts along with GQ and genotype likelihoods.

      If the reference base is not in CANONICAL_DNA_BASES, both GQ and genotype
      likelihoods are set to None.

      Args:
        summary_counts: A single AlleleCountSummary.

      Returns:
        A tuple of summary_counts, quantized GQ, raw GQ, and genotype
        likelihoods for summary_counts where raw GQ and genotype_likelihood are
        calculated by self.reference_confidence.

      Raises:
        ValueError: The reference base is not a valid DNA or IUPAC base.
      """
      if summary_counts.ref_base not in CANONICAL_DNA_BASES:
        if summary_counts.ref_base in EXTENDED_IUPAC_CODES:
          # Skip calculating gq and likelihoods, since this is an ambiguous
          # reference base.
          quantized_gq, raw_gq, likelihoods = None, None, None
          has_valid_gl = True
          n_total = summary_counts.total_read_count
        else:
          raise ValueError('Invalid reference base={} found during gvcf '
                           'calculation'.format(summary_counts.ref_base))
      else:
        n_ref = summary_counts.ref_supporting_read_count
        n_total = summary_counts.total_read_count
        raw_gq, likelihoods = self.reference_confidence(n_ref, n_total)
        quantized_gq = _quantize_gq(raw_gq, self.options.gq_resolution)
        has_valid_gl = (np.amax(likelihoods) == likelihoods[0])
      return _GVCF(
          summary_counts=summary_counts,
          quantized_gq=quantized_gq,
          raw_gq=raw_gq,
          likelihoods=likelihoods,
          read_depth=n_total,
          has_valid_gl=has_valid_gl)

    # Combines contiguous, compatible single-bp blocks into larger gVCF blocks,
    # respecting non-reference variants interspersed among them. Yields each
    # combined gVCF Variant proto, in order. Compatible right now means that the
    # blocks to be merged have the same non-None GQ value.
    for key, combinable in itertools.groupby(
        (with_gq_and_likelihoods(sc) for sc in allele_count_summaries),
        key=operator.attrgetter('quantized_gq', 'has_valid_gl')):
      quantized_gq_val, gl_is_valid = key
      if quantized_gq_val is None:
        # A None key indicates that a non-DNA reference base was encountered, so
        # skip this group.
        continue

      if gl_is_valid:
        combinable = list(combinable)
        min_gq = min(elt.raw_gq for elt in combinable)
        min_dp = min(elt.read_depth for elt in combinable)
        first_record, last_record = combinable[0], combinable[-1]
        call = variants_pb2.VariantCall(
            call_set_name=self.options.sample_name,
            genotype=[0, 0],
            genotype_likelihood=first_record.likelihoods)
        variantcall_utils.set_gq(call, min_gq)
        variantcall_utils.set_min_dp(call, min_dp)
        yield variants_pb2.Variant(
            reference_name=first_record.summary_counts.reference_name,
            reference_bases=first_record.summary_counts.ref_base,
            alternate_bases=[vcf_constants.GVCF_ALT_ALLELE],
            start=first_record.summary_counts.position,
            end=last_record.summary_counts.position + 1,
            calls=[call])
      else:
        # After evaluating the effect of including sites with contradictory GL
        # (where the value for hom_ref is not maximal), we concluded that
        # un-calling these sites (by setting its genotype "./.") is better
        # for cohort merging.
        # See internal for detail.
        for elt in combinable:
          uncalled_gt = [-1, -1]
          call = variants_pb2.VariantCall(
              call_set_name=self.options.sample_name,
              genotype=uncalled_gt,
              genotype_likelihood=elt.likelihoods)
          variantcall_utils.set_gq(call, elt.raw_gq)
          variantcall_utils.set_min_dp(call, elt.read_depth)
          yield variants_pb2.Variant(
              reference_name=elt.summary_counts.reference_name,
              reference_bases=elt.summary_counts.ref_base,
              alternate_bases=[vcf_constants.GVCF_ALT_ALLELE],
              start=elt.summary_counts.position,
              end=elt.summary_counts.position + 1,
              calls=[call])

</source>
</class>

<class classid="5" nclones="3" nlines="11" similarity="91">
<source file="systems/deepvariant-1.0.0/deepvariant/vcf_candidate_importer_test.py" startline="74" endline="88" pcid="173">
  def fake_allele_counter(self, start_pos, counts):
    allele_counter = mock.Mock()
    # pylint: disable=g-complex-comprehension
    allele_counter.summary_counts.return_value = [
        deepvariant_pb2.AlleleCountSummary(
            ref_supporting_read_count=n_ref,
            total_read_count=n_ref + n_alt,
            ref_base=ref,
            reference_name='chr1',
            position=start_pos + i)
        for i, (n_alt, n_ref, ref) in enumerate(counts)
    ]
    # pylint: enable=g-complex-comprehension
    return allele_counter

</source>
<source file="systems/deepvariant-1.0.0/deepvariant/very_sensitive_caller_test.py" startline="70" endline="84" pcid="241">
  def fake_allele_counter(self, start_pos, counts):
    allele_counter = mock.Mock()
    # pylint: disable=g-complex-comprehension
    allele_counter.summary_counts.return_value = [
        deepvariant_pb2.AlleleCountSummary(
            ref_supporting_read_count=n_ref,
            total_read_count=n_ref + n_alt,
            ref_base=ref,
            reference_name='chr1',
            position=start_pos + i)
        for i, (n_alt, n_ref, ref) in enumerate(counts)
    ]
    # pylint: enable=g-complex-comprehension
    return allele_counter

</source>
<source file="systems/deepvariant-1.0.0/deeptrio/very_sensitive_caller_test.py" startline="71" endline="86" pcid="358">
  def fake_allele_counter(self, start_pos, counts):
    allele_counter = mock.Mock()
    # pylint: disable=g-complex-comprehension
    allele_counter.summary_counts.return_value = [
        deepvariant_pb2.AlleleCountSummary(
            ref_supporting_read_count=n_ref,
            total_read_count=n_ref + n_alt,
            ref_base=ref,
            reference_name='chr1',
            position=start_pos + i)
        for i, (n_alt, n_ref, ref) in enumerate(counts)
    ]
    # pylint: enable=g-complex-comprehension
    allele_counter.counts.return_value = counts
    return allele_counter

</source>
</class>

<class classid="6" nclones="2" nlines="21" similarity="90">
<source file="systems/deepvariant-1.0.0/deepvariant/vcf_candidate_importer_test.py" startline="89" endline="126" pcid="174">
  def test_calls_from_vcf(self):
    # Our test AlleleCounts are 5 positions:
    #
    # 10: A ref [no reads]
    # 11: G/C variant
    # 12: G ref [no reads]
    # 13: G ref [no reads]
    # 14: T/C variant
    #
    # The ref sites have no reads for ref or any alt simply because it
    # simplifies comparing them with the expected variant genotype likelihoods.
    # We aren't testing the correctness of the gvcf calculation here (that's
    # elsewhere) but rather focusing here on the separation of variants from
    # gvcf records, and the automatic merging of the gvcf blocks.
    allele_counter = self.fake_allele_counter(10, [
        (0, 0, 'A'),
        (10, 10, 'G'),
        (0, 0, 'G'),
        (0, 0, 'G'),
        (10, 10, 'T'),
    ])
    fake_candidates = [
        deepvariant_pb2.DeepVariantCall(
            variant=test_utils.make_variant(alleles=['G', 'C'], start=11)),
        deepvariant_pb2.DeepVariantCall(
            variant=test_utils.make_variant(alleles=['T', 'C'], start=14)),
    ]

    caller = self.make_test_caller(0.01, 100)
    with mock.patch.object(caller, 'cpp_variant_caller') as mock_cpp:
      mock_cpp.calls_from_vcf.return_value = fake_candidates
      candidates, _ = caller.calls_and_gvcfs(allele_counter, False)

    mock_cpp.calls_from_vcf.assert_called_once_with(allele_counter,
                                                    caller.vcf_reader)
    self.assertEqual(candidates, fake_candidates)

  # Golden sets are created with learning/genomics/internal/create_golden.sh.
</source>
<source file="systems/deepvariant-1.0.0/deepvariant/very_sensitive_caller_test.py" startline="85" endline="121" pcid="242">
  def test_calls_from_allele_counts(self):
    # Our test AlleleCounts are 5 positions:
    #
    # 10: A ref [no reads]
    # 11: G/C variant
    # 12: G ref [no reads]
    # 13: G ref [no reads]
    # 14: T/C variant
    #
    # The ref sites have no reads for ref or any alt simply because it
    # simplifies comparing them with the expected variant genotype likelihoods.
    # We aren't testing the correctness of the gvcf calculation here (that's
    # elsewhere) but rather focusing here on the separation of variants from
    # gvcf records, and the automatic merging of the gvcf blocks.
    allele_counter = self.fake_allele_counter(10, [
        (0, 0, 'A'),
        (10, 10, 'G'),
        (0, 0, 'G'),
        (0, 0, 'G'),
        (10, 10, 'T'),
    ])
    fake_candidates = [
        deepvariant_pb2.DeepVariantCall(
            variant=test_utils.make_variant(alleles=['G', 'C'], start=11)),
        deepvariant_pb2.DeepVariantCall(
            variant=test_utils.make_variant(alleles=['T', 'C'], start=14)),
    ]

    caller = self.make_test_caller(0.01, 100)
    with mock.patch.object(caller, 'cpp_variant_caller') as mock_cpp:
      mock_cpp.calls_from_allele_counter.return_value = fake_candidates
      candidates, _ = caller.calls_and_gvcfs(allele_counter, False)

    mock_cpp.calls_from_allele_counter.assert_called_once_with(allele_counter)
    self.assertEqual(candidates, fake_candidates)


</source>
</class>

<class classid="7" nclones="2" nlines="28" similarity="92">
<source file="systems/deepvariant-1.0.0/deepvariant/labeler/variant_labeler.py" startline="208" endline="276" pcid="188">
def _genotype_from_matched_truth(candidate_variant, truth_variant):
  """Gets the diploid genotype for candidate_variant from matched truth_variant.

  This method figures out the genotype for candidate_variant by matching alleles
  in candidate_variant with those used by the genotype assigned to
  truth_variant. For example, if candidate is A/C and truth is A/C with a 0/1
  genotype, then this function would return (0, 1) indicating that there's one
  copy of the A allele and one of C in truth. If the true genotype is 1/1, then
  this routine would return (1, 1).

  The routine allows candidate_variant and truth_variant to differ in both
  the number of alternate alleles, and even in the representation of the same
  alleles due to those differences. For example, candidate could be:

      AGT/A/AGTGT => 2 bp deletion and 2 bp insertion

  and truth could have:

      A/AGT => just the simplified 2 bp insertion

  And this routine will correctly equate the AGT/AGTGT allele in candidate
  with the A/AGT in truth and use the number of copies of AGT in truth to
  compute the number of copies of AGTGT when determining the returned genotype.

  Args:
    candidate_variant: Our candidate third_party.nucleus.protos.Variant variant.
    truth_variant: Our third_party.nucleus.protos.Variant truth variant
      containing true alleles and genotypes.

  Returns:
    A tuple genotypes with the same semantics at the genotype field of the
    VariantCall proto.

  Raises:
    ValueError: If candidate_variant is None, truth_variant is None, or
      truth_variant doesn't have genotypes.
  """
  if candidate_variant is None:
    raise ValueError('candidate_variant cannot be None')
  if truth_variant is None:
    raise ValueError('truth_variant cannot be None')
  if not variantcall_utils.has_genotypes(
      variant_utils.only_call(truth_variant)):
    raise ValueError('truth_variant needs genotypes to be used for labeling',
                     truth_variant)

  def _match_one_allele(true_allele):
    if true_allele == truth_variant.reference_bases:
      return 0
    else:
      simplifed_true_allele = variant_utils.simplify_alleles(
          truth_variant.reference_bases, true_allele)
      for alt_index, alt_allele in enumerate(candidate_variant.alternate_bases):
        simplifed_alt_allele = variant_utils.simplify_alleles(
            candidate_variant.reference_bases, alt_allele)
        if simplifed_true_allele == simplifed_alt_allele:
          return alt_index + 1
      # If nothing matched, we don't have this alt, so the alt allele index for
      # should be 0 (i.e., not any alt).
      return 0

  # If our candidate_variant is a reference call, return a (0, 0) genotype.
  if variant_utils.is_ref(candidate_variant):
    return (0, 0)
  else:
    return tuple(
        sorted(
            _match_one_allele(true_allele) for true_allele in
            variant_utils.genotype_as_alleles(truth_variant)))
</source>
<source file="systems/deepvariant-1.0.0/deepvariant/labeler/positional_labeler.py" startline="168" endline="236" pcid="204">
def _genotype_from_matched_truth(candidate_variant, truth_variant):
  """Gets the diploid genotype for candidate_variant from matched truth_variant.

  This method figures out the genotype for candidate_variant by matching alleles
  in candidate_variant with those used by the genotype assigned to
  truth_variant. For example, if candidate is A/C and truth is A/C with a 0/1
  genotype, then this function would return (0, 1) indicating that there's one
  copy of the A allele and one of C in truth. If the true genotype is 1/1, then
  this routine would return (1, 1).

  The routine allows candidate_variant and truth_variant to differ in both
  the number of alternate alleles, and even in the representation of the same
  alleles due to those differences. For example, candidate could be:

      AGT/A/AGTGT => 2 bp deletion and 2 bp insertion

  and truth could have:

      A/AGT => just the simplified 2 bp insertion

  And this routine will correctly equate the AGT/AGTGT allele in candidate
  with the A/AGT in truth and use the number of copies of AGT in truth to
  compute the number of copies of AGTGT when determining the returned genotype.

  Args:
    candidate_variant: Our candidate third_party.nucleus.protos.Variant variant.
    truth_variant: Our third_party.nucleus.protos.Variant truth variant
      containing true alleles and genotypes.

  Returns:
    A tuple genotypes with the same semantics at the genotype field of the
    VariantCall proto.

  Raises:
    ValueError: If candidate_variant is None, truth_variant is None, or
      truth_variant doesn't have genotypes.
  """
  if candidate_variant is None:
    raise ValueError('candidate_variant cannot be None')
  if truth_variant is None:
    raise ValueError('truth_variant cannot be None')
  if not variantcall_utils.has_genotypes(
      variant_utils.only_call(truth_variant)):
    raise ValueError('truth_variant needs genotypes to be used for labeling',
                     truth_variant)

  def _match_one_allele(true_allele):
    if true_allele == truth_variant.reference_bases:
      return 0
    else:
      simplified_true_allele = variant_utils.simplify_alleles(
          truth_variant.reference_bases, true_allele)
      for alt_index, alt_allele in enumerate(candidate_variant.alternate_bases):
        simplified_alt_allele = variant_utils.simplify_alleles(
            candidate_variant.reference_bases, alt_allele)
        if simplified_true_allele == simplified_alt_allele:
          return alt_index + 1
      # If nothing matched, we don't have this alt, so the alt allele index for
      # should be 0 (i.e., not any alt).
      return 0

  # If our candidate_variant is a reference call, return a (0, 0) genotype.
  if variant_utils.is_ref(candidate_variant):
    return (0, 0)
  else:
    return tuple(
        _match_one_allele(true_allele)
        for true_allele in variant_utils.genotype_as_alleles(
            variant_utils.unphase_all_genotypes(truth_variant)))
</source>
</class>

<class classid="8" nclones="2" nlines="13" similarity="100">
<source file="systems/deepvariant-1.0.0/deepvariant/show_examples_test.py" startline="134" endline="147" pcid="215">
  def test_show_examples_end2end_calling_examples(self):
    output_prefix = test_utils.test_tmpfile('calling')
    FLAGS.examples = testdata.GOLDEN_CALLING_EXAMPLES
    FLAGS.output = output_prefix
    show_examples.run()
    ls = glob.glob('{}*'.format(output_prefix))
    filenames = [os.path.basename(path) for path in ls]
    self.assertTrue(
        all(['calling_channels' in filename for filename in filenames]))
    self.assertTrue(all([filename.endswith('.png') for filename in filenames]))
    self.assertFalse(
        any(['label' in filename for filename in filenames]),
        msg='Calling examples should NOT produce labeled images.')

</source>
<source file="systems/deepvariant-1.0.0/deepvariant/show_examples_test.py" startline="149" endline="162" pcid="216">
  def test_show_examples_end2end_training_examples(self):
    output_prefix = test_utils.test_tmpfile('training')
    FLAGS.examples = testdata.GOLDEN_TRAINING_EXAMPLES
    FLAGS.output = output_prefix
    show_examples.run()
    ls = glob.glob('{}*'.format(output_prefix))
    filenames = [os.path.basename(path) for path in ls]
    self.assertTrue(
        all(['training_channels' in filename for filename in filenames]))
    self.assertTrue(all([filename.endswith('.png') for filename in filenames]))
    self.assertTrue(
        all(['label' in filename for filename in filenames]),
        msg='Training examples should produce labeled images.')

</source>
</class>

<class classid="9" nclones="2" nlines="14" similarity="73">
<source file="systems/deepvariant-1.0.0/deepvariant/realigner/python/ssw_wrap_test.py" startline="55" endline="71" pcid="279">
  def test_Align(self):
    """Tests the Align method."""
    aligner = ssw.Aligner()
    filter_ = ssw.Filter()
    length = aligner.set_reference_sequence(REF)
    self.assertLen(REF, length)
    alignment = aligner.align(QUERY, filter_)
    self.assertEqual(21, alignment.sw_score)
    self.assertEqual(8, alignment.sw_score_next_best)
    self.assertEqual(8, alignment.ref_begin)
    self.assertEqual(21, alignment.ref_end)
    self.assertEqual(0, alignment.query_begin)
    self.assertEqual(14, alignment.query_end)
    self.assertEqual(4, alignment.ref_end_next_best)
    self.assertEqual(2, alignment.mismatches)
    self.assertEqual(six.b('4=1X4=1I5='), alignment.cigar_string)

</source>
<source file="systems/deepvariant-1.0.0/deepvariant/realigner/python/ssw_wrap_test.py" startline="72" endline="86" pcid="280">
  def test_Align2_reversed(self):
    """Tests the Align method, reversing query and ref from above."""
    aligner = ssw.Aligner()
    filter_ = ssw.Filter()
    aligner.set_reference_sequence(QUERY)
    alignment = aligner.align(REF, filter_)
    self.assertEqual(21, alignment.sw_score)
    self.assertEqual(8, alignment.query_begin)
    self.assertEqual(21, alignment.query_end)
    self.assertEqual(0, alignment.ref_begin)
    self.assertEqual(14, alignment.ref_end)
    self.assertEqual(2, alignment.mismatches)
    self.assertEqual(six.b('8S4=1X4=1D5=17S'), alignment.cigar_string)


</source>
</class>

<class classid="10" nclones="2" nlines="18" similarity="100">
<source file="systems/deepvariant-1.0.0/deepvariant/realigner/python/ssw_misc_test.py" startline="51" endline="71" pcid="282">
  def test_short(self):
    """Test very short strings."""
    ref = 'tttt'
    query = 'ttAtt'
    match = 4
    mismatch = 2
    gap_extend_penalty = 2
    gap_open_penalty = 4

    aligner = ssw.Aligner.construct(
        match_score=match,
        mismatch_penalty=mismatch,
        gap_opening_penalty=gap_open_penalty,
        gap_extending_penalty=gap_extend_penalty)
    filter_ = ssw.Filter()
    length = aligner.set_reference_sequence(ref)
    self.assertLen(ref, length)
    alignment = aligner.align(query, filter_)
    p(alignment)
    self.assertEqual(six.b('2=1I2='), alignment.cigar_string)

</source>
<source file="systems/deepvariant-1.0.0/deepvariant/realigner/python/ssw_misc_test.py" startline="72" endline="93" pcid="283">
  def test_longer(self):
    """Test longer strings, so the second-best alignment is considered."""
    ref = 'TTTTGGGGGGGGGGGGG'
    query = 'TTATTGGGGGGGGGGGGG'
    match = 4
    mismatch = 2
    gap_extend_penalty = 2
    gap_open_penalty = 4

    aligner = ssw.Aligner.construct(
        match_score=match,
        mismatch_penalty=mismatch,
        gap_opening_penalty=gap_open_penalty,
        gap_extending_penalty=gap_extend_penalty)
    filter_ = ssw.Filter()
    length = aligner.set_reference_sequence(ref)
    self.assertLen(ref, length)
    alignment = aligner.align(query, filter_)
    p(alignment)
    self.assertEqual(six.b('2=1I15='), alignment.cigar_string)


</source>
</class>

<class classid="11" nclones="2" nlines="28" similarity="89">
<source file="systems/deepvariant-1.0.0/deepvariant/python/variant_calling_wrap_test.py" startline="58" endline="94" pcid="319">
  def test_call_from_allele_counter(self):
    ref = fasta.IndexedFastaReader(testdata.CHR20_FASTA)
    sam_reader = sam.SamReader(testdata.CHR20_BAM)
    size = 1000
    region = ranges.make_range('chr20', 10000000, 10000000 + size)
    allele_counter = _allelecounter.AlleleCounter(
        ref.c_reader, region,
        deepvariant_pb2.AlleleCounterOptions(partition_size=size))
    caller = variant_calling.VariantCaller(
        deepvariant_pb2.VariantCallerOptions(
            min_count_snps=2,
            min_count_indels=2,
            min_fraction_snps=0.12,
            min_fraction_indels=0.12,
            sample_name='sample_name',
            p_error=0.001,
            max_gq=50,
            gq_resolution=1,
            ploidy=2))

    # Grab all of the reads in our region and add them to the allele_counter.
    reads = list(sam_reader.query(region))
    self.assertNotEmpty(reads)
    for read in reads:
      allele_counter.add(read, 'sample_id')

    # Get the candidates records for this whole region.
    candidates = caller.calls_from_allele_counter(allele_counter)

    # We should have at least some candidates and some gvcf records.
    self.assertNotEmpty(candidates)

    # Each candidate should be a DeepVariantCall.
    for candidate in candidates:
      self.assertIsInstance(candidate, deepvariant_pb2.DeepVariantCall)


</source>
<source file="systems/deepvariant-1.0.0/deeptrio/python/variant_calling_deeptrio_wrap_test.py" startline="57" endline="95" pcid="361">
  def test_call_from_allele_counter(self):
    ref = fasta.IndexedFastaReader(testdata.CHR20_FASTA)
    sam_reader = sam.SamReader(testdata.CHR20_BAM)
    size = 1000
    region = ranges.make_range('chr20', 10000000, 10000000 + size)
    allele_counter = _allelecounter.AlleleCounter(
        ref.c_reader, region,
        deepvariant_pb2.AlleleCounterOptions(partition_size=size))
    caller = variant_calling_deeptrio.VariantCaller(
        deepvariant_pb2.VariantCallerOptions(
            min_count_snps=2,
            min_count_indels=2,
            min_fraction_snps=0.12,
            min_fraction_indels=0.12,
            sample_name='sample_name',
            p_error=0.001,
            max_gq=50,
            gq_resolution=1,
            ploidy=2))

    # Grab all of the reads in our region and add them to the allele_counter.
    reads = list(sam_reader.query(region))
    self.assertNotEmpty(reads)
    for read in reads:
      allele_counter.add(read, 'sample_id')

    # Get the candidates records for this whole region.
    allele_counts = {}
    allele_counts['sample_id'] = allele_counter.counts()
    candidates = caller.calls_from_allele_counts(allele_counts, 'sample_id')

    # We should have at least some candidates and some gvcf records.
    self.assertNotEmpty(candidates)

    # Each candidate should be a DeepVariantCall.
    for candidate in candidates:
      self.assertIsInstance(candidate, deepvariant_pb2.DeepVariantCall)


</source>
</class>

<class classid="12" nclones="2" nlines="12" similarity="91">
<source file="systems/deepvariant-1.0.0/third_party/nucleus/util/vis_test.py" startline="186" endline="200" pcid="411">
  def test_save_to_png(self, shape, should_succeed):
    arr = _image_array(shape)

    if should_succeed:
      temp_dir = self.create_tempdir().full_path
      output_path = os.path.join(temp_dir, 'test.png')
      # check the file doesn't already exist before function runs
      self.assertEmpty(glob.glob(output_path))
      vis.save_to_png(arr, path=output_path)
      self.assertLen(glob.glob(output_path), 1)
    else:
      self.assertRaisesWithPredicateMatch(
          ValueError, lambda x: str(x).index('dimensions') != -1,
          vis.save_to_png, arr)

</source>
<source file="systems/deepvariant-1.0.0/third_party/nucleus/util/vis_test.py" startline="208" endline="222" pcid="412">
  def test_array_to_png_works_with_floats(self, shape, should_succeed):
    arr = np.random.random(shape)

    if should_succeed:
      temp_dir = self.create_tempdir().full_path
      output_path = os.path.join(temp_dir, 'test.png')
      # Check the file doesn't already exist before function runs.
      self.assertEmpty(glob.glob(output_path))
      vis.array_to_png(arr, path=output_path)
      self.assertLen(glob.glob(output_path), 1)
    else:
      self.assertRaisesWithPredicateMatch(
          ValueError, lambda x: str(x).index('dimensions') != -1,
          vis.array_to_png, arr)

</source>
</class>

<class classid="13" nclones="2" nlines="15" similarity="81">
<source file="systems/deepvariant-1.0.0/third_party/nucleus/io/python/vcf_writer_wrap_test.py" startline="284" endline="311" pcid="693">
  def test_round_trip_vcf(self, test_datum_name):
    # Round-trip variants through writing and reading:
    # 1. Read variants v1 from VcfReader;
    # 2. Write v1 to vcf using our VcfWriter;
    # 3. Read back in using VcfReader -- v2;
    # 4. compare v1 and v2.
    in_file = test_utils.genomics_core_testdata(test_datum_name)
    out_file = test_utils.test_tmpfile('output_' + test_datum_name)

    v1_reader = vcf.VcfReader(in_file)
    v1_records = list(v1_reader.iterate())
    self.assertTrue(v1_records, 'Reader failed to find records')

    header = copy.deepcopy(v1_reader.header)
    writer_options = variants_pb2.VcfWriterOptions()

    with vcf_writer.VcfWriter.to_file(out_file, header,
                                      writer_options) as writer:
      for record in v1_records:
        writer.write(record)

    v2_reader = vcf.VcfReader(out_file)
    v2_records = list(v2_reader.iterate())

    self.assertEqual(v1_records, v2_records,
                     'Round-tripped variants not as expected')


</source>
<source file="systems/deepvariant-1.0.0/third_party/nucleus/io/python/fastq_writer_wrap_test.py" startline="120" endline="144" pcid="719">
  def test_round_trip_fastq(self, test_datum_name):
    # Round-trip FASTQ records through writing and reading:
    # 1. Read records v1 from FastqReader;
    # 2. Write v1 to fastq using our FastqWriter;
    # 3. Read back in using FastqReader -- v2;
    # 4. compare v1 and v2.
    in_file = test_utils.genomics_core_testdata(test_datum_name)
    out_file = test_utils.test_tmpfile('output_' + test_datum_name)

    v1_reader = fastq.FastqReader(in_file)
    v1_records = list(v1_reader.iterate())
    self.assertTrue(v1_records, 'Reader failed to find records')

    writer_options = fastq_pb2.FastqWriterOptions()

    with fastq_writer.FastqWriter.to_file(out_file, writer_options) as writer:
      for record in v1_records:
        writer.write(record)

    v2_reader = fastq.FastqReader(out_file)
    v2_records = list(v2_reader.iterate())
    self.assertEqual(v1_records, v2_records,
                     'Round-tripped FASTQ files not as expected')


</source>
</class>

<class classid="14" nclones="3" nlines="13" similarity="76">
<source file="systems/deepvariant-1.0.0/third_party/nucleus/io/python/gff_writer_wrap_test.py" startline="65" endline="81" pcid="712">
  def test_writing_canned_records(self):
    """Tests writing all the records that are 'canned' in our tfrecord file."""
    # This file is in TFRecord format.
    tfrecord_file = test_utils.genomics_core_testdata(
        'test_features.gff.tfrecord')
    writer_options = gff_pb2.GffWriterOptions()
    gff_records = list(
        tfrecord.read_tfrecords(tfrecord_file, proto=gff_pb2.GffRecord))
    out_fname = test_utils.test_tmpfile('output.gff')
    with gff_writer.GffWriter.to_file(out_fname, self.header,
                                      writer_options) as writer:
      for record in gff_records:
        writer.write(record)

    with open(out_fname) as f:
      self.assertEqual(f.readlines(), self.expected_gff_content)

</source>
<source file="systems/deepvariant-1.0.0/third_party/nucleus/io/python/fastq_writer_wrap_test.py" startline="80" endline="96" pcid="716">
  def test_writing_canned_records(self):
    """Tests writing all the variants that are 'canned' in our tfrecord file."""
    # This file is in TFRecord format.
    tfrecord_file = test_utils.genomics_core_testdata(
        'test_reads.fastq.tfrecord')

    writer_options = fastq_pb2.FastqWriterOptions()
    fastq_records = list(
        tfrecord.read_tfrecords(tfrecord_file, proto=fastq_pb2.FastqRecord))
    out_fname = test_utils.test_tmpfile('output.fastq')
    with fastq_writer.FastqWriter.to_file(out_fname, writer_options) as writer:
      for record in fastq_records:
        writer.write(record)

    with gfile.Open(out_fname, 'r') as f:
      self.assertEqual(f.readlines(), self.expected_fastq_content)

</source>
<source file="systems/deepvariant-1.0.0/third_party/nucleus/io/python/bed_writer_wrap_test.py" startline="67" endline="85" pcid="721">
  def test_writing_canned_records(self):
    """Tests writing all the records that are 'canned' in our tfrecord file."""
    # This file is in TFRecord format.
    tfrecord_file = test_utils.genomics_core_testdata(
        'test_regions.bed.tfrecord')

    header = bed_pb2.BedHeader(num_fields=12)
    writer_options = bed_pb2.BedWriterOptions()
    bed_records = list(
        tfrecord.read_tfrecords(tfrecord_file, proto=bed_pb2.BedRecord))
    out_fname = test_utils.test_tmpfile('output.bed')
    with bed_writer.BedWriter.to_file(out_fname, header,
                                      writer_options) as writer:
      for record in bed_records:
        writer.write(record)

    with gfile.Open(out_fname, 'r') as f:
      self.assertEqual(f.readlines(), self.expected_bed_content)

</source>
</class>

</clones>
