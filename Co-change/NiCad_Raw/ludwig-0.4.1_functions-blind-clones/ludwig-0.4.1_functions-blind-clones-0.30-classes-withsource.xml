<clones>
<systeminfo processor="nicad6" system="ludwig-0.4.1" granularity="functions-blind" threshold="30%" minlines="10" maxlines="2500"/>
<cloneinfo npcs="1142" npairs="734"/>
<runinfo ncompares="32225" cputime="76191"/>
<classinfo nclasses="38"/>

<class classid="1" nclones="3" nlines="18" similarity="70">
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_ray.py" startline="224" endline="245" pcid="10">

@pytest.mark.distributed
def test_ray_image():
    with tempfile.TemporaryDirectory() as tmpdir:
        image_dest_folder = os.path.join(tmpdir, 'generated_images')
        input_features = [
            image_feature(
                folder=image_dest_folder,
                encoder='resnet',
                preprocessing={
                    'in_memory': True,
                    'height': 12,
                    'width': 12,
                    'num_channels': 3,
                    'num_processes': 5
                },
                fc_size=16,
                num_filters=8
            ),
        ]
        output_features = [binary_feature()]
        run_test_parquet(input_features, output_features)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_ray.py" startline="287" endline="306" pcid="14">

@pytest.mark.distributed
def test_ray_lazy_load_image_error():
    with tempfile.TemporaryDirectory() as tmpdir:
        image_dest_folder = os.path.join(tmpdir, 'generated_images')
        input_features = [
            image_feature(
                folder=image_dest_folder,
                encoder='resnet',
                preprocessing={
                    'in_memory': False,
                    'height': 12,
                    'width': 12,
                    'num_channels': 3,
                    'num_processes': 5
                },
                fc_size=16,
                num_filters=8
            ),
        ]
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_experiment.py" startline="782" endline="807" pcid="189">
        input_features[0]['encoder'] = encoder
        run_experiment(input_features, output_features, dataset=rel_path)


def test_visual_question_answering(csv_filename):
    image_dest_folder = os.path.join(os.getcwd(), 'generated_images')
    input_features = [
        image_feature(
            folder=image_dest_folder,
            encoder='resnet',
            preprocessing={
                'in_memory': True,
                'height': 8,
                'width': 8,
                'num_channels': 3,
                'num_processes': 5
            },
            fc_size=8,
            num_filters=8
        ),
        text_feature(encoder='embed', min_len=1, level='word'),
    ]
    output_features = [sequence_feature(decoder='generator', cell_type='lstm')]
    rel_path = generate_data(input_features, output_features, csv_filename)
    run_experiment(input_features, output_features, dataset=rel_path)

</source>
</class>

<class classid="2" nclones="3" nlines="27" similarity="82">
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_kfold_cv.py" startline="180" endline="234" pcid="16">
def test_kfold_cv_api_from_file():
    # k-fold_cross_validate api with config_file
    num_folds = 3

    # setup temporary directory to run test
    with tempfile.TemporaryDirectory() as tmpdir:

        # setup required data structures for test
        training_data_fp = os.path.join(tmpdir, 'train.csv')
        config_fp = os.path.join(tmpdir, 'config.yaml')

        # generate synthetic data for the test
        input_features = [
            numerical_feature(normalization='zscore'),
            numerical_feature(normalization='zscore')
        ]

        output_features = [
            category_feature(vocab_size=2, reduce_input='sum')
        ]

        generate_data(input_features, output_features, training_data_fp)

        # generate config file
        config = {
            'input_features': input_features,
            'output_features': output_features,
            'combiner': {'type': 'concat', 'fc_size': 14},
            'training': {'epochs': 2}
        }

        with open(config_fp, 'w') as f:
            yaml.dump(config, f)

        # test kfold_cross_validate api with config file

        # execute k-fold cross validation run
        (
            kfold_cv_stats,
            kfold_split_indices
        ) = kfold_cross_validate(
            3,
            config=config_fp,
            dataset=training_data_fp
        )

        # correct structure for results from kfold cv
        for key in ['fold_' + str(i + 1)
                    for i in range(num_folds)] + ['overall']:
            assert key in kfold_cv_stats

        for key in ['fold_' + str(i + 1) for i in range(num_folds)]:
            assert key in kfold_split_indices


</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_kfold_cv.py" startline="296" endline="346" pcid="18">
def test_kfold_cv_dataset_formats(data_format):
    # k-fold_cross_validate api with in-memory config
    num_folds = 3

    # setup temporary directory to run test
    with tempfile.TemporaryDirectory() as tmpdir:

        # setup required data structures for test
        training_data_fp = os.path.join(tmpdir, 'train.csv')

        # generate synthetic data for the test
        input_features = [
            numerical_feature(normalization='zscore'),
            numerical_feature(normalization='zscore')
        ]

        output_features = [
            numerical_feature()
        ]

        generate_data(input_features, output_features, training_data_fp)
        dataset_to_use = create_data_set_to_use(data_format, training_data_fp)

        # generate config file
        config = {
            'input_features': input_features,
            'output_features': output_features,
            'combiner': {'type': 'concat', 'fc_size': 14},
            'training': {'epochs': 2}
        }

        # test kfold_cross_validate api with config in-memory

        # execute k-fold cross validation run
        (
            kfold_cv_stats,
            kfold_split_indices
        ) = kfold_cross_validate(
            3,
            config=config,
            dataset=dataset_to_use
        )

        # correct structure for results from kfold cv
        for key in ['fold_' + str(i + 1)
                    for i in range(num_folds)] + ['overall']:
            assert key in kfold_cv_stats

        for key in ['fold_' + str(i + 1) for i in range(num_folds)]:
            assert key in kfold_split_indices

</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_kfold_cv.py" startline="236" endline="287" pcid="17">
def test_kfold_cv_api_in_memory():
    # k-fold_cross_validate api with in-memory config
    num_folds = 3

    # setup temporary directory to run test
    with tempfile.TemporaryDirectory() as tmpdir:

        # setup required data structures for test
        training_data_fp = os.path.join(tmpdir, 'train.csv')

        # generate synthetic data for the test
        input_features = [
            numerical_feature(normalization='zscore'),
            numerical_feature(normalization='zscore')
        ]

        output_features = [
            numerical_feature()
        ]

        generate_data(input_features, output_features, training_data_fp)

        # generate config file
        config = {
            'input_features': input_features,
            'output_features': output_features,
            'combiner': {'type': 'concat', 'fc_size': 14},
            'training': {'epochs': 2}
        }

        # test kfold_cross_validate api with config in-memory

        # execute k-fold cross validation run
        (
            kfold_cv_stats,
            kfold_split_indices
        ) = kfold_cross_validate(
            3,
            config=config,
            dataset=training_data_fp
        )

        # correct structure for results from kfold cv
        for key in ['fold_' + str(i + 1)
                    for i in range(num_folds)] + ['overall']:
            assert key in kfold_cv_stats

        for key in ['fold_' + str(i + 1) for i in range(num_folds)]:
            assert key in kfold_split_indices



</source>
</class>

<class classid="3" nclones="25" nlines="48" similarity="71">
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization.py" startline="95" endline="140" pcid="21">
        content['config']['output_features'][output_feature]['name']
    return output_feature_name


def test_visualization_learning_curves_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [text_feature(encoder='parallel_cnn')]
    output_features = [category_feature()]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    input_features[0]['encoder'] = 'parallel_cnn'
    exp_dir_name = run_experiment(
        input_features,
        output_features,
        dataset=rel_path
    )

    vis_output_pattern_pdf = os.path.join(exp_dir_name, '*.pdf')
    vis_output_pattern_png = os.path.join(exp_dir_name, '*.png')
    train_stats = os.path.join(exp_dir_name, 'training_statistics.json')
    test_cmd_pdf = ['python',
                    '-m',
                    'ludwig.visualize',
                    '--visualization',
                    'learning_curves',
                    '--training_statistics',
                    train_stats,
                    '-od', exp_dir_name]
    test_cmd_png = test_cmd_pdf.copy() + ['-ff', 'png']

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(
            command,
        )
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 4 == len(figure_cnt)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization.py" startline="141" endline="192" pcid="22">

    shutil.rmtree(exp_dir_name, ignore_errors=True)


def test_visualization_confusion_matrix_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [text_feature(encoder='parallel_cnn')]
    output_features = [category_feature()]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    input_features[0]['encoder'] = 'parallel_cnn'
    exp_dir_name = run_experiment(
        input_features,
        output_features,
        dataset=rel_path
    )
    vis_output_pattern_pdf = os.path.join(exp_dir_name, '*.pdf')
    vis_output_pattern_png = os.path.join(exp_dir_name, '*.png')
    experiment_source_data_name = csv_filename.split('.')[0]
    ground_truth_metadata = experiment_source_data_name + '.meta.json'
    test_stats = os.path.join(exp_dir_name, 'test_statistics.json')
    test_cmd_pdf = ['python',
                    '-m',
                    'ludwig.visualize',
                    '--visualization',
                    'confusion_matrix',
                    '--test_statistics',
                    test_stats,
                    '--ground_truth_metadata',
                    ground_truth_metadata,
                    '-od', exp_dir_name]
    test_cmd_png = test_cmd_pdf.copy() + ['-ff', 'png']
    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 2 == len(figure_cnt)

    shutil.rmtree(exp_dir_name, ignore_errors=True)
    shutil.rmtree('results', ignore_errors=True)
    for file in glob.glob(experiment_source_data_name + '.*'):
        try:
            os.remove(file)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization.py" startline="1702" endline="1762" pcid="45">
        except OSError as e:  # if failed, report it back to the user
            print("Error: %s - %s." % (e.filename, e.strerror))


def test_visualization_frequency_vs_f1_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [
        category_feature(vocab_size=10)
    ]
    output_features = [category_feature(vocab_size=2, reduce_input='sum')]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment(
        input_features,
        output_features,
        dataset=rel_path
    )
    vis_output_pattern_pdf = os.path.join(exp_dir_name, '*.pdf')
    vis_output_pattern_png = os.path.join(exp_dir_name, '*.png')
    output_feature_name = get_output_feature_name(exp_dir_name)
    test_stats = os.path.join(exp_dir_name, 'test_statistics.json')
    experiment_source_data_name = csv_filename.split('.')[0]
    ground_truth_metadata = experiment_source_data_name + '.meta.json'
    test_cmd_pdf = ['python',
                    '-m',
                    'ludwig.visualize',
                    '--visualization',
                    'frequency_vs_f1',
                    '--ground_truth_metadata',
                    ground_truth_metadata,
                    '--output_feature_name',
                    output_feature_name,
                    '--test_statistics',
                    test_stats,
                    test_stats,
                    '--model_names',
                    'Model1',
                    'Model2',
                    '-od', exp_dir_name]
    test_cmd_png = test_cmd_pdf.copy() + ['-ff', 'png']

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 2 == len(figure_cnt)

    shutil.rmtree(exp_dir_name, ignore_errors=True)
    shutil.rmtree('results', ignore_errors=True)
    for file in glob.glob(experiment_source_data_name + '.*'):
        try:
            os.remove(file)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization.py" startline="193" endline="254" pcid="23">
        except OSError as e:  # if failed, report it back to the user
            print("Error: %s - %s." % (e.filename, e.strerror))


def test_visualization_compare_performance_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    Compare performance between two models. To reduce test complexity
    one model is compared to it self.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [text_feature(encoder='parallel_cnn')]
    output_features = [category_feature()]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    input_features[0]['encoder'] = 'parallel_cnn'
    exp_dir_name = run_experiment(
        input_features,
        output_features,
        dataset=rel_path
    )
    vis_output_pattern_pdf = os.path.join(exp_dir_name, '*.pdf')
    vis_output_pattern_png = os.path.join(exp_dir_name, '*.png')
    experiment_source_data_name = csv_filename.split('.')[0]
    test_stats = os.path.join(exp_dir_name, 'test_statistics.json')

    test_cmd_pdf = ['python',
                    '-m',
                    'ludwig.visualize',
                    '--visualization',
                    'compare_performance',
                    '--test_statistics',
                    test_stats,
                    test_stats,
                    '-m',
                    'Model1',
                    'Model2',
                    '-od', exp_dir_name]
    test_cmd_png = test_cmd_pdf.copy() + ['-ff', 'png']

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE
        )
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)

    shutil.rmtree(exp_dir_name, ignore_errors=True)
    shutil.rmtree('results', ignore_errors=True)
    for file in glob.glob(experiment_source_data_name + '.*'):
        try:
            os.remove(file)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization.py" startline="669" endline="728" pcid="30">
        except OSError as e:  # if failed, report it back to the user
            print("Error: %s - %s." % (e.filename, e.strerror))


def test_visualization_compare_classifiers_multiclass_multimetric_output_saved(
        csv_filename
):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [
        category_feature(vocab_size=10)
    ]
    output_features = [category_feature(vocab_size=2, reduce_input='sum')]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment(
        input_features,
        output_features,
        dataset=rel_path
    )
    vis_output_pattern_pdf = os.path.join(exp_dir_name, '*.pdf')
    vis_output_pattern_png = os.path.join(exp_dir_name, '*.png')
    output_feature_name = get_output_feature_name(exp_dir_name)
    test_stats = os.path.join(exp_dir_name, 'test_statistics.json')
    experiment_source_data_name = csv_filename.split('.')[0]
    ground_truth_metadata = experiment_source_data_name + '.meta.json'
    test_cmd_pdf = ['python',
                    '-m',
                    'ludwig.visualize',
                    '--visualization',
                    'compare_classifiers_multiclass_multimetric',
                    '--output_feature_name',
                    output_feature_name,
                    '--test_statistics',
                    test_stats,
                    test_stats,
                    '--ground_truth_metadata',
                    ground_truth_metadata,
                    '-od', exp_dir_name]
    test_cmd_png = test_cmd_pdf.copy() + ['-ff', 'png']

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 4 == len(figure_cnt)

    shutil.rmtree(exp_dir_name, ignore_errors=True)
    shutil.rmtree('results', ignore_errors=True)
    for file in glob.glob(experiment_source_data_name + '.*'):
        try:
            os.remove(file)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization.py" startline="1510" endline="1565" pcid="42">
        except OSError as e:  # if failed, report it back to the user
            print("Error: %s - %s." % (e.filename, e.strerror))


def test_visualization_roc_curves_from_test_statistics_output_saved(
        csv_filename
):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [binary_feature(), bag_feature()]
    output_features = [binary_feature()]
    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)

    exp_dir_name = run_experiment(
        input_features,
        output_features,
        dataset=rel_path
    )
    vis_output_pattern_pdf = os.path.join(exp_dir_name, '*.pdf')
    vis_output_pattern_png = os.path.join(exp_dir_name, '*.png')
    output_feature_name = get_output_feature_name(exp_dir_name)
    test_stats = os.path.join(exp_dir_name, 'test_statistics.json')
    experiment_source_data_name = csv_filename.split('.')[0]
    test_cmd_pdf = ['python',
                    '-m',
                    'ludwig.visualize',
                    '--visualization',
                    'roc_curves_from_test_statistics',
                    '--output_feature_name',
                    output_feature_name,
                    '--test_statistics',
                    test_stats,
                    '--model_names',
                    'Model1',
                    '-od', exp_dir_name]
    test_cmd_png = test_cmd_pdf.copy() + ['-ff', 'png']

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)

    shutil.rmtree(exp_dir_name, ignore_errors=True)
    shutil.rmtree('results', ignore_errors=True)
    for file in glob.glob(experiment_source_data_name + '.*'):
        try:
            os.remove(file)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization.py" startline="798" endline="866" pcid="32">
        except OSError as e:  # if failed, report it back to the user
            print("Error: %s - %s." % (e.filename, e.strerror))


def test_visualization_compare_classifiers_predictions_csv_output_saved(
        csv_filename
):
    """Ensure pdf and png figures from the experiments can be saved.

    Predictions are loaded form csv file.
    :param csv_filename: csv fixture from tests.fixtures.filenames.csv_filename
    :return: None
    """
    input_features = [
        category_feature(vocab_size=10)
    ]
    output_features = [category_feature(vocab_size=2, reduce_input='sum')]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment(
        input_features,
        output_features,
        dataset=rel_path
    )
    vis_output_pattern_pdf = os.path.join(exp_dir_name, '*.pdf')
    vis_output_pattern_png = os.path.join(exp_dir_name, '*.png')
    output_feature_name = get_output_feature_name(exp_dir_name)
    prediction = os.path.join(exp_dir_name, 'predictions.parquet')
    experiment_source_data_name = csv_filename.split('.')[0]
    ground_truth = experiment_source_data_name + '.csv'
    split_file = experiment_source_data_name + '.split.csv'
    test_cmd_pdf = ['python',
                    '-m',
                    'ludwig.visualize',
                    '--visualization',
                    'compare_classifiers_predictions',
                    '--ground_truth',
                    ground_truth,
                    '--output_feature_name',
                    output_feature_name,
                    '--split_file',
                    split_file,
                    '--ground_truth_metadata',
                    exp_dir_name + '/model/training_set_metadata.json',
                    '--predictions',
                    prediction,
                    prediction,
                    '--model_names',
                    'Model1',
                    'Model2',
                    '-od', exp_dir_name]
    test_cmd_png = test_cmd_pdf.copy() + ['-ff', 'png']

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)

    shutil.rmtree(exp_dir_name, ignore_errors=True)
    shutil.rmtree('results', ignore_errors=True)
    for file in glob.glob(experiment_source_data_name + '.*'):
        try:
            os.remove(file)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization.py" startline="325" endline="394" pcid="25">
        except OSError as e:  # if failed, report it back to the user
            print("Error: %s - %s." % (e.filename, e.strerror))


def test_visualization_compare_classifiers_from_prob_npy_output_saved(
        csv_filename
):
    """Ensure pdf and png figures from the experiments can be saved.

    Probabilities are loaded from npy file.
    :param csv_filename: csv fixture from tests.fixtures.filenames.csv_filename
    :return: None
    """
    input_features = [
        category_feature(vocab_size=10)
    ]
    output_features = [category_feature(vocab_size=2, reduce_input='sum')]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment(
        input_features,
        output_features,
        dataset=rel_path
    )

    vis_output_pattern_pdf = os.path.join(exp_dir_name, '*.pdf')
    vis_output_pattern_png = os.path.join(exp_dir_name, '*.png')
    output_feature_name = get_output_feature_name(exp_dir_name)
    probability = os.path.join(exp_dir_name, 'predictions.parquet')
    experiment_source_data_name = csv_filename.split('.')[0]
    ground_truth = experiment_source_data_name + '.csv'
    split_file = experiment_source_data_name + '.split.csv'
    test_cmd_pdf = ['python',
                    '-m',
                    'ludwig.visualize',
                    '--visualization',
                    'compare_classifiers_performance_from_prob',
                    '--ground_truth',
                    ground_truth,
                    '--output_feature_name',
                    output_feature_name,
                    '--split_file',
                    split_file,
                    '--ground_truth_metadata',
                    exp_dir_name + '/model/training_set_metadata.json',
                    '--probabilities',
                    probability,
                    probability,
                    '--model_names',
                    'Model1',
                    'Model2',
                    '-od', exp_dir_name]
    test_cmd_png = test_cmd_pdf.copy() + ['-ff', 'png']

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)

    shutil.rmtree(exp_dir_name, ignore_errors=True)
    shutil.rmtree('results', ignore_errors=True)
    for file in glob.glob(experiment_source_data_name + '.*'):
        try:
            os.remove(file)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization.py" startline="1069" endline="1138" pcid="36">
        except OSError as e:  # if failed, report it back to the user
            print("Error: %s - %s." % (e.filename, e.strerror))


def test_visualization_confidence_thresholding_data_vs_acc_subset_output_saved(
        csv_filename
):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [
        category_feature(vocab_size=10)
    ]
    output_features = [category_feature(vocab_size=2, reduce_input='sum')]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment(
        input_features,
        output_features,
        dataset=rel_path
    )
    vis_output_pattern_pdf = os.path.join(exp_dir_name, '*.pdf')
    vis_output_pattern_png = os.path.join(exp_dir_name, '*.png')
    output_feature_name = get_output_feature_name(exp_dir_name)
    probability = os.path.join(exp_dir_name, 'predictions.parquet')
    experiment_source_data_name = csv_filename.split('.')[0]
    ground_truth = experiment_source_data_name + '.csv'
    split_file = experiment_source_data_name + '.split.csv'
    test_cmd_pdf = ['python',
                    '-m',
                    'ludwig.visualize',
                    '--visualization',
                    'confidence_thresholding_data_vs_acc_subset',
                    '--ground_truth',
                    ground_truth,
                    '--output_feature_name',
                    output_feature_name,
                    '--split_file',
                    split_file,
                    '--ground_truth_metadata',
                    exp_dir_name + '/model/training_set_metadata.json',
                    '--probabilities',
                    probability,
                    probability,
                    '--model_names',
                    'Model1',
                    'Model2',
                    '--top_n_classes',
                    '3',
                    '-od', exp_dir_name]
    test_cmd_png = test_cmd_pdf.copy() + ['-ff', 'png']

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)

    shutil.rmtree(exp_dir_name, ignore_errors=True)
    shutil.rmtree('results', ignore_errors=True)
    for file in glob.glob(experiment_source_data_name + '.*'):
        try:
            os.remove(file)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization.py" startline="465" endline="534" pcid="27">
        except OSError as e:  # if failed, report it back to the user
            print("Error: %s - %s." % (e.filename, e.strerror))


def test_visualization_compare_classifiers_from_pred_csv_output_saved(
        csv_filename
):
    """Ensure pdf and png figures from the experiments can be saved.

    Predictions are loaded from csv file.
    :param csv_filename: csv fixture from tests.fixtures.filenames.csv_filename
    :return: None
    """
    input_features = [
        category_feature(vocab_size=10)
    ]
    output_features = [category_feature(vocab_size=2, reduce_input='sum')]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment(
        input_features,
        output_features,
        dataset=rel_path
    )
    vis_output_pattern_pdf = os.path.join(exp_dir_name, '*.pdf')
    vis_output_pattern_png = os.path.join(exp_dir_name, '*.png')
    output_feature_name = get_output_feature_name(exp_dir_name)
    prediction = os.path.join(exp_dir_name, 'predictions.parquet')
    experiment_source_data_name = csv_filename.split('.')[0]
    ground_truth = experiment_source_data_name + '.csv'
    split_file = experiment_source_data_name + '.split.csv'
    ground_truth_metadata = experiment_source_data_name + '.meta.json'
    test_cmd_pdf = ['python',
                    '-m',
                    'ludwig.visualize',
                    '--visualization',
                    'compare_classifiers_performance_from_pred',
                    '--ground_truth_metadata',
                    ground_truth_metadata,
                    '--ground_truth',
                    ground_truth,
                    '--output_feature_name',
                    output_feature_name,
                    '--split_file',
                    split_file,
                    '--predictions',
                    prediction,
                    prediction,
                    '--model_names',
                    'Model1',
                    'Model2',
                    '-od', exp_dir_name]
    test_cmd_png = test_cmd_pdf.copy() + ['-ff', 'png']

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)

    shutil.rmtree(exp_dir_name, ignore_errors=True)
    shutil.rmtree('results', ignore_errors=True)
    for file in glob.glob(experiment_source_data_name + '.*'):
        try:
            os.remove(file)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization.py" startline="1566" endline="1635" pcid="43">
        except OSError as e:  # if failed, report it back to the user
            print("Error: %s - %s." % (e.filename, e.strerror))


def test_visualization_calibration_1_vs_all_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [
        category_feature(vocab_size=10)
    ]
    output_features = [category_feature(vocab_size=2, reduce_input='sum')]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment(
        input_features,
        output_features,
        dataset=rel_path
    )
    vis_output_pattern_pdf = os.path.join(exp_dir_name, '*.pdf')
    vis_output_pattern_png = os.path.join(exp_dir_name, '*.png')
    output_feature_name = get_output_feature_name(exp_dir_name)
    probability = os.path.join(exp_dir_name, 'predictions.parquet')
    experiment_source_data_name = csv_filename.split('.')[0]
    ground_truth = experiment_source_data_name + '.csv'
    split_file = experiment_source_data_name + '.split.csv'
    test_cmd_pdf = ['python',
                    '-m',
                    'ludwig.visualize',
                    '--visualization',
                    'calibration_1_vs_all',
                    '--metrics',
                    'accuracy',
                    '--ground_truth',
                    ground_truth,
                    '--output_feature_name',
                    output_feature_name,
                    '--split_file',
                    split_file,
                    '--ground_truth_metadata',
                    exp_dir_name + '/model/training_set_metadata.json',
                    '--probabilities',
                    probability,
                    probability,
                    '--model_names',
                    'Model1',
                    'Model2',
                    '--top_k',
                    '6',
                    '-od', exp_dir_name]
    test_cmd_png = test_cmd_pdf.copy() + ['-ff', 'png']

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 7 == len(figure_cnt)

    shutil.rmtree(exp_dir_name, ignore_errors=True)
    shutil.rmtree('results', ignore_errors=True)
    for file in glob.glob(experiment_source_data_name + '.*'):
        try:
            os.remove(file)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization.py" startline="1139" endline="1210" pcid="37">
        except OSError as e:  # if failed, report it back to the user
            print("Error: %s - %s." % (e.filename, e.strerror))


def test_vis_confidence_thresholding_data_vs_acc_subset_per_class_output_saved(
        csv_filename
):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [
        category_feature(vocab_size=10)
    ]
    output_features = [category_feature(vocab_size=5, reduce_input='sum')]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment(
        input_features,
        output_features,
        dataset=rel_path
    )
    vis_output_pattern_pdf = os.path.join(exp_dir_name, '*.pdf')
    vis_output_pattern_png = os.path.join(exp_dir_name, '*.png')
    output_feature_name = get_output_feature_name(exp_dir_name)
    probability = os.path.join(exp_dir_name, 'predictions.parquet')
    experiment_source_data_name = csv_filename.split('.')[0]
    ground_truth = experiment_source_data_name + '.csv'
    split_file = experiment_source_data_name + '.split.csv'
    test_cmd_pdf = ['python',
                    '-m',
                    'ludwig.visualize',
                    '--visualization',
                    'confidence_thresholding_data_vs_acc_subset_per_class',
                    '--ground_truth',
                    ground_truth,
                    '--output_feature_name',
                    output_feature_name,
                    '--split_file',
                    split_file,
                    '--ground_truth_metadata',
                    exp_dir_name + '/model/training_set_metadata.json',
                    '--probabilities',
                    probability,
                    probability,
                    '--model_names',
                    'Model1',
                    'Model2',
                    '--top_n_classes',
                    '3',
                    '-od', exp_dir_name]
    test_cmd_png = test_cmd_pdf.copy() + ['-ff', 'png']

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        # 3 figures should be saved because experiment setting top_n_classes = 3
        # hence one figure per class
        assert 3 == len(figure_cnt)

    shutil.rmtree(exp_dir_name, ignore_errors=True)
    shutil.rmtree('results', ignore_errors=True)
    for file in glob.glob(experiment_source_data_name + '.*'):
        try:
            os.remove(file)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization.py" startline="395" endline="464" pcid="26">
        except OSError as e:  # if failed, report it back to the user
            print("Error: %s - %s." % (e.filename, e.strerror))


def test_visualization_compare_classifiers_from_pred_npy_output_saved(
        csv_filename
):
    """Ensure pdf and png figures from the experiments can be saved.

    Predictions are loaded from npy file.
    :param csv_filename: csv fixture from tests.fixtures.filenames.csv_filename
    :return: None
    """
    input_features = [
        category_feature(vocab_size=10)
    ]
    output_features = [category_feature(vocab_size=2, reduce_input='sum')]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment(
        input_features,
        output_features,
        dataset=rel_path
    )
    vis_output_pattern_pdf = os.path.join(exp_dir_name, '*.pdf')
    vis_output_pattern_png = os.path.join(exp_dir_name, '*.png')
    output_feature_name = get_output_feature_name(exp_dir_name)
    prediction = os.path.join(exp_dir_name, 'predictions.parquet')
    experiment_source_data_name = csv_filename.split('.')[0]
    ground_truth = experiment_source_data_name + '.csv'
    split_file = experiment_source_data_name + '.split.csv'
    ground_truth_metadata = experiment_source_data_name + '.meta.json'
    test_cmd_pdf = ['python',
                    '-m',
                    'ludwig.visualize',
                    '--visualization',
                    'compare_classifiers_performance_from_pred',
                    '--ground_truth_metadata',
                    ground_truth_metadata,
                    '--ground_truth',
                    ground_truth,
                    '--output_feature_name',
                    output_feature_name,
                    '--split_file',
                    split_file,
                    '--predictions',
                    prediction,
                    prediction,
                    '--model_names',
                    'Model1',
                    'Model2',
                    '-od', exp_dir_name]
    test_cmd_png = test_cmd_pdf.copy() + ['-ff', 'png']

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)

    shutil.rmtree(exp_dir_name, ignore_errors=True)
    shutil.rmtree('results', ignore_errors=True)
    for file in glob.glob(experiment_source_data_name + '.*'):
        try:
            os.remove(file)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization.py" startline="255" endline="324" pcid="24">
        except OSError as e:  # if failed, report it back to the user
            print("Error: %s - %s." % (e.filename, e.strerror))


def test_visualization_compare_classifiers_from_prob_csv_output_saved(
        csv_filename
):
    """Ensure pdf and png figures from the experiments can be saved.

    Probabilities are loaded from csv file.
    :param csv_filename: csv fixture from tests.fixtures.filenames.csv_filename
    :return: None
    """
    input_features = [
        category_feature(vocab_size=10)
    ]
    output_features = [category_feature(vocab_size=2, reduce_input='sum')]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment(
        input_features,
        output_features,
        dataset=rel_path
    )

    vis_output_pattern_pdf = os.path.join(exp_dir_name, '*.pdf')
    vis_output_pattern_png = os.path.join(exp_dir_name, '*.png')
    output_feature_name = get_output_feature_name(exp_dir_name)
    probability = os.path.join(exp_dir_name, 'predictions.parquet')
    experiment_source_data_name = csv_filename.split('.')[0]
    ground_truth = experiment_source_data_name + '.csv'
    split_file = get_split_path(csv_filename)
    test_cmd_pdf = ['python',
                    '-m',
                    'ludwig.visualize',
                    '--visualization',
                    'compare_classifiers_performance_from_prob',
                    '--ground_truth',
                    ground_truth,
                    '--output_feature_name',
                    output_feature_name,
                    '--split_file',
                    split_file,
                    '--ground_truth_metadata',
                    exp_dir_name + '/model/training_set_metadata.json',
                    '--probabilities',
                    probability,
                    probability,
                    '--model_names',
                    'Model1',
                    'Model2',
                    '-od', exp_dir_name]
    test_cmd_png = test_cmd_pdf.copy() + ['-ff', 'png']

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)

    shutil.rmtree(exp_dir_name, ignore_errors=True)
    shutil.rmtree('results', ignore_errors=True)
    for file in glob.glob(experiment_source_data_name + '.*'):
        try:
            os.remove(file)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization.py" startline="1363" endline="1439" pcid="40">
        except OSError as e:  # if failed, report it back to the user
            print("Error: %s - %s." % (e.filename, e.strerror))


def test_visualization_binary_threshold_vs_metric_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [
        text_feature(vocab_size=10, min_len=1, encoder='stacked_cnn'),
        numerical_feature(),
        category_feature(vocab_size=10, embedding_size=5),
        set_feature(),
        sequence_feature(vocab_size=10, max_len=10, encoder='embed')
    ]
    output_features = [
        category_feature(vocab_size=4, reduce_input='sum')
    ]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    input_features[0]['encoder'] = 'parallel_cnn'
    exp_dir_name = run_experiment(
        input_features,
        output_features,
        dataset=rel_path
    )
    vis_output_pattern_pdf = os.path.join(exp_dir_name, '*.pdf')
    vis_output_pattern_png = os.path.join(exp_dir_name, '*.png')
    output_feature_name = get_output_feature_name(exp_dir_name)
    probability = os.path.join(exp_dir_name, 'predictions.parquet')
    experiment_source_data_name = csv_filename.split('.')[0]
    ground_truth = experiment_source_data_name + '.csv'
    split_file = experiment_source_data_name + '.split.csv'
    test_cmd_pdf = ['python',
                    '-m',
                    'ludwig.visualize',
                    '--visualization',
                    'binary_threshold_vs_metric',
                    '--positive_label',
                    '2',
                    '--metrics',
                    'accuracy',
                    '--ground_truth',
                    ground_truth,
                    '--output_feature_name',
                    output_feature_name,
                    '--split_file',
                    split_file,
                    '--ground_truth_metadata',
                    exp_dir_name + '/model/training_set_metadata.json',
                    '--probabilities',
                    probability,
                    probability,
                    '--model_names',
                    'Model1',
                    'Model2',
                    '-od', exp_dir_name]
    test_cmd_png = test_cmd_pdf.copy() + ['-ff', 'png']

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)

    shutil.rmtree(exp_dir_name, ignore_errors=True)
    shutil.rmtree('results', ignore_errors=True)
    for file in glob.glob(experiment_source_data_name + '.*'):
        try:
            os.remove(file)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization.py" startline="729" endline="797" pcid="31">
        except OSError as e:  # if failed, report it back to the user
            print("Error: %s - %s." % (e.filename, e.strerror))


def test_visualization_compare_classifiers_predictions_npy_output_saved(
        csv_filename
):
    """Ensure pdf and png figures from the experiments can be saved.

    Predictions are loaded form npy file.
    :param csv_filename: csv fixture from tests.fixtures.filenames.csv_filename
    :return: None
    """
    input_features = [
        category_feature(vocab_size=10)
    ]
    output_features = [category_feature(vocab_size=2, reduce_input='sum')]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment(
        input_features,
        output_features,
        dataset=rel_path
    )
    vis_output_pattern_pdf = os.path.join(exp_dir_name, '*.pdf')
    vis_output_pattern_png = os.path.join(exp_dir_name, '*.png')
    output_feature_name = get_output_feature_name(exp_dir_name)
    prediction = os.path.join(exp_dir_name, 'predictions.parquet')
    experiment_source_data_name = csv_filename.split('.')[0]
    ground_truth = experiment_source_data_name + '.csv'
    split_file = experiment_source_data_name + '.split.csv'
    test_cmd_pdf = ['python',
                    '-m',
                    'ludwig.visualize',
                    '--visualization',
                    'compare_classifiers_predictions',
                    '--ground_truth',
                    ground_truth,
                    '--output_feature_name',
                    output_feature_name,
                    '--split_file',
                    split_file,
                    '--ground_truth_metadata',
                    exp_dir_name + '/model/training_set_metadata.json',
                    '--predictions',
                    prediction,
                    prediction,
                    '--model_names',
                    'Model1',
                    'Model2',
                    '-od', exp_dir_name]
    test_cmd_png = test_cmd_pdf.copy() + ['-ff', 'png']

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)

    shutil.rmtree(exp_dir_name, ignore_errors=True)
    shutil.rmtree('results', ignore_errors=True)
    for file in glob.glob(experiment_source_data_name + '.*'):
        try:
            os.remove(file)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization.py" startline="603" endline="668" pcid="29">
        except OSError as e:  # if failed, report it back to the user
            print("Error: %s - %s." % (e.filename, e.strerror))


def test_visualization_compare_classifiers_changing_k_output_pdf(csv_filename):
    """It should be possible to save figures as pdf in the specified directory.

    """
    input_features = [
        category_feature(vocab_size=10)
    ]
    output_features = [category_feature(vocab_size=2, reduce_input='sum')]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment(
        input_features,
        output_features,
        dataset=rel_path
    )
    vis_output_pattern_pdf = os.path.join(exp_dir_name, '*.pdf')
    vis_output_pattern_png = os.path.join(exp_dir_name, '*.png')
    output_feature_name = get_output_feature_name(exp_dir_name)
    probability = os.path.join(exp_dir_name, 'predictions.parquet')
    experiment_source_data_name = csv_filename.split('.')[0]
    ground_truth = experiment_source_data_name + '.csv'
    split_file = experiment_source_data_name + '.split.csv'
    ground_truth_metadata = exp_dir_name + '/model/training_set_metadata.json'
    test_cmd_pdf = ['python',
                    '-m',
                    'ludwig.visualize',
                    '--visualization',
                    'compare_classifiers_performance_changing_k',
                    '--output_feature_name',
                    output_feature_name,
                    '--split_file',
                    split_file,
                    '--ground_truth_metadata',
                    ground_truth_metadata,
                    '--probabilities',
                    probability,
                    probability,
                    '--model_names',
                    'Model1',
                    'Model2',
                    '--ground_truth',
                    ground_truth,
                    '--top_n_classes',
                    '6',
                    '-od', exp_dir_name]
    test_cmd_png = test_cmd_pdf.copy() + ['-ff', 'png']

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]
    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)

    shutil.rmtree(exp_dir_name, ignore_errors=True)
    shutil.rmtree('results', ignore_errors=True)
    for file in glob.glob(experiment_source_data_name + '.*'):
        try:
            os.remove(file)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization.py" startline="1001" endline="1068" pcid="35">
        except OSError as e:  # if failed, report it back to the user
            print("Error: %s - %s." % (e.filename, e.strerror))


def test_visualization_confidence_thresholding_data_vs_acc_output_saved(
        csv_filename
):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [
        category_feature(vocab_size=10)
    ]
    output_features = [category_feature(vocab_size=2, reduce_input='sum')]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment(
        input_features,
        output_features,
        dataset=rel_path
    )
    vis_output_pattern_pdf = os.path.join(exp_dir_name, '*.pdf')
    vis_output_pattern_png = os.path.join(exp_dir_name, '*.png')
    output_feature_name = get_output_feature_name(exp_dir_name)
    probability = os.path.join(exp_dir_name, 'predictions.parquet')
    experiment_source_data_name = csv_filename.split('.')[0]
    ground_truth = experiment_source_data_name + '.csv'
    split_file = experiment_source_data_name + '.split.csv'
    test_cmd_pdf = ['python',
                    '-m',
                    'ludwig.visualize',
                    '--visualization',
                    'confidence_thresholding_data_vs_acc',
                    '--ground_truth',
                    ground_truth,
                    '--output_feature_name',
                    output_feature_name,
                    '--split_file',
                    split_file,
                    '--ground_truth_metadata',
                    exp_dir_name + '/model/training_set_metadata.json',
                    '--probabilities',
                    probability,
                    probability,
                    '--model_names',
                    'Model1',
                    'Model2',
                    '-od', exp_dir_name]
    test_cmd_png = test_cmd_pdf.copy() + ['-ff', 'png']

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)

    shutil.rmtree(exp_dir_name, ignore_errors=True)
    shutil.rmtree('results', ignore_errors=True)
    for file in glob.glob(experiment_source_data_name + '.*'):
        try:
            os.remove(file)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization.py" startline="1440" endline="1509" pcid="41">
        except OSError as e:  # if failed, report it back to the user
            print("Error: %s - %s." % (e.filename, e.strerror))


def test_visualization_roc_curves_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [
        category_feature(vocab_size=10)
    ]
    output_features = [category_feature(vocab_size=2, reduce_input='sum')]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment(
        input_features,
        output_features,
        dataset=rel_path
    )
    vis_output_pattern_pdf = os.path.join(exp_dir_name, '*.pdf')
    vis_output_pattern_png = os.path.join(exp_dir_name, '*.png')
    output_feature_name = get_output_feature_name(exp_dir_name)
    probability = os.path.join(exp_dir_name, 'predictions.parquet')
    experiment_source_data_name = csv_filename.split('.')[0]
    ground_truth = experiment_source_data_name + '.csv'
    split_file = experiment_source_data_name + '.split.csv'
    test_cmd_pdf = ['python',
                    '-m',
                    'ludwig.visualize',
                    '--visualization',
                    'roc_curves',
                    '--positive_label',
                    '2',
                    '--metrics',
                    'accuracy',
                    '--ground_truth',
                    ground_truth,
                    '--output_feature_name',
                    output_feature_name,
                    '--split_file',
                    split_file,
                    '--ground_truth_metadata',
                    exp_dir_name + '/model/training_set_metadata.json',
                    '--probabilities',
                    probability,
                    probability,
                    '--model_names',
                    'Model1',
                    'Model2',
                    '-od', exp_dir_name]
    test_cmd_png = test_cmd_pdf.copy() + ['-ff', 'png']

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)

    shutil.rmtree(exp_dir_name, ignore_errors=True)
    shutil.rmtree('results', ignore_errors=True)
    for file in glob.glob(experiment_source_data_name + '.*'):
        try:
            os.remove(file)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization.py" startline="867" endline="934" pcid="33">
        except OSError as e:  # if failed, report it back to the user
            print("Error: %s - %s." % (e.filename, e.strerror))


def test_visualization_cmp_classifiers_predictions_distribution_output_saved(
        csv_filename
):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [
        category_feature(vocab_size=10)
    ]
    output_features = [category_feature(vocab_size=2, reduce_input='sum')]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment(
        input_features,
        output_features,
        dataset=rel_path
    )
    vis_output_pattern_pdf = os.path.join(exp_dir_name, '*.pdf')
    vis_output_pattern_png = os.path.join(exp_dir_name, '*.png')
    output_feature_name = get_output_feature_name(exp_dir_name)
    prediction = os.path.join(exp_dir_name, 'predictions.parquet')
    experiment_source_data_name = csv_filename.split('.')[0]
    ground_truth = experiment_source_data_name + '.csv'
    split_file = experiment_source_data_name + '.split.csv'
    test_cmd_pdf = ['python',
                    '-m',
                    'ludwig.visualize',
                    '--visualization',
                    'compare_classifiers_predictions_distribution',
                    '--ground_truth',
                    ground_truth,
                    '--output_feature_name',
                    output_feature_name,
                    '--split_file',
                    split_file,
                    '--ground_truth_metadata',
                    exp_dir_name + '/model/training_set_metadata.json',
                    '--predictions',
                    prediction,
                    prediction,
                    '--model_names',
                    'Model1',
                    'Model2',
                    '-od', exp_dir_name]
    test_cmd_png = test_cmd_pdf.copy() + ['-ff', 'png']

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)

    shutil.rmtree(exp_dir_name, ignore_errors=True)
    shutil.rmtree('results', ignore_errors=True)
    for file in glob.glob(experiment_source_data_name + '.*'):
        try:
            os.remove(file)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization.py" startline="935" endline="1000" pcid="34">
        except OSError as e:  # if failed, report it back to the user
            print("Error: %s - %s." % (e.filename, e.strerror))


def test_visualization_cconfidence_thresholding_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [
        category_feature(vocab_size=10)
    ]
    output_features = [category_feature(vocab_size=2, reduce_input='sum')]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment(
        input_features,
        output_features,
        dataset=rel_path
    )
    vis_output_pattern_pdf = os.path.join(exp_dir_name, '*.pdf')
    vis_output_pattern_png = os.path.join(exp_dir_name, '*.png')
    output_feature_name = get_output_feature_name(exp_dir_name)
    probability = os.path.join(exp_dir_name, 'predictions.parquet')
    experiment_source_data_name = csv_filename.split('.')[0]
    ground_truth = experiment_source_data_name + '.csv'
    split_file = experiment_source_data_name + '.split.csv'
    test_cmd_pdf = ['python',
                    '-m',
                    'ludwig.visualize',
                    '--visualization',
                    'confidence_thresholding',
                    '--ground_truth',
                    ground_truth,
                    '--output_feature_name',
                    output_feature_name,
                    '--split_file',
                    split_file,
                    '--ground_truth_metadata',
                    exp_dir_name + '/model/training_set_metadata.json',
                    '--probabilities',
                    probability,
                    probability,
                    '--model_names',
                    'Model1',
                    'Model2',
                    '-od', exp_dir_name]
    test_cmd_png = test_cmd_pdf.copy() + ['-ff', 'png']

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)

    shutil.rmtree(exp_dir_name, ignore_errors=True)
    shutil.rmtree('results', ignore_errors=True)
    for file in glob.glob(experiment_source_data_name + '.*'):
        try:
            os.remove(file)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization.py" startline="1636" endline="1701" pcid="44">
        except OSError as e:  # if failed, report it back to the user
            print("Error: %s - %s." % (e.filename, e.strerror))


def test_visualization_calibration_multiclass_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [
        category_feature(vocab_size=10)
    ]
    output_features = [category_feature(vocab_size=2, reduce_input='sum')]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment(
        input_features,
        output_features,
        dataset=rel_path
    )
    vis_output_pattern_pdf = os.path.join(exp_dir_name, '*.pdf')
    vis_output_pattern_png = os.path.join(exp_dir_name, '*.png')
    output_feature_name = get_output_feature_name(exp_dir_name)
    probability = os.path.join(exp_dir_name, 'predictions.parquet')
    experiment_source_data_name = csv_filename.split('.')[0]
    ground_truth = experiment_source_data_name + '.csv'
    split_file = experiment_source_data_name + '.split.csv'
    test_cmd_pdf = ['python',
                    '-m',
                    'ludwig.visualize',
                    '--visualization',
                    'calibration_multiclass',
                    '--ground_truth',
                    ground_truth,
                    '--output_feature_name',
                    output_feature_name,
                    '--split_file',
                    split_file,
                    '--ground_truth_metadata',
                    exp_dir_name + '/model/training_set_metadata.json',
                    '--probabilities',
                    probability,
                    probability,
                    '--model_names',
                    'Model1',
                    'Model2',
                    '-od', exp_dir_name]
    test_cmd_png = test_cmd_pdf.copy() + ['-ff', 'png']

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 2 == len(figure_cnt)

    shutil.rmtree(exp_dir_name, ignore_errors=True)
    shutil.rmtree('results', ignore_errors=True)
    for file in glob.glob(experiment_source_data_name + '.*'):
        try:
            os.remove(file)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization.py" startline="535" endline="602" pcid="28">
        except OSError as e:  # if failed, report it back to the user
            print("Error: %s - %s." % (e.filename, e.strerror))


def test_visualization_compare_classifiers_subset_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [
        category_feature(vocab_size=10)
    ]
    output_features = [category_feature(vocab_size=2, reduce_input='sum')]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    exp_dir_name = run_experiment(
        input_features,
        output_features,
        dataset=rel_path
    )
    vis_output_pattern_pdf = os.path.join(exp_dir_name, '*.pdf')
    vis_output_pattern_png = os.path.join(exp_dir_name, '*.png')
    output_feature_name = get_output_feature_name(exp_dir_name)
    probability = os.path.join(exp_dir_name, 'predictions.parquet')
    experiment_source_data_name = csv_filename.split('.')[0]
    ground_truth = experiment_source_data_name + '.csv'
    split_file = experiment_source_data_name + '.split.csv'
    test_cmd_pdf = ['python',
                    '-m',
                    'ludwig.visualize',
                    '--visualization',
                    'compare_classifiers_performance_subset',
                    '--output_feature_name',
                    output_feature_name,
                    '--split_file',
                    split_file,
                    '--ground_truth_metadata',
                    exp_dir_name + '/model/training_set_metadata.json',
                    '--probabilities',
                    probability,
                    probability,
                    '--model_names',
                    'Model1',
                    'Model2',
                    '--ground_truth',
                    ground_truth,
                    '--top_n_classes',
                    '6',
                    '-od', exp_dir_name]
    test_cmd_png = test_cmd_pdf.copy() + ['-ff', 'png']

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(command)
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)

    shutil.rmtree(exp_dir_name, ignore_errors=True)
    shutil.rmtree('results', ignore_errors=True)
    for file in glob.glob(experiment_source_data_name + '.*'):
        try:
            os.remove(file)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization.py" startline="1211" endline="1288" pcid="38">
        except OSError as e:  # if failed, report it back to the user
            print("Error: %s - %s." % (e.filename, e.strerror))


def test_vis_confidence_thresholding_2thresholds_2d_output_saved(
        csv_filename
):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [
        text_feature(vocab_size=10, min_len=1, encoder='stacked_cnn'),
        numerical_feature(),
        category_feature(vocab_size=10, embedding_size=5),
        set_feature(),
        sequence_feature(vocab_size=10, max_len=10, encoder='embed')
    ]
    output_features = [
        category_feature(vocab_size=2, reduce_input='sum'),
        category_feature(vocab_size=2, reduce_input='sum')
    ]
    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    input_features[0]['encoder'] = 'parallel_cnn'
    exp_dir_name = run_experiment(
        input_features,
        output_features,
        dataset=rel_path
    )
    vis_output_pattern_pdf = os.path.join(exp_dir_name, '*.pdf')
    vis_output_pattern_png = os.path.join(exp_dir_name, '*.png')
    treshhold_output_feature_name1 = get_output_feature_name(exp_dir_name)
    treshhold_output_feature_name2 = get_output_feature_name(exp_dir_name,
                                                             output_feature=1)
    probability = os.path.join(exp_dir_name, 'predictions.parquet')
    experiment_source_data_name = csv_filename.split('.')[0]
    ground_truth = experiment_source_data_name + '.csv'
    split_file = experiment_source_data_name + '.split.csv'
    test_cmd_pdf = ['python',
                    '-m',
                    'ludwig.visualize',
                    '--visualization',
                    'confidence_thresholding_2thresholds_2d',
                    '--ground_truth',
                    ground_truth,
                    '--split_file',
                    split_file,
                    '--ground_truth_metadata',
                    exp_dir_name + '/model/training_set_metadata.json',
                    '--probabilities',
                    probability,
                    '--threshold_output_feature_names',
                    treshhold_output_feature_name1,
                    treshhold_output_feature_name2,
                    '--model_names',
                    'Model1',
                    '-od', exp_dir_name]
    test_cmd_png = test_cmd_pdf.copy() + ['-ff', 'png']

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(
            command,
        )
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 3 == len(figure_cnt)

    shutil.rmtree(exp_dir_name, ignore_errors=True)
    shutil.rmtree('results', ignore_errors=True)
    for file in glob.glob(experiment_source_data_name + '.*'):
        try:
            os.remove(file)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization.py" startline="1289" endline="1362" pcid="39">
        except OSError as e:  # if failed, report it back to the user
            print("Error: %s - %s." % (e.filename, e.strerror))


def test_vis_confidence_thresholding_2thresholds_3d_output_saved(csv_filename):
    """Ensure pdf and png figures from the experiments can be saved.

    :param csv_filename: csv fixture from tests.conftest.csv_filename
    :return: None
    """
    input_features = [
        text_feature(vocab_size=10, min_len=1, encoder='stacked_cnn'),
        numerical_feature(),
        category_feature(vocab_size=10, embedding_size=5),
        set_feature(),
        sequence_feature(vocab_size=10, max_len=10, encoder='embed')
    ]
    output_features = [
        category_feature(vocab_size=2, reduce_input='sum'),
        category_feature(vocab_size=2, reduce_input='sum')
    ]
    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    input_features[0]['encoder'] = 'parallel_cnn'
    exp_dir_name = run_experiment(
        input_features,
        output_features,
        dataset=rel_path
    )
    vis_output_pattern_pdf = os.path.join(exp_dir_name, '*.pdf')
    vis_output_pattern_png = os.path.join(exp_dir_name, '*.png')
    treshhold_output_feature_name1 = get_output_feature_name(exp_dir_name)
    treshhold_output_feature_name2 = get_output_feature_name(exp_dir_name,
                                                             output_feature=1)
    probability = os.path.join(exp_dir_name, 'predictions.parquet')
    experiment_source_data_name = csv_filename.split('.')[0]
    ground_truth = experiment_source_data_name + '.csv'
    split_file = experiment_source_data_name + '.split.csv'
    test_cmd_pdf = ['python',
                    '-m',
                    'ludwig.visualize',
                    '--visualization',
                    'confidence_thresholding_2thresholds_3d',
                    '--ground_truth',
                    ground_truth,
                    '--split_file',
                    split_file,
                    '--ground_truth_metadata',
                    exp_dir_name + '/model/training_set_metadata.json',
                    '--probabilities',
                    probability,
                    '--threshold_output_feature_names',
                    treshhold_output_feature_name1,
                    treshhold_output_feature_name2,
                    '-od', exp_dir_name]
    test_cmd_png = test_cmd_pdf.copy() + ['-ff', 'png']

    commands = [test_cmd_pdf, test_cmd_png]
    vis_patterns = [vis_output_pattern_pdf, vis_output_pattern_png]

    for command, viz_pattern in zip(commands, vis_patterns):
        result = subprocess.run(
            command,
        )
        figure_cnt = glob.glob(viz_pattern)

        assert 0 == result.returncode
        assert 1 == len(figure_cnt)

    shutil.rmtree(exp_dir_name, ignore_errors=True)
    shutil.rmtree('results', ignore_errors=True)
    for file in glob.glob(experiment_source_data_name + '.*'):
        try:
            os.remove(file)
</source>
</class>

<class classid="4" nclones="8" nlines="11" similarity="71">
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_cli.py" startline="120" endline="132" pcid="53">
def test_train_cli_dataset(csv_filename):
    """Test training using `ludwig train --dataset`."""
    with tempfile.TemporaryDirectory() as tmpdir:
        config_filename = os.path.join(tmpdir,
                                       'config.yaml')
        dataset_filename = _prepare_data(csv_filename,
                                         config_filename)
        _run_ludwig('train',
                    dataset=dataset_filename,
                    config_file=config_filename,
                    output_directory=tmpdir)


</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_cli.py" startline="251" endline="267" pcid="60">
def test_evaluate_cli(csv_filename):
    """Test evaluate cli."""
    with tempfile.TemporaryDirectory() as tmpdir:
        config_filename = os.path.join(tmpdir,
                                       'config.yaml')
        dataset_filename = _prepare_data(csv_filename,
                                         config_filename)
        _run_ludwig('train',
                    dataset=dataset_filename,
                    config_file=config_filename,
                    output_directory=tmpdir)
        _run_ludwig('evaluate',
                    dataset=dataset_filename,
                    model_path=os.path.join(tmpdir, 'experiment_run', 'model'),
                    output_directory=os.path.join(tmpdir, 'predictions'))


</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_cli.py" startline="219" endline="231" pcid="58">
def test_experiment_cli(csv_filename):
    """Test experiment cli."""
    with tempfile.TemporaryDirectory() as tmpdir:
        config_filename = os.path.join(tmpdir,
                                       'config.yaml')
        dataset_filename = _prepare_data(csv_filename,
                                         config_filename)
        _run_ludwig('experiment',
                    dataset=dataset_filename,
                    config_file=config_filename,
                    output_directory=tmpdir)


</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_cli.py" startline="233" endline="249" pcid="59">
def test_predict_cli(csv_filename):
    """Test predict cli."""
    with tempfile.TemporaryDirectory() as tmpdir:
        config_filename = os.path.join(tmpdir,
                                       'config.yaml')
        dataset_filename = _prepare_data(csv_filename,
                                         config_filename)
        _run_ludwig('train',
                    dataset=dataset_filename,
                    config_file=config_filename,
                    output_directory=tmpdir)
        _run_ludwig('predict',
                    dataset=dataset_filename,
                    model_path=os.path.join(tmpdir, 'experiment_run', 'model'),
                    output_directory=os.path.join(tmpdir, 'predictions'))


</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_cli.py" startline="201" endline="217" pcid="57">
def test_export_neuropod_cli(csv_filename):
    """Test exporting Ludwig model to neuropod format."""
    with tempfile.TemporaryDirectory() as tmpdir:
        config_filename = os.path.join(tmpdir,
                                       'config.yaml')
        dataset_filename = _prepare_data(csv_filename,
                                         config_filename)
        _run_ludwig('train',
                    dataset=dataset_filename,
                    config_file=config_filename,
                    output_directory=tmpdir)
        _run_ludwig('export_neuropod',
                    model_path=os.path.join(tmpdir, 'experiment_run', 'model'),
                    output_path=os.path.join(tmpdir, 'neuropod')
                    )


</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_cli.py" startline="182" endline="198" pcid="56">
def test_export_savedmodel_cli(csv_filename):
    """Test exporting Ludwig model to Tensorflows savedmodel format."""
    with tempfile.TemporaryDirectory() as tmpdir:
        config_filename = os.path.join(tmpdir,
                                       'config.yaml')
        dataset_filename = _prepare_data(csv_filename,
                                         config_filename)
        _run_ludwig('train',
                    dataset=dataset_filename,
                    config_file=config_filename,
                    output_directory=tmpdir)
        _run_ludwig('export_savedmodel',
                    model_path=os.path.join(tmpdir, 'experiment_run', 'model'),
                    output_path=os.path.join(tmpdir, 'savedmodel')
                    )


</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_cli.py" startline="269" endline="281" pcid="61">
def test_hyperopt_cli(csv_filename):
    """Test hyperopt cli."""
    with tempfile.TemporaryDirectory() as tmpdir:
        config_filename = os.path.join(tmpdir,
                                       'config.yaml')
        dataset_filename = _prepare_hyperopt_data(csv_filename,
                                                  config_filename)
        _run_ludwig('hyperopt',
                    dataset=dataset_filename,
                    config_file=config_filename,
                    output_directory=tmpdir)


</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_cli.py" startline="283" endline="303" pcid="62">
def test_visualize_cli(csv_filename):
    """Test Ludwig 'visualize' cli."""
    with tempfile.TemporaryDirectory() as tmpdir:
        config_filename = os.path.join(tmpdir,
                                       'config.yaml')
        dataset_filename = _prepare_data(csv_filename,
                                         config_filename)
        _run_ludwig('train',
                    dataset=dataset_filename,
                    config_file=config_filename,
                    output_directory=tmpdir)
        _run_ludwig('visualize',
                    visualization='learning_curves',
                    model_names='run',
                    training_statistics=os.path.join(
                        tmpdir, 'experiment_run', 'training_statistics.json'
                    ),
                    output_directory=os.path.join(tmpdir, 'visualizations')
                    )


</source>
</class>

<class classid="5" nclones="2" nlines="50" similarity="84">
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_server.py" startline="117" endline="193" pcid="74">
def test_server_integration_with_images(csv_filename):
    # Image Inputs
    image_dest_folder = os.path.join(os.getcwd(), 'generated_images')

    # Resnet encoder
    input_features = [
        image_feature(
            folder=image_dest_folder,
            preprocessing={
                'in_memory': True,
                'height': 8,
                'width': 8,
                'num_channels': 3
            },
            fc_size=16,
            num_filters=8
        ),
        text_feature(encoder='embed', min_len=1),
        numerical_feature(normalization='zscore')
    ]
    output_features = [
        category_feature(vocab_size=2),
        numerical_feature()
    ]

    rel_path = generate_data(input_features, output_features, csv_filename)
    model, output_dir = train_model(input_features, output_features,
                                    data_csv=rel_path)

    app = server(model)
    client = TestClient(app)
    response = client.get('/')
    assert response.status_code == 200

    response = client.post('/predict')
    # expect the HTTP 400 error code for this situation
    assert response.status_code == 400
    assert response.json() == ALL_FEATURES_PRESENT_ERROR

    data_df = read_csv(rel_path)

    # One-off prediction
    first_entry = data_df.T.to_dict()[0]
    data, files = convert_to_form(first_entry)
    server_response = client.post('/predict', data=data, files=files)
    assert server_response.status_code == 200
    server_response = server_response.json()

    server_response_keys = sorted(list(server_response.keys()))
    assert server_response_keys == sorted(output_keys_for(output_features))

    model_output, _ = model.predict(
        dataset=[first_entry], data_format=dict
    )
    model_output = model_output.to_dict('records')[0]
    assert model_output == server_response

    # Batch prediction
    assert len(data_df) > 1
    files = convert_to_batch_form(data_df)
    server_response = client.post('/batch_predict', files=files)
    assert server_response.status_code == 200
    server_response = server_response.json()

    server_response_keys = sorted(server_response['columns'])
    assert server_response_keys == sorted(output_keys_for(output_features))
    assert len(data_df) == len(server_response['data'])

    model_output, _ = model.predict(dataset=data_df)
    model_output = model_output.to_dict('split')
    assert model_output == server_response

    # Cleanup
    shutil.rmtree(output_dir, ignore_errors=True)
    shutil.rmtree(image_dest_folder, ignore_errors=True)


</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_server.py" startline="195" endline="262" pcid="75">
def test_server_integration_with_audio(single_record, csv_filename):
    # Audio Inputs
    audio_dest_folder = os.path.join(os.getcwd(), 'generated_audio')

    # Resnet encoder
    input_features = [
        audio_feature(
            folder=audio_dest_folder,
        ),
        text_feature(encoder='embed', min_len=1),
        numerical_feature(normalization='zscore')
    ]
    output_features = [
        category_feature(vocab_size=2),
        numerical_feature()
    ]

    rel_path = generate_data(input_features, output_features, csv_filename)
    model, output_dir = train_model(input_features, output_features,
                                    data_csv=rel_path)

    app = server(model)
    client = TestClient(app)
    response = client.get('/')
    assert response.status_code == 200

    response = client.post('/predict')
    # expect the HTTP 400 error code for this situation
    assert response.status_code == 400
    assert response.json() == ALL_FEATURES_PRESENT_ERROR

    data_df = read_csv(rel_path)

    if single_record:
        # Single record prediction
        first_entry = data_df.T.to_dict()[0]
        data, files = convert_to_form(first_entry)
        server_response = client.post('/predict', data=data, files=files)
        assert server_response.status_code == 200
        server_response = server_response.json()

        server_response_keys = sorted(list(server_response.keys()))
        assert server_response_keys == sorted(output_keys_for(output_features))

        model_output, _ = model.predict(
            dataset=[first_entry], data_format=dict
        )
        model_output = model_output.to_dict('records')[0]
        assert model_output == server_response
    else:
        # Batch prediction
        assert len(data_df) > 1
        files = convert_to_batch_form(data_df)
        server_response = client.post('/batch_predict', files=files)
        assert server_response.status_code == 200
        server_response = server_response.json()

        server_response_keys = sorted(server_response['columns'])
        assert server_response_keys == sorted(output_keys_for(output_features))
        assert len(data_df) == len(server_response['data'])

        model_output, _ = model.predict(dataset=data_df)
        model_output = model_output.to_dict('split')
        assert model_output == server_response

    # Cleanup
    shutil.rmtree(output_dir, ignore_errors=True)
    shutil.rmtree(audio_dest_folder, ignore_errors=True)
</source>
</class>

<class classid="6" nclones="2" nlines="11" similarity="90">
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_graph_execution.py" startline="75" endline="89" pcid="86">
)
def test_experiment_multiple_seq_seq(csv_filename, output_features):
    with graph_mode():
        input_features = [
            text_feature(vocab_size=100, min_len=1, encoder='stacked_cnn'),
            numerical_feature(normalization='zscore'),
            category_feature(vocab_size=10, embedding_size=5),
            set_feature(),
            sequence_feature(vocab_size=10, max_len=10, encoder='embed')
        ]
        output_features = output_features

        rel_path = generate_data(input_features, output_features, csv_filename)
        run_experiment(input_features, output_features, dataset=rel_path)

</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_experiment.py" startline="265" endline="278" pcid="176">
    ]
)
def test_experiment_multiple_seq_seq(csv_filename, output_features):
    input_features = [
        text_feature(vocab_size=100, min_len=1, encoder='stacked_cnn'),
        numerical_feature(normalization='zscore'),
        category_feature(vocab_size=10, embedding_size=5),
        set_feature(),
        sequence_feature(vocab_size=10, max_len=10, encoder='embed')
    ]
    output_features = output_features

    rel_path = generate_data(input_features, output_features, csv_filename)
    run_experiment(input_features, output_features, dataset=rel_path)
</source>
</class>

<class classid="7" nclones="19" nlines="18" similarity="70">
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization_api.py" startline="143" endline="165" pcid="119">


def test_learning_curves_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    viz_outputs = ('pdf', 'png')
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + '/*.{}'.format(
                viz_output)
            visualize.learning_curves(
                [experiment.train_stats],
                output_feature_name=None,
                output_directory=tmpvizdir,
                file_format=viz_output
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 4 == len(figure_cnt)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization_api.py" startline="166" endline="192" pcid="120">


def test_compare_performance_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    # extract test stats only
    test_stats = experiment.test_stats_full
    viz_outputs = ('pdf', 'png')
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + '/*.{}'.format(
                viz_output
            )
            visualize.compare_performance(
                [test_stats, test_stats],
                output_feature_name=None,
                model_names=['Model1', 'Model2'],
                output_directory=tmpvizdir,
                file_format=viz_output
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 1 == len(figure_cnt)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization_api.py" startline="819" endline="847" pcid="138">


def test_calibration_multiclass_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    probabilities = experiment.probabilities
    viz_outputs = ('pdf', 'png')
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + '/*.{}'.format(
                viz_output
            )
            visualize.calibration_multiclass(
                [probabilities, probabilities],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                labels_limit=0,
                model_names=['Model1', 'Model2'],
                output_directory=tmpvizdir,
                file_format=viz_output
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 2 == len(figure_cnt)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization_api.py" startline="848" endline="877" pcid="139">


def test_confusion_matrix_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    # extract test stats only
    test_stats = experiment.test_stats_full
    viz_outputs = ('pdf', 'png')
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + '/*.{}'.format(
                viz_output
            )
            visualize.confusion_matrix(
                [test_stats, test_stats],
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                top_n_classes=[0],
                normalize=False,
                model_names=['Model1', 'Model2'],
                output_directory=tmpvizdir,
                file_format=viz_output
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 4 == len(figure_cnt)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization_api.py" startline="222" endline="249" pcid="122">


def test_compare_classifier_performance_from_pred_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    prediction = experiment.predictions
    viz_outputs = ('pdf', 'png')
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + '/*.{}'.format(
                viz_output)
            visualize.compare_classifiers_performance_from_pred(
                [prediction, prediction],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                labels_limit=0,
                model_namess=['Model1', 'Model2'],
                output_directory=tmpvizdir,
                file_format=viz_output
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 1 == len(figure_cnt)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization_api.py" startline="310" endline="338" pcid="125">


def test_compare_classifiers_multiclass_multimetric_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    # extract test stats only
    test_stats = experiment.test_stats_full
    viz_outputs = ('pdf', 'png')
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + '/*.{}'.format(
                viz_output
            )
            visualize.compare_classifiers_multiclass_multimetric(
                [test_stats, test_stats],
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                top_n_classes=[6],
                model_namess=['Model1', 'Model2'],
                output_directory=tmpvizdir,
                file_format=viz_output
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 4 == len(figure_cnt)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization_api.py" startline="368" endline="397" pcid="127">


def test_compare_classifiers_predictions_distribution_vis_api(
        experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    predictions = experiment.predictions_num
    viz_outputs = ('pdf', 'png')
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + '/*.{}'.format(
                viz_output
            )
            visualize.compare_classifiers_predictions_distribution(
                [predictions, predictions],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                labels_limit=0,
                model_names=['Model1', 'Model2'],
                output_directory=tmpvizdir,
                file_format=viz_output
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 1 == len(figure_cnt)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization_api.py" startline="280" endline="309" pcid="124">


def test_compare_classifiers_performance_changing_k_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    probabilities = experiment.probabilities
    viz_outputs = ('pdf', 'png')
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + '/*.{}'.format(
                viz_output
            )
            visualize.compare_classifiers_performance_changing_k(
                [probabilities, probabilities],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                top_k=3,
                labels_limit=0,
                model_namess=['Model1', 'Model2'],
                output_directory=tmpvizdir,
                file_format=viz_output
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 1 == len(figure_cnt)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization_api.py" startline="456" endline="486" pcid="130">


def test_confidence_thresholding_data_vs_acc_subset_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    probabilities = experiment.probabilities
    viz_outputs = ('pdf', 'png')
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + '/*.{}'.format(
                viz_output
            )
            visualize.confidence_thresholding_data_vs_acc_subset(
                [probabilities, probabilities],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                top_n_classes=[3],
                labels_limit=0,
                subset='ground_truth',
                model_names=['Model1', 'Model2'],
                output_directory=tmpvizdir,
                file_format=viz_output
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 1 == len(figure_cnt)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization_api.py" startline="718" endline="747" pcid="135">


def test_roc_curves_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    probabilities = experiment.probabilities
    viz_outputs = ('pdf', 'png')
    positive_label = 2
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + '/*.{}'.format(
                viz_output
            )
            visualize.roc_curves(
                [probabilities, probabilities],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                positive_label,
                model_names=['Model1', 'Model2'],
                output_directory=tmpvizdir,
                file_format=viz_output
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 1 == len(figure_cnt)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization_api.py" startline="339" endline="367" pcid="126">


def test_compare_classifiers_predictions_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    predictions = experiment.predictions
    viz_outputs = ('pdf', 'png')
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + '/*.{}'.format(
                viz_output
            )
            visualize.compare_classifiers_predictions(
                [predictions, predictions],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                labels_limit=0,
                model_names=['Model1', 'Model2'],
                output_directory=tmpvizdir,
                file_format=viz_output
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 1 == len(figure_cnt)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization_api.py" startline="878" endline="906" pcid="140">


def test_frequency_vs_f1_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    # extract test stats
    test_stats = experiment.test_stats_full
    viz_outputs = ('pdf', 'png')
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + '/*.{}'.format(
                viz_output
            )
            visualize.frequency_vs_f1(
                [test_stats, test_stats],
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                top_n_classes=[0],
                model_names=['Model1', 'Model2'],
                output_directory=tmpvizdir,
                file_format=viz_output
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 2 == len(figure_cnt)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization_api.py" startline="427" endline="455" pcid="129">


def test_confidence_thresholding_data_vs_acc_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    probabilities = experiment.probabilities
    viz_outputs = ('pdf', 'png')
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + '/*.{}'.format(
                viz_output
            )
            visualize.confidence_thresholding_data_vs_acc(
                [probabilities, probabilities],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                labels_limit=0,
                model_names=['Model1', 'Model2'],
                output_directory=tmpvizdir,
                file_format=viz_output
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 1 == len(figure_cnt)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization_api.py" startline="193" endline="221" pcid="121">


def test_compare_classifier_performance_from_prob_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    probability = experiment.probabilities
    viz_outputs = ('pdf', 'png')
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + '/*.{}'.format(
                viz_output)
            visualize.compare_classifiers_performance_from_prob(
                [probability, probability],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                top_n_classes=[0],
                labels_limit=0,
                model_namess=['Model1', 'Model2'],
                output_directory=tmpvizdir,
                file_format=viz_output
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 1 == len(figure_cnt)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization_api.py" startline="398" endline="426" pcid="128">


def test_confidence_thresholding_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    probabilities = experiment.probabilities
    viz_outputs = ('pdf', 'png')
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + '/*.{}'.format(
                viz_output
            )
            visualize.confidence_thresholding(
                [probabilities, probabilities],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                labels_limit=0,
                model_names=['Model1', 'Model2'],
                output_directory=tmpvizdir,
                file_format=viz_output
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 1 == len(figure_cnt)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization_api.py" startline="250" endline="279" pcid="123">


def test_compare_classifiers_performance_subset_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    probabilities = experiment.probabilities
    viz_outputs = ('pdf', 'png')
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + '/*.{}'.format(
                viz_output)
            visualize.compare_classifiers_performance_subset(
                [probabilities, probabilities],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                top_n_classes=[6],
                labels_limit=0,
                subset='ground_truth',
                model_namess=['Model1', 'Model2'],
                output_directory=tmpvizdir,
                file_format=viz_output
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 1 == len(figure_cnt)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization_api.py" startline="686" endline="717" pcid="134">


def test_binary_threshold_vs_metric_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    probabilities = experiment.probabilities
    viz_outputs = ('pdf', 'png')
    metrics = ['accuracy']
    positive_label = 2
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + '/*.{}'.format(
                viz_output
            )
            visualize.binary_threshold_vs_metric(
                [probabilities, probabilities],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                metrics,
                positive_label,
                model_names=['Model1', 'Model2'],
                output_directory=tmpvizdir,
                file_format=viz_output
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 1 == len(figure_cnt)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization_api.py" startline="487" endline="521" pcid="131">


def test_confidence_thresholding_data_vs_acc_subset_per_class_vis_api(
        experiment_to_use
):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    probabilities = experiment.probabilities
    viz_outputs = ('pdf', 'png')
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = tmpvizdir + '/*.{}'.format(
                viz_output
            )
            visualize.confidence_thresholding_data_vs_acc_subset_per_class(
                [probabilities, probabilities],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                top_n_classes=[3],
                labels_limit=0,
                subset='ground_truth',
                model_names=['Model1', 'Model2'],
                output_directory=tmpvizdir,
                file_format=viz_output
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            # 3 figures should be saved because experiment setting top_n_classes = 3
            # hence one figure per class
            assert 3 == len(figure_cnt)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization_api.py" startline="789" endline="818" pcid="137">


def test_calibration_1_vs_all_vis_api(experiment_to_use):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param experiment_to_use: Object containing trained model and results to
        test visualization
    :return: None
    """
    experiment = experiment_to_use
    probabilities = experiment.probabilities
    viz_outputs = ('pdf', 'png')
    with TemporaryDirectory() as tmpvizdir:
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = os.path.join(
                tmpvizdir, '*.{}'.format(viz_output)
            )
            visualize.calibration_1_vs_all(
                [probabilities, probabilities],
                experiment.ground_truth,
                experiment.ground_truth_metadata,
                experiment.output_feature_name,
                top_n_classes=[6],
                labels_limit=0,
                model_namess=['Model1', 'Model2'],
                output_directory=tmpvizdir,
                file_format=viz_output
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 7 == len(figure_cnt)
</source>
</class>

<class classid="8" nclones="2" nlines="59" similarity="94">
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization_api.py" startline="522" endline="603" pcid="132">


def test_confidence_thresholding_2thresholds_2d_vis_api(csv_filename):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param csv_filename: csv fixture from tests.fixtures.filenames.csv_filename
    :return: None
    """
    input_features = [
        text_feature(vocab_size=10, min_len=1, encoder='stacked_cnn'),
        numerical_feature(),
        category_feature(vocab_size=10, embedding_size=5),
        set_feature(),
        sequence_feature(vocab_size=10, max_len=10, encoder='embed')
    ]
    output_features = [
        category_feature(vocab_size=2, reduce_input='sum'),
        category_feature(vocab_size=2, reduce_input='sum')
    ]
    encoder = 'parallel_cnn'
    with TemporaryDirectory() as tmpvizdir:
        # Generate test data
        data_csv = generate_data(input_features, output_features,
                                 os.path.join(tmpvizdir, csv_filename))
        input_features[0]['encoder'] = encoder
        model = run_api_experiment(input_features, output_features)
        test_df, train_df, val_df = obtain_df_splits(data_csv)
        _, _, output_dir = model.train(
            training_set=train_df,
            validation_set=val_df,
            output_directory=os.path.join(tmpvizdir, 'results')
        )
        test_stats, predictions, _ = model.evaluate(
            dataset=test_df,
            collect_predictions=True,
            output_dir=output_dir
        )

        output_feature_name1 = output_features[0]['name']
        output_feature_name2 = output_features[1]['name']

        ground_truth_metadata = model.training_set_metadata
        feature1_cols = [
            f'{output_feature_name1}_probabilities_{label}'
            for label in ground_truth_metadata[output_feature_name1]['idx2str']
        ]
        feature2_cols = [
            f'{output_feature_name2}_probabilities_{label}'
            for label in ground_truth_metadata[output_feature_name2]['idx2str']
        ]

        # probabilities need to be list of lists containing each row data from the
        # probability columns ref: https://ludwig-ai.github.io/ludwig-docs/api/#test - Return
        probability1 = predictions.loc[:, feature1_cols].values
        probability2 = predictions.loc[:, feature2_cols].values

        target_predictions1 = test_df[output_feature_name1]
        target_predictions2 = test_df[output_feature_name2]
        ground_truth1 = np.asarray([
            ground_truth_metadata[output_feature_name1]['str2idx'][prediction]
            for prediction in target_predictions1
        ])
        ground_truth2 = np.asarray([
            ground_truth_metadata[output_feature_name2]['str2idx'][prediction]
            for prediction in target_predictions2
        ])
        viz_outputs = ('pdf', 'png')
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = os.path.join(output_dir, '*.{}').format(
                viz_output)
            visualize.confidence_thresholding_2thresholds_2d(
                [probability1, probability2],
                [ground_truth1, ground_truth2],
                model.training_set_metadata,
                [output_feature_name1, output_feature_name2],
                labels_limit=0,
                model_names=['Model1'],
                output_directory=output_dir,
                file_format=viz_output
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 3 == len(figure_cnt)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_visualization_api.py" startline="604" endline="685" pcid="133">


def test_confidence_thresholding_2thresholds_3d_vis_api(csv_filename):
    """Ensure pdf and png figures can be saved via visualization API call.

    :param csv_filename: csv fixture from tests.fixtures.filenames.csv_filename
    :return: None
    """
    input_features = [
        text_feature(vocab_size=10, min_len=1, encoder='stacked_cnn'),
        numerical_feature(),
        category_feature(vocab_size=10, embedding_size=5),
        set_feature(),
        sequence_feature(vocab_size=10, max_len=10, encoder='embed')
    ]
    output_features = [
        category_feature(vocab_size=2, reduce_input='sum'),
        category_feature(vocab_size=2, reduce_input='sum')
    ]
    encoder = 'parallel_cnn'
    with TemporaryDirectory() as tmpvizdir:
        # Generate test data
        data_csv = generate_data(input_features, output_features,
                                 os.path.join(tmpvizdir, csv_filename))
        input_features[0]['encoder'] = encoder
        model = run_api_experiment(input_features, output_features)
        test_df, train_df, val_df = obtain_df_splits(data_csv)
        _, _, output_dir = model.train(
            training_set=train_df,
            validation_set=val_df,
            output_directory=os.path.join(tmpvizdir, 'results')
        )
        test_stats, predictions, _ = model.evaluate(
            dataset=test_df,
            collect_predictions=True,
            output_directory=output_dir
        )

        output_feature_name1 = output_features[0]['name']
        output_feature_name2 = output_features[1]['name']

        ground_truth_metadata = model.training_set_metadata
        feature1_cols = [
            f'{output_feature_name1}_probabilities_{label}'
            for label in ground_truth_metadata[output_feature_name1]['idx2str']
        ]
        feature2_cols = [
            f'{output_feature_name2}_probabilities_{label}'
            for label in ground_truth_metadata[output_feature_name2]['idx2str']
        ]

        # probabilities need to be list of lists containing each row data from the
        # probability columns ref: https://ludwig-ai.github.io/ludwig-docs/api/#test - Return
        probability1 = predictions.loc[:, feature1_cols].values
        probability2 = predictions.loc[:, feature2_cols].values

        target_predictions1 = test_df[output_feature_name1]
        target_predictions2 = test_df[output_feature_name2]
        ground_truth1 = np.asarray([
            ground_truth_metadata[output_feature_name1]['str2idx'][prediction]
            for prediction in target_predictions1
        ])
        ground_truth2 = np.asarray([
            ground_truth_metadata[output_feature_name2]['str2idx'][prediction]
            for prediction in target_predictions2
        ])
        viz_outputs = ('pdf', 'png')
        for viz_output in viz_outputs:
            vis_output_pattern_pdf = os.path.join(
                output_dir, '*.{}'.format(viz_output)
            )
            visualize.confidence_thresholding_2thresholds_3d(
                [probability1, probability2],
                [ground_truth1, ground_truth2],
                model.training_set_metadata,
                [output_feature_name1, output_feature_name2],
                labels_limit=0,
                output_directory=output_dir,
                file_format=viz_output
            )
            figure_cnt = glob.glob(vis_output_pattern_pdf)
            assert 1 == len(figure_cnt)
</source>
</class>

<class classid="9" nclones="3" nlines="20" similarity="72">
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_sequence_sampled_softmax.py" startline="134" endline="171" pcid="150">
def test_sequence_tagger(
        enc_cell_type,
        attention,
        csv_filename
):
    # Define input and output features
    input_features = [
        sequence_feature(
            max_len=10,
            encoder='rnn',
            cell_type=enc_cell_type,
            reduce_output=None
        )
    ]
    output_features = [
        sequence_feature(
            max_len=10,
            decoder='tagger',
            attention=attention,
            reduce_input=None,
        )
    ]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)

    # setup sampled softmax loss
    output_features[0].update(
        {
            'loss': {
                'type': 'sampled_softmax_cross_entropy',
                'negative_samples': 7
            }
        }
    )

    # run the experiment
    run_experiment(input_features, output_features, dataset=rel_path)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_experiment.py" startline="612" endline="641" pcid="183">


@pytest.mark.parametrize('enc_cell_type', ['lstm', 'rnn', 'gru'])
@pytest.mark.parametrize('attention', [False, True])
def test_sequence_tagger(
        enc_cell_type,
        attention,
        csv_filename
):
    # Define input and output features
    input_features = [
        sequence_feature(
            max_len=10,
            encoder='rnn',
            cell_type=enc_cell_type,
            reduce_output=None
        )
    ]
    output_features = [
        sequence_feature(
            max_len=10,
            decoder='tagger',
            attention=attention,
            reduce_input=None
        )
    ]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)

</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_experiment.py" startline="642" endline="667" pcid="184">
    # run the experiment
    run_experiment(input_features, output_features, dataset=rel_path)


def test_sequence_tagger_text(
        csv_filename
):
    # Define input and output features
    input_features = [
        text_feature(
            max_len=10,
            encoder='rnn',
            reduce_output=None
        )
    ]
    output_features = [
        sequence_feature(
            max_len=10,
            decoder='tagger',
            reduce_input=None
        )
    ]

    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)

</source>
</class>

<class classid="10" nclones="2" nlines="50" similarity="70">
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_hyperopt.py" startline="150" endline="231" pcid="153">
def test_hyperopt_run_hyperopt(csv_filename, samplers):
    input_features = [
        text_feature(name="utterance", cell_type="lstm", reduce_output="sum"),
        category_feature(vocab_size=2, reduce_input="sum")]

    output_features = [category_feature(vocab_size=2, reduce_input="sum")]

    rel_path = generate_data(input_features, output_features, csv_filename)

    config = {
        "input_features": input_features,
        "output_features": output_features,
        "combiner": {"type": "concat", "num_fc_layers": 2},
        "training": {"epochs": 2, "learning_rate": 0.001}
    }

    output_feature_name = output_features[0]['name']

    
    hyperopt_configs = {
        "parameters": {
            "training.learning_rate": {
                "type": "float",
                "low": 0.0001,
                "high": 0.01,
                "space": "log",
                "steps": 3,
            },
            output_feature_name + ".fc_layers": {
                'type': 'category',
                'values': [
                    [{'fc_size': 512}, {'fc_size': 256}],
                    [{'fc_size': 512}],
                    [{'fc_size': 256}]
                ]
            },
            output_feature_name + ".fc_size": {
                "type": "int",
                "low": 32,
                "high": 256,
                "steps": 5
            },
            output_feature_name + ".num_fc_layers": {
                'type': 'int',
                'low': 1,
                'high': 5,
                'space': 'linear',
                'steps': 4
            }
        },
        "goal": "minimize",
        'output_feature': output_feature_name,
        'validation_metrics': 'loss',
        'executor': {'type': 'serial'},
        'sampler': {'type': samplers["type"], 'num_samples': 2}
    }

    # add hyperopt parameter space to the config
    config['hyperopt'] = hyperopt_configs

    hyperopt_results = hyperopt(
        config,
        dataset=rel_path,
        output_directory='results_hyperopt'
    )

    # check for return results
    assert isinstance(hyperopt_results, HyperoptResults)

    # check for existence of the hyperopt statistics file
    assert os.path.isfile(
        os.path.join('results_hyperopt', 'hyperopt_statistics.json')
    )

    if os.path.isfile(
        os.path.join('results_hyperopt', 'hyperopt_statistics.json')
    ):
        os.remove( 
            os.path.join('results_hyperopt', 'hyperopt_statistics.json')
        )


</source>
<source file="systems/ludwig-0.4.1/tests/conftest.py" startline="91" endline="152" pcid="203">
@pytest.fixture(scope='module')
def hyperopt_results():
    """
    This function generates hyperopt results
    """
    input_features = [
        text_feature(name="utterance", cell_type="lstm", reduce_output="sum"),
        category_feature(vocab_size=2, reduce_input="sum")]

    output_features = [category_feature(vocab_size=2, reduce_input="sum")]

    csv_filename = uuid.uuid4().hex[:10].upper() + '.csv'
    rel_path = generate_data(input_features, output_features, csv_filename)

    config = {
        "input_features": input_features,
        "output_features": output_features,
        "combiner": {"type": "concat", "num_fc_layers": 2},
        "training": {"epochs": 2, "learning_rate": 0.001}
    }

    output_feature_name = output_features[0]['name']

    hyperopt_configs = {
        "parameters": {
            "training.learning_rate": {
                "type": "float",
                "low": 0.0001,
                "high": 0.01,
                "space": "log",
                "steps": 3,
            },
            output_feature_name + ".fc_size": {
                "type": "int",
                "low": 32,
                "high": 256,
                "steps": 5
            },
            output_feature_name + ".num_fc_layers": {
                'type': 'int',
                'low': 1,
                'high': 5,
                'space': 'linear',
                'steps': 4
            }
        },
        "goal": "minimize",
        'output_feature': output_feature_name,
        'validation_metrics': 'loss',
        'executor': {'type': 'serial'},
        'sampler': {'type': 'random', 'num_samples': 2}
    }

    # add hyperopt parameter space to the config
    config['hyperopt'] = hyperopt_configs

    hyperopt(
        config,
        dataset=rel_path,
        output_directory='results'
    )

</source>
</class>

<class classid="11" nclones="3" nlines="23" similarity="75">
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_api.py" startline="349" endline="379" pcid="162">
def test_api_skip_parameters_train(
        csv_filename,
        skip_save_training_description,
        skip_save_training_statistics,
        skip_save_model,
        skip_save_progress,
        skip_save_log,
        skip_save_processed_input,
):
    # Single sequence input, single category output
    input_features = [category_feature(vocab_size=2)]
    output_features = [category_feature(vocab_size=2)]

    with tempfile.TemporaryDirectory() as output_dir:
        # Generate test data
        rel_path = generate_data(input_features, output_features,
                                 os.path.join(output_dir, csv_filename))
        run_api_commands(
            input_features,
            output_features,
            data_csv=rel_path,
            output_dir=output_dir,
            skip_save_training_description=skip_save_training_description,
            skip_save_training_statistics=skip_save_training_statistics,
            skip_save_model=skip_save_model,
            skip_save_progress=skip_save_progress,
            skip_save_log=skip_save_log,
            skip_save_processed_input=skip_save_processed_input,
        )


</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_api.py" startline="410" endline="438" pcid="164">
def test_api_skip_parameters_evaluate(
        csv_filename,
        skip_save_unprocessed_output,
        skip_save_predictions,
        skip_save_eval_stats,
        skip_collect_predictions,
        skip_collect_overall_stats,
):
    # Single sequence input, single category output
    input_features = [category_feature(vocab_size=2)]
    output_features = [category_feature(vocab_size=2)]

    with tempfile.TemporaryDirectory() as output_dir:
        # Generate test data
        rel_path = generate_data(input_features, output_features,
                                 os.path.join(output_dir, csv_filename))
        run_api_commands(
            input_features,
            output_features,
            data_csv=rel_path,
            output_dir=output_dir,
            skip_save_unprocessed_output=skip_save_unprocessed_output,
            skip_save_predictions=skip_save_predictions,
            skip_save_eval_stats=skip_save_eval_stats,
            skip_collect_predictions=skip_collect_predictions,
            skip_collect_overall_stats=skip_collect_overall_stats,
        )


</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_api.py" startline="382" endline="404" pcid="163">
def test_api_skip_parameters_predict(
        csv_filename,
        skip_save_unprocessed_output,
        skip_save_predictions,
):
    # Single sequence input, single category output
    input_features = [category_feature(vocab_size=2)]
    output_features = [category_feature(vocab_size=2)]

    with tempfile.TemporaryDirectory() as output_dir:
        # Generate test data
        rel_path = generate_data(input_features, output_features,
                                 os.path.join(output_dir, csv_filename))
        run_api_commands(
            input_features,
            output_features,
            data_csv=rel_path,
            output_dir=output_dir,
            skip_save_unprocessed_output=skip_save_unprocessed_output,
            skip_save_predictions=skip_save_predictions,
        )


</source>
</class>

<class classid="12" nclones="2" nlines="10" similarity="90">
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_experiment.py" startline="67" endline="81" pcid="166">

@pytest.mark.parametrize('encoder', ENCODERS)
def test_experiment_text_feature_non_HF(encoder, csv_filename):
    input_features = [
        text_feature(
            vocab_size=30,
            min_len=1,
            encoder=encoder,
            preprocessing={'word_tokenizer': 'space'}
        )
    ]
    output_features = [category_feature(vocab_size=2)]
    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    run_experiment(input_features, output_features, dataset=rel_path)
</source>
<source file="systems/ludwig-0.4.1/tests/integration_tests/test_experiment.py" startline="83" endline="98" pcid="167">

@spawn
def run_experiment_with_encoder(encoder, csv_filename):
    # Run in a subprocess to clear TF and prevent OOM
    # This also allows us to use GPU resources
    input_features = [
        text_feature(
            vocab_size=30,
            min_len=1,
            encoder=encoder,
        )
    ]
    output_features = [category_feature(vocab_size=2)]
    # Generate test data
    rel_path = generate_data(input_features, output_features, csv_filename)
    run_experiment(input_features, output_features, dataset=rel_path)
</source>
</class>

<class classid="13" nclones="3" nlines="22" similarity="77">
<source file="systems/ludwig-0.4.1/tests/ludwig/utils/test_hyperopt_utils.py" startline="77" endline="104" pcid="222">
@pytest.mark.parametrize("key", ["test_1", "test_2"])
def test_grid_strategy(key):
    hyperopt_test_params = HYPEROPT_PARAMS[key]
    goal = hyperopt_test_params["goal"]
    grid_sampler_params = hyperopt_test_params["parameters"]

    grid_sampler = GridSampler(goal=goal, parameters=grid_sampler_params)

    actual_params_keys = grid_sampler.sample().keys()
    expected_params_keys = grid_sampler_params.keys()

    for sample in grid_sampler.samples:
        for param in actual_params_keys:
            value = sample[param]
            param_type = grid_sampler_params[param]["type"]
            if param_type == "int" or param_type == "float":
                low = grid_sampler_params[param]["low"]
                high = grid_sampler_params[param]["high"]
                assert value >= low and value <= high
            else:
                assert value in set(grid_sampler_params[param]["values"])

    assert actual_params_keys == expected_params_keys
    assert grid_sampler.search_space == hyperopt_test_params[
        "expected_search_space"]
    assert len(
        grid_sampler.samples) == hyperopt_test_params["expected_len_grids"]

</source>
<source file="systems/ludwig-0.4.1/tests/ludwig/utils/test_hyperopt_utils.py" startline="106" endline="132" pcid="223">
@pytest.mark.parametrize("key", ["test_1", "test_2"])
def test_random_sampler(key):
    hyperopt_test_params = HYPEROPT_PARAMS[key]
    goal = hyperopt_test_params["goal"]
    random_sampler_params = hyperopt_test_params["parameters"]
    num_samples = hyperopt_test_params["num_samples"]

    random_sampler = RandomSampler(
        goal=goal, parameters=random_sampler_params, num_samples=num_samples)

    actual_params_keys = random_sampler.sample().keys()
    expected_params_keys = random_sampler_params.keys()

    for sample in random_sampler.samples:
        for param in actual_params_keys:
            value = sample[param]
            param_type = random_sampler_params[param]["type"]
            if param_type == "int" or param_type == "float":
                low = random_sampler_params[param]["low"]
                high = random_sampler_params[param]["high"]
                assert value >= low and value <= high
            else:
                assert value in set(random_sampler_params[param]["values"])

    assert actual_params_keys == expected_params_keys
    assert len(random_sampler.samples) == num_samples

</source>
<source file="systems/ludwig-0.4.1/tests/ludwig/utils/test_hyperopt_utils.py" startline="134" endline="162" pcid="224">
@pytest.mark.parametrize("key", ["test_1", "test_2"])
def test_pysot_sampler(key):
    hyperopt_test_params = HYPEROPT_PARAMS[key]
    goal = hyperopt_test_params["goal"]
    pysot_sampler_params = hyperopt_test_params["parameters"]
    num_samples = hyperopt_test_params["num_samples"]

    pysot_sampler = PySOTSampler(
        goal=goal, parameters=pysot_sampler_params, num_samples=num_samples)

    actual_params_keys = pysot_sampler.sample().keys()
    expected_params_keys = pysot_sampler_params.keys()

    pysot_sampler_samples = 1

    for _ in range(num_samples - 1):
        sample = pysot_sampler.sample()
        for param in actual_params_keys:
            value = sample[param]
            param_type = pysot_sampler_params[param]["type"]
            if param_type == "int" or param_type == "float":
                low = pysot_sampler_params[param]["low"]
                high = pysot_sampler_params[param]["high"]
                assert value >= low and value <= high
            else:
                assert value in set(pysot_sampler_params[param]["values"])
        pysot_sampler_samples += 1

    assert actual_params_keys == expected_params_keys
</source>
</class>

<class classid="14" nclones="2" nlines="35" similarity="80">
<source file="systems/ludwig-0.4.1/tests/ludwig/modules/test_encoder.py" startline="101" endline="146" pcid="242">

def test_image_encoders_resnet():
    # Test the resnet encoder for images
    encoder_args = {
        'resnet_size': 8, 'num_filters': 8, 'fc_size': 28,
        'weights_regularizer': L1_REGULARIZER,
        'bias_regularizer': L1_REGULARIZER,
        'activity_regularizer': L1_REGULARIZER,
        'dropout': DROPOUT
    }
    image_size = (10, 10, 3)

    output_shape = [1, 28]
    input_image = generate_images(image_size, 1)

    encoder = create_encoder(ResNetEncoder, encoder_args)
    encoder_test(
        encoder=encoder,
        input_data=input_image,
        output_dtype=np.float,
        output_shape=output_shape,
        output_data=None
    )

    output_shape = [5, 28]
    input_images = generate_images(image_size, 5)

    encoder_test(
        encoder=encoder,
        input_data=input_images,
        output_dtype=np.float,
        output_shape=output_shape,
        output_data=None
    )

    assert encoder is not None
    assert encoder.resnet.__class__.__name__ == 'ResNet'
    assert encoder.resnet.num_filters == 8
    assert encoder.resnet.resnet_size == 8
    assert encoder.resnet.filter_size == 3
    assert encoder.flatten.__class__.__name__ == 'Flatten'
    assert encoder.fc_stack.__class__.__name__ == 'FCStack'
    assert len(encoder.fc_stack.layers) == 1
    assert encoder.fc_stack.layers[0]['fc_size'] == 28
    assert encoder.fc_stack.layers[0]['activation'] == 'relu'

</source>
<source file="systems/ludwig-0.4.1/tests/ludwig/modules/test_encoder.py" startline="200" endline="244" pcid="244">

def test_image_encoders_mlpmixer():
    # Test the resnet encoder for images
    encoder_args = {
        'patch_size': 5, 'embed_size': 8, 'token_size': 32,
        'channel_dim': 16, 'num_layers': 2,
        'weights_regularizer': L1_REGULARIZER,
        'bias_regularizer': L1_REGULARIZER,
        'activity_regularizer': L1_REGULARIZER,
        'dropout': DROPOUT
    }
    image_size = (10, 10, 3)

    output_shape = [1, 8]
    input_image = generate_images(image_size, 1)

    encoder = create_encoder(MLPMixerEncoder, encoder_args)
    encoder_test(
        encoder=encoder,
        input_data=input_image,
        output_dtype=np.float,
        output_shape=output_shape,
        output_data=None
    )

    output_shape = [5, 8]
    input_images = generate_images(image_size, 5)

    encoder_test(
        encoder=encoder,
        input_data=input_images,
        output_dtype=np.float,
        output_shape=output_shape,
        output_data=None
    )

    assert encoder is not None
    assert encoder.mlp_mixer.__class__.__name__ == 'MLPMixer'
    assert len(encoder.mlp_mixer.mixer_blocks) == 2
    assert encoder.mlp_mixer.mixer_blocks[0].mlp1.hidden_size == 32
    assert encoder.mlp_mixer.mixer_blocks[0].mlp2.hidden_size == 16
    assert encoder.mlp_mixer.patch_conv.__class__.__name__ == 'Conv2D'
    assert encoder.mlp_mixer.patch_conv.kernel_size == (5, 5)
    assert encoder.mlp_mixer.patch_conv.strides == (5, 5)
    assert encoder.mlp_mixer.patch_conv.filters == 8
</source>
</class>

<class classid="15" nclones="2" nlines="25" similarity="76">
<source file="systems/ludwig-0.4.1/ludwig/decoders/generic_decoders.py" startline="32" endline="57" pcid="251">
    def __init__(
            self,
            use_bias=True,
            kernel_initializer='glorot_uniform',
            bias_initializer='zeros',
            kernel_regularizer=None,
            bias_regularizer=None,
            activity_regularizer=None,
            activation=None,
            **kwargs
    ):
        super().__init__()
        logger.debug(' {}'.format(self.name))

        logger.debug('  Dense')
        self.dense = Dense(
            1,
            use_bias=use_bias,
            kernel_initializer=kernel_initializer,
            bias_initializer=bias_initializer,
            kernel_regularizer=kernel_regularizer,
            bias_regularizer=bias_regularizer,
            activity_regularizer=activity_regularizer,
            activation=activation
        )

</source>
<source file="systems/ludwig-0.4.1/ludwig/decoders/generic_decoders.py" startline="120" endline="153" pcid="255">
    def __init__(
            self,
            num_classes,
            use_bias=True,
            weights_initializer='glorot_uniform',
            bias_initializer='zeros',
            weights_regularizer=None,
            bias_regularizer=None,
            activity_regularizer=None,
            **kwargs
    ):
        super().__init__()
        logger.debug(' {}'.format(self.name))

        logger.debug('  Dense')
        self.dense = Dense(
            num_classes,
            use_bias=use_bias,
            kernel_initializer=weights_initializer,
            bias_initializer=bias_initializer,
            kernel_regularizer=weights_regularizer,
            bias_regularizer=bias_regularizer,
            activity_regularizer=activity_regularizer
        )

        self.sampled_loss = False
        if LOSS in kwargs and TYPE in kwargs[LOSS] and kwargs[LOSS][TYPE] is not None:
            self.sampled_loss = kwargs[LOSS][TYPE].startswith('sampled')

        # this is needed because TF2 initialzies the weights at the first call
        # so the first time we need to compute the full dense,
        # otherwise the weights of the Dense layer would not be initialized
        self.first_call = True

</source>
</class>

<class classid="16" nclones="2" nlines="41" similarity="83">
<source file="systems/ludwig-0.4.1/ludwig/evaluate.py" startline="35" endline="137" pcid="283">
def evaluate_cli(
        model_path: str,
        dataset: Union[str, dict, pd.DataFrame] = None,
        data_format: str = None,
        split: str = FULL,
        batch_size: int = 128,
        skip_save_unprocessed_output: bool = False,
        skip_save_predictions: bool = False,
        skip_save_eval_stats: bool = False,
        skip_collect_predictions: bool = False,
        skip_collect_overall_stats: bool = False,
        output_directory: str = 'results',
        gpus: Union[str, int, List[int]] = None,
        gpu_memory_limit: int = None,
        allow_parallel_threads: bool = True,
        callbacks: List[Callback] = None,
        backend: Union[Backend, str] = None,
        logging_level: int = logging.INFO,
        debug: bool = False,
        **kwargs
) -> None:
    """
    Loads pre-trained model and evaluates its performance by comparing the
    predictions against ground truth.

    # Inputs

    :param model_path: (str) filepath to pre-trained model.
    :param dataset: (Union[str, dict, pandas.DataFrame], default: `None`)
        source containing the entire dataset to be used in the evaluation.
    :param data_format: (str, default: `None`) format to interpret data
        sources. Will be inferred automatically if not specified.  Valid
        formats are `'auto'`, `'csv'`, `'excel'`, `'feather'`,
        `'fwf'`, `'hdf5'` (cache file produced during previous training),
        `'html'` (file containing a single HTML `<table>`), `'json'`, `'jsonl'`,
        `'parquet'`, `'pickle'` (pickled Pandas DataFrame), `'sas'`, `'spss'`,
        `'stata'`, `'tsv'`.
    :param split: (str, default: `full`) split on which
        to perform predictions. Valid values are `'training'`, `'validation'`,
        `'test'` and `'full'`.
    :param batch_size: (int, default `128`) size of batches for processing.
    :param skip_save_unprocessed_output: (bool, default: `False`) by default
        predictions and their probabilities are saved in both raw
        unprocessed numpy files containing tensors and as postprocessed
        CSV files (one for each output feature). If this parameter is True,
        only the CSV ones are saved and the numpy ones are skipped.
    :param skip_save_predictions: (bool, default: `False`) skips saving test
        predictions CSV files
    :param skip_save_eval_stats: (bool, default: `False`) skips saving test
        statistics JSON file
   :param skip_collect_predictions: (bool, default: `False`) skips
        collecting post-processed predictions during eval.
    :param skip_collect_overall_stats: (bool, default: `False`) skips
        collecting overall stats during eval.
    :param output_directory: (str, default: `'results'`) the directory that
        will contain the training statistics, TensorBoard logs, the saved
        model and the training progress files.
    :param gpus: (list, default: `None`) list of GPUs that are available
        for training.
    :param gpu_memory_limit: (int, default: `None`) maximum memory in MB to
        allocate per GPU device.
    :param allow_parallel_threads: (bool, default: `True`) allow TensorFlow
        to use multithreading parallelism to improve performance at
        the cost of determinism.
    :param callbacks: (list, default: `None`) a list of
        `ludwig.callbacks.Callback` objects that provide hooks into the
        Ludwig pipeline.
    :param backend: (Union[Backend, str]) `Backend` or string name
        of backend to use to execute preprocessing / training steps.
    :param logging_level: (int) Log level that will be sent to stderr.
    :param debug: (bool, default: `False) if `True` turns on `tfdbg` with
        `inf_or_nan` checks.
        **kwargs:

    # Returns

    :return: (`None`)
    """
    model = LudwigModel.load(
        model_path,
        logging_level=logging_level,
        backend=backend,
        gpus=gpus,
        gpu_memory_limit=gpu_memory_limit,
        allow_parallel_threads=allow_parallel_threads,
        callbacks=callbacks,
    )
    model.evaluate(
        dataset=dataset,
        data_format=data_format,
        batch_size=batch_size,
        split=split,
        skip_save_unprocessed_output=skip_save_unprocessed_output,
        skip_save_predictions=skip_save_predictions,
        skip_save_eval_stats=skip_save_eval_stats,
        collect_predictions=not skip_collect_predictions,
        collect_overall_stats=not skip_collect_overall_stats,
        output_directory=output_directory,
        return_type='dict',
        debug=debug
    )


</source>
<source file="systems/ludwig-0.4.1/ludwig/predict.py" startline="35" endline="124" pcid="1056">
def predict_cli(
        model_path: str,
        dataset: Union[str, dict, pd.DataFrame] = None,
        data_format: str = None,
        split: str = FULL,
        batch_size: int = 128,
        skip_save_unprocessed_output: bool = False,
        skip_save_predictions: bool = False,
        output_directory: str = 'results',
        gpus: Union[str, int, List[int]] = None,
        gpu_memory_limit: int = None,
        allow_parallel_threads: bool = True,
        callbacks: List[Callback] = None,
        backend: Union[Backend, str] = None,
        logging_level: int = logging.INFO,
        debug: bool = False,
        **kwargs
) -> None:
    """
    Loads pre-trained model to make predictions on the provided data set.

    # Inputs

    :param model_path: (str) filepath to pre-trained model.
    :param dataset: (Union[str, dict, pandas.DataFrame], default: `None`)
        source containing the entire dataset to be used in the prediction.
    :param data_format: (str, default: `None`) format to interpret data
        sources. Will be inferred automatically if not specified.  Valid
        formats are `'auto'`, `'csv'`, `'excel'`, `'feather'`,
        `'fwf'`, `'hdf5'` (cache file produced during previous training),
        `'html'` (file containing a single HTML `<table>`), `'json'`, `'jsonl'`,
        `'parquet'`, `'pickle'` (pickled Pandas DataFrame), `'sas'`, `'spss'`,
        `'stata'`, `'tsv'`.
    :param split: (str, default: `full`) split on which
        to perform predictions. Valid values are `'training'`, `'validation'`,
        `'test'` and `'full'`.
    :param batch_size: (int, default `128`) size of batches for processing.
    :param skip_save_unprocessed_output: (bool, default: `False`) by default
        predictions and their probabilities are saved in both raw
        unprocessed numpy files containing tensors and as postprocessed
        CSV files (one for each output feature). If this parameter is True,
        only the CSV ones are saved and the numpy ones are skipped.
    :param skip_save_predictions: (bool, default: `False`) skips saving test
        predictions CSV files
    :param output_directory: (str, default: `'results'`) the directory that
        will contain the training statistics, TensorBoard logs, the saved
        model and the training progress files.
    :param gpus: (list, default: `None`) list of GPUs that are available
        for training.
    :param gpu_memory_limit: (int, default: `None`) maximum memory in MB to
        allocate per GPU device.
    :param allow_parallel_threads: (bool, default: `True`) allow TensorFlow
        to use multithreading parallelism to improve performance at
        the cost of determinism.
    :param callbacks: (list, default: `None`) a list of
        `ludwig.callbacks.Callback` objects that provide hooks into the
        Ludwig pipeline.
    :param backend: (Union[Backend, str]) `Backend` or string name
        of backend to use to execute preprocessing / training steps.
    :param logging_level: (int) Log level that will be sent to stderr.
    :param debug: (bool, default: `False) if `True` turns on `tfdbg` with
        `inf_or_nan` checks.
        **kwargs:

    # Returns

    :return: ('None')
    """
    model = LudwigModel.load(
        model_path,
        logging_level=logging_level,
        backend=backend,
        gpus=gpus,
        gpu_memory_limit=gpu_memory_limit,
        allow_parallel_threads=allow_parallel_threads,
        callbacks=callbacks,
    )
    model.predict(
        dataset=dataset,
        data_format=data_format,
        split=split,
        batch_size=batch_size,
        skip_save_unprocessed_output=skip_save_unprocessed_output,
        skip_save_predictions=skip_save_predictions,
        output_directory=output_directory,
        return_type='dict',
        debug=debug,
    )


</source>
</class>

<class classid="17" nclones="3" nlines="104" similarity="79">
<source file="systems/ludwig-0.4.1/ludwig/evaluate.py" startline="138" endline="297" pcid="284">
def cli(sys_argv):
    parser = argparse.ArgumentParser(
        description='This script loads a pretrained model '
                    'and evaluates its performance by comparing'
                    'its predictions with ground truth.',
        prog='ludwig evaluate',
        usage='%(prog)s [options]'
    )

    # ---------------
    # Data parameters
    # ---------------
    parser.add_argument(
        '--dataset',
        help='input data file path',
        required=True
    )
    parser.add_argument(
        '--data_format',
        help='format of the input data',
        default='auto',
        choices=['auto', 'csv', 'excel', 'feather', 'fwf', 'hdf5',
                 'html' 'tables', 'json', 'jsonl', 'parquet', 'pickle', 'sas',
                 'spss', 'stata', 'tsv']
    )
    parser.add_argument(
        '-s',
        '--split',
        default=FULL,
        choices=[TRAINING, VALIDATION, TEST, FULL],
        help='the split to test the model on'
    )

    # ----------------
    # Model parameters
    # ----------------
    parser.add_argument(
        '-m',
        '--model_path',
        help='model to load',
        required=True
    )

    # -------------------------
    # Output results parameters
    # -------------------------
    parser.add_argument(
        '-od',
        '--output_directory',
        type=str,
        default='results',
        help='directory that contains the results'
    )
    parser.add_argument(
        '-ssuo',
        '--skip_save_unprocessed_output',
        help='skips saving intermediate NPY output files',
        action='store_true', default=False
    )
    parser.add_argument(
        '-sses',
        '--skip_save_eval_stats',
        help='skips saving intermediate JSON eval statistics',
        action='store_true', default=False
    )
    parser.add_argument(
        '-scp',
        '--skip_collect_predictions',
        help='skips collecting predictions',
        action='store_true', default=False
    )
    parser.add_argument(
        '-scos',
        '--skip_collect_overall_stats',
        help='skips collecting overall stats',
        action='store_true', default=False
    )

    # ------------------
    # Generic parameters
    # ------------------
    parser.add_argument(
        '-bs',
        '--batch_size',
        type=int,
        default=128,
        help='size of batches'
    )

    # ------------------
    # Runtime parameters
    # ------------------
    parser.add_argument(
        '-g',
        '--gpus',
        type=int,
        default=0,
        help='list of gpu to use'
    )
    parser.add_argument(
        '-gml',
        '--gpu_memory_limit',
        type=int,
        default=None,
        help='maximum memory in MB to allocate per GPU device'
    )
    parser.add_argument(
        '-dpt',
        '--disable_parallel_threads',
        action='store_false',
        dest='allow_parallel_threads',
        help='disable TensorFlow from using multithreading for reproducibility'
    )
    parser.add_argument(
        "-b",
        "--backend",
        help='specifies backend to use for parallel / distributed execution, '
             'defaults to local execution or Horovod if called using horovodrun',
        choices=ALL_BACKENDS,
    )
    parser.add_argument(
        '-dbg',
        '--debug',
        action='store_true',
        default=False,
        help='enables debugging mode'
    )
    parser.add_argument(
        '-l',
        '--logging_level',
        default='info',
        help='the level of logging to use',
        choices=['critical', 'error', 'warning', 'info', 'debug', 'notset']
    )

    add_contrib_callback_args(parser)
    args = parser.parse_args(sys_argv)
    args.evaluate_performance = True

    args.callbacks = args.callbacks or []
    for callback in args.callbacks:
        callback.on_cmdline('evaluate', *sys_argv)

    args.logging_level = logging_level_registry[args.logging_level]
    logging.getLogger('ludwig').setLevel(
        args.logging_level
    )
    global logger
    logger = logging.getLogger('ludwig.test_performance')

    args.backend = initialize_backend(args.backend)
    if args.backend.is_coordinator():
        print_ludwig('Evaluate', LUDWIG_VERSION)
        logger.info('Dataset path: {}'.format(args.dataset))
        logger.info('Model path: {}'.format(args.model_path))
        logger.info('')

    evaluate_cli(**vars(args))


</source>
<source file="systems/ludwig-0.4.1/ludwig/collect.py" startline="216" endline="372" pcid="1017">
def cli_collect_activations(sys_argv):
    """Command Line Interface to communicate with the collection of tensors and
    there are several options that can specified when calling this function:

    --data_csv: Filepath for the input csv
    --data_hdf5: Filepath for the input hdf5 file, if there is a csv file, this
                 is not read
    --d: Refers to the dataset type of the file being read, by default is
         *generic*
    --s: Refers to the split of the data, can be one of: train, test,
         validation, full
    --m: Input model that is necessary to collect to the tensors, this is a
         required *option*
    --t: Tensors to collect
    --od: Output directory of the model, defaults to results
    --bs: Batch size
    --g: Number of gpus that are to be used
    --gf: Fraction of each GPUs memory to use.
    --dbg: Debug if the model is to be started with python debugger
    --v: Verbose: Defines the logging level that the user will be exposed to
    """
    parser = argparse.ArgumentParser(
        description='This script loads a pretrained model and uses it collect '
                    'tensors for each datapoint in the dataset.',
        prog='ludwig collect_activations',
        usage='%(prog)s [options]')

    # ---------------
    # Data parameters
    # ---------------
    parser.add_argument(
        '--dataset',
        help='input data file path',
        required=True
    )
    parser.add_argument(
        '--data_format',
        help='format of the input data',
        default='auto',
        choices=['auto', 'csv', 'excel', 'feather', 'fwf', 'hdf5',
                 'html' 'tables', 'json', 'jsonl', 'parquet', 'pickle', 'sas',
                 'spss', 'stata', 'tsv']
    )
    parser.add_argument(
        '-s',
        '--split',
        default=FULL,
        choices=[TRAINING, VALIDATION, TEST, FULL],
        help='the split to obtain the model activations from'
    )

    # ----------------
    # Model parameters
    # ----------------
    parser.add_argument(
        '-m',
        '--model_path',
        help='model to load',
        required=True
    )
    parser.add_argument(
        '-lyr',
        '--layers',
        help='tensors to collect',
        nargs='+',
        required=True
    )



    # -------------------------
    # Output results parameters
    # -------------------------
    parser.add_argument(
        '-od',
        '--output_directory',
        type=str,
        default='results',
        help='directory that contains the results'
    )

    # ------------------
    # Generic parameters
    # ------------------
    parser.add_argument(
        '-bs',
        '--batch_size',
        type=int,
        default=128,
        help='size of batches'
    )

    # ------------------
    # Runtime parameters
    # ------------------
    parser.add_argument(
        '-g',
        '--gpus',
        type=int,
        default=0,
        help='list of gpu to use'
    )
    parser.add_argument(
        '-gml',
        '--gpu_memory_limit',
        type=int,
        default=None,
        help='maximum memory in MB to allocate per GPU device'
    )
    parser.add_argument(
        '-dpt',
        '--disable_parallel_threads',
        action='store_false',
        dest='allow_parallel_threads',
        help='disable TensorFlow from using multithreading for reproducibility'
    )
    parser.add_argument(
        "-b",
        "--backend",
        help='specifies backend to use for parallel / distributed execution, '
             'defaults to local execution or Horovod if called using horovodrun',
        choices=ALL_BACKENDS,
    )
    parser.add_argument(
        '-dbg',
        '--debug',
        action='store_true',
        default=False,
        help='enables debugging mode'
    )
    parser.add_argument(
        '-l',
        '--logging_level',
        default='info',
        help='the level of logging to use',
        choices=['critical', 'error', 'warning', 'info', 'debug', 'notset']
    )

    add_contrib_callback_args(parser)
    args = parser.parse_args(sys_argv)

    args.callbacks = args.callbacks or []
    for callback in args.callbacks:
        callback.on_cmdline('collect_activations', *sys_argv)

    args.logging_level = logging_level_registry[args.logging_level]
    logging.getLogger('ludwig').setLevel(
        args.logging_level
    )
    global logger
    logger = logging.getLogger('ludwig.collect')

    print_ludwig('Collect Activations', LUDWIG_VERSION)

    collect_activations(**vars(args))


</source>
<source file="systems/ludwig-0.4.1/ludwig/predict.py" startline="125" endline="270" pcid="1057">
def cli(sys_argv):
    parser = argparse.ArgumentParser(
        description='This script loads a pretrained model '
                    'and uses it to predict',
        prog='ludwig predict',
        usage='%(prog)s [options]'
    )

    # ---------------
    # Data parameters
    # ---------------
    parser.add_argument(
        '--dataset',
        help='input data file path',
        required=True
    )
    parser.add_argument(
        '--data_format',
        help='format of the input data',
        default='auto',
        choices=['auto', 'csv', 'excel', 'feather', 'fwf', 'hdf5',
                 'html', 'tables', 'json', 'jsonl', 'parquet', 'pickle', 'sas',
                 'spss', 'stata', 'tsv']
    )
    parser.add_argument(
        '-s',
        '--split',
        default=FULL,
        choices=[TRAINING, VALIDATION, TEST, FULL],
        help='the split to test the model on'
    )

    # ----------------
    # Model parameters
    # ----------------
    parser.add_argument(
        '-m',
        '--model_path',
        help='model to load',
        required=True
    )

    # -------------------------
    # Output results parameters
    # -------------------------
    parser.add_argument(
        '-od',
        '--output_directory',
        type=str,
        default='results',
        help='directory that contains the results'
    )
    parser.add_argument(
        '-ssuo',
        '--skip_save_unprocessed_output',
        help='skips saving intermediate NPY output files',
        action='store_true', default=False
    )
    parser.add_argument(
        '-sstp',
        '--skip_save_predictions',
        help='skips saving predictions CSV files',
        action='store_true', default=False
    )

    # ------------------
    # Generic parameters
    # ------------------
    parser.add_argument(
        '-bs',
        '--batch_size',
        type=int,
        default=128,
        help='size of batches'
    )

    # ------------------
    # Runtime parameters
    # ------------------
    parser.add_argument(
        '-g',
        '--gpus',
        type=int,
        default=0,
        help='list of gpu to use'
    )
    parser.add_argument(
        '-gml',
        '--gpu_memory_limit',
        type=int,
        default=None,
        help='maximum memory in MB to allocate per GPU device'
    )
    parser.add_argument(
        '-dpt',
        '--disable_parallel_threads',
        action='store_false',
        dest='allow_parallel_threads',
        help='disable TensorFlow from using multithreading for reproducibility'
    )
    parser.add_argument(
        "-b",
        "--backend",
        help='specifies backend to use for parallel / distributed execution, '
             'defaults to local execution or Horovod if called using horovodrun',
        choices=ALL_BACKENDS,
    )
    parser.add_argument(
        '-dbg',
        '--debug',
        action='store_true',
        default=False,
        help='enables debugging mode'
    )
    parser.add_argument(
        '-l',
        '--logging_level',
        default='info',
        help='the level of logging to use',
        choices=['critical', 'error', 'warning', 'info', 'debug', 'notset']
    )

    add_contrib_callback_args(parser)
    args = parser.parse_args(sys_argv)

    args.callbacks = args.callbacks or []
    for callback in args.callbacks:
        callback.on_cmdline('predict', *sys_argv)

    args.logging_level = logging_level_registry[args.logging_level]
    logging.getLogger('ludwig').setLevel(
        args.logging_level
    )
    global logger
    logger = logging.getLogger('ludwig.predict')

    args.backend = initialize_backend(args.backend)
    if args.backend.is_coordinator():
        print_ludwig('Predict', LUDWIG_VERSION)
        logger.info('Dataset path: {}'.format(args.dataset))
        logger.info('Model path: {}'.format(args.model_path))
        logger.info('')

    predict_cli(**vars(args))


</source>
</class>

<class classid="18" nclones="7" nlines="110" similarity="73">
<source file="systems/ludwig-0.4.1/ludwig/encoders/sequence_encoders.py" startline="234" endline="504" pcid="335">
class ParallelCNN(SequenceEncoder):

    def __init__(
            self,
            should_embed=True,
            vocab=None,
            representation='dense',
            embedding_size=256,
            embeddings_trainable=True,
            pretrained_embeddings=None,
            embeddings_on_cpu=False,
            conv_layers=None,
            num_conv_layers=None,
            filter_size=3,
            num_filters=256,
            pool_function='max',
            pool_size=None,
            fc_layers=None,
            num_fc_layers=None,
            fc_size=256,
            use_bias=True,
            weights_initializer='glorot_uniform',
            bias_initializer='zeros',
            weights_regularizer=None,
            bias_regularizer=None,
            activity_regularizer=None,
            # weights_constraint=None,
            # bias_constraint=None,
            norm=None,
            norm_params=None,
            activation='relu',
            dropout=0,
            reduce_output='max',
            **kwargs):
        """
            :param should_embed: If True the input sequence is expected
                   to be made of integers and will be mapped into embeddings
            :type should_embed: Boolean
            :param vocab: Vocabulary of the input feature to encode
            :type vocab: List
            :param representation: the possible values are `dense` and `sparse`.
                   `dense` means the mebeddings are initialized randomly,
                   `sparse` meanse they are initialized to be one-hot encodings.
            :type representation: Str (one of 'dense' or 'sparse')
            :param embedding_size: it is the maximum embedding size, the actual
                   size will be `min(vocaularyb_size, embedding_size)`
                   for `dense` representations and exacly `vocaularyb_size`
                   for the `sparse` encoding, where `vocabulary_size` is
                   the number of different strings appearing in the training set
                   in the column the feature is named after (plus 1 for `<UNK>`).
            :type embedding_size: Integer
            :param embeddings_trainable: If `True` embeddings are trained during
                   the training process, if `False` embeddings are fixed.
                   It may be useful when loading pretrained embeddings
                   for avoiding finetuning them. This parameter has effect only
                   for `representation` is `dense` as `sparse` one-hot encodings
                    are not trainable.
            :type embeddings_trainable: Boolean
            :param pretrained_embeddings: by default `dense` embeddings
                   are initialized randomly, but this parameter allows to specify
                   a path to a file containing embeddings in the GloVe format.
                   When the file containing the embeddings is loaded, only the
                   embeddings with labels present in the vocabulary are kept,
                   the others are discarded. If the vocabulary contains strings
                   that have no match in the embeddings file, their embeddings
                   are initialized with the average of all other embedding plus
                   some random noise to make them different from each other.
                   This parameter has effect only if `representation` is `dense`.
            :type pretrained_embeddings: str (filepath)
            :param embeddings_on_cpu: by default embedings matrices are stored
                   on GPU memory if a GPU is used, as it allows
                   for faster access, but in some cases the embedding matrix
                   may be really big and this parameter forces the placement
                   of the embedding matrix in regular memroy and the CPU is used
                   to resolve them, slightly slowing down the process
                   as a result of data transfer between CPU and GPU memory.
            :param conv_layers: it is a list of dictionaries containing
                   the parameters of all the convolutional layers. The length
                   of the list determines the number of parallel convolutional
                   layers and the content of each dictionary determines
                   the parameters for a specific layer. The available parameters
                   for each layer are: `filter_size`, `num_filters`, `pool`,
                   `norm`, `activation` and `regularize`. If any of those values
                   is missing from the dictionary, the default one specified
                   as a parameter of the encoder will be used instead. If both
                   `conv_layers` and `num_conv_layers` are `None`, a default
                   list will be assigned to `conv_layers` with the value
                   `[{filter_size: 2}, {filter_size: 3}, {filter_size: 4},
                   {filter_size: 5}]`.
            :type conv_layers: List
            :param num_conv_layers: if `conv_layers` is `None`, this is
                   the number of parallel convolutional layers.
            :type num_conv_layers: Integer
            :param filter_size:  if a `filter_size` is not already specified in
                   `conv_layers` this is the default `filter_size` that
                   will be used for each layer. It indicates how wide is
                   the 1d convolutional filter.
            :type filter_size: Integer
            :param num_filters: if a `num_filters` is not already specified in
                   `conv_layers` this is the default `num_filters` that
                   will be used for each layer. It indicates the number
                   of filters, and by consequence the output channels of
                   the 1d convolution.
            :type num_filters: Integer
            :param pool_size: if a `pool_size` is not already specified
                  in `conv_layers` this is the default `pool_size` that
                  will be used for each layer. It indicates the size of
                  the max pooling that will be performed along the `s` sequence
                  dimension after the convolution operation.
            :type pool_size: Integer
            :param fc_layers: it is a list of dictionaries containing
                   the parameters of all the fully connected layers. The length
                   of the list determines the number of stacked fully connected
                   layers and the content of each dictionary determines
                   the parameters for a specific layer. The available parameters
                   for each layer are: `fc_size`, `norm`, `activation` and
                   `regularize`. If any of those values is missing from
                   the dictionary, the default one specified as a parameter of
                   the encoder will be used instead. If both `fc_layers` and
                   `num_fc_layers` are `None`, a default list will be assigned
                   to `fc_layers` with the value
                   `[{fc_size: 512}, {fc_size: 256}]`
                   (only applies if `reduce_output` is not `None`).
            :type fc_layers: List
            :param num_fc_layers: if `fc_layers` is `None`, this is the number
                   of stacked fully connected layers (only applies if
                   `reduce_output` is not `None`).
            :type num_fc_layers: Integer
            :param fc_size: if a `fc_size` is not already specified in
                   `fc_layers` this is the default `fc_size` that will be used
                   for each layer. It indicates the size of the output
                   of a fully connected layer.
            :type fc_size: Integer
            :param norm: if a `norm` is not already specified in `conv_layers`
                   or `fc_layers` this is the default `norm` that will be used
                   for each layer. It indicates the norm of the output.
            :type norm: str
            :param activation: Default activation function to use
            :type activation: Str
            :param dropout: determines if there should be a dropout layer before
                   returning the encoder output.
            :type dropout: Boolean
            :param initializer: the initializer to use. If `None` it uses
                   `glorot_uniform`. Options are: `constant`, `identity`,
                   `zeros`, `ones`, `orthogonal`, `normal`, `uniform`,
                   `truncated_normal`, `variance_scaling`, `glorot_normal`,
                   `glorot_uniform`, `xavier_normal`, `xavier_uniform`,
                   `he_normal`, `he_uniform`, `lecun_normal`, `lecun_uniform`.
                   Alternatively it is possible to specify a dictionary with
                   a key `type` that identifies the type of initialzier and
                   other keys for its parameters,
                   e.g. `{type: normal, mean: 0, stddev: 0}`.
                   To know the parameters of each initializer, please refer
                   to TensorFlow's documentation.
            :type initializer: str
            :param regularize: if a `regularize` is not already specified in
                   `conv_layers` or `fc_layers` this is the default `regularize`
                   that will be used for each layer. It indicates if
                   the layer weights should be considered when computing
                   a regularization loss.
            :type regularize:
            :param reduce_output: defines how to reduce the output tensor of
                   the convolutional layers along the `s` sequence length
                   dimention if the rank of the tensor is greater than 2.
                   Available values are: `sum`, `mean` or `avg`, `max`, `concat`
                   (concatenates along the first dimension), `last` (returns
                   the last vector of the first dimension) and `None` or `null`
                   (which does not reduce and returns the full tensor).
            :type reduce_output: str
        """
        super().__init__()
        logger.debug(' {}'.format(self.name))

        if conv_layers is not None and num_conv_layers is None:
            # use custom-defined layers
            self.conv_layers = conv_layers
            self.num_conv_layers = len(conv_layers)
        elif conv_layers is None and num_conv_layers is not None:
            # generate num_conv_layers with default parameters
            self.conv_layers = None
            self.num_conv_layers = num_conv_layers
        elif conv_layers is None and num_conv_layers is None:
            # use default layers with varying filter sizes
            self.conv_layers = [
                {'filter_size': 2},
                {'filter_size': 3},
                {'filter_size': 4},
                {'filter_size': 5}
            ]
            self.num_conv_layers = 4
        else:
            raise ValueError(
                'Invalid layer parametrization, use either conv_layers or'
                ' num_conv_layers'
            )

        # The user is expected to provide fc_layers or num_fc_layers
        # The following logic handles the case where the user either provides
        # both or neither.
        if fc_layers is None and num_fc_layers is None:
            # use default layers with varying filter sizes
            fc_layers = [
                {'fc_size': 512},
                {'fc_size': 256}
            ]
            num_fc_layers = 2
        elif fc_layers is not None and num_fc_layers is not None:
            raise ValueError(
                'Invalid layer parametrization, use either fc_layers or '
                'num_fc_layers only. Not both.'
            )

        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.should_embed = should_embed
        self.embed_sequence = None

        if self.should_embed:
            logger.debug('  EmbedSequence')
            self.embed_sequence = EmbedSequence(
                vocab,
                embedding_size,
                representation=representation,
                embeddings_trainable=embeddings_trainable,
                pretrained_embeddings=pretrained_embeddings,
                embeddings_on_cpu=embeddings_on_cpu,
                dropout=dropout,
                embedding_initializer=weights_initializer,
                embedding_regularizer=weights_regularizer
            )

        logger.debug('  ParallelConv1D')
        self.parallel_conv1d = ParallelConv1D(
            layers=self.conv_layers,
            default_num_filters=num_filters,
            default_filter_size=filter_size,
            default_use_bias=use_bias,
            default_weights_initializer=weights_initializer,
            default_bias_initializer=bias_initializer,
            default_weights_regularizer=weights_regularizer,
            default_bias_regularizer=bias_regularizer,
            default_activity_regularizer=activity_regularizer,
            # default_weights_constraint=None,
            # default_bias_constraint=None,
            default_norm=norm,
            default_norm_params=norm_params,
            default_activation=activation,
            default_dropout=dropout,
            default_pool_function=pool_function,
            default_pool_size=pool_size,
            default_pool_padding='same',
        )

        if self.reduce_output is not None:
            logger.debug('  FCStack')
            self.fc_stack = FCStack(
                layers=fc_layers,
                num_layers=num_fc_layers,
                default_fc_size=fc_size,
                default_use_bias=use_bias,
                default_weights_initializer=weights_initializer,
                default_bias_initializer=bias_initializer,
                default_weights_regularizer=weights_regularizer,
                default_bias_regularizer=bias_regularizer,
                default_activity_regularizer=activity_regularizer,
                # default_weights_constraint=weights_constraint,
                # default_bias_constraint=bias_constraint,
                default_norm=norm,
                default_norm_params=norm_params,
                default_activation=activation,
                default_dropout=dropout,
</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/sequence_encoders.py" startline="550" endline="856" pcid="337">
class StackedCNN(SequenceEncoder):

    def __init__(
            self,
            should_embed=True,
            vocab=None,
            representation='dense',
            embedding_size=256,
            embeddings_trainable=True,
            pretrained_embeddings=None,
            embeddings_on_cpu=False,
            conv_layers=None,
            num_conv_layers=None,
            num_filters=256,
            filter_size=5,
            strides=1,
            padding='same',
            dilation_rate=1,
            pool_function='max',
            pool_size=None,
            pool_strides=None,
            pool_padding='same',
            fc_layers=None,
            num_fc_layers=None,
            fc_size=256,
            use_bias=True,
            weights_initializer='glorot_uniform',
            bias_initializer='zeros',
            weights_regularizer=None,
            bias_regularizer=None,
            activity_regularizer=None,
            # weights_constraint=None,
            # bias_constraint=None,
            norm=None,
            norm_params=None,
            activation='relu',
            dropout=0,
            reduce_output='max',
            **kwargs
    ):
        """
            :param should_embed: If True the input sequence is expected
                   to be made of integers and will be mapped into embeddings
            :type should_embed: Boolean
            :param vocab: Vocabulary of the input feature to encode
            :type vocab: List
            :param representation: the possible values are `dense` and `sparse`.
                   `dense` means the mebeddings are initialized randomly,
                   `sparse` meanse they are initialized to be one-hot encodings.
            :type representation: Str (one of 'dense' or 'sparse')
            :param embedding_size: it is the maximum embedding size, the actual
                   size will be `min(vocaularyb_size, embedding_size)`
                   for `dense` representations and exacly `vocaularyb_size`
                   for the `sparse` encoding, where `vocabulary_size` is
                   the number of different strings appearing in the training set
                   in the column the feature is named after (plus 1 for `<UNK>`).
            :type embedding_size: Integer
            :param embeddings_trainable: If `True` embeddings are trained during
                   the training process, if `False` embeddings are fixed.
                   It may be useful when loading pretrained embeddings
                   for avoiding finetuning them. This parameter has effect only
                   for `representation` is `dense` as `sparse` one-hot encodings
                    are not trainable.
            :type embeddings_trainable: Boolean
            :param pretrained_embeddings: by default `dense` embeddings
                   are initialized randomly, but this parameter allows to specify
                   a path to a file containing embeddings in the GloVe format.
                   When the file containing the embeddings is loaded, only the
                   embeddings with labels present in the vocabulary are kept,
                   the others are discarded. If the vocabulary contains strings
                   that have no match in the embeddings file, their embeddings
                   are initialized with the average of all other embedding plus
                   some random noise to make them different from each other.
                   This parameter has effect only if `representation` is `dense`.
            :type pretrained_embeddings: str (filepath)
            :param embeddings_on_cpu: by default embedings matrices are stored
                   on GPU memory if a GPU is used, as it allows
                   for faster access, but in some cases the embedding matrix
                   may be really big and this parameter forces the placement
                   of the embedding matrix in regular memroy and the CPU is used
                   to resolve them, slightly slowing down the process
                   as a result of data transfer between CPU and GPU memory.
            :param conv_layers: it is a list of dictionaries containing
                   the parameters of all the convolutional layers. The length
                   of the list determines the number of parallel convolutional
                   layers and the content of each dictionary determines
                   the parameters for a specific layer. The available parameters
                   for each layer are: `filter_size`, `num_filters`, `pool`,
                   `norm`, `activation` and `regularize`. If any of those values
                   is missing from the dictionary, the default one specified
                   as a parameter of the encoder will be used instead. If both
                   `conv_layers` and `num_conv_layers` are `None`, a default
                   list will be assigned to `conv_layers` with the value
                   `[{filter_size: 2}, {filter_size: 3}, {filter_size: 4},
                   {filter_size: 5}]`.
            :type conv_layers: List
            :param num_conv_layers: if `conv_layers` is `None`, this is
                   the number of stacked convolutional layers.
            :type num_conv_layers: Integer
            :param filter_size:  if a `filter_size` is not already specified in
                   `conv_layers` this is the default `filter_size` that
                   will be used for each layer. It indicates how wide is
                   the 1d convolutional filter.
            :type filter_size: Integer
            :param num_filters: if a `num_filters` is not already specified in
                   `conv_layers` this is the default `num_filters` that
                   will be used for each layer. It indicates the number
                   of filters, and by consequence the output channels of
                   the 1d convolution.
            :type num_filters: Integer
            :param pool_size: if a `pool_size` is not already specified
                  in `conv_layers` this is the default `pool_size` that
                  will be used for each layer. It indicates the size of
                  the max pooling that will be performed along the `s` sequence
                  dimension after the convolution operation.
            :type pool_size: Integer
            :param fc_layers: it is a list of dictionaries containing
                   the parameters of all the fully connected layers. The length
                   of the list determines the number of stacked fully connected
                   layers and the content of each dictionary determines
                   the parameters for a specific layer. The available parameters
                   for each layer are: `fc_size`, `norm`, `activation` and
                   `regularize`. If any of those values is missing from
                   the dictionary, the default one specified as a parameter of
                   the encoder will be used instead. If both `fc_layers` and
                   `num_fc_layers` are `None`, a default list will be assigned
                   to `fc_layers` with the value
                   `[{fc_size: 512}, {fc_size: 256}]`
                   (only applies if `reduce_output` is not `None`).
            :type fc_layers: List
            :param num_fc_layers: if `fc_layers` is `None`, this is the number
                   of stacked fully connected layers (only applies if
                   `reduce_output` is not `None`).
            :type num_fc_layers: Integer
            :param fc_size: if a `fc_size` is not already specified in
                   `fc_layers` this is the default `fc_size` that will be used
                   for each layer. It indicates the size of the output
                   of a fully connected layer.
            :type fc_size: Integer
            :param norm: if a `norm` is not already specified in `conv_layers`
                   or `fc_layers` this is the default `norm` that will be used
                   for each layer. It indicates the norm of the output.
            :type norm: str
            :param activation: Default activation function to use
            :type activation: Str
            :param dropout: determines if there should be a dropout layer before
                   returning the encoder output.
            :type dropout: Boolean
            :param initializer: the initializer to use. If `None` it uses
                   `glorot_uniform`. Options are: `constant`, `identity`,
                   `zeros`, `ones`, `orthogonal`, `normal`, `uniform`,
                   `truncated_normal`, `variance_scaling`, `glorot_normal`,
                   `glorot_uniform`, `xavier_normal`, `xavier_uniform`,
                   `he_normal`, `he_uniform`, `lecun_normal`, `lecun_uniform`.
                   Alternatively it is possible to specify a dictionary with
                   a key `type` that identifies the type of initialzier and
                   other keys for its parameters,
                   e.g. `{type: normal, mean: 0, stddev: 0}`.
                   To know the parameters of each initializer, please refer
                   to TensorFlow's documentation.
            :type initializer: str
            :param regularize: if a `regularize` is not already specified in
                   `conv_layers` or `fc_layers` this is the default `regularize`
                   that will be used for each layer. It indicates if
                   the layer weights should be considered when computing
                   a regularization loss.
            :type regularize:
            :param reduce_output: defines how to reduce the output tensor of
                   the convolutional layers along the `s` sequence length
                   dimention if the rank of the tensor is greater than 2.
                   Available values are: `sum`, `mean` or `avg`, `max`, `concat`
                   (concatenates along the first dimension), `last` (returns
                   the last vector of the first dimension) and `None` or `null`
                   (which does not reduce and returns the full tensor).
            :type reduce_output: str
        """
        super().__init__()
        logger.debug(' {}'.format(self.name))

        if conv_layers is not None and num_conv_layers is None:
            # use custom-defined layers
            self.conv_layers = conv_layers
            self.num_conv_layers = len(conv_layers)
        elif conv_layers is None and num_conv_layers is not None:
            # generate num_conv_layers with default parameters
            self.conv_layers = None
            self.num_conv_layers = num_conv_layers
        elif conv_layers is None and num_conv_layers is None:
            # use default layers with varying filter sizes
            self.conv_layers = [
                {
                    'filter_size': 7,
                    'pool_size': 3,
                    'regularize': False
                },
                {
                    'filter_size': 7,
                    'pool_size': 3,
                    'regularize': False
                },
                {
                    'filter_size': 3,
                    'pool_size': None,
                    'regularize': False
                },
                {
                    'filter_size': 3,
                    'pool_size': None,
                    'regularize': False
                },
                {
                    'filter_size': 3,
                    'pool_size': None,
                    'regularize': True
                },
                {
                    'filter_size': 3,
                    'pool_size': 3,
                    'regularize': True
                }
            ]
            self.num_conv_layers = 6
        else:
            raise ValueError(
                'Invalid layer parametrization, use either conv_layers or '
                'num_conv_layers'
            )

        # The user is expected to provide fc_layers or num_fc_layers
        # The following logic handles the case where the user either provides
        # both or neither.
        if fc_layers is None and num_fc_layers is None:
            # use default layers with varying filter sizes
            fc_layers = [
                {'fc_size': 512},
                {'fc_size': 256}
            ]
            num_fc_layers = 2
        elif fc_layers is not None and num_fc_layers is not None:
            raise ValueError(
                'Invalid layer parametrization, use either fc_layers or '
                'num_fc_layers only. Not both.'
            )

        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.should_embed = should_embed
        self.embed_sequence = None

        if self.should_embed:
            logger.debug('  EmbedSequence')
            self.embed_sequence = EmbedSequence(
                vocab,
                embedding_size,
                representation=representation,
                embeddings_trainable=embeddings_trainable,
                pretrained_embeddings=pretrained_embeddings,
                embeddings_on_cpu=embeddings_on_cpu,
                dropout=dropout,
                embedding_initializer=weights_initializer,
                embedding_regularizer=weights_regularizer
            )

        logger.debug('  Conv1DStack')
        self.conv1d_stack = Conv1DStack(
            layers=self.conv_layers,
            default_num_filters=num_filters,
            default_filter_size=filter_size,
            default_strides=strides,
            default_padding=padding,
            default_dilation_rate=dilation_rate,
            default_use_bias=use_bias,
            default_weights_initializer=weights_initializer,
            default_bias_initializer=bias_initializer,
            default_weights_regularizer=weights_regularizer,
            default_bias_regularizer=bias_regularizer,
            default_activity_regularizer=activity_regularizer,
            # default_weights_constraint=None,
            # default_bias_constraint=None,
            default_norm=norm,
            default_norm_params=norm_params,
            default_activation=activation,
            default_dropout=dropout,
            default_pool_function=pool_function,
            default_pool_size=pool_size,
            default_pool_strides=pool_strides,
            default_pool_padding=pool_padding,
        )

        if self.reduce_output is not None:
            logger.debug('  FCStack')
            self.fc_stack = FCStack(
                layers=fc_layers,
                num_layers=num_fc_layers,
                default_fc_size=fc_size,
                default_use_bias=use_bias,
                default_weights_initializer=weights_initializer,
                default_bias_initializer=bias_initializer,
                default_weights_regularizer=weights_regularizer,
                default_bias_regularizer=bias_regularizer,
                default_activity_regularizer=activity_regularizer,
                # default_weights_constraint=weights_constraint,
                # default_bias_constraint=bias_constraint,
                default_norm=norm,
                default_norm_params=norm_params,
                default_activation=activation,
                default_dropout=dropout,
</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/sequence_encoders.py" startline="1251" endline="1481" pcid="341">
class StackedRNN(SequenceEncoder):

    def __init__(
            self,
            should_embed=True,
            vocab=None,
            representation='dense',
            embedding_size=256,
            embeddings_trainable=True,
            pretrained_embeddings=None,
            embeddings_on_cpu=False,
            num_layers=1,
            state_size=256,
            cell_type='rnn',
            bidirectional=False,
            activation='tanh',
            recurrent_activation='sigmoid',
            unit_forget_bias=True,
            recurrent_initializer='orthogonal',
            recurrent_regularizer=None,
            # recurrent_constraint=None,
            dropout=0.0,
            recurrent_dropout=0.0,
            fc_layers=None,
            num_fc_layers=0,
            fc_size=256,
            use_bias=True,
            weights_initializer='glorot_uniform',
            bias_initializer='zeros',
            weights_regularizer=None,
            bias_regularizer=None,
            activity_regularizer=None,
            # weights_constraint=None,
            # bias_constraint=None,
            norm=None,
            norm_params=None,
            fc_activation='relu',
            fc_dropout=0,
            reduce_output='last',
            **kwargs
    ):
        """
            :param should_embed: If True the input sequence is expected
                   to be made of integers and will be mapped into embeddings
            :type should_embed: Boolean
            :param vocab: Vocabulary of the input feature to encode
            :type vocab: List
            :param representation: the possible values are `dense` and `sparse`.
                   `dense` means the mebeddings are initialized randomly,
                   `sparse` meanse they are initialized to be one-hot encodings.
            :type representation: Str (one of 'dense' or 'sparse')
            :param embedding_size: it is the maximum embedding size, the actual
                   size will be `min(vocaularyb_size, embedding_size)`
                   for `dense` representations and exacly `vocaularyb_size`
                   for the `sparse` encoding, where `vocabulary_size` is
                   the number of different strings appearing in the training set
                   in the column the feature is named after (plus 1 for `<UNK>`).
            :type embedding_size: Integer
            :param embeddings_trainable: If `True` embeddings are trained during
                   the training process, if `False` embeddings are fixed.
                   It may be useful when loading pretrained embeddings
                   for avoiding finetuning them. This parameter has effect only
                   for `representation` is `dense` as `sparse` one-hot encodings
                    are not trainable.
            :type embeddings_trainable: Boolean
            :param pretrained_embeddings: by default `dense` embeddings
                   are initialized randomly, but this parameter allows to specify
                   a path to a file containing embeddings in the GloVe format.
                   When the file containing the embeddings is loaded, only the
                   embeddings with labels present in the vocabulary are kept,
                   the others are discarded. If the vocabulary contains strings
                   that have no match in the embeddings file, their embeddings
                   are initialized with the average of all other embedding plus
                   some random noise to make them different from each other.
                   This parameter has effect only if `representation` is `dense`.
            :type pretrained_embeddings: str (filepath)
            :param embeddings_on_cpu: by default embedings matrices are stored
                   on GPU memory if a GPU is used, as it allows
                   for faster access, but in some cases the embedding matrix
                   may be really big and this parameter forces the placement
                   of the embedding matrix in regular memroy and the CPU is used
                   to resolve them, slightly slowing down the process
                   as a result of data transfer between CPU and GPU memory.
            :param conv_layers: it is a list of dictionaries containing
                   the parameters of all the convolutional layers. The length
                   of the list determines the number of parallel convolutional
                   layers and the content of each dictionary determines
                   the parameters for a specific layer. The available parameters
                   for each layer are: `filter_size`, `num_filters`, `pool`,
                   `norm`, `activation` and `regularize`. If any of those values
                   is missing from the dictionary, the default one specified
                   as a parameter of the encoder will be used instead. If both
                   `conv_layers` and `num_conv_layers` are `None`, a default
                   list will be assigned to `conv_layers` with the value
                   `[{filter_size: 2}, {filter_size: 3}, {filter_size: 4},
                   {filter_size: 5}]`.
            :type conv_layers: List
            :param num_conv_layers: if `conv_layers` is `None`, this is
                   the number of stacked convolutional layers.
            :type num_conv_layers: Integer
            :param filter_size:  if a `filter_size` is not already specified in
                   `conv_layers` this is the default `filter_size` that
                   will be used for each layer. It indicates how wide is
                   the 1d convolutional filter.
            :type filter_size: Integer
            :param num_filters: if a `num_filters` is not already specified in
                   `conv_layers` this is the default `num_filters` that
                   will be used for each layer. It indicates the number
                   of filters, and by consequence the output channels of
                   the 1d convolution.
            :type num_filters: Integer
            :param pool_size: if a `pool_size` is not already specified
                  in `conv_layers` this is the default `pool_size` that
                  will be used for each layer. It indicates the size of
                  the max pooling that will be performed along the `s` sequence
                  dimension after the convolution operation.
            :type pool_size: Integer
            :param num_rec_layers: the number of stacked recurrent layers.
            :type num_rec_layers: Integer
            :param cell_type: the type of recurrent cell to use.
                   Avalable values are: `rnn`, `lstm`, `lstm_block`, `lstm`,
                   `ln`, `lstm_cudnn`, `gru`, `gru_block`, `gru_cudnn`.
                   For reference about the differences between the cells please
                   refer to TensorFlow's documentstion. We suggest to use the
                   `block` variants on CPU and the `cudnn` variants on GPU
                   because of their increased speed.
            :type cell_type: str
            :param state_size: the size of the state of the rnn.
            :type state_size: Integer
            :param bidirectional: if `True` two recurrent networks will perform
                   encoding in the forward and backward direction and
                   their outputs will be concatenated.
            :type bidirectional: Boolean
            :param dropout: determines if there should be a dropout layer before
                   returning the encoder output.
            :type dropout: Boolean
            :param initializer: the initializer to use. If `None` it uses
                   `glorot_uniform`. Options are: `constant`, `identity`,
                   `zeros`, `ones`, `orthogonal`, `normal`, `uniform`,
                   `truncated_normal`, `variance_scaling`, `glorot_normal`,
                   `glorot_uniform`, `xavier_normal`, `xavier_uniform`,
                   `he_normal`, `he_uniform`, `lecun_normal`, `lecun_uniform`.
                   Alternatively it is possible to specify a dictionary with
                   a key `type` that identifies the type of initialzier and
                   other keys for its parameters,
                   e.g. `{type: normal, mean: 0, stddev: 0}`.
                   To know the parameters of each initializer, please refer
                   to TensorFlow's documentation.
            :type initializer: str
            :param regularize: if a `regularize` is not already specified in
                   `conv_layers` or `fc_layers` this is the default `regularize`
                   that will be used for each layer. It indicates if
                   the layer weights should be considered when computing
                   a regularization loss.
            :type regularize:
            :param reduce_output: defines how to reduce the output tensor of
                   the convolutional layers along the `s` sequence length
                   dimention if the rank of the tensor is greater than 2.
                   Available values are: `sum`, `mean` or `avg`, `max`, `concat`
                   (concatenates along the first dimension), `last` (returns
                   the last vector of the first dimension) and `None` or `null`
                   (which does not reduce and returns the full tensor).
            :type reduce_output: str
        """
        super().__init__()
        logger.debug(' {}'.format(self.name))

        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        if self.reduce_output is None:
            self.supports_masking = True

        self.should_embed = should_embed
        self.embed_sequence = None

        if self.should_embed:
            logger.debug('  EmbedSequence')
            self.embed_sequence = EmbedSequence(
                vocab,
                embedding_size,
                representation=representation,
                embeddings_trainable=embeddings_trainable,
                pretrained_embeddings=pretrained_embeddings,
                embeddings_on_cpu=embeddings_on_cpu,
                dropout=fc_dropout,
                embedding_initializer=weights_initializer,
                embedding_regularizer=weights_regularizer
            )

        logger.debug('  RecurrentStack')
        self.recurrent_stack = RecurrentStack(
            state_size=state_size,
            cell_type=cell_type,
            num_layers=num_layers,
            bidirectional=bidirectional,
            activation=activation,
            recurrent_activation=recurrent_activation,
            use_bias=use_bias,
            unit_forget_bias=unit_forget_bias,
            weights_initializer=weights_initializer,
            recurrent_initializer=recurrent_initializer,
            bias_initializer=bias_initializer,
            weights_regularizer=weights_regularizer,
            recurrent_regularizer=recurrent_regularizer,
            bias_regularizer=bias_regularizer,
            activity_regularizer=activity_regularizer,
            # kernel_constraint=kernel_constraint,
            # recurrent_constraint=recurrent_constraint,
            # bias_constraint=bias_constraint,
            dropout=dropout,
            recurrent_dropout=recurrent_dropout,
        )

        if self.reduce_output is not None:
            logger.debug('  FCStack')
            self.fc_stack = FCStack(
                layers=fc_layers,
                num_layers=num_fc_layers,
                default_fc_size=fc_size,
                default_use_bias=use_bias,
                default_weights_initializer=weights_initializer,
                default_bias_initializer=bias_initializer,
                default_weights_regularizer=weights_regularizer,
                default_bias_regularizer=bias_regularizer,
                default_activity_regularizer=activity_regularizer,
                # default_weights_constraint=weights_constraint,
                # default_bias_constraint=bias_constraint,
                default_norm=norm,
                default_norm_params=norm_params,
                default_activation=fc_activation,
                default_dropout=fc_dropout,
</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/sequence_encoders.py" startline="908" endline="1199" pcid="339">
class StackedParallelCNN(SequenceEncoder):

    def __init__(
            self,
            should_embed=True,
            vocab=None,
            representation='dense',
            embedding_size=256,
            embeddings_trainable=True,
            pretrained_embeddings=None,
            embeddings_on_cpu=False,
            stacked_layers=None,
            num_stacked_layers=None,
            filter_size=3,
            num_filters=256,
            pool_function='max',
            pool_size=None,
            fc_layers=None,
            num_fc_layers=None,
            fc_size=256,
            use_bias=True,
            weights_initializer='glorot_uniform',
            bias_initializer='zeros',
            weights_regularizer=None,
            bias_regularizer=None,
            activity_regularizer=None,
            # weights_constraint=None,
            # bias_constraint=None,
            norm=None,
            norm_params=None,
            activation='relu',
            dropout=0,
            reduce_output='max',
            **kwargs
    ):
        """
            :param should_embed: If True the input sequence is expected
                   to be made of integers and will be mapped into embeddings
            :type should_embed: Boolean
            :param vocab: Vocabulary of the input feature to encode
            :type vocab: List
            :param representation: the possible values are `dense` and `sparse`.
                   `dense` means the mebeddings are initialized randomly,
                   `sparse` meanse they are initialized to be one-hot encodings.
            :type representation: Str (one of 'dense' or 'sparse')
            :param embedding_size: it is the maximum embedding size, the actual
                   size will be `min(vocaularyb_size, embedding_size)`
                   for `dense` representations and exacly `vocaularyb_size`
                   for the `sparse` encoding, where `vocabulary_size` is
                   the number of different strings appearing in the training set
                   in the column the feature is named after (plus 1 for `<UNK>`).
            :type embedding_size: Integer
            :param embeddings_trainable: If `True` embeddings are trained during
                   the training process, if `False` embeddings are fixed.
                   It may be useful when loading pretrained embeddings
                   for avoiding finetuning them. This parameter has effect only
                   for `representation` is `dense` as `sparse` one-hot encodings
                    are not trainable.
            :type embeddings_trainable: Boolean
            :param pretrained_embeddings: by default `dense` embeddings
                   are initialized randomly, but this parameter allows to specify
                   a path to a file containing embeddings in the GloVe format.
                   When the file containing the embeddings is loaded, only the
                   embeddings with labels present in the vocabulary are kept,
                   the others are discarded. If the vocabulary contains strings
                   that have no match in the embeddings file, their embeddings
                   are initialized with the average of all other embedding plus
                   some random noise to make them different from each other.
                   This parameter has effect only if `representation` is `dense`.
            :type pretrained_embeddings: str (filepath)
            :param embeddings_on_cpu: by default embedings matrices are stored
                   on GPU memory if a GPU is used, as it allows
                   for faster access, but in some cases the embedding matrix
                   may be really big and this parameter forces the placement
                   of the embedding matrix in regular memroy and the CPU is used
                   to resolve them, slightly slowing down the process
                   as a result of data transfer between CPU and GPU memory.
            :param stacked_layers: it is a of lists of list of dictionaries
                   containing the parameters of the stack of
                   parallel convolutional layers. The length of the list
                   determines the number of stacked parallel
                   convolutional layers, length of the sub-lists determines
                   the number of parallel conv layers and the content
                   of each dictionary determines the parameters for
                   a specific layer. The available parameters for each layer are:
                   `filter_size`, `num_filters`, `pool_size`, `norm`,
                   `activation` and `regularize`. If any of those values
                   is missing from the dictionary, the default one specified
                   as a parameter of the encoder will be used instead. If both
                   `stacked_layers` and `num_stacked_layers` are `None`,
                   a default list will be assigned to `stacked_layers` with
                   the value `[[{filter_size: 2}, {filter_size: 3},
                   {filter_size: 4}, {filter_size: 5}], [{filter_size: 2},
                   {filter_size: 3}, {filter_size: 4}, {filter_size: 5}],
                   [{filter_size: 2}, {filter_size: 3}, {filter_size: 4},
                   {filter_size: 5}]]`.
            :type stacked_layers: List
            :param num_stacked_layers: if `stacked_layers` is `None`, this is
                   the number of elements in the stack of
                   parallel convolutional layers.
            :type num_stacked_layers: Integer
            :param filter_size:  if a `filter_size` is not already specified in
                   `conv_layers` this is the default `filter_size` that
                   will be used for each layer. It indicates how wide is
                   the 1d convolutional filter.
            :type filter_size: Integer
            :param num_filters: if a `num_filters` is not already specified in
                   `conv_layers` this is the default `num_filters` that
                   will be used for each layer. It indicates the number
                   of filters, and by consequence the output channels of
                   the 1d convolution.
            :type num_filters: Integer
            :param pool_size: if a `pool_size` is not already specified
                  in `conv_layers` this is the default `pool_size` that
                  will be used for each layer. It indicates the size of
                  the max pooling that will be performed along the `s` sequence
                  dimension after the convolution operation.
            :type pool_size: Integer
            :param fc_layers: it is a list of dictionaries containing
                   the parameters of all the fully connected layers. The length
                   of the list determines the number of stacked fully connected
                   layers and the content of each dictionary determines
                   the parameters for a specific layer. The available parameters
                   for each layer are: `fc_size`, `norm`, `activation` and
                   `regularize`. If any of those values is missing from
                   the dictionary, the default one specified as a parameter of
                   the encoder will be used instead. If both `fc_layers` and
                   `num_fc_layers` are `None`, a default list will be assigned
                   to `fc_layers` with the value
                   `[{fc_size: 512}, {fc_size: 256}]`
                   (only applies if `reduce_output` is not `None`).
            :type fc_layers: List
            :param num_fc_layers: if `fc_layers` is `None`, this is the number
                   of stacked fully connected layers (only applies if
                   `reduce_output` is not `None`).
            :type num_fc_layers: Integer
            :param fc_size: if a `fc_size` is not already specified in
                   `fc_layers` this is the default `fc_size` that will be used
                   for each layer. It indicates the size of the output
                   of a fully connected layer.
            :type fc_size: Integer
            :param norm: if a `norm` is not already specified in `conv_layers`
                   or `fc_layers` this is the default `norm` that will be used
                   for each layer. It indicates the norm of the output.
            :type norm: str
            :param activation: Default activation function to use
            :type activation: Str
            :param dropout: determines if there should be a dropout layer before
                   returning the encoder output.
            :type dropout: Boolean
            :param initializer: the initializer to use. If `None` it uses
                   `glorot_uniform`. Options are: `constant`, `identity`,
                   `zeros`, `ones`, `orthogonal`, `normal`, `uniform`,
                   `truncated_normal`, `variance_scaling`, `glorot_normal`,
                   `glorot_uniform`, `xavier_normal`, `xavier_uniform`,
                   `he_normal`, `he_uniform`, `lecun_normal`, `lecun_uniform`.
                   Alternatively it is possible to specify a dictionary with
                   a key `type` that identifies the type of initialzier and
                   other keys for its parameters,
                   e.g. `{type: normal, mean: 0, stddev: 0}`.
                   To know the parameters of each initializer, please refer
                   to TensorFlow's documentation.
            :type initializer: str
            :param regularize: if a `regularize` is not already specified in
                   `conv_layers` or `fc_layers` this is the default `regularize`
                   that will be used for each layer. It indicates if
                   the layer weights should be considered when computing
                   a regularization loss.
            :type regularize:
            :param reduce_output: defines how to reduce the output tensor of
                   the convolutional layers along the `s` sequence length
                   dimention if the rank of the tensor is greater than 2.
                   Available values are: `sum`, `mean` or `avg`, `max`, `concat`
                   (concatenates along the first dimension), `last` (returns
                   the last vector of the first dimension) and `None` or `null`
                   (which does not reduce and returns the full tensor).
            :type reduce_output: str
        """
        super().__init__()
        logger.debug(' {}'.format(self.name))

        if stacked_layers is not None and num_stacked_layers is None:
            # use custom-defined layers
            self.stacked_layers = stacked_layers
            self.num_stacked_layers = len(stacked_layers)
        elif stacked_layers is None and num_stacked_layers is not None:
            # generate num_conv_layers with default parameters
            self.stacked_layers = None
            self.num_stacked_layers = num_stacked_layers
        elif stacked_layers is None and num_stacked_layers is None:
            # use default layers with varying filter sizes
            self.stacked_layers = [
                [
                    {'filter_size': 2},
                    {'filter_size': 3},
                    {'filter_size': 4},
                    {'filter_size': 5}
                ],
                [
                    {'filter_size': 2},
                    {'filter_size': 3},
                    {'filter_size': 4},
                    {'filter_size': 5}
                ],
                [
                    {'filter_size': 2},
                    {'filter_size': 3},
                    {'filter_size': 4},
                    {'filter_size': 5}
                ]
            ]
            self.num_stacked_layers = 6
        else:
            raise ValueError(
                'Invalid layer parametrization, use either stacked_layers or'
                ' num_stacked_layers'
            )

        # The user is expected to provide fc_layers or num_fc_layers
        # The following logic handles the case where the user either provides
        # both or neither.
        if fc_layers is None and num_fc_layers is None:
            # use default layers with varying filter sizes
            fc_layers = [
                {'fc_size': 512},
                {'fc_size': 256}
            ]
            num_fc_layers = 2
        elif fc_layers is not None and num_fc_layers is not None:
            raise ValueError(
                'Invalid layer parametrization, use either fc_layers or '
                'num_fc_layers only. Not both.'
            )

        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.should_embed = should_embed
        self.embed_sequence = None

        if self.should_embed:
            logger.debug('  EmbedSequence')
            self.embed_sequence = EmbedSequence(
                vocab,
                embedding_size,
                representation=representation,
                embeddings_trainable=embeddings_trainable,
                pretrained_embeddings=pretrained_embeddings,
                embeddings_on_cpu=embeddings_on_cpu,
                dropout=dropout,
                embedding_initializer=weights_initializer,
                embedding_regularizer=weights_regularizer
            )

        logger.debug('  ParallelConv1DStack')
        self.parallel_conv1d_stack = ParallelConv1DStack(
            stacked_layers=self.stacked_layers,
            default_num_filters=num_filters,
            default_filter_size=filter_size,
            default_use_bias=use_bias,
            default_weights_initializer=weights_initializer,
            default_bias_initializer=bias_initializer,
            default_weights_regularizer=weights_regularizer,
            default_bias_regularizer=bias_regularizer,
            default_activity_regularizer=activity_regularizer,
            # default_weights_constraint=weights_constraint,
            # default_bias_constraint=bias_constraint,
            default_norm=norm,
            default_norm_params=norm_params,
            default_activation=activation,
            default_dropout=dropout,
            default_pool_function=pool_function,
            default_pool_size=pool_size,
        )

        if self.reduce_output is not None:
            logger.debug('  FCStack')
            self.fc_stack = FCStack(
                layers=fc_layers,
                num_layers=num_fc_layers,
                default_fc_size=fc_size,
                default_use_bias=use_bias,
                default_weights_initializer=weights_initializer,
                default_bias_initializer=bias_initializer,
                default_weights_regularizer=weights_regularizer,
                default_bias_regularizer=bias_regularizer,
                default_activity_regularizer=activity_regularizer,
                # default_weights_constraint=weights_constraint,
                # default_bias_constraint=bias_constraint,
                default_norm=norm,
                default_norm_params=norm_params,
                default_activation=activation,
                default_dropout=dropout,
</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/sequence_encoders.py" startline="1536" endline="1789" pcid="343">
class StackedCNNRNN(SequenceEncoder):

    def __init__(
            self,
            should_embed=True,
            vocab=None,
            representation='dense',
            embedding_size=256,
            embeddings_trainable=True,
            pretrained_embeddings=None,
            embeddings_on_cpu=False,
            conv_layers=None,
            num_conv_layers=1,
            num_filters=256,
            filter_size=5,
            strides=1,
            padding='same',
            dilation_rate=1,
            conv_activation='relu',
            conv_dropout=0.0,
            pool_function='max',
            pool_size=2,
            pool_strides=None,
            pool_padding='same',
            num_rec_layers=1,
            state_size=256,
            cell_type='rnn',
            bidirectional=False,
            activation='tanh',
            recurrent_activation='sigmoid',
            unit_forget_bias=True,
            recurrent_initializer='orthogonal',
            recurrent_regularizer=None,
            # recurrent_constraint=None,
            dropout=0.0,
            recurrent_dropout=0.0,
            fc_layers=None,
            num_fc_layers=0,
            fc_size=256,
            use_bias=True,
            weights_initializer='glorot_uniform',
            bias_initializer='zeros',
            weights_regularizer=None,
            bias_regularizer=None,
            activity_regularizer=None,
            # weights_constraint=None,
            # bias_constraint=None,
            norm=None,
            norm_params=None,
            fc_activation='relu',
            fc_dropout=0,
            reduce_output='last',
            **kwargs
    ):
        """
            :param should_embed: If True the input sequence is expected
                   to be made of integers and will be mapped into embeddings
            :type should_embed: Boolean
            :param vocab: Vocabulary of the input feature to encode
            :type vocab: List
            :param representation: the possible values are `dense` and `sparse`.
                   `dense` means the mebeddings are initialized randomly,
                   `sparse` meanse they are initialized to be one-hot encodings.
            :type representation: Str (one of 'dense' or 'sparse')
            :param embedding_size: it is the maximum embedding size, the actual
                   size will be `min(vocaularyb_size, embedding_size)`
                   for `dense` representations and exacly `vocaularyb_size`
                   for the `sparse` encoding, where `vocabulary_size` is
                   the number of different strings appearing in the training set
                   in the column the feature is named after (plus 1 for `<UNK>`).
            :type embedding_size: Integer
            :param embeddings_trainable: If `True` embeddings are trained during
                   the training process, if `False` embeddings are fixed.
                   It may be useful when loading pretrained embeddings
                   for avoiding finetuning them. This parameter has effect only
                   for `representation` is `dense` as `sparse` one-hot encodings
                    are not trainable.
            :type embeddings_trainable: Boolean
            :param pretrained_embeddings: by default `dense` embeddings
                   are initialized randomly, but this parameter allows to specify
                   a path to a file containing embeddings in the GloVe format.
                   When the file containing the embeddings is loaded, only the
                   embeddings with labels present in the vocabulary are kept,
                   the others are discarded. If the vocabulary contains strings
                   that have no match in the embeddings file, their embeddings
                   are initialized with the average of all other embedding plus
                   some random noise to make them different from each other.
                   This parameter has effect only if `representation` is `dense`.
            :type pretrained_embeddings: str (filepath)
            :param embeddings_on_cpu: by default embedings matrices are stored
                   on GPU memory if a GPU is used, as it allows
                   for faster access, but in some cases the embedding matrix
                   may be really big and this parameter forces the placement
                   of the embedding matrix in regular memroy and the CPU is used
                   to resolve them, slightly slowing down the process
                   as a result of data transfer between CPU and GPU memory.
            :param num_layers: the number of stacked recurrent layers.
            :type num_layers: Integer
            :param cell_type: the type of recurrent cell to use.
                   Avalable values are: `rnn`, `lstm`, `lstm_block`, `lstm`,
                   `ln`, `lstm_cudnn`, `gru`, `gru_block`, `gru_cudnn`.
                   For reference about the differences between the cells please
                   refer to TensorFlow's documentstion. We suggest to use the
                   `block` variants on CPU and the `cudnn` variants on GPU
                   because of their increased speed.
            :type cell_type: str
            :param state_size: the size of the state of the rnn.
            :type state_size: Integer
            :param bidirectional: if `True` two recurrent networks will perform
                   encoding in the forward and backward direction and
                   their outputs will be concatenated.
            :type bidirectional: Boolean
            :param dropout: determines if there should be a dropout layer before
                   returning the encoder output.
            :type dropout: Boolean
            :param initializer: the initializer to use. If `None` it uses
                   `glorot_uniform`. Options are: `constant`, `identity`,
                   `zeros`, `ones`, `orthogonal`, `normal`, `uniform`,
                   `truncated_normal`, `variance_scaling`, `glorot_normal`,
                   `glorot_uniform`, `xavier_normal`, `xavier_uniform`,
                   `he_normal`, `he_uniform`, `lecun_normal`, `lecun_uniform`.
                   Alternatively it is possible to specify a dictionary with
                   a key `type` that identifies the type of initialzier and
                   other keys for its parameters,
                   e.g. `{type: normal, mean: 0, stddev: 0}`.
                   To know the parameters of each initializer, please refer
                   to TensorFlow's documentation.
            :type initializer: str
            :param regularize: if a `regularize` is not already specified in
                   `conv_layers` or `fc_layers` this is the default `regularize`
                   that will be used for each layer. It indicates if
                   the layer weights should be considered when computing
                   a regularization loss.
            :type regularize:
            :param reduce_output: defines how to reduce the output tensor of
                   the convolutional layers along the `s` sequence length
                   dimention if the rank of the tensor is greater than 2.
                   Available values are: `sum`, `mean` or `avg`, `max`, `concat`
                   (concatenates along the first dimension), `last` (returns
                   the last vector of the first dimension) and `None` or `null`
                   (which does not reduce and returns the full tensor).
            :type reduce_output: str
        """
        super().__init__()
        logger.debug(' {}'.format(self.name))

        if conv_layers is not None and num_conv_layers is None:
            # use custom-defined layers
            self.conv_layers = conv_layers
            self.num_conv_layers = len(conv_layers)
        elif conv_layers is None and num_conv_layers is not None:
            # generate num_conv_layers with default parameters
            self.conv_layers = None
            self.num_conv_layers = num_conv_layers
        elif conv_layers is None and num_conv_layers is None:
            # use default layers with varying filter sizes
            self.conv_layers = [
                {'pool_size': 3},
                {'pool_size': None}
            ]
            self.num_conv_layers = 2
        else:
            raise ValueError(
                'Invalid layer parametrization, use either conv_layers or '
                'num_conv_layers'
            )

        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.should_embed = should_embed
        self.embed_sequence = None

        if self.should_embed:
            logger.debug('  EmbedSequence')
            self.embed_sequence = EmbedSequence(
                vocab,
                embedding_size,
                representation=representation,
                embeddings_trainable=embeddings_trainable,
                pretrained_embeddings=pretrained_embeddings,
                embeddings_on_cpu=embeddings_on_cpu,
                dropout=fc_dropout,
                embedding_initializer=weights_initializer,
                embedding_regularizer=weights_regularizer
            )

        logger.debug('  Conv1DStack')
        self.conv1d_stack = Conv1DStack(
            layers=self.conv_layers,
            default_num_filters=num_filters,
            default_filter_size=filter_size,
            default_strides=strides,
            default_padding=padding,
            default_dilation_rate=dilation_rate,
            default_use_bias=use_bias,
            default_weights_initializer=weights_initializer,
            default_bias_initializer=bias_initializer,
            default_weights_regularizer=weights_regularizer,
            default_bias_regularizer=bias_regularizer,
            default_activity_regularizer=activity_regularizer,
            # default_weights_constraint=None,
            # default_bias_constraint=None,
            default_norm=norm,
            default_norm_params=norm_params,
            default_activation=conv_activation,
            default_dropout=conv_dropout,
            default_pool_function=pool_function,
            default_pool_size=pool_size,
            default_pool_strides=pool_strides,
            default_pool_padding=pool_padding,
        )

        logger.debug('  RecurrentStack')
        self.recurrent_stack = RecurrentStack(
            state_size=state_size,
            cell_type=cell_type,
            num_layers=num_rec_layers,
            bidirectional=bidirectional,
            activation=activation,
            recurrent_activation=recurrent_activation,
            use_bias=use_bias,
            unit_forget_bias=unit_forget_bias,
            weights_initializer=weights_initializer,
            recurrent_initializer=recurrent_initializer,
            bias_initializer=bias_initializer,
            weights_regularizer=weights_regularizer,
            recurrent_regularizer=recurrent_regularizer,
            bias_regularizer=bias_regularizer,
            activity_regularizer=activity_regularizer,
            # kernel_constraint=kernel_constraint,
            # recurrent_constraint=recurrent_constraint,
            # bias_constraint=bias_constraint,
            dropout=dropout,
            recurrent_dropout=recurrent_dropout,
        )

        if self.reduce_output is not None:
            logger.debug('  FCStack')
            self.fc_stack = FCStack(
                layers=fc_layers,
                num_layers=num_fc_layers,
                default_fc_size=fc_size,
                default_use_bias=use_bias,
                default_weights_initializer=weights_initializer,
                default_bias_initializer=bias_initializer,
                default_weights_regularizer=weights_regularizer,
                default_bias_regularizer=bias_regularizer,
                default_activity_regularizer=activity_regularizer,
                # default_weights_constraint=weights_constraint,
                # default_bias_constraint=bias_constraint,
                default_norm=norm,
                default_norm_params=norm_params,
                default_activation=fc_activation,
                default_dropout=fc_dropout,
</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/image_encoders.py" startline="45" endline="136" pcid="362">

    def __init__(
            self,
            conv_layers=None,
            num_conv_layers=None,
            filter_size=3,
            num_filters=32,
            strides=(1, 1),
            padding='valid',
            dilation_rate=(1, 1),
            conv_use_bias=True,
            conv_weights_initializer='glorot_uniform',
            conv_bias_initializer='zeros',
            conv_weights_regularizer=None,
            conv_bias_regularizer=None,
            conv_activity_regularizer=None,
            # conv_weights_constraint=None,
            # conv_bias_constraint=None,
            conv_norm=None,
            conv_norm_params=None,
            conv_activation='relu',
            conv_dropout=0,
            pool_function='max',
            pool_size=(2, 2),
            pool_strides=None,
            fc_layers=None,
            num_fc_layers=1,
            fc_size=128,
            fc_use_bias=True,
            fc_weights_initializer='glorot_uniform',
            fc_bias_initializer='zeros',
            fc_weights_regularizer=None,
            fc_bias_regularizer=None,
            fc_activity_regularizer=None,
            # fc_weights_constraint=None,
            # fc_bias_constraint=None,
            fc_norm=None,
            fc_norm_params=None,
            fc_activation='relu',
            fc_dropout=0,
            **kwargs
    ):
        super().__init__()

        logger.debug(' {}'.format(self.name))

        logger.debug('  Conv2DStack')
        self.conv_stack_2d = Conv2DStack(
            layers=conv_layers,
            num_layers=num_conv_layers,
            default_num_filters=num_filters,
            default_filter_size=filter_size,
            default_strides=strides,
            default_padding=padding,
            default_dilation_rate=dilation_rate,
            default_use_bias=conv_use_bias,
            default_weights_initializer=conv_weights_initializer,
            default_bias_initializer=conv_bias_initializer,
            default_weights_regularizer=conv_weights_regularizer,
            default_bias_regularizer=conv_bias_regularizer,
            default_activity_regularizer=conv_activity_regularizer,
            # default_weights_constraint=conv_weights_constraint,
            # default_bias_constraint=conv_bias_constraint,
            default_norm=conv_norm,
            default_norm_params=conv_norm_params,
            default_activation=conv_activation,
            default_dropout=conv_dropout,
            default_pool_function=pool_function,
            default_pool_size=pool_size,
            default_pool_strides=pool_strides,
        )

        self.flatten = Flatten()

        logger.debug('  FCStack')
        self.fc_stack = FCStack(
            layers=fc_layers,
            num_layers=num_fc_layers,
            default_fc_size=fc_size,
            default_use_bias=fc_use_bias,
            default_weights_initializer=fc_weights_initializer,
            default_bias_initializer=fc_bias_initializer,
            default_weights_regularizer=fc_weights_regularizer,
            default_bias_regularizer=fc_bias_regularizer,
            default_activity_regularizer=fc_activity_regularizer,
            # default_weights_constraint=fc_weights_constraint,
            # default_bias_constraint=fc_bias_constraint,
            default_norm=fc_norm,
            default_norm_params=fc_norm_params,
            default_activation=fc_activation,
            default_dropout=fc_dropout,
        )
</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/sequence_encoders.py" startline="1850" endline="2070" pcid="345">
class StackedTransformer(SequenceEncoder):

    def __init__(
            self,
            max_sequence_length,
            should_embed=True,
            vocab=None,
            representation='dense',
            embedding_size=256,
            embeddings_trainable=True,
            pretrained_embeddings=None,
            embeddings_on_cpu=False,
            num_layers=1,
            hidden_size=256,
            num_heads=8,
            transformer_fc_size=256,
            dropout=0.1,
            fc_layers=None,
            num_fc_layers=0,
            fc_size=256,
            use_bias=True,
            weights_initializer='glorot_uniform',
            bias_initializer='zeros',
            weights_regularizer=None,
            bias_regularizer=None,
            activity_regularizer=None,
            # weights_constraint=None,
            # bias_constraint=None,
            norm=None,
            norm_params=None,
            fc_activation='relu',
            fc_dropout=0,
            reduce_output='last',
            **kwargs
    ):
        """
            :param should_embed: If True the input sequence is expected
                   to be made of integers and will be mapped into embeddings
            :type should_embed: Boolean
            :param vocab: Vocabulary of the input feature to encode
            :type vocab: List
            :param representation: the possible values are `dense` and `sparse`.
                   `dense` means the mebeddings are initialized randomly,
                   `sparse` meanse they are initialized to be one-hot encodings.
            :type representation: Str (one of 'dense' or 'sparse')
            :param embedding_size: it is the maximum embedding size, the actual
                   size will be `min(vocaularyb_size, embedding_size)`
                   for `dense` representations and exacly `vocaularyb_size`
                   for the `sparse` encoding, where `vocabulary_size` is
                   the number of different strings appearing in the training set
                   in the column the feature is named after (plus 1 for `<UNK>`).
            :type embedding_size: Integer
            :param embeddings_trainable: If `True` embeddings are trained during
                   the training process, if `False` embeddings are fixed.
                   It may be useful when loading pretrained embeddings
                   for avoiding finetuning them. This parameter has effect only
                   for `representation` is `dense` as `sparse` one-hot encodings
                    are not trainable.
            :type embeddings_trainable: Boolean
            :param pretrained_embeddings: by default `dense` embeddings
                   are initialized randomly, but this parameter allows to specify
                   a path to a file containing embeddings in the GloVe format.
                   When the file containing the embeddings is loaded, only the
                   embeddings with labels present in the vocabulary are kept,
                   the others are discarded. If the vocabulary contains strings
                   that have no match in the embeddings file, their embeddings
                   are initialized with the average of all other embedding plus
                   some random noise to make them different from each other.
                   This parameter has effect only if `representation` is `dense`.
            :type pretrained_embeddings: str (filepath)
            :param embeddings_on_cpu: by default embedings matrices are stored
                   on GPU memory if a GPU is used, as it allows
                   for faster access, but in some cases the embedding matrix
                   may be really big and this parameter forces the placement
                   of the embedding matrix in regular memroy and the CPU is used
                   to resolve them, slightly slowing down the process
                   as a result of data transfer between CPU and GPU memory.
            :param conv_layers: it is a list of dictionaries containing
                   the parameters of all the convolutional layers. The length
                   of the list determines the number of parallel convolutional
                   layers and the content of each dictionary determines
                   the parameters for a specific layer. The available parameters
                   for each layer are: `filter_size`, `num_filters`, `pool`,
                   `norm`, `activation` and `regularize`. If any of those values
                   is missing from the dictionary, the default one specified
                   as a parameter of the encoder will be used instead. If both
                   `conv_layers` and `num_conv_layers` are `None`, a default
                   list will be assigned to `conv_layers` with the value
                   `[{filter_size: 2}, {filter_size: 3}, {filter_size: 4},
                   {filter_size: 5}]`.
            :type conv_layers: List
            :param num_conv_layers: if `conv_layers` is `None`, this is
                   the number of stacked convolutional layers.
            :type num_conv_layers: Integer
            :param filter_size:  if a `filter_size` is not already specified in
                   `conv_layers` this is the default `filter_size` that
                   will be used for each layer. It indicates how wide is
                   the 1d convolutional filter.
            :type filter_size: Integer
            :param num_filters: if a `num_filters` is not already specified in
                   `conv_layers` this is the default `num_filters` that
                   will be used for each layer. It indicates the number
                   of filters, and by consequence the output channels of
                   the 1d convolution.
            :type num_filters: Integer
            :param pool_size: if a `pool_size` is not already specified
                  in `conv_layers` this is the default `pool_size` that
                  will be used for each layer. It indicates the size of
                  the max pooling that will be performed along the `s` sequence
                  dimension after the convolution operation.
            :type pool_size: Integer
            :param num_rec_layers: the number of stacked recurrent layers.
            :type num_rec_layers: Integer
            :param cell_type: the type of recurrent cell to use.
                   Avalable values are: `rnn`, `lstm`, `lstm_block`, `lstm`,
                   `ln`, `lstm_cudnn`, `gru`, `gru_block`, `gru_cudnn`.
                   For reference about the differences between the cells please
                   refer to TensorFlow's documentstion. We suggest to use the
                   `block` variants on CPU and the `cudnn` variants on GPU
                   because of their increased speed.
            :type cell_type: str
            :param state_size: the size of the state of the rnn.
            :type state_size: Integer
            :param bidirectional: if `True` two recurrent networks will perform
                   encoding in the forward and backward direction and
                   their outputs will be concatenated.
            :type bidirectional: Boolean
            :param dropout: determines if there should be a dropout layer before
                   returning the encoder output.
            :type dropout: Boolean
            :param initializer: the initializer to use. If `None` it uses
                   `glorot_uniform`. Options are: `constant`, `identity`,
                   `zeros`, `ones`, `orthogonal`, `normal`, `uniform`,
                   `truncated_normal`, `variance_scaling`, `glorot_normal`,
                   `glorot_uniform`, `xavier_normal`, `xavier_uniform`,
                   `he_normal`, `he_uniform`, `lecun_normal`, `lecun_uniform`.
                   Alternatively it is possible to specify a dictionary with
                   a key `type` that identifies the type of initialzier and
                   other keys for its parameters,
                   e.g. `{type: normal, mean: 0, stddev: 0}`.
                   To know the parameters of each initializer, please refer
                   to TensorFlow's documentation.
            :type initializer: str
            :param regularize: if a `regularize` is not already specified in
                   `conv_layers` or `fc_layers` this is the default `regularize`
                   that will be used for each layer. It indicates if
                   the layer weights should be considered when computing
                   a regularization loss.
            :type regularize:
            :param reduce_output: defines how to reduce the output tensor of
                   the convolutional layers along the `s` sequence length
                   dimention if the rank of the tensor is greater than 2.
                   Available values are: `sum`, `mean` or `avg`, `max`, `concat`
                   (concatenates along the first dimension), `last` (returns
                   the last vector of the first dimension) and `None` or `null`
                   (which does not reduce and returns the full tensor).
            :type reduce_output: str
        """
        super().__init__()
        logger.debug(' {}'.format(self.name))

        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        if self.reduce_output is None:
            self.supports_masking = True

        self.should_embed = should_embed
        self.should_project = False
        self.embed_sequence = None

        if self.should_embed:
            logger.debug('  EmbedSequence')
            self.embed_sequence = TokenAndPositionEmbedding(
                max_sequence_length,
                vocab,
                embedding_size,
                representation=representation,
                embeddings_trainable=embeddings_trainable,
                pretrained_embeddings=pretrained_embeddings,
                embeddings_on_cpu=embeddings_on_cpu,
                dropout=dropout,
                embedding_initializer=weights_initializer,
                embedding_regularizer=weights_regularizer
            )

            if embedding_size != hidden_size:
                logger.debug('  project_to_embed_size Dense')
                self.project_to_hidden_size = Dense(hidden_size)
                self.should_project = True
        else:
            logger.debug('  project_to_embed_size Dense')
            self.project_to_hidden_size = Dense(hidden_size)
            self.should_project = True

        logger.debug('  TransformerStack')
        self.transformer_stack = TransformerStack(
            hidden_size=hidden_size,
            num_heads=num_heads,
            fc_size=transformer_fc_size,
            num_layers=num_layers,
            dropout=dropout
        )

        if self.reduce_output is not None:
            logger.debug('  FCStack')
            self.fc_stack = FCStack(
                layers=fc_layers,
                num_layers=num_fc_layers,
                default_fc_size=fc_size,
                default_use_bias=use_bias,
                default_weights_initializer=weights_initializer,
                default_bias_initializer=bias_initializer,
                default_weights_regularizer=weights_regularizer,
                default_bias_regularizer=bias_regularizer,
                default_activity_regularizer=activity_regularizer,
                # default_weights_constraint=weights_constraint,
                # default_bias_constraint=bias_constraint,
                default_norm=norm,
                default_norm_params=norm_params,
                default_activation=fc_activation,
                default_dropout=fc_dropout,
</source>
</class>

<class classid="19" nclones="6" nlines="21" similarity="76">
<source file="systems/ludwig-0.4.1/ludwig/encoders/sequence_encoders.py" startline="505" endline="546" pcid="336">
            )

    def call(self, inputs, training=None, mask=None):
        """
            :param inputs: The input sequence fed into the encoder.
                   Shape: [batch x sequence length], type tf.int
            :type inputs: Tensor
            :param training: bool specifying if in training mode (important for dropout)
            :type training: bool
        """
        # ================ Embeddings ================
        if self.should_embed:
            embedded_sequence = self.embed_sequence(
                inputs, training=training, mask=mask
            )
        else:
            embedded_sequence = inputs
            while len(embedded_sequence.shape) < 3:
                embedded_sequence = tf.expand_dims(embedded_sequence, -1)

        # shape=(?, sequence_length, embedding_size)
        hidden = embedded_sequence

        # ================ Conv Layers ================
        hidden = self.parallel_conv1d(
            hidden,
            training=training,
            mask=mask
        )

        # ================ Sequence Reduction ================
        if self.reduce_output is not None:
            hidden = self.reduce_sequence(hidden)

            # ================ FC Layers ================
            hidden = self.fc_stack(
                hidden,
                training=training,
                mask=mask
            )

        return {'encoder_output': hidden}
</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/sequence_encoders.py" startline="1482" endline="1532" pcid="342">
            )

    def call(self, inputs, training=None, mask=None):
        """
            :param input_sequence: The input sequence fed into the encoder.
                   Shape: [batch x sequence length], type tf.int32
            :type input_sequence: Tensor
            :param regularizer: The regularizer to use for the weights
                   of the encoder.
            :type regularizer:
            :param dropout: Tensor (tf.float) of the probability of dropout
            :type dropout: Tensor
            :param is_training: Tesnor (tf.bool) specifying if in training mode
                   (important for dropout)
            :type is_training: Tensor
        """
        # ================ Embeddings ================
        if self.should_embed:
            embedded_sequence = self.embed_sequence(
                inputs, training=training, mask=mask
            )
        else:
            embedded_sequence = inputs
            while len(embedded_sequence.shape) < 3:
                embedded_sequence = tf.expand_dims(embedded_sequence, -1)

        # shape=(?, sequence_length, embedding_size)
        hidden = embedded_sequence

        # ================ Recurrent Layers ================
        hidden, final_state = self.recurrent_stack(
            hidden,
            training=training,
            mask=mask
        )

        # ================ Sequence Reduction ================
        if self.reduce_output is not None:
            hidden = self.reduce_sequence(hidden)

            # ================ FC Layers ================
            hidden = self.fc_stack(
                hidden,
                training=training,
                mask=mask
            )

        return {
            'encoder_output': hidden,
            'encoder_output_state': final_state
        }
</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/sequence_encoders.py" startline="1200" endline="1247" pcid="340">
            )

    def call(self, inputs, training=None, mask=None):
        """
            :param inputs: The input sequence fed into the encoder.
                   Shape: [batch x sequence length], type tf.int32
            :type inputs: Tensor
            :param regularizer: The regularizer to use for the weights
                   of the encoder.
            :type regularizer:
            :param dropout: Tensor (tf.float) of the probability of dropout
            :type dropout: Tensor
            :param is_training: Tesnor (tf.bool) specifying if in training mode
                   (important for dropout)
            :type is_training: Tensor
        """
        # ================ Embeddings ================
        if self.should_embed:
            embedded_sequence = self.embed_sequence(
                inputs, training=training, mask=mask
            )
        else:
            embedded_sequence = inputs
            while len(embedded_sequence.shape) < 3:
                embedded_sequence = tf.expand_dims(embedded_sequence, -1)

        # shape=(?, sequence_length, embedding_size)
        hidden = embedded_sequence

        # ================ Conv Layers ================
        hidden = self.parallel_conv1d_stack(
            hidden,
            training=training,
            mask=mask
        )

        # ================ Sequence Reduction ================
        if self.reduce_output is not None:
            hidden = self.reduce_sequence(hidden)

            # ================ FC Layers ================
            hidden = self.fc_stack(
                hidden,
                training=training,
                mask=mask
            )

        return {'encoder_output': hidden}
</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/sequence_encoders.py" startline="857" endline="904" pcid="338">
            )

    def call(self, inputs, training=None, mask=None):
        """
            :param input_sequence: The input sequence fed into the encoder.
                   Shape: [batch x sequence length], type tf.int32
            :type input_sequence: Tensor
            :param regularizer: The regularizer to use for the weights
                   of the encoder.
            :type regularizer:
            :param dropout: Tensor (tf.float) of the probability of dropout
            :type dropout: Tensor
            :param is_training: Tesnor (tf.bool) specifying if in training mode
                   (important for dropout)
            :type is_training: Tensor
        """
        # ================ Embeddings ================
        if self.should_embed:
            embedded_sequence = self.embed_sequence(
                inputs, training=training, mask=mask
            )
        else:
            embedded_sequence = inputs
            while len(embedded_sequence.shape) < 3:
                embedded_sequence = tf.expand_dims(embedded_sequence, -1)

        # shape=(?, sequence_length, embedding_size)
        hidden = embedded_sequence

        # ================ Conv Layers ================
        hidden = self.conv1d_stack(
            hidden,
            training=training,
            mask=mask
        )

        # ================ Sequence Reduction ================
        if self.reduce_output is not None:
            hidden = self.reduce_sequence(hidden)

            # ================ FC Layers ================
            hidden = self.fc_stack(
                hidden,
                training=training,
                mask=mask
            )

        return {'encoder_output': hidden}
</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/sequence_encoders.py" startline="1790" endline="1846" pcid="344">
            )

    def call(self, inputs, training=None, mask=None):
        """
            :param input_sequence: The input sequence fed into the encoder.
                   Shape: [batch x sequence length], type tf.int32
            :type input_sequence: Tensor
            :param regularizer: The regularizer to use for the weights
                   of the encoder.
            :type regularizer:
            :param dropout: Tensor (tf.float) of the probability of dropout
            :type dropout: Tensor
            :param is_training: Tesnor (tf.bool) specifying if in training mode
                   (important for dropout)
            :type is_training: Tensor
        """
        # ================ Embeddings ================
        if self.should_embed:
            embedded_sequence = self.embed_sequence(
                inputs, training=training, mask=mask
            )
        else:
            embedded_sequence = inputs
            while len(embedded_sequence.shape) < 3:
                embedded_sequence = tf.expand_dims(embedded_sequence, -1)

        # shape=(?, sequence_length, embedding_size)
        hidden = embedded_sequence

        # ================ Conv Layers ================
        hidden = self.conv1d_stack(
            hidden,
            training=training,
            mask=mask
        )

        # ================ Recurrent Layers ================
        hidden, final_state = self.recurrent_stack(
            hidden,
            training=training
        )

        # ================ Sequence Reduction ================
        if self.reduce_output is not None:
            hidden = self.reduce_sequence(hidden)

            # ================ FC Layers ================
            hidden = self.fc_stack(
                hidden,
                training=training,
                mask=mask
            )

        return {
            'encoder_output': hidden,
            'encoder_output_state': final_state
        }
</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/sequence_encoders.py" startline="2071" endline="2120" pcid="346">
            )

    def call(self, inputs, training=None, mask=None):
        """
            :param input_sequence: The input sequence fed into the encoder.
                   Shape: [batch x sequence length], type tf.int32
            :type input_sequence: Tensor
            :param regularizer: The regularizer to use for the weights
                   of the encoder.
            :type regularizer:
            :param dropout: Tensor (tf.float) of the probability of dropout
            :type dropout: Tensor
            :param is_training: Tesnor (tf.bool) specifying if in training mode
                   (important for dropout)
            :type is_training: Tensor
        """
        # ================ Embeddings ================
        if self.should_embed:
            embedded_sequence = self.embed_sequence(
                inputs, training=training, mask=mask
            )
        else:
            embedded_sequence = inputs
            while len(embedded_sequence.shape) < 3:
                embedded_sequence = tf.expand_dims(embedded_sequence, -1)

        # shape=(?, sequence_length, embedding_size)
        if self.should_project:
            hidden = self.project_to_hidden_size(embedded_sequence)
        else:
            hidden = embedded_sequence
        # shape=(?, sequence_length, hidden)

        # ================ Transformer Layers ================
        hidden = self.transformer_stack(
            hidden,
            training=training,
            mask=mask
        )

        # ================ Sequence Reduction ================
        if self.reduce_output is not None:
            hidden = self.reduce_sequence(hidden)

            # ================ FC Layers ================
            hidden = self.fc_stack(
                hidden,
                training=training,
                mask=mask
            )
</source>
</class>

<class classid="20" nclones="6" nlines="49" similarity="70">
<source file="systems/ludwig-0.4.1/ludwig/encoders/generic_encoders.py" startline="45" endline="85" pcid="352">
    def __init__(
            self,
            layers=None,
            num_layers=1,
            fc_size=256,
            use_bias=True,
            weights_initializer='glorot_uniform',
            bias_initializer='zeros',
            weights_regularizer=None,
            bias_regularizer=None,
            activity_regularizer=None,
            # weights_constraint=None,
            # bias_constraint=None,
            norm=None,
            norm_params=None,
            activation='relu',
            dropout=0,
            **kwargs
    ):
        super().__init__()
        logger.debug(' {}'.format(self.name))

        logger.debug('  FCStack')
        self.fc_stack = FCStack(
            layers=layers,
            num_layers=num_layers,
            default_fc_size=fc_size,
            default_use_bias=use_bias,
            default_weights_initializer=weights_initializer,
            default_bias_initializer=bias_initializer,
            default_weights_regularizer=weights_regularizer,
            default_bias_regularizer=bias_regularizer,
            default_activity_regularizer=activity_regularizer,
            # default_weights_constraint=weights_constraint,
            # default_bias_constraint=bias_constraint,
            default_norm=norm,
            default_norm_params=norm_params,
            default_activation=activation,
            default_dropout=dropout,
        )

</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/date_encoders.py" startline="330" endline="421" pcid="377">
    def __init__(
            self,
            fc_layers=None,
            num_fc_layers=0,
            fc_size=10,
            use_bias=True,
            weights_initializer='glorot_uniform',
            bias_initializer='zeros',
            weights_regularizer=None,
            bias_regularizer=None,
            activity_regularizer=None,
            # weights_constraint=None,
            # bias_constraint=None,
            norm=None,
            norm_params=None,
            activation='relu',
            dropout=0,
            **kwargs
    ):
        """
            :param fc_layers: list of dictionaries containing the parameters of
                    all the fully connected layers
            :type fc_layers: List
            :param num_fc_layers: Number of stacked fully connected layers
            :type num_fc_layers: Integer
            :param fc_size: Size of each layer
            :type fc_size: Integer
            :param use_bias: bool determines where to use a bias vector
            :type use_bias: bool
            :param weights_initializer: Initializer for the weights (aka kernel)
                   matrix
            :type weights_initializer: string
            :param bias_initializer: Initializer for the bias vector
            :type bias_initializer: string
            :param weights_regularizer: regularizer applied to the weights
                   (kernal) matrix
            :type weights_regularizer: string
            :param bias_regularizer: reguralizer function applied to biase vector.
            :type bias_regularizer: string
            :param activity_regularizer: Regularizer applied to the output of the
                   layer (activation)
            :type activity_regularizer: string
            :param norm: type of normalization to use 'batch' or 'layer'
            :type norm: string, default None
            :param norm_params: parameters to pass to normalization function
            :type norm_params: dictionary
            :param activation: Activation function to use.
            :type activation: string
            :param dropout: determines if there should be a dropout layer before
                   returning the encoder output.
            :type dropout: float
        """
        super().__init__()
        logger.debug(' {}'.format(self.name))

        logger.debug('  year FCStack')
        self.year_fc = FCStack(
            num_layers=1,
            default_fc_size=1,
            default_use_bias=use_bias,
            default_weights_initializer=weights_initializer,
            default_bias_initializer=bias_initializer,
            default_weights_regularizer=weights_regularizer,
            default_bias_regularizer=bias_regularizer,
            default_activity_regularizer=activity_regularizer,
            # default_weights_constraint=weights_constraint,
            # default_bias_constraint=bias_constraint,
            default_norm=None,
            default_norm_params=None,
            default_activation=None,
            default_dropout=dropout,
        )

        logger.debug('  FCStack')
        self.fc_stack = FCStack(
            layers=fc_layers,
            num_layers=num_fc_layers,
            default_fc_size=fc_size,
            default_use_bias=use_bias,
            default_weights_initializer=weights_initializer,
            default_bias_initializer=bias_initializer,
            default_weights_regularizer=weights_regularizer,
            default_bias_regularizer=bias_regularizer,
            default_activity_regularizer=activity_regularizer,
            # default_weights_constraint=weights_constraint,
            # default_bias_constraint=bias_constraint,
            default_norm=norm,
            default_norm_params=norm_params,
            default_activation=activation,
            default_dropout=dropout,
        )

</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/set_encoders.py" startline="40" endline="101" pcid="380">
    def __init__(
            self,
            vocab,
            representation='dense',
            embedding_size=50,
            embeddings_trainable=True,
            pretrained_embeddings=None,
            embeddings_on_cpu=False,
            fc_layers=None,
            num_fc_layers=0,
            fc_size=10,
            use_bias=True,
            weights_initializer='glorot_uniform',
            bias_initializer='zeros',
            weights_regularizer=None,
            bias_regularizer=None,
            activity_regularizer=None,
            # weights_constraint=None,
            # bias_constraint=None,
            norm=None,
            norm_params=None,
            activation='relu',
            dropout=0.0,
            reduce_output='sum',
            **kwargs
    ):
        super().__init__()
        logger.debug(' {}'.format(self.name))

        logger.debug('  EmbedSparse')
        self.embed_sparse = EmbedSparse(
            vocab,
            embedding_size,
            representation=representation,
            embeddings_trainable=embeddings_trainable,
            pretrained_embeddings=pretrained_embeddings,
            embeddings_on_cpu=embeddings_on_cpu,
            dropout=dropout,
            embedding_initializer=weights_initializer,
            embedding_regularizer=weights_regularizer,
            reduce_output=reduce_output,
        )

        logger.debug('  FCStack')
        self.fc_stack = FCStack(
            layers=fc_layers,
            num_layers=num_fc_layers,
            default_fc_size=fc_size,
            default_use_bias=use_bias,
            default_weights_initializer=weights_initializer,
            default_bias_initializer=bias_initializer,
            default_weights_regularizer=weights_regularizer,
            default_bias_regularizer=bias_regularizer,
            default_activity_regularizer=activity_regularizer,
            # default_weights_constraint=weights_constraint,
            # default_bias_constraint=bias_constraint,
            default_norm=norm,
            default_norm_params=norm_params,
            default_activation=activation,
            default_dropout=dropout,
        )

</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/h3_encoders.py" startline="424" endline="583" pcid="359">
    def __init__(
            self,
            embedding_size=10,
            embeddings_on_cpu=False,
            num_layers=1,
            state_size=10,
            cell_type='rnn',
            bidirectional=False,
            activation='tanh',
            recurrent_activation='sigmoid',
            use_bias=True,
            unit_forget_bias=True,
            weights_initializer='glorot_uniform',
            recurrent_initializer='orthogonal',
            bias_initializer='zeros',
            weights_regularizer=None,
            recurrent_regularizer=None,
            bias_regularizer=None,
            activity_regularizer=None,
            dropout=0.0,
            recurrent_dropout=0.0,
            reduce_output='last',
            **kwargs
    ):
        """
            :param embedding_size: it is the maximum embedding size, the actual
                   size will be `min(vocaularyb_size, embedding_size)`
                   for `dense` representations and exacly `vocaularyb_size`
                   for the `sparse` encoding, where `vocabulary_size` is
                   the number of different strings appearing in the training set
                   in the column the feature is named after (plus 1 for `<UNK>`).
            :type embedding_size: Integer
            :param embeddings_on_cpu: by default embedings matrices are stored
                   on GPU memory if a GPU is used, as it allows
                   for faster access, but in some cases the embedding matrix
                   may be really big and this parameter forces the placement
                   of the embedding matrix in regular memroy and the CPU is used
                   to resolve them, slightly slowing down the process
                   as a result of data transfer between CPU and GPU memory.
            :param num_layers: the number of stacked recurrent layers.
            :type num_layers: Integer
            :param cell_type: the type of recurrent cell to use.
                   Avalable values are: `rnn`, `lstm`, `lstm_block`, `lstm`,
                   `ln`, `lstm_cudnn`, `gru`, `gru_block`, `gru_cudnn`.
                   For reference about the differences between the cells please
                   refer to TensorFlow's documentstion. We suggest to use the
                   `block` variants on CPU and the `cudnn` variants on GPU
                   because of their increased speed.
            :type cell_type: str
            :param state_size: the size of the state of the rnn.
            :type state_size: Integer
            :param bidirectional: if `True` two recurrent networks will perform
                   encoding in the forward and backward direction and
                   their outputs will be concatenated.
            :type bidirectional: Boolean
            :param activation: Activation function to use.
            :type activation: string
            :param recurrent_activation: Activation function to use for the
                    recurrent step.
            :type recurrent_activation: string
            :param use_bias: bool determines where to use a bias vector
            :type use_bias: bool
            :param unit_forget_bias: if True add 1 to the bias forget gate at
                   initialization.
            :type unit_forget_bias: bool
            :param weights_initializer: Initializer for the weights (aka kernel)
                   matrix
            :type weights_initializer: string
            :param recurrent_initializer: Initializer for the recurrent weights
                   matrix
            :type recurrent_initializer: string
            :param bias_initializer: Initializer for the bias vector
            :type bias_initializer: string
            :param weights_regularizer: regularizer applied to the weights
                   (kernal) matrix
            :type weights_regularizer: string
            :param recurrent_regularizer: Regularizer for the recurrent weights
                   matrix
            :type recurrent_regularizer: string
            :param bias_regularizer: reguralizer function applied to biase vector.
            :type bias_regularizer: string
            :param activity_regularizer: Regularizer applied to the output of the
                   layer (activation)
            :type activity_regularizer: string
            :param dropout: determines if there should be a dropout layer before
                   returning the encoder output.
            :type dropout: float
            :param recurrent_dropout: Float between 0.0 and 1.0.  Fraction of
                   the units to drop for the linear transformation of the
                   recurrent state.
            :type recurrent_dropout: float
            :param initializer: the initializer to use. If `None` it uses
                   `glorot_uniform`. Options are: `constant`, `identity`,
                   `zeros`, `ones`, `orthogonal`, `normal`, `uniform`,
                   `truncated_normal`, `variance_scaling`, `glorot_normal`,
                   `glorot_uniform`, `xavier_normal`, `xavier_uniform`,
                   `he_normal`, `he_uniform`, `lecun_normal`, `lecun_uniform`.
                   Alternatively it is possible to specify a dictionary with
                   a key `type` that identifies the type of initialzier and
                   other keys for its parameters,
                   e.g. `{type: normal, mean: 0, stddev: 0}`.
                   To know the parameters of each initializer, please refer
                   to TensorFlow's documentation.
            :type initializer: str
            :param regularize: if a `regularize` is not already specified in
                   `conv_layers` or `fc_layers` this is the default `regularize`
                   that will be used for each layer. It indicates if
                   the layer weights should be considered when computing
                   a regularization loss.
            :type regularize:
            :param reduce_output: defines how to reduce the output tensor of
                   the convolutional layers along the `s` sequence length
                   dimention if the rank of the tensor is greater than 2.
                   Available values are: `sum`, `mean` or `avg`, `max`, `concat`
                   (concatenates along the first dimension), `last` (returns
                   the last vector of the first dimension) and `None` or `null`
                   (which does not reduce and returns the full tensor).
            :type reduce_output: str
        """
        super().__init__()
        logger.debug(' {}'.format(self.name))

        self.embedding_size = embedding_size

        self.h3_embed = H3Embed(
            embedding_size,
            embeddings_on_cpu=embeddings_on_cpu,
            dropout=dropout,
            weights_initializer=weights_initializer,
            bias_initializer=bias_initializer,
            weights_regularizer=weights_regularizer,
            bias_regularizer=bias_regularizer,
            activity_regularizer=activity_regularizer,
            # weights_constraint=weights_constraint,
            # bias_constraint=bias_constraint,
            reduce_output=None
        )

        logger.debug('  RecurrentStack')
        self.recurrent_stack = RecurrentStack(
            state_size=state_size,
            cell_type=cell_type,
            num_layers=num_layers,
            bidirectional=bidirectional,
            activation=activation,
            recurrent_activation=recurrent_activation,
            use_bias=use_bias,
            unit_forget_bias=unit_forget_bias,
            weights_initializer=weights_initializer,
            recurrent_initializer=recurrent_initializer,
            bias_initializer=bias_initializer,
            weights_regularizer=weights_regularizer,
            recurrent_regularizer=recurrent_regularizer,
            bias_regularizer=bias_regularizer,
            activity_regularizer=activity_regularizer,
            dropout=dropout,
            recurrent_dropout=recurrent_dropout,
            reduce_output=reduce_output
        )

</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/h3_encoders.py" startline="276" endline="378" pcid="357">
    def __init__(
            self,
            embedding_size=10,
            embeddings_on_cpu=False,
            should_softmax=False,
            fc_layers=None,
            num_fc_layers=0,
            fc_size=10,
            use_bias=True,
            weights_initializer='glorot_uniform',
            bias_initializer='zeros',
            weights_regularizer=None,
            bias_regularizer=None,
            activity_regularizer=None,
            # weights_constraint=None,
            # bias_constraint=None,
            norm=None,
            norm_params=None,
            activation='relu',
            dropout=0,
            **kwargs
    ):
        """
            :param embedding_size: it is the maximum embedding size, the actual
                   size will be `min(vocaularyb_size, embedding_size)`
                   for `dense` representations and exacly `vocaularyb_size`
                   for the `sparse` encoding, where `vocabulary_size` is
                   the number of different strings appearing in the training set
                   in the column the feature is named after (plus 1 for `<UNK>`).
            :type embedding_size: Integer
            :param embeddings_on_cpu: by default embedings matrices are stored
                   on GPU memory if a GPU is used, as it allows
                   for faster access, but in some cases the embedding matrix
                   may be really big and this parameter forces the placement
                   of the embedding matrix in regular memroy and the CPU is used
                   to resolve them, slightly slowing down the process
                   as a result of data transfer between CPU and GPU memory.
            :param dropout: determines if there should be a dropout layer before
                   returning the encoder output.
            :type dropout: Boolean
            :param initializer: the initializer to use. If `None`, the default
                   initialized of each variable is used (`glorot_uniform`
                   in most cases). Options are: `constant`, `identity`, `zeros`,
                    `ones`, `orthogonal`, `normal`, `uniform`,
                    `truncated_normal`, `variance_scaling`, `glorot_normal`,
                    `glorot_uniform`, `xavier_normal`, `xavier_uniform`,
                    `he_normal`, `he_uniform`, `lecun_normal`, `lecun_uniform`.
                    Alternatively it is possible to specify a dictionary with
                    a key `type` that identifies the type of initialzier and
                    other keys for its parameters, e.g.
                    `{type: normal, mean: 0, stddev: 0}`.
                    To know the parameters of each initializer, please refer to
                    TensorFlow's documentation.
            :type initializer: str
            :param regularize: if `True` the embedding wieghts are added to
                   the set of weights that get reularized by a regularization
                   loss (if the `regularization_lambda` in `training`
                   is greater than 0).
            :type regularize: Boolean
        """
        super().__init__()
        logger.debug(' {}'.format(self.name))

        self.should_softmax = should_softmax
        self.reduce_sequence = SequenceReducer(reduce_mode='sum')

        self.h3_embed = H3Embed(
            embedding_size,
            embeddings_on_cpu=embeddings_on_cpu,
            dropout=dropout,
            weights_initializer=weights_initializer,
            bias_initializer=bias_initializer,
            weights_regularizer=weights_regularizer,
            bias_regularizer=bias_regularizer,
            activity_regularizer=activity_regularizer,
            # weights_constraint=weights_constraint,
            # bias_constraint=bias_constraint,
            reduce_output=None
        )

        self.aggregation_weights = tf.Variable(
            get_initializer(weights_initializer)([19, 1])
        )

        logger.debug('  FCStack')
        self.fc_stack = FCStack(
            layers=fc_layers,
            num_layers=num_fc_layers,
            default_fc_size=fc_size,
            default_use_bias=use_bias,
            default_weights_initializer=weights_initializer,
            default_bias_initializer=bias_initializer,
            default_weights_regularizer=weights_regularizer,
            default_bias_regularizer=bias_regularizer,
            default_activity_regularizer=activity_regularizer,
            # default_weights_constraint=weights_constraint,
            # default_bias_constraint=bias_constraint,
            default_norm=norm,
            default_norm_params=norm_params,
            default_activation=activation,
            default_dropout=dropout,
        )

</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/bag_encoders.py" startline="39" endline="100" pcid="372">
    def __init__(
            self,
            vocab,
            embedding_size=50,
            representation='dense',
            embeddings_trainable=True,
            pretrained_embeddings=None,
            force_embedding_size=False,
            embeddings_on_cpu=False,
            fc_layers=None,
            num_fc_layers=0,
            fc_size=10,
            use_bias=True,
            weights_initializer='glorot_uniform',
            bias_initializer='zeros',
            weights_regularizer=None,
            bias_regularizer=None,
            activity_regularizer=None,
            # weights_constraint=None,
            # bias_constraint=None,
            norm=None,
            norm_params=None,
            activation='relu',
            dropout=0.0,
            **kwargs
    ):
        super().__init__()
        logger.debug(' {}'.format(self.name))

        logger.debug('  EmbedWeighted')
        self.embed_weighted = EmbedWeighted(
            vocab,
            embedding_size,
            representation=representation,
            embeddings_trainable=embeddings_trainable,
            pretrained_embeddings=pretrained_embeddings,
            force_embedding_size=force_embedding_size,
            embeddings_on_cpu=embeddings_on_cpu,
            dropout=dropout,
            embedding_initializer=weights_initializer,
            embedding_regularizer=weights_regularizer
        )

        logger.debug('  FCStack')
        self.fc_stack = FCStack(
            layers=fc_layers,
            num_layers=num_fc_layers,
            default_fc_size=fc_size,
            default_use_bias=use_bias,
            default_weights_initializer=weights_initializer,
            default_bias_initializer=bias_initializer,
            default_weights_regularizer=weights_regularizer,
            default_bias_regularizer=bias_regularizer,
            default_activity_regularizer=activity_regularizer,
            # default_weights_constraint=weights_constraint,
            # default_bias_constraint=bias_constraint,
            default_norm=norm,
            default_norm_params=norm_params,
            default_activation=activation,
            default_dropout=dropout,
        )

</source>
</class>

<class classid="21" nclones="2" nlines="115" similarity="72">
<source file="systems/ludwig-0.4.1/ludwig/encoders/h3_encoders.py" startline="45" endline="200" pcid="355">
    def __init__(
            self,
            embedding_size=10,
            embeddings_on_cpu=False,
            fc_layers=None,
            num_fc_layers=0,
            fc_size=10,
            use_bias=True,
            weights_initializer='glorot_uniform',
            bias_initializer='zeros',
            weights_regularizer=None,
            bias_regularizer=None,
            activity_regularizer=None,
            # weights_constraint=None,
            # bias_constraint=None,
            norm=None,
            norm_params=None,
            activation='relu',
            dropout=0,
            reduce_output='sum',
            **kwargs
    ):
        """
            :param embedding_size: it is the maximum embedding size, the actual
                   size will be `min(vocaularyb_size, embedding_size)`
                   for `dense` representations and exacly `vocaularyb_size`
                   for the `sparse` encoding, where `vocabulary_size` is
                   the number of different strings appearing in the training set
                   in the column the feature is named after (plus 1 for `<UNK>`).
            :type embedding_size: Integer
            :param embeddings_on_cpu: by default embedings matrices are stored
                   on GPU memory if a GPU is used, as it allows
                   for faster access, but in some cases the embedding matrix
                   may be really big and this parameter forces the placement
                   of the embedding matrix in regular memroy and the CPU is used
                   to resolve them, slightly slowing down the process
                   as a result of data transfer between CPU and GPU memory.
            :param dropout: determines if there should be a dropout layer before
                   returning the encoder output.
            :type dropout: Boolean
            :param initializer: the initializer to use. If `None`, the default
                   initialized of each variable is used (`glorot_uniform`
                   in most cases). Options are: `constant`, `identity`, `zeros`,
                    `ones`, `orthogonal`, `normal`, `uniform`,
                    `truncated_normal`, `variance_scaling`, `glorot_normal`,
                    `glorot_uniform`, `xavier_normal`, `xavier_uniform`,
                    `he_normal`, `he_uniform`, `lecun_normal`, `lecun_uniform`.
                    Alternatively it is possible to specify a dictionary with
                    a key `type` that identifies the type of initialzier and
                    other keys for its parameters, e.g.
                    `{type: normal, mean: 0, stddev: 0}`.
                    To know the parameters of each initializer, please refer to
                    TensorFlow's documentation.
            :type initializer: str
            :param regularize: if `True` the embedding wieghts are added to
                   the set of weights that get reularized by a regularization
                   loss (if the `regularization_lambda` in `training`
                   is greater than 0).
            :type regularize: Boolean
        """
        super().__init__()
        logger.debug(' {}'.format(self.name))

        self.embedding_size = embedding_size
        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)

        logger.debug('  mode Embed')
        self.embed_mode = Embed(
            [str(i) for i in range(3)],
            embedding_size,
            representation='dense',
            embeddings_trainable=True,
            pretrained_embeddings=None,
            force_embedding_size=True,
            embeddings_on_cpu=embeddings_on_cpu,
            dropout=dropout,
            embedding_initializer=weights_initializer,
            embedding_regularizer=weights_regularizer
        )

        logger.debug('  edge Embed')
        self.embed_edge = Embed(
            [str(i) for i in range(7)],
            embedding_size,
            representation='dense',
            embeddings_trainable=True,
            pretrained_embeddings=None,
            force_embedding_size=True,
            embeddings_on_cpu=embeddings_on_cpu,
            dropout=dropout,
            embedding_initializer=weights_initializer,
            embedding_regularizer=weights_regularizer
        )

        logger.debug('  resolution Embed')
        self.embed_resolution = Embed(
            [str(i) for i in range(16)],
            embedding_size,
            representation='dense',
            embeddings_trainable=True,
            pretrained_embeddings=None,
            force_embedding_size=True,
            embeddings_on_cpu=embeddings_on_cpu,
            dropout=dropout,
            embedding_initializer=weights_initializer,
            embedding_regularizer=weights_regularizer
        )

        logger.debug('  base cell Embed')
        self.embed_base_cell = Embed(
            [str(i) for i in range(122)],
            embedding_size,
            representation='dense',
            embeddings_trainable=True,
            pretrained_embeddings=None,
            force_embedding_size=True,
            embeddings_on_cpu=embeddings_on_cpu,
            dropout=dropout,
            embedding_initializer=weights_initializer,
            embedding_regularizer=weights_regularizer
        )

        logger.debug('  cells Embed')
        self.embed_cells = Embed(
            [str(i) for i in range(8)],
            embedding_size,
            representation='dense',
            embeddings_trainable=True,
            pretrained_embeddings=None,
            force_embedding_size=True,
            embeddings_on_cpu=embeddings_on_cpu,
            dropout=dropout,
            embedding_initializer=weights_initializer,
            embedding_regularizer=weights_regularizer
        )

        logger.debug('  FCStack')
        self.fc_stack = FCStack(
            layers=fc_layers,
            num_layers=num_fc_layers,
            default_fc_size=fc_size,
            default_use_bias=use_bias,
            default_weights_initializer=weights_initializer,
            default_bias_initializer=bias_initializer,
            default_weights_regularizer=weights_regularizer,
            default_bias_regularizer=bias_regularizer,
            default_activity_regularizer=activity_regularizer,
            # default_weights_constraint=weights_constraint,
            # default_bias_constraint=bias_constraint,
            default_norm=norm,
            default_norm_params=norm_params,
            default_activation=activation,
            default_dropout=dropout,
        )

</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/date_encoders.py" startline="43" endline="242" pcid="375">
    def __init__(
            self,
            embedding_size=10,
            embeddings_on_cpu=False,
            fc_layers=None,
            num_fc_layers=0,
            fc_size=10,
            use_bias=True,
            weights_initializer='glorot_uniform',
            bias_initializer='zeros',
            weights_regularizer=None,
            bias_regularizer=None,
            activity_regularizer=None,
            # weights_constraint=None,
            # bias_constraint=None,
            norm=None,
            norm_params=None,
            activation='relu',
            dropout=0,
            **kwargs
    ):
        """
            :param embedding_size: it is the maximum embedding size, the actual
                   size will be `min(vocaularyb_size, embedding_size)`
                   for `dense` representations and exacly `vocaularyb_size`
                   for the `sparse` encoding, where `vocabulary_size` is
                   the number of different strings appearing in the training set
                   in the column the feature is named after (plus 1 for `<UNK>`).
            :type embedding_size: Integer
            :param embeddings_on_cpu: by default embedings matrices are stored
                   on GPU memory if a GPU is used, as it allows
                   for faster access, but in some cases the embedding matrix
                   may be really big and this parameter forces the placement
                   of the embedding matrix in regular memroy and the CPU is used
                   to resolve them, slightly slowing down the process
                   as a result of data transfer between CPU and GPU memory.
            :param fc_layers: list of dictionaries containing the parameters of
                    all the fully connected layers
            :type fc_layers: List
            :param num_fc_layers: Number of stacked fully connected layers
            :type num_fc_layers: Integer
            :param fc_size: Size of each layer
            :type fc_size: Integer
            :param use_bias: bool determines where to use a bias vector
            :type use_bias: bool
            :param weights_initializer: Initializer for the weights (aka kernel)
                   matrix
            :type weights_initializer: string
            :param bias_initializer: Initializer for the bias vector
            :type bias_initializer: string
            :param weights_regularizer: regularizer applied to the weights
                   (kernal) matrix
            :type weights_regularizer: string
            :param bias_regularizer: reguralizer function applied to biase vector.
            :type bias_regularizer: string
            :param activity_regularizer: Regularizer applied to the output of the
                   layer (activation)
            :type activity_regularizer: string
            :param norm: type of normalization to use 'batch' or 'layer'
            :type norm: string, default None
            :param norm_params: parameters to pass to normalization function
            :type norm_params: dictionary
            :param activation: Activation function to use.
            :type activation: string
            :param dropout: determines if there should be a dropout layer before
                   returning the encoder output.
            :type dropout: float

        """
        super().__init__()
        logger.debug(' {}'.format(self.name))

        logger.debug('  year FCStack')
        self.year_fc = FCStack(
            num_layers=1,
            default_fc_size=1,
            default_use_bias=use_bias,
            default_weights_initializer=weights_initializer,
            default_bias_initializer=bias_initializer,
            default_weights_regularizer=weights_regularizer,
            default_bias_regularizer=bias_regularizer,
            default_activity_regularizer=activity_regularizer,
            # default_weights_constraint=weights_constraint,
            # default_bias_constraint=bias_constraint,
            default_norm=None,
            default_norm_params=None,
            default_activation=None,
            default_dropout=dropout,
        )

        logger.debug('  month Embed')
        self.embed_month = Embed(
            [str(i) for i in range(12)],
            embedding_size,
            representation='dense',
            embeddings_trainable=True,
            pretrained_embeddings=None,
            embeddings_on_cpu=embeddings_on_cpu,
            dropout=dropout,
            embedding_initializer=weights_initializer,
            embedding_regularizer=weights_regularizer
        )

        logger.debug('  day Embed')
        self.embed_day = Embed(
            [str(i) for i in range(31)],
            embedding_size,
            representation='dense',
            embeddings_trainable=True,
            pretrained_embeddings=None,
            embeddings_on_cpu=embeddings_on_cpu,
            dropout=dropout,
            embedding_initializer=weights_initializer,
            embedding_regularizer=weights_regularizer
        )

        logger.debug('  weekday Embed')
        self.embed_weekday = Embed(
            [str(i) for i in range(7)],
            embedding_size,
            representation='dense',
            embeddings_trainable=True,
            pretrained_embeddings=None,
            embeddings_on_cpu=embeddings_on_cpu,
            dropout=dropout,
            embedding_initializer=weights_initializer,
            embedding_regularizer=weights_regularizer
        )

        logger.debug('  yearday Embed')
        self.embed_yearday = Embed(
            [str(i) for i in range(366)],
            embedding_size,
            representation='dense',
            embeddings_trainable=True,
            pretrained_embeddings=None,
            embeddings_on_cpu=embeddings_on_cpu,
            dropout=dropout,
            embedding_initializer=weights_initializer,
            embedding_regularizer=weights_regularizer
        )

        logger.debug('  hour Embed')
        self.embed_hour = Embed(
            [str(i) for i in range(24)],
            embedding_size,
            representation='dense',
            embeddings_trainable=True,
            pretrained_embeddings=None,
            embeddings_on_cpu=embeddings_on_cpu,
            dropout=dropout,
            embedding_initializer=weights_initializer,
            embedding_regularizer=weights_regularizer
        )

        logger.debug('  minute Embed')
        self.embed_minute = Embed(
            [str(i) for i in range(60)],
            embedding_size,
            representation='dense',
            embeddings_trainable=True,
            pretrained_embeddings=None,
            embeddings_on_cpu=embeddings_on_cpu,
            dropout=dropout,
            embedding_initializer=weights_initializer,
            embedding_regularizer=weights_regularizer
        )

        logger.debug('  second Embed')
        self.embed_second = Embed(
            [str(i) for i in range(60)],
            embedding_size,
            representation='dense',
            embeddings_trainable=True,
            pretrained_embeddings=None,
            embeddings_on_cpu=embeddings_on_cpu,
            dropout=dropout,
            embedding_initializer=weights_initializer,
            embedding_regularizer=weights_regularizer
        )

        logger.debug('  FCStack')
        self.fc_stack = FCStack(
            layers=fc_layers,
            num_layers=num_fc_layers,
            default_fc_size=fc_size,
            default_use_bias=use_bias,
            default_weights_initializer=weights_initializer,
            default_bias_initializer=bias_initializer,
            default_weights_regularizer=weights_regularizer,
            default_bias_regularizer=bias_regularizer,
            default_activity_regularizer=activity_regularizer,
            # default_weights_constraint=weights_constraint,
            # default_bias_constraint=bias_constraint,
            default_norm=norm,
            default_norm_params=norm_params,
            default_activation=activation,
            default_dropout=dropout,
        )

</source>
</class>

<class classid="22" nclones="18" nlines="21" similarity="86">
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="51" endline="78" pcid="383">
    def __init__(
            self,
            pretrained_model_name_or_path='bert-base-uncased',
            reduce_output='cls_pooled',
            trainable=True,
            num_tokens=None,
            **kwargs
    ):
        super().__init__()
        try:
            from transformers import TFBertModel
        except ModuleNotFoundError:
            logger.error(
                ' transformers is not installed. '
                'In order to install all text feature dependencies run '
                'pip install ludwig[text]'
            )
            sys.exit(-1)

        self.transformer = TFBertModel.from_pretrained(
            pretrained_model_name_or_path
        )
        self.reduce_output = reduce_output
        if not self.reduce_output == 'cls_pooled':
            self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.transformer.trainable = trainable
        self.transformer.resize_token_embeddings(num_tokens)

</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="209" endline="233" pcid="389">
    def __init__(
            self,
            pretrained_model_name_or_path='transfo-xl-wt103',
            reduce_output='sum',
            trainable=True,
            **kwargs
    ):
        super().__init__()
        try:
            from transformers import TFTransfoXLModel
        except ModuleNotFoundError:
            logger.error(
                ' transformers is not installed. '
                'In order to install all text feature dependencies run '
                'pip install ludwig[text]'
            )
            sys.exit(-1)

        self.transformer = TFTransfoXLModel.from_pretrained(
            pretrained_model_name_or_path
        )
        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.transformer.trainable = trainable

</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="413" endline="439" pcid="397">
    def __init__(
            self,
            pretrained_model_name_or_path='distilbert-base-uncased',
            reduce_output='sum',
            trainable=True,
            num_tokens=None,
            **kwargs
    ):
        super().__init__()
        try:
            from transformers import TFDistilBertModel
        except ModuleNotFoundError:
            logger.error(
                ' transformers is not installed. '
                'In order to install all text feature dependencies run '
                'pip install ludwig[text]'
            )
            sys.exit(-1)

        self.transformer = TFDistilBertModel.from_pretrained(
            pretrained_model_name_or_path
        )
        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.transformer.trainable = trainable
        self.transformer.resize_token_embeddings(num_tokens)

</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="158" endline="184" pcid="387">
    def __init__(
            self,
            pretrained_model_name_or_path='gpt2',
            reduce_output='sum',
            trainable=True,
            num_tokens=None,
            **kwargs
    ):
        super().__init__()
        try:
            from transformers import TFGPT2Model
        except ModuleNotFoundError:
            logger.error(
                ' transformers is not installed. '
                'In order to install all text feature dependencies run '
                'pip install ludwig[text]'
            )
            sys.exit(-1)

        self.transformer = TFGPT2Model.from_pretrained(
            pretrained_model_name_or_path
        )
        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.transformer.trainable = trainable
        self.transformer.resize_token_embeddings(num_tokens)

</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="307" endline="333" pcid="393">
    def __init__(
            self,
            pretrained_model_name_or_path='xlm-mlm-en-2048',
            reduce_output='sum',
            trainable=True,
            num_tokens=None,
            **kwargs
    ):
        super().__init__()
        try:
            from transformers import TFXLMModel
        except ModuleNotFoundError:
            logger.error(
                ' transformers is not installed. '
                'In order to install all text feature dependencies run '
                'pip install ludwig[text]'
            )
            sys.exit(-1)

        self.transformer = TFXLMModel.from_pretrained(
            pretrained_model_name_or_path
        )
        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.transformer.trainable = trainable
        self.transformer.resize_token_embeddings(num_tokens)

</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="107" endline="133" pcid="385">
    def __init__(
            self,
            reduce_output='sum',
            pretrained_model_name_or_path='openai-gpt',
            trainable=True,
            num_tokens=None,
            **kwargs
    ):
        super().__init__()
        try:
            from transformers import TFOpenAIGPTModel
        except ModuleNotFoundError:
            logger.error(
                ' transformers is not installed. '
                'In order to install all text feature dependencies run '
                'pip install ludwig[text]'
            )
            sys.exit(-1)

        self.transformer = TFOpenAIGPTModel.from_pretrained(
            pretrained_model_name_or_path
        )
        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.transformer.trainable = trainable
        self.transformer.resize_token_embeddings(num_tokens)

</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="463" endline="489" pcid="399">
    def __init__(
            self,
            pretrained_model_name_or_path='ctrl',
            reduce_output='sum',
            trainable=True,
            num_tokens=None,
            **kwargs
    ):
        super().__init__()
        try:
            from transformers import TFCTRLModel
        except ModuleNotFoundError:
            logger.error(
                ' transformers is not installed. '
                'In order to install all text feature dependencies run '
                'pip install ludwig[text]'
            )
            sys.exit(-1)

        self.transformer = TFCTRLModel.from_pretrained(
            pretrained_model_name_or_path
        )
        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.transformer.trainable = trainable
        self.transformer.resize_token_embeddings(num_tokens)

</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="256" endline="282" pcid="391">
    def __init__(
            self,
            pretrained_model_name_or_path='xlnet-base-cased',
            reduce_output='sum',
            trainable=True,
            num_tokens=None,
            **kwargs
    ):
        super().__init__()
        try:
            from transformers import TFXLNetModel
        except ModuleNotFoundError:
            logger.error(
                ' transformers is not installed. '
                'In order to install all text feature dependencies run '
                'pip install ludwig[text]'
            )
            sys.exit(-1)

        self.transformer = TFXLNetModel.from_pretrained(
            pretrained_model_name_or_path
        )
        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.transformer.trainable = trainable
        self.transformer.resize_token_embeddings(num_tokens)

</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="782" endline="808" pcid="411">
    def __init__(
            self,
            pretrained_model_name_or_path='jplu/tf-flaubert-small-cased',
            reduce_output='sum',
            trainable=True,
            num_tokens=None,
            **kwargs
    ):
        super().__init__()
        try:
            from transformers import TFFlaubertModel
        except ModuleNotFoundError:
            logger.error(
                ' transformers is not installed. '
                'In order to install all text feature dependencies run '
                'pip install ludwig[text]'
            )
            sys.exit(-1)

        self.transformer = TFFlaubertModel.from_pretrained(
            pretrained_model_name_or_path
        )
        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.transformer.trainable = trainable
        self.transformer.resize_token_embeddings(num_tokens)

</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="833" endline="859" pcid="413">
    def __init__(
            self,
            pretrained_model_name_or_path='google/electra-small-discriminator',
            reduce_output='sum',
            trainable=True,
            num_tokens=None,
            **kwargs
    ):
        super().__init__()
        try:
            from transformers import TFElectraModel
        except ModuleNotFoundError:
            logger.error(
                ' transformers is not installed. '
                'In order to install all text feature dependencies run '
                'pip install ludwig[text]'
            )
            sys.exit(-1)

        self.transformer = TFElectraModel.from_pretrained(
            pretrained_model_name_or_path
        )
        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.transformer.trainable = trainable
        self.transformer.resize_token_embeddings(num_tokens)

</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="624" endline="650" pcid="405">
    def __init__(
            self,
            pretrained_model_name_or_path='t5-small',
            reduce_output='sum',
            trainable=True,
            num_tokens=None,
            **kwargs
    ):
        super().__init__()
        try:
            from transformers import TFT5Model
        except ModuleNotFoundError:
            logger.error(
                ' transformers is not installed. '
                'In order to install all text feature dependencies run '
                'pip install ludwig[text]'
            )
            sys.exit(-1)

        self.transformer = TFT5Model.from_pretrained(
            pretrained_model_name_or_path
        )
        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.transformer.trainable = trainable
        self.transformer.resize_token_embeddings(num_tokens)

</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="675" endline="701" pcid="407">
    def __init__(
            self,
            pretrained_model_name_or_path='google/mt5-small',
            reduce_output='sum',
            trainable=True,
            num_tokens=None,
            **kwargs
    ):
        super().__init__()
        try:
            from transformers import TFMT5Model
        except ModuleNotFoundError:
            logger.error(
                ' transformers is not installed. '
                'In order to install all text feature dependencies run '
                'pip install ludwig[text]'
            )
            sys.exit(-1)

        self.transformer = TFMT5Model.from_pretrained(
            pretrained_model_name_or_path
        )
        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.transformer.trainable = trainable
        self.transformer.resize_token_embeddings(num_tokens)

</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="727" endline="754" pcid="409">
    def __init__(
            self,
            pretrained_model_name_or_path='jplu/tf-xlm-roberta-base',
            reduce_output='cls_pooled',
            trainable=True,
            num_tokens=None,
            **kwargs
    ):
        super().__init__()
        try:
            from transformers import TFXLMRobertaModel
        except ModuleNotFoundError:
            logger.error(
                ' transformers is not installed. '
                'In order to install all text feature dependencies run '
                'pip install ludwig[text]'
            )
            sys.exit(-1)

        self.transformer = TFXLMRobertaModel.from_pretrained(
            pretrained_model_name_or_path
        )
        self.reduce_output = reduce_output
        if not self.reduce_output == 'cls_pooled':
            self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.transformer.trainable = trainable
        self.transformer.resize_token_embeddings(num_tokens)

</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="569" endline="596" pcid="403">
    def __init__(
            self,
            pretrained_model_name_or_path='albert-base-v2',
            reduce_output='cls_pooled',
            trainable=True,
            num_tokens=None,
            **kwargs
    ):
        super().__init__()
        try:
            from transformers import TFAlbertModel
        except ModuleNotFoundError:
            logger.error(
                ' transformers is not installed. '
                'In order to install all text feature dependencies run '
                'pip install ludwig[text]'
            )
            sys.exit(-1)

        self.transformer = TFAlbertModel.from_pretrained(
            pretrained_model_name_or_path
        )
        self.reduce_output = reduce_output
        if not self.reduce_output == 'cls_pooled':
            self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.transformer.trainable = trainable
        self.transformer.resize_token_embeddings(num_tokens)

</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="514" endline="541" pcid="401">
    def __init__(
            self,
            pretrained_model_name_or_path='jplu/tf-camembert-base',
            reduce_output='cls_pooled',
            trainable=True,
            num_tokens=None,
            **kwargs
    ):
        super().__init__()
        try:
            from transformers import TFCamembertModel
        except ModuleNotFoundError:
            logger.error(
                ' transformers is not installed. '
                'In order to install all text feature dependencies run '
                'pip install ludwig[text]'
            )
            sys.exit(-1)

        self.transformer = TFCamembertModel.from_pretrained(
            pretrained_model_name_or_path
        )
        self.reduce_output = reduce_output
        if not self.reduce_output == 'cls_pooled':
            self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.transformer.trainable = trainable
        self.transformer.resize_token_embeddings(num_tokens)

</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="358" endline="385" pcid="395">
    def __init__(
            self,
            pretrained_model_name_or_path='roberta-base',
            reduce_output='cls_pooled',
            trainable=True,
            num_tokens=None,
            **kwargs
    ):
        super().__init__()
        try:
            from transformers import TFRobertaModel
        except ModuleNotFoundError:
            logger.error(
                ' transformers is not installed. '
                'In order to install all text feature dependencies run '
                'pip install ludwig[text]'
            )
            sys.exit(-1)

        self.transformer = TFRobertaModel.from_pretrained(
            pretrained_model_name_or_path
        )
        self.reduce_output = reduce_output
        if not self.reduce_output == 'cls_pooled':
            self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.transformer.trainable = trainable
        self.transformer.resize_token_embeddings(num_tokens)

</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="935" endline="962" pcid="417">
    def __init__(
            self,
            pretrained_model_name_or_path,
            reduce_output='sum',
            trainable=True,
            num_tokens=None,
            **kwargs
    ):
        super().__init__()
        try:
            from transformers import TFAutoModel
        except ModuleNotFoundError:
            logger.error(
                ' transformers is not installed. '
                'In order to install all text feature dependencies run '
                'pip install ludwig[text]'
            )
            sys.exit(-1)

        self.transformer = TFAutoModel.from_pretrained(
            pretrained_model_name_or_path
        )
        self.reduce_output = reduce_output
        if not self.reduce_output == 'cls_pooled':
            self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.transformer.trainable = trainable
        self.transformer.resize_token_embeddings(num_tokens)

</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="884" endline="911" pcid="415">
    def __init__(
            self,
            pretrained_model_name_or_path='allenai/longformer-base-4096',
            reduce_output='cls_pooled',
            trainable=True,
            num_tokens=None,
            **kwargs
    ):
        super().__init__()
        try:
            from transformers import TFLongformerModel
        except ModuleNotFoundError:
            logger.error(
                ' transformers is not installed. '
                'In order to install all text feature dependencies run '
                'pip install ludwig[text]'
            )
            sys.exit(-1)

        self.transformer = TFLongformerModel.from_pretrained(
            pretrained_model_name_or_path
        )
        self.reduce_output = reduce_output
        if not self.reduce_output == 'cls_pooled':
            self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        self.transformer.trainable = trainable
        self.transformer.resize_token_embeddings(num_tokens)

</source>
</class>

<class classid="23" nclones="14" nlines="13" similarity="71">
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="79" endline="95" pcid="384">
    def call(self, inputs, training=None, mask=None):
        if mask is not None:
            mask = tf.cast(mask, dtype=tf.int32)
        transformer_outputs = self.transformer({
            "input_ids": inputs,
            "attention_mask": mask,
            "token_type_ids": tf.zeros_like(inputs),
        }, training=training)
        if self.reduce_output == 'cls_pooled':
            hidden = transformer_outputs[1]
        else:
            hidden = transformer_outputs[0][:, 1:-1, :]
            hidden = self.reduce_sequence(hidden, self.reduce_output)

        return {'encoder_output': hidden}


</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="490" endline="502" pcid="400">
    def call(self, inputs, training=None, mask=None):
        if mask is not None:
            mask = tf.cast(mask, dtype=tf.int32)
        transformer_outputs = self.transformer({
            "input_ids": inputs,
            "attention_mask": mask,
            "token_type_ids": tf.zeros_like(inputs),
        }, training=training)
        hidden = transformer_outputs[0]
        hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {'encoder_output': hidden}


</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="185" endline="198" pcid="388">
    def call(self, inputs, training=None, mask=None):
        if mask is not None:
            mask = tf.cast(mask, dtype=tf.int32)
        transformer_outputs = self.transformer({
            "input_ids": inputs,
            "attention_mask": mask,
            "token_type_ids": tf.zeros_like(inputs),
        }, training=training)
        hidden = transformer_outputs[0]
        hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {'encoder_output': hidden}


# @register(name='transformer_xl')
</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="860" endline="872" pcid="414">
    def call(self, inputs, training=None, mask=None):
        if mask is not None:
            mask = tf.cast(mask, dtype=tf.int32)
        transformer_outputs = self.transformer({
            "input_ids": inputs,
            "attention_mask": mask,
            "token_type_ids": tf.zeros_like(inputs),
        }, training=training)
        hidden = transformer_outputs[0][:, 1:-1, :]
        hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {'encoder_output': hidden}


</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="386" endline="401" pcid="396">
    def call(self, inputs, training=None, mask=None):
        if mask is not None:
            mask = tf.cast(mask, dtype=tf.int32)
        transformer_outputs = self.transformer({
            "input_ids": inputs,
            "attention_mask": mask,
            "token_type_ids": tf.zeros_like(inputs),
        }, training=training)
        if self.reduce_output == 'cls_pooled':
            hidden = transformer_outputs[1]
        else:
            hidden = transformer_outputs[0][:, 1:-1, :]  # bos + [sent] + sep
            hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {'encoder_output': hidden}


</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="134" endline="146" pcid="386">
    def call(self, inputs, training=None, mask=None):
        if mask is not None:
            mask = tf.cast(mask, dtype=tf.int32)
        transformer_outputs = self.transformer({
            "input_ids": inputs,
            "attention_mask": mask,
            "token_type_ids": tf.zeros_like(inputs),
        }, training=training)
        hidden = transformer_outputs[0]
        hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {'encoder_output': hidden}


</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="755" endline="770" pcid="410">
    def call(self, inputs, training=None, mask=None):
        if mask is not None:
            mask = tf.cast(mask, dtype=tf.int32)
        transformer_outputs = self.transformer({
            "input_ids": inputs,
            "attention_mask": mask,
            "token_type_ids": tf.zeros_like(inputs),
        }, training=training)
        if self.reduce_output == 'cls_pooled':
            hidden = transformer_outputs[1]
        else:
            hidden = transformer_outputs[0][:, 1:-1, :]
            hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {'encoder_output': hidden}


</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="809" endline="821" pcid="412">
    def call(self, inputs, training=None, mask=None):
        if mask is not None:
            mask = tf.cast(mask, dtype=tf.int32)
        transformer_outputs = self.transformer({
            'input_ids': inputs,
            'attention_mask': mask,
            'token_type_ids': tf.zeros_like(inputs),
        }, training=training)
        hidden = transformer_outputs[0][:, 1:-1, :]
        hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {'encoder_output': hidden}


</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="334" endline="346" pcid="394">
    def call(self, inputs, training=None, mask=None):
        if mask is not None:
            mask = tf.cast(mask, dtype=tf.int32)
        transformer_outputs = self.transformer({
            "input_ids": inputs,
            "attention_mask": mask,
            "token_type_ids": tf.zeros_like(inputs),
        }, training=training)
        hidden = transformer_outputs[0][:, 1:-1, :]  # bos + [sent] + sep
        hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {'encoder_output': hidden}


</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="597" endline="612" pcid="404">
    def call(self, inputs, training=None, mask=None):
        if mask is not None:
            mask = tf.cast(mask, dtype=tf.int32)
        transformer_outputs = self.transformer({
            "input_ids": inputs,
            "attention_mask": mask,
            "token_type_ids": tf.zeros_like(inputs),
        }, training=training)
        if self.reduce_output == 'cls_pooled':
            hidden = transformer_outputs[1]
        else:
            hidden = transformer_outputs[0][:, 1:-1, :]
            hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {'encoder_output': hidden}


</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="912" endline="927" pcid="416">
    def call(self, inputs, training=None, mask=None):
        if mask is not None:
            mask = tf.cast(mask, dtype=tf.int32)
        transformer_outputs = self.transformer({
            "input_ids": inputs,
            "attention_mask": mask,
            "token_type_ids": tf.zeros_like(inputs),
        }, training=training)
        if self.reduce_output == 'cls_pooled':
            hidden = transformer_outputs[1]
        else:
            hidden = transformer_outputs[0][:, 1:-1, :]  # bos + [sent] + sep
            hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {'encoder_output': hidden}


</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="963" endline="980" pcid="418">
    def call(self, inputs, training=None, mask=None):
        if mask is not None:
            mask = tf.cast(mask, dtype=tf.int32)
        transformer_outputs = self.transformer({
            "input_ids": inputs,
            "training": training,
            "attention_mask": mask,
            "token_type_ids": tf.zeros_like(inputs)
        }, return_dict=True)
        if self.reduce_output == 'cls_pooled':
            # this works only if the user know that the specific model
            # they want to use has the same outputs of
            # the BERT base class call() function
            hidden = transformer_outputs['cls_pooled']
        else:
            hidden = transformer_outputs['last_hidden_state']
            hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {'encoder_output': hidden}
</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="283" endline="295" pcid="392">
    def call(self, inputs, training=None, mask=None):
        if mask is not None:
            mask = tf.cast(mask, dtype=tf.int32)
        transformer_outputs = self.transformer({
            "input_ids": inputs,
            "attention_mask": mask,
            "token_type_ids": tf.zeros_like(inputs),
        }, training=training)
        hidden = transformer_outputs[0]
        hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {'encoder_output': hidden}


</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="542" endline="557" pcid="402">
    def call(self, inputs, training=None, mask=None):
        if mask is not None:
            mask = tf.cast(mask, dtype=tf.int32)
        transformer_outputs = self.transformer({
            "input_ids": inputs,
            "attention_mask": mask,
            "token_type_ids": tf.zeros_like(inputs),
        }, training=training)
        if self.reduce_output == 'cls_pooled':
            hidden = transformer_outputs[1]
        else:
            hidden = transformer_outputs[0][:, 1:-1, :]
            hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {'encoder_output': hidden}


</source>
</class>

<class classid="24" nclones="2" nlines="12" similarity="100">
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="651" endline="663" pcid="406">
    def call(self, inputs, training=None, mask=None):
        if mask is not None:
            mask = tf.cast(mask, dtype=tf.int32)
        transformer_outputs = self.transformer(
            inputs,
            decoder_input_ids=inputs,
            training=training,
            attention_mask=mask,
        )
        hidden = transformer_outputs[0][:, 0:-1, :]  # [sent] + [eos token]
        hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {'encoder_output': hidden}

</source>
<source file="systems/ludwig-0.4.1/ludwig/encoders/text_encoders.py" startline="702" endline="715" pcid="408">
    def call(self, inputs, training=None, mask=None):
        if mask is not None:
            mask = tf.cast(mask, dtype=tf.int32)
        transformer_outputs = self.transformer(
            inputs,
            decoder_input_ids=inputs,
            training=training,
            attention_mask=mask,
        )
        hidden = transformer_outputs[0][:, 0:-1, :]  # [sent] + [eos token]
        hidden = self.reduce_sequence(hidden, self.reduce_output)
        return {'encoder_output': hidden}


</source>
</class>

<class classid="25" nclones="2" nlines="79" similarity="73">
<source file="systems/ludwig-0.4.1/ludwig/experiment.py" startline="38" endline="253" pcid="419">
def experiment_cli(
        config: Union[str, dict],
        dataset: Union[str, dict, pd.DataFrame] = None,
        training_set: Union[str, dict, pd.DataFrame] = None,
        validation_set: Union[str, dict, pd.DataFrame] = None,
        test_set: Union[str, dict, pd.DataFrame] = None,
        training_set_metadata: Union[str, dict] = None,
        data_format: str = None,
        experiment_name: str = 'experiment',
        model_name: str = 'run',
        model_load_path: str = None,
        model_resume_path: str = None,
        eval_split: str = TEST,
        skip_save_training_description: bool = False,
        skip_save_training_statistics: bool = False,
        skip_save_model: bool = False,
        skip_save_progress: bool = False,
        skip_save_log: bool = False,
        skip_save_processed_input: bool = False,
        skip_save_unprocessed_output: bool = False,
        skip_save_predictions: bool = False,
        skip_save_eval_stats: bool = False,
        skip_collect_predictions: bool = False,
        skip_collect_overall_stats: bool = False,
        output_directory: str = 'results',
        gpus: Union[str, int, List[int]] = None,
        gpu_memory_limit: int = None,
        allow_parallel_threads: bool = True,
        callbacks: List[Callback] = None,
        backend: Union[Backend, str] = None,
        random_seed: int = default_random_seed,
        debug: bool = False,
        logging_level: int = logging.INFO,
        **kwargs
):
    """Trains a model on a dataset's training and validation splits and
    uses it to predict on the test split.
    It saves the trained model and the statistics of training and testing.

    # Inputs

    :param config: (Union[str, dict]) in-memory representation of
            config or string path to a YAML config file.
    :param dataset: (Union[str, dict, pandas.DataFrame], default: `None`)
        source containing the entire dataset to be used in the experiment.
        If it has a split column, it will be used for splitting (0 for train,
        1 for validation, 2 for test), otherwise the dataset will be
        randomly split.
    :param training_set: (Union[str, dict, pandas.DataFrame], default: `None`)
        source containing training data.
    :param validation_set: (Union[str, dict, pandas.DataFrame], default: `None`)
        source containing validation data.
    :param test_set: (Union[str, dict, pandas.DataFrame], default: `None`)
        source containing test data.
    :param training_set_metadata: (Union[str, dict], default: `None`)
        metadata JSON file or loaded metadata.  Intermediate preprocessed
        structure containing the mappings of the input
        dataset created the first time an input file is used in the same
        directory with the same name and a '.meta.json' extension.
    :param data_format: (str, default: `None`) format to interpret data
        sources. Will be inferred automatically if not specified.  Valid
        formats are `'auto'`, `'csv'`, `'excel'`, `'feather'`,
        `'fwf'`, `'hdf5'` (cache file produced during previous training),
        `'html'` (file containing a single HTML `<table>`), `'json'`, `'jsonl'`,
        `'parquet'`, `'pickle'` (pickled Pandas DataFrame), `'sas'`, `'spss'`,
        `'stata'`, `'tsv'`.
    :param experiment_name: (str, default: `'experiment'`) name for
        the experiment.
    :param model_name: (str, default: `'run'`) name of the model that is
        being used.
    :param model_load_path: (str, default: `None`) if this is specified the
        loaded model will be used as initialization
        (useful for transfer learning).
    :param model_resume_path: (str, default: `None`) resumes training of
        the model from the path specified. The config is restored.
        In addition to config, training statistics and loss for
        epoch and the state of the optimizer are restored such that
        training can be effectively continued from a previously interrupted
        training process.
    :param eval_split: (str, default: `test`) split on which
        to perform evaluation. Valid values are `training`, `validation`
        and `test`.
    :param skip_save_training_description: (bool, default: `False`) disables
        saving the description JSON file.
    :param skip_save_training_statistics: (bool, default: `False`) disables
        saving training statistics JSON file.
    :param skip_save_model: (bool, default: `False`) disables
        saving model weights and hyperparameters each time the model
        improves. By default Ludwig saves model weights after each epoch
        the validation metric improves, but if the model is really big
        that can be time consuming. If you do not want to keep
        the weights and just find out what performance a model can get
        with a set of hyperparameters, use this parameter to skip it,
        but the model will not be loadable later on and the returned model
        will have the weights obtained at the end of training, instead of
        the weights of the epoch with the best validation performance.
   :param skip_save_progress: (bool, default: `False`) disables saving
        progress each epoch. By default Ludwig saves weights and stats
        after each epoch for enabling resuming of training, but if
        the model is really big that can be time consuming and will uses
        twice as much space, use this parameter to skip it, but training
        cannot be resumed later on.
    :param skip_save_log: (bool, default: `False`) disables saving
        TensorBoard logs. By default Ludwig saves logs for the TensorBoard,
        but if it is not needed turning it off can slightly increase the
        overall speed.
    :param skip_save_processed_input: (bool, default: `False`) if input
        dataset is provided it is preprocessed and cached by saving an HDF5
        and JSON files to avoid running the preprocessing again. If this
        parameter is `False`, the HDF5 and JSON file are not saved.
    :param skip_save_unprocessed_output: (bool, default: `False`) by default
        predictions and their probabilities are saved in both raw
        unprocessed numpy files containing tensors and as postprocessed
        CSV files (one for each output feature). If this parameter is True,
        only the CSV ones are saved and the numpy ones are skipped.
    :param skip_save_predictions: (bool, default: `False`) skips saving test
        predictions CSV files
    :param skip_save_eval_stats: (bool, default: `False`) skips saving test
        statistics JSON file
   :param skip_collect_predictions: (bool, default: `False`) skips
        collecting post-processed predictions during eval.
    :param skip_collect_overall_stats: (bool, default: `False`) skips
        collecting overall stats during eval.
    :param output_directory: (str, default: `'results'`) the directory that
        will contain the training statistics, TensorBoard logs, the saved
        model and the training progress files.
    :param gpus: (list, default: `None`) list of GPUs that are available
        for training.
    :param gpu_memory_limit: (int, default: `None`) maximum memory in MB to
        allocate per GPU device.
    :param allow_parallel_threads: (bool, default: `True`) allow TensorFlow
        to use multithreading parallelism to improve performance at
        the cost of determinism.
    :param callbacks: (list, default: `None`) a list of
        `ludwig.callbacks.Callback` objects that provide hooks into the
        Ludwig pipeline.
    :param backend: (Union[Backend, str]) `Backend` or string name
        of backend to use to execute preprocessing / training steps.
    :param random_seed: (int: default: 42) random seed used for weights
        initialization, splits and any other random function.
    :param debug: (bool, default: `False) if `True` turns on `tfdbg` with
        `inf_or_nan` checks.
    :param logging_level: (int) Log level that will be sent to stderr.

    # Return
    :return: (Tuple[LudwigModel, dict, dict, tuple, str)) `(model, evaluation_statistics, training_statistics, preprocessed_data, output_directory)`
        `model` LudwigModel instance
        `evaluation_statistics` dictionary with evaluation performance
            statistics on the test_set,
        `training_statistics` is a dictionary of training statistics for
            each output
        feature containing loss and metrics values for each epoch,
        `preprocessed_data` tuple containing preprocessed
        `(training_set, validation_set, test_set)`, `output_directory`
        filepath string to where results are stored.

    """
    if isinstance(config, str):
        config = load_yaml(config)
    backend = initialize_backend(backend or config.get('backend'))

    if model_load_path:
        model = LudwigModel.load(
            model_load_path,
            logging_level=logging_level,
            backend=backend,
            gpus=gpus,
            gpu_memory_limit=gpu_memory_limit,
            allow_parallel_threads=allow_parallel_threads,
            callbacks=callbacks,
        )
    else:
        model = LudwigModel(
            config=config,
            logging_level=logging_level,
            backend=backend,
            gpus=gpus,
            gpu_memory_limit=gpu_memory_limit,
            allow_parallel_threads=allow_parallel_threads,
            callbacks=callbacks,
        )
    (
        eval_stats,
        train_stats,
        preprocessed_data,
        output_directory
    ) = model.experiment(
        dataset=dataset,
        training_set=training_set,
        validation_set=validation_set,
        test_set=test_set,
        training_set_metadata=training_set_metadata,
        data_format=data_format,
        experiment_name=experiment_name,
        model_name=model_name,
        model_resume_path=model_resume_path,
        eval_split=eval_split,
        skip_save_training_description=skip_save_training_description,
        skip_save_training_statistics=skip_save_training_statistics,
        skip_save_model=skip_save_model,
        skip_save_progress=skip_save_progress,
        skip_save_log=skip_save_log,
        skip_save_processed_input=skip_save_processed_input,
        skip_save_unprocessed_output=skip_save_unprocessed_output,
        skip_save_predictions=skip_save_predictions,
        skip_save_eval_stats=skip_save_eval_stats,
        skip_collect_predictions=skip_collect_predictions,
        skip_collect_overall_stats=skip_collect_overall_stats,
        output_directory=output_directory,
        random_seed=random_seed,
        debug=debug,
    )

    return model, eval_stats, train_stats, preprocessed_data, output_directory


</source>
<source file="systems/ludwig-0.4.1/ludwig/train.py" startline="36" endline="201" pcid="865">
def train_cli(
        config: Union[str, dict] = None,
        dataset: Union[str, dict, pd.DataFrame] = None,
        training_set: Union[str, dict, pd.DataFrame] = None,
        validation_set: Union[str, dict, pd.DataFrame] = None,
        test_set: Union[str, dict, pd.DataFrame] = None,
        training_set_metadata: Union[str, dict] = None,
        data_format: str = None,
        experiment_name: str = 'api_experiment',
        model_name: str = 'run',
        model_load_path: str = None,
        model_resume_path: str = None,
        skip_save_training_description: bool = False,
        skip_save_training_statistics: bool = False,
        skip_save_model: bool = False,
        skip_save_progress: bool = False,
        skip_save_log: bool = False,
        skip_save_processed_input: bool = False,
        output_directory: str = 'results',
        gpus: Union[str, int, List[int]] = None,
        gpu_memory_limit: int = None,
        allow_parallel_threads: bool = True,
        callbacks: List[Callback] = None,
        backend: Union[Backend, str] = None,
        random_seed: int = default_random_seed,
        logging_level: int =logging.INFO,
        debug: bool = False,
        **kwargs
) -> None:
    """*train* defines the entire training procedure used by Ludwig's
    internals. Requires most of the parameters that are taken into the model.
    Builds a full ludwig model and performs the training.

    :param config: (Union[str, dict]) in-memory representation of
            config or string path to a YAML config file.
    :param dataset: (Union[str, dict, pandas.DataFrame], default: `None`)
        source containing the entire dataset to be used for training.
        If it has a split column, it will be used for splitting (0 for train,
        1 for validation, 2 for test), otherwise the dataset will be
        randomly split.
    :param training_set: (Union[str, dict, pandas.DataFrame], default: `None`)
        source containing training data.
    :param validation_set: (Union[str, dict, pandas.DataFrame], default: `None`)
        source containing validation data.
    :param test_set: (Union[str, dict, pandas.DataFrame], default: `None`)
        source containing test data.
    :param training_set_metadata: (Union[str, dict], default: `None`)
        metadata JSON file or loaded metadata.  Intermediate preprocessed
        structure containing the mappings of the input
        dataset created the first time an input file is used in the same
        directory with the same name and a '.meta.json' extension.
    :param data_format: (str, default: `None`) format to interpret data
        sources. Will be inferred automatically if not specified.  Valid
        formats are `'auto'`, `'csv'`, `'excel'`, `'feather'`,
        `'fwf'`, `'hdf5'` (cache file produced during previous training),
        `'html'` (file containing a single HTML `<table>`), `'json'`, `'jsonl'`,
        `'parquet'`, `'pickle'` (pickled Pandas DataFrame), `'sas'`, `'spss'`,
        `'stata'`, `'tsv'`.
    :param experiment_name: (str, default: `'experiment'`) name for
        the experiment.
    :param model_name: (str, default: `'run'`) name of the model that is
        being used.
    :param model_load_path: (str, default: `None`) if this is specified the
        loaded model will be used as initialization
        (useful for transfer learning).
    :param model_resume_path: (str, default: `None`) resumes training of
        the model from the path specified. The config is restored.
        In addition to config, training statistics, loss for each
        epoch and the state of the optimizer are restored such that
        training can be effectively continued from a previously interrupted
        training process.
    :param skip_save_training_description: (bool, default: `False`) disables
        saving the description JSON file.
    :param skip_save_training_statistics: (bool, default: `False`) disables
        saving training statistics JSON file.
    :param skip_save_model: (bool, default: `False`) disables
        saving model weights and hyperparameters each time the model
        improves. By default Ludwig saves model weights after each epoch
        the validation metric improves, but if the model is really big
        that can be time consuming. If you do not want to keep
        the weights and just find out what performance a model can get
        with a set of hyperparameters, use this parameter to skip it,
        but the model will not be loadable later on and the returned model
        will have the weights obtained at the end of training, instead of
        the weights of the epoch with the best validation performance.
    :param skip_save_progress: (bool, default: `False`) disables saving
        progress each epoch. By default Ludwig saves weights and stats
        after each epoch for enabling resuming of training, but if
        the model is really big that can be time consuming and will uses
        twice as much space, use this parameter to skip it, but training
        cannot be resumed later on.
    :param skip_save_log: (bool, default: `False`) disables saving
        TensorBoard logs. By default Ludwig saves logs for the TensorBoard,
        but if it is not needed turning it off can slightly increase the
        overall speed.
    :param skip_save_processed_input: (bool, default: `False`) if input
        dataset is provided it is preprocessed and cached by saving an HDF5
        and JSON files to avoid running the preprocessing again. If this
        parameter is `False`, the HDF5 and JSON file are not saved.
    :param output_directory: (str, default: `'results'`) the directory that
        will contain the training statistics, TensorBoard logs, the saved
        model and the training progress files.
    :param gpus: (list, default: `None`) list of GPUs that are available
        for training.
    :param gpu_memory_limit: (int, default: `None`) maximum memory in MB to
        allocate per GPU device.
    :param allow_parallel_threads: (bool, default: `True`) allow TensorFlow
        to use multithreading parallelism to improve performance at
        the cost of determinism.
    :param callbacks: (list, default: `None`) a list of
        `ludwig.callbacks.Callback` objects that provide hooks into the
        Ludwig pipeline.
    :param backend: (Union[Backend, str]) `Backend` or string name
        of backend to use to execute preprocessing / training steps.
    :param random_seed: (int: default: 42) random seed used for weights
        initialization, splits and any other random function.
    :param debug: (bool, default: `False) if `True` turns on `tfdbg` with
        `inf_or_nan` checks.
    :param logging_level: (int) Log level that will be sent to stderr.

    # Return

    :return: (`None`)
    """
    if model_load_path:
        model = LudwigModel.load(
            model_load_path,
            logging_level=logging_level,
            backend=backend,
            gpus=gpus,
            gpu_memory_limit=gpu_memory_limit,
            allow_parallel_threads=allow_parallel_threads,
            callbacks=callbacks,
        )
    else:
        model = LudwigModel(
            config=config,
            logging_level=logging_level,
            backend=backend,
            gpus=gpus,
            gpu_memory_limit=gpu_memory_limit,
            allow_parallel_threads=allow_parallel_threads,
            callbacks=callbacks,
        )
    model.train(
        dataset=dataset,
        training_set=training_set,
        validation_set=validation_set,
        test_set=test_set,
        training_set_metadata=training_set_metadata,
        data_format=data_format,
        experiment_name=experiment_name,
        model_name=model_name,
        model_resume_path=model_resume_path,
        skip_save_training_description=skip_save_training_description,
        skip_save_training_statistics=skip_save_training_statistics,
        skip_save_model=skip_save_model,
        skip_save_progress=skip_save_progress,
        skip_save_log=skip_save_log,
        skip_save_processed_input=skip_save_processed_input,
        output_directory=output_directory,
        random_seed=random_seed,
        debug=debug,
    )


</source>
</class>

<class classid="26" nclones="2" nlines="168" similarity="79">
<source file="systems/ludwig-0.4.1/ludwig/experiment.py" startline="300" endline="574" pcid="421">
def cli(sys_argv):
    parser = argparse.ArgumentParser(
        description='This script trains and evaluates a model',
        prog='ludwig experiment',
        usage='%(prog)s [options]'
    )

    # ----------------------------
    # Experiment naming parameters
    # ----------------------------
    parser.add_argument(
        '--output_directory',
        type=str,
        default='results',
        help='directory that contains the results'
    )
    parser.add_argument(
        '--experiment_name',
        type=str,
        default='experiment',
        help='experiment name'
    )
    parser.add_argument(
        '--model_name',
        type=str,
        default='run',
        help='name for the model'
    )

    # ---------------
    # Data parameters
    # ---------------
    parser.add_argument(
        '--dataset',
        help='input data file path. '
             'If it has a split column, it will be used for splitting '
             '(0: train, 1: validation, 2: test), '
             'otherwise the dataset will be randomly split'
    )
    parser.add_argument('--training_set', help='input train data file path')
    parser.add_argument(
        '--validation_set', help='input validation data file path'
    )
    parser.add_argument('--test_set', help='input test data file path')

    parser.add_argument(
        '--training_set_metadata',
        help='input metadata JSON file path. An intermediate preprocessed file '
             'containing the mappings of the input file created '
             'the first time a file is used, in the same directory '
             'with the same name and a .json extension'
    )

    parser.add_argument(
        '--data_format',
        help='format of the input data',
        default='auto',
        choices=['auto', 'csv', 'excel', 'feather', 'fwf', 'hdf5',
                 'html' 'tables', 'json', 'jsonl', 'parquet', 'pickle', 'sas',
                 'spss', 'stata', 'tsv']
    )

    parser.add_argument(
        '-es',
        '--eval_split',
        default=TEST,
        choices=[TRAINING, VALIDATION, TEST, FULL],
        help='the split to evaluate the model on'
    )

    parser.add_argument(
        '-sspi',
        '--skip_save_processed_input',
        help='skips saving intermediate HDF5 and JSON files',
        action='store_true',
        default=False
    )
    parser.add_argument(
        '-ssuo',
        '--skip_save_unprocessed_output',
        help='skips saving intermediate NPY output files',
        action='store_true',
        default=False
    )

    # -----------------
    # K-fold parameters
    # -----------------
    parser.add_argument(
        '-kf',
        '--k_fold',
        type=int,
        default=None,
        help='number of folds for a k-fold cross validation run '
    )
    parser.add_argument(
        '-skfsi',
        '--skip_save_k_fold_split_indices',
        action='store_true',
        default=False,
        help='disables saving indices generated to split training data set '
             'for the k-fold cross validation run, but if it is not needed '
             'turning it off can slightly increase the overall speed'
    )

    # ----------------
    # Model parameters
    # ----------------
    config = parser.add_mutually_exclusive_group(required=True)
    config.add_argument(
        '-c',
        '--config',
        type=load_config_from_str,
        help='JSON or YAML serialized string of the model configuration'
    )
    config.add_argument(
        '-cf',
        '--config_file',
        dest='config',
        type=load_yaml,
        help='Path to the YAML file containing the model configuration'
    )

    parser.add_argument(
        '-mlp',
        '--model_load_path',
        help='path of a pretrained model to load as initialization'
    )
    parser.add_argument(
        '-mrp',
        '--model_resume_path',
        help='path of the model directory to resume training of'
    )
    parser.add_argument(
        '-sstd',
        '--skip_save_training_description',
        action='store_true',
        default=False,
        help='disables saving the description JSON file'
    )
    parser.add_argument(
        '-ssts',
        '--skip_save_training_statistics',
        action='store_true',
        default=False,
        help='disables saving training statistics JSON file'
    )
    parser.add_argument(
        '-sstp',
        '--skip_save_predictions',
        help='skips saving test predictions CSV files',
        action='store_true', default=False
    )
    parser.add_argument(
        '-sstes',
        '--skip_save_eval_stats',
        help='skips saving eval statistics JSON file',
        action='store_true', default=False
    )
    parser.add_argument(
        '-ssm',
        '--skip_save_model',
        action='store_true',
        default=False,
        help='disables saving model weights and hyperparameters each time '
             'the model improves. '
             'By default Ludwig saves model weights after each epoch '
             'the validation metric imprvoes, but if the model is really big '
             'that can be time consuming. If you do not want to keep '
             'the weights and just find out what performance a model can get '
             'with a set of hyperparameters, use this parameter to skip it,'
             'but the model will not be loadable later on'
    )
    parser.add_argument(
        '-ssp',
        '--skip_save_progress',
        action='store_true',
        default=False,
        help='disables saving progress each epoch. By default Ludwig saves '
             'weights and stats after each epoch for enabling resuming '
             'of training, but if the model is really big that can be '
             'time consuming and will uses twice as much space, use '
             'this parameter to skip it, but training cannot be resumed '
             'later on'
    )
    parser.add_argument(
        '-ssl',
        '--skip_save_log',
        action='store_true',
        default=False,
        help='disables saving TensorBoard logs. By default Ludwig saves '
             'logs for the TensorBoard, but if it is not needed turning it off '
             'can slightly increase the overall speed'
    )

    # ------------------
    # Runtime parameters
    # ------------------
    parser.add_argument(
        '-rs',
        '--random_seed',
        type=int,
        default=42,
        help='a random seed that is going to be used anywhere there is a call '
             'to a random number generator: data splitting, parameter '
             'initialization and training set shuffling'
    )
    parser.add_argument(
        '-g',
        '--gpus',
        nargs='+',
        type=int,
        default=None,
        help='list of GPUs to use'
    )
    parser.add_argument(
        '-gml',
        '--gpu_memory_limit',
        type=int,
        default=None,
        help='maximum memory in MB to allocate per GPU device'
    )
    parser.add_argument(
        '-dpt',
        '--disable_parallel_threads',
        action='store_false',
        dest='allow_parallel_threads',
        help='disable TensorFlow from using multithreading for reproducibility'
    )
    parser.add_argument(
        "-b",
        "--backend",
        help='specifies backend to use for parallel / distributed execution, '
             'defaults to local execution or Horovod if called using horovodrun',
        choices=ALL_BACKENDS,
    )
    parser.add_argument(
        '-dbg',
        '--debug',
        action='store_true',
        default=False,
        help='enables debugging mode'
    )
    parser.add_argument(
        '-l',
        '--logging_level',
        default='info',
        help='the level of logging to use',
        choices=['critical', 'error', 'warning', 'info', 'debug', 'notset']
    )

    add_contrib_callback_args(parser)
    args = parser.parse_args(sys_argv)

    args.callbacks = args.callbacks or []
    for callback in args.callbacks:
        callback.on_cmdline('experiment', *sys_argv)

    args.logging_level = logging_level_registry[args.logging_level]
    logging.getLogger('ludwig').setLevel(
        args.logging_level
    )
    global logger
    logger = logging.getLogger('ludwig.experiment')

    args.backend = initialize_backend(args.backend or args.config.get('backend'))
    if args.backend.is_coordinator():
        print_ludwig('Experiment', LUDWIG_VERSION)

    if args.k_fold is None:
        experiment_cli(**vars(args))
    else:
        kfold_cross_validate_cli(**vars(args))


</source>
<source file="systems/ludwig-0.4.1/ludwig/train.py" startline="202" endline="421" pcid="866">
def cli(sys_argv):
    parser = argparse.ArgumentParser(
        description='This script trains a model',
        prog='ludwig train',
        usage='%(prog)s [options]'
    )

    # ----------------------------
    # Experiment naming parameters
    # ----------------------------
    parser.add_argument(
        '--output_directory',
        type=str,
        default='results',
        help='directory that contains the results'
    )
    parser.add_argument(
        '--experiment_name',
        type=str,
        default='experiment',
        help='experiment name'
    )
    parser.add_argument(
        '--model_name',
        type=str,
        default='run',
        help='name for the model'
    )

    # ---------------
    # Data parameters
    # ---------------
    parser.add_argument(
        '--dataset',
        help='input data file path. '
             'If it has a split column, it will be used for splitting '
             '(0: train, 1: validation, 2: test), '
             'otherwise the dataset will be randomly split'
    )
    parser.add_argument('--training_set', help='input train data file path')
    parser.add_argument(
        '--validation_set', help='input validation data file path'
    )
    parser.add_argument('--test_set', help='input test data file path')

    parser.add_argument(
        '--training_set_metadata',
        help='input metadata JSON file path. An intermediate preprocessed file '
             'containing the mappings of the input file created '
             'the first time a file is used, in the same directory '
             'with the same name and a .json extension'
    )

    parser.add_argument(
        '--data_format',
        help='format of the input data',
        default='auto',
        choices=['auto', 'csv', 'excel', 'feather', 'fwf', 'hdf5',
                 'html' 'tables', 'json', 'jsonl', 'parquet', 'pickle', 'sas',
                 'spss', 'stata', 'tsv']
    )

    parser.add_argument(
        '-sspi',
        '--skip_save_processed_input',
        help='skips saving intermediate HDF5 and JSON files',
        action='store_true',
        default=False
    )

    # ----------------
    # Model parameters
    # ----------------
    config = parser.add_mutually_exclusive_group(required=True)
    config.add_argument(
        '-c',
        '--config',
        type=load_config_from_str,
        help='JSON or YAML serialized string of the model configuration'
    )
    config.add_argument(
        '-cf',
        '--config_file',
        dest='config',
        type=load_yaml,
        help='Path to the YAML file containing the model configuration'
    )

    parser.add_argument(
        '-mlp',
        '--model_load_path',
        help='path of a pretrained model to load as initialization'
    )
    parser.add_argument(
        '-mrp',
        '--model_resume_path',
        help='path of the model directory to resume training of'
    )
    parser.add_argument(
        '-sstd',
        '--skip_save_training_description',
        action='store_true',
        default=False,
        help='disables saving the description JSON file'
    )
    parser.add_argument(
        '-ssts',
        '--skip_save_training_statistics',
        action='store_true',
        default=False,
        help='disables saving training statistics JSON file'
    )
    parser.add_argument(
        '-ssm',
        '--skip_save_model',
        action='store_true',
        default=False,
        help='disables saving weights each time the model improves. '
             'By default Ludwig saves  weights after each epoch '
             'the validation metric (improves, but  if the model is really big '
             'that can be time consuming. If you do not want to keep '
             'the weights and just find out what performance a model can get '
             'with a set of hyperparameters, use this parameter to skip it'
    )
    parser.add_argument(
        '-ssp',
        '--skip_save_progress',
        action='store_true',
        default=False,
        help='disables saving weights after each epoch. By default ludwig saves '
             'weights after each epoch for enabling resuming of training, but '
             'if the model is really big that can be time consuming and will '
             'save twice as much space, use this parameter to skip it'
    )
    parser.add_argument(
        '-ssl',
        '--skip_save_log',
        action='store_true',
        default=False,
        help='disables saving TensorBoard logs. By default Ludwig saves '
             'logs for the TensorBoard, but if it is not needed turning it off '
             'can slightly increase the overall speed'
    )

    # ------------------
    # Runtime parameters
    # ------------------
    parser.add_argument(
        '-rs',
        '--random_seed',
        type=int,
        default=42,
        help='a random seed that is going to be used anywhere there is a call '
             'to a random number generator: data splitting, parameter '
             'initialization and training set shuffling'
    )
    parser.add_argument(
        '-g',
        '--gpus',
        nargs='+',
        type=int,
        default=None,
        help='list of gpus to use'
    )
    parser.add_argument(
        '-gml',
        '--gpu_memory_limit',
        type=int,
        default=None,
        help='maximum memory in MB to allocate per GPU device'
    )
    parser.add_argument(
        '-dpt',
        '--disable_parallel_threads',
        action='store_false',
        dest='allow_parallel_threads',
        help='disable TensorFlow from using multithreading for reproducibility'
    )
    parser.add_argument(
        "-b",
        "--backend",
        help='specifies backend to use for parallel / distributed execution, '
             'defaults to local execution or Horovod if called using horovodrun',
        choices=ALL_BACKENDS,
    )
    parser.add_argument(
        '-dbg',
        '--debug',
        action='store_true',
        default=False, help='enables debugging mode'
    )
    parser.add_argument(
        '-l',
        '--logging_level',
        default='info',
        help='the level of logging to use',
        choices=['critical', 'error', 'warning', 'info', 'debug', 'notset']
    )

    add_contrib_callback_args(parser)
    args = parser.parse_args(sys_argv)

    args.callbacks = args.callbacks or []
    for callback in args.callbacks:
        callback.on_cmdline('train', *sys_argv)

    args.logging_level = logging_level_registry[args.logging_level]
    logging.getLogger('ludwig').setLevel(
        args.logging_level
    )
    global logger
    logger = logging.getLogger('ludwig.train')

    args.backend = initialize_backend(args.backend or args.config.get('backend'))
    if args.backend.is_coordinator():
        print_ludwig('Train', LUDWIG_VERSION)

    train_cli(**vars(args))


</source>
</class>

<class classid="27" nclones="4" nlines="29" similarity="71">
<source file="systems/ludwig-0.4.1/ludwig/utils/visualization_utils.py" startline="772" endline="822" pcid="649">


def threshold_vs_metric_plot(
        thresholds,
        scores,
        algorithm_names=None,
        title=None,
        filename=None,
        callbacks=None,
):
    sns.set_style('whitegrid')

    colors = plt.get_cmap('tab10').colors

    # y_ticks_minor = np.linspace(0.0, 1.0, num=21)
    # y_ticks_major = np.linspace(0.0, 1.0, num=11)
    # y_ticks_major_labels = ['{:3.0f}%'.format(y * 100) for y in y_ticks_major]

    fig, ax1 = plt.subplots()

    if title is not None:
        ax1.set_title(title)

    ax1.grid(which='both')
    ax1.grid(which='minor', alpha=0.5)
    ax1.grid(which='major', alpha=0.75)
    ax1.set_xticks([x for idx, x in enumerate(thresholds) if idx % 2 == 0])
    ax1.set_xticks(thresholds, minor=True)

    # ax1.set_xlim(0, 1)
    ax1.set_xlabel('confidence threshold')

    # ax1.set_ylim(0, 1)
    # ax1.set_yticks(y_ticks_major)
    # ax1.set_yticklabels(y_ticks_major_labels)
    # ax1.set_yticks(y_ticks_minor, minor=True)

    for i in range(len(scores)):
        algorithm_name = algorithm_names[
                             i] + ' ' if algorithm_names is not None and i < len(
            algorithm_names) else ''
        ax1.plot(thresholds, scores[i], label=algorithm_name, color=colors[i],
                 linewidth=3, marker='o')

    ax1.legend(frameon=True)
    plt.tight_layout()
    visualize_callbacks(callbacks, plt.gcf())
    if filename:
        plt.savefig(filename)
    else:
        plt.show()
</source>
<source file="systems/ludwig-0.4.1/ludwig/utils/visualization_utils.py" startline="1105" endline="1143" pcid="657">


def plot_distributions(
        distributions,
        labels=None,
        title=None,
        filename=None,
        callbacks=None,
):
    sns.set_style('whitegrid')

    colors = plt.get_cmap('tab10').colors

    fig, ax1 = plt.subplots()

    if title is not None:
        ax1.set_title(title)

    ax1.grid(which='both')
    ax1.grid(which='minor', alpha=0.5)
    ax1.grid(which='major', alpha=0.75)

    ax1.set_xlabel('class')

    ax1.set_ylabel('p')
    ax1.tick_params('y')

    for i, distribution in enumerate(distributions):
        ax1.plot(distribution, color=colors[i], alpha=0.6,
                 label=labels[i] if labels is not None and i < len(
                     labels) else 'Distribution {}'.format(i))

    ax1.legend(frameon=True)
    fig.tight_layout()
    visualize_callbacks(callbacks, plt.gcf())
    if filename:
        plt.savefig(filename)
    else:
        plt.show()
</source>
<source file="systems/ludwig-0.4.1/ludwig/utils/visualization_utils.py" startline="932" endline="967" pcid="652">


def brier_plot(
        brier_scores,
        algorithm_names=None,
        title=None,
        filename=None,
        callbacks=None,
):
    sns.set_style('whitegrid')

    if title is not None:
        plt.title(title)

    colors = plt.get_cmap('tab10').colors

    plt.grid(which='both')
    plt.grid(which='minor', alpha=0.5)
    plt.grid(which='major', alpha=0.75)
    plt.xlabel('class')
    plt.ylabel('brier')

    for i in range(brier_scores.shape[1]):
        plt.plot(brier_scores[:, i],
                 label=algorithm_names[
                           i] + ' ' if algorithm_names is not None and i < len(
                     algorithm_names) else '',
                 color=colors[i], linewidth=3)

    plt.legend()
    plt.tight_layout()
    visualize_callbacks(callbacks, plt.gcf())
    if filename:
        plt.savefig(filename)
    else:
        plt.show()
</source>
<source file="systems/ludwig-0.4.1/ludwig/utils/visualization_utils.py" startline="1144" endline="1178" pcid="658">


def plot_distributions_difference(
        distribution,
        labels=None,
        title=None,
        filename=None,
        callbacks=None,
):
    sns.set_style('whitegrid')

    colors = plt.get_cmap('tab10').colors

    fig, ax1 = plt.subplots()

    if title is not None:
        ax1.set_title(title)

    ax1.grid(which='both')
    ax1.grid(which='minor', alpha=0.5)
    ax1.grid(which='major', alpha=0.75)

    ax1.set_xlabel('class')

    ax1.set_ylabel('p')
    ax1.tick_params('y')

    ax1.plot(distribution, color=colors[0])

    fig.tight_layout()
    visualize_callbacks(callbacks, plt.gcf())
    if filename:
        plt.savefig(filename)
    else:
        plt.show()
</source>
</class>

<class classid="28" nclones="3" nlines="26" similarity="76">
<source file="systems/ludwig-0.4.1/ludwig/utils/visualization_utils.py" startline="1303" endline="1333" pcid="661">


def hyperopt_int_plot(
        hyperopt_results_df,
        hp_name,
        metric,
        title,
        filename,
        log_scale_x=False,
        log_scale_y=True
):
    sns.set_style('whitegrid')
    plt.figure()
    seaborn_figure = sns.scatterplot(
        x=hp_name,
        y=metric,
        data=hyperopt_results_df
    )
    seaborn_figure.set_title(title)
    if log_scale_x:
        seaborn_figure.set(xscale="log")
    if log_scale_y:
        seaborn_figure.set(yscale="log")
    seaborn_figure.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))
    seaborn_figure.xaxis.set_major_formatter(ticker.ScalarFormatter())
    seaborn_figure.xaxis.set_minor_formatter(ticker.NullFormatter())
    seaborn_figure.figure.tight_layout()
    if filename:
        seaborn_figure.figure.savefig(filename)
    else:
        seaborn_figure.figure.show()
</source>
<source file="systems/ludwig-0.4.1/ludwig/utils/visualization_utils.py" startline="1334" endline="1362" pcid="662">


def hyperopt_float_plot(
        hyperopt_results_df,
        hp_name,
        metric,
        title,
        filename,
        log_scale_x=False,
        log_scale_y=True
):
    sns.set_style('whitegrid')
    plt.figure()
    seaborn_figure = sns.scatterplot(
        x=hp_name,
        y=metric,
        data=hyperopt_results_df
    )
    seaborn_figure.set_title(title)
    seaborn_figure.set(ylabel=metric)
    if log_scale_x:
        seaborn_figure.set(xscale="log")
    if log_scale_y:
        seaborn_figure.set(yscale="log")
    seaborn_figure.figure.tight_layout()
    if filename:
        seaborn_figure.figure.savefig(filename)
    else:
        seaborn_figure.figure.show()
</source>
<source file="systems/ludwig-0.4.1/ludwig/utils/visualization_utils.py" startline="1363" endline="1390" pcid="663">


def hyperopt_category_plot(
        hyperopt_results_df,
        hp_name,
        metric,
        title,
        filename,
        log_scale=True
):
    sns.set_style('whitegrid')
    plt.figure()
    seaborn_figure = sns.violinplot(
        x=hp_name,
        y=metric,
        data=hyperopt_results_df,
        fit_reg=False
    )
    seaborn_figure.set_title(title)
    seaborn_figure.set(ylabel=metric)
    sns.despine()
    if log_scale:
        seaborn_figure.set(yscale="log")
    plt.tight_layout()
    if filename:
        plt.savefig(filename)
    else:
        plt.show()
</source>
</class>

<class classid="29" nclones="2" nlines="10" similarity="70">
<source file="systems/ludwig-0.4.1/ludwig/datasets/santander_value_prediction/__init__.py" startline="51" endline="62" pcid="737">
    def process_downloaded_dataset(self):
        super().process_downloaded_dataset()
        processed_df = pd.read_csv(os.path.join(self.processed_dataset_path,
                                                self.csv_filename))
        # Ensure feature column names are strings (some are numeric); keep special names as is
        processed_df.columns = ['C' + str(col) for col in processed_df.columns]
        processed_df.rename(
            columns={'CID': 'ID', 'Ctarget': 'target', 'Csplit': 'split'}, inplace=True)
        processed_df.to_csv(
            os.path.join(self.processed_dataset_path, self.csv_filename),
            index=False
        )
</source>
<source file="systems/ludwig-0.4.1/ludwig/datasets/goemotions/__init__.py" startline="45" endline="57" pcid="741">
    def process_downloaded_dataset(self):
        super().process_downloaded_dataset()
        # format emotion ids to be a set of emotion ids vs. string
        processed_df = pd.read_csv(os.path.join(self.processed_dataset_path,
                                                self.csv_filename))
        processed_df.columns = ['text', 'emotion_ids', 'comment_id', 'split']
        processed_df['emotion_ids'] = processed_df['emotion_ids'].apply(
            lambda e_id: " ".join(e_id.split(","))
        )
        processed_df.to_csv(
            os.path.join(self.processed_dataset_path, self.csv_filename),
            index=False
        )
</source>
</class>

<class classid="30" nclones="4" nlines="10" similarity="81">
<source file="systems/ludwig-0.4.1/ludwig/datasets/porto_seguro_safe_driver/__init__.py" startline="42" endline="52" pcid="745">
    def __init__(
            self,
            cache_dir=DEFAULT_CACHE_LOCATION,
            kaggle_username=None,
            kaggle_key=None
    ):
        self.kaggle_username = kaggle_username
        self.kaggle_key = kaggle_key
        self.is_kaggle_competition = True
        super().__init__(dataset_name='porto_seguro_safe_driver', cache_dir=cache_dir)
        
</source>
<source file="systems/ludwig-0.4.1/ludwig/datasets/titanic/__init__.py" startline="45" endline="55" pcid="789">
    def __init__(
            self,
            cache_dir=DEFAULT_CACHE_LOCATION,
            kaggle_username=None,
            kaggle_key=None
    ):
        self.kaggle_username = kaggle_username
        self.kaggle_key = kaggle_key
        self.is_kaggle_competition = True
        super().__init__(dataset_name='titanic', cache_dir=cache_dir)

</source>
<source file="systems/ludwig-0.4.1/ludwig/datasets/rossmann_store_sales/__init__.py" startline="51" endline="62" pcid="794">
    def __init__(
            self,
            cache_dir=DEFAULT_CACHE_LOCATION,
            kaggle_username=None,
            kaggle_key=None
    ):
        self.kaggle_username = kaggle_username
        self.kaggle_key = kaggle_key
        self.is_kaggle_competition = True
        super().__init__(dataset_name='rossmann_store_sales',
                         cache_dir=cache_dir)

</source>
<source file="systems/ludwig-0.4.1/ludwig/datasets/allstate_claims_severity/__init__.py" startline="42" endline="51" pcid="775">
    def __init__(
            self,
            cache_dir=DEFAULT_CACHE_LOCATION,
            kaggle_username=None,
            kaggle_key=None
    ):
        self.kaggle_username = kaggle_username
        self.kaggle_key = kaggle_key
        self.is_kaggle_competition = True
        super().__init__(dataset_name='allstate_claims_severity', cache_dir=cache_dir)
</source>
</class>

<class classid="31" nclones="5" nlines="15" similarity="70">
<source file="systems/ludwig-0.4.1/ludwig/features/text_feature.py" startline="234" endline="253" pcid="890">
    def add_feature_data(
            feature,
            input_df,
            proc_df,
            metadata,
            preprocessing_parameters,
            backend,
            skip_save_processed_input
    ):
        chars_data, words_data = TextFeatureMixin.feature_data(
            input_df[feature[COLUMN]].astype(str),
            metadata[feature[NAME]],
            preprocessing_parameters,
            backend
        )
        proc_df['{}_char'.format(feature[PROC_COLUMN])] = chars_data
        proc_df['{}_word'.format(feature[PROC_COLUMN])] = words_data
        return proc_df


</source>
<source file="systems/ludwig-0.4.1/ludwig/features/timeseries_feature.py" startline="132" endline="149" pcid="996">

    @staticmethod
    def add_feature_data(
            feature,
            input_df,
            proc_df,
            metadata,
            preprocessing_parameters,
            backend,
            skip_save_processed_input
    ):
        proc_df[feature[PROC_COLUMN]] = TimeseriesFeatureMixin.feature_data(
            input_df[feature[COLUMN]].astype(str),
            metadata[feature[NAME]],
            preprocessing_parameters,
            backend
        )
        return proc_df
</source>
<source file="systems/ludwig-0.4.1/ludwig/features/sequence_feature.py" startline="123" endline="140" pcid="913">
        return sequence_data

    @staticmethod
    def add_feature_data(
            feature,
            input_df,
            proc_df,
            metadata,
            preprocessing_parameters,
            backend,
            skip_save_processed_input
    ):
        sequence_data = SequenceInputFeature.feature_data(
            input_df[feature[COLUMN]].astype(str),
            metadata[feature[NAME]], preprocessing_parameters,
            backend
        )
        proc_df[feature[PROC_COLUMN]] = sequence_data
</source>
<source file="systems/ludwig-0.4.1/ludwig/features/bag_feature.py" startline="91" endline="108" pcid="953">
    def add_feature_data(
            feature,
            input_df,
            proc_df,
            metadata,
            preprocessing_parameters,
            backend,
            skip_save_processed_input
    ):
        proc_df[feature[PROC_COLUMN]] = BagFeatureMixin.feature_data(
            input_df[feature[COLUMN]].astype(str),
            metadata[feature[NAME]],
            preprocessing_parameters,
            backend
        )
        return proc_df


</source>
<source file="systems/ludwig-0.4.1/ludwig/features/date_feature.py" startline="107" endline="125" pcid="942">
    def add_feature_data(
            feature,
            input_df,
            proc_df,
            metadata,
            preprocessing_parameters,
            backend,
            skip_save_processed_input
    ):
        datetime_format = preprocessing_parameters['datetime_format']
        proc_df[feature[PROC_COLUMN]] = backend.df_engine.map_objects(
            input_df[feature[COLUMN]],
            lambda x: np.array(DateFeatureMixin.date_to_list(
                x, datetime_format, preprocessing_parameters
            ), dtype=np.int16)
        )
        return proc_df


</source>
</class>

<class classid="32" nclones="2" nlines="13" similarity="71">
<source file="systems/ludwig-0.4.1/ludwig/features/text_feature.py" startline="266" endline="284" pcid="892">
    def call(self, inputs, training=None, mask=None):
        assert isinstance(inputs, tf.Tensor)
        assert inputs.dtype == tf.int8 or inputs.dtype == tf.int16 or \
               inputs.dtype == tf.int32 or inputs.dtype == tf.int64
        assert len(inputs.shape) == 2

        inputs_exp = tf.cast(inputs, dtype=tf.int32)

        if self.pad_idx is not None:
            inputs_mask = tf.not_equal(inputs, self.pad_idx)
        else:
            inputs_mask = None
        lengths = tf.reduce_sum(tf.cast(inputs_mask, dtype=tf.int32), axis=1)
        encoder_output = self.encoder_obj(
            inputs_exp, training=training, mask=inputs_mask
        )

        encoder_output[LENGTHS] = lengths
        return encoder_output
</source>
<source file="systems/ludwig-0.4.1/ludwig/features/sequence_feature.py" startline="153" endline="166" pcid="915">
        else:
            self.encoder_obj = self.initialize_encoder(feature)

    def call(self, inputs, training=None, mask=None):
        assert isinstance(inputs, tf.Tensor)
        assert inputs.dtype == tf.int8 or inputs.dtype == tf.int16 or \
               inputs.dtype == tf.int32 or inputs.dtype == tf.int64
        assert len(inputs.shape) == 2

        inputs_exp = tf.cast(inputs, dtype=tf.int32)
        inputs_mask = tf.not_equal(inputs, 0)
        lengths = tf.reduce_sum(tf.cast(inputs_mask, dtype=tf.int32), axis=1)
        encoder_output = self.encoder_obj(
            inputs_exp, training=training, mask=inputs_mask
</source>
</class>

<class classid="33" nclones="2" nlines="18" similarity="83">
<source file="systems/ludwig-0.4.1/ludwig/features/text_feature.py" startline="414" endline="435" pcid="902">
    @staticmethod
    def calculate_overall_stats(
            predictions,
            targets,
            train_set_metadata,
    ):
        overall_stats = {}
        level_idx2str = '{}_{}'.format(train_set_metadata['level'], 'idx2str')

        sequences = targets
        last_elem_sequence = sequences[np.arange(sequences.shape[0]),
                                       (sequences != 0).cumsum(1).argmax(1)]
        confusion_matrix = ConfusionMatrix(
            last_elem_sequence,
            predictions[LAST_PREDICTIONS],
            labels=train_set_metadata[level_idx2str]
        )
        overall_stats['confusion_matrix'] = confusion_matrix.cm.tolist()
        overall_stats['overall_stats'] = confusion_matrix.stats()
        overall_stats['per_class_stats'] = confusion_matrix.per_class_stats()

        return overall_stats
</source>
<source file="systems/ludwig-0.4.1/ludwig/features/sequence_feature.py" startline="407" endline="426" pcid="930">
                for cls in feature_metadata['idx2str']
            ]

    @staticmethod
    def calculate_overall_stats(
            predictions,
            targets,
            train_set_metadata
    ):
        overall_stats = {}
        sequences = targets
        last_elem_sequence = sequences[np.arange(sequences.shape[0]),
                                       (sequences != 0).cumsum(1).argmax(1)]
        confusion_matrix = ConfusionMatrix(
            last_elem_sequence,
            predictions[LAST_PREDICTIONS],
            labels=train_set_metadata['idx2str']
        )
        overall_stats['confusion_matrix'] = confusion_matrix.cm.tolist()
        overall_stats['overall_stats'] = confusion_matrix.stats()
</source>
</class>

<class classid="34" nclones="5" nlines="39" similarity="71">
<source file="systems/ludwig-0.4.1/ludwig/collect.py" startline="373" endline="453" pcid="1018">
def cli_collect_weights(sys_argv):
    """Command Line Interface to collecting the weights for the model
    --m: Input model that is necessary to collect to the tensors, this is a
         required *option*
    --t: Tensors to collect
    --od: Output directory of the model, defaults to results
    --dbg: Debug if the model is to be started with python debugger
    --v: Verbose: Defines the logging level that the user will be exposed to
    """
    parser = argparse.ArgumentParser(
        description='This script loads a pretrained model '
                    'and uses it collect weights.',
        prog='ludwig collect_weights',
        usage='%(prog)s [options]'
    )

    # ----------------
    # Model parameters
    # ----------------
    parser.add_argument(
        '-m',
        '--model_path',
        help='model to load',
        required=True
    )
    parser.add_argument(
        '-t',
        '--tensors',
        help='tensors to collect',
        nargs='+',
        required=True
    )

    # -------------------------
    # Output results parameters
    # -------------------------
    parser.add_argument(
        '-od',
        '--output_directory',
        type=str,
        default='results',
        help='directory that contains the results'
    )

    # ------------------
    # Runtime parameters
    # ------------------
    parser.add_argument(
        '-dbg',
        '--debug',
        action='store_true',
        default=False,
        help='enables debugging mode'
    )
    parser.add_argument(
        '-l',
        '--logging_level',
        default='info',
        help='the level of logging to use',
        choices=['critical', 'error', 'warning', 'info', 'debug', 'notset']
    )

    add_contrib_callback_args(parser)
    args = parser.parse_args(sys_argv)

    args.callbacks = args.callbacks or []
    for callback in args.callbacks:
        callback.on_cmdline('collect_weights', *sys_argv)

    args.logging_level = logging_level_registry[args.logging_level]
    logging.getLogger('ludwig').setLevel(
        args.logging_level
    )
    global logger
    logger = logging.getLogger('ludwig.collect')

    print_ludwig('Collect Weights', LUDWIG_VERSION)

    collect_weights(**vars(args))


</source>
<source file="systems/ludwig-0.4.1/ludwig/export.py" startline="117" endline="175" pcid="1049">

def cli_export_savedmodel(sys_argv):
    parser = argparse.ArgumentParser(
        description='This script loads a pretrained model '
                    'and saves it as a SavedModel.',
        prog='ludwig export_savedmodel',
        usage='%(prog)s [options]'
    )

    # ----------------
    # Model parameters
    # ----------------
    parser.add_argument(
        '-m',
        '--model_path',
        help='model to load',
        required=True
    )

    # -----------------
    # Output parameters
    # -----------------
    parser.add_argument(
        '-od',
        '--output_path',
        type=str,
        help='path where to save the export model',
        required=True
    )

    # ------------------
    # Runtime parameters
    # ------------------
    parser.add_argument(
        '-l',
        '--logging_level',
        default='info',
        help='the level of logging to use',
        choices=['critical', 'error', 'warning', 'info', 'debug', 'notset']
    )

    add_contrib_callback_args(parser)
    args = parser.parse_args(sys_argv)

    args.callbacks = args.callbacks or []
    for callback in args.callbacks:
        callback.on_cmdline('export_savedmodel', *sys_argv)

    args.logging_level = logging_level_registry[args.logging_level]
    logging.getLogger('ludwig').setLevel(
        args.logging_level
    )
    global logger
    logger = logging.getLogger('ludwig.export')

    print_ludwig('Export SavedModel', LUDWIG_VERSION)

    export_savedmodel(**vars(args))

</source>
<source file="systems/ludwig-0.4.1/ludwig/export.py" startline="241" endline="305" pcid="1051">

def cli_export_mlflow(sys_argv):
    parser = argparse.ArgumentParser(
        description='This script loads a pretrained model '
                    'and saves it as an MLFlow model.',
        prog='ludwig export_mlflow',
        usage='%(prog)s [options]'
    )

    # ----------------
    # Model parameters
    # ----------------
    parser.add_argument(
        '-m',
        '--model_path',
        help='model to load',
        required=True
    )
    parser.add_argument(
        '-mn',
        '--registered_model_name',
        help='model name to upload to in MLflow model registry',
        default='mlflow'
    )

    # -----------------
    # Output parameters
    # -----------------
    parser.add_argument(
        '-od',
        '--output_path',
        type=str,
        help='path where to save the exported model',
        required=True
    )

    # ------------------
    # Runtime parameters
    # ------------------
    parser.add_argument(
        '-l',
        '--logging_level',
        default='info',
        help='the level of logging to use',
        choices=['critical', 'error', 'warning', 'info', 'debug', 'notset']
    )

    add_contrib_callback_args(parser)
    args = parser.parse_args(sys_argv)

    args.callbacks = args.callbacks or []
    for callback in args.callbacks:
        callback.on_cmdline('export_mlflow', *sys_argv)

    args.logging_level = logging_level_registry[args.logging_level]
    logging.getLogger('ludwig').setLevel(
        args.logging_level
    )
    global logger
    logger = logging.getLogger('ludwig.export')

    print_ludwig('Export MLFlow', LUDWIG_VERSION)

    export_mlflow(**vars(args))

</source>
<source file="systems/ludwig-0.4.1/ludwig/export.py" startline="176" endline="240" pcid="1050">

def cli_export_neuropod(sys_argv):
    parser = argparse.ArgumentParser(
        description='This script loads a pretrained model '
                    'and saves it as a Neuropod.',
        prog='ludwig export_neuropod',
        usage='%(prog)s [options]'
    )

    # ----------------
    # Model parameters
    # ----------------
    parser.add_argument(
        '-m',
        '--model_path',
        help='model to load',
        required=True
    )
    parser.add_argument(
        '-mn',
        '--model_name',
        help='model name',
        default='neuropod'
    )

    # -----------------
    # Output parameters
    # -----------------
    parser.add_argument(
        '-od',
        '--output_path',
        type=str,
        help='path where to save the export model',
        required=True
    )

    # ------------------
    # Runtime parameters
    # ------------------
    parser.add_argument(
        '-l',
        '--logging_level',
        default='info',
        help='the level of logging to use',
        choices=['critical', 'error', 'warning', 'info', 'debug', 'notset']
    )

    add_contrib_callback_args(parser)
    args = parser.parse_args(sys_argv)

    args.callbacks = args.callbacks or []
    for callback in args.callbacks:
        callback.on_cmdline('export_neuropod', *sys_argv)

    args.logging_level = logging_level_registry[args.logging_level]
    logging.getLogger('ludwig').setLevel(
        args.logging_level
    )
    global logger
    logger = logging.getLogger('ludwig.export')

    print_ludwig('Export Neuropod', LUDWIG_VERSION)

    export_neuropod(**vars(args))

</source>
<source file="systems/ludwig-0.4.1/ludwig/collect.py" startline="454" endline="507" pcid="1019">
def cli_collect_summary(sys_argv):
    """Command Line Interface to collecting a summary of the model layers and weights.
    --m: Input model that is necessary to collect to the tensors, this is a
         required *option*
    --v: Verbose: Defines the logging level that the user will be exposed to
    """
    parser = argparse.ArgumentParser(
        description='This script loads a pretrained model '
                    'and prints names of weights and layers activations '
                    'to use with other collect commands',
        prog='ludwig collect_summary',
        usage='%(prog)s [options]'
    )

    # ----------------
    # Model parameters
    # ----------------
    parser.add_argument(
        '-m',
        '--model_path',
        help='model to load',
        required=True
    )

    # ------------------
    # Runtime parameters
    # ------------------
    parser.add_argument(
        '-l',
        '--logging_level',
        default='info',
        help='the level of logging to use',
        choices=['critical', 'error', 'warning', 'info', 'debug', 'notset']
    )

    add_contrib_callback_args(parser)
    args = parser.parse_args(sys_argv)

    args.callbacks = args.callbacks or []
    for callback in args.callbacks:
        callback.on_cmdline('collect_summary', *sys_argv)

    args.logging_level = logging_level_registry[args.logging_level]
    logging.getLogger('ludwig').setLevel(
        args.logging_level
    )
    global logger
    logger = logging.getLogger('ludwig.collect')

    print_ludwig('Collect Summary', LUDWIG_VERSION)

    print_model_summary(**vars(args))


</source>
</class>

<class classid="35" nclones="2" nlines="12" similarity="83">
<source file="systems/ludwig-0.4.1/ludwig/export.py" startline="58" endline="86" pcid="1047">

def export_neuropod(
        model_path,
        output_path='neuropod',
        model_name='neuropod',
        **kwargs
):
    """Exports a model to Neuropod

    # Inputs

    :param model_path: (str) filepath to pre-trained model.
    :param output_path: (str, default: `'neuropod'`)  directory to store the
        neuropod model.
    :param model_name: (str, default: `'neuropod'`) save neuropod under this
        name.

    # Return

    :returns: (`None`)
    """
    logger.info('Model path: {}'.format(model_path))
    logger.info('Output path: {}'.format(output_path))
    logger.info('\n')

    utils_export_neuropod(model_path, output_path, model_name)

    logger.info('Saved to: {0}'.format(output_path))

</source>
<source file="systems/ludwig-0.4.1/ludwig/export.py" startline="87" endline="116" pcid="1048">

def export_mlflow(
        model_path,
        output_path='mlflow',
        registered_model_name=None,
        **kwargs
):
    """Exports a model to MLflow

    # Inputs

    :param model_path: (str) filepath to pre-trained model.
    :param output_path: (str, default: `'mlflow'`)  directory to store the
        mlflow model.
    :param registered_model_name: (str, default: `None`) save mlflow under this
        name in the model registry. Saved locally if `None`.

    # Return

    :returns: (`None`)
    """
    logger.info('Model path: {}'.format(model_path))
    logger.info('Output path: {}'.format(output_path))
    logger.info('\n')

    from ludwig.contribs.mlflow.model import export_model
    export_model(model_path, output_path, registered_model_name)

    logger.info('Saved to: {0}'.format(output_path))

</source>
</class>

<class classid="36" nclones="2" nlines="14" similarity="85">
<source file="systems/ludwig-0.4.1/ludwig/modules/loss_modules.py" startline="251" endline="268" pcid="1091">
def softmax_cross_entropy_with_class_weighting(
    logits, one_hot_labels, class_weights, labels_smoothing=0.0
):
    class_weights_const = tf.expand_dims(
        tf.constant(class_weights, dtype=tf.float32), 0
    )
    sample_weights = tf.reduce_sum(
        tf.multiply(one_hot_labels, class_weights_const), 1
    )
    return tf.compat.v1.losses.softmax_cross_entropy(
        onehot_labels=one_hot_labels,
        logits=logits,
        label_smoothing=labels_smoothing,
        weights=sample_weights,
        reduction=tf.losses.Reduction.NONE,
    )


</source>
<source file="systems/ludwig-0.4.1/ludwig/modules/loss_modules.py" startline="269" endline="284" pcid="1092">
def sigmoid_cross_entropy_with_class_weighting(
    logits, multi_class_labels, class_weights, labels_smoothing=0.0
):
    class_weights_const = tf.expand_dims(
        tf.constant(class_weights, dtype=tf.float32), 0
    )
    sample_weights = tf.multiply(multi_class_labels, class_weights_const)
    return tf.compat.v1.losses.sigmoid_cross_entropy(
        multi_class_labels=multi_class_labels,
        logits=logits,
        label_smoothing=labels_smoothing,
        weights=sample_weights,
        reduction=tf.losses.Reduction.NONE,
    )


</source>
</class>

<class classid="37" nclones="2" nlines="14" similarity="80">
<source file="systems/ludwig-0.4.1/ludwig/modules/loss_modules.py" startline="429" endline="446" pcid="1097">
def weighted_softmax_cross_entropy(
    logits, vector_labels, class_weights=1, labels_smoothing=0, **kwargs
):
    use_class_weights = not isinstance(class_weights, (int, float))
    if use_class_weights:
        loss = softmax_cross_entropy_with_class_weighting(
            logits, vector_labels, class_weights, labels_smoothing
        )
    else:
        loss = tf.keras.losses.categorical_crossentropy(
            y_true=vector_labels,
            y_pred=logits,
            from_logits=True,
            label_smoothing=labels_smoothing,
        )
    return loss


</source>
<source file="systems/ludwig-0.4.1/ludwig/modules/loss_modules.py" startline="447" endline="464" pcid="1098">
def weighted_sigmoid_cross_entropy(
    logits, vector_labels, class_weights=1, labels_smoothing=0, **kwargs
):
    use_class_weights = not isinstance(class_weights, (int, float))
    if use_class_weights:
        loss = sigmoid_cross_entropy_with_class_weighting(
            logits, vector_labels, class_weights, labels_smoothing
        )
    else:
        loss = tf.nn.sigmoid_cross_entropy_with_logits(
            labels=vector_labels,
            logits=logits,
            # labels_smoothing=labels_smoothing  # todo reintroduce
        )
    return loss


# used for categorical and sequence features
</source>
</class>

<class classid="38" nclones="4" nlines="33" similarity="88">
<source file="systems/ludwig-0.4.1/ludwig/modules/embedding_modules.py" startline="135" endline="171" pcid="1108">
    def __init__(
            self,
            vocab,
            embedding_size,
            representation='dense',
            embeddings_trainable=True,
            pretrained_embeddings=None,
            force_embedding_size=False,
            embeddings_on_cpu=False,
            dropout=0.0,
            embedding_initializer=None,
            embedding_regularizer=None
    ):
        super().__init__()
        self.supports_masking = True

        self.embeddings, self.embedding_size = embedding_matrix_on_device(
            vocab,
            embedding_size,
            representation=representation,
            embeddings_trainable=embeddings_trainable,
            pretrained_embeddings=pretrained_embeddings,
            force_embedding_size=force_embedding_size,
            embeddings_on_cpu=embeddings_on_cpu,
            embedding_initializer=embedding_initializer,
        )

        if embedding_regularizer:
            embedding_regularizer_obj = tf.keras.regularizers.get(
                embedding_regularizer)
            self.add_loss(lambda: embedding_regularizer_obj(self.embeddings))

        if dropout > 0:
            self.dropout = Dropout(dropout)
        else:
            self.dropout = None

</source>
<source file="systems/ludwig-0.4.1/ludwig/modules/embedding_modules.py" startline="184" endline="220" pcid="1110">
    def __init__(
            self,
            vocab,
            embedding_size,
            representation='dense',
            embeddings_trainable=True,
            pretrained_embeddings=None,
            force_embedding_size=False,
            embeddings_on_cpu=False,
            dropout=0.0,
            embedding_initializer=None,
            embedding_regularizer=None
    ):
        super().__init__()

        self.embeddings, self.embedding_size = embedding_matrix_on_device(
            vocab,
            embedding_size,
            representation=representation,
            embeddings_trainable=embeddings_trainable,
            pretrained_embeddings=pretrained_embeddings,
            force_embedding_size=force_embedding_size,
            embeddings_on_cpu=embeddings_on_cpu,
            embedding_initializer=embedding_initializer,
        )
        self.vocab_length = len(vocab)

        if embedding_regularizer:
            embedding_regularizer_obj = tf.keras.regularizers.get(
                embedding_regularizer)
            self.add_loss(lambda: embedding_regularizer_obj(self.embeddings))

        if dropout > 0:
            self.dropout = Dropout(dropout)
        else:
            self.dropout = None

</source>
<source file="systems/ludwig-0.4.1/ludwig/modules/embedding_modules.py" startline="309" endline="345" pcid="1114">
    def __init__(
            self,
            vocab,
            embedding_size,
            representation='dense',
            embeddings_trainable=True,
            pretrained_embeddings=None,
            force_embedding_size=False,
            embeddings_on_cpu=False,
            dropout=0.0,
            embedding_initializer=None,
            embedding_regularizer=None
    ):
        super().__init__()
        self.supports_masking = True

        self.embeddings, self.embedding_size = embedding_matrix_on_device(
            vocab,
            embedding_size,
            representation=representation,
            embeddings_trainable=embeddings_trainable,
            pretrained_embeddings=pretrained_embeddings,
            force_embedding_size=force_embedding_size,
            embeddings_on_cpu=embeddings_on_cpu,
            embedding_initializer=embedding_initializer,
        )

        if embedding_regularizer:
            embedding_regularizer_obj = tf.keras.regularizers.get(
                embedding_regularizer)
            self.add_loss(lambda: embedding_regularizer_obj(self.embeddings))

        if dropout > 0:
            self.dropout = Dropout(dropout)
        else:
            self.dropout = None

</source>
<source file="systems/ludwig-0.4.1/ludwig/modules/embedding_modules.py" startline="245" endline="283" pcid="1112">
    def __init__(
            self,
            vocab,
            embedding_size=50,
            representation='dense',
            embeddings_trainable=True,
            pretrained_embeddings=None,
            force_embedding_size=False,
            embeddings_on_cpu=False,
            dropout=0.0,
            embedding_initializer=None,
            embedding_regularizer=None,
            reduce_output='sum'
    ):
        super().__init__()

        self.embeddings, self.embedding_size = embedding_matrix_on_device(
            vocab,
            embedding_size,
            representation=representation,
            embeddings_trainable=embeddings_trainable,
            pretrained_embeddings=pretrained_embeddings,
            force_embedding_size=force_embedding_size,
            embeddings_on_cpu=embeddings_on_cpu,
            embedding_initializer=embedding_initializer,
        )

        if embedding_regularizer:
            embedding_regularizer_obj = tf.keras.regularizers.get(
                embedding_regularizer)
            self.add_loss(lambda: embedding_regularizer_obj(self.embeddings))

        if dropout > 0:
            self.dropout = Dropout(dropout)
        else:
            self.dropout = None

        self.reduce_output = reduce_output

</source>
</class>

</clones>
