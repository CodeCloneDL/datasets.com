<html>
<head>
    <title>NiCad6 Clone Report</title>
    <style type="text/css">
        body {font-family:sans-serif;}
        table {background-color:white; border:0px; padding:0px; border-spacing:4px; width:auto; margin-left:30px; margin-right:auto;}
        td {background-color:rgba(192,212,238,0.8); border:0px; padding:8px; width:auto; vertical-align:top; border-radius:8px}
        pre {background-color:white; padding:4px;}
        a {color:darkblue;}
    </style>
</head>
<body>
<h2>NiCad6 Clone Report</h2>
<table>
<tr style="font-size:14pt">
<td><b>System:</b> &nbsp; catalyst-22.02</td>
<td><b>Clone pairs:</b> &nbsp; 180</td>
<td><b>Clone classes:</b> &nbsp; 31</td>
</tr>
<tr style="font-size:12pt">
<td style="background-color:white">Clone type: &nbsp; 3-2</td>
<td style="background-color:white">Granularity: &nbsp; functions-blind</td>
<td style="background-color:white">Max diff threshold: &nbsp; 30%</td>
<td style="background-color:white">Clone size: &nbsp; 10 - 2500 lines</td>
<td style="background-color:white">Total functions-blind: &nbsp; 866</td>
</tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 1:</b> &nbsp; 2 fragments, nominal size 17 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag41')" href="javascript:;">
catalyst-22.02/catalyst/contrib/models/mnist.py: 10-31
</a>
<div class="mid" id="frag41" style="display:none"><pre>
    def __init__(self, out_features: int, normalize: bool = True):
        """
        Args:
            out_features: size of the output tensor
            normalize: boolean flag to add normalize layer
        """
        super().__init__()
        layers = [
            nn.Conv2d(1, 32, 3, 1),
            nn.ReLU(),
            nn.Conv2d(32, 64, 3, 1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            Flatten(),
            nn.Linear(9216, 128),
            nn.ReLU(),
            nn.Linear(128, out_features),
        ]
        if normalize:
            layers.append(Normalize())
        self._net = nn.Sequential(*layers)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag43')" href="javascript:;">
catalyst-22.02/catalyst/contrib/models/mnist.py: 46-68
</a>
<div class="mid" id="frag43" style="display:none"><pre>
    def __init__(self, out_features: int):
        """
        Args:
            out_features: size of the output tensor
        """
        super().__init__()
        layers = [
            nn.Conv2d(1, 32, 3, 1),
            nn.LeakyReLU(),
            nn.BatchNorm2d(32),
            nn.Conv2d(32, 64, 3, 1),
            nn.LeakyReLU(),
            nn.MaxPool2d(2),
            Flatten(),
            nn.BatchNorm1d(9216),
            nn.Linear(9216, 128),
            nn.LeakyReLU(),
            nn.Linear(128, out_features),
            nn.BatchNorm1d(out_features),
        ]

        self._net = nn.Sequential(*layers)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 2:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 90%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag49')" href="javascript:;">
catalyst-22.02/catalyst/contrib/data/reader_cv.py: 10-30
</a>
<div class="mid" id="frag49" style="display:none"><pre>
    def __init__(
        self,
        input_key: str,
        output_key: Optional[str] = None,
        rootpath: Optional[str] = None,
        grayscale: bool = False,
    ):
        """
        Args:
            input_key: key to use from annotation dict
            output_key: key to use to store the result,
                default: ``input_key``
            rootpath: path to images dataset root directory
                (so your can use relative paths in annotations)
            grayscale: flag if you need to work only
                with grayscale images
        """
        super().__init__(input_key, output_key or input_key)
        self.rootpath = rootpath
        self.grayscale = grayscale

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag51')" href="javascript:;">
catalyst-22.02/catalyst/contrib/data/reader_cv.py: 51-72
</a>
<div class="mid" id="frag51" style="display:none"><pre>
    def __init__(
        self,
        input_key: str,
        output_key: Optional[str] = None,
        rootpath: Optional[str] = None,
        clip_range: Tuple[Union[int, float], Union[int, float]] = (0, 1),
    ):
        """
        Args:
            input_key: key to use from annotation dict
            output_key: key to use to store the result,
                default: ``input_key``
            rootpath: path to images dataset root directory
                (so your can use relative paths in annotations)
            clip_range (Tuple[int, int]): lower and upper interval edges,
                image values outside the interval are clipped
                to the interval edges
        """
        super().__init__(input_key, output_key or input_key)
        self.rootpath = rootpath
        self.clip = clip_range

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 3:</b> &nbsp; 2 fragments, nominal size 21 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag66')" href="javascript:;">
catalyst-22.02/catalyst/contrib/utils/thresholds.py: 300-339
</a>
<div class="mid" id="frag66" style="display:none"><pre>
def get_multilabel_thresholds_greedy(
    scores: np.ndarray,
    labels: np.ndarray,
    objective: METRIC_FN,
    num_iterations: int = 100,
    num_thresholds: int = 100,
    thresholds: np.ndarray = None,
    patience: int = 3,
    atol: float = 0.01,
) -&gt; Tuple[float, List[float]]:
    """Finds best thresholds
    for multilabel classification task with brute-force algorithm.

    Args:
        scores: estimated per-class scores/probabilities predicted by the model
        labels: ground truth labels
        objective: callable function, metric which we want to maximize
        num_iterations: number of iteration for brute-force algorithm
        num_thresholds: number of thresholds ot try for each class
        thresholds: baseline thresholds, which we want to optimize
        patience: maximum number of iteration before early stop exit
        atol: minimum required improvement per iteration for early stop exit

    Returns:
        tuple with best found objective score and per-class thresholds
    """
    best_metric, thresholds = get_thresholds_greedy(
        scores=scores,
        labels=labels,
        score_fn=partial(_multilabel_score_fn, objective=objective),
        num_iterations=num_iterations,
        num_thresholds=num_thresholds,
        thresholds=thresholds,
        patience=patience,
        atol=atol,
    )

    return best_metric, thresholds


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag68')" href="javascript:;">
catalyst-22.02/catalyst/contrib/utils/thresholds.py: 347-386
</a>
<div class="mid" id="frag68" style="display:none"><pre>
def get_multiclass_thresholds_greedy(
    scores: np.ndarray,
    labels: np.ndarray,
    objective: METRIC_FN,
    num_iterations: int = 100,
    num_thresholds: int = 100,
    thresholds: np.ndarray = None,
    patience: int = 3,
    atol: float = 0.01,
) -&gt; Tuple[float, List[float]]:
    """Finds best thresholds
    for multiclass classification task with brute-force algorithm.

    Args:
        scores: estimated per-class scores/probabilities predicted by the model
        labels: ground truth labels
        objective: callable function, metric which we want to maximize
        num_iterations: number of iteration for brute-force algorithm
        num_thresholds: number of thresholds ot try for each class
        thresholds: baseline thresholds, which we want to optimize
        patience: maximum number of iteration before early stop exit
        atol: minimum required improvement per iteration for early stop exit

    Returns:
        tuple with best found objective score and per-class thresholds
    """
    best_metric, thresholds = get_thresholds_greedy(
        scores=scores,
        labels=labels,
        score_fn=partial(_multiclass_score_fn, objective=objective),
        num_iterations=num_iterations,
        num_thresholds=num_thresholds,
        thresholds=thresholds,
        patience=patience,
        atol=atol,
    )

    return best_metric, thresholds


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 4:</b> &nbsp; 2 fragments, nominal size 26 lines, similarity 92%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag69')" href="javascript:;">
catalyst-22.02/catalyst/contrib/utils/thresholds.py: 387-426
</a>
<div class="mid" id="frag69" style="display:none"><pre>
def get_best_multilabel_thresholds(
    scores: np.ndarray, labels: np.ndarray, objective: METRIC_FN
) -&gt; Tuple[float, List[float]]:
    """Finds best thresholds for multilabel classification task.

    Args:
        scores: estimated per-class scores/probabilities predicted by the model
        labels: ground truth labels
        objective: callable function, metric which we want to maximize

    Returns:
        tuple with best found objective score and per-class thresholds
    """
    num_classes = scores.shape[1]
    best_metric, best_thresholds = 0.0, []

    for baseline_thresholds_fn in [
        get_baseline_thresholds,
        get_multiclass_thresholds,
        get_binary_threshold,
        get_multilabel_thresholds,
    ]:
        _, baseline_thresholds = baseline_thresholds_fn(
            labels=labels, scores=scores, objective=objective
        )
        if isinstance(baseline_thresholds, (int, float)):
            baseline_thresholds = [baseline_thresholds] * num_classes
        metric_value, thresholds_value = get_multilabel_thresholds_greedy(
            labels=labels,
            scores=scores,
            objective=objective,
            thresholds=baseline_thresholds,
        )
        if metric_value &gt; best_metric:
            best_metric = metric_value
            best_thresholds = thresholds_value

    return best_metric, best_thresholds


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag70')" href="javascript:;">
catalyst-22.02/catalyst/contrib/utils/thresholds.py: 427-468
</a>
<div class="mid" id="frag70" style="display:none"><pre>
def get_best_multiclass_thresholds(
    scores: np.ndarray, labels: np.ndarray, objective: METRIC_FN
) -&gt; Tuple[float, List[float]]:
    """Finds best thresholds for multiclass classification task.

    Args:
        scores: estimated per-class scores/probabilities predicted by the model
        labels: ground truth labels
        objective: callable function, metric which we want to maximize

    Returns:
        tuple with best found objective score and per-class thresholds
    """
    num_classes = scores.shape[1]
    best_metric, best_thresholds = 0.0, []
    labels_onehot = np.zeros((labels.size, labels.max() + 1))
    labels_onehot[np.arange(labels.size), labels] = 1

    for baseline_thresholds_fn in [
        get_baseline_thresholds,
        get_multiclass_thresholds,
        get_binary_threshold,
        get_multilabel_thresholds,
    ]:
        _, baseline_thresholds = baseline_thresholds_fn(
            labels=labels_onehot, scores=scores, objective=objective
        )
        if isinstance(baseline_thresholds, (int, float)):
            baseline_thresholds = [baseline_thresholds] * num_classes
        metric_value, thresholds_value = get_multiclass_thresholds_greedy(
            labels=labels,
            scores=scores,
            objective=objective,
            thresholds=baseline_thresholds,
        )
        if metric_value &gt; best_metric:
            best_metric = metric_value
            best_thresholds = thresholds_value

    return best_metric, best_thresholds


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 5:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 85%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag98')" href="javascript:;">
catalyst-22.02/catalyst/contrib/datasets/movielens.py: 148-165
</a>
<div class="mid" id="frag98" style="display:none"><pre>
    def _download(self):
        """Download and extract files/"""
        if self._check_exists():
            return

        os.makedirs(self.raw_folder, exist_ok=True)
        os.makedirs(self.processed_folder, exist_ok=True)
        url = self.resources[0]
        md5 = self.resources[1]

        download_and_extract_archive(
            url=url,
            download_root=self.raw_folder,
            filename=self.filename,
            md5=md5,
            remove_finished=True,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag110')" href="javascript:;">
catalyst-22.02/catalyst/contrib/datasets/movielens.py: 528-543
</a>
<div class="mid" id="frag110" style="display:none"><pre>
    def _download(self):
        """Download and extract files"""
        if self._check_exists():
            return

        os.makedirs(self.raw_folder, exist_ok=True)
        os.makedirs(self.processed_folder, exist_ok=True)
        url = self.resources[0]

        download_and_extract_archive(
            url=url,
            download_root=self.raw_folder,
            filename=self.filename,
            remove_finished=True,
        )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 6:</b> &nbsp; 2 fragments, nominal size 22 lines, similarity 73%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag133')" href="javascript:;">
catalyst-22.02/catalyst/contrib/optimizers/adamp.py: 42-84
</a>
<div class="mid" id="frag133" style="display:none"><pre>
    def __init__(
        self,
        params,
        lr=1e-3,
        betas=(0.9, 0.999),
        eps=1e-8,
        weight_decay=0,
        delta=0.1,
        wd_ratio=0.1,
        nesterov=False,
    ):
        """

        Args:
            params: iterable of parameters to optimize
                or dicts defining parameter groups
            lr (float, optional): learning rate (default: 1e-3)
            betas (Tuple[float, float], optional): coefficients
                used for computing running averages of gradient
                and its square (default: (0.9, 0.999))
            eps (float, optional): term added to the denominator to improve
                numerical stability (default: 1e-8)
            weight_decay (float, optional): weight decay coefficient
                (default: 1e-2)
            delta: threshold that determines whether
                a set of parameters is scale invariant or not (default: 0.1)
            wd_ratio: relative weight decay applied on scale-invariant
                parameters compared to that applied on scale-variant parameters
                (default: 0.1)
            nesterov (boolean, optional): enables Nesterov momentum
                (default: False)
        """
        defaults = dict(  # noqa: C408
            lr=lr,
            betas=betas,
            eps=eps,
            weight_decay=weight_decay,
            delta=delta,
            wd_ratio=wd_ratio,
            nesterov=nesterov,
        )
        super(AdamP, self).__init__(params, defaults)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag142')" href="javascript:;">
catalyst-22.02/catalyst/contrib/optimizers/sgdp.py: 42-85
</a>
<div class="mid" id="frag142" style="display:none"><pre>
    def __init__(
        self,
        params,
        lr=required,
        momentum=0,
        weight_decay=0,
        dampening=0,
        nesterov=False,
        eps=1e-8,
        delta=0.1,
        wd_ratio=0.1,
    ):
        """

        Args:
            params: iterable of parameters to optimize
                or dicts defining parameter groups
            lr: learning rate
            momentum (float, optional): momentum factor (default: 0)
            weight_decay (float, optional): weight decay (L2 penalty)
                (default: 0)
            dampening (float, optional): dampening for momentum (default: 0)
            nesterov (bool, optional): enables Nesterov momentum
                (default: False)
            eps (float, optional): term added to the denominator to improve
                numerical stability (default: 1e-8)
            delta: threshold that determines whether
                a set of parameters is scale invariant or not (default: 0.1)
            wd_ratio: relative weight decay applied on scale-invariant
                parameters compared to that applied on scale-variant parameters
                (default: 0.1)
        """
        defaults = dict(  # noqa: C408
            lr=lr,
            momentum=momentum,
            dampening=dampening,
            weight_decay=weight_decay,
            nesterov=nesterov,
            eps=eps,
            delta=delta,
            wd_ratio=wd_ratio,
        )
        super(SGDP, self).__init__(params, defaults)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 7:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag137')" href="javascript:;">
catalyst-22.02/catalyst/contrib/optimizers/adamp.py: 97-112
</a>
<div class="mid" id="frag137" style="display:none"><pre>
    def _projection(self, p, grad, perturb, delta, wd_ratio, eps):
        wd = 1
        expand_size = [-1] + [1] * (len(p.shape) - 1)
        for view_func in [self._channel_view, self._layer_view]:

            cosine_sim = self._cosine_similarity(grad, p.data, eps, view_func)

            if cosine_sim.max() &lt; delta / math.sqrt(view_func(p.data).size(1)):
                p_n = p.data / view_func(p.data).norm(dim=1).view(expand_size).add_(eps)
                perturb -= p_n * view_func(p_n * perturb).sum(dim=1).view(expand_size)
                wd = wd_ratio

                return perturb, wd

        return perturb, wd

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag146')" href="javascript:;">
catalyst-22.02/catalyst/contrib/optimizers/sgdp.py: 98-113
</a>
<div class="mid" id="frag146" style="display:none"><pre>
    def _projection(self, p, grad, perturb, delta, wd_ratio, eps):
        wd = 1
        expand_size = [-1] + [1] * (len(p.shape) - 1)
        for view_func in [self._channel_view, self._layer_view]:

            cosine_sim = self._cosine_similarity(grad, p.data, eps, view_func)

            if cosine_sim.max() &lt; delta / math.sqrt(view_func(p.data).size(1)):
                p_n = p.data / view_func(p.data).norm(dim=1).view(expand_size).add_(eps)
                perturb -= p_n * view_func(p_n * perturb).sum(dim=1).view(expand_size)
                wd = wd_ratio

                return perturb, wd

        return perturb, wd

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 8:</b> &nbsp; 3 fragments, nominal size 19 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag170')" href="javascript:;">
catalyst-22.02/catalyst/contrib/losses/dice.py: 17-47
</a>
<div class="mid" id="frag170" style="display:none"><pre>
    def __init__(
        self,
        class_dim: int = 1,
        mode: str = "macro",
        weights: List[float] = None,
        eps: float = 1e-7,
    ):
        """
        Args:
            class_dim: indicates class dimention (K) for
                ``outputs`` and ``targets`` tensors (default = 1)
            mode: class summation strategy. Must be one of ['micro', 'macro',
                'weighted']. If mode='micro', classes are ignored, and metric
                are calculated generally. If mode='macro', metric are
                calculated per-class and than are averaged over all classes.
                If mode='weighted', metric are calculated per-class and than
                summed over all classes with weights.
            weights: class weights(for mode="weighted")
            eps: epsilon to avoid zero division
        """
        super().__init__()
        assert mode in ["micro", "macro", "weighted"]
        self.loss_fn = partial(
            dice,
            eps=eps,
            class_dim=class_dim,
            threshold=None,
            mode=mode,
            weights=weights,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag224')" href="javascript:;">
catalyst-22.02/catalyst/contrib/losses/trevsky.py: 16-54
</a>
<div class="mid" id="frag224" style="display:none"><pre>
    def __init__(
        self,
        alpha: float,
        beta: Optional[float] = None,
        class_dim: int = 1,
        mode: str = "macro",
        weights: List[float] = None,
        eps: float = 1e-7,
    ):
        """
        Args:
            alpha: false negative coefficient, bigger alpha bigger penalty for
                false negative. Must be in (0, 1)
            beta: false positive coefficient, bigger alpha bigger penalty for
                false positive. Must be in (0, 1), if None beta = (1 - alpha)
            class_dim: indicates class dimention (K) for
                ``outputs`` and ``targets`` tensors (default = 1)
            mode: class summation strategy. Must be one of ['micro', 'macro',
                'weighted']. If mode='micro', classes are ignored, and metric
                are calculated generally. If mode='macro', metric are
                calculated separately and than are averaged over all classes.
                If mode='weighted', metric are calculated separately and than
                summed over all classes with weights.
            weights: class weights(for mode="weighted")
            eps: epsilon to avoid zero division
        """
        super().__init__()
        assert mode in ["micro", "macro", "weighted"]
        self.loss_fn = partial(
            trevsky,
            eps=eps,
            alpha=alpha,
            beta=beta,
            class_dim=class_dim,
            threshold=None,
            mode=mode,
            weights=weights,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag226')" href="javascript:;">
catalyst-22.02/catalyst/contrib/losses/trevsky.py: 68-107
</a>
<div class="mid" id="frag226" style="display:none"><pre>
    def __init__(
        self,
        alpha: float,
        beta: Optional[float] = None,
        gamma: float = 4 / 3,
        class_dim: int = 1,
        mode: str = "macro",
        weights: List[float] = None,
        eps: float = 1e-7,
    ):
        """
        Args:
            alpha: false negative coefficient, bigger alpha bigger penalty for
                false negative. Must be in (0, 1)
            beta: false positive coefficient, bigger alpha bigger penalty for
                false positive. Must be in (0, 1), if None beta = (1 - alpha)
            gamma: focal coefficient. It determines how much the weight of
            simple examples is reduced.
            class_dim: indicates class dimention (K) for
                ``outputs`` and ``targets`` tensors (default = 1)
            mode: class summation strategy. Must be one of ['micro', 'macro',
                'weighted']. If mode='micro', classes are ignored, and metric
                are calculated generally. If mode='macro', metric are
                calculated separately and than are averaged over all classes.
                If mode='weighted', metric are calculated separately and than
                summed over all classes with weights.
            weights: class weights(for mode="weighted")
            eps: epsilon to avoid zero division
        """
        super().__init__()
        self.gamma = gamma
        self.trevsky_loss = TrevskyLoss(
            alpha=alpha,
            beta=beta,
            class_dim=class_dim,
            mode=mode,
            weights=weights,
            eps=eps,
        )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 9:</b> &nbsp; 4 fragments, nominal size 16 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag260')" href="javascript:;">
catalyst-22.02/catalyst/contrib/layers/amsoftmax.py: 40-57
</a>
<div class="mid" id="frag260" style="display:none"><pre>
    def __init__(  # noqa: D107
        self,
        in_features: int,
        out_features: int,
        s: float = 64.0,
        m: float = 0.5,
        eps: float = 1e-6,
    ):
        super(AMSoftmax, self).__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.s = s
        self.m = m
        self.eps = eps

        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))
        nn.init.xavier_uniform_(self.weight)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag266')" href="javascript:;">
catalyst-22.02/catalyst/contrib/layers/arcface.py: 42-60
</a>
<div class="mid" id="frag266" style="display:none"><pre>
    def __init__(  # noqa: D107
        self,
        in_features: int,
        out_features: int,
        s: float = 64.0,
        m: float = 0.5,
        eps: float = 1e-6,
    ):
        super(ArcFace, self).__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.s = s
        self.m = m
        self.threshold = math.pi - m
        self.eps = eps

        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))
        nn.init.xavier_uniform_(self.weight)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag269')" href="javascript:;">
catalyst-22.02/catalyst/contrib/layers/arcface.py: 151-173
</a>
<div class="mid" id="frag269" style="display:none"><pre>
    def __init__(  # noqa: D107
        self,
        in_features: int,
        out_features: int,
        s: float = 64.0,
        m: float = 0.5,
        k: int = 3,
        eps: float = 1e-6,
    ):
        super(SubCenterArcFace, self).__init__()
        self.in_features = in_features
        self.out_features = out_features

        self.s = s
        self.m = m
        self.k = k
        self.eps = eps

        self.weight = nn.Parameter(torch.FloatTensor(k, in_features, out_features))
        nn.init.xavier_uniform_(self.weight)

        self.threshold = math.pi - self.m

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag333')" href="javascript:;">
catalyst-22.02/catalyst/contrib/layers/cosface.py: 134-149
</a>
<div class="mid" id="frag333" style="display:none"><pre>
    def __init__(  # noqa: D107
        self,
        in_features: int,
        out_features: int,
        dynamical_s: bool = True,
        eps: float = 1e-6,
    ):
        super(AdaCos, self).__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.s = math.sqrt(2) * math.log(out_features - 1)
        self.eps = eps

        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))
        nn.init.xavier_uniform_(self.weight)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 10:</b> &nbsp; 3 fragments, nominal size 12 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag262')" href="javascript:;">
catalyst-22.02/catalyst/contrib/layers/amsoftmax.py: 71-107
</a>
<div class="mid" id="frag262" style="display:none"><pre>
    def forward(
        self, input: torch.Tensor, target: torch.LongTensor = None
    ) -&gt; torch.Tensor:
        """
        Args:
            input: input features,
                expected shapes ``BxF`` where ``B``
                is batch dimension and ``F`` is an
                input feature dimension.
            target: target classes,
                expected shapes ``B`` where
                ``B`` is batch dimension.
                If `None` then will be returned
                projection on centroids.
                Default is `None`.

        Returns:
            tensor (logits) with shapes ``BxC``
            where ``C`` is a number of classes
            (out_features).
        """
        cos_theta = F.linear(F.normalize(input), F.normalize(self.weight))

        if target is None:
            return cos_theta

        cos_theta = torch.clamp(cos_theta, -1.0 + self.eps, 1.0 - self.eps)

        one_hot = torch.zeros_like(cos_theta)
        one_hot.scatter_(1, target.view(-1, 1).long(), 1)

        logits = torch.where(one_hot.bool(), cos_theta - self.m, cos_theta)
        logits *= self.s

        return logits


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag332')" href="javascript:;">
catalyst-22.02/catalyst/contrib/layers/cosface.py: 64-99
</a>
<div class="mid" id="frag332" style="display:none"><pre>
    def forward(
        self, input: torch.Tensor, target: torch.LongTensor = None
    ) -&gt; torch.Tensor:
        """
        Args:
            input: input features,
                expected shapes ``BxF`` where ``B``
                is batch dimension and ``F`` is an
                input feature dimension.
            target: target classes,
                expected shapes ``B`` where
                ``B`` is batch dimension.
                If `None` then will be returned
                projection on centroids.
                Default is `None`.

        Returns:
            tensor (logits) with shapes ``BxC``
            where ``C`` is a number of classes
            (out_features).
        """
        cosine = F.linear(F.normalize(input), F.normalize(self.weight))
        phi = cosine - self.m

        if target is None:
            return cosine

        one_hot = torch.zeros_like(cosine)
        one_hot.scatter_(1, target.view(-1, 1).long(), 1)

        logits = (one_hot * phi) + ((1.0 - one_hot) * cosine)
        logits *= self.s

        return logits


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag268')" href="javascript:;">
catalyst-22.02/catalyst/contrib/layers/arcface.py: 74-112
</a>
<div class="mid" id="frag268" style="display:none"><pre>
    def forward(
        self, input: torch.Tensor, target: torch.LongTensor = None
    ) -&gt; torch.Tensor:
        """
        Args:
            input: input features,
                expected shapes ``BxF`` where ``B``
                is batch dimension and ``F`` is an
                input feature dimension.
            target: target classes,
                expected shapes ``B`` where
                ``B`` is batch dimension.
                If `None` then will be returned
                projection on centroids.
                Default is `None`.

        Returns:
            tensor (logits) with shapes ``BxC``
            where ``C`` is a number of classes
            (out_features).
        """
        cos_theta = F.linear(F.normalize(input), F.normalize(self.weight))

        if target is None:
            return cos_theta

        theta = torch.acos(torch.clamp(cos_theta, -1.0 + self.eps, 1.0 - self.eps))

        one_hot = torch.zeros_like(cos_theta)
        one_hot.scatter_(1, target.view(-1, 1).long(), 1)

        mask = torch.where(theta &gt; self.threshold, torch.zeros_like(one_hot), one_hot)

        logits = torch.cos(torch.where(mask.bool(), theta + self.m, theta))
        logits *= self.s

        return logits


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 11:</b> &nbsp; 22 fragments, nominal size 19 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag386')" href="javascript:;">
catalyst-22.02/catalyst/callbacks/criterion.py: 23-45
</a>
<div class="mid" id="frag386" style="display:none"><pre>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        metric_key: str,
        criterion_key: str = None,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            input_key=input_key,
            target_key=target_key,
            metric_fn=self._metric_fn,
            metric_key=metric_key,
            compute_on_call=True,
            log_on_batch=True,
            prefix=prefix,
            suffix=suffix,
        )
        self.criterion_key = criterion_key
        self.criterion = None

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag397')" href="javascript:;">
catalyst-22.02/catalyst/callbacks/metrics/accuracy.py: 94-117
</a>
<div class="mid" id="frag397" style="display:none"><pre>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        num_classes: int = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=AccuracyMetric(
                topk=topk,
                num_classes=num_classes,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag390')" href="javascript:;">
catalyst-22.02/catalyst/callbacks/metrics/functional_metric.py: 23-48
</a>
<div class="mid" id="frag390" style="display:none"><pre>
    def __init__(
        self,
        input_key: Union[str, Iterable[str], Dict[str, str]],
        target_key: Union[str, Iterable[str], Dict[str, str]],
        metric_fn: Callable,
        metric_key: str,
        compute_on_call: bool = True,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=FunctionalBatchMetric(
                metric_fn=metric_fn,
                metric_key=metric_key,
                compute_on_call=compute_on_call,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag392')" href="javascript:;">
catalyst-22.02/catalyst/callbacks/metrics/classification.py: 193-218
</a>
<div class="mid" id="frag392" style="display:none"><pre>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        num_classes: Optional[int] = None,
        zero_division: int = 0,
        log_on_batch: bool = True,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MultilabelPrecisionRecallF1SupportMetric(
                zero_division=zero_division,
                prefix=prefix,
                suffix=suffix,
                compute_per_class_metrics=compute_per_class_metrics,
                num_classes=num_classes,
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag395')" href="javascript:;">
catalyst-22.02/catalyst/callbacks/metrics/cmc_score.py: 201-225
</a>
<div class="mid" id="frag395" style="display:none"><pre>
    def __init__(
        self,
        embeddings_key: str,
        pids_key: str,
        cids_key: str,
        is_query_key: str,
        topk: Iterable[int] = None,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=ReidCMCMetric(
                embeddings_key=embeddings_key,
                pids_key=pids_key,
                cids_key=cids_key,
                is_query_key=is_query_key,
                topk=topk,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=[embeddings_key, is_query_key],
            target_key=[pids_key, cids_key],
        )

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag393')" href="javascript:;">
catalyst-22.02/catalyst/callbacks/metrics/cmc_score.py: 151-173
</a>
<div class="mid" id="frag393" style="display:none"><pre>
    def __init__(
        self,
        embeddings_key: str,
        labels_key: str,
        is_query_key: str,
        topk: Iterable[int] = None,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=CMCMetric(
                embeddings_key=embeddings_key,
                labels_key=labels_key,
                is_query_key=is_query_key,
                topk=topk,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=[embeddings_key, is_query_key],
            target_key=[labels_key],
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag391')" href="javascript:;">
catalyst-22.02/catalyst/callbacks/metrics/classification.py: 86-111
</a>
<div class="mid" id="frag391" style="display:none"><pre>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        num_classes: Optional[int] = None,
        zero_division: int = 0,
        log_on_batch: bool = True,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MulticlassPrecisionRecallF1SupportMetric(
                zero_division=zero_division,
                prefix=prefix,
                suffix=suffix,
                compute_per_class_metrics=compute_per_class_metrics,
                num_classes=num_classes,
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag405')" href="javascript:;">
catalyst-22.02/catalyst/callbacks/metrics/segmentation.py: 96-125
</a>
<div class="mid" id="frag405" style="display:none"><pre>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        class_dim: int = 1,
        weights: Optional[List[float]] = None,
        class_names: Optional[List[str]] = None,
        threshold: Optional[float] = None,
        log_on_batch: bool = True,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=IOUMetric(
                class_dim=class_dim,
                weights=weights,
                class_names=class_names,
                threshold=threshold,
                compute_per_class_metrics=compute_per_class_metrics,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag403')" href="javascript:;">
catalyst-22.02/catalyst/callbacks/metrics/auc.py: 82-100
</a>
<div class="mid" id="frag403" style="display:none"><pre>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=AUCMetric(
                compute_per_class_metrics=compute_per_class_metrics,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=input_key,
            target_key=target_key,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag406')" href="javascript:;">
catalyst-22.02/catalyst/callbacks/metrics/segmentation.py: 214-243
</a>
<div class="mid" id="frag406" style="display:none"><pre>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        class_dim: int = 1,
        weights: Optional[List[float]] = None,
        class_names: Optional[List[str]] = None,
        threshold: Optional[float] = None,
        log_on_batch: bool = True,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=DiceMetric(
                class_dim=class_dim,
                weights=weights,
                class_names=class_names,
                threshold=threshold,
                compute_per_class_metrics=compute_per_class_metrics,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag407')" href="javascript:;">
catalyst-22.02/catalyst/callbacks/metrics/segmentation.py: 334-367
</a>
<div class="mid" id="frag407" style="display:none"><pre>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        alpha: float,
        beta: Optional[float] = None,
        class_dim: int = 1,
        weights: Optional[List[float]] = None,
        class_names: Optional[List[str]] = None,
        threshold: Optional[float] = None,
        log_on_batch: bool = True,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=TrevskyMetric(
                alpha=alpha,
                beta=beta,
                class_dim=class_dim,
                weights=weights,
                class_names=class_names,
                threshold=threshold,
                compute_per_class_metrics=compute_per_class_metrics,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag538')" href="javascript:;">
catalyst-22.02/catalyst/metrics/_ndcg.py: 138-155
</a>
<div class="mid" id="frag538" style="display:none"><pre>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init NDCGMetric"""
        super().__init__(
            metric_name="ndcg",
            metric_function=ndcg,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag399')" href="javascript:;">
catalyst-22.02/catalyst/callbacks/metrics/recsys.py: 102-119
</a>
<div class="mid" id="frag399" style="display:none"><pre>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=HitrateMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag398')" href="javascript:;">
catalyst-22.02/catalyst/callbacks/metrics/accuracy.py: 186-205
</a>
<div class="mid" id="frag398" style="display:none"><pre>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        threshold: Union[float, torch.Tensor] = 0.5,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MultilabelAccuracyMetric(
                threshold=threshold, prefix=prefix, suffix=suffix
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag537')" href="javascript:;">
catalyst-22.02/catalyst/metrics/_map.py: 146-163
</a>
<div class="mid" id="frag537" style="display:none"><pre>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MAPMetric"""
        super().__init__(
            metric_name="map",
            metric_function=mean_average_precision,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag400')" href="javascript:;">
catalyst-22.02/catalyst/callbacks/metrics/recsys.py: 213-230
</a>
<div class="mid" id="frag400" style="display:none"><pre>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MAPMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag523')" href="javascript:;">
catalyst-22.02/catalyst/metrics/_hitrate.py: 134-151
</a>
<div class="mid" id="frag523" style="display:none"><pre>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init HitrateMetric"""
        super().__init__(
            metric_name="hitrate",
            metric_function=hitrate,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag524')" href="javascript:;">
catalyst-22.02/catalyst/metrics/_mrr.py: 132-149
</a>
<div class="mid" id="frag524" style="display:none"><pre>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MRRMetric"""
        super().__init__(
            metric_name="mrr",
            metric_function=mrr,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag402')" href="javascript:;">
catalyst-22.02/catalyst/callbacks/metrics/recsys.py: 435-452
</a>
<div class="mid" id="frag402" style="display:none"><pre>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag401')" href="javascript:;">
catalyst-22.02/catalyst/callbacks/metrics/recsys.py: 324-341
</a>
<div class="mid" id="frag401" style="display:none"><pre>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MRRMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag595')" href="javascript:;">
catalyst-22.02/catalyst/metrics/_accuracy.py: 136-155
</a>
<div class="mid" id="frag595" style="display:none"><pre>
    def __init__(
        self,
        topk: Iterable[int] = None,
        num_classes: int = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init AccuracyMetric"""
        self.topk = topk or get_default_topk(num_classes)
        super().__init__(
            metric_name="accuracy",
            metric_function=accuracy,
            topk=self.topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag389')" href="javascript:;">
catalyst-22.02/catalyst/callbacks/metrics/r2_squared.py: 60-74
</a>
<div class="mid" id="frag389" style="display:none"><pre>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=R2Squared(prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
        )


</pre></div>
</td>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 12:</b> &nbsp; 2 fragments, nominal size 17 lines, similarity 82%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag408')" href="javascript:;">
catalyst-22.02/catalyst/callbacks/metrics/scikit_learn.py: 110-129
</a>
<div class="mid" id="frag408" style="display:none"><pre>
    def __init__(
        self,
        keys: Mapping[str, Any],
        metric_fn: Union[Callable, str],
        metric_key: str,
        log_on_batch: bool = True,
        **metric_kwargs
    ):
        """Init."""
        if isinstance(metric_fn, str):
            metric_fn = sklearn.metrics.__dict__[metric_fn]
        metric_fn = partial(metric_fn, **metric_kwargs)

        super().__init__(
            metric=FunctionalBatchMetric(metric_fn=metric_fn, metric_key=metric_key),
            input_key=keys,
            target_key=keys,
            log_on_batch=log_on_batch,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag410')" href="javascript:;">
catalyst-22.02/catalyst/callbacks/metrics/scikit_learn.py: 239-258
</a>
<div class="mid" id="frag410" style="display:none"><pre>
    def __init__(
        self,
        keys: Mapping[str, Any],
        metric_fn: Union[Callable, str],
        metric_key: str,
        **metric_kwargs
    ):
        """Init."""
        if isinstance(metric_fn, str):
            metric_fn = sklearn.metrics.__dict__[metric_fn]
        metric_fn = partial(metric_fn, **metric_kwargs)

        super().__init__(
            metric=FunctionalLoaderMetric(
                metric_fn=metric_fn, metric_key=metric_key, accumulative_fields=keys
            ),
            input_key=keys,
            target_key=keys,
        )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 13:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 78%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag539')" href="javascript:;">
catalyst-22.02/catalyst/metrics/_functional_metric.py: 55-68
</a>
<div class="mid" id="frag539" style="display:none"><pre>
    def __init__(
        self,
        metric_fn: Callable,
        metric_key: str,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init"""
        super().__init__(compute_on_call=compute_on_call, prefix=prefix, suffix=suffix)
        self.metric_fn = metric_fn
        self.metric_name = f"{self.prefix}{metric_key}{self.suffix}"
        self.additive_metric = AdditiveMetric()

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag545')" href="javascript:;">
catalyst-22.02/catalyst/metrics/_functional_metric.py: 177-193
</a>
<div class="mid" id="frag545" style="display:none"><pre>
    def __init__(
        self,
        metric_fn: Callable,
        metric_key: str,
        accumulative_fields: Iterable[str] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init"""
        super().__init__(compute_on_call=compute_on_call, prefix=prefix, suffix=suffix)
        self.metric_fn = metric_fn
        self.metric_name = f"{self.prefix}{metric_key}{self.suffix}"
        self.accumulative_metric = AccumulativeMetric(
            keys=accumulative_fields, compute_on_call=compute_on_call
        )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 14:</b> &nbsp; 3 fragments, nominal size 22 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag562')" href="javascript:;">
catalyst-22.02/catalyst/metrics/functional/_segmentation.py: 174-270
</a>
<div class="mid" id="frag562" style="display:none"><pre>
def iou(
    outputs: torch.Tensor,
    targets: torch.Tensor,
    class_dim: int = 1,
    threshold: float = None,
    mode: str = "per-class",
    weights: Optional[List[float]] = None,
    eps: float = 1e-7,
) -&gt; torch.Tensor:
    """
    Computes the iou/jaccard score,
    iou score = intersection / union = tp / (tp + fp + fn)

    Args:
        outputs: [N; K; ...] tensor that for each of the N examples
            indicates the probability of the example belonging to each of
            the K classes, according to the model.
        targets:  binary [N; K; ...] tensor that encodes which of the K
            classes are associated with the N-th input
        class_dim: indicates class dimention (K) for
            ``outputs`` and ``targets`` tensors (default = 1), if
            mode = "micro" means nothing
        threshold: threshold for outputs binarization
        mode: class summation strategy. Must be one of ['micro', 'macro',
            'weighted', 'per-class']. If mode='micro', classes are ignored,
            and metric are calculated generally. If mode='macro', metric are
            calculated per-class and than are averaged over all classes. If
            mode='weighted', metric are calculated per-class and than summed
            over all classes with weights. If mode='per-class', metric are
            calculated separately for all classes
        weights: class weights(for mode="weighted")
        eps: epsilon to avoid zero division

    Returns:
        IoU (Jaccard) score for each class(if mode='weighted') or aggregated IOU

    Example:

    .. code-block:: python

        import torch
        from catalyst import metrics

        size = 4
        half_size = size // 2
        shape = (1, 1, size, size)
        empty = torch.zeros(shape)
        full = torch.ones(shape)
        left = torch.ones(shape)
        left[:, :, :, half_size:] = 0
        right = torch.ones(shape)
        right[:, :, :, :half_size] = 0
        top_left = torch.zeros(shape)
        top_left[:, :, :half_size, :half_size] = 1
        pred = torch.cat([empty, left, empty, full, left, top_left], dim=1)
        targets = torch.cat([full, right, empty, full, left, left], dim=1)

        metrics.iou(
            outputs=pred,
            targets=targets,
            class_dim=1,
            threshold=0.5,
            mode="per-class"
        )
        # tensor([0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.5])

        metrics.iou(
            outputs=pred,
            targets=targets,
            class_dim=1,
            threshold=0.5,
            mode="macro"
        )
        # tensor(0.5833)

        metrics.iou(
            outputs=pred,
            targets=targets,
            class_dim=1,
            threshold=0.5,
            mode="micro"
        )
        # tensor(0.4375)
    """
    metric_fn = partial(_iou, eps=eps)
    score = _get_region_based_metrics(
        outputs=outputs,
        targets=targets,
        metric_fn=metric_fn,
        class_dim=class_dim,
        threshold=threshold,
        mode=mode,
        weights=weights,
    )
    return score


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag564')" href="javascript:;">
catalyst-22.02/catalyst/metrics/functional/_segmentation.py: 369-477
</a>
<div class="mid" id="frag564" style="display:none"><pre>
def trevsky(
    outputs: torch.Tensor,
    targets: torch.Tensor,
    alpha: float,
    beta: Optional[float] = None,
    class_dim: int = 1,
    threshold: float = None,
    mode: str = "per-class",
    weights: Optional[List[float]] = None,
    eps: float = 1e-7,
) -&gt; torch.Tensor:
    """
    Computes the trevsky score,
    trevsky score = tp / (tp + fp * beta + fn * alpha)

    Args:
        outputs: [N; K; ...] tensor that for each of the N examples
            indicates the probability of the example belonging to each of
            the K classes, according to the model.
        targets:  binary [N; K; ...] tensor that encodes which of the K
            classes are associated with the N-th input
        alpha: false negative coefficient, bigger alpha bigger penalty for
            false negative. Must be in (0, 1)
        beta: false positive coefficient, bigger alpha bigger penalty for false
            positive. Must be in (0, 1), if None beta = (1 - alpha)
        class_dim: indicates class dimention (K) for
            ``outputs`` and ``targets`` tensors (default = 1)
        threshold: threshold for outputs binarization
        mode: class summation strategy. Must be one of ['micro', 'macro',
            'weighted', 'per-class']. If mode='micro', classes are ignored,
            and metric are calculated generally. If mode='macro', metric are
            calculated per-class and than are averaged over all classes. If
            mode='weighted', metric are calculated per-class and than summed
            over all classes with weights. If mode='per-class', metric are
            calculated separately for all classes
        weights: class weights(for mode="weighted")
        eps: epsilon to avoid zero division

    Returns:
        Trevsky score for each class(if mode='weighted') or aggregated score

    Example:

    .. code-block:: python

        import torch
        from catalyst import metrics

        size = 4
        half_size = size // 2
        shape = (1, 1, size, size)
        empty = torch.zeros(shape)
        full = torch.ones(shape)
        left = torch.ones(shape)
        left[:, :, :, half_size:] = 0
        right = torch.ones(shape)
        right[:, :, :, :half_size] = 0
        top_left = torch.zeros(shape)
        top_left[:, :, :half_size, :half_size] = 1
        pred = torch.cat([empty, left, empty, full, left, top_left], dim=1)
        targets = torch.cat([full, right, empty, full, left, left], dim=1)

        metrics.trevsky(
            outputs=pred,
            targets=targets,
            alpha=0.2,
            class_dim=1,
            threshold=0.5,
            mode="per-class"
        )
        # tensor([0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.8333])

        metrics.trevsky(
            outputs=pred,
            targets=targets,
            alpha=0.2,
            class_dim=1,
            threshold=0.5,
            mode="macro"
        )
        # tensor(0.6389)

        metrics.trevsky(
            outputs=pred,
            targets=targets,
            alpha=0.2,
            class_dim=1,
            threshold=0.5,
            mode="micro"
        )
        # tensor(0.7000)
    """
    # assert 0 &lt; alpha &lt; 1  # I am not sure about this
    if beta is None:
        assert 0 &lt; alpha &lt; 1, "if beta=None, alpha must be in (0, 1)"
        beta = 1 - alpha
    metric_fn = partial(_trevsky, alpha=alpha, beta=beta, eps=eps)
    score = _get_region_based_metrics(
        outputs=outputs,
        targets=targets,
        metric_fn=metric_fn,
        class_dim=class_dim,
        threshold=threshold,
        mode=mode,
        weights=weights,
    )
    return score


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag563')" href="javascript:;">
catalyst-22.02/catalyst/metrics/functional/_segmentation.py: 271-368
</a>
<div class="mid" id="frag563" style="display:none"><pre>
def dice(
    outputs: torch.Tensor,
    targets: torch.Tensor,
    class_dim: int = 1,
    threshold: float = None,
    mode: str = "per-class",
    weights: Optional[List[float]] = None,
    eps: float = 1e-7,
) -&gt; torch.Tensor:
    """
    Computes the dice score,
    dice score = 2 * intersection / (intersection + union)) = \
    = 2 * tp / (2 * tp + fp + fn)

    Args:
        outputs: [N; K; ...] tensor that for each of the N examples
            indicates the probability of the example belonging to each of
            the K classes, according to the model.
        targets:  binary [N; K; ...] tensor that encodes which of the K
            classes are associated with the N-th input
        class_dim: indicates class dimention (K) for
            ``outputs`` and ``targets`` tensors (default = 1), if
            mode = "micro" means nothing
        threshold: threshold for outputs binarization
        mode: class summation strategy. Must be one of ['micro', 'macro',
            'weighted', 'per-class']. If mode='micro', classes are ignored,
            and metric are calculated generally. If mode='macro', metric are
            calculated per-class and than are averaged over all classes. If
            mode='weighted', metric are calculated per-class and than summed
            over all classes with weights. If mode='per-class', metric are
            calculated separately for all classes
        weights: class weights(for mode="weighted")
        eps: epsilon to avoid zero division

    Returns:
        Dice score for each class(if mode='weighted') or aggregated Dice

    Example:

    .. code-block:: python

        import torch
        from catalyst import metrics

        size = 4
        half_size = size // 2
        shape = (1, 1, size, size)
        empty = torch.zeros(shape)
        full = torch.ones(shape)
        left = torch.ones(shape)
        left[:, :, :, half_size:] = 0
        right = torch.ones(shape)
        right[:, :, :, :half_size] = 0
        top_left = torch.zeros(shape)
        top_left[:, :, :half_size, :half_size] = 1
        pred = torch.cat([empty, left, empty, full, left, top_left], dim=1)
        targets = torch.cat([full, right, empty, full, left, left], dim=1)

        metrics.dice(
            outputs=pred,
            targets=targets,
            class_dim=1,
            threshold=0.5,
            mode="per-class"
        )
        # tensor([0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.6667])

        metrics.dice(
            outputs=pred,
            targets=targets,
            class_dim=1,
            threshold=0.5,
            mode="macro"
        )
        # tensor(0.6111)

        metrics.dice(
            outputs=pred,
            targets=targets,
            class_dim=1,
            threshold=0.5,
            mode="micro"
        )
        # tensor(0.6087)
    """
    metric_fn = partial(_dice, eps=eps)
    score = _get_region_based_metrics(
        outputs=outputs,
        targets=targets,
        metric_fn=metric_fn,
        class_dim=class_dim,
        threshold=threshold,
        mode=mode,
        weights=weights,
    )
    return score


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 15:</b> &nbsp; 2 fragments, nominal size 20 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag571')" href="javascript:;">
catalyst-22.02/catalyst/metrics/functional/_focal.py: 5-53
</a>
<div class="mid" id="frag571" style="display:none"><pre>
def sigmoid_focal_loss(
    outputs: torch.Tensor,
    targets: torch.Tensor,
    gamma: float = 2.0,
    alpha: float = 0.25,
    reduction: str = "mean",
):
    """
    Compute binary focal loss between target and output logits.

    Args:
        outputs: tensor of arbitrary shape
        targets: tensor of the same shape as input
        gamma: gamma for focal loss
        alpha: alpha for focal loss
        reduction (string, optional):
            specifies the reduction to apply to the output:
            ``"none"`` | ``"mean"`` | ``"sum"`` | ``"batchwise_mean"``.
            ``"none"``: no reduction will be applied,
            ``"mean"``: the sum of the output will be divided by the number of
            elements in the output,
            ``"sum"``: the output will be summed.

    Returns:
        computed loss

    Source: https://github.com/BloodAxe/pytorch-toolbelt
    """
    targets = targets.type(outputs.type())

    logpt = -F.binary_cross_entropy_with_logits(outputs, targets, reduction="none")
    pt = torch.exp(logpt)

    # compute the loss
    loss = -((1 - pt).pow(gamma)) * logpt

    if alpha is not None:
        loss = loss * (alpha * targets + (1 - alpha) * (1 - targets))

    if reduction == "mean":
        loss = loss.mean()
    if reduction == "sum":
        loss = loss.sum()
    if reduction == "batchwise_mean":
        loss = loss.sum(0)

    return loss


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag572')" href="javascript:;">
catalyst-22.02/catalyst/metrics/functional/_focal.py: 54-113
</a>
<div class="mid" id="frag572" style="display:none"><pre>
def reduced_focal_loss(
    outputs: torch.Tensor,
    targets: torch.Tensor,
    threshold: float = 0.5,
    gamma: float = 2.0,
    reduction="mean",
) -&gt; torch.Tensor:
    """Compute reduced focal loss between target and output logits.

    It has been proposed in `Reduced Focal Loss\: 1st Place Solution to xView
    object detection in Satellite Imagery`_ paper.

    .. note::
        ``size_average`` and ``reduce`` params are in the process of being
        deprecated, and in the meantime, specifying either of those two args
        will override ``reduction``.

    Source: https://github.com/BloodAxe/pytorch-toolbelt

    .. _Reduced Focal Loss\: 1st Place Solution to xView object detection
        in Satellite Imagery: https://arxiv.org/abs/1903.01347

    Args:
        outputs: tensor of arbitrary shape
        targets: tensor of the same shape as input
        threshold: threshold for focal reduction
        gamma: gamma for focal reduction
        reduction: specifies the reduction to apply to the output:
            ``"none"`` | ``"mean"`` | ``"sum"`` | ``"batchwise_mean"``.
            ``"none"``: no reduction will be applied,
            ``"mean"``: the sum of the output will be divided by the number of
            elements in the output,
            ``"sum"``: the output will be summed.
            ``"batchwise_mean"`` computes mean loss per sample in batch.
            Default: "mean"

    Returns:  # noqa: DAR201
        torch.Tensor: computed loss
    """
    targets = targets.type(outputs.type())

    logpt = -F.binary_cross_entropy_with_logits(outputs, targets, reduction="none")
    pt = torch.exp(logpt)

    # compute the loss
    focal_reduction = ((1.0 - pt) / threshold).pow(gamma)
    focal_reduction[pt &lt; threshold] = 1

    loss = -focal_reduction * logpt

    if reduction == "mean":
        loss = loss.mean()
    if reduction == "sum":
        loss = loss.sum()
    if reduction == "batchwise_mean":
        loss = loss.sum(0)

    return loss


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 16:</b> &nbsp; 4 fragments, nominal size 16 lines, similarity 73%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag573')" href="javascript:;">
catalyst-22.02/catalyst/metrics/functional/_precision.py: 8-67
</a>
<div class="mid" id="frag573" style="display:none"><pre>
def precision(
    outputs: torch.Tensor,
    targets: torch.Tensor,
    argmax_dim: int = -1,
    eps: float = 1e-7,
    num_classes: Optional[int] = None,
) -&gt; Union[float, torch.Tensor]:
    """
    Multiclass precision score.

    Args:
        outputs: estimated targets as predicted by a model
            with shape [bs; ..., (num_classes or 1)]
        targets: ground truth (correct) target values
            with shape [bs; ..., 1]
        argmax_dim: int, that specifies dimension for argmax transformation
            in case of scores/probabilities in ``outputs``
        eps: float. Epsilon to avoid zero division.
        num_classes: int, that specifies number of classes if it known

    Returns:
        Tensor: precision for every class

    Examples:

    .. code-block:: python

        import torch
        from catalyst import metrics
        metrics.precision(
            outputs=torch.tensor([
                [1, 0, 0],
                [0, 1, 0],
                [0, 0, 1],
            ]),
            targets=torch.tensor([0, 1, 2]),
        )
        # tensor([1., 1., 1.])


    .. code-block:: python

        import torch
        from catalyst import metrics
        metrics.precision(
            outputs=torch.tensor([[0, 0, 1, 1, 0, 1, 0, 1]]),
            targets=torch.tensor([[0, 1, 0, 1, 0, 0, 1, 1]]),
        )
        # tensor([0.5000, 0.5000]
    """
    precision_score, _, _, _, = precision_recall_fbeta_support(
        outputs=outputs,
        targets=targets,
        argmax_dim=argmax_dim,
        eps=eps,
        num_classes=num_classes,
    )
    return precision_score


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag588')" href="javascript:;">
catalyst-22.02/catalyst/metrics/functional/_f1_score.py: 64-111
</a>
<div class="mid" id="frag588" style="display:none"><pre>
def f1_score(
    outputs: torch.Tensor,
    targets: torch.Tensor,
    eps: float = 1e-7,
    argmax_dim: int = -1,
    num_classes: Optional[int] = None,
) -&gt; Union[float, torch.Tensor]:
    """Fbeta_score with beta=1.

    Args:
        outputs: A list of predicted elements
        targets:  A list of elements that are to be predicted
        eps: epsilon to avoid zero division
        argmax_dim: int, that specifies dimension for argmax transformation
            in case of scores/probabilities in ``outputs``
        num_classes: int, that specifies number of classes if it known

    Returns:
        float: F_1 score

    Example:

    .. code-block:: python

        import torch
        from catalyst import metrics
        metrics.f1_score(
            outputs=torch.tensor([
                [1, 0, 0],
                [0, 1, 0],
                [0, 0, 1],
            ]),
            targets=torch.tensor([0, 1, 2]),
        )
        # tensor([1., 1., 1.]),  # per class fbeta
    """
    score = fbeta_score(
        outputs=outputs,
        targets=targets,
        beta=1,
        eps=eps,
        argmax_dim=argmax_dim,
        num_classes=num_classes,
    )

    return score


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag589')" href="javascript:;">
catalyst-22.02/catalyst/metrics/functional/_recall.py: 8-68
</a>
<div class="mid" id="frag589" style="display:none"><pre>
def recall(
    outputs: torch.Tensor,
    targets: torch.Tensor,
    argmax_dim: int = -1,
    eps: float = 1e-7,
    num_classes: Optional[int] = None,
) -&gt; Union[float, torch.Tensor]:
    """
    Multiclass recall score.

    Args:
        outputs: estimated targets as predicted by a model
            with shape [bs; ..., (num_classes or 1)]
        targets: ground truth (correct) target values
            with shape [bs; ..., 1]
        argmax_dim: int, that specifies dimension for argmax transformation
            in case of scores/probabilities in ``outputs``
        eps: float. Epsilon to avoid zero division.
        num_classes: int, that specifies number of classes if it known

    Returns:
        Tensor: recall for every class

    Examples:

    .. code-block:: python

        import torch
        from catalyst import metrics
        metrics.recall(
            outputs=torch.tensor([
                [1, 0, 0],
                [0, 1, 0],
                [0, 0, 1],
            ]),
            targets=torch.tensor([0, 1, 2]),
        )
        # tensor([1., 1., 1.])


    .. code-block:: python

        import torch
        from catalyst import metrics
        metrics.recall(
            outputs=torch.tensor([[0, 0, 1, 1, 0, 1, 0, 1]]),
            targets=torch.tensor([[0, 1, 0, 1, 0, 0, 1, 1]]),
        )
        # tensor([0.5000, 0.5000]
    """
    _, recall_score, _, _ = precision_recall_fbeta_support(
        outputs=outputs,
        targets=targets,
        argmax_dim=argmax_dim,
        eps=eps,
        num_classes=num_classes,
    )

    return recall_score


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag587')" href="javascript:;">
catalyst-22.02/catalyst/metrics/functional/_f1_score.py: 8-63
</a>
<div class="mid" id="frag587" style="display:none"><pre>
def fbeta_score(
    outputs: torch.Tensor,
    targets: torch.Tensor,
    beta: float = 1.0,
    eps: float = 1e-7,
    argmax_dim: int = -1,
    num_classes: Optional[int] = None,
) -&gt; Union[float, torch.Tensor]:
    """Counts fbeta score for given ``outputs`` and ``targets``.

    Args:
        outputs: A list of predicted elements
        targets:  A list of elements that are to be predicted
        beta: beta param for f_score
        eps: epsilon to avoid zero division
        argmax_dim: int, that specifies dimension for argmax transformation
            in case of scores/probabilities in ``outputs``
        num_classes: int, that specifies number of classes if it known

    Raises:
        ValueError: If ``beta`` is a negative number.

    Returns:
        float: F_beta score.

    Example:

    .. code-block:: python

        import torch
        from catalyst import metrics
        metrics.fbeta_score(
            outputs=torch.tensor([
                [1, 0, 0],
                [0, 1, 0],
                [0, 0, 1],
            ]),
            targets=torch.tensor([0, 1, 2]),
            beta=1,
        )
        # tensor([1., 1., 1.]),  # per class fbeta
    """
    if beta &lt; 0:
        raise ValueError("beta parameter should be non-negative")

    _p, _r, fbeta, _ = precision_recall_fbeta_support(
        outputs=outputs,
        targets=targets,
        beta=beta,
        eps=eps,
        argmax_dim=argmax_dim,
        num_classes=num_classes,
    )
    return fbeta


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 17:</b> &nbsp; 2 fragments, nominal size 15 lines, similarity 93%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag614')" href="javascript:;">
catalyst-22.02/tests/contrib/datasets/test_movielens_20m.py: 30-66
</a>
<div class="mid" id="frag614" style="display:none"><pre>
def test_download_split_by_user():
    """
    Test movielense download
    """
    MovieLens20M(MOVIELENS20M_ROOT, download=True, sample=True)

    filename = "ml-20m"

    # check if data folder exists
    assert os.path.isdir(MOVIELENS20M_ROOT) is True

    # cehck if class folder exists
    assert os.path.isdir(f"{MOVIELENS20M_ROOT}/MovieLens20M") is True

    # check if raw folder exists
    assert os.path.isdir(f"{MOVIELENS20M_ROOT}/MovieLens20M/raw") is True

    # check if processed folder exists
    assert os.path.isdir(f"{MOVIELENS20M_ROOT}/MovieLens20M/processed") is True

    # check some random file from MovieLens
    assert (
        os.path.isfile(
            f"{MOVIELENS20M_ROOT}/MovieLens20M/raw/{filename}/genome-scores.csv"
        )
        is True
    )

    # check if data file is not Nulll
    assert (
        os.path.getsize(
            f"{MOVIELENS20M_ROOT}/MovieLens20M/raw/{filename}/genome-scores.csv"
        )
        &gt; 0
    )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag615')" href="javascript:;">
catalyst-22.02/tests/contrib/datasets/test_movielens_20m.py: 69-105
</a>
<div class="mid" id="frag615" style="display:none"><pre>
def test_download_split_by_ts():
    """
    Test movielense download
    """
    MovieLens20M(MOVIELENS20M_ROOT, download=True, split="ts", sample=True)

    filename = "ml-20m"

    # check if data folder exists
    assert os.path.isdir(MOVIELENS20M_ROOT) is True

    # cehck if class folder exists
    assert os.path.isdir(f"{MOVIELENS20M_ROOT}/MovieLens20M") is True

    # check if raw folder exists
    assert os.path.isdir(f"{MOVIELENS20M_ROOT}/MovieLens20M/raw") is True

    # check if processed folder exists
    assert os.path.isdir(f"{MOVIELENS20M_ROOT}/MovieLens20M/processed") is True

    # check some random file from MovieLens
    assert (
        os.path.isfile(
            f"{MOVIELENS20M_ROOT}/MovieLens20M/raw/{filename}/genome-scores.csv"
        )
        is True
    )

    # check if data file is not Nulll
    assert (
        os.path.getsize(
            f"{MOVIELENS20M_ROOT}/MovieLens20M/raw/{filename}/genome-scores.csv"
        )
        &gt; 0
    )


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 18:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 84%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag617')" href="javascript:;">
catalyst-22.02/tests/contrib/datasets/test_movielens_20m.py: 142-160
</a>
<div class="mid" id="frag617" style="display:none"><pre>
def test_users_per_item_filtering():
    """
    Tets retrieveing the minimal ranking
    """
    min_users_per_item = 2.0

    movielens_20m_min_users = MovieLens20M(
        MOVIELENS20M_ROOT,
        download=True,
        min_users_per_item=min_users_per_item,
        sample=True,
        n_rows=1000000,
    )

    assert (
        movielens_20m_min_users.users_activity["user_cnt"] &gt;= min_users_per_item
    ).any()


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag618')" href="javascript:;">
catalyst-22.02/tests/contrib/datasets/test_movielens_20m.py: 163-182
</a>
<div class="mid" id="frag618" style="display:none"><pre>
def test_items_per_user_filtering():
    """
    Tets retrieveing the minimal ranking
    """
    min_items_per_user = 2.0
    min_users_per_item = 1.0
    movielens_20m_min_users = MovieLens20M(
        MOVIELENS20M_ROOT,
        download=True,
        min_items_per_user=min_items_per_user,
        min_users_per_item=min_users_per_item,
        sample=True,
        n_rows=1000000,
    )

    assert (
        movielens_20m_min_users.items_activity["item_cnt"] &gt;= min_items_per_user
    ).any()


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 19:</b> &nbsp; 2 fragments, nominal size 72 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag625')" href="javascript:;">
catalyst-22.02/tests/catalyst/runners/test_sklearn_classifier.py: 25-113
</a>
<div class="mid" id="frag625" style="display:none"><pre>
def train_experiment(engine=None):
    with TemporaryDirectory() as logdir:
        utils.set_global_seed(RANDOM_STATE)
        # 1. generate data
        num_samples, num_features, num_classes = int(1e4), int(30), 3
        X, y = make_classification(
            n_samples=num_samples,
            n_features=num_features,
            n_informative=num_features,
            n_repeated=0,
            n_redundant=0,
            n_classes=num_classes,
            n_clusters_per_class=1,
        )
        X, y = torch.tensor(X), torch.tensor(y)
        dataset = TensorDataset(X, y)
        loader = DataLoader(dataset, batch_size=64, num_workers=1, shuffle=True)

        # 2. model, optimizer and scheduler
        hidden_size, out_features = 20, 16
        model = nn.Sequential(
            nn.Linear(num_features, hidden_size),
            nn.ReLU(),
            nn.Linear(hidden_size, out_features),
        )
        optimizer = Adam(model.parameters(), lr=LR)
        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [2])

        # 3. criterion with triplets sampling
        sampler_inbatch = HardTripletsSampler(norm_required=False)
        criterion = TripletMarginLossWithSampler(
            margin=0.5, sampler_inbatch=sampler_inbatch
        )

        # 4. training with catalyst Runner
        class CustomRunner(dl.SupervisedRunner):
            def handle_batch(self, batch) -&gt; None:
                features, targets = batch["features"].float(), batch["targets"].long()
                embeddings = self.model(features)
                self.batch = {
                    "embeddings": embeddings,
                    "targets": targets,
                }

        callbacks = [
            dl.SklearnModelCallback(
                feature_key="embeddings",
                target_key="targets",
                train_loader="train",
                valid_loaders="valid",
                model_fn=RandomForestClassifier,
                predict_method="predict_proba",
                predict_key="sklearn_predict",
                random_state=RANDOM_STATE,
                n_estimators=100,
            ),
            dl.ControlFlowCallbackWrapper(
                dl.AccuracyCallback(
                    target_key="targets", input_key="sklearn_predict", topk=(1, 3)
                ),
                loaders="valid",
            ),
        ]

        runner = CustomRunner(input_key="features", output_key="embeddings")
        runner.train(
            engine=engine,
            model=model,
            criterion=criterion,
            optimizer=optimizer,
            callbacks=callbacks,
            scheduler=scheduler,
            loaders={"train": loader, "valid": loader},
            verbose=False,
            valid_loader="valid",
            valid_metric="accuracy01",
            minimize_valid_metric=False,
            num_epochs=TRAIN_EPOCH,
            logdir=logdir,
        )

        best_accuracy = max(
            epoch_metrics["valid"]["accuracy01"]
            for epoch_metrics in runner.experiment_metrics.values()
        )

        assert best_accuracy &gt; 0.9


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag635')" href="javascript:;">
catalyst-22.02/tests/catalyst/runners/test_sklearn_classifier_mnist.py: 37-127
</a>
<div class="mid" id="frag635" style="display:none"><pre>
def train_experiment(engine=None):
    with TemporaryDirectory() as logdir:
        utils.set_global_seed(RANDOM_STATE)
        # 1. train, valid and test loaders
        train_data = MNIST(DATA_ROOT, train=True)
        train_labels = train_data.targets.cpu().numpy().tolist()
        train_sampler = BatchBalanceClassSampler(
            train_labels, num_classes=10, num_samples=4
        )
        train_loader = DataLoader(train_data, batch_sampler=train_sampler)

        valid_dataset = MNIST(root=DATA_ROOT, train=False)
        valid_loader = DataLoader(dataset=valid_dataset, batch_size=32)

        test_dataset = MNIST(root=DATA_ROOT, train=False)
        test_loader = DataLoader(dataset=test_dataset, batch_size=32)

        # 2. model and optimizer
        model = nn.Sequential(
            nn.Flatten(), nn.Linear(28 * 28, 16), nn.LeakyReLU(inplace=True)
        )
        optimizer = Adam(model.parameters(), lr=LR)
        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [2])

        # 3. criterion with triplets sampling
        sampler_inbatch = HardTripletsSampler(norm_required=False)
        criterion = TripletMarginLossWithSampler(
            margin=0.5, sampler_inbatch=sampler_inbatch
        )

        # 4. training with catalyst Runner
        class CustomRunner(dl.SupervisedRunner):
            def handle_batch(self, batch) -&gt; None:
                images, targets = batch["features"].float(), batch["targets"].long()
                features = self.model(images)
                self.batch = {
                    "embeddings": features,
                    "targets": targets,
                }

        callbacks = [
            dl.ControlFlowCallbackWrapper(
                dl.CriterionCallback(
                    input_key="embeddings", target_key="targets", metric_key="loss"
                ),
                loaders="train",
            ),
            dl.SklearnModelCallback(
                feature_key="embeddings",
                target_key="targets",
                train_loader="train",
                valid_loaders=["valid", "infer"],
                model_fn=RandomForestClassifier,
                predict_method="predict_proba",
                predict_key="sklearn_predict",
                random_state=RANDOM_STATE,
                n_estimators=50,
            ),
            dl.ControlFlowCallbackWrapper(
                dl.AccuracyCallback(
                    target_key="targets", input_key="sklearn_predict", topk=(1, 3)
                ),
                loaders=["valid", "infer"],
            ),
        ]

        runner = CustomRunner(input_key="features", output_key="embeddings")
        runner.train(
            engine=engine,
            model=model,
            criterion=criterion,
            optimizer=optimizer,
            scheduler=scheduler,
            callbacks=callbacks,
            loaders={"train": train_loader, "valid": valid_loader, "infer": test_loader},
            verbose=False,
            valid_loader="valid",
            valid_metric="accuracy01",
            minimize_valid_metric=False,
            num_epochs=TRAIN_EPOCH,
            logdir=logdir,
        )

        best_accuracy = max(
            epoch_metrics["infer"]["accuracy01"]
            for epoch_metrics in runner.experiment_metrics.values()
        )

        assert best_accuracy &gt; 0.8


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 20:</b> &nbsp; 3 fragments, nominal size 21 lines, similarity 80%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag646')" href="javascript:;">
catalyst-22.02/tests/catalyst/runners/test_reid.py: 75-104
</a>
<div class="mid" id="frag646" style="display:none"><pre>
    def handle_batch(self, batch: Dict[str, torch.Tensor]) -&gt; None:
        """
        Process batch

        Args:
            batch: batch data
        """
        if self.is_train_loader:
            images, targets = batch["features"].float(), batch["targets"].long()
            features = self.model(images)
            self.batch = {
                "embeddings": features,
                "targets": targets,
            }
        else:
            images, targets, cids, is_query = (
                batch["features"].float(),
                batch["targets"].long(),
                batch["cids"].long(),
                batch["is_query"].bool(),
            )
            features = self.model(images)
            self.batch = {
                "embeddings": features,
                "targets": targets,
                "cids": cids,
                "is_query": is_query,
            }


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag736')" href="javascript:;">
catalyst-22.02/tests/pipelines/test_metric_learning.py: 32-53
</a>
<div class="mid" id="frag736" style="display:none"><pre>
    def handle_batch(self, batch) -&gt; None:
        if self.is_train_loader:
            images, targets = batch["features"].float(), batch["targets"].long()
            features = self.model(images)
            self.batch = {
                "embeddings": features,
                "targets": targets,
            }
        else:
            images, targets, is_query = (
                batch["features"].float(),
                batch["targets"].long(),
                batch["is_query"].bool(),
            )
            features = self.model(images)
            self.batch = {
                "embeddings": features,
                "targets": targets,
                "is_query": is_query,
            }


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag649')" href="javascript:;">
catalyst-22.02/tests/catalyst/runners/test_reid.py: 200-228
</a>
<div class="mid" id="frag649" style="display:none"><pre>
    def handle_batch(self, batch: Dict[str, torch.Tensor]) -&gt; None:
        """
        Handle batch for train and valid loaders

        Args:
            batch: batch to process
        """
        if self.is_train_loader:
            images, targets = batch["features"].float(), batch["targets"].long()
            features = self.model(images)
            self.batch = {
                "embeddings": features,
                "targets": targets,
                "images": images,
            }
        else:
            images, targets, is_query = (
                batch["features"].float(),
                batch["targets"].long(),
                batch["is_query"].bool(),
            )
            features = self.model(images)
            self.batch = {
                "embeddings": features,
                "targets": targets,
                "is_query": is_query,
            }


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 21:</b> &nbsp; 2 fragments, nominal size 56 lines, similarity 84%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag651')" href="javascript:;">
catalyst-22.02/tests/catalyst/runners/test_reid.py: 291-361
</a>
<div class="mid" id="frag651" style="display:none"><pre>
def test_reid_pipeline():
    """This test checks that reid pipeline runs and compute metrics with ReidCMCScoreCallback"""
    with TemporaryDirectory() as logdir:

        # 1. train and valid loaders
        train_dataset = MnistMLDataset(root=DATA_ROOT)
        sampler = BatchBalanceClassSampler(
            labels=train_dataset.get_labels(),
            num_classes=3,
            num_samples=10,
            num_batches=20,
        )
        train_loader = DataLoader(
            dataset=train_dataset, batch_sampler=sampler, num_workers=0
        )

        valid_dataset = MnistReIDQGDataset(root=DATA_ROOT, gallery_fraq=0.2)
        valid_loader = DataLoader(dataset=valid_dataset, batch_size=1024)

        # 2. model and optimizer
        model = MnistSimpleNet(out_features=16)
        optimizer = Adam(model.parameters(), lr=0.001)

        # 3. criterion with triplets sampling
        sampler_inbatch = AllTripletsSampler(max_output_triplets=1000)
        criterion = TripletMarginLossWithSampler(
            margin=0.5, sampler_inbatch=sampler_inbatch
        )

        # 4. training with catalyst Runner
        callbacks = [
            dl.ControlFlowCallbackWrapper(
                dl.CriterionCallback(
                    input_key="embeddings", target_key="targets", metric_key="loss"
                ),
                loaders="train",
            ),
            dl.ControlFlowCallbackWrapper(
                dl.ReidCMCScoreCallback(
                    embeddings_key="embeddings",
                    pids_key="targets",
                    cids_key="cids",
                    is_query_key="is_query",
                    topk=[1],
                ),
                loaders="valid",
            ),
            dl.PeriodicLoaderCallback(
                valid_loader_key="valid",
                valid_metric_key="cmc01",
                minimize=False,
                valid=2,
            ),
        ]

        runner = ReIDCustomRunner()
        runner.train(
            model=model,
            criterion=criterion,
            optimizer=optimizer,
            callbacks=callbacks,
            loaders=OrderedDict({"train": train_loader, "valid": valid_loader}),
            verbose=False,
            logdir=logdir,
            valid_loader="valid",
            valid_metric="cmc01",
            minimize_valid_metric=False,
            num_epochs=10,
        )
        assert "cmc01" in runner.loader_metrics
        assert runner.loader_metrics["cmc01"] &gt; 0.65
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag737')" href="javascript:;">
catalyst-22.02/tests/pipelines/test_metric_learning.py: 54-122
</a>
<div class="mid" id="frag737" style="display:none"><pre>
def train_experiment(engine=None):
    with TemporaryDirectory() as logdir:

        # 1. train and valid loaders
        train_dataset = MnistMLDataset(root=DATA_ROOT)
        sampler = BatchBalanceClassSampler(
            labels=train_dataset.get_labels(),
            num_classes=5,
            num_samples=10,
            num_batches=10,
        )
        train_loader = DataLoader(dataset=train_dataset, batch_sampler=sampler)

        valid_dataset = MnistQGDataset(root=DATA_ROOT, gallery_fraq=0.2)
        valid_loader = DataLoader(dataset=valid_dataset, batch_size=1024)

        # 2. model and optimizer
        model = MnistSimpleNet(out_features=16)
        optimizer = Adam(model.parameters(), lr=0.001)

        # 3. criterion with triplets sampling
        sampler_inbatch = HardTripletsSampler(norm_required=False)
        criterion = TripletMarginLossWithSampler(
            margin=0.5, sampler_inbatch=sampler_inbatch
        )

        # 4. training with catalyst Runner
        callbacks = [
            dl.ControlFlowCallbackWrapper(
                dl.CriterionCallback(
                    input_key="embeddings", target_key="targets", metric_key="loss"
                ),
                loaders="train",
            ),
            dl.ControlFlowCallbackWrapper(
                dl.CMCScoreCallback(
                    embeddings_key="embeddings",
                    labels_key="targets",
                    is_query_key="is_query",
                    topk=[1],
                ),
                loaders="valid",
            ),
            dl.PeriodicLoaderCallback(
                valid_loader_key="valid",
                valid_metric_key="cmc01",
                minimize=False,
                valid=2,
            ),
        ]

        runner = CustomRunner(input_key="features", output_key="embeddings")
        runner.train(
            engine=engine,
            model=model,
            criterion=criterion,
            optimizer=optimizer,
            callbacks=callbacks,
            loaders={"train": train_loader, "valid": valid_loader},
            verbose=False,
            logdir=logdir,
            valid_loader="valid",
            valid_metric="cmc01",
            minimize_valid_metric=False,
            num_epochs=2,
        )


# Device
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 22:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 92%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag652')" href="javascript:;">
catalyst-22.02/tests/catalyst/data/test_loader.py: 8-22
</a>
<div class="mid" id="frag652" style="display:none"><pre>
def test_batch_limit1() -&gt; None:
    for shuffle in (False, True):
        num_samples, num_features = int(1e2), int(1e1)
        X, y = torch.rand(num_samples, num_features), torch.rand(num_samples)
        dataset = TensorDataset(X, y)
        loader = DataLoader(dataset, batch_size=4, num_workers=1, shuffle=shuffle)
        loader = BatchLimitLoaderWrapper(loader, num_batches=1)

        batch1 = next(iter(loader))[0]
        batch2 = next(iter(loader))[0]
        batch3 = next(iter(loader))[0]
        assert all(torch.isclose(x, y).all() for x, y in zip(batch1, batch2))
        assert all(torch.isclose(x, y).all() for x, y in zip(batch2, batch3))


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag653')" href="javascript:;">
catalyst-22.02/tests/catalyst/data/test_loader.py: 23-36
</a>
<div class="mid" id="frag653" style="display:none"><pre>
def test_batch_limit2() -&gt; None:
    for shuffle in (False, True):
        num_samples, num_features = int(1e2), int(1e1)
        X, y = torch.rand(num_samples, num_features), torch.rand(num_samples)
        dataset = TensorDataset(X, y)
        loader = DataLoader(dataset, batch_size=4, num_workers=1, shuffle=shuffle)
        loader = BatchLimitLoaderWrapper(loader, num_batches=2)

        batch1 = next(iter(loader))[0]
        batch2 = next(iter(loader))[0]
        batch3 = next(iter(loader))[0]
        batch4 = next(iter(loader))[0]
        assert all(torch.isclose(x, y).all() for x, y in zip(batch1, batch3))
        assert all(torch.isclose(x, y).all() for x, y in zip(batch2, batch4))
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 23:</b> &nbsp; 2 fragments, nominal size 36 lines, similarity 80%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag658')" href="javascript:;">
catalyst-22.02/tests/catalyst/callbacks/test_metric_aggregation.py: 31-71
</a>
<div class="mid" id="frag658" style="display:none"><pre>
def test_aggregation_1():
    """
    Aggregation as weighted_sum
    """
    loaders, model, criterion, optimizer = prepare_experiment()
    runner = dl.SupervisedRunner()
    runner.train(
        model=model,
        criterion=criterion,
        optimizer=optimizer,
        loaders=loaders,
        logdir="./logs/aggregation_1/",
        num_epochs=3,
        callbacks=[
            dl.CriterionCallback(
                input_key="logits",
                target_key="targets",
                metric_key="loss_bce",
                criterion_key="bce",
            ),
            dl.CriterionCallback(
                input_key="logits",
                target_key="targets",
                metric_key="loss_focal",
                criterion_key="focal",
            ),
            # loss aggregation
            dl.MetricAggregationCallback(
                metric_key="loss",
                metrics={"loss_focal": 0.6, "loss_bce": 0.4},
                mode="weighted_sum",
            ),
        ],
    )
    for loader in ["train", "valid"]:
        metrics = runner.epoch_metrics[loader]
        loss_1 = metrics["loss_bce"] * 0.4 + metrics["loss_focal"] * 0.6
        loss_2 = metrics["loss"]
        assert np.abs(loss_1 - loss_2) &lt; 1e-5


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag659')" href="javascript:;">
catalyst-22.02/tests/catalyst/callbacks/test_metric_aggregation.py: 72-114
</a>
<div class="mid" id="frag659" style="display:none"><pre>
def test_aggregation_2():
    """
    Aggregation with custom function
    """
    loaders, model, criterion, optimizer = prepare_experiment()
    runner = dl.SupervisedRunner()

    def aggregation_function(metrics, runner):
        epoch = runner.epoch_step
        loss = (3 / 2 - epoch / 2) * metrics["loss_focal"] + (
            1 / 2 * epoch - 1 / 2
        ) * metrics["loss_bce"]
        return loss

    runner.train(
        model=model,
        criterion=criterion,
        optimizer=optimizer,
        loaders=loaders,
        logdir="./logs/aggregation_2/",
        num_epochs=3,
        callbacks=[
            dl.CriterionCallback(
                input_key="logits",
                target_key="targets",
                metric_key="loss_bce",
                criterion_key="bce",
            ),
            dl.CriterionCallback(
                input_key="logits",
                target_key="targets",
                metric_key="loss_focal",
                criterion_key="focal",
            ),
            # loss aggregation
            dl.MetricAggregationCallback(metric_key="loss", mode=aggregation_function),
        ],
    )
    for loader in ["train", "valid"]:
        metrics = runner.epoch_metrics[loader]
        loss_1 = metrics["loss_bce"]
        loss_2 = metrics["loss"]
        assert np.abs(loss_1 - loss_2) &lt; 1e-5
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 24:</b> &nbsp; 10 fragments, nominal size 46 lines, similarity 74%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag667')" href="javascript:;">
catalyst-22.02/tests/catalyst/callbacks/test_periodic_loader.py: 133-196
</a>
<div class="mid" id="frag667" style="display:none"><pre>
def test_validation_with_period_3():
    old_stdout = sys.stdout
    sys.stdout = str_stdout = StringIO()

    # experiment_setup
    logdir = "./logs/periodic_loader"
    checkpoint = logdir + "/checkpoints"
    logfile = checkpoint + "/model.storage.json"

    # data
    num_samples, num_features = int(1e4), int(1e1)
    X = torch.rand(num_samples, num_features)
    y = torch.randint(0, 5, size=[num_samples])
    dataset = TensorDataset(X, y)
    loader = DataLoader(dataset, batch_size=32, num_workers=1)
    loaders = {
        "train": loader,
        "valid": loader,
    }

    # model, criterion, optimizer, scheduler
    model = torch.nn.Linear(num_features, 5)
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters())
    runner = SupervisedRunner()

    # first stage
    runner.train(
        model=model,
        criterion=criterion,
        optimizer=optimizer,
        loaders=loaders,
        logdir=logdir,
        num_epochs=10,
        verbose=False,
        valid_loader="valid",
        valid_metric="loss",
        minimize_valid_metric=True,
        callbacks=[
            PeriodicLoaderCallback(
                valid_loader_key="valid", valid_metric_key="loss", minimize=True, valid=3
            ),
            CheckRunCallback(num_epoch_steps=10),
        ],
    )

    sys.stdout = old_stdout
    exp_output = str_stdout.getvalue()

    # assert len(re.findall(r"\(train\)", exp_output)) == 10
    # assert len(re.findall(r"\(valid\)", exp_output)) == 3
    # assert len(re.findall(r".*/train\.\d\.pth", exp_output)) == 1

    assert os.path.isfile(logfile)
    assert os.path.isfile(checkpoint + "/model.0009.pth")
    # assert os.path.isfile(checkpoint + "/train.9_full.pth")
    assert os.path.isfile(checkpoint + "/model.best.pth")
    # assert os.path.isfile(checkpoint + "/best_full.pth")
    assert os.path.isfile(checkpoint + "/model.last.pth")
    # assert os.path.isfile(checkpoint + "/last_full.pth")

    shutil.rmtree(logdir, ignore_errors=True)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag672')" href="javascript:;">
catalyst-22.02/tests/catalyst/callbacks/test_periodic_loader.py: 552-611
</a>
<div class="mid" id="frag672" style="display:none"><pre>
def test_negative_period_exception():
    old_stdout = sys.stdout
    sys.stdout = str_stdout = StringIO()

    # experiment_setup
    logdir = "./logs/periodic_loader"
    checkpoint = logdir + "/checkpoints"
    logfile = checkpoint + "/model.storage.json"

    # data
    num_samples, num_features = int(1e4), int(1e1)
    X = torch.rand(num_samples, num_features)
    y = torch.randint(0, 5, size=[num_samples])
    dataset = TensorDataset(X, y)
    loader = DataLoader(dataset, batch_size=32, num_workers=1)
    loaders = {
        "train": loader,
        "train_additional": loader,
        "valid": loader,
        "valid_additional": loader,
    }

    # model, criterion, optimizer, scheduler
    model = torch.nn.Linear(num_features, 5)
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters())
    runner = SupervisedRunner()

    with pytest.raises(ValueError):
        runner.train(
            model=model,
            criterion=criterion,
            optimizer=optimizer,
            loaders=loaders,
            logdir=logdir,
            num_epochs=10,
            verbose=False,
            valid_loader="valid",
            valid_metric="loss",
            minimize_valid_metric=True,
            callbacks=[
                PeriodicLoaderCallback(
                    valid_loader_key="valid",
                    valid_metric_key="loss",
                    minimize=True,
                    train_additional=1,
                    train_not_exists=-10,
                    valid=3,
                    valid_additional=-1,
                    valid_not_exist=1,
                )
            ],
        )

    sys.stdout = old_stdout
    exp_output = str_stdout.getvalue()

    shutil.rmtree(logdir, ignore_errors=True)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag669')" href="javascript:;">
catalyst-22.02/tests/catalyst/callbacks/test_periodic_loader.py: 262-432
</a>
<div class="mid" id="frag669" style="display:none"><pre>
def test_multiple_loaders():
    old_stdout = sys.stdout
    sys.stdout = str_stdout = StringIO()

    # experiment_setup
    logdir = "./logs/periodic_loader"
    checkpoint = logdir + "/checkpoints"
    logfile = checkpoint + "/model.storage.json"

    # data
    num_samples, num_features = int(1e4), int(1e1)
    X = torch.rand(num_samples, num_features)
    y = torch.randint(0, 5, size=[num_samples])
    dataset = TensorDataset(X, y)
    loader = DataLoader(dataset, batch_size=32, num_workers=1)
    loaders = {
        "train": loader,
        "train_additional": loader,
        "valid": loader,
        "valid_additional": loader,
    }

    # model, criterion, optimizer, scheduler
    model = torch.nn.Linear(num_features, 5)
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters())
    runner = SupervisedRunner()

    # first stage
    runner.train(
        model=model,
        criterion=criterion,
        optimizer=optimizer,
        loaders=loaders,
        logdir=logdir,
        num_epochs=10,
        verbose=False,
        valid_loader="valid",
        valid_metric="loss",
        minimize_valid_metric=True,
        callbacks=[
            PeriodicLoaderCallback(
                valid_loader_key="valid",
                valid_metric_key="loss",
                minimize=True,
                train_additional=2,
                valid=3,
                valid_additional=0,
            ),
            CheckRunCallback(num_epoch_steps=10),
        ],
    )

    sys.stdout = old_stdout
    exp_output = str_stdout.getvalue()

    # assert len(re.findall(r"\(train\)", exp_output)) == 10
    # assert len(re.findall(r"\(train_additional\)", exp_output)) == 5
    # assert len(re.findall(r"\(valid\)", exp_output)) == 3
    # assert len(re.findall(r"\(valid_additional\)", exp_output)) == 0
    # assert len(re.findall(r".*/train\.\d\.pth", exp_output)) == 1

    assert os.path.isfile(logfile)
    assert os.path.isfile(checkpoint + "/model.0009.pth")
    # assert os.path.isfile(checkpoint + "/train.9_full.pth")
    assert os.path.isfile(checkpoint + "/model.best.pth")
    # assert os.path.isfile(checkpoint + "/best_full.pth")
    assert os.path.isfile(checkpoint + "/model.last.pth")
    # assert os.path.isfile(checkpoint + "/last_full.pth")

    shutil.rmtree(logdir, ignore_errors=True)


# def test_multiple_loaders_and_multiple_stages():
#     old_stdout = sys.stdout
#     sys.stdout = str_stdout = StringIO()

#     # experiment_setup
#     logdir = "./logs/periodic_loader"
#     checkpoint = logdir + "/checkpoints"
#     logfile = checkpoint + "/model.storage.json"

#     # data
#     num_samples, num_features = int(1e4), int(1e1)
#     X = torch.rand(num_samples, num_features)
#     y = torch.randint(0, 5, size=[num_samples])
#     dataset = TensorDataset(X, y)
#     loader = DataLoader(dataset, batch_size=32, num_workers=1)
#     loaders = {
#         "train": loader,
#         "train_additional": loader,
#         "valid": loader,
#         "valid_additional": loader,
#     }

#     # model, criterion, optimizer, scheduler
#     model = torch.nn.Linear(num_features, 5)
#     criterion = torch.nn.CrossEntropyLoss()
#     optimizer = torch.optim.Adam(model.parameters())
#     runner = SupervisedRunner()

#     # first stage
#     runner.train(
#         model=model,
#         criterion=criterion,
#         optimizer=optimizer,
#         loaders=loaders,
#         logdir=logdir,
#         num_epochs=5,
#         verbose=False,
#         valid_loader="valid",
#         valid_metric="loss",
#         minimize_valid_metric=True,
#         callbacks=[
#             PeriodicLoaderCallback(
#                 valid_loader="valid",
#                 valid_metric="loss",
#                 minimize=True,
#                 train_additional=2,
#                 valid=3,
#                 valid_additional=0,
#             ),
#             CheckRunCallback(num_epoch_steps=5),
#         ],
#     )

#     # second stage
#     runner.train(
#         model=model,
#         criterion=criterion,
#         optimizer=optimizer,
#         loaders=loaders,
#         logdir=logdir,
#         num_epochs=10,
#         verbose=False,
#         valid_loader="valid",
#         valid_metric="loss",
#         minimize_valid_metric=True,
#         callbacks=[
#             PeriodicLoaderCallback(
#                 valid_loader="valid",
#                 valid_metric="loss",
#                 minimize=True,
#                 train_additional=2,
#                 valid=3,
#                 valid_additional=0,
#             ),
#             CheckRunCallback(num_epoch_steps=10),
#         ],
#     )

#     sys.stdout = old_stdout
#     exp_output = str_stdout.getvalue()

#     # assert len(re.findall(r"\(train\)", exp_output)) == 15
#     # assert len(re.findall(r"\(train_additional\)", exp_output)) == 7
#     # assert len(re.findall(r"\(valid\)", exp_output)) == 4
#     # assert len(re.findall(r"\(valid_additional\)", exp_output)) == 0
#     # assert len(re.findall(r".*/train\.\d\.pth", exp_output)) == 2

#     assert os.path.isfile(logfile)
#     assert os.path.isfile(checkpoint + "/train.9.pth")
#     assert os.path.isfile(checkpoint + "/train.9_full.pth")
#     assert os.path.isfile(checkpoint + "/best.pth")
#     assert os.path.isfile(checkpoint + "/best_full.pth")
#     assert os.path.isfile(checkpoint + "/last.pth")
#     assert os.path.isfile(checkpoint + "/last_full.pth")

#     shutil.rmtree(logdir, ignore_errors=True)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag670')" href="javascript:;">
catalyst-22.02/tests/catalyst/callbacks/test_periodic_loader.py: 433-491
</a>
<div class="mid" id="frag670" style="display:none"><pre>
def test_no_loaders_epoch():
    old_stdout = sys.stdout
    sys.stdout = str_stdout = StringIO()

    # experiment_setup
    logdir = "./logs/periodic_loader"
    checkpoint = logdir + "/checkpoints"
    logfile = checkpoint + "/model.storage.json"

    # data
    num_samples, num_features = int(1e4), int(1e1)
    X = torch.rand(num_samples, num_features)
    y = torch.randint(0, 5, size=[num_samples])
    dataset = TensorDataset(X, y)
    loader = DataLoader(dataset, batch_size=32, num_workers=1)
    loaders = {
        "train": loader,
        "train_additional": loader,
        "valid": loader,
        "valid_additional": loader,
    }

    # model, criterion, optimizer, scheduler
    model = torch.nn.Linear(num_features, 5)
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters())
    runner = SupervisedRunner()

    with pytest.raises(ValueError):
        runner.train(
            model=model,
            criterion=criterion,
            optimizer=optimizer,
            loaders=loaders,
            logdir=logdir,
            num_epochs=10,
            verbose=False,
            valid_loader="valid",
            valid_metric="loss",
            minimize_valid_metric=True,
            callbacks=[
                PeriodicLoaderCallback(
                    valid_loader_key="valid",
                    valid_metric_key="loss",
                    minimize=True,
                    train=2,
                    train_additional=2,
                    valid=3,
                    valid_additional=0,
                )
            ],
        )

    sys.stdout = old_stdout
    exp_output = str_stdout.getvalue()

    shutil.rmtree(logdir, ignore_errors=True)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag674')" href="javascript:;">
catalyst-22.02/tests/catalyst/callbacks/test_periodic_loader.py: 672-748
</a>
<div class="mid" id="frag674" style="display:none"><pre>
def test_ignoring_unknown_loaders():
    old_stdout = sys.stdout
    sys.stdout = str_stdout = StringIO()

    # experiment_setup
    logdir = "./logs/periodic_loader"
    checkpoint = logdir + "/checkpoints"
    logfile = checkpoint + "/model.storage.json"

    # data
    num_samples, num_features = int(1e4), int(1e1)
    X = torch.rand(num_samples, num_features)
    y = torch.randint(0, 5, size=[num_samples])
    dataset = TensorDataset(X, y)
    loader = DataLoader(dataset, batch_size=32, num_workers=1)
    loaders = {
        "train": loader,
        "train_additional": loader,
        "valid": loader,
        "valid_additional": loader,
    }

    # model, criterion, optimizer, scheduler
    model = torch.nn.Linear(num_features, 5)
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters())
    runner = SupervisedRunner()

    # first stage
    runner.train(
        model=model,
        criterion=criterion,
        optimizer=optimizer,
        loaders=loaders,
        logdir=logdir,
        num_epochs=10,
        verbose=False,
        valid_loader="valid",
        valid_metric="loss",
        minimize_valid_metric=True,
        callbacks=[
            PeriodicLoaderCallback(
                valid_loader_key="valid",
                valid_metric_key="loss",
                minimize=True,
                train_additional=2,
                train_not_exists=2,
                valid=3,
                valid_additional=0,
                valid_not_exist=1,
            ),
            CheckRunCallback(num_epoch_steps=10),
        ],
    )

    sys.stdout = old_stdout
    exp_output = str_stdout.getvalue()

    # assert len(re.findall(r"\(train\)", exp_output)) == 10
    # assert len(re.findall(r"\(train_additional\)", exp_output)) == 5
    # assert len(re.findall(r"\(train_not_exists\)", exp_output)) == 0
    # assert len(re.findall(r"\(valid\)", exp_output)) == 3
    # assert len(re.findall(r"\(valid_additional\)", exp_output)) == 0
    # assert len(re.findall(r"\(valid_not_exist\)", exp_output)) == 0
    # assert len(re.findall(r".*/train\.\d\.pth", exp_output)) == 1

    assert os.path.isfile(logfile)
    assert os.path.isfile(checkpoint + "/model.0009.pth")
    # assert os.path.isfile(checkpoint + "/train.9_full.pth")
    assert os.path.isfile(checkpoint + "/model.best.pth")
    # assert os.path.isfile(checkpoint + "/best_full.pth")
    assert os.path.isfile(checkpoint + "/model.last.pth")
    # assert os.path.isfile(checkpoint + "/last_full.pth")

    shutil.rmtree(logdir, ignore_errors=True)


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag668')" href="javascript:;">
catalyst-22.02/tests/catalyst/callbacks/test_periodic_loader.py: 198-261
</a>
<div class="mid" id="frag668" style="display:none"><pre>
def test_validation_with_period_0():
    old_stdout = sys.stdout
    sys.stdout = str_stdout = StringIO()

    # experiment_setup
    logdir = "./logs/periodic_loader"
    checkpoint = logdir + "/checkpoints"
    logfile = checkpoint + "/model.storage.json"

    # data
    num_samples, num_features = int(1e4), int(1e1)
    X = torch.rand(num_samples, num_features)
    y = torch.randint(0, 5, size=[num_samples])
    dataset = TensorDataset(X, y)
    loader = DataLoader(dataset, batch_size=32, num_workers=1)
    loaders = {
        "train": loader,
        "valid": loader,
    }

    # model, criterion, optimizer, scheduler
    model = torch.nn.Linear(num_features, 5)
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters())
    runner = SupervisedRunner()

    # first stage
    runner.train(
        model=model,
        criterion=criterion,
        optimizer=optimizer,
        loaders=loaders,
        logdir=logdir,
        num_epochs=5,
        verbose=False,
        valid_loader="valid",
        valid_metric="loss",
        minimize_valid_metric=True,
        callbacks=[
            PeriodicLoaderCallback(
                valid_loader_key="valid", valid_metric_key="loss", minimize=True, valid=0
            ),
            CheckRunCallback(num_epoch_steps=5),
        ],
    )

    sys.stdout = old_stdout
    exp_output = str_stdout.getvalue()

    # assert len(re.findall(r"\(train\)", exp_output)) == 5
    # assert len(re.findall(r"\(valid\)", exp_output)) == 0
    # assert len(re.findall(r".*/train\.\d\.pth", exp_output)) == 1

    assert os.path.isfile(logfile)
    assert os.path.isfile(checkpoint + "/train.5.pth")
    assert os.path.isfile(checkpoint + "/train.5_full.pth")
    assert os.path.isfile(checkpoint + "/best.pth")
    assert os.path.isfile(checkpoint + "/best_full.pth")
    assert os.path.isfile(checkpoint + "/last.pth")
    assert os.path.isfile(checkpoint + "/last_full.pth")

    shutil.rmtree(logdir, ignore_errors=True)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag671')" href="javascript:;">
catalyst-22.02/tests/catalyst/callbacks/test_periodic_loader.py: 492-551
</a>
<div class="mid" id="frag671" style="display:none"><pre>
def test_wrong_period_type():
    old_stdout = sys.stdout
    sys.stdout = str_stdout = StringIO()

    # experiment_setup
    logdir = "./logs/periodic_loader"
    checkpoint = logdir + "/checkpoints"
    logfile = checkpoint + "/model.storage.json"

    # data
    num_samples, num_features = int(1e4), int(1e1)
    X = torch.rand(num_samples, num_features)
    y = torch.randint(0, 5, size=[num_samples])
    dataset = TensorDataset(X, y)
    loader = DataLoader(dataset, batch_size=32, num_workers=1)
    loaders = {
        "train": loader,
        "train_additional": loader,
        "valid": loader,
        "valid_additional": loader,
    }

    # model, criterion, optimizer, scheduler
    model = torch.nn.Linear(num_features, 5)
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters())
    runner = SupervisedRunner()

    with pytest.raises(TypeError):
        runner.train(
            model=model,
            criterion=criterion,
            optimizer=optimizer,
            loaders=loaders,
            logdir=logdir,
            num_epochs=10,
            verbose=False,
            valid_loader="valid",
            valid_metric="loss",
            minimize_valid_metric=True,
            callbacks=[
                PeriodicLoaderCallback(
                    valid_loader_key="valid",
                    valid_metric_key="loss",
                    minimize=True,
                    train_additional=[],
                    train_not_exists=2,
                    valid=3,
                    valid_additional=0,
                    valid_not_exist=1,
                )
            ],
        )

    sys.stdout = old_stdout
    exp_output = str_stdout.getvalue()

    shutil.rmtree(logdir, ignore_errors=True)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag675')" href="javascript:;">
catalyst-22.02/tests/catalyst/callbacks/test_periodic_loader.py: 749-907
</a>
<div class="mid" id="frag675" style="display:none"><pre>
def test_loading_best_state_at_end():
    old_stdout = sys.stdout
    sys.stdout = str_stdout = StringIO()

    # experiment_setup
    logdir = "./logs/periodic_loader"
    checkpoint = logdir + "/checkpoints"
    logfile = checkpoint + "/model.storage.json"

    # data
    num_samples, num_features = int(1e4), int(1e1)
    X = torch.rand(num_samples, num_features)
    y = torch.randint(0, 5, size=[num_samples])
    dataset = TensorDataset(X, y)
    loader = DataLoader(dataset, batch_size=32, num_workers=1)
    loaders = {
        "train": loader,
        "valid": loader,
    }

    # model, criterion, optimizer, scheduler
    model = torch.nn.Linear(num_features, 5)
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters())
    runner = SupervisedRunner()

    # first stage
    runner.train(
        model=model,
        criterion=criterion,
        optimizer=optimizer,
        loaders=loaders,
        logdir=logdir,
        num_epochs=5,
        verbose=False,
        valid_loader="valid",
        valid_metric="loss",
        minimize_valid_metric=True,
        callbacks=[
            PeriodicLoaderCallback(
                valid_loader_key="valid", valid_metric_key="loss", minimize=True, valid=3
            ),
            CheckRunCallback(num_epoch_steps=5),
        ],
        load_best_on_end=True,
    )

    sys.stdout = old_stdout
    exp_output = str_stdout.getvalue()

    # assert len(re.findall(r"\(train\)", exp_output)) == 5
    # assert len(re.findall(r"\(valid\)", exp_output)) == 1
    # assert len(re.findall(r"\(global epoch 3, epoch 3, stage train\)", exp_output)) == 1
    # assert len(re.findall(r".*/train\.\d\.pth", exp_output)) == 1

    assert os.path.isfile(logfile)
    assert os.path.isfile(checkpoint + "/model.0003.pth")
    # assert os.path.isfile(checkpoint + "/train.3_full.pth")
    assert os.path.isfile(checkpoint + "/model.best.pth")
    # assert os.path.isfile(checkpoint + "/best_full.pth")
    assert os.path.isfile(checkpoint + "/model.last.pth")
    # assert os.path.isfile(checkpoint + "/last_full.pth")

    shutil.rmtree(logdir, ignore_errors=True)


# @pytest.mark.skip(reason="disabled")
# def test_loading_best_state_at_end_with_custom_scores():
#     class Metric(Callback):
#         def __init__(self, values):
#             super().__init__(CallbackOrder.metric)
#             self.values = values

#         def on_loader_end(self, runner: "IRunner") -&gt; None:
#             score = self.values[runner.loader_key][runner.stage_epoch_step]
#             runner.loader_metrics["metric"] = score

#     old_stdout = sys.stdout
#     sys.stdout = str_stdout = StringIO()

#     # experiment_setup
#     logdir = "./logs/periodic_loader"
#     checkpoint = logdir  # + "/checkpoints"
#     logfile = checkpoint + "/model.storage.json"

#     # data
#     num_samples, num_features = int(1e4), int(1e1)
#     X = torch.rand(num_samples, num_features)
#     y = torch.randint(0, 5, size=[num_samples])
#     dataset = TensorDataset(X, y)
#     loader = DataLoader(dataset, batch_size=32, num_workers=1)
#     loaders = {
#         "train": loader,
#         "valid": loader,
#     }

#     # model, criterion, optimizer, scheduler
#     model = torch.nn.Linear(num_features, 5)
#     criterion = torch.nn.CrossEntropyLoss()
#     optimizer = torch.optim.Adam(model.parameters())
#     runner = SupervisedRunner()

#     n_epochs = 10
#     period = 3
#     metrics = {
#         "train": {i: i * 0.1 for i in range(1, 11)},
#         "valid": {
#             i: v
#             for i, v in enumerate(
#                 [0.05, 0.1, 0.15, 0.15, 0.2, 0.18, 0.22, 0.11, 0.13, 0.12], 1
#             )
#         },
#     }

#     # first stage
#     runner.train(
#         model=model,
#         criterion=criterion,
#         optimizer=optimizer,
#         loaders=loaders,
#         logdir=logdir,
#         num_epochs=n_epochs,
#         verbose=False,
#         valid_loader="valid",
#         valid_metric="metric",
#         minimize_valid_metric=False,
#         callbacks=[
#             PeriodicLoaderCallback(
#                 valid_loader="valid",
#                 valid_metric="metric",
#                 minimize=True,
#                 valid=period,
#             ),
#             CheckRunCallback(num_epoch_steps=n_epochs),
#             Metric(metrics),
#         ],
#         load_best_on_end=True,
#     )

#     sys.stdout = old_stdout
#     exp_output = str_stdout.getvalue()

#     # assert len(re.findall(r"\(train\)", exp_output)) == n_epochs
#     # assert len(re.findall(r"\(valid\)", exp_output)) == (n_epochs // period)
#     # assert len(re.findall(r"\(global epoch 6, epoch 6, stage train\)", exp_output)) == 1
#     # assert len(re.findall(r".*/train\.\d\.pth", exp_output)) == 1

#     assert os.path.isfile(logfile)
#     assert os.path.isfile(checkpoint + "/train.6.pth")
#     assert os.path.isfile(checkpoint + "/train.6_full.pth")
#     assert os.path.isfile(checkpoint + "/best.pth")
#     assert os.path.isfile(checkpoint + "/best_full.pth")
#     assert os.path.isfile(checkpoint + "/last.pth")
#     assert os.path.isfile(checkpoint + "/last_full.pth")

#     shutil.rmtree(logdir, ignore_errors=True)


# @pytest.mark.skip(reason="disabled")
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag673')" href="javascript:;">
catalyst-22.02/tests/catalyst/callbacks/test_periodic_loader.py: 612-671
</a>
<div class="mid" id="frag673" style="display:none"><pre>
def test_zero_period_validation_exception():
    old_stdout = sys.stdout
    sys.stdout = str_stdout = StringIO()

    # experiment_setup
    logdir = "./logs/periodic_loader"
    checkpoint = logdir + "/checkpoints"
    logfile = checkpoint + "/model.storage.json"

    # data
    num_samples, num_features = int(1e4), int(1e1)
    X = torch.rand(num_samples, num_features)
    y = torch.randint(0, 5, size=[num_samples])
    dataset = TensorDataset(X, y)
    loader = DataLoader(dataset, batch_size=32, num_workers=1)
    loaders = {
        "train": loader,
        "train_additional": loader,
        "valid": loader,
        "valid_additional": loader,
    }

    # model, criterion, optimizer, scheduler
    model = torch.nn.Linear(num_features, 5)
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters())
    runner = SupervisedRunner()

    with pytest.raises(ValueError):
        runner.train(
            model=model,
            criterion=criterion,
            optimizer=optimizer,
            loaders=loaders,
            logdir=logdir,
            num_epochs=10,
            verbose=False,
            valid_loader="valid",
            valid_metric="loss",
            minimize_valid_metric=True,
            callbacks=[
                PeriodicLoaderCallback(
                    valid_loader_key="valid",
                    valid_metric_key="loss",
                    minimize=True,
                    train_additional=1,
                    train_not_exists=3,
                    valid=0,
                    valid_additional=2,
                    valid_not_exist=1,
                )
            ],
        )

    sys.stdout = old_stdout
    exp_output = str_stdout.getvalue()

    shutil.rmtree(logdir, ignore_errors=True)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag676')" href="javascript:;">
catalyst-22.02/tests/catalyst/callbacks/test_periodic_loader.py: 908-985
</a>
<div class="mid" id="frag676" style="display:none"><pre>
def test_multiple_best_checkpoints():
    old_stdout = sys.stdout
    sys.stdout = str_stdout = StringIO()

    # experiment_setup
    logdir = "./logs/periodic_loader"
    checkpoint = logdir  # + "/checkpoints"
    logfile = checkpoint + "/model.storage.json"

    # data
    num_samples, num_features = int(1e4), int(1e1)
    X = torch.rand(num_samples, num_features)
    y = torch.randint(0, 5, size=[num_samples])
    dataset = TensorDataset(X, y)
    loader = DataLoader(dataset, batch_size=32, num_workers=1)
    loaders = {
        "train": loader,
        "valid": loader,
    }

    # model, criterion, optimizer, scheduler
    model = torch.nn.Linear(num_features, 5)
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters())
    runner = SupervisedRunner()

    n_epochs = 12
    period = 2
    # first stage
    runner.train(
        model=model,
        criterion=criterion,
        optimizer=optimizer,
        loaders=loaders,
        logdir=logdir,
        num_epochs=n_epochs,
        verbose=False,
        valid_loader="valid",
        valid_metric="loss",
        minimize_valid_metric=True,
        callbacks=[
            PeriodicLoaderCallback(
                valid_loader_key="valid",
                valid_metric_key="loss",
                minimize=True,
                valid=period,
            ),
            CheckRunCallback(num_epoch_steps=n_epochs),
            CheckpointCallback(
                logdir=logdir,
                loader_key="valid",
                metric_key="loss",
                minimize=True,
                topk=3,
            ),
        ],
    )

    sys.stdout = old_stdout
    exp_output = str_stdout.getvalue()

    # assert len(re.findall(r"\(train\)", exp_output)) == n_epochs
    # assert len(re.findall(r"\(valid\)", exp_output)) == (n_epochs // period)
    # assert len(re.findall(r".*/train\.\d{1,2}\.pth", exp_output)) == 3

    assert os.path.isfile(logfile)
    assert os.path.isfile(checkpoint + "/model.0008.pth")
    # assert os.path.isfile(checkpoint + "/train.8_full.pth")
    assert os.path.isfile(checkpoint + "/model.0010.pth")
    # assert os.path.isfile(checkpoint + "/train.10_full.pth")
    assert os.path.isfile(checkpoint + "/model.0012.pth")
    # assert os.path.isfile(checkpoint + "/train.12_full.pth")
    assert os.path.isfile(checkpoint + "/model.best.pth")
    # assert os.path.isfile(checkpoint + "/best_full.pth")
    assert os.path.isfile(checkpoint + "/model.last.pth")
    # assert os.path.isfile(checkpoint + "/last_full.pth")

    shutil.rmtree(logdir, ignore_errors=True)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 25:</b> &nbsp; 2 fragments, nominal size 22 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag685')" href="javascript:;">
catalyst-22.02/tests/catalyst/callbacks/test_soft_update.py: 20-53
</a>
<div class="mid" id="frag685" style="display:none"><pre>
def test_soft_update():

    model = nn.ModuleDict(
        {
            "target": nn.Linear(10, 10, bias=False),
            "source": nn.Linear(10, 10, bias=False),
        }
    )
    set_requires_grad(model, False)
    model["target"].weight.data.fill_(0)

    runner = DummyRunner(model=model)
    runner.is_train_loader = True

    soft_update = dl.SoftUpdateCallaback(
        target_model="target",
        source_model="source",
        tau=0.1,
        scope="on_batch_end",
    )
    soft_update.on_batch_end(runner)

    checks = (
        (
            (0.1 * runner.model["source"].weight.data)
            == runner.model["target"].weight.data
        )
        .flatten()
        .tolist()
    )

    assert all(checks)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag686')" href="javascript:;">
catalyst-22.02/tests/catalyst/callbacks/test_soft_update.py: 54-78
</a>
<div class="mid" id="frag686" style="display:none"><pre>
def test_soft_update_not_work():

    model = nn.ModuleDict(
        {
            "target": nn.Linear(10, 10, bias=False),
            "source": nn.Linear(10, 10, bias=False),
        }
    )
    set_requires_grad(model, False)
    model["target"].weight.data.fill_(0)

    runner = DummyRunner(model=model)
    runner.is_train_loader = True

    soft_update = dl.SoftUpdateCallaback(
        target_model="target",
        source_model="source",
        tau=0.1,
        scope="on_batch_start",
    )
    soft_update.on_batch_end(runner)

    checks = (runner.model["target"].weight.data == 0).flatten().tolist()

    assert all(checks)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 26:</b> &nbsp; 2 fragments, nominal size 27 lines, similarity 96%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag689')" href="javascript:;">
catalyst-22.02/tests/catalyst/callbacks/test_wrapper.py: 23-54
</a>
<div class="mid" id="frag689" style="display:none"><pre>
    def test_enabled(self):
        runner = Mock(loader_key="train", epoch=1)

        orders = (
            CallbackOrder.Internal,
            CallbackOrder.Metric,
            CallbackOrder.MetricAggregation,
            CallbackOrder.Optimizer,
            CallbackOrder.Scheduler,
            CallbackOrder.External,
        )

        events = (
            "on_loader_start",
            "on_loader_end",
            "on_experiment_start",
            "on_experiment_end",
            "on_epoch_start",
            "on_epoch_end",
            "on_batch_start",
            "on_batch_end",
            "on_exception",
        )

        for event in events:
            for order in orders:
                callback = RaiserCallback(order, event)
                wrapper = CallbackWrapper(callback, enable_callback=True)

                with self.assertRaises(Dummy):
                    wrapper.__getattribute__(event)(runner)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag690')" href="javascript:;">
catalyst-22.02/tests/catalyst/callbacks/test_wrapper.py: 55-83
</a>
<div class="mid" id="frag690" style="display:none"><pre>
    def test_disabled(self):
        runner = Mock(loader_key="train", epoch=1)

        orders = (
            CallbackOrder.Internal,
            CallbackOrder.Metric,
            CallbackOrder.MetricAggregation,
            CallbackOrder.Optimizer,
            CallbackOrder.Scheduler,
            CallbackOrder.External,
        )

        events = (
            "on_loader_start",
            "on_loader_end",
            "on_experiment_start",
            "on_experiment_end",
            "on_epoch_start",
            "on_epoch_end",
            "on_batch_start",
            "on_batch_end",
            "on_exception",
        )

        for event in events:
            for order in orders:
                callback = RaiserCallback(order, event)
                wrapper = CallbackWrapper(callback, enable_callback=False)
                wrapper.__getattribute__(event)(runner)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 27:</b> &nbsp; 2 fragments, nominal size 33 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag701')" href="javascript:;">
catalyst-22.02/tests/catalyst/metrics/functional/test_iou.py: 7-56
</a>
<div class="mid" id="frag701" style="display:none"><pre>
def test_iou():
    """
    Tests for catalyst.metrics.iou metric.
    """
    size = 4
    half_size = size // 2
    shape = (1, 1, size, size)

    # check 0: one empty
    empty = torch.zeros(shape)
    full = torch.ones(shape)
    assert iou(empty, full, class_dim=1, mode="per-class").item() == 0

    # check 0: no overlap
    left = torch.ones(shape)
    left[:, :, :, half_size:] = 0
    right = torch.ones(shape)
    right[:, :, :, :half_size] = 0
    assert iou(left, right, class_dim=1, mode="per-class").item() == 0

    # check 1: both empty, both full, complete overlap
    assert iou(empty, empty, class_dim=1, mode="per-class").item() == 1
    assert iou(full, full, class_dim=1, mode="per-class").item() == 1
    assert iou(left, left, class_dim=1, mode="per-class").item() == 1

    # check 0.5: half overlap
    top_left = torch.zeros(shape)
    top_left[:, :, :half_size, :half_size] = 1
    assert torch.isclose(
        iou(top_left, left, class_dim=1, mode="per-class"), torch.Tensor([[0.5]])
    )
    assert torch.isclose(
        iou(top_left, left, class_dim=1, mode="micro"), torch.Tensor([[0.5]])
    )
    assert torch.isclose(
        iou(top_left, left, class_dim=1, mode="macro"), torch.Tensor([[0.5]])
    )

    # check multiclass: 0, 0, 1, 1, 1, 0.5
    a = torch.cat([empty, left, empty, full, left, top_left], dim=1)
    b = torch.cat([full, right, empty, full, left, left], dim=1)
    ans = torch.Tensor([0, 0, 1, 1, 1, 0.5])
    ans_micro = torch.tensor(0.4375)
    assert torch.allclose(iou(a, b, class_dim=1, mode="per-class"), ans)
    assert torch.allclose(iou(a, b, class_dim=1, mode="micro"), ans_micro)

    aaa = torch.cat([a, a, a], dim=0)
    bbb = torch.cat([b, b, b], dim=0)
    assert torch.allclose(iou(aaa, bbb, class_dim=1, mode="per-class"), ans)
    assert torch.allclose(iou(aaa, bbb, class_dim=1, mode="micro"), ans_micro)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag714')" href="javascript:;">
catalyst-22.02/tests/catalyst/metrics/functional/test_dice.py: 7-56
</a>
<div class="mid" id="frag714" style="display:none"><pre>
def test_dice():
    """
    Tests for catalyst.metrics.dice metric.
    """
    size = 4
    half_size = size // 2
    shape = (1, 1, size, size)

    # check 0: one empty
    empty = torch.zeros(shape)
    full = torch.ones(shape)
    assert dice(empty, full, class_dim=1, mode="per-class").item() == 0

    # check 0: no overlap
    left = torch.ones(shape)
    left[:, :, :, half_size:] = 0
    right = torch.ones(shape)
    right[:, :, :, :half_size] = 0
    assert dice(left, right, class_dim=1, mode="per-class").item() == 0

    # check 1: both empty, both full, complete overlap
    assert dice(empty, empty, class_dim=1, mode="per-class").item() == 1
    assert dice(full, full, class_dim=1, mode="per-class").item() == 1
    assert dice(left, left, class_dim=1, mode="per-class").item() == 1

    # check 0.5: half overlap
    top_left = torch.zeros(shape)
    top_left[:, :, :half_size, :half_size] = 1
    assert torch.isclose(
        dice(top_left, left, class_dim=1, mode="per-class"), torch.Tensor([[0.6666666]])
    )
    assert torch.isclose(
        dice(top_left, left, class_dim=1, mode="micro"), torch.Tensor([[0.6666666]])
    )
    assert torch.isclose(
        dice(top_left, left, class_dim=1, mode="macro"), torch.Tensor([[0.6666666]])
    )

    # check multiclass: 0, 0, 1, 1, 1, 0.66667
    a = torch.cat([empty, left, empty, full, left, top_left], dim=1)
    b = torch.cat([full, right, empty, full, left, left], dim=1)
    ans = torch.Tensor([0, 0, 1, 1, 1, 0.6666666])
    ans_micro = torch.tensor(0.6087)
    assert torch.allclose(dice(a, b, class_dim=1, mode="per-class"), ans)
    assert torch.allclose(dice(a, b, class_dim=1, mode="micro"), ans_micro)

    aaa = torch.cat([a, a, a], dim=0)
    bbb = torch.cat([b, b, b], dim=0)
    assert torch.allclose(dice(aaa, bbb, class_dim=1, mode="per-class"), ans)
    assert torch.allclose(dice(aaa, bbb, class_dim=1, mode="micro"), ans_micro)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 28:</b> &nbsp; 3 fragments, nominal size 13 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag705')" href="javascript:;">
catalyst-22.02/tests/catalyst/metrics/functional/test_classification.py: 99-125
</a>
<div class="mid" id="frag705" style="display:none"><pre>
def test_micro(
    tp: np.array,
    fp: np.array,
    fn: np.array,
    support: np.array,
    zero_division: int,
    true_answer: Tuple[float],
):
    """
    Test micro metrics averaging

    Args:
        tp: true positive statistic
        fp: false positive statistic
        fn: false negative statistic
        support: support statistic
        zero_division: 0 or 1
        true_answer: true metric value
    """
    _, micro, _, _ = get_aggregated_metrics(
        tp=tp, fp=fp, fn=fn, support=support, zero_division=zero_division
    )
    assert micro[-1] is None
    for pred, real in zip(micro[:-1], true_answer):
        assert abs(pred - real) &lt; EPS


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag707')" href="javascript:;">
catalyst-22.02/tests/catalyst/metrics/functional/test_classification.py: 211-235
</a>
<div class="mid" id="frag707" style="display:none"><pre>
def test_weighted(
    tp: np.array,
    fp: np.array,
    fn: np.array,
    support: np.array,
    zero_division: int,
    true_answer: Tuple[float],
):
    """
    Test weighted metrics averaging

    Args:
        tp: true positive statistic
        fp: false positive statistic
        fn: false negative statistic
        support: support statistic
        zero_division: 0 or 1
        true_answer: true metric value
    """
    _, _, _, weighted = get_aggregated_metrics(
        tp=tp, fp=fp, fn=fn, support=support, zero_division=zero_division
    )
    assert weighted[-1] is None
    for pred, real in zip(weighted[:-1], true_answer):
        assert abs(pred - real) &lt; EPS
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag706')" href="javascript:;">
catalyst-22.02/tests/catalyst/metrics/functional/test_classification.py: 155-181
</a>
<div class="mid" id="frag706" style="display:none"><pre>
def test_macro_average(
    tp: np.array,
    fp: np.array,
    fn: np.array,
    support: np.array,
    zero_division: int,
    true_answer: Tuple[float],
):
    """
    Test macro metrics averaging

    Args:
        tp: true positive statistic
        fp: false positive statistic
        fn: false negative statistic
        support: support statistic
        zero_division: 0 or 1
        true_answer: true metric value
    """
    _, _, macro, _ = get_aggregated_metrics(
        tp=tp, fp=fp, fn=fn, support=support, zero_division=zero_division
    )
    assert macro[-1] is None
    for pred, real in zip(macro[:-1], true_answer):
        assert abs(pred - real) &lt; EPS


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 29:</b> &nbsp; 3 fragments, nominal size 11 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag727')" href="javascript:;">
catalyst-22.02/tests/catalyst/metrics/test_additive.py: 28-49
</a>
<div class="mid" id="frag727" style="display:none"><pre>
def test_additive_mean(
    values_list: Iterable[float],
    num_samples_list: Iterable[int],
    true_values_list: Iterable[float],
) -&gt; None:
    """
    Test additive metric mean computation

    Args:
        values_list: list of values to update metric
        num_samples_list: list of num_samples
        true_values_list: list of metric intermediate value
    """
    metric = AdditiveMetric()
    for value, num_samples, true_value in zip(
        values_list, num_samples_list, true_values_list
    ):
        metric.update(value=value, num_samples=num_samples)
        mean, _ = metric.compute()
        assert np.isclose(mean, true_value)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag729')" href="javascript:;">
catalyst-22.02/tests/catalyst/metrics/test_additive.py: 105-126
</a>
<div class="mid" id="frag729" style="display:none"><pre>
def test_additive_mode(
    values_list: Union[Iterable[float], Iterable[torch.Tensor]],
    num_samples_list: Iterable[int],
    true_values_list: Iterable[float],
    mode: Iterable[str],
):
    """
    Test additive metric std computation

    Args:
        values_list: list of values to update metric
        num_samples_list: list of num_samples
        true_values_list: list of metric intermediate value
        mode: `AdditiveMetric` mode
    """
    metric = AdditiveMetric(mode=mode)
    for value, num_samples, true_value in zip(
        values_list, num_samples_list, true_values_list
    ):
        metric.update(value=value, num_samples=num_samples)
        mean, _ = metric.compute()
        assert np.isclose(mean, true_value)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag728')" href="javascript:;">
catalyst-22.02/tests/catalyst/metrics/test_additive.py: 66-87
</a>
<div class="mid" id="frag728" style="display:none"><pre>
def test_additive_std(
    values_list: Iterable[float],
    num_samples_list: Iterable[int],
    true_values_list: Iterable[float],
):
    """
    Test additive metric std computation

    Args:
        values_list: list of values to update metric
        num_samples_list: list of num_samples
        true_values_list: list of metric intermediate value
    """
    metric = AdditiveMetric()
    for value, num_samples, true_value in zip(
        values_list, num_samples_list, true_values_list
    ):
        metric.update(value=value, num_samples=num_samples)
        _, std = metric.compute()
        assert np.isclose(std, true_value)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 30:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag780')" href="javascript:;">
catalyst-22.02/examples/catalyst_rl/db.py: 124-136
</a>
<div class="mid" id="frag780" style="display:none"><pre>
        def add_message(self, message: IRLDatabaseMessage):
            if message == IRLDatabaseMessage.ENABLE_SAMPLING:
                self._set_flag("sampling_flag", 1)
            elif message == IRLDatabaseMessage.DISABLE_SAMPLING:
                self._set_flag("sampling_flag", 0)
            elif message == IRLDatabaseMessage.DISABLE_TRAINING:
                self._set_flag("sampling_flag", 0)
                self._set_flag("training_flag", 0)
            elif message == IRLDatabaseMessage.ENABLE_TRAINING:
                self._set_flag("training_flag", 1)
            else:
                raise NotImplementedError("unknown message", message)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag794')" href="javascript:;">
catalyst-22.02/examples/catalyst_rl/db.py: 253-265
</a>
<div class="mid" id="frag794" style="display:none"><pre>
        def add_message(self, message: IRLDatabaseMessage):
            if message == IRLDatabaseMessage.ENABLE_SAMPLING:
                self._set_flag("sampling_flag", 1)
            elif message == IRLDatabaseMessage.DISABLE_SAMPLING:
                self._set_flag("sampling_flag", 0)
            elif message == IRLDatabaseMessage.DISABLE_TRAINING:
                self._set_flag("sampling_flag", 0)
                self._set_flag("training_flag", 0)
            elif message == IRLDatabaseMessage.ENABLE_TRAINING:
                self._set_flag("training_flag", 1)
            else:
                raise NotImplementedError("unknown message", message)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 31:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 78%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag855')" href="javascript:;">
catalyst-22.02/examples/self_supervised/src/common.py: 154-171
</a>
<div class="mid" id="frag855" style="display:none"><pre>
def resnet_mnist(in_size: int, in_channels: int, out_features: int, size: int = 16):
    sz, sz2, sz4 = size, size * 2, size * 4
    out_size = (((in_size // 16) * 16) ** 2 * 4) // size
    return nn.Sequential(
        conv_block(in_channels, sz),
        conv_block(sz, sz2, pool=True),
        ResidualBlock(nn.Sequential(conv_block(sz2, sz2), conv_block(sz2, sz2))),
        conv_block(sz2, sz4, pool=True),
        ResidualBlock(nn.Sequential(conv_block(sz4, sz4), conv_block(sz4, sz4))),
        nn.Sequential(
            nn.MaxPool2d(4),
            nn.Flatten(),
            nn.Dropout(0.2),
            nn.Linear(out_size, out_features),
        ),
    )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag856')" href="javascript:;">
catalyst-22.02/examples/self_supervised/src/common.py: 172-193
</a>
<div class="mid" id="frag856" style="display:none"><pre>
def resnet9(in_size: int, in_channels: int, out_features: int, size: int = 16):
    sz, sz2, sz4, sz8 = size, size * 2, size * 4, size * 8
    assert (
        in_size &gt;= 32
    ), "The graph is not valid for images with resolution lower then 32x32."
    out_size = (((in_size // 32) * 32) ** 2 * 2) // size
    return nn.Sequential(
        conv_block(in_channels, sz),
        conv_block(sz, sz2, pool=True),
        ResidualBlock(nn.Sequential(conv_block(sz2, sz2), conv_block(sz2, sz2))),
        conv_block(sz2, sz4, pool=True),
        conv_block(sz4, sz8, pool=True),
        ResidualBlock(nn.Sequential(conv_block(sz8, sz8), conv_block(sz8, sz8))),
        nn.Sequential(
            nn.MaxPool2d(4),
            nn.Flatten(),
            nn.Dropout(0.2),
            nn.Linear(out_size, out_features),
        ),
    )


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<script language="JavaScript">
function ShowHide(divId) { 
    if(document.getElementById(divId).style.display == 'none') {
        document.getElementById(divId).style.display='block';
    } else { 
        document.getElementById(divId).style.display = 'none';
    } 
}
</script>
</body>
</html>
