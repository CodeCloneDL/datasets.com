<html>
<head>
    <title>NiCad6 Clone Report</title>
    <style type="text/css">
        body {font-family:sans-serif;}
        table {background-color:white; border:0px; padding:0px; border-spacing:4px; width:auto; margin-left:30px; margin-right:auto;}
        td {background-color:rgba(192,212,238,0.8); border:0px; padding:8px; width:auto; vertical-align:top; border-radius:8px}
        pre {background-color:white; padding:4px;}
        a {color:darkblue;}
    </style>
</head>
<body>
<h2>NiCad6 Clone Report</h2>
<table>
<tr style="font-size:14pt">
<td><b>System:</b> &nbsp; sonnet-2.0.0</td>
<td><b>Clone pairs:</b> &nbsp; 15</td>
<td><b>Clone classes:</b> &nbsp; 11</td>
</tr>
<tr style="font-size:12pt">
<td style="background-color:white">Clone type: &nbsp; 2</td>
<td style="background-color:white">Granularity: &nbsp; functions-blind</td>
<td style="background-color:white">Max diff threshold: &nbsp; 0%</td>
<td style="background-color:white">Clone size: &nbsp; 10 - 2500 lines</td>
<td style="background-color:white">Total functions-blind: &nbsp; 1040</td>
</tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 1:</b> &nbsp; 3 fragments, nominal size 23 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag147')" href="javascript:;">
sonnet-2.0.0/sonnet/src/conv.py: 173-223
</a>
<div class="mid" id="frag147" style="display:none"><pre>
  def __init__(self,
               output_channels: int,
               kernel_shape: Union[int, Sequence[int]],
               stride: Union[int, Sequence[int]] = 1,
               rate: Union[int, Sequence[int]] = 1,
               padding: Union[Text, pad.Paddings] = "SAME",
               with_bias: bool = True,
               w_init: Optional[initializers.Initializer] = None,
               b_init: Optional[initializers.Initializer] = None,
               data_format: Text = "NWC",
               name: Optional[Text] = None):
    """Constructs a ``Conv1D`` module.

    Args:
      output_channels: The number of output channels.
      kernel_shape: Sequence of length 1, or an integer. ``kernel_shape`` will
        be expanded to define a kernel size in all dimensions.
      stride: Sequence of strides of length 1, or an integer. ``stride`` will be
        expanded to define stride in all dimensions.
      rate: Sequence of dilation rates of length 1, or integer that is used to
        define dilation rate in all dimensions. 1 corresponds to standard
        convolution, ``rate &gt; 1`` corresponds to dilated convolution.
      padding: Padding to apply to the input. This can be either ``SAME``,
        ``VALID`` or a callable or sequence of callables of size 1. Any
        callables must take a single integer argument equal to the effective
        kernel size and return a list of two integers representing the padding
        before and after. See snt.pad.* for more details and example functions.
      with_bias: Whether to include bias parameters. Default ``True``.
      w_init: Optional initializer for the weights. By default the weights are
        initialized truncated random normal values with a standard deviation of
        ``1``/``sqrt(input_feature_size)``, which is commonly used when the
        inputs are zero centered (see https://arxiv.org/abs/1502.03167v3).
      b_init: Optional initializer for the bias. By default the bias is
        initialized to zero.
      data_format: The data format of the input.
      name: Name of the module.
    """
    super(Conv1D, self).__init__(
        num_spatial_dims=1,
        output_channels=output_channels,
        kernel_shape=kernel_shape,
        stride=stride,
        rate=rate,
        padding=padding,
        with_bias=with_bias,
        w_init=w_init,
        b_init=b_init,
        data_format=data_format,
        name=name)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag149')" href="javascript:;">
sonnet-2.0.0/sonnet/src/conv.py: 282-331
</a>
<div class="mid" id="frag149" style="display:none"><pre>
  def __init__(self,
               output_channels: int,
               kernel_shape: Union[int, Sequence[int]],
               stride: Union[int, Sequence[int]] = 1,
               rate: Union[int, Sequence[int]] = 1,
               padding: Union[Text, pad.Paddings] = "SAME",
               with_bias: bool = True,
               w_init: Optional[initializers.Initializer] = None,
               b_init: Optional[initializers.Initializer] = None,
               data_format: Text = "NDHWC",
               name: Optional[Text] = None):
    """Constructs a ``Conv3D`` module.

    Args:
      output_channels: The number of output channels.
      kernel_shape: Sequence of kernel sizes (of length 3), or an integer.
        ``kernel_shape`` will be expanded to define a kernel size in all
        dimensions.
      stride: Sequence of strides (of length 3), or an integer. `stride` will be
        expanded to define stride in all dimensions.
      rate: Sequence of dilation rates (of length 3), or integer that is used to
        define dilation rate in all dimensions. 1 corresponds to standard
        convolution, ``rate &gt; 1`` corresponds to dilated convolution.
      padding: Padding to apply to the input. This can either ``SAME``,
        ``VALID`` or a callable or sequence of callables up to size N. Any
        callables must take a single integer argument equal to the effective
        kernel size and return a list of two integers representing the padding
        before and after. See snt.pad.* for more details and example functions.
      with_bias: Whether to include bias parameters. Default ``True``.
      w_init: Optional initializer for the weights. By default the weights are
        initialized truncated random normal values with a standard deviation of
        ``1 / sqrt(input_feature_size)``, which is commonly used when the inputs
        are zero centered (see https://arxiv.org/abs/1502.03167v3).
      b_init: Optional initializer for the bias. By default the bias is
        initialized to zero.
      data_format: The data format of the input.
      name: Name of the module.
    """
    super(Conv3D, self).__init__(
        num_spatial_dims=3,
        output_channels=output_channels,
        kernel_shape=kernel_shape,
        stride=stride,
        rate=rate,
        padding=padding,
        with_bias=with_bias,
        w_init=w_init,
        b_init=b_init,
        data_format=data_format,
        name=name)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag148')" href="javascript:;">
sonnet-2.0.0/sonnet/src/conv.py: 227-278
</a>
<div class="mid" id="frag148" style="display:none"><pre>
  def __init__(self,
               output_channels: int,
               kernel_shape: Union[int, Sequence[int]],
               stride: Union[int, Sequence[int]] = 1,
               rate: Union[int, Sequence[int]] = 1,
               padding: Union[Text, pad.Paddings] = "SAME",
               with_bias: bool = True,
               w_init: Optional[initializers.Initializer] = None,
               b_init: Optional[initializers.Initializer] = None,
               data_format: Text = "NHWC",
               name: Optional[Text] = None):
    """Constructs a ``Conv2D`` module.

    Args:
      output_channels: The number of output channels.
      kernel_shape: Sequence of kernel sizes (of length 2), or an integer.
        ``kernel_shape`` will be expanded to define a kernel size in all
        dimensions.
      stride: Sequence of strides (of length 2), or an integer. ``stride`` will
        be expanded to define stride in all dimensions.
      rate: Sequence of dilation rates (of length 2), or integer that is used to
        define dilation rate in all dimensions. 1 corresponds to standard
        convolution, ``rate &gt; 1`` corresponds to dilated convolution.
      padding: Padding to apply to the input. This can either ``SAME``,
        ``VALID`` or a callable or sequence of callables of size 2. Any
        callables must take a single integer argument equal to the effective
        kernel size and return a list of two integers representing the padding
        before and after. See snt.pad.* for more details and example functions.
      with_bias: Whether to include bias parameters. Default ``True``.
      w_init: Optional initializer for the weights. By default the weights are
        initialized truncated random normal values with a standard deviation of
        ``1 / sqrt(input_feature_size)``, which is commonly used when the inputs
        are zero centered (see https://arxiv.org/abs/1502.03167v3).
      b_init: Optional initializer for the bias. By default the bias is
        initialized to zero.
      data_format: The data format of the input.
      name: Name of the module.
    """
    super(Conv2D, self).__init__(
        num_spatial_dims=2,
        output_channels=output_channels,
        kernel_shape=kernel_shape,
        stride=stride,
        rate=rate,
        padding=padding,
        with_bias=with_bias,
        w_init=w_init,
        b_init=b_init,
        data_format=data_format,
        name=name)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 2:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag230')" href="javascript:;">
sonnet-2.0.0/sonnet/src/base_test.py: 180-193
</a>
<div class="mid" id="frag230" style="display:none"><pre>
  def test_get_attr_doesnt_enter_name_scope(self):
    scope_names = []

    class GetAttrModule(base.Module):

      def __getattr__(self, name):
        scope_names.append((name, get_name_scope()))
        return super(GetAttrModule, self).__getattr__(name)

    mod = GetAttrModule()
    with self.assertRaises(AttributeError):
      mod.does_not_exist  # pylint: disable=pointless-statement
    self.assertIn(("does_not_exist", ""), scope_names)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag232')" href="javascript:;">
sonnet-2.0.0/sonnet/src/base_test.py: 194-208
</a>
<div class="mid" id="frag232" style="display:none"><pre>
  def test_get_attribute_doesnt_enter_name_scope(self):
    scope_names = []

    class GetAttributeModule(base.Module):

      def __getattribute__(self, name):
        scope_names.append((name, get_name_scope()))
        return super(GetAttributeModule, self).__getattribute__(name)

    mod = GetAttributeModule()
    with self.assertRaises(AttributeError):
      mod.does_not_exist  # pylint: disable=pointless-statement
    self.assertIn(("does_not_exist", ""), scope_names)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 3:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag326')" href="javascript:;">
sonnet-2.0.0/sonnet/src/optimizers/rmsprop_test.py: 66-82
</a>
<div class="mid" id="frag326" style="display:none"><pre>
  def testDense(self):
    parameters = [tf.Variable([1., 2.]), tf.Variable([3., 4.])]
    updates = [tf.constant([5., 5.]), tf.constant([3., 3.])]
    optimizer = self.make_optimizer(learning_rate=0.1)
    # Step 1 of RMSProp
    optimizer.apply(updates, parameters)
    self.assertAllClose([[0.683772, 1.683772], [2.683772, 3.683772]],
                        [x.numpy() for x in parameters])
    # Step 2 of RMSProp
    optimizer.apply(updates, parameters)
    self.assertAllClose([[0.454357, 1.454357], [2.454357, 3.454357]],
                        [x.numpy() for x in parameters])
    # Step 3 of RMSProp
    optimizer.apply(updates, parameters)
    self.assertAllClose([[0.262262, 1.262262], [2.262262, 3.262262]],
                        [x.numpy() for x in parameters])

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag360')" href="javascript:;">
sonnet-2.0.0/sonnet/src/optimizers/adam_test.py: 63-79
</a>
<div class="mid" id="frag360" style="display:none"><pre>
  def testDense(self):
    parameters = [tf.Variable([1., 2.]), tf.Variable([3., 4.])]
    updates = [tf.constant([5., 5.]), tf.constant([3., 3.])]
    optimizer = self.make_optimizer(learning_rate=0.001)
    # Step 1 of Adam
    optimizer.apply(updates, parameters)
    self.assertAllClose([[0.999, 1.999], [2.999, 3.999]],
                        [x.numpy() for x in parameters])
    # Step 2 of Adam
    optimizer.apply(updates, parameters)
    self.assertAllClose([[0.998, 1.998], [2.998, 3.998]],
                        [x.numpy() for x in parameters])
    # Step 3 of Adam
    optimizer.apply(updates, parameters)
    self.assertAllClose([[0.997, 1.997], [2.997, 3.997]],
                        [x.numpy() for x in parameters])

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 4:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag407')" href="javascript:;">
sonnet-2.0.0/sonnet/src/conv_test.py: 158-173
</a>
<div class="mid" id="frag407" style="display:none"><pre>
  def testUnknownBatchSizeNHWC(self):
    x = tf.TensorSpec([None, 5, 5, 3], dtype=tf.float32)

    c = conv.ConvND(
        num_spatial_dims=2,
        output_channels=2,
        kernel_shape=3,
        data_format="NHWC")
    defun_conv = tf.function(c).get_concrete_function(x)

    out1 = defun_conv(tf.ones([3, 5, 5, 3]))
    self.assertEqual(out1.shape, [3, 5, 5, 2])

    out2 = defun_conv(tf.ones([5, 5, 5, 3]))
    self.assertEqual(out2.shape, [5, 5, 5, 2])

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag575')" href="javascript:;">
sonnet-2.0.0/sonnet/src/conv_transpose_test.py: 97-112
</a>
<div class="mid" id="frag575" style="display:none"><pre>
  def testUnknownBatchSizeNHWC(self):
    x = tf.TensorSpec([None, 5, 5, 3], dtype=tf.float32)

    c = conv_transpose.ConvNDTranspose(
        num_spatial_dims=2,
        output_channels=2,
        kernel_shape=3,
        data_format="NHWC")
    defun_conv = tf.function(c).get_concrete_function(x)

    out1 = defun_conv(tf.ones([3, 5, 5, 3]))
    self.assertEqual(out1.shape, [3, 5, 5, 2])

    out2 = defun_conv(tf.ones([5, 5, 5, 3]))
    self.assertEqual(out2.shape, [5, 5, 5, 2])

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 5:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag408')" href="javascript:;">
sonnet-2.0.0/sonnet/src/conv_test.py: 174-191
</a>
<div class="mid" id="frag408" style="display:none"><pre>
  def testUnknownBatchSizeNCHW(self):
    if self.primary_device == "CPU":
      self.skipTest("NCHW not supported on CPU")

    x = tf.TensorSpec([None, 3, 5, 5], dtype=tf.float32)
    c = conv.ConvND(
        num_spatial_dims=2,
        output_channels=2,
        kernel_shape=3,
        data_format="NCHW")
    defun_conv = tf.function(c).get_concrete_function(x)

    out1 = defun_conv(tf.ones([3, 3, 5, 5]))
    self.assertEqual(out1.shape, [3, 2, 5, 5])

    out2 = defun_conv(tf.ones([5, 3, 5, 5]))
    self.assertEqual(out2.shape, [5, 2, 5, 5])

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag576')" href="javascript:;">
sonnet-2.0.0/sonnet/src/conv_transpose_test.py: 113-131
</a>
<div class="mid" id="frag576" style="display:none"><pre>
  def testUnknownBatchSizeNCHW(self):
    if self.primary_device == "CPU":
      self.skipTest("NCHW not supported on CPU")

    x = tf.TensorSpec([None, 3, 5, 5], dtype=tf.float32)

    c = conv_transpose.ConvNDTranspose(
        num_spatial_dims=2,
        output_channels=2,
        kernel_shape=3,
        data_format="NCHW")
    defun_conv = tf.function(c).get_concrete_function(x)

    out1 = defun_conv(tf.ones([3, 3, 5, 5]))
    self.assertEqual(out1.shape, [3, 2, 5, 5])

    out2 = defun_conv(tf.ones([5, 3, 5, 5]))
    self.assertEqual(out2.shape, [5, 2, 5, 5])

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 6:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag409')" href="javascript:;">
sonnet-2.0.0/sonnet/src/conv_test.py: 193-206
</a>
<div class="mid" id="frag409" style="display:none"><pre>
  def testUnknownChannels(self, autograph):
    x = tf.TensorSpec([3, 3, 3, None], dtype=tf.float32)

    c = conv.ConvND(
        num_spatial_dims=2,
        output_channels=1,
        kernel_shape=3,
        data_format="NHWC")
    defun_conv = tf.function(c, autograph=autograph)

    with self.assertRaisesRegex(ValueError,
                                "The number of input channels must be known"):
      defun_conv.get_concrete_function(x)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag577')" href="javascript:;">
sonnet-2.0.0/sonnet/src/conv_transpose_test.py: 133-146
</a>
<div class="mid" id="frag577" style="display:none"><pre>
  def testUnknownChannels(self, autograph):
    x = tf.TensorSpec([3, 3, 3, None], dtype=tf.float32)

    c = conv_transpose.ConvNDTranspose(
        num_spatial_dims=2,
        output_channels=1,
        kernel_shape=3,
        data_format="NHWC")
    defun_conv = tf.function(c, autograph=autograph)

    with self.assertRaisesRegex(ValueError,
                                "The number of input channels must be known"):
      defun_conv.get_concrete_function(x)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 7:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag465')" href="javascript:;">
sonnet-2.0.0/sonnet/src/linear.py: 36-63
</a>
<div class="mid" id="frag465" style="display:none"><pre>
  def __init__(self,
               output_size: int,
               with_bias: bool = True,
               w_init: Optional[initializers.Initializer] = None,
               b_init: Optional[initializers.Initializer] = None,
               name: Optional[Text] = None):
    """Constructs a `Linear` module.

    Args:
      output_size: Output dimensionality.
      with_bias: Whether to include bias parameters. Default `True`.
      w_init: Optional initializer for the weights. By default the weights are
        initialized truncated random normal values with a standard deviation of
        `1 / sqrt(input_feature_size)`, which is commonly used when the inputs
        are zero centered (see https://arxiv.org/abs/1502.03167v3).
      b_init: Optional initializer for the bias. By default the bias is
        initialized to zero.
      name: Name of the module.
    """
    super(Linear, self).__init__(name=name)
    self.output_size = output_size
    self.with_bias = with_bias
    self.w_init = w_init
    if with_bias:
      self.b_init = b_init if b_init is not None else initializers.Zeros()
    elif b_init is not None:
      raise ValueError("When not using a bias the b_init must be None.")

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag805')" href="javascript:;">
sonnet-2.0.0/sonnet/src/parallel_linear.py: 44-71
</a>
<div class="mid" id="frag805" style="display:none"><pre>
  def __init__(self,
               output_size: int,
               with_bias: bool = True,
               w_init: Optional[initializers.Initializer] = None,
               b_init: Optional[initializers.Initializer] = None,
               name: Optional[Text] = None):
    """Constructs a `ParallelLinear` module.

    Args:
      output_size: Output dimensionality.
      with_bias: Whether to include bias parameters. Default `True`.
      w_init: Optional initializer for the weights. By default the weights are
        initialized truncated random normal values with a standard deviation of
        `1 / sqrt(input_feature_size)`, which is commonly used when the inputs
        are zero centered (see https://arxiv.org/abs/1502.03167v3).
      b_init: Optional initializer for the bias. By default the bias is
        initialized to zero.
      name: Name of the module.
    """
    super(ParallelLinears, self).__init__(name=name)
    self.output_size = output_size
    self.with_bias = with_bias
    self.w_init = w_init
    if with_bias:
      self.b_init = b_init if b_init is not None else initializers.Zeros()
    elif b_init is not None:
      raise ValueError("When not using a bias the b_init must be None.")

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 8:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag501')" href="javascript:;">
sonnet-2.0.0/sonnet/src/nets/dnc/write_test.py: 84-96
</a>
<div class="mid" id="frag501" style="display:none"><pre>
  def testShape(self):
    batch_size = 1
    num_writes = 2
    memory_size = 5
    word_size = 3

    mem = tf.random.uniform([batch_size, memory_size, word_size])
    write_address = tf.random.uniform([batch_size, num_writes, memory_size])
    reset_weights = tf.random.uniform([batch_size, num_writes, word_size])
    writer = write.erase(mem, write_address, reset_weights)
    self.assertTrue(writer.shape.as_list(),
                    [batch_size, memory_size, word_size])

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag505')" href="javascript:;">
sonnet-2.0.0/sonnet/src/nets/dnc/write_test.py: 178-190
</a>
<div class="mid" id="frag505" style="display:none"><pre>
  def testShape(self):
    batch_size = 4
    num_writes = 2
    memory_size = 5
    word_size = 3

    mem = tf.random.uniform([batch_size, memory_size, word_size])
    write_address = tf.random.uniform([batch_size, num_writes, memory_size])
    values = tf.random.uniform([batch_size, num_writes, word_size])
    writer = write.additive_write(mem, write_address, values)
    self.assertAllEqual(writer.shape.as_list(),
                        [batch_size, memory_size, word_size])

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 9:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag626')" href="javascript:;">
sonnet-2.0.0/sonnet/src/recurrent_test.py: 70-83
</a>
<div class="mid" id="frag626" style="display:none"><pre>
  def testInitialization(self):
    core = recurrent.VanillaRNN(
        hidden_size=self.hidden_size,
        w_i_init=initializers.Ones(),
        w_h_init=initializers.Ones(),
        b_init=initializers.Ones())
    inputs = tf.random.uniform([self.batch_size, self.input_size])
    prev_state = core.initial_state(self.batch_size)
    core(inputs, prev_state)

    for v in core.variables:
      self.assertAllClose(self.evaluate(v), self.evaluate(tf.ones_like(v)))


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag654')" href="javascript:;">
sonnet-2.0.0/sonnet/src/recurrent_test.py: 486-499
</a>
<div class="mid" id="frag654" style="display:none"><pre>
  def testInitialization(self):
    core = recurrent.GRU(
        hidden_size=self.hidden_size,
        w_i_init=initializers.Ones(),
        w_h_init=initializers.Ones(),
        b_init=initializers.Ones())
    inputs = tf.random.uniform([self.batch_size, self.input_size])
    prev_state = core.initial_state(self.batch_size)
    core(inputs, prev_state)

    for v in core.variables:
      self.assertAllClose(self.evaluate(v), self.evaluate(tf.ones_like(v)))


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 10:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag728')" href="javascript:;">
sonnet-2.0.0/sonnet/src/mixed_precision_test.py: 198-212
</a>
<div class="mid" id="frag728" style="display:none"><pre>
  def test_function_create_module_eligible(self, test_class):
    mixed_precision.enable(tf.float16)

    @mixed_precision.modes([tf.float32, tf.float16])
    def model():
      x = tf.Variable([[1., 9.], [8., 9.]])
      d = test_class(x)
      d.check_type = mixed_precision.modes([tf.float32, tf.float16])(
          d.check_type)

      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
      self.assertEqual(d.check_type(x, tf.float16).dtype, tf.float32)

    model()

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag730')" href="javascript:;">
sonnet-2.0.0/sonnet/src/mixed_precision_test.py: 213-227
</a>
<div class="mid" id="frag730" style="display:none"><pre>
  def test_function_create_module_ineligible(self, test_class):
    mixed_precision.enable(tf.float16)

    @mixed_precision.modes([tf.float32, tf.float16])
    def model():
      x = tf.Variable([[1., 9.], [8., 9.]])
      d = test_class(x)
      d.check_type = mixed_precision.modes([tf.float32, tf.bfloat16])(
          d.check_type)

      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)

    model()

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 11:</b> &nbsp; 3 fragments, nominal size 25 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag889')" href="javascript:;">
sonnet-2.0.0/sonnet/src/conv_transpose.py: 197-250
</a>
<div class="mid" id="frag889" style="display:none"><pre>
  def __init__(self,
               output_channels: int,
               kernel_shape: Union[int, Sequence[int]],
               output_shape: Optional[types.ShapeLike] = None,
               stride: Union[int, Sequence[int]] = 1,
               rate: Union[int, Sequence[int]] = 1,
               padding: Text = "SAME",
               with_bias: bool = True,
               w_init: Optional[initializers.Initializer] = None,
               b_init: Optional[initializers.Initializer] = None,
               data_format: Text = "NWC",
               name: Optional[Text] = None):
    """Constructs a `Conv1DTranspose` module.

    Args:
      output_channels: Number of output channels.
      kernel_shape: Sequence of integers (of length 1), or an integer
        representing kernel shape. `kernel_shape` will be expanded to define a
        kernel size in all dimensions.
      output_shape: Output shape of the spatial dimensions of a transpose
        convolution. Can be either an integer or an iterable of integers or
        `Dimension`s, or a `TensorShape` (of length 1). If a `None` value is
        given, a default shape is automatically calculated.
      stride: Sequence of integers (of length 1), or an integer. `stride` will
        be expanded to define stride in all dimensions.
      rate: Sequence of integers (of length 1), or integer that is used to
        define dilation rate in all dimensions. 1 corresponds to standard 1D
        convolution, `rate &gt; 1` corresponds to dilated convolution.
      padding: Padding algorithm, either "SAME" or "VALID".
      with_bias: Boolean, whether to include bias parameters. Default `True`.
      w_init: Optional initializer for the weights. By default the weights are
        initialized truncated random normal values with a standard deviation of
        `1 / sqrt(input_feature_size)`, which is commonly used when the
        inputs are zero centered (see https://arxiv.org/abs/1502.03167v3).
      b_init: Optional initializer for the bias. By default the bias is
        initialized to zero.
      data_format: The data format of the input.
      name: Name of the module.
    """
    super(Conv1DTranspose, self).__init__(
        num_spatial_dims=1,
        output_channels=output_channels,
        kernel_shape=kernel_shape,
        output_shape=output_shape,
        stride=stride,
        rate=rate,
        padding=padding,
        with_bias=with_bias,
        w_init=w_init,
        b_init=b_init,
        data_format=data_format,
        name=name)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag891')" href="javascript:;">
sonnet-2.0.0/sonnet/src/conv_transpose.py: 311-362
</a>
<div class="mid" id="frag891" style="display:none"><pre>
  def __init__(self,
               output_channels: int,
               kernel_shape: Union[int, Sequence[int]],
               output_shape: Optional[types.ShapeLike] = None,
               stride: Union[int, Sequence[int]] = 1,
               rate: Union[int, Sequence[int]] = 1,
               padding: Text = "SAME",
               with_bias: bool = True,
               w_init: Optional[initializers.Initializer] = None,
               b_init: Optional[initializers.Initializer] = None,
               data_format: Text = "NDHWC",
               name: Optional[Text] = None):
    """Constructs a `Conv3DTranspose` module.

    Args:
      output_channels: An integer, The number of output channels.
      kernel_shape: Sequence of integers (of length 3), or an integer
        representing kernel shape. `kernel_shape` will be expanded to define a
        kernel size in all dimensions.
      output_shape: Output shape of the spatial dimensions of a transpose
        convolution. Can be either an integer or an iterable of integers or
        `Dimension`s, or a `TensorShape` (of length 3). If a None value is
        given, a default shape is automatically calculated.
      stride: Sequence of integers (of length 3), or an integer. `stride` will
        be expanded to define stride in all dimensions.
      rate: Sequence of integers (of length 3), or integer that is used to
        define dilation rate in all dimensions. 1 corresponds to standard 3D
        convolution, `rate &gt; 1` corresponds to dilated convolution.
      padding: Padding algorithm, either "SAME" or "VALID".
      with_bias: Boolean, whether to include bias parameters. Default `True`.
      w_init: Optional initializer for the weights. By default the weights are
        initialized truncated random normal values with a standard deviation of
        `1 / sqrt(input_feature_size)`, which is commonly used when the
        inputs are zero centered (see https://arxiv.org/abs/1502.03167v3).
      b_init: Optional initializer for the bias. By default the bias is
        initialized to zero.
      data_format: The data format of the input.
      name: Name of the module.
    """
    super(Conv3DTranspose, self).__init__(
        num_spatial_dims=3,
        output_channels=output_channels,
        kernel_shape=kernel_shape,
        output_shape=output_shape,
        stride=stride,
        rate=rate,
        padding=padding,
        with_bias=with_bias,
        w_init=w_init,
        b_init=b_init,
        data_format=data_format,
        name=name)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag890')" href="javascript:;">
sonnet-2.0.0/sonnet/src/conv_transpose.py: 254-307
</a>
<div class="mid" id="frag890" style="display:none"><pre>
  def __init__(self,
               output_channels: int,
               kernel_shape: Union[int, Sequence[int]],
               output_shape: Optional[types.ShapeLike] = None,
               stride: Union[int, Sequence[int]] = 1,
               rate: Union[int, Sequence[int]] = 1,
               padding: Text = "SAME",
               with_bias: bool = True,
               w_init: Optional[initializers.Initializer] = None,
               b_init: Optional[initializers.Initializer] = None,
               data_format: Text = "NHWC",
               name: Optional[Text] = None):
    """Constructs a `Conv2DTranspose` module.

    Args:
      output_channels: An integer, The number of output channels.
      kernel_shape: Sequence of integers (of length 2), or an integer
        representing kernel shape. `kernel_shape` will be expanded to define a
        kernel size in all dimensions.
      output_shape: Output shape of the spatial dimensions of a transpose
        convolution. Can be either an integer or an iterable of integers or
        `Dimension`s, or a `TensorShape` (of length 2). If a `None` value is
        given, a default shape is automatically calculated.
      stride: Sequence of integers (of length 2), or an integer. `stride` will
        be expanded to define stride in all dimensions.
      rate: Sequence of integers (of length 2), or integer that is used to
        define dilation rate in all dimensions. 1 corresponds to standard 2D
        convolution, `rate &gt; 1` corresponds to dilated convolution.
      padding: Padding algorithm, either "SAME" or "VALID".
      with_bias: Boolean, whether to include bias parameters. Default `True`.
      w_init: Optional initializer for the weights. By default the weights are
        initialized truncated random normal values with a standard deviation of
        `1 / sqrt(input_feature_size)`, which is commonly used when the
        inputs are zero centered (see https://arxiv.org/abs/1502.03167v3).
      b_init: Optional initializer for the bias. By default the bias is
        initialized to zero.
      data_format: The data format of the input.
      name: Name of the module.
    """
    super(Conv2DTranspose, self).__init__(
        num_spatial_dims=2,
        output_channels=output_channels,
        kernel_shape=kernel_shape,
        output_shape=output_shape,
        stride=stride,
        rate=rate,
        padding=padding,
        with_bias=with_bias,
        w_init=w_init,
        b_init=b_init,
        data_format=data_format,
        name=name)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<script language="JavaScript">
function ShowHide(divId) { 
    if(document.getElementById(divId).style.display == 'none') {
        document.getElementById(divId).style.display='block';
    } else { 
        document.getElementById(divId).style.display = 'none';
    } 
}
</script>
</body>
</html>
