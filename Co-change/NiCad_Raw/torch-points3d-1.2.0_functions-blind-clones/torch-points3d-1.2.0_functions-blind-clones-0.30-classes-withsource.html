<html>
<head>
    <title>NiCad6 Clone Report</title>
    <style type="text/css">
        body {font-family:sans-serif;}
        table {background-color:white; border:0px; padding:0px; border-spacing:4px; width:auto; margin-left:30px; margin-right:auto;}
        td {background-color:rgba(192,212,238,0.8); border:0px; padding:8px; width:auto; vertical-align:top; border-radius:8px}
        pre {background-color:white; padding:4px;}
        a {color:darkblue;}
    </style>
</head>
<body>
<h2>NiCad6 Clone Report</h2>
<table>
<tr style="font-size:14pt">
<td><b>System:</b> &nbsp; torch-points3d-1.2.0</td>
<td><b>Clone pairs:</b> &nbsp; 118</td>
<td><b>Clone classes:</b> &nbsp; 45</td>
</tr>
<tr style="font-size:12pt">
<td style="background-color:white">Clone type: &nbsp; 3-2</td>
<td style="background-color:white">Granularity: &nbsp; functions-blind</td>
<td style="background-color:white">Max diff threshold: &nbsp; 30%</td>
<td style="background-color:white">Clone size: &nbsp; 10 - 2500 lines</td>
<td style="background-color:white">Total functions-blind: &nbsp; 1377</td>
</tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 1:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 78%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag42')" href="javascript:;">
torch-points3d-1.2.0/scripts/test_registration_scripts/save_feature.py: 98-133
</a>
<div class="mid" id="frag42" style="display:none"><pre>
def main(cfg):
    OmegaConf.set_struct(cfg, False)

    # Get device
    device = torch.device("cuda" if (torch.cuda.is_available() and cfg.training.cuda) else "cpu")
    log.info("DEVICE : {}".format(device))

    # Enable CUDNN BACKEND
    torch.backends.cudnn.enabled = cfg.training.enable_cudnn

    # Checkpoint
    checkpoint = ModelCheckpoint(cfg.training.checkpoint_dir, cfg.model_name, cfg.training.weight_name, strict=True)

    # Setup the dataset config
    # Generic config

    dataset = instantiate_dataset(cfg.data)
    model = checkpoint.create_model(dataset, weight_name=cfg.training.weight_name)
    log.info(model)
    log.info("Model size = %i", sum(param.numel() for param in model.parameters() if param.requires_grad))

    log.info(dataset)

    model.eval()
    if cfg.enable_dropout:
        model.enable_dropout_in_eval()
    model = model.to(device)

    # Run training / evaluation
    output_path = os.path.join(cfg.training.checkpoint_dir, cfg.data.name, "features")
    if not os.path.exists(output_path):
        os.makedirs(output_path, exist_ok=True)

    run(model, dataset, device, output_path, cfg)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag45')" href="javascript:;">
torch-points3d-1.2.0/scripts/test_registration_scripts/evaluate.py: 178-208
</a>
<div class="mid" id="frag45" style="display:none"><pre>
def main(cfg):
    OmegaConf.set_struct(cfg, False)

    # Get device
    device = torch.device("cuda" if (torch.cuda.is_available() and cfg.training.cuda) else "cpu")
    log.info("DEVICE : {}".format(device))

    # Enable CUDNN BACKEND
    torch.backends.cudnn.enabled = cfg.training.enable_cudnn

    # Checkpoint
    checkpoint = ModelCheckpoint(cfg.training.checkpoint_dir, cfg.model_name, cfg.training.weight_name, strict=True)

    # Setup the dataset config
    # Generic config

    dataset = instantiate_dataset(cfg.data)
    model = checkpoint.create_model(dataset, weight_name=cfg.training.weight_name)
    log.info(model)
    log.info("Model size = %i", sum(param.numel() for param in model.parameters() if param.requires_grad))

    log.info(dataset)

    model.eval()
    if cfg.enable_dropout:
        model.enable_dropout_in_eval()
    model = model.to(device)

    run(model, dataset, device, cfg)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 2:</b> &nbsp; 2 fragments, nominal size 17 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag49')" href="javascript:;">
torch-points3d-1.2.0/scripts/test_registration_scripts/misc.py: 4-24
</a>
<div class="mid" id="frag49" style="display:none"><pre>
def read_gt_log(path):
    """
    read the gt.log of evaluation set of 3DMatch or ETH Dataset and parse it.
    """
    list_pair = []
    list_mat = []
    with open(path, "r") as f:
        all_mat = f.readlines()
    mat = np.zeros((4, 4))
    for i in range(len(all_mat)):
        if i % 5 == 0:
            if i != 0:
                list_mat.append(mat)
            mat = np.zeros((4, 4))
            list_pair.append(list(map(int, all_mat[i].split("\t")[:-1])))
        else:
            line = all_mat[i].split("\t")

            mat[i % 5 - 1] = np.asarray(line[:4], dtype=np.float)
    list_mat.append(mat)
    return list_pair, list_mat
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag50')" href="javascript:;">
torch-points3d-1.2.0/scripts/test_registration_scripts/descriptor_matcher.py: 17-39
</a>
<div class="mid" id="frag50" style="display:none"><pre>
def read_gt_log(path):
    """
    read the gt.log of evaluation set of 3DMatch or ETH Dataset and parse it.
    """
    list_pair = []
    list_mat = []
    with open(path, "r") as f:
        all_mat = f.readlines()
    mat = np.zeros((4, 4))
    for i in range(len(all_mat)):
        if i % 5 == 0:
            if i != 0:
                list_mat.append(mat)
            mat = np.zeros((4, 4))
            list_pair.append(list(map(int, all_mat[i].split("\t")[:-1])))
        else:
            line = all_mat[i].split("\t")

            mat[i % 5 - 1] = np.asarray(line[:4], dtype=np.float)
    list_mat.append(mat)
    return list_pair, list_mat


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 3:</b> &nbsp; 6 fragments, nominal size 15 lines, similarity 73%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag88')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/applications/rsconv.py: 122-148
</a>
<div class="mid" id="frag88" style="display:none"><pre>
    def forward(self, data, *args, **kwargs):
        """ This method does a forward on the Unet

        Parameters:
        -----------
        data
            A dictionary that contains the data itself and its metadata information. Should contain
                x -- Features [B, N, C]
                pos -- Points [B, N, 3]
        """
        self._set_input(data)
        data = self.input
        stack_down = [data]
        for i in range(len(self.down_modules) - 1):
            data = self.down_modules[i](data)
            stack_down.append(data)
        data = self.down_modules[-1](data)

        if not isinstance(self.inner_modules[0], Identity):
            stack_down.append(data)
            data = self.inner_modules[0](data)

        if self.has_mlp_head:
            data.x = self.mlp(data.x)
        return data


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag131')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/applications/sparseconv3d.py: 170-206
</a>
<div class="mid" id="frag131" style="display:none"><pre>
    def forward(self, data, *args, **kwargs):
        """Run forward pass.
        Input --- D1 -- D2 -- D3 -- U1 -- U2 -- output
                   |      |_________|     |
                   |______________________|

        Parameters
        -----------
        data
            A SparseTensor that contains the data itself and its metadata information. Should contain
                F -- Features [N, C]
                coords -- Coords [N, 4]

        Returns
        --------
        data:
            - pos [N, 3] (coords or real pos if xyz is in data)
            - x [N, output_nc]
            - batch [N]
        """
        self._set_input(data)
        data = self.input
        stack_down = []
        for i in range(len(self.down_modules) - 1):
            data = self.down_modules[i](data)
            stack_down.append(data)

        data = self.down_modules[-1](data)
        stack_down.append(None)
        # TODO : Manage the inner module
        for i in range(len(self.up_modules)):
            data = self.up_modules[i](data, stack_down.pop())

        out = Batch(x=data.F, pos=self.xyz).to(self.device)
        if self.has_mlp_head:
            out.x = self.mlp(out.x)
        return out
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag139')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/applications/pointnet2.py: 127-152
</a>
<div class="mid" id="frag139" style="display:none"><pre>
    def forward(self, data, *args, **kwargs):
        """
        Parameters:
        -----------
        data
            A dictionary that contains the data itself and its metadata information. Should contain
                x -- Features [B, N, C]
                pos -- Points [B, N, 3]
        """
        self._set_input(data)
        data = self.input
        stack_down = [data]
        for i in range(len(self.down_modules) - 1):
            data = self.down_modules[i](data)
            stack_down.append(data)
        data = self.down_modules[-1](data)

        if not isinstance(self.inner_modules[0], Identity):
            stack_down.append(data)
            data = self.inner_modules[0](data)

        if self.has_mlp_head:
            data.x = self.mlp(data.x)
        return data


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag100')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/applications/minkowski.py: 160-196
</a>
<div class="mid" id="frag100" style="display:none"><pre>
    def forward(self, data, *args, **kwargs):
        """Run forward pass.
        Input --- D1 -- D2 -- D3 -- U1 -- U2 -- output
                   |      |_________|     |
                   |______________________|

        Parameters
        -----------
        data
            A SparseTensor that contains the data itself and its metadata information. Should contain
                F -- Features [N, C]
                coords -- Coords [N, 4]

        Returns
        --------
        data:
            - pos [N, 3] (coords or real pos if xyz is in data)
            - x [N, output_nc]
            - batch [N]
        """
        self._set_input(data)
        data = self.input
        stack_down = []
        for i in range(len(self.down_modules) - 1):
            data = self.down_modules[i](data)
            stack_down.append(data)

        data = self.down_modules[-1](data)
        stack_down.append(None)
        # TODO : Manage the inner module
        for i in range(len(self.up_modules)):
            data = self.up_modules[i](data, stack_down.pop())

        out = Batch(x=data.F, pos=self.xyz, batch=data.C[:, 0])
        if self.has_mlp_head:
            out.x = self.mlp(out.x)
        return out
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag120')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/applications/kpconv.py: 121-154
</a>
<div class="mid" id="frag120" style="display:none"><pre>
    def forward(self, data, *args, **kwargs):
        """
        Parameters
        -----------
        data:
            A dictionary that contains the data itself and its metadata information. Should contain
            - pos [N, 3]
            - x [N, C]
            - multiscale (optional) precomputed data for the down convolutions
            - upsample (optional) precomputed data for the up convolutions

        Returns
        --------
        data:
            - pos [1, 3] - Dummy pos
            - x [1, output_nc]
        """
        self._set_input(data)
        data = self.input
        stack_down = [data]
        for i in range(len(self.down_modules) - 1):
            data = self.down_modules[i](data)
            stack_down.append(data)
        data = self.down_modules[-1](data)

        if not isinstance(self.inner_modules[0], Identity):
            stack_down.append(data)
            data = self.inner_modules[0](data)

        if self.has_mlp_head:
            data.x = self.mlp(data.x)
        return data


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag140')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/applications/pointnet2.py: 154-191
</a>
<div class="mid" id="frag140" style="display:none"><pre>
    def forward(self, data, *args, **kwargs):
        """ This method does a forward on the Unet assuming symmetrical skip connections
        Input --- D1 -- D2 -- I -- U1 -- U2 -- U3 -- output
           |       |      |________|      |    |
           |       |______________________|    |
           |___________________________________|

        Parameters:
        -----------
        data
            A dictionary that contains the data itself and its metadata information. Should contain
                x -- Features [B, N, C]
                pos -- Points [B, N, 3]
        """
        self._set_input(data)
        data = self.input
        stack_down = [data]
        for i in range(len(self.down_modules) - 1):
            data = self.down_modules[i](data)
            stack_down.append(data)
        data = self.down_modules[-1](data)

        if not isinstance(self.inner_modules[0], Identity):
            stack_down.append(data)
            data = self.inner_modules[0](data)

        sampling_ids = self._collect_sampling_ids(stack_down)

        for i in range(len(self.up_modules)):
            data = self.up_modules[i]((data, stack_down.pop()))

        for key, value in sampling_ids.items():
            setattr(data, key, value)

        if self.has_mlp_head:
            data.x = self.mlp(data.x)

        return data
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 4:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 83%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag94')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/applications/minkowski.py: 82-95
</a>
<div class="mid" id="frag94" style="display:none"><pre>
    def __init__(self, model_config, model_type, dataset, modules, *args, **kwargs):
        super(BaseMinkowski, self).__init__(model_config, model_type, dataset, modules)
        self.weight_initialization()
        default_output_nc = kwargs.get("default_output_nc", None)
        if not default_output_nc:
            default_output_nc = extract_output_nc(model_config)

        self._output_nc = default_output_nc
        self._has_mlp_head = False
        if "output_nc" in kwargs:
            self._has_mlp_head = True
            self._output_nc = kwargs["output_nc"]
            self.mlp = MLP([default_output_nc, self.output_nc], activation=torch.nn.LeakyReLU(0.2), bias=False)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag125')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/applications/sparseconv3d.py: 94-107
</a>
<div class="mid" id="frag125" style="display:none"><pre>
    def __init__(self, model_config, model_type, dataset, modules, *args, **kwargs):
        super().__init__(model_config, model_type, dataset, modules)
        self.weight_initialization()
        default_output_nc = kwargs.get("default_output_nc", None)
        if not default_output_nc:
            default_output_nc = extract_output_nc(model_config)

        self._output_nc = default_output_nc
        self._has_mlp_head = False
        if "output_nc" in kwargs:
            self._has_mlp_head = True
            self._output_nc = kwargs["output_nc"]
            self.mlp = MLP([default_output_nc, self.output_nc], activation=torch.nn.ReLU(), bias=False)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 5:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag99')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/applications/minkowski.py: 130-158
</a>
<div class="mid" id="frag99" style="display:none"><pre>
    def forward(self, data, *args, **kwargs):
        """
        Parameters:
        -----------
        data
            A SparseTensor that contains the data itself and its metadata information. Should contain
                F -- Features [N, C]
                coords -- Coords [N, 4]

        Returns
        --------
        data:
            - x [1, output_nc]

        """
        self._set_input(data)
        data = self.input
        for i in range(len(self.down_modules)):
            data = self.down_modules[i](data)

        out = Batch(x=data.F, batch=data.C[:, 0].long().to(data.F.device))
        if not isinstance(self.inner_modules[0], Identity):
            out = self.inner_modules[0](out)

        if self.has_mlp_head:
            out.x = self.mlp(out.x)
        return out


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag130')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/applications/sparseconv3d.py: 140-168
</a>
<div class="mid" id="frag130" style="display:none"><pre>
    def forward(self, data, *args, **kwargs):
        """
        Parameters:
        -----------
        data
            A SparseTensor that contains the data itself and its metadata information. Should contain
                F -- Features [N, C]
                coords -- Coords [N, 4]

        Returns
        --------
        data:
            - x [1, output_nc]

        """
        self._set_input(data)
        data = self.input
        for i in range(len(self.down_modules)):
            data = self.down_modules[i](data)

        out = Batch(x=data.F, batch=data.C[:, 0].long().to(data.F.device))
        if not isinstance(self.inner_modules[0], Identity):
            out = self.inner_modules[0](out)

        if self.has_mlp_head:
            out.x = self.mlp(out.x)
        return out


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 6:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 85%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag116')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/applications/kpconv.py: 76-90
</a>
<div class="mid" id="frag116" style="display:none"><pre>
    def __init__(self, model_config, model_type, dataset, modules, *args, **kwargs):
        super(BaseKPConv, self).__init__(model_config, model_type, dataset, modules)
        try:
            default_output_nc = extract_output_nc(model_config)
        except:
            default_output_nc = -1
            log.warning("Could not resolve number of output channels")

        self._output_nc = default_output_nc
        self._has_mlp_head = False
        if "output_nc" in kwargs:
            self._has_mlp_head = True
            self._output_nc = kwargs["output_nc"]
            self.mlp = MLP([default_output_nc, self.output_nc], activation=torch.nn.LeakyReLU(0.2), bias=False)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag135')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/applications/pointnet2.py: 89-105
</a>
<div class="mid" id="frag135" style="display:none"><pre>
    def __init__(self, model_config, model_type, dataset, modules, *args, **kwargs):
        super(BasePointnet2, self).__init__(model_config, model_type, dataset, modules)

        try:
            default_output_nc = extract_output_nc(model_config)
        except:
            default_output_nc = -1
            log.warning("Could not resolve number of output channels")

        self._has_mlp_head = False
        self._output_nc = default_output_nc
        if "output_nc" in kwargs:
            self._has_mlp_head = True
            self._output_nc = kwargs["output_nc"]
            self.mlp = Seq()
            self.mlp.append(Conv1D(default_output_nc, self._output_nc, bn=True, bias=False))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 7:</b> &nbsp; 3 fragments, nominal size 11 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag124')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/applications/sparseconv3d.py: 77-90
</a>
<div class="mid" id="frag124" style="display:none"><pre>
    def _build_encoder(self):
        if self._config:
            model_config = self._config
        else:
            path_to_model = os.path.join(
                PATH_TO_CONFIG,
                "encoder_{}.yaml".format(self.num_layers),
            )
            model_config = OmegaConf.load(path_to_model)
        ModelFactory.resolve_model(model_config, self.num_features, self._kwargs)
        modules_lib = sys.modules[__name__]
        return SparseConv3dEncoder(model_config, None, None, modules_lib, **self.kwargs)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag134')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/applications/pointnet2.py: 71-84
</a>
<div class="mid" id="frag134" style="display:none"><pre>
    def _build_encoder(self):
        if self._config:
            model_config = self._config
        else:
            path_to_model = os.path.join(
                PATH_TO_CONFIG,
                "encoder_{}_{}.yaml".format(self.num_layers, "ms" if self.kwargs["multiscale"] else "ss"),
            )
            model_config = OmegaConf.load(path_to_model)
        ModelFactory.resolve_model(model_config, self.num_features, self._kwargs)
        modules_lib = sys.modules[__name__]
        return PointNet2Encoder(model_config, None, None, modules_lib, **self.kwargs)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag133')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/applications/pointnet2.py: 59-70
</a>
<div class="mid" id="frag133" style="display:none"><pre>
    def _build_unet(self):
        if self._config:
            model_config = self._config
        else:
            path_to_model = os.path.join(
                PATH_TO_CONFIG, "unet_{}_{}.yaml".format(self.num_layers, "ms" if self.kwargs["multiscale"] else "ss")
            )
            model_config = OmegaConf.load(path_to_model)
        ModelFactory.resolve_model(model_config, self.num_features, self._kwargs)
        modules_lib = sys.modules[__name__]
        return PointNet2Unet(model_config, None, None, modules_lib, **self.kwargs)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 8:</b> &nbsp; 3 fragments, nominal size 28 lines, similarity 89%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag160')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/models/registration/spconv3d.py: 11-47
</a>
<div class="mid" id="frag160" style="display:none"><pre>
    def __init__(self, option, model_type, dataset, modules):
        FragmentBaseModel.__init__(self, option)
        self.mode = option.loss_mode
        self.normalize_feature = option.normalize_feature
        self.loss_names = ["loss_reg", "loss"]
        self.metric_loss_module, self.miner_module = FragmentBaseModel.get_metric_loss_and_miner(
            getattr(option, "metric_loss", None), getattr(option, "miner", None)
        )
        # Unet
        self.backbone = SparseConv3d(
            "unet", dataset.feature_dimension, config=option.backbone, backend=option.get("backend", "minkowski")
        )
        # Last Layer
        if option.mlp_cls is not None:
            last_mlp_opt = option.mlp_cls
            in_feat = last_mlp_opt.nn[0]
            self.FC_layer = Seq()
            for i in range(1, len(last_mlp_opt.nn)):
                self.FC_layer.append(
                    str(i),
                    Sequential(
                        *[
                            Linear(in_feat, last_mlp_opt.nn[i], bias=False),
                            FastBatchNorm1d(last_mlp_opt.nn[i], momentum=last_mlp_opt.bn_momentum),
                            LeakyReLU(0.2),
                        ]
                    ),
                )
                in_feat = last_mlp_opt.nn[i]

            if last_mlp_opt.dropout:
                self.FC_layer.append(Dropout(p=last_mlp_opt.dropout))

            self.FC_layer.append(Linear(in_feat, in_feat, bias=False))
        else:
            self.FC_layer = torch.nn.Identity()

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag171')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/models/registration/minkowski.py: 103-136
</a>
<div class="mid" id="frag171" style="display:none"><pre>
    def __init__(self, option, model_type, dataset, modules):
        UnwrappedUnetBasedModel.__init__(self, option, model_type, dataset, modules)
        self.mode = option.loss_mode
        self.normalize_feature = option.normalize_feature
        self.loss_names = ["loss_reg", "loss"]
        self.metric_loss_module, self.miner_module = FragmentBaseModel.get_metric_loss_and_miner(
            getattr(option, "metric_loss", None), getattr(option, "miner", None)
        )
        # Last Layer

        if option.mlp_cls is not None:
            last_mlp_opt = option.mlp_cls
            in_feat = last_mlp_opt.nn[0]
            self.FC_layer = Seq()
            for i in range(1, len(last_mlp_opt.nn)):
                self.FC_layer.append(
                    str(i),
                    Sequential(
                        *[
                            Linear(in_feat, last_mlp_opt.nn[i], bias=False),
                            FastBatchNorm1d(last_mlp_opt.nn[i], momentum=last_mlp_opt.bn_momentum),
                            LeakyReLU(0.2),
                        ]
                    ),
                )
                in_feat = last_mlp_opt.nn[i]

            if last_mlp_opt.dropout:
                self.FC_layer.append(Dropout(p=last_mlp_opt.dropout))

            self.FC_layer.append(Linear(in_feat, in_feat, bias=False))
        else:
            self.FC_layer = torch.nn.Identity()

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag165')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/models/registration/minkowski.py: 16-49
</a>
<div class="mid" id="frag165" style="display:none"><pre>
    def __init__(self, option, model_type, dataset, modules):
        FragmentBaseModel.__init__(self, option)
        self.mode = option.loss_mode
        self.normalize_feature = option.normalize_feature
        self.loss_names = ["loss_reg", "loss"]
        self.metric_loss_module, self.miner_module = FragmentBaseModel.get_metric_loss_and_miner(
            getattr(option, "metric_loss", None), getattr(option, "miner", None)
        )
        # Last Layer

        if option.mlp_cls is not None:
            last_mlp_opt = option.mlp_cls
            in_feat = last_mlp_opt.nn[0]
            self.FC_layer = Seq()
            for i in range(1, len(last_mlp_opt.nn)):
                self.FC_layer.append(
                    str(i),
                    Sequential(
                        *[
                            Linear(in_feat, last_mlp_opt.nn[i], bias=False),
                            FastBatchNorm1d(last_mlp_opt.nn[i], momentum=last_mlp_opt.bn_momentum),
                            LeakyReLU(0.2),
                        ]
                    ),
                )
                in_feat = last_mlp_opt.nn[i]

            if last_mlp_opt.dropout:
                self.FC_layer.append(Dropout(p=last_mlp_opt.dropout))

            self.FC_layer.append(Linear(in_feat, in_feat, bias=False))
        else:
            self.FC_layer = torch.nn.Identity()

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 9:</b> &nbsp; 2 fragments, nominal size 23 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag205')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/models/segmentation/rsconv.py: 18-48
</a>
<div class="mid" id="frag205" style="display:none"><pre>
    def __init__(self, option, model_type, dataset, modules):
        # call the initialization method of UnwrappedUnetBasedModel
        UnwrappedUnetBasedModel.__init__(self, option, model_type, dataset, modules)
        self._num_classes = dataset.num_classes
        self._weight_classes = dataset.weight_classes
        self._use_category = getattr(option, "use_category", False)
        if self._use_category:
            if not dataset.class_to_segments:
                raise ValueError(
                    "The dataset needs to specify a class_to_segments property when using category information for segmentation"
                )
            self._num_categories = len(dataset.class_to_segments.keys())
            log.info("Using category information for the predictions with %i categories", self._num_categories)
        else:
            self._num_categories = 0

        # Last MLP
        last_mlp_opt = option.mlp_cls

        self.FC_layer = Seq()
        last_mlp_opt.nn[0] += self._num_categories
        for i in range(1, len(last_mlp_opt.nn)):
            self.FC_layer.append(Conv1D(last_mlp_opt.nn[i - 1], last_mlp_opt.nn[i], bn=True, bias=False))
        if last_mlp_opt.dropout:
            self.FC_layer.append(torch.nn.Dropout(p=last_mlp_opt.dropout))

        self.FC_layer.append(Conv1D(last_mlp_opt.nn[-1], self._num_classes, activation=None, bias=True, bn=False))
        self.loss_names = ["loss_seg"]

        self.visual_names = ["data_visual"]

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag242')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/models/segmentation/pointnet2.py: 34-64
</a>
<div class="mid" id="frag242" style="display:none"><pre>
    def __init__(self, option, model_type, dataset, modules):
        # call the initialization method of UnetBasedModel
        UnetBasedModel.__init__(self, option, model_type, dataset, modules)
        self._num_classes = dataset.num_classes
        self._weight_classes = dataset.weight_classes
        self._use_category = getattr(option, "use_category", False)
        if self._use_category:
            if not dataset.class_to_segments:
                raise ValueError(
                    "The dataset needs to specify a class_to_segments property when using category information for segmentation"
                )
            self._num_categories = len(dataset.class_to_segments.keys())
            log.info("Using category information for the predictions with %i categories", self._num_categories)
        else:
            self._num_categories = 0

        # Last MLP
        last_mlp_opt = option.mlp_cls

        self.FC_layer = Seq()
        last_mlp_opt.nn[0] += self._num_categories
        for i in range(1, len(last_mlp_opt.nn)):
            self.FC_layer.append(Conv1D(last_mlp_opt.nn[i - 1], last_mlp_opt.nn[i], bn=True, bias=False))
        if last_mlp_opt.dropout:
            self.FC_layer.append(torch.nn.Dropout(p=last_mlp_opt.dropout))

        self.FC_layer.append(Conv1D(last_mlp_opt.nn[-1], self._num_classes, activation=None, bias=True, bn=False))
        self.loss_names = ["loss_seg"]

        self.visual_names = ["data_visual"]

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 10:</b> &nbsp; 2 fragments, nominal size 45 lines, similarity 91%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag213')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/models/segmentation/kpconv.py: 23-81
</a>
<div class="mid" id="frag213" style="display:none"><pre>
    def __init__(self, option, model_type, dataset, modules):
        # Extract parameters from the dataset
        self._num_classes = dataset.num_classes
        self._weight_classes = dataset.weight_classes
        self._use_category = getattr(option, "use_category", False)
        if self._use_category:
            if not dataset.class_to_segments:
                raise ValueError(
                    "The dataset needs to specify a class_to_segments property when using category information for segmentation"
                )
            self._class_to_seg = dataset.class_to_segments
            self._num_categories = len(self._class_to_seg)
            log.info("Using category information for the predictions with %i categories", self._num_categories)
        else:
            self._num_categories = 0

        # Assemble encoder / decoder
        UnwrappedUnetBasedModel.__init__(self, option, model_type, dataset, modules)

        # Build final MLP
        last_mlp_opt = option.mlp_cls
        if self._use_category:
            self.FC_layer = MultiHeadClassifier(
                last_mlp_opt.nn[0],
                self._class_to_seg,
                dropout_proba=last_mlp_opt.dropout,
                bn_momentum=last_mlp_opt.bn_momentum,
            )
        else:
            in_feat = last_mlp_opt.nn[0] + self._num_categories
            self.FC_layer = Sequential()
            for i in range(1, len(last_mlp_opt.nn)):
                self.FC_layer.add_module(
                    str(i),
                    Sequential(
                        *[
                            Linear(in_feat, last_mlp_opt.nn[i], bias=False),
                            FastBatchNorm1d(last_mlp_opt.nn[i], momentum=last_mlp_opt.bn_momentum),
                            LeakyReLU(0.2),
                        ]
                    ),
                )
                in_feat = last_mlp_opt.nn[i]

            if last_mlp_opt.dropout:
                self.FC_layer.add_module("Dropout", Dropout(p=last_mlp_opt.dropout))

            self.FC_layer.add_module("Class", Lin(in_feat, self._num_classes, bias=False))
            self.FC_layer.add_module("Softmax", nn.LogSoftmax(-1))
        self.loss_names = ["loss_seg"]

        self.lambda_reg = self.get_from_opt(option, ["loss_weights", "lambda_reg"])
        if self.lambda_reg:
            self.loss_names += ["loss_reg"]

        self.lambda_internal_losses = self.get_from_opt(option, ["loss_weights", "lambda_internal_losses"])

        self.visual_names = ["data_visual"]

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag232')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/models/segmentation/ppnet.py: 23-76
</a>
<div class="mid" id="frag232" style="display:none"><pre>
    def __init__(self, option, model_type, dataset, modules):
        # Extract parameters from the dataset
        self._num_classes = dataset.num_classes
        self._weight_classes = dataset.weight_classes
        self._use_category = getattr(option, "use_category", False)
        if self._use_category:
            if not dataset.class_to_segments:
                raise ValueError(
                    "The dataset needs to specify a class_to_segments property when using category information for segmentation"
                )
            self._class_to_seg = dataset.class_to_segments
            self._num_categories = len(self._class_to_seg)
            log.info("Using category information for the predictions with %i categories", self._num_categories)
        else:
            self._num_categories = 0

        # Assemble encoder / decoder
        UnwrappedUnetBasedModel.__init__(self, option, model_type, dataset, modules)

        # Build final MLP
        last_mlp_opt = option.mlp_cls
        if self._use_category:
            self.FC_layer = MultiHeadClassifier(
                last_mlp_opt.nn[0],
                self._class_to_seg,
                dropout_proba=last_mlp_opt.dropout,
                bn_momentum=last_mlp_opt.bn_momentum,
            )
        else:
            in_feat = last_mlp_opt.nn[0] + self._num_categories
            self.FC_layer = Sequential()
            for i in range(1, len(last_mlp_opt.nn)):
                self.FC_layer.add_module(
                    str(i),
                    Sequential(
                        *[
                            Linear(in_feat, last_mlp_opt.nn[i], bias=False),
                            FastBatchNorm1d(last_mlp_opt.nn[i], momentum=last_mlp_opt.bn_momentum),
                            LeakyReLU(0.2),
                        ]
                    ),
                )
                in_feat = last_mlp_opt.nn[i]

            if last_mlp_opt.dropout:
                self.FC_layer.add_module("Dropout", Dropout(p=last_mlp_opt.dropout))

            self.FC_layer.add_module("Class", Lin(in_feat, self._num_classes, bias=False))
            self.FC_layer.add_module("Softmax", nn.LogSoftmax(-1))
        self.loss_names = ["loss_seg"]

        self.visual_names = ["data_visual"]
        self.init_weights()

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 11:</b> &nbsp; 2 fragments, nominal size 16 lines, similarity 93%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag214')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/models/segmentation/kpconv.py: 82-105
</a>
<div class="mid" id="frag214" style="display:none"><pre>
    def set_input(self, data, device):
        """Unpack input data from the dataloader and perform necessary pre-processing steps.
        Parameters:
            input: a dictionary that contains the data itself and its metadata information.
        """
        data = data.to(device)
        data.x = add_ones(data.pos, data.x, True)

        if isinstance(data, MultiScaleBatch):
            self.pre_computed = data.multiscale
            self.upsample = data.upsample
            del data.upsample
            del data.multiscale
        else:
            self.upsample = None
            self.pre_computed = None

        self.input = data
        self.labels = data.y
        self.batch_idx = data.batch

        if self._use_category:
            self.category = data.category

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag233')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/models/segmentation/ppnet.py: 77-99
</a>
<div class="mid" id="frag233" style="display:none"><pre>
    def set_input(self, data, device):
        """Unpack input data from the dataloader and perform necessary pre-processing steps.
        Parameters:
            input: a dictionary that contains the data itself and its metadata information.
        """
        data = data.to(device)

        if isinstance(data, MultiScaleBatch):
            self.pre_computed = data.multiscale
            self.upsample = data.upsample
            del data.upsample
            del data.multiscale
        else:
            self.upsample = None
            self.pre_computed = None

        self.input = data
        self.labels = data.y
        self.batch_idx = data.batch

        if self._use_category:
            self.category = data.category

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 12:</b> &nbsp; 2 fragments, nominal size 27 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag215')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/models/segmentation/kpconv.py: 106-141
</a>
<div class="mid" id="frag215" style="display:none"><pre>
    def forward(self, *args, **kwargs) -&gt; Any:
        """Run forward pass. This will be called by both functions &lt;optimize_parameters&gt; and &lt;test&gt;."""
        stack_down = []

        data = self.input
        for i in range(len(self.down_modules) - 1):
            data = self.down_modules[i](data, precomputed=self.pre_computed)
            stack_down.append(data)

        data = self.down_modules[-1](data, precomputed=self.pre_computed)
        innermost = False

        if not isinstance(self.inner_modules[0], Identity):
            stack_down.append(data)
            data = self.inner_modules[0](data)
            innermost = True

        for i in range(len(self.up_modules)):
            if i == 0 and innermost:
                data = self.up_modules[i]((data, stack_down.pop()))
            else:
                data = self.up_modules[i]((data, stack_down.pop()), precomputed=self.upsample)

        last_feature = data.x
        if self._use_category:
            self.output = self.FC_layer(last_feature, self.category)
        else:
            self.output = self.FC_layer(last_feature)

        if self.labels is not None:
            self.compute_loss()

        self.data_visual = self.input
        self.data_visual.pred = torch.max(self.output, -1)[1]
        return self.output

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag234')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/models/segmentation/ppnet.py: 100-135
</a>
<div class="mid" id="frag234" style="display:none"><pre>
    def forward(self, *args, **kwargs) -&gt; Any:
        """Run forward pass. This will be called by both functions &lt;optimize_parameters&gt; and &lt;test&gt;."""
        stack_down = []

        data = self.input
        for i in range(len(self.down_modules) - 1):
            data = self.down_modules[i](data, precomputed=self.pre_computed)
            stack_down.append(data)

        data = self.down_modules[-1](data, precomputed=self.pre_computed)
        innermost = False

        if not isinstance(self.inner_modules[0], Identity):
            stack_down.append(data)
            data = self.inner_modules[0](data)
            innermost = True

        for i in range(len(self.up_modules)):
            if i == 0 and innermost:
                data = self.up_modules[i]((data, stack_down.pop()))
            else:
                data = self.up_modules[i]((data, stack_down.pop()), precomputed=self.upsample)

        last_feature = data.x
        if self._use_category:
            self.output = self.FC_layer(last_feature, self.category)
        else:
            self.output = self.FC_layer(last_feature)

        if self.labels is not None:
            self.compute_loss()

        self.data_visual = self.input
        self.data_visual.pred = torch.max(self.output, -1)[1]
        return self.output

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 13:</b> &nbsp; 3 fragments, nominal size 16 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag253')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/models/base_architectures/unet.py: 186-205
</a>
<div class="mid" id="frag253" style="display:none"><pre>
    def _fetch_arguments_from_list(self, opt, index):
        """Fetch the arguments for a single convolution from multiple lists
        of arguments - for models specified in the compact format.
        """
        args = {}
        for o, v in opt.items():
            name = str(o)
            if is_list(v) and len(getattr(opt, o)) &gt; 0:
                if name[-1] == "s" and name not in SPECIAL_NAMES:
                    name = name[:-1]
                v_index = v[index]
                if is_list(v_index):
                    v_index = list(v_index)
                args[name] = v_index
            else:
                if is_list(v):
                    v = list(v)
                args[name] = v
        return args

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag277')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/models/base_architectures/backbone.py: 110-129
</a>
<div class="mid" id="frag277" style="display:none"><pre>
    def _fetch_arguments_from_list(self, opt, index):
        """Fetch the arguments for a single convolution from multiple lists
        of arguments - for models specified in the compact format.
        """
        args = {}
        for o, v in opt.items():
            name = str(o)
            if is_list(v) and len(getattr(opt, o)) &gt; 0:
                if name[-1] == "s" and name not in SPECIAL_NAMES:
                    name = name[:-1]
                v_index = v[index]
                if is_list(v_index):
                    v_index = list(v_index)
                args[name] = v_index
            else:
                if is_list(v):
                    v = list(v)
                args[name] = v
        return args

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag268')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/models/base_architectures/unet.py: 444-463
</a>
<div class="mid" id="frag268" style="display:none"><pre>
    def _fetch_arguments_from_list(self, opt, index):
        """Fetch the arguments for a single convolution from multiple lists
        of arguments - for models specified in the compact format.
        """
        args = {}
        for o, v in opt.items():
            name = str(o)
            if is_list(v) and len(getattr(opt, o)) &gt; 0:
                if name[-1] == "s" and name not in SPECIAL_NAMES:
                    name = name[:-1]
                v_index = v[index]
                if is_list(v_index):
                    v_index = list(v_index)
                args[name] = v_index
            else:
                if is_list(v):
                    v = list(v)
                args[name] = v
        return args

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 14:</b> &nbsp; 2 fragments, nominal size 34 lines, similarity 73%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag345')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/datasets/registration/kitti.py: 23-57
</a>
<div class="mid" id="frag345" style="display:none"><pre>
    def __init__(self, root,
                 mode='train',
                 self_supervised=False,
                 min_size_block=0.3,
                 max_size_block=2,
                 max_dist_overlap=0.01,
                 max_time_distance=3,
                 min_dist=10,
                 transform=None,
                 pre_transform=None,
                 pre_filter=None,
                 is_online_matching=False,
                 num_pos_pairs=1024,
                 ss_transform=None,
                 min_points=300):
        BaseKitti.__init__(self,
                           root,
                           mode,
                           max_dist_overlap,
                           max_time_distance,
                           min_dist,
                           transform,
                           pre_transform,
                           pre_filter)

        self.path_match = osp.join(self.processed_dir, self.mode, "matches")
        self.list_fragment = [f for f in os.listdir(self.path_match) if "matches" in f]
        self.is_online_matching = is_online_matching
        self.num_pos_pairs = num_pos_pairs
        self.self_supervised = self_supervised
        self.min_size_block = min_size_block
        self.max_size_block = max_size_block
        self.ss_transform = ss_transform
        self.min_points = min_points

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag434')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/datasets/registration/modelnet.py: 32-66
</a>
<div class="mid" id="frag434" style="display:none"><pre>
    def __init__(self, root,
                 name_modelnet="10",
                 min_size_block=0.3,
                 max_size_block=2,
                 max_dist_overlap=0.1,
                 train=True,
                 transform=None,
                 pre_transform=None,
                 pre_filter=None,
                 num_pos_pairs=1024,
                 ss_transform=None,
                 min_points=500,
                 use_fps=False
    ):
        SampledModelNet.__init__(self,
                                 root,
                                 name_modelnet,
                                 train,
                                 transform,
                                 pre_transform,
                                 pre_filter)
        self.self_supervised = True # only self supervised is allowed for modelnet
        self.is_online_matching = False
        self.num_pos_pairs = num_pos_pairs
        self.min_size_block = min_size_block
        self.max_size_block = max_size_block
        self.max_dist_overlap = max_dist_overlap
        self.ss_transform = ss_transform
        self.min_points = min_points
        self.train = train
        if(self.train):
            self.name = "train"
        else:
            self.name = "test"

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 15:</b> &nbsp; 4 fragments, nominal size 29 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag388')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/datasets/registration/testkaist.py: 24-53
</a>
<div class="mid" id="frag388" style="display:none"><pre>
    def __init__(self, root,
                 transform=None,
                 pre_transform=None,
                 pre_filter=None,
                 verbose=False,
                 debug=False,
                 num_pos_pairs=200,
                 max_dist_overlap=0.01,
                 self_supervised=False,
                 min_size_block=2,
                 max_size_block=3,
                 min_points=500,
                 ss_transform=None,
                 use_fps=False):
        self.link_pairs = "https://cloud.mines-paristech.fr/index.php/s/4cTpY4CKPAXFGk4/download"
        BasePCRBTest.__init__(self,
                              root=root,
                              transform=transform,
                              pre_transform=pre_transform,
                              pre_filter=pre_filter,
                              verbose=verbose, debug=debug,
                              max_dist_overlap=max_dist_overlap,
                              num_pos_pairs=num_pos_pairs,
                              self_supervised=self_supervised,
                              min_size_block=min_size_block,
                              max_size_block=max_size_block,
                              min_points=min_points,
                              ss_transform=ss_transform,
                              use_fps=use_fps)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag399')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/datasets/registration/testtum.py: 28-57
</a>
<div class="mid" id="frag399" style="display:none"><pre>
    def __init__(self, root,
                 transform=None,
                 pre_transform=None,
                 pre_filter=None,
                 verbose=False,
                 debug=False,
                 num_pos_pairs=200,
                 max_dist_overlap=0.01,
                 self_supervised=False,
                 min_size_block=2,
                 max_size_block=3,
                 min_points=500,
                 ss_transform=None,
                 use_fps=False):
        self.link_pairs = "https://cloud.mines-paristech.fr/index.php/s/yjd20Ih9ExqLlHM/download"
        BasePCRBTest.__init__(self,
                              root=root,
                              transform=transform,
                              pre_transform=pre_transform,
                              pre_filter=pre_filter,
                              verbose=verbose, debug=debug,
                              max_dist_overlap=max_dist_overlap,
                              num_pos_pairs=num_pos_pairs,
                              self_supervised=self_supervised,
                              min_size_block=min_size_block,
                              max_size_block=max_size_block,
                              min_points=min_points,
                              ss_transform=ss_transform,
                              use_fps=use_fps)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag404')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/datasets/registration/testeth.py: 63-92
</a>
<div class="mid" id="frag404" style="display:none"><pre>
    def __init__(self, root,
                 transform=None,
                 pre_transform=None,
                 pre_filter=None,
                 verbose=False,
                 debug=False,
                 num_pos_pairs=200,
                 max_dist_overlap=0.01,
                 self_supervised=False,
                 min_size_block=2,
                 max_size_block=3,
                 min_points=500,
                 ss_transform=None,
                 use_fps=False):
        self.link_pairs = "https://cloud.mines-paristech.fr/index.php/s/aIRBieRybts3kEs/download"
        BasePCRBTest.__init__(self,
                              root=root,
                              transform=transform,
                              pre_transform=pre_transform,
                              pre_filter=pre_filter,
                              verbose=verbose, debug=debug,
                              max_dist_overlap=max_dist_overlap,
                              num_pos_pairs=num_pos_pairs,
                              self_supervised=self_supervised,
                              min_size_block=min_size_block,
                              max_size_block=max_size_block,
                              min_points=min_points,
                              ss_transform=ss_transform,
                              use_fps=use_fps)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag430')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/datasets/registration/testplanetary.py: 36-65
</a>
<div class="mid" id="frag430" style="display:none"><pre>
    def __init__(self, root,
                 transform=None,
                 pre_transform=None,
                 pre_filter=None,
                 verbose=False,
                 debug=False,
                 num_pos_pairs=200,
                 max_dist_overlap=0.01,
                 self_supervised=False,
                 min_size_block=2,
                 max_size_block=3,
                 min_points=500,
                 ss_transform=None,
                 use_fps=False):
        self.link_pairs = "https://cloud.mines-paristech.fr/index.php/s/7cqiTMIIqwvMOtA/download"
        BasePCRBTest.__init__(self,
                              root=root,
                              transform=transform,
                              pre_transform=pre_transform,
                              pre_filter=pre_filter,
                              verbose=verbose, debug=debug,
                              max_dist_overlap=max_dist_overlap,
                              num_pos_pairs=num_pos_pairs,
                              self_supervised=self_supervised,
                              min_size_block=min_size_block,
                              max_size_block=max_size_block,
                              min_points=min_points,
                              ss_transform=ss_transform,
                              use_fps=use_fps)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 16:</b> &nbsp; 2 fragments, nominal size 17 lines, similarity 88%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag389')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/datasets/registration/testkaist.py: 54-71
</a>
<div class="mid" id="frag389" style="display:none"><pre>
    def download(self):
        folder = os.path.join(self.raw_dir, "test")
        if files_exist([folder]):  # pragma: no cover
            log.warning("already downloaded {}".format("test"))
            return
        else:
            makedirs(folder)
        log.info("Download elements in the file {}...".format(folder))
        for name, url in self.DATASETS:
            log.info(f'Downloading sequence {name}')
            filename = os.path.join(folder,name+".zip")
            gdown.download(url, filename, quiet=False)
            with ZipFile(filename, 'r') as zip_obj:
                zip_obj.extractall(folder)
            os.remove(filename)

        self.download_pairs(folder)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag400')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/datasets/registration/testtum.py: 58-77
</a>
<div class="mid" id="frag400" style="display:none"><pre>
    def download(self):
        folder = os.path.join(self.raw_dir, "test")
        if files_exist([folder]):  # pragma: no cover
            log.warning("already downloaded {}".format("test"))
            return
        else:
            makedirs(folder)
        log.info("Download elements in the file {}...".format(folder))
        for name, url in self.DATASETS:
            dataset_folder = os.path.join(folder,name)
            os.mkdir(dataset_folder)
            log.info(f'Downloading sequence {name}')
            filename = os.path.join(folder,name+".zip")
            gdown.download(url, filename, quiet=False)
            with ZipFile(filename, 'r') as zip_obj:
                zip_obj.extractall(dataset_folder)
            os.remove(filename)

        self.download_pairs(folder)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 17:</b> &nbsp; 4 fragments, nominal size 24 lines, similarity 84%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag391')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/datasets/registration/testkaist.py: 84-111
</a>
<div class="mid" id="frag391" style="display:none"><pre>
    def __init__(self, dataset_opt):

        super().__init__(dataset_opt)
        pre_transform = self.pre_transform
        train_transform = self.train_transform
        ss_transform = getattr(self, "ss_transform", None)
        test_transform = self.test_transform

        # training is similar to test but only unsupervised training is allowed XD
        self.train_dataset = TestPairKaist(
            root=self._data_path,
            pre_transform=pre_transform,
            transform=train_transform,
            max_dist_overlap=dataset_opt.max_dist_overlap,
            self_supervised=True,
            min_size_block=dataset_opt.min_size_block,
            max_size_block=dataset_opt.max_size_block,
            num_pos_pairs=dataset_opt.num_pos_pairs,
            min_points=dataset_opt.min_points,
            ss_transform=ss_transform,
            use_fps=dataset_opt.use_fps)
        self.test_dataset = TestPairKaist(
            root=self._data_path,
            pre_transform=pre_transform,
            transform=test_transform,
            max_dist_overlap=dataset_opt.max_dist_overlap,
            num_pos_pairs=dataset_opt.num_pos_pairs,
            self_supervised=False)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag433')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/datasets/registration/testplanetary.py: 114-142
</a>
<div class="mid" id="frag433" style="display:none"><pre>
    def __init__(self, dataset_opt):

        super().__init__(dataset_opt)
        pre_transform = self.pre_transform
        train_transform = self.train_transform
        ss_transform = getattr(self, "ss_transform", None)
        test_transform = self.test_transform

        # training is similar to test but only unsupervised training is allowed XD
        self.train_dataset = TestPairPlanetary(
            root=self._data_path,
            pre_transform=pre_transform,
            transform=train_transform,
            max_dist_overlap=dataset_opt.max_dist_overlap,
            self_supervised=True,
            min_size_block=dataset_opt.min_size_block,
            max_size_block=dataset_opt.max_size_block,
            num_pos_pairs=dataset_opt.num_pos_pairs,
            min_points=dataset_opt.min_points,
            ss_transform=ss_transform,
            use_fps=dataset_opt.use_fps
        )
        self.test_dataset = TestPairPlanetary(
            root=self._data_path,
            pre_transform=pre_transform,
            transform=test_transform,
            max_dist_overlap=dataset_opt.max_dist_overlap,
            num_pos_pairs=dataset_opt.num_pos_pairs,
            self_supervised=False)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag407')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/datasets/registration/testeth.py: 132-157
</a>
<div class="mid" id="frag407" style="display:none"><pre>
    def __init__(self, dataset_opt):

        super().__init__(dataset_opt)
        pre_transform = self.pre_transform
        train_transform = self.train_transform
        ss_transform = getattr(self, "ss_transform", None)
        test_transform = self.test_transform

        # training is similar to test but only unsupervised training is allowed XD
        self.train_dataset = TestPairETH(root=self._data_path,
                                         pre_transform=pre_transform,
                                         transform=train_transform,
                                         max_dist_overlap=dataset_opt.max_dist_overlap,
                                         self_supervised=True,
                                         min_size_block=dataset_opt.min_size_block,
                                         max_size_block=dataset_opt.max_size_block,
                                         num_pos_pairs=dataset_opt.num_pos_pairs,
                                         min_points=dataset_opt.min_points,
                                         ss_transform=ss_transform,
                                         use_fps=dataset_opt.use_fps)
        self.test_dataset = TestPairETH(root=self._data_path,
                                        pre_transform=pre_transform,
                                        transform=test_transform,
                                        max_dist_overlap=dataset_opt.max_dist_overlap,
                                        num_pos_pairs=dataset_opt.num_pos_pairs,
                                        self_supervised=False)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag402')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/datasets/registration/testtum.py: 90-115
</a>
<div class="mid" id="frag402" style="display:none"><pre>
    def __init__(self, dataset_opt):

        super().__init__(dataset_opt)
        pre_transform = self.pre_transform
        train_transform = self.train_transform
        ss_transform = getattr(self, "ss_transform", None)
        test_transform = self.test_transform

        # training is similar to test but only unsupervised training is allowed XD
        self.train_dataset = TestPairTUM(root=self._data_path,
                                         pre_transform=pre_transform,
                                         transform=train_transform,
                                         max_dist_overlap=dataset_opt.max_dist_overlap,
                                         self_supervised=True,
                                         min_size_block=dataset_opt.min_size_block,
                                         max_size_block=dataset_opt.max_size_block,
                                         num_pos_pairs=dataset_opt.num_pos_pairs,
                                         min_points=dataset_opt.min_points,
                                         ss_transform=ss_transform,
                                         use_fps=dataset_opt.use_fps)
        self.test_dataset = TestPairTUM(root=self._data_path,
                                        pre_transform=pre_transform,
                                        transform=test_transform,
                                        max_dist_overlap=dataset_opt.max_dist_overlap,
                                        num_pos_pairs=dataset_opt.num_pos_pairs,
                                        self_supervised=False)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 18:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 92%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag393')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/datasets/registration/base_siamese_dataset.py: 40-55
</a>
<div class="mid" id="frag393" style="display:none"><pre>
    def _get_collate_function(conv_type, is_multiscale, pre_collate_transform=None):
        is_dense = ConvolutionFormatFactory.check_is_dense_format(conv_type)
        if is_multiscale:
            if conv_type.lower() == ConvolutionFormat.PARTIAL_DENSE.value.lower():
                fn = PairMultiScaleBatch.from_data_list
            else:
                raise NotImplementedError(
                    "MultiscaleTransform is activated and supported only for partial_dense format"
                )
        else:
            if is_dense:
                fn = DensePairBatch.from_data_list
            else:
                fn = PairBatch.from_data_list
        return partial(BaseDataset._collate_fn, collate_fn=fn, pre_collate_transform=pre_collate_transform)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag482')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/datasets/base_dataset.py: 160-175
</a>
<div class="mid" id="frag482" style="display:none"><pre>
    def _get_collate_function(conv_type, is_multiscale, pre_collate_transform=None):
        is_dense = ConvolutionFormatFactory.check_is_dense_format(conv_type)
        if is_multiscale:
            if conv_type.lower() == ConvolutionFormat.PARTIAL_DENSE.value.lower():
                fn = MultiScaleBatch.from_data_list
            else:
                raise NotImplementedError(
                    "MultiscaleTransform is activated and supported only for partial_dense format"
                )
        else:
            if is_dense:
                fn = SimpleBatch.from_data_list
            else:
                fn = torch_geometric.data.batch.Batch.from_data_list
        return partial(BaseDataset._collate_fn, collate_fn=fn, pre_collate_transform=pre_collate_transform)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 19:</b> &nbsp; 2 fragments, nominal size 54 lines, similarity 73%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag419')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/datasets/registration/general3dmatch.py: 22-127
</a>
<div class="mid" id="frag419" style="display:none"><pre>
    def __init__(
        self,
        root,
        radius_patch=0.3,
        num_frame_per_fragment=50,
        mode="train_small",
        min_overlap_ratio=0.3,
        max_overlap_ratio=1.0,
        max_dist_overlap=0.01,
        tsdf_voxel_size=0.02,
        limit_size=700,
        depth_thresh=6,
        is_fine=True,
        transform=None,
        pre_transform=None,
        pre_filter=None,
        verbose=False,
        debug=False,
        num_random_pt=5000,
        is_offline=False,
        pre_transform_patch=None,
    ):
        r"""
        Patch extracted from :the Princeton 3DMatch dataset\n
        `"3DMatch: Learning Local Geometric Descriptors from RGB-D Reconstructions"
        &lt;https://arxiv.org/pdf/1603.08182.pdf&gt;`_
        paper, containing rgbd frames of the following dataset:
        `" SUN3D: A Database of Big Spaces Reconstructed using SfM and Object Labels
        "&lt;http://sun3d.cs.princeton.edu/&gt;`
        `"Scene Coordinate Regression Forests for Camera Relocalization in RGB-D Images
        "&lt;https://www.microsoft.com/en-us/research/publication/scene-coordinate-regression-forests-for-camera-relocalization-in-rgb-d-images/&gt;`
        `"Unsupervised Feature Learning for 3D Scene Labeling
        "&lt;http://rgbd-dataset.cs.washington.edu/dataset/rgbd-scenes-v2/&gt;`
        `"BundleFusion: Real-time Globally Consistent 3D Reconstruction using Online
        Surface Re-integration
        "&lt;http://graphics.stanford.edu/projects/bundlefusion/&gt;`
        `"Learning to Navigate the Energy Landscape
        "&lt;http://graphics.stanford.edu/projects/reloc/&gt;`

        Args:

            root (string): Root directory where the dataset should be saved

            radius_patch(float, optional): the size of the patch

            num_frame_per_fragment (int, optional): indicate the number of frames
                we use to build fragments. If it is equal to 0, then we don't
                build fragments and use the raw frames.

            mode (string, optional): If :obj:`True`, loads the training dataset,
            otherwise the test dataset. (default: :obj:`True`)

            min_overlap_ratio(float, optional): the minimum overlap we should have to match two fragments (overlap is the number of points in a fragment that matches in an other fragment divided by the number of points)

            max_dist_overlap(float, optional): minimum distance to consider that a point match with an other.
            tsdf_voxel_size(float, optional): the size of the tsdf voxel grid to perform fine RGBD fusion to create fine fragments
            depth_thresh: threshold to remove depth pixel that are two far.

            is_fine: fine mode for the fragment fusion

            limit_size : limit the number of pixel at each direction to abvoid to heavy tsdf voxel

            transform (callable, optional): A function/transform that takes in
                an :obj:`torch_geometric.data.Data` object and returns a
                transformed version. The data object will be transformed before
                every access. (default: :obj:`None`)

            pre_transform (callable, optional): A function/transform that takes in
                an :obj:`torch_geometric.data.Data` object and returns a
                transformed version. The data object will be transformed before
                being saved to disk. (default: :obj:`None`)
            pre_filter (callable, optional): A function that takes in an
                :obj:`torch_geometric.data.Data` object and returns a boolean
                value, indicating whether the data object should be included in the
                final dataset. (default: :obj:`None`)
            num_random_pt: number of point we select
        """
        self.is_patch = True
        super(Patch3DMatch, self).__init__(
            root,
            num_frame_per_fragment,
            mode,
            min_overlap_ratio,
            max_overlap_ratio,
            max_dist_overlap,
            tsdf_voxel_size,
            limit_size,
            depth_thresh,
            is_fine,
            transform,
            pre_transform,
            pre_filter,
            verbose,
            debug,
            num_random_pt,
            is_offline,
            radius_patch,
            pre_transform_patch,
        )

        self.radius_patch = radius_patch
        self.is_offline = is_offline
        self.path_data = osp.join(self.processed_dir, self.mode, "matches")
        if self.is_offline:
            self.path_data = osp.join(self.processed_dir, self.mode, "patches")

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag424')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/datasets/registration/general3dmatch.py: 229-286
</a>
<div class="mid" id="frag424" style="display:none"><pre>
    def __init__(
            self,
            root,
            num_frame_per_fragment=50,
            mode="train_small",
            min_overlap_ratio=0.3,
            max_overlap_ratio=1.0,
            max_dist_overlap=0.01,
            tsdf_voxel_size=0.02,
            limit_size=700,
            depth_thresh=6,
            is_fine=True,
            transform=None,
            pre_transform=None,
            pre_transform_fragment=None,
            pre_filter=None,
            verbose=False,
            debug=False,
            is_online_matching=False,
            num_pos_pairs=1024,
            self_supervised=False,
            min_size_block=0.3,
            max_size_block=2,
            ss_transform=None,
            min_points=500,
            use_fps=False
    ):
        self.is_patch = False
        Base3DMatch.__init__(
            self,
            root,
            num_frame_per_fragment,
            mode,
            min_overlap_ratio,
            max_overlap_ratio,
            max_dist_overlap,
            tsdf_voxel_size,
            limit_size,
            depth_thresh,
            is_fine,
            transform,
            pre_transform,
            pre_transform_fragment,
            pre_filter,
            verbose,
            debug,
        )
        self.path_match = osp.join(self.processed_dir, self.mode, "matches")
        self.list_fragment = [f for f in os.listdir(self.path_match) if "matches" in f]
        self.is_online_matching = is_online_matching
        self.num_pos_pairs = num_pos_pairs
        self.self_supervised = self_supervised
        self.min_size_block = min_size_block
        self.max_size_block = max_size_block
        self.ss_transform = ss_transform
        self.min_points = min_points
        self.use_fps = use_fps

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 20:</b> &nbsp; 2 fragments, nominal size 26 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag634')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/core/losses/__init__.py: 23-61
</a>
<div class="mid" id="frag634" style="display:none"><pre>
def instantiate_loss_or_miner(option, mode="loss"):
    """
    create a loss from an OmegaConf dict such as
    TripletMarginLoss.
    params:
        margin=0.1
    It can also instantiate a miner to better learn a loss
    """
    class_ = getattr(option, "class", None)
    try:
        params = option.params
    except KeyError:
        params = None

    try:
        lparams = option.lparams
    except KeyError:
        lparams = None

    if "loss" in mode:
        cls = getattr(_custom_losses, class_, None)
        if not cls:
            cls = getattr(_torch_metric_learning_losses, class_, None)
            if not cls:
                raise ValueError("loss %s is nowhere to be found" % class_)
    elif mode == "miner":
        cls = getattr(_torch_metric_learning_miners, class_, None)
        if not cls:
            raise ValueError("miner %s is nowhere to be found" % class_)
    else:
        raise NotImplementedError("Cannot instantiate this mode {}".format(mode))

    if params and lparams:
        return cls(*lparams, **params)
    if params:
        return cls(**params)
    if lparams:
        return cls(*params)
    return cls()
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag839')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/core/data_transform/__init__.py: 48-81
</a>
<div class="mid" id="frag839" style="display:none"><pre>
def instantiate_transform(transform_option, attr="transform"):
    """ Creates a transform from an OmegaConf dict such as
    transform: GridSampling3D
        params:
            size: 0.01
    """
    tr_name = getattr(transform_option, attr, None)
    try:
        tr_params = transform_option.params
    except KeyError:
        tr_params = None
    try:
        lparams = transform_option.lparams
    except KeyError:
        lparams = None

    cls = getattr(_custom_transforms, tr_name, None)
    if not cls:
        cls = getattr(_torch_geometric_transforms, tr_name, None)
        if not cls:
            raise ValueError("Transform %s is nowhere to be found" % tr_name)

    if tr_params and lparams:
        return cls(*lparams, **tr_params)

    if tr_params:
        return cls(**tr_params)

    if lparams:
        return cls(*lparams)

    return cls()


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 21:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 71%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag646')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/core/base_conv/message_passing.py: 138-156
</a>
<div class="mid" id="frag646" style="display:none"><pre>
    def forward(self, data, **kwargs):
        batch_obj = Batch()
        x, pos, batch = data.x, data.pos, data.batch
        if pos is not None:
            x = self.nn(torch.cat([x, pos], dim=1))
        else:
            x = self.nn(x)
        x = self.pool(x, batch)
        batch_obj.x = x
        if pos is not None:
            batch_obj.pos = pos.new_zeros((x.size(0), 3))
        batch_obj.batch = torch.arange(x.size(0), device=batch.device)
        copy_from_to(data, batch_obj)
        return batch_obj


#################### COMMON MODULE ########################


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag661')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/core/base_conv/partial_dense.py: 91-102
</a>
<div class="mid" id="frag661" style="display:none"><pre>
    def forward(self, data, **kwargs):
        batch_obj = Batch()
        x, pos, batch = data.x, data.pos, data.batch
        x = self.nn(torch.cat([x, pos], dim=1))
        x = self.pool(x, batch)
        batch_obj.x = x
        batch_obj.pos = pos.new_zeros((x.size(0), 3))
        batch_obj.batch = torch.arange(x.size(0), device=x.device)
        copy_from_to(data, batch_obj)
        return batch_obj


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 22:</b> &nbsp; 2 fragments, nominal size 19 lines, similarity 89%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag710')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/core/data_transform/transforms.py: 115-145
</a>
<div class="mid" id="frag710" style="display:none"><pre>
    def _process(self, data):
        if not hasattr(data, self.KDTREE_KEY):
            tree = KDTree(np.asarray(data.pos), leaf_size=50)
        else:
            tree = getattr(data, self.KDTREE_KEY)

        # The kdtree has bee attached to data for optimization reason.
        # However, it won't be used for down the transform pipeline and should be removed before any collate func call.
        if hasattr(data, self.KDTREE_KEY) and self._delattr_kd_tree:
            delattr(data, self.KDTREE_KEY)

        # apply grid sampling
        grid_data = self._grid_sampling(data.clone())

        datas = []
        for grid_center in np.asarray(grid_data.pos):
            pts = np.asarray(grid_center)[np.newaxis]

            # Find closest point within the original data
            ind = torch.LongTensor(tree.query(pts, k=1)[1][0])
            grid_label = data.y[ind]

            # Find neighbours within the original data
            ind = torch.LongTensor(tree.query_radius(pts, r=self._radius)[0])
            sampler = SphereSampling(self._radius, grid_center, align_origin=self._center)
            new_data = sampler(data)
            new_data.center_label = grid_label

            datas.append(new_data)
        return datas

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag714')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/core/data_transform/transforms.py: 183-213
</a>
<div class="mid" id="frag714" style="display:none"><pre>
    def _process(self, data):
        if not hasattr(data, self.KDTREE_KEY):
            tree = KDTree(np.asarray(data.pos[:, :-1]), leaf_size=50)
        else:
            tree = getattr(data, self.KDTREE_KEY)

        # The kdtree has bee attached to data for optimization reason.
        # However, it won't be used for down the transform pipeline and should be removed before any collate func call.
        if hasattr(data, self.KDTREE_KEY) and self._delattr_kd_tree:
            delattr(data, self.KDTREE_KEY)

        # apply grid sampling
        grid_data = self._grid_sampling(data.clone())

        datas = []
        for grid_center in np.unique(grid_data.pos[:, :-1], axis=0):
            pts = np.asarray(grid_center)[np.newaxis]

            # Find closest point within the original data
            ind = torch.LongTensor(tree.query(pts, k=1)[1][0])
            grid_label = data.y[ind]

            # Find neighbours within the original data
            ind = torch.LongTensor(tree.query_radius(pts, r=self._radius)[0])
            sampler = CylinderSampling(self._radius, grid_center, align_origin=self._center)
            new_data = sampler(data)
            new_data.center_label = grid_label

            datas.append(new_data)
        return datas

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 23:</b> &nbsp; 2 fragments, nominal size 22 lines, similarity 90%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag726')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/core/data_transform/transforms.py: 314-337
</a>
<div class="mid" id="frag726" style="display:none"><pre>
    def __call__(self, data):
        num_points = data.pos.shape[0]
        if not hasattr(data, self.KDTREE_KEY):
            tree = KDTree(np.asarray(data.pos), leaf_size=50)
            setattr(data, self.KDTREE_KEY, tree)
        else:
            tree = getattr(data, self.KDTREE_KEY)

        t_center = torch.FloatTensor(self._centre)
        ind = torch.LongTensor(tree.query_radius(self._centre, r=self._radius)[0])
        new_data = Data()
        for key in set(data.keys):
            if key == self.KDTREE_KEY:
                continue
            item = data[key]
            if torch.is_tensor(item) and num_points == item.shape[0]:
                item = item[ind]
                if self._align_origin and key == "pos":  # Center the sphere.
                    item -= t_center
            elif torch.is_tensor(item):
                item = item.clone()
            setattr(new_data, key, item)
        return new_data

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag729')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/core/data_transform/transforms.py: 368-392
</a>
<div class="mid" id="frag729" style="display:none"><pre>
    def __call__(self, data):
        num_points = data.pos.shape[0]
        if not hasattr(data, self.KDTREE_KEY):
            tree = KDTree(np.asarray(data.pos[:, :-1]), leaf_size=50)
            setattr(data, self.KDTREE_KEY, tree)
        else:
            tree = getattr(data, self.KDTREE_KEY)

        t_center = torch.FloatTensor(self._centre)
        ind = torch.LongTensor(tree.query_radius(self._centre, r=self._radius)[0])

        new_data = Data()
        for key in set(data.keys):
            if key == self.KDTREE_KEY:
                continue
            item = data[key]
            if torch.is_tensor(item) and num_points == item.shape[0]:
                item = item[ind]
                if self._align_origin and key == "pos":  # Center the cylinder.
                    item[:, :-1] -= t_center
            elif torch.is_tensor(item):
                item = item.clone()
            setattr(new_data, key, item)
        return new_data

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 24:</b> &nbsp; 2 fragments, nominal size 30 lines, similarity 87%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag950')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/modules/RSConv/dense.py: 108-144
</a>
<div class="mid" id="frag950" style="display:none"><pre>
    def __init__(
        self,
        npoint=None,
        radii=None,
        nsample=None,
        down_conv_nn=None,
        channel_raising_nn=None,
        bn=True,
        use_xyz=True,
        activation=nn.ReLU(),
        **kwargs
    ):
        assert len(radii) == len(nsample)
        if len(radii) != len(down_conv_nn):
            log.warn("The down_conv_nn has a different size as radii. Make sure of have SharedRSConv")
        super(RSConvSharedMSGDown, self).__init__(
            DenseFPSSampler(num_to_sample=npoint), DenseRadiusNeighbourFinder(radii, nsample), **kwargs
        )

        self.use_xyz = use_xyz
        self.npoint = npoint
        self.mlps = nn.ModuleList()

        # https://github.com/Yochengliu/Relation-Shape-CNN/blob/6464eb8bb4efc686adec9da437112ef888e55684/utils/pointnet2_modules.py#L106
        self._mapper = RSConvMapper(down_conv_nn, activation=activation, use_xyz=self.use_xyz)

        self.mlp_out = Sequential(
            *[
                Conv1d(channel_raising_nn[0], channel_raising_nn[-1], kernel_size=1, stride=1, bias=True),
                nn.BatchNorm1d(channel_raising_nn[-1]),
                activation,
            ]
        )

        for i in range(len(radii)):
            self.mlps.append(SharedRSConv(self._mapper, radii[i]))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag961')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/modules/RSConv/dense.py: 401-440
</a>
<div class="mid" id="frag961" style="display:none"><pre>
    def __init__(
        self,
        npoint=None,
        radii=None,
        nsample=None,
        down_conv_nn=None,
        channel_raising_nn=None,
        bn=True,
        bias=True,
        use_xyz=True,
        activation=nn.ReLU(),
        **kwargs
    ):
        assert len(radii) == len(nsample)
        if len(radii) != len(down_conv_nn):
            log.warning("The down_conv_nn has a different size as radii. Make sure to have sharedMLP")
        super(RSConvMSGDown, self).__init__(
            DenseFPSSampler(num_to_sample=npoint), DenseRadiusNeighbourFinder(radii, nsample), **kwargs
        )

        self.use_xyz = use_xyz
        self.npoint = npoint
        self.mlps = nn.ModuleList()

        # https://github.com/Yochengliu/Relation-Shape-CNN/blob/6464eb8bb4efc686adec9da437112ef888e55684/utils/pointnet2_modules.py#L106

        self.mlp_out = Sequential(
            *[
                Conv1d(channel_raising_nn[0], channel_raising_nn[-1], kernel_size=1, stride=1, bias=True),
                nn.BatchNorm1d(channel_raising_nn[-1]),
                activation,
            ]
        )

        for i in range(len(radii)):
            mapper = RSConvMapper(down_conv_nn, activation=activation, use_xyz=self.use_xyz)
            self.mlps.append(SharedRSConv(mapper, radii[i]))

        self._mapper = mapper

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 25:</b> &nbsp; 2 fragments, nominal size 17 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag951')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/modules/RSConv/dense.py: 145-166
</a>
<div class="mid" id="frag951" style="display:none"><pre>
    def _prepare_features(self, x, pos, new_pos, idx):
        new_pos_trans = pos.transpose(1, 2).contiguous()
        grouped_pos_absolute = tp.grouping_operation(new_pos_trans, idx)  # (B, 3, npoint, nsample)
        centroids = new_pos.transpose(1, 2).unsqueeze(-1)
        grouped_pos_normalized = grouped_pos_absolute - centroids

        if x is not None:
            grouped_features = tp.grouping_operation(x, idx)
            if self.use_xyz:
                new_features = torch.cat(
                    [grouped_pos_absolute, grouped_pos_normalized, grouped_features], dim=1
                )  # (B, 3 + 3 + C, npoint, nsample)
            else:
                new_features = grouped_features
        else:
            assert self.use_xyz, "Cannot have not features and not use xyz as a feature!"
            new_features = torch.cat(
                [grouped_pos_absolute, grouped_pos_normalized], dim=1
            )  # (B, 3 + 3 npoint, nsample)

        return new_features, centroids

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag962')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/modules/RSConv/dense.py: 441-462
</a>
<div class="mid" id="frag962" style="display:none"><pre>
    def _prepare_features(self, x, pos, new_pos, idx):
        new_pos_trans = pos.transpose(1, 2).contiguous()
        grouped_pos_absolute = tp.grouping_operation(new_pos_trans, idx)  # (B, 3, npoint, nsample)
        centroids = new_pos.transpose(1, 2).unsqueeze(-1)
        grouped_pos_normalized = grouped_pos_absolute - centroids

        if x is not None:
            grouped_features = tp.grouping_operation(x, idx)
            if self.use_xyz:
                new_features = torch.cat(
                    [grouped_pos_absolute, grouped_pos_normalized, grouped_features], dim=1
                )  # (B, 3 + 3 + C, npoint, nsample)
            else:
                new_features = grouped_features
        else:
            assert self.use_xyz, "Cannot have not features and not use xyz as a feature!"
            new_features = torch.cat(
                [grouped_pos_absolute, grouped_pos_normalized], dim=1
            )  # (B, 3 + 3 npoint, nsample)

        return new_features, centroids

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 26:</b> &nbsp; 2 fragments, nominal size 38 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag993')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/modules/KPConv/kernels.py: 37-73
</a>
<div class="mid" id="frag993" style="display:none"><pre>
    def __init__(
        self,
        num_inputs,
        num_outputs,
        point_influence,
        n_kernel_points=15,
        fixed="center",
        KP_influence="linear",
        aggregation_mode="sum",
        dimension=3,
        add_one=False,
        **kwargs
    ):
        super(KPConvLayer, self).__init__()
        self.kernel_radius = self._INFLUENCE_TO_RADIUS * point_influence
        self.point_influence = point_influence
        self.add_one = add_one
        self.num_inputs = num_inputs + self.add_one * 1
        self.num_outputs = num_outputs

        self.KP_influence = KP_influence
        self.n_kernel_points = n_kernel_points
        self.aggregation_mode = aggregation_mode

        # Initial kernel extent for this layer
        K_points_numpy = load_kernels(
            self.kernel_radius, n_kernel_points, num_kernels=1, dimension=dimension, fixed=fixed,
        )

        self.K_points = Parameter(
            torch.from_numpy(K_points_numpy.reshape((n_kernel_points, dimension))).to(torch.float), requires_grad=False,
        )

        weights = torch.empty([n_kernel_points, self.num_inputs, num_outputs], dtype=torch.float)
        torch.nn.init.xavier_normal_(weights)
        self.weight = Parameter(weights)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag996')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/modules/KPConv/kernels.py: 129-180
</a>
<div class="mid" id="frag996" style="display:none"><pre>
    def __init__(
        self,
        num_inputs,
        num_outputs,
        point_influence,
        n_kernel_points=15,
        fixed="center",
        KP_influence="linear",
        aggregation_mode="sum",
        dimension=3,
        modulated=False,
        loss_mode="fitting",
        add_one=False,
        **kwargs
    ):
        super(KPConvDeformableLayer, self).__init__()
        self.kernel_radius = self._INFLUENCE_TO_RADIUS * point_influence
        self.point_influence = point_influence
        self.add_one = add_one
        self.num_inputs = num_inputs + self.add_one * 1
        self.num_outputs = num_outputs

        self.KP_influence = KP_influence
        self.n_kernel_points = n_kernel_points
        self.aggregation_mode = aggregation_mode
        self.modulated = modulated
        self.internal_losses = {self.PERMISSIVE_LOSS_KEY: 0.0, self.FITTING_LOSS_KEY: 0.0, self.REPULSION_LOSS_KEY: 0.0}
        self.loss_mode = loss_mode

        # Initial kernel extent for this layer
        K_points_numpy = load_kernels(
            self.kernel_radius, n_kernel_points, num_kernels=1, dimension=dimension, fixed=fixed,
        )
        self.K_points = Parameter(
            torch.from_numpy(K_points_numpy.reshape((n_kernel_points, dimension))).to(torch.float), requires_grad=False,
        )

        # Create independant weight for the first convolution and a bias term as no batch normalization happen
        if modulated:
            offset_dim = (dimension + 1) * self.n_kernel_points
        else:
            offset_dim = dimension * self.n_kernel_points
        offset_weights = torch.empty([n_kernel_points, self.num_inputs, offset_dim], dtype=torch.float)
        torch.nn.init.xavier_normal_(offset_weights)
        self.offset_weights = Parameter(offset_weights)
        self.offset_bias = Parameter(torch.zeros(offset_dim, dtype=torch.float))

        # Main deformable weights
        weights = torch.empty([n_kernel_points, self.num_inputs, num_outputs], dtype=torch.float)
        torch.nn.init.xavier_normal_(weights)
        self.weight = Parameter(weights)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 27:</b> &nbsp; 3 fragments, nominal size 42 lines, similarity 81%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1006')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/modules/MinkowskiEngine/resunet.py: 141-195
</a>
<div class="mid" id="frag1006" style="display:none"><pre>
    def forward(self, x):
        out_s1 = self.conv1(x)
        out_s1 = self.norm1(out_s1)
        out_s1 = self.block1(out_s1)
        out = MEF.relu(out_s1)

        out_s2 = self.conv2(out)
        out_s2 = self.norm2(out_s2)
        out_s2 = self.block2(out_s2)
        out = MEF.relu(out_s2)

        out_s4 = self.conv3(out)
        out_s4 = self.norm3(out_s4)
        out_s4 = self.block3(out_s4)
        out = MEF.relu(out_s4)

        out_s8 = self.conv4(out)
        out_s8 = self.norm4(out_s8)
        out_s8 = self.block4(out_s8)
        out = MEF.relu(out_s8)

        out = self.conv4_tr(out)
        out = self.norm4_tr(out)
        out = self.block4_tr(out)
        out_s4_tr = MEF.relu(out)

        out = ME.cat(out_s4_tr, out_s4)

        out = self.conv3_tr(out)
        out = self.norm3_tr(out)
        out = self.block3_tr(out)
        out_s2_tr = MEF.relu(out)

        out = ME.cat(out_s2_tr, out_s2)

        out = self.conv2_tr(out)
        out = self.norm2_tr(out)
        out = self.block2_tr(out)
        out_s1_tr = MEF.relu(out)

        out = ME.cat(out_s1_tr, out_s1)
        out = self.conv1_tr(out)
        out = MEF.relu(out)
        out = self.final(out)

        if self.normalize_feature:
            return ME.SparseTensor(
                out.F / torch.norm(out.F, p=2, dim=1, keepdim=True),
                coords_key=out.coords_key,
                coords_manager=out.coords_man,
            )
        else:
            return out


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1063')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/modules/MinkowskiEngine/res16unet.py: 450-510
</a>
<div class="mid" id="frag1063" style="display:none"><pre>
    def forward(self, x):
        out = self.conv0p1s1(x)
        out = self.bn0(out)
        out_p1 = self.relu(out)

        out = self.conv1p1s2(out_p1)
        out = self.bn1(out)
        out = self.relu(out)
        out_b1p2 = self.block1(out)

        out = self.conv2p2s2(out_b1p2)
        out = self.bn2(out)
        out = self.relu(out)
        out_b2p4 = self.block2(out)

        out = self.conv3p4s2(out_b2p4)
        out = self.bn3(out)
        out = self.relu(out)
        out_b3p8 = self.block3(out)

        # pixel_dist=16
        out = self.conv4p8s2(out_b3p8)
        out = self.bn4(out)
        out = self.relu(out)
        out = self.block4(out)

        # pixel_dist=8
        out = self.convtr4p16s2(out)
        out = self.bntr4(out)
        out = self.relu(out)

        out = me.cat(out, out_b3p8)
        out = self.block5(out)

        # pixel_dist=4
        out = self.convtr5p8s2(out)
        out = self.bntr5(out)
        out = self.relu(out)

        out = me.cat(out, out_b2p4)
        out = self.block6(out)

        # pixel_dist=2
        out = self.convtr6p4s2(out)
        out = self.bntr6(out)
        out = self.relu(out)

        out = me.cat(out, out_b1p2)
        out = self.block7(out)

        # pixel_dist=1
        out = self.convtr7p2s2(out)
        out = self.bntr7(out)
        out = self.relu(out)

        out = me.cat(out, out_p1)
        out = self.block8(out)

        return self.final(out)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1018')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/modules/MinkowskiEngine/networks.py: 187-247
</a>
<div class="mid" id="frag1018" style="display:none"><pre>
    def forward(self, x):
        out = self.conv0p1s1(x)
        out = self.bn0(out)
        out_p1 = self.relu(out)

        out = self.conv1p1s2(out_p1)
        out = self.bn1(out)
        out = self.relu(out)
        out_b1p2 = self.block1(out)

        out = self.conv2p2s2(out_b1p2)
        out = self.bn2(out)
        out = self.relu(out)
        out_b2p4 = self.block2(out)

        out = self.conv3p4s2(out_b2p4)
        out = self.bn3(out)
        out = self.relu(out)
        out_b3p8 = self.block3(out)

        # tensor_stride=16
        out = self.conv4p8s2(out_b3p8)
        out = self.bn4(out)
        out = self.relu(out)
        out = self.block4(out)

        # tensor_stride=8
        out = self.convtr4p16s2(out)
        out = self.bntr4(out)
        out = self.relu(out)

        out = ME.cat(out, out_b3p8)
        out = self.block5(out)

        # tensor_stride=4
        out = self.convtr5p8s2(out)
        out = self.bntr5(out)
        out = self.relu(out)

        out = ME.cat(out, out_b2p4)
        out = self.block6(out)

        # tensor_stride=2
        out = self.convtr6p4s2(out)
        out = self.bntr6(out)
        out = self.relu(out)

        out = ME.cat(out, out_b1p2)
        out = self.block7(out)

        # tensor_stride=1
        out = self.convtr7p2s2(out)
        out = self.bntr7(out)
        out = self.relu(out)

        out = ME.cat(out, out_p1)
        out = self.block8(out)

        return self.final(out)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 28:</b> &nbsp; 8 fragments, nominal size 13 lines, similarity 71%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1015')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/modules/MinkowskiEngine/networks.py: 71-89
</a>
<div class="mid" id="frag1015" style="display:none"><pre>
    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.pool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.conv5(x)
        x = self.bn5(x)
        x = self.relu(x)

        x = self.glob_avg(x)
        return self.final(x)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1059')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/modules/MinkowskiEngine/res16unet.py: 231-245
</a>
<div class="mid" id="frag1059" style="display:none"><pre>
    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.pool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.final(x)
        return x


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1053')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/modules/MinkowskiEngine/res16unet.py: 95-117
</a>
<div class="mid" id="frag1053" style="display:none"><pre>
    def forward(self, x):
        residual = x

        out = self.conv1(x)
        out = self.norm1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.norm2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.norm3(out)

        if self.downsample is not None:
            residual = self.downsample(x)

        out += residual
        out = self.relu(out)

        return out


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1035')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/modules/MinkowskiEngine/modules.py: 345-368
</a>
<div class="mid" id="frag1035" style="display:none"><pre>
    def forward(self, x):
        residual = x

        out = self.conv1(x)
        out = self.norm1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.norm2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.norm3(out)
        out = self.se(out)

        if self.downsample is not None:
            residual = self.downsample(x)

        out += residual
        out = self.relu(out)

        return out


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1022')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/modules/MinkowskiEngine/modules.py: 82-104
</a>
<div class="mid" id="frag1022" style="display:none"><pre>
    def forward(self, x):
        residual = x

        out = self.conv1(x)
        out = self.norm1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.norm2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.norm3(out)

        if self.downsample is not None:
            residual = self.downsample(x)

        out += residual
        out = self.relu(out)

        return out


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1051')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/modules/MinkowskiEngine/res16unet.py: 36-54
</a>
<div class="mid" id="frag1051" style="display:none"><pre>
    def forward(self, x):
        residual = x

        out = self.conv1(x)
        out = self.norm1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.norm2(out)

        if self.downsample is not None:
            residual = self.downsample(x)

        out += residual
        out = self.relu(out)

        return out


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1020')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/modules/MinkowskiEngine/modules.py: 42-60
</a>
<div class="mid" id="frag1020" style="display:none"><pre>
    def forward(self, x):
        residual = x

        out = self.conv1(x)
        out = self.norm1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.norm2(out)

        if self.downsample is not None:
            residual = self.downsample(x)

        out += residual
        out = self.relu(out)

        return out


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1033')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/modules/MinkowskiEngine/modules.py: 304-323
</a>
<div class="mid" id="frag1033" style="display:none"><pre>
    def forward(self, x):
        residual = x

        out = self.conv1(x)
        out = self.norm1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.norm2(out)
        out = self.se(out)

        if self.downsample is not None:
            residual = self.downsample(x)

        out += residual
        out = self.relu(out)

        return out


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 29:</b> &nbsp; 2 fragments, nominal size 36 lines, similarity 88%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1026')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/modules/MinkowskiEngine/modules.py: 177-216
</a>
<div class="mid" id="frag1026" style="display:none"><pre>
    def __init__(
        self,
        down_conv_nn=[],
        kernel_sizes=[],
        strides=[],
        dilations=[],
        kernel_size=3,
        stride=1,
        dilation=1,
        norm_layer=ME.MinkowskiBatchNorm,
        activation=ME.MinkowskiReLU,
        bn_momentum=0.1,
        dimension=-1,
        down_stride=2,
        **kwargs
    ):

        super(ResnetBlockDown, self).__init__(
            down_conv_nn[0],
            down_conv_nn[1],
            down_conv_nn[2],
            kernel_sizes=kernel_sizes,
            strides=strides,
            dilations=dilations,
            kernel_size=kernel_size,
            stride=stride,
            dilation=dilation,
            norm_layer=norm_layer,
            activation=activation,
            bn_momentum=bn_momentum,
            dimension=dimension,
        )

        self.downsample = nn.Sequential(
            ME.MinkowskiConvolution(
                down_conv_nn[0], down_conv_nn[2], kernel_size=2, stride=down_stride, dimension=dimension
            ),
            ME.MinkowskiBatchNorm(down_conv_nn[2]),
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1028')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/modules/MinkowskiEngine/modules.py: 225-264
</a>
<div class="mid" id="frag1028" style="display:none"><pre>
    def __init__(
        self,
        up_conv_nn=[],
        kernel_sizes=[],
        strides=[],
        dilations=[],
        kernel_size=3,
        stride=1,
        dilation=1,
        norm_layer=ME.MinkowskiBatchNorm,
        activation=ME.MinkowskiReLU,
        bn_momentum=0.1,
        dimension=-1,
        up_stride=2,
        skip=True,
        **kwargs
    ):

        self.skip = skip

        super(ResnetBlockUp, self).__init__(
            up_conv_nn[0],
            up_conv_nn[1],
            up_conv_nn[2],
            kernel_sizes=kernel_sizes,
            strides=strides,
            dilations=dilations,
            kernel_size=kernel_size,
            stride=stride,
            dilation=dilation,
            norm_layer=norm_layer,
            activation=activation,
            bn_momentum=bn_momentum,
            dimension=dimension,
        )

        self.upsample = ME.MinkowskiConvolutionTranspose(
            up_conv_nn[0], up_conv_nn[2], kernel_size=2, stride=up_stride, dimension=dimension
        )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 30:</b> &nbsp; 2 fragments, nominal size 50 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1036')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/modules/MinkowskiEngine/api_modules.py: 25-75
</a>
<div class="mid" id="frag1036" style="display:none"><pre>
    def __init__(self, input_nc, output_nc, convolution, dimension=3):
        ME.MinkowskiNetwork.__init__(self, dimension)
        self.block = (
            Seq()
            .append(
                convolution(
                    in_channels=input_nc,
                    out_channels=output_nc,
                    kernel_size=3,
                    stride=1,
                    dilation=1,
                    has_bias=False,
                    dimension=dimension,
                )
            )
            .append(ME.MinkowskiBatchNorm(output_nc))
            .append(ME.MinkowskiReLU())
            .append(
                convolution(
                    in_channels=output_nc,
                    out_channels=output_nc,
                    kernel_size=3,
                    stride=1,
                    dilation=1,
                    has_bias=False,
                    dimension=dimension,
                )
            )
            .append(ME.MinkowskiBatchNorm(output_nc))
            .append(ME.MinkowskiReLU())
        )

        if input_nc != output_nc:
            self.downsample = (
                Seq()
                .append(
                    convolution(
                        in_channels=input_nc,
                        out_channels=output_nc,
                        kernel_size=1,
                        stride=1,
                        dilation=1,
                        has_bias=False,
                        dimension=dimension,
                    )
                )
                .append(ME.MinkowskiBatchNorm(output_nc))
            )
        else:
            self.downsample = None

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1038')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/modules/MinkowskiEngine/api_modules.py: 90-152
</a>
<div class="mid" id="frag1038" style="display:none"><pre>
    def __init__(self, input_nc, output_nc, convolution, dimension=3, reduction=4):
        self.block = (
            Seq()
            .append(
                convolution(
                    in_channels=input_nc,
                    out_channels=output_nc // reduction,
                    kernel_size=1,
                    stride=1,
                    dilation=1,
                    has_bias=False,
                    dimension=dimension,
                )
            )
            .append(ME.MinkowskiBatchNorm(output_nc // reduction))
            .append(ME.MinkowskiReLU())
            .append(
                convolution(
                    output_nc // reduction,
                    output_nc // reduction,
                    kernel_size=3,
                    stride=1,
                    dilation=1,
                    has_bias=False,
                    dimension=dimension,
                )
            )
            .append(ME.MinkowskiBatchNorm(output_nc // reduction))
            .append(ME.MinkowskiReLU())
            .append(
                convolution(
                    output_nc // reduction,
                    output_nc,
                    kernel_size=1,
                    stride=1,
                    dilation=1,
                    has_bias=False,
                    dimension=dimension,
                )
            )
            .append(ME.MinkowskiBatchNorm(output_nc))
            .append(ME.MinkowskiReLU())
        )

        if input_nc != output_nc:
            self.downsample = (
                Seq()
                .append(
                    convolution(
                        in_channels=input_nc,
                        out_channels=output_nc,
                        kernel_size=1,
                        stride=1,
                        dilation=1,
                        has_bias=False,
                        dimension=dimension,
                    )
                )
                .append(ME.MinkowskiBatchNorm(output_nc))
            )
        else:
            self.downsample = None

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 31:</b> &nbsp; 2 fragments, nominal size 20 lines, similarity 80%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1050')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/modules/MinkowskiEngine/res16unet.py: 14-35
</a>
<div class="mid" id="frag1050" style="display:none"><pre>
    def __init__(
        self,
        inplanes,
        planes,
        stride=1,
        dilation=1,
        downsample=None,
        conv_type=ConvType.HYPERCUBE,
        bn_momentum=0.1,
        D=3,
    ):
        super(BasicBlockBase, self).__init__()

        self.conv1 = conv(inplanes, planes, kernel_size=3, stride=stride, dilation=dilation, conv_type=conv_type, D=D)
        self.norm1 = get_norm(self.NORM_TYPE, planes, D, bn_momentum=bn_momentum)
        self.conv2 = conv(
            planes, planes, kernel_size=3, stride=1, dilation=dilation, bias=False, conv_type=conv_type, D=D
        )
        self.norm2 = get_norm(self.NORM_TYPE, planes, D, bn_momentum=bn_momentum)
        self.relu = MinkowskiReLU(inplace=True)
        self.downsample = downsample

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1052')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/modules/MinkowskiEngine/res16unet.py: 71-94
</a>
<div class="mid" id="frag1052" style="display:none"><pre>
    def __init__(
        self,
        inplanes,
        planes,
        stride=1,
        dilation=1,
        downsample=None,
        conv_type=ConvType.HYPERCUBE,
        bn_momentum=0.1,
        D=3,
    ):
        super(BottleneckBase, self).__init__()
        self.conv1 = conv(inplanes, planes, kernel_size=1, D=D)
        self.norm1 = get_norm(self.NORM_TYPE, planes, D, bn_momentum=bn_momentum)

        self.conv2 = conv(planes, planes, kernel_size=3, stride=stride, dilation=dilation, conv_type=conv_type, D=D)
        self.norm2 = get_norm(self.NORM_TYPE, planes, D, bn_momentum=bn_momentum)

        self.conv3 = conv(planes, planes * self.expansion, kernel_size=1, D=D)
        self.norm3 = get_norm(self.NORM_TYPE, planes * self.expansion, D, bn_momentum=bn_momentum)

        self.relu = MinkowskiReLU(inplace=True)
        self.downsample = downsample

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 32:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1067')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/modules/SparseConv3d/nn/minkowski.py: 6-25
</a>
<div class="mid" id="frag1067" style="display:none"><pre>
    def __init__(
        self,
        in_channels: int,
        out_channels: int,
        kernel_size: int = 3,
        stride: int = 1,
        dilation: int = 1,
        bias: bool = False,
    ) -&gt; None:
        super().__init__(
            in_channels,
            out_channels,
            kernel_size=kernel_size,
            stride=stride,
            dilation=dilation,
            has_bias=bias,
            dimension=3,
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1068')" href="javascript:;">
torch-points3d-1.2.0/torch_points3d/modules/SparseConv3d/nn/minkowski.py: 27-46
</a>
<div class="mid" id="frag1068" style="display:none"><pre>
    def __init__(
        self,
        in_channels: int,
        out_channels: int,
        kernel_size: int = 3,
        stride: int = 1,
        dilation: int = 1,
        bias: bool = False,
    ) -&gt; None:
        super().__init__(
            in_channels,
            out_channels,
            kernel_size=kernel_size,
            stride=stride,
            dilation=dilation,
            has_bias=bias,
            dimension=3,
        )


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 33:</b> &nbsp; 3 fragments, nominal size 20 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1098')" href="javascript:;">
torch-points3d-1.2.0/test/test_visualization.py: 27-49
</a>
<div class="mid" id="frag1098" style="display:none"><pre>
    def test_empty(self):
        mock_data = Data()
        mock_data.pos = torch.zeros((batch_size, num_points, 3))
        mock_data.y = torch.zeros((batch_size, num_points, 1))
        mock_data.pred = torch.zeros((batch_size, num_points, 1))
        data = {}

        self.run_path = os.path.join(DIR, "test_viz")
        if not os.path.exists(self.run_path):
            os.makedirs(self.run_path)

        mock_num_batches = {"train": 9, "test": 3, "val": 0}
        config = OmegaConf.load(os.path.join(DIR, "test_config/viz/viz_config_indices.yaml"))
        visualizer = Visualizer(config.visualization, mock_num_batches, batch_size, self.run_path)

        for epoch in range(epochs):
            run(9, visualizer, epoch, "train", data)
            run(3, visualizer, epoch, "test", data)
            run(2, visualizer, epoch, "val", data)

        self.assertEqual(len(os.listdir(os.path.join(self.run_path, "viz"))), 0)
        shutil.rmtree(self.run_path)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1102')" href="javascript:;">
torch-points3d-1.2.0/test/test_visualization.py: 138-163
</a>
<div class="mid" id="frag1102" style="display:none"><pre>
    def test_dense_data(self):
        mock_data = Data()
        mock_data.pos = torch.zeros((batch_size, num_points, 3))
        mock_data.y = torch.zeros((batch_size, num_points, 1))
        mock_data.pred = torch.zeros((batch_size, num_points, 1))
        data = {"mock_date": mock_data}

        self.run_path = os.path.join(DIR, "test_viz")
        if not os.path.exists(self.run_path):
            os.makedirs(self.run_path)

        mock_num_batches = {"train": 9, "test": 3, "val": 0}
        config = OmegaConf.load(os.path.join(DIR, "test_config/viz/viz_config_deterministic.yaml"))
        visualizer = Visualizer(config.visualization, mock_num_batches, batch_size, self.run_path)

        for epoch in range(epochs):
            run(9, visualizer, epoch, "train", data)
            run(3, visualizer, epoch, "test", data)
            run(0, visualizer, epoch, "val", data)

        for split in ["train", "test"]:
            targets = os.listdir(os.path.join(self.run_path, "viz", "0", split))
            for epoch in range(1, epochs):
                self.assertEqual(targets, os.listdir(os.path.join(self.run_path, "viz", str(epoch), split)))
        shutil.rmtree(self.run_path)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1099')" href="javascript:;">
torch-points3d-1.2.0/test/test_visualization.py: 50-76
</a>
<div class="mid" id="frag1099" style="display:none"><pre>
    def test_indices(self):
        mock_data = Data()
        mock_data.pos = torch.zeros((batch_size, num_points, 3))
        mock_data.y = torch.zeros((batch_size, num_points, 1))
        mock_data.pred = torch.zeros((batch_size, num_points, 1))
        data = {"mock_date": mock_data}

        self.run_path = os.path.join(DIR, "test_viz")
        if not os.path.exists(self.run_path):
            os.makedirs(self.run_path)

        mock_num_batches = {"train": 9, "test": 3, "val": 0}
        config = OmegaConf.load(os.path.join(DIR, "test_config/viz/viz_config_indices.yaml"))
        visualizer = Visualizer(config.visualization, mock_num_batches, batch_size, self.run_path)

        for epoch in range(epochs):
            run(9, visualizer, epoch, "train", data)
            run(3, visualizer, epoch, "test", data)
            run(0, visualizer, epoch, "val", data)

        targets = {'train': set(["1_1.ply", "0_0.ply"]),
                   'test': set(["0_0.ply"])}
        for split in ["train", "test"]:
            for epoch in range(epochs):
                self.assertEqual(targets[split], set(os.listdir(os.path.join(self.run_path, "viz", str(epoch), split))))
        shutil.rmtree(self.run_path)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 34:</b> &nbsp; 2 fragments, nominal size 25 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1100')" href="javascript:;">
torch-points3d-1.2.0/test/test_visualization.py: 77-105
</a>
<div class="mid" id="frag1100" style="display:none"><pre>
    def test_save_all(self):
        mock_data = Data()
        mock_data.pos = torch.zeros((num_points * batch_size, 3))
        mock_data.y = torch.zeros((num_points * batch_size, 1))
        mock_data.pred = torch.zeros((num_points * batch_size, 1))
        mock_data.batch = torch.zeros((num_points * batch_size))
        mock_data.batch[:num_points] = 1
        data = {"mock_date": mock_data}

        self.run_path = os.path.join(DIR, "test_viz")
        if not os.path.exists(self.run_path):
            os.makedirs(self.run_path)

        epochs = 2
        num_samples = 100
        mock_num_batches = {"train": num_samples}

        config = OmegaConf.load(os.path.join(DIR, "test_config/viz/viz_config_save_all.yaml"))
        visualizer = Visualizer(config.visualization, mock_num_batches, batch_size, self.run_path)

        for epoch in range(epochs):
            run(num_samples // batch_size, visualizer, epoch, "train", data)

        for split in ["train"]:
            for epoch in range(epochs):
                current = set(os.listdir(os.path.join(self.run_path, "viz", str(epoch), split)))
                self.assertGreaterEqual(len(current), num_samples)
        shutil.rmtree(self.run_path)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1101')" href="javascript:;">
torch-points3d-1.2.0/test/test_visualization.py: 106-137
</a>
<div class="mid" id="frag1101" style="display:none"><pre>
    def test_pyg_data(self):
        mock_data = Data()
        mock_data.pos = torch.zeros((num_points * batch_size, 3))
        mock_data.y = torch.zeros((num_points * batch_size, 1))
        mock_data.pred = torch.zeros((num_points * batch_size, 1))
        mock_data.batch = torch.zeros((num_points * batch_size))
        mock_data.batch[:num_points] = 1
        data = {"mock_date": mock_data}

        self.run_path = os.path.join(DIR, "test_viz")
        if not os.path.exists(self.run_path):
            os.makedirs(self.run_path)

        epochs = 10
        num_batches = 100
        mock_num_batches = {"train": num_batches}

        config = OmegaConf.load(os.path.join(DIR, "test_config/viz/viz_config_non_deterministic.yaml"))
        visualizer = Visualizer(config.visualization, mock_num_batches, batch_size, self.run_path)

        for epoch in range(epochs):
            run(num_batches, visualizer, epoch, "train", data)

        count = 0
        for split in ["train"]:
            target = set(os.listdir(os.path.join(self.run_path, "viz", "0", split)))
            for epoch in range(1, epochs):
                current = set(os.listdir(os.path.join(self.run_path, "viz", str(epoch), split)))
                count += 1 if len(target &amp; current) == 0 else 0
        self.assertGreaterEqual(count, 4)
        shutil.rmtree(self.run_path)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 35:</b> &nbsp; 3 fragments, nominal size 19 lines, similarity 85%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1197')" href="javascript:;">
torch-points3d-1.2.0/test/test_lr_scheduler.py: 25-48
</a>
<div class="mid" id="frag1197" style="display:none"><pre>
    def test_update_scheduler_on_epoch(self):

        base_lr = 0.1
        gamma = 0.9
        conf = os.path.join(DIR, "test_config/lr_scheduler.yaml")
        opt = OmegaConf.load(conf)
        opt.update_lr_scheduler_on = "on_epoch"
        model = DifferentiableMockModel(opt)
        model.instantiate_optimizers(opt)
        model.schedulers.__repr__()

        data = Data(pos=torch.randn((1, 3)))
        model.set_input(data, torch.device("cpu"))

        num_epochs = 5
        num_samples_epoch = 32
        batch_size = 4
        steps = num_samples_epoch // batch_size

        for epoch in range(num_epochs):
            for step in range(steps):
                model.optimize_parameters(epoch, batch_size)
        self.assertEqual(get_lr(model._optimizer), base_lr * gamma ** (num_epochs - 1))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1199')" href="javascript:;">
torch-points3d-1.2.0/test/test_lr_scheduler.py: 72-96
</a>
<div class="mid" id="frag1199" style="display:none"><pre>
    def test_update_scheduler_on_batch(self):
        base_lr = 0.1
        gamma = 0.9
        conf = os.path.join(DIR, "test_config/lr_scheduler.yaml")
        opt = OmegaConf.load(conf)
        opt.update_lr_scheduler_on = "on_num_batch"
        model = DifferentiableMockModel(opt)
        model.instantiate_optimizers(opt)

        data = Data(pos=torch.randn((1, 3)))
        model.set_input(data, torch.device("cpu"))

        num_epochs = 5
        num_samples_epoch = 32
        batch_size = 4
        steps = num_samples_epoch // batch_size

        count_batch = 0
        for epoch in range(num_epochs):
            for step in range(steps):
                count_batch += 1
                model.optimize_parameters(epoch, batch_size)
        self.assertEqual(get_lr(model._optimizer), base_lr * gamma ** (count_batch))


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1198')" href="javascript:;">
torch-points3d-1.2.0/test/test_lr_scheduler.py: 49-71
</a>
<div class="mid" id="frag1198" style="display:none"><pre>
    def test_update_scheduler_on_sample(self):
        base_lr = 0.1
        gamma = 0.9
        conf = os.path.join(DIR, "test_config/lr_scheduler.yaml")
        opt = OmegaConf.load(conf)
        opt.update_lr_scheduler_on = "on_num_sample"
        model = DifferentiableMockModel(opt)
        model.instantiate_optimizers(opt)

        data = Data(pos=torch.randn((1, 3)))
        model.set_input(data, torch.device("cpu"))

        num_epochs = 5
        num_samples_epoch = 32
        batch_size = 4
        steps = num_samples_epoch // batch_size

        for epoch in range(num_epochs):
            for step in range(steps):
                model.optimize_parameters(epoch, batch_size)

        self.assertEqual(get_lr(model._optimizer), base_lr * gamma ** (num_epochs - 1))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 36:</b> &nbsp; 3 fragments, nominal size 12 lines, similarity 91%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1203')" href="javascript:;">
torch-points3d-1.2.0/test/test_sampler.py: 45-58
</a>
<div class="mid" id="frag1203" style="display:none"><pre>
    def test_multi_radius_search(self):
        x = torch.Tensor([[-1, -1], [-1, 1], [1, -1], [1, 1]])
        batch_x = torch.tensor([0, 0, 0, 0])
        y = torch.Tensor([[-1, 0], [1, 0]])
        batch_y = torch.tensor([0, 0])
        nei_finder = MultiscaleRadiusNeighbourFinder([1, 10], 4)
        multiscale = []
        for i in range(2):
            multiscale.append(nei_finder(x, y, batch_x, batch_y, i))

        self.assertEqual(len(multiscale), 2)
        self.assertEqual(multiscale[0][1, :].shape[0], 4)
        self.assertEqual(multiscale[1][1, :].shape[0], 8)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1204')" href="javascript:;">
torch-points3d-1.2.0/test/test_sampler.py: 59-72
</a>
<div class="mid" id="frag1204" style="display:none"><pre>
    def test_multi_num_search(self):
        x = torch.Tensor([[-1, -1], [-1, 1], [1, -1], [1, 1]])
        batch_x = torch.tensor([0, 0, 0, 0])
        y = torch.Tensor([[-1, 0], [1, 0]])
        batch_y = torch.tensor([0, 0])
        nei_finder = MultiscaleRadiusNeighbourFinder(10, [3, 4])
        multiscale = []
        for i in range(2):
            multiscale.append(nei_finder(x, y, batch_x, batch_y, i))

        self.assertEqual(len(multiscale), 2)
        self.assertEqual(multiscale[0][1, :].shape[0], 6)
        self.assertEqual(multiscale[1][1, :].shape[0], 8)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1205')" href="javascript:;">
torch-points3d-1.2.0/test/test_sampler.py: 73-87
</a>
<div class="mid" id="frag1205" style="display:none"><pre>
    def test_multiall(self):
        x = torch.Tensor([[-1, -1], [-1, 1], [1, -1], [1, 1]])
        batch_x = torch.tensor([0, 0, 0, 0])
        y = torch.Tensor([[-1, 0], [1, 0]])
        batch_y = torch.tensor([0, 0])

        nei_finder = MultiscaleRadiusNeighbourFinder([1, 10], [3, 4])
        multiscale = []
        for i in range(2):
            multiscale.append(nei_finder(x, y, batch_x, batch_y, i))

        self.assertEqual(len(multiscale), 2)
        self.assertEqual(multiscale[0][1, :].shape[0], 4)
        self.assertEqual(multiscale[1][1, :].shape[0], 8)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 37:</b> &nbsp; 2 fragments, nominal size 17 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1212')" href="javascript:;">
torch-points3d-1.2.0/test/test_panoptictracker.py: 48-66
</a>
<div class="mid" id="frag1212" style="display:none"><pre>
    def test_eval_single_class(self):
        gts = [
            _Instance(classname=1, indices=np.array([1, 2, 3]), score=1, scan_id=0),
            _Instance(classname=1, indices=np.array([4, 5]), score=1, scan_id=0),
            _Instance(classname=1, indices=np.array([6, 7, 8]), score=1, scan_id=0),
        ]

        preds = [
            _Instance(classname=1, indices=np.array([1, 2, 3]), score=1, scan_id=0),
            _Instance(classname=1, indices=np.array([6]), score=0, scan_id=0),
        ]
        meter = InstanceAPMeter()
        meter.add(preds, gts)

        rec, prec, ap = meter.eval(0.5)
        np.testing.assert_allclose(rec[1], np.asarray([1.0 / 3.0, 1.0 / 3.0]))
        np.testing.assert_allclose(prec[1], np.asarray([1.0, 1.0 / 2.0]))
        self.assertAlmostEqual(ap[1], 1.0 / 3.0)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1214')" href="javascript:;">
torch-points3d-1.2.0/test/test_panoptictracker.py: 83-104
</a>
<div class="mid" id="frag1214" style="display:none"><pre>
    def test_eval_two_classes(self):
        gts = [
            _Instance(classname=1, indices=np.array([1, 2, 3]), score=1, scan_id=0),
            _Instance(classname=1, indices=np.array([4, 5]), score=1, scan_id=0),
            _Instance(classname=2, indices=np.array([6, 7]), score=1, scan_id=0),
        ]

        preds = [
            _Instance(classname=1, indices=np.array([1, 2, 3]), score=1, scan_id=0),
            _Instance(classname=2, indices=np.array([6]), score=0, scan_id=0),
        ]
        meter = InstanceAPMeter()
        meter.add(preds, gts)

        rec, prec, _ = meter.eval(0.25)
        np.testing.assert_allclose(rec[1], np.asarray([1.0 / 2.0]))
        np.testing.assert_allclose(prec[1], np.asarray([1.0]))

        np.testing.assert_allclose(rec[2], np.asarray([1.0]))
        np.testing.assert_allclose(prec[2], np.asarray([1.0]))


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 38:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 73%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1222')" href="javascript:;">
torch-points3d-1.2.0/test/test_panoptictracker.py: 155-168
</a>
<div class="mid" id="frag1222" style="display:none"><pre>
    def test_track_basic(self):
        tracker = PanopticTracker(MockDataset())
        model = MockModel()
        tracker.track(
            model,
            data=Data(pos=torch.tensor([[1, 2]]), batch=torch.tensor([0, 0, 0])),
            min_cluster_points=0,
            iou_threshold=0.25,
        )
        metrics = tracker.get_metrics()
        self.assertAlmostEqual(metrics["train_Iacc"], 1)
        self.assertAlmostEqual(metrics["train_pos"], 1)
        self.assertAlmostEqual(metrics["train_neg"], 0)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1223')" href="javascript:;">
torch-points3d-1.2.0/test/test_panoptictracker.py: 169-185
</a>
<div class="mid" id="frag1223" style="display:none"><pre>
    def test_track_finalise(self):
        tracker = PanopticTracker(MockDataset())
        model = MockModel()
        tracker.track(
            model,
            data=Data(pos=torch.tensor([[1, 2]]), batch=torch.tensor([0, 0, 0])),
            min_cluster_points=0,
            iou_threshold=0.25,
            track_instances=True,
        )
        tracker.finalise(
            track_instances=True, iou_threshold=0.25,
        )
        metrics = tracker.get_metrics()
        self.assertAlmostEqual(metrics["train_map"], 1)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 39:</b> &nbsp; 4 fragments, nominal size 10 lines, similarity 81%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1245')" href="javascript:;">
torch-points3d-1.2.0/test/test_registration_metrics.py: 22-35
</a>
<div class="mid" id="frag1245" style="display:none"><pre>
    def test_estimate_transfo(self):

        a = torch.randn(100, 3)

        R_gt = euler_angles_to_rotation_matrix(torch.rand(3) * np.pi)
        t_gt = torch.rand(3)
        T_gt = torch.eye(4)
        T_gt[:3, :3] = R_gt
        T_gt[:3, 3] = t_gt
        b = a.mm(R_gt.T) + t_gt
        T_pred = estimate_transfo(a, b)

        npt.assert_allclose(T_pred.numpy(), T_gt.numpy(), rtol=1e-3)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1247')" href="javascript:;">
torch-points3d-1.2.0/test/test_registration_metrics.py: 48-60
</a>
<div class="mid" id="frag1247" style="display:none"><pre>
    def test_fast_global_registration_with_outliers(self):
        a = torch.randn(100, 3)
        R_gt = euler_angles_to_rotation_matrix(torch.rand(3) * np.pi)
        t_gt = torch.rand(3)
        T_gt = torch.eye(4)
        T_gt[:3, :3] = R_gt
        T_gt[:3, 3] = t_gt
        b = a.mm(R_gt.T) + t_gt
        b[[1, 5, 20, 32, 74, 17, 27, 77, 88, 89]] *= 42
        T_pred = fast_global_registration(a, b, mu_init=1, num_iter=20)
        # T_pred = estimate_transfo(a, b)
        npt.assert_allclose(T_pred.numpy(), T_gt.numpy(), rtol=1e-3)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1246')" href="javascript:;">
torch-points3d-1.2.0/test/test_registration_metrics.py: 36-47
</a>
<div class="mid" id="frag1246" style="display:none"><pre>
    def test_fast_global_registration(self):
        a = torch.randn(100, 3)

        R_gt = euler_angles_to_rotation_matrix(torch.rand(3) * np.pi)
        t_gt = torch.rand(3)
        T_gt = torch.eye(4)
        T_gt[:3, :3] = R_gt
        T_gt[:3, 3] = t_gt
        b = a.mm(R_gt.T) + t_gt
        T_pred = fast_global_registration(a, b, mu_init=1, num_iter=20)
        npt.assert_allclose(T_pred.numpy(), T_gt.numpy(), rtol=1e-3)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1248')" href="javascript:;">
torch-points3d-1.2.0/test/test_registration_metrics.py: 61-73
</a>
<div class="mid" id="frag1248" style="display:none"><pre>
    def test_ransac(self):
        a = torch.randn(100, 3)
        R_gt = euler_angles_to_rotation_matrix(torch.rand(3) * np.pi)
        t_gt = torch.rand(3)
        T_gt = torch.eye(4)
        T_gt[:3, :3] = R_gt
        T_gt[:3, 3] = t_gt
        b = a.mm(R_gt.T) + t_gt
        b[[1, 5, 20, 32, 74, 17, 27, 77, 88, 89]] *= 42
        T_pred = ransac_registration(a, b, distance_threshold=0.01)
        # T_pred = estimate_transfo(a, b)
        npt.assert_allclose(T_pred.numpy(), T_gt.numpy(), rtol=1e-3)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 40:</b> &nbsp; 3 fragments, nominal size 16 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1268')" href="javascript:;">
torch-points3d-1.2.0/test/test_trainer.py: 19-43
</a>
<div class="mid" id="frag1268" style="display:none"><pre>
    def test_trainer_on_shapenet_fixed(self):
        self.path_outputs = os.path.join(DIR_PATH, "data/shapenet/outputs")
        if not os.path.exists(self.path_outputs):
            os.makedirs(self.path_outputs)
        os.chdir(self.path_outputs)

        cfg = OmegaConf.load(os.path.join(DIR_PATH, "data/shapenet/shapenet_config.yaml"))
        cfg.training.epochs = 2
        cfg.training.num_workers = 0
        cfg.data.is_test = True
        cfg.data.dataroot = os.path.join(DIR_PATH, "data/")

        trainer = Trainer(cfg)
        trainer.train()

        self.assertEqual(trainer.early_break, True)
        self.assertEqual(trainer.profiling, False)
        self.assertEqual(trainer.precompute_multi_scale, False)
        self.assertEqual(trainer.wandb_log, False)

        keys = [k for k in trainer._tracker.get_metrics().keys()]
        self.assertEqual(keys, ["test_loss_seg", "test_Cmiou", "test_Imiou"])
        trainer._cfg.voting_runs = 2
        trainer.eval()

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1270')" href="javascript:;">
torch-points3d-1.2.0/test/test_trainer.py: 58-74
</a>
<div class="mid" id="frag1270" style="display:none"><pre>
    def test_trainer_on_scannet_segmentation(self):
        self.path_outputs = os.path.join(DIR_PATH, "data/scannet/outputs")
        if not os.path.exists(self.path_outputs):
            os.makedirs(self.path_outputs)
        os.chdir(self.path_outputs)
        cfg = OmegaConf.load(os.path.join(DIR_PATH, "data/scannet/config_segmentation.yaml"))
        cfg.training.epochs = 2
        cfg.training.num_workers = 0
        cfg.data.is_test = True
        cfg.data.dataroot = os.path.join(DIR_PATH, "data/")
        trainer = Trainer(cfg)
        trainer.train()
        trainer._cfg.voting_runs = 2
        trainer._cfg.tracker_options.full_res = True
        trainer._cfg.tracker_options.make_submission = True
        trainer.eval()

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1269')" href="javascript:;">
torch-points3d-1.2.0/test/test_trainer.py: 44-57
</a>
<div class="mid" id="frag1269" style="display:none"><pre>
    def test_trainer_on_scannet_object_detection(self):
        self.path_outputs = os.path.join(DIR_PATH, "data/scannet-fixed/outputs")
        if not os.path.exists(self.path_outputs):
            os.makedirs(self.path_outputs)
        os.chdir(self.path_outputs)

        cfg = OmegaConf.load(os.path.join(DIR_PATH, "data/scannet-fixed/config_object_detection.yaml"))
        cfg.training.epochs = 2
        cfg.training.num_workers = 0
        cfg.data.is_test = True
        cfg.data.dataroot = os.path.join(DIR_PATH, "data/")
        trainer = Trainer(cfg)
        trainer.train()

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 41:</b> &nbsp; 4 fragments, nominal size 49 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1288')" href="javascript:;">
torch-points3d-1.2.0/test/test_api.py: 38-96
</a>
<div class="mid" id="frag1288" style="display:none"><pre>
    def test_kpconv(self):
        from torch_points3d.applications.kpconv import KPConv

        input_nc = 3
        num_layers = 4
        grid_sampling = 0.02
        in_feat = 32
        model = KPConv(
            architecture="unet",
            input_nc=input_nc,
            in_feat=in_feat,
            in_grid_size=grid_sampling,
            num_layers=num_layers,
            config=None,
        )
        dataset = MockDatasetGeometric(input_nc + 1, transform=GridSampling3D(0.01), num_points=128)
        self.assertEqual(len(model._modules["down_modules"]), num_layers + 1)
        self.assertEqual(len(model._modules["inner_modules"]), 1)
        self.assertEqual(len(model._modules["up_modules"]), 4)
        self.assertFalse(model.has_mlp_head)
        self.assertEqual(model.output_nc, in_feat)

        try:
            data_out = model.forward(dataset[0])
            self.assertEqual(data_out.x.shape[1], in_feat)
        except Exception as e:
            print("Model failing:")
            print(model)
            raise e

        input_nc = 3
        num_layers = 4
        grid_sampling = 0.02
        in_feat = 32
        output_nc = 5
        model = KPConv(
            architecture="unet",
            input_nc=input_nc,
            output_nc=output_nc,
            in_feat=in_feat,
            in_grid_size=grid_sampling,
            num_layers=num_layers,
            config=None,
        )
        dataset = MockDatasetGeometric(input_nc + 1, transform=GridSampling3D(0.01), num_points=128)
        self.assertEqual(len(model._modules["down_modules"]), num_layers + 1)
        self.assertEqual(len(model._modules["inner_modules"]), 1)
        self.assertEqual(len(model._modules["up_modules"]), 4)
        self.assertTrue(model.has_mlp_head)
        self.assertEqual(model.output_nc, output_nc)

        try:
            data_out = model.forward(dataset[0])
            self.assertEqual(data_out.x.shape[1], output_nc)
        except Exception as e:
            print("Model failing:")
            print(model)
            raise e

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1295')" href="javascript:;">
torch-points3d-1.2.0/test/test_api.py: 309-360
</a>
<div class="mid" id="frag1295" style="display:none"><pre>
    def test_minkowski(self):
        from torch_points3d.applications.minkowski import Minkowski

        input_nc = 3
        num_layers = 4
        in_feat = 16
        model = Minkowski(
            architecture="encoder", input_nc=input_nc, in_feat=in_feat, num_layers=num_layers, config=None,
        )
        dataset = MockDatasetGeometric(input_nc, transform=GridSampling3D(0.01, quantize_coords=True), num_points=128)
        self.assertEqual(len(model._modules["down_modules"]), num_layers + 1)
        self.assertEqual(len(model._modules["inner_modules"]), 1)
        self.assertFalse(model.has_mlp_head)
        self.assertEqual(model.output_nc, 8 * in_feat)

        try:
            data_out = model.forward(dataset[0])
            # self.assertEqual(data_out.x.shape[1], 8 * in_feat)
        except Exception as e:
            print("Model failing:")
            print(model)
            raise e

        input_nc = 3
        num_layers = 4
        grid_sampling = 0.02
        in_feat = 32
        output_nc = 5
        model = Minkowski(
            architecture="encoder",
            input_nc=input_nc,
            output_nc=output_nc,
            in_feat=in_feat,
            in_grid_size=grid_sampling,
            num_layers=num_layers,
            config=None,
        )
        dataset = MockDatasetGeometric(input_nc, transform=GridSampling3D(0.01, quantize_coords=True), num_points=128)
        self.assertEqual(len(model._modules["down_modules"]), num_layers + 1)
        self.assertEqual(len(model._modules["inner_modules"]), 1)
        self.assertTrue(model.has_mlp_head)
        self.assertEqual(model.output_nc, output_nc)

        try:
            data_out = model.forward(dataset[0])
            self.assertEqual(data_out.x.shape[1], output_nc)
        except Exception as e:
            print("Model failing:")
            print(model)
            raise e


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1292')" href="javascript:;">
torch-points3d-1.2.0/test/test_api.py: 200-256
</a>
<div class="mid" id="frag1292" style="display:none"><pre>
    def test_kpconv(self):
        from torch_points3d.applications.kpconv import KPConv

        input_nc = 3
        num_layers = 4
        grid_sampling = 0.02
        in_feat = 16
        model = KPConv(
            architecture="encoder",
            input_nc=input_nc,
            in_feat=in_feat,
            in_grid_size=grid_sampling,
            num_layers=num_layers,
            config=None,
        )
        dataset = MockDatasetGeometric(input_nc + 1, transform=GridSampling3D(0.01), num_points=128)
        self.assertEqual(len(model._modules["down_modules"]), num_layers + 1)
        self.assertEqual(len(model._modules["inner_modules"]), 1)
        self.assertFalse(model.has_mlp_head)
        self.assertEqual(model.output_nc, 32 * in_feat)

        try:
            data_out = model.forward(dataset[0])
            self.assertEqual(data_out.x.shape[1], 32 * in_feat)
        except Exception as e:
            print("Model failing:")
            print(model)
            raise e

        input_nc = 3
        num_layers = 4
        grid_sampling = 0.02
        in_feat = 32
        output_nc = 5
        model = KPConv(
            architecture="encoder",
            input_nc=input_nc,
            output_nc=output_nc,
            in_feat=in_feat,
            in_grid_size=grid_sampling,
            num_layers=num_layers,
            config=None,
        )
        dataset = MockDatasetGeometric(input_nc + 1, transform=GridSampling3D(0.01), num_points=128)
        self.assertEqual(len(model._modules["down_modules"]), num_layers + 1)
        self.assertEqual(len(model._modules["inner_modules"]), 1)
        self.assertTrue(model.has_mlp_head)
        self.assertEqual(model.output_nc, output_nc)

        try:
            data_out = model.forward(dataset[0])
            self.assertEqual(data_out.x.shape[1], output_nc)
        except Exception as e:
            print("Model failing:")
            print(model)
            raise e

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1291')" href="javascript:;">
torch-points3d-1.2.0/test/test_api.py: 151-198
</a>
<div class="mid" id="frag1291" style="display:none"><pre>
    def test_sparseconv3d(self):
        from torch_points3d.applications.sparseconv3d import SparseConv3d

        input_nc = 3
        num_layers = 4
        in_feat = 32
        out_feat = in_feat * 3
        model = SparseConv3d(
            architecture="unet", input_nc=input_nc, in_feat=in_feat, num_layers=num_layers, config=None,
        )
        dataset = MockDatasetGeometric(input_nc, transform=GridSampling3D(0.01, quantize_coords=True), num_points=128)
        self.assertEqual(len(model._modules["down_modules"]), num_layers + 1)
        self.assertEqual(len(model._modules["inner_modules"]), 1)
        self.assertEqual(len(model._modules["up_modules"]), 4 + 1)
        self.assertFalse(model.has_mlp_head)
        self.assertEqual(model.output_nc, out_feat)

        try:
            data_out = model.forward(dataset[0])
            self.assertEqual(data_out.x.shape[1], out_feat)
        except Exception as e:
            print("Model failing:")
            print(model)
            print(e)

        input_nc = 3
        num_layers = 4

        output_nc = 5
        model = SparseConv3d(
            architecture="unet", input_nc=input_nc, output_nc=output_nc, num_layers=num_layers, config=None,
        )
        dataset = MockDatasetGeometric(input_nc, transform=GridSampling3D(0.01, quantize_coords=True), num_points=128)
        self.assertEqual(len(model._modules["down_modules"]), num_layers + 1)
        self.assertEqual(len(model._modules["inner_modules"]), 1)
        self.assertEqual(len(model._modules["up_modules"]), 4 + 1)
        self.assertTrue(model.has_mlp_head)
        self.assertEqual(model.output_nc, output_nc)

        try:
            data_out = model.forward(dataset[0])
            self.assertEqual(data_out.x.shape[1], output_nc)
        except Exception as e:
            print("Model failing:")
            print(model)
            raise e


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 42:</b> &nbsp; 4 fragments, nominal size 24 lines, similarity 91%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1289')" href="javascript:;">
torch-points3d-1.2.0/test/test_api.py: 97-123
</a>
<div class="mid" id="frag1289" style="display:none"><pre>
    def test_pn2(self):
        from torch_points3d.applications.pointnet2 import PointNet2

        input_nc = 2
        num_layers = 3
        output_nc = 5
        model = PointNet2(
            architecture="unet",
            input_nc=input_nc,
            output_nc=output_nc,
            num_layers=num_layers,
            multiscale=True,
            config=None,
        )
        dataset = MockDataset(input_nc, num_points=512)
        self.assertEqual(len(model._modules["down_modules"]), num_layers - 1)
        self.assertEqual(len(model._modules["inner_modules"]), 1)
        self.assertEqual(len(model._modules["up_modules"]), num_layers)

        try:
            data_out = model.forward(dataset[0])
            self.assertEqual(data_out.x.shape[1], output_nc)
        except Exception as e:
            print("Model failing:")
            print(model)
            raise e

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1293')" href="javascript:;">
torch-points3d-1.2.0/test/test_api.py: 257-282
</a>
<div class="mid" id="frag1293" style="display:none"><pre>
    def test_pn2(self):
        from torch_points3d.applications.pointnet2 import PointNet2

        input_nc = 2
        num_layers = 3
        output_nc = 5
        model = PointNet2(
            architecture="encoder",
            input_nc=input_nc,
            output_nc=output_nc,
            num_layers=num_layers,
            multiscale=True,
            config=None,
        )
        dataset = MockDataset(input_nc, num_points=512)
        self.assertEqual(len(model._modules["down_modules"]), num_layers - 1)
        self.assertEqual(len(model._modules["inner_modules"]), 1)

        try:
            data_out = model.forward(dataset[0])
            self.assertEqual(data_out.x.shape[1], output_nc)
        except Exception as e:
            print("Model failing:")
            print(model)
            raise e

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1290')" href="javascript:;">
torch-points3d-1.2.0/test/test_api.py: 124-150
</a>
<div class="mid" id="frag1290" style="display:none"><pre>
    def test_rsconv(self):
        from torch_points3d.applications.rsconv import RSConv

        input_nc = 2
        num_layers = 4
        output_nc = 5
        model = RSConv(
            architecture="unet",
            input_nc=input_nc,
            output_nc=output_nc,
            num_layers=num_layers,
            multiscale=True,
            config=None,
        )
        dataset = MockDataset(input_nc, num_points=1024)
        self.assertEqual(len(model._modules["down_modules"]), num_layers)
        self.assertEqual(len(model._modules["inner_modules"]), 2)
        self.assertEqual(len(model._modules["up_modules"]), num_layers)

        try:
            data_out = model.forward(dataset[0])
            self.assertEqual(data_out.x.shape[1], output_nc)
        except Exception as e:
            print("Model failing:")
            print(model)
            raise e

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1294')" href="javascript:;">
torch-points3d-1.2.0/test/test_api.py: 283-308
</a>
<div class="mid" id="frag1294" style="display:none"><pre>
    def test_rsconv(self):
        from torch_points3d.applications.rsconv import RSConv

        input_nc = 2
        num_layers = 4
        output_nc = 5
        model = RSConv(
            architecture="encoder",
            input_nc=input_nc,
            output_nc=output_nc,
            num_layers=num_layers,
            multiscale=True,
            config=None,
        )
        dataset = MockDataset(input_nc, num_points=1024)
        self.assertEqual(len(model._modules["down_modules"]), num_layers)
        self.assertEqual(len(model._modules["inner_modules"]), 1)

        try:
            data_out = model.forward(dataset[0])
            self.assertEqual(data_out.x.shape[1], output_nc)
        except Exception as e:
            print("Model failing:")
            print(model)
            raise e

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 43:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1317')" href="javascript:;">
torch-points3d-1.2.0/test/test_shapenetforward.py: 60-72
</a>
<div class="mid" id="frag1317" style="display:none"><pre>
    def test_predictupsampledense(self):
        dataset = ForwardShapenetDataset(self.config)
        dataset.create_dataloaders(MockModel(DictConfig({"conv_type": "DENSE"})), 2, False, 1, False)
        forward_set = dataset.test_dataloaders[0]
        for b in forward_set:
            output = torch.tensor([[1, 0], [1, 0], [0, 1], [0, 1]])
            predicted = dataset.predict_original_samples(b, "DENSE", output)
            self.assertEqual(len(predicted), 2)
            self.assertEqual(predicted["example1.txt"].shape, (3, 4))
            self.assertEqual(predicted["example2.txt"].shape, (4, 4))
            npt.assert_allclose(predicted["example1.txt"][:, -1], np.asarray([0, 0, 0]))
            npt.assert_allclose(predicted["example2.txt"][:, -1], np.asarray([1, 1, 1, 1]))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1318')" href="javascript:;">
torch-points3d-1.2.0/test/test_shapenetforward.py: 73-85
</a>
<div class="mid" id="frag1318" style="display:none"><pre>
    def test_predictupsamplepartialdense(self):
        dataset = ForwardShapenetDataset(self.config)
        dataset.create_dataloaders(MockModel(DictConfig({"conv_type": "PARTIAL_DENSE"})), 2, False, 1, False)
        forward_set = dataset.test_dataloaders[0]
        for b in forward_set:
            output = torch.tensor([[1, 0], [1, 0], [0, 1], [0, 1]])
            predicted = dataset.predict_original_samples(b, "PARTIAL_DENSE", output)
            self.assertEqual(len(predicted), 2)
            self.assertEqual(predicted["example1.txt"].shape, (3, 4))
            self.assertEqual(predicted["example2.txt"].shape, (4, 4))
            npt.assert_allclose(predicted["example1.txt"][:, -1], np.asarray([0, 0, 0]))
            npt.assert_allclose(predicted["example2.txt"][:, -1], np.asarray([1, 1, 1, 1]))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 44:</b> &nbsp; 2 fragments, nominal size 16 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1327')" href="javascript:;">
torch-points3d-1.2.0/test/test_transform.py: 152-167
</a>
<div class="mid" id="frag1327" style="display:none"><pre>
    def test_AddFeatsByKeys(self):
        N = 10
        mapping = {"a": 1, "b": 2, "c": 3, "d": 4}
        keys, values = np.asarray(list(mapping.keys())), np.asarray(list(mapping.values()))
        data = Data(
            a=torch.randn((N, 1)),
            b=torch.randn((N, 2)),
            c=torch.randn((N, 3)),
            d=torch.randn((N, 4)),
            pos=torch.randn((N)),
        )
        mask = np.random.uniform(0, 1, (4)) &gt; 0.1
        transform = AddFeatsByKeys(mask, keys)
        data_out = transform(data)
        self.assertEqual(data_out.x.shape[-1], np.sum(values[mask]))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1328')" href="javascript:;">
torch-points3d-1.2.0/test/test_transform.py: 168-184
</a>
<div class="mid" id="frag1328" style="display:none"><pre>
    def test_RemoveAttributes(self):
        N = 10
        mapping = {"a": 1, "b": 2, "c": 3, "d": 4}
        keys = np.asarray(list(mapping.keys()))
        data = Data(
            a=torch.randn((N, 1)),
            b=torch.randn((N, 2)),
            c=torch.randn((N, 3)),
            d=torch.randn((N, 4)),
            pos=torch.randn((N)),
        )
        mask = np.random.uniform(0, 1, (4)) &gt; 0.5
        transform = RemoveAttributes(keys[mask])
        data_out = transform(data)
        for key in keys[mask]:
            self.assertNotIn(key, list(data_out.keys))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 45:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1342')" href="javascript:;">
torch-points3d-1.2.0/test/test_transform.py: 342-355
</a>
<div class="mid" id="frag1342" style="display:none"><pre>
    def test_lottery_transform(self):
        """
        test the lottery transform when params are indicated in the yaml
        """
        pos = torch.randn(10000, 3)
        x = torch.randn(10000, 6)
        dummy = torch.randn(10000, 6)
        data = Data(pos=pos, x=x, dummy=dummy)
        conf = ListConfig([{"transform": "GridSampling3D", "params": {"size": 0.1}}, {"transform": "Center"},])
        tr = LotteryTransform(transform_options=conf)
        tr(data)
        self.assertIsInstance(tr.random_transforms.transforms[0], GridSampling3D)
        self.assertIsInstance(tr.random_transforms.transforms[1], T.Center)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1343')" href="javascript:;">
torch-points3d-1.2.0/test/test_transform.py: 356-380
</a>
<div class="mid" id="frag1343" style="display:none"><pre>
    def test_lottery_transform_from_yaml(self):
        """
        test the lottery transform when params are indicated in the yaml
        """
        string = """

        - transform: LotteryTransform
          params:
            transform_options:
              - transform: GridSampling3D
                params:
                  size: 0.1
              - transform: Center
        """
        conf = OmegaConf.create(string)
        pos = torch.randn(10000, 3)
        x = torch.randn(10000, 6)
        dummy = torch.randn(10000, 6)
        data = Data(pos=pos, x=x, dummy=dummy)

        tr = instantiate_transforms(conf).transforms[0]
        tr(data)
        self.assertIsInstance(tr.random_transforms.transforms[0], GridSampling3D)
        self.assertIsInstance(tr.random_transforms.transforms[1], T.Center)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<script language="JavaScript">
function ShowHide(divId) { 
    if(document.getElementById(divId).style.display == 'none') {
        document.getElementById(divId).style.display='block';
    } else { 
        document.getElementById(divId).style.display = 'none';
    } 
}
</script>
</body>
</html>
