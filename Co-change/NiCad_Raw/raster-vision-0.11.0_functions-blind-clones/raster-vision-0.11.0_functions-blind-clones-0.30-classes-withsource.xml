<clones>
<systeminfo processor="nicad6" system="raster-vision-0.11.0" granularity="functions-blind" threshold="30%" minlines="10" maxlines="2500"/>
<cloneinfo npcs="2959" npairs="438"/>
<runinfo ncompares="132197" cputime="101903"/>
<classinfo nclasses="164"/>

<class classid="1" nclones="2" nlines="16" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/cli/main.py" startline="226" endline="246" pcid="29">
    def add_to_parser(self, parser, ctx):
        def parser_process(value, state):
            value = str(value)
            while state.rargs:
                value = '{} {}'.format(value, state.rargs.pop(0))
            self._previous_parser_process(value, state)

        retval = super(OptionEatAll, self).add_to_parser(parser, ctx)

        for name in self.opts:
            our_parser = parser._long_opt.get(name) or parser._short_opt.get(
                name)
            if our_parser:
                self._eat_all_parser = our_parser
                self._previous_parser_process = our_parser.process
                our_parser.process = parser_process
                break

        return retval


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/cli.py" startline="17" endline="37" pcid="1905">
    def add_to_parser(self, parser, ctx):
        def parser_process(value, state):
            value = str(value)
            while state.rargs:
                value = '{} {}'.format(value, state.rargs.pop(0))
            self._previous_parser_process(value, state)

        retval = super(OptionEatAll, self).add_to_parser(parser, ctx)

        for name in self.opts:
            our_parser = parser._long_opt.get(name) or parser._short_opt.get(
                name)
            if our_parser:
                self._eat_all_parser = our_parser
                self._previous_parser_process = our_parser.process
                our_parser.process = parser_process
                break

        return retval


</source>
</class>

<class classid="2" nclones="5" nlines="19" similarity="72">
<source file="systems/raster-vision-0.11.0/rastervision/backend/pytorch_semantic_segmentation_config.py" startline="13" endline="32" pcid="33">
    def __init__(self,
                 batch_size=None,
                 lr=None,
                 one_cycle=None,
                 num_epochs=None,
                 model_arch=None,
                 sync_interval=None,
                 debug=None,
                 log_tensorboard=None,
                 run_tensorboard=None):
        self.batch_size = batch_size
        self.lr = lr
        self.one_cycle = one_cycle
        self.num_epochs = num_epochs
        self.model_arch = model_arch
        self.sync_interval = sync_interval
        self.debug = debug
        self.log_tensorboard = log_tensorboard
        self.run_tensorboard = run_tensorboard

</source>
<source file="systems/raster-vision-0.11.0/rastervision/evaluation/class_evaluation_item.py" startline="13" endline="32" pcid="1107">
    def __init__(self,
                 precision=None,
                 recall=None,
                 f1=None,
                 count_error=None,
                 gt_count=0,
                 class_id=None,
                 class_name=None,
                 conf_mat=None):
        self.precision = precision
        self.recall = recall
        self.f1 = f1
        self.count_error = count_error
        # Ground truth count of elements (boxes for object detection, pixels
        # for segmentation, cells for classification).
        self.gt_count = gt_count
        self.conf_mat = conf_mat
        self.class_id = class_id
        self.class_name = class_name

</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/evaluation/class_evaluation_item.py" startline="13" endline="32" pcid="1949">
    def __init__(self,
                 precision=None,
                 recall=None,
                 f1=None,
                 count_error=None,
                 gt_count=0,
                 class_id=None,
                 class_name=None,
                 conf_mat=None):
        self.precision = precision
        self.recall = recall
        self.f1 = f1
        self.count_error = count_error
        # Ground truth count of elements (boxes for object detection, pixels
        # for segmentation, cells for classification).
        self.gt_count = gt_count
        self.conf_mat = conf_mat
        self.class_id = class_id
        self.class_name = class_name

</source>
<source file="systems/raster-vision-0.11.0/rastervision/backend/pytorch_object_detection_config.py" startline="13" endline="32" pcid="38">
    def __init__(self,
                 batch_size=None,
                 lr=None,
                 one_cycle=None,
                 num_epochs=None,
                 model_arch=None,
                 sync_interval=None,
                 log_tensorboard=None,
                 run_tensorboard=None,
                 debug=None):
        self.batch_size = batch_size
        self.lr = lr
        self.one_cycle = one_cycle
        self.num_epochs = num_epochs
        self.model_arch = model_arch
        self.sync_interval = sync_interval
        self.log_tensorboard = log_tensorboard
        self.run_tensorboard = run_tensorboard
        self.debug = debug

</source>
<source file="systems/raster-vision-0.11.0/rastervision/backend/pytorch_chip_classification_config.py" startline="13" endline="38" pcid="163">
    def __init__(self,
                 batch_size=None,
                 lr=None,
                 one_cycle=None,
                 num_epochs=None,
                 model_arch=None,
                 sync_interval=None,
                 debug=None,
                 log_tensorboard=None,
                 run_tensorboard=None,
                 rare_classes=None,
                 desired_prob=None,
                 augmentors=[]):
        self.batch_size = batch_size
        self.lr = lr
        self.one_cycle = one_cycle
        self.num_epochs = num_epochs
        self.model_arch = model_arch
        self.sync_interval = sync_interval
        self.debug = debug
        self.log_tensorboard = log_tensorboard
        self.run_tensorboard = run_tensorboard
        self.rare_classes = rare_classes
        self.desired_prob = desired_prob
        self.augmentors = augmentors

</source>
</class>

<class classid="3" nclones="3" nlines="23" similarity="75">
<source file="systems/raster-vision-0.11.0/rastervision/backend/pytorch_semantic_segmentation_config.py" startline="51" endline="100" pcid="36">
    def with_train_options(self,
                           batch_size=8,
                           lr=1e-4,
                           one_cycle=True,
                           num_epochs=5,
                           model_arch='resnet50',
                           sync_interval=1,
                           debug=False,
                           log_tensorboard=True,
                           run_tensorboard=True):
        """Set options for training models.

        Args:
            batch_size: (int) the batch size
            lr: (float) the learning rate if using a fixed LR
                (ie. one_cycle is False),
                or the maximum LR to use if one_cycle is True
            one_cycle: (bool) True if cyclic learning rate scheduler should
                be used. This
                cycles the LR once during the course of training and seems to
                result in a pretty consistent improvement. See lr for more
                details.
            num_epochs: (int) number of epochs (sweeps through training set) to
                train model for
            model_arch: (str) classification model backbone to use for DeepLabV3
                architecture. Currently, only Resnet50 works.
            sync_interval: (int) sync training directory to cloud every
                sync_interval epochs.
            debug: (bool) if True, save debug chips (ie. visualizations of
                input to model during training) during training and use
                single-core for creating minibatches.
            log_tensorboard: (bool) if True, write events to Tensorboard log
                file
            run_tensorboard: (bool) if True, run a Tensorboard server at
                port 6006 that uses the logs generated by the log_tensorboard
                option
        """
        b = deepcopy(self)
        b.train_opts = TrainOptions(
            batch_size=batch_size,
            lr=lr,
            one_cycle=one_cycle,
            num_epochs=num_epochs,
            model_arch=model_arch,
            sync_interval=sync_interval,
            debug=debug,
            log_tensorboard=log_tensorboard,
            run_tensorboard=run_tensorboard)
        return b

</source>
<source file="systems/raster-vision-0.11.0/rastervision/backend/pytorch_object_detection_config.py" startline="52" endline="102" pcid="41">
    def with_train_options(self,
                           batch_size=8,
                           lr=1e-4,
                           one_cycle=True,
                           num_epochs=5,
                           model_arch='resnet18',
                           sync_interval=1,
                           log_tensorboard=True,
                           run_tensorboard=True,
                           debug=False):
        """Set options for training models.

        Args:
            batch_size: (int) the batch size
            lr: (float) the learning rate if using a fixed LR
                (ie. one_cycle is False),
                or the maximum LR to use if one_cycle is True
            one_cycle: (bool) True if cyclic learning rate scheduler should
                be used. This
                cycles the LR once during the course of training and seems to
                result in a pretty consistent improvement. See lr for more
                details.
            num_epochs: (int) number of epochs (sweeps through training set) to
                train model for
            model_arch: (str) classification model backbone to use.
                Any Resnet option in torchvision.models is valid,
                for example, resnet18.
            sync_interval: (int) sync training directory to cloud every
                sync_interval epochs.
            log_tensorboard: (bool) if True, write events to Tensorboard log
                file
            run_tensorboard: (bool) if True, run a Tensorboard server at
                port 6006 that uses the logs generated by the log_tensorboard
                option
            debug: (bool) if True, save debug chips (ie. visualizations of
                input to model during training) during training and use
                single-core for creating minibatches.
        """
        b = deepcopy(self)
        b.train_opts = TrainOptions(
            batch_size=batch_size,
            lr=lr,
            one_cycle=one_cycle,
            num_epochs=num_epochs,
            model_arch=model_arch,
            sync_interval=sync_interval,
            log_tensorboard=log_tensorboard,
            run_tensorboard=run_tensorboard,
            debug=debug)
        return b

</source>
<source file="systems/raster-vision-0.11.0/rastervision/backend/pytorch_chip_classification_config.py" startline="57" endline="124" pcid="166">
    def with_train_options(self,
                           batch_size=8,
                           lr=1e-4,
                           one_cycle=True,
                           num_epochs=1,
                           model_arch='resnet18',
                           sync_interval=1,
                           debug=False,
                           log_tensorboard=True,
                           run_tensorboard=True,
                           rare_classes=[],
                           desired_prob=None,
                           augmentors=[]):
        """Set options for training models.

        Args:
            batch_size: (int) the batch size
            weight_decay: (float) the weight decay
            lr: (float) the learning rate if using a fixed LR
                (ie. one_cycle is False),
                or the maximum LR to use if one_cycle is True
            one_cycle: (bool) True if cyclic learning rate scheduler should
                be used. This
                cycles the LR once during the course of training and seems to
                result in a pretty consistent improvement. See lr for more
                details.
            num_epochs: (int) number of epochs (sweeps through training set) to
                train model for
            model_arch: (str) Any classification model option in
                torchvision.models is valid, for example, resnet18.
            sync_interval: (int) sync training directory to cloud every
                sync_interval epochs.
            debug: (bool) if True, save debug chips (ie. visualizations of
                input to model during training) during training and use
                single-core for creating minibatches.
            log_tensorboard: (bool) if True, write events to Tensorboard log
                file
            run_tensorboard: (bool) if True, run a Tensorboard server at
                port 6006 that uses the logs generated by the log_tensorboard
                option
            rare_classes: (list) of integers with class indices that should be
                oversampled during the training. The goal is to reduce the effect
                of severe class imbalance influencing training.
            desired_prob: (float) when a list of rare classes is given, a single
                float can be given (between 0.0 and 1.0) indicating the desired
                probability of the rare classes. If e.g. set to 0.5, the change of
                drawing any rare class sample is 0.5.
            augmentors: (list of str) any of ['Blur', 'RandomRotate90', 'HorizontalFlip',
                'VerticalFlip', 'GaussianBlur', or 'GaussNoise', 'RGBShift', 'ToGray'].
                These use the default settings for each of the transforms in
                https://albumentations.readthedocs.io
        """
        b = deepcopy(self)
        b.train_opts = TrainOptions(
            batch_size=batch_size,
            lr=lr,
            one_cycle=one_cycle,
            num_epochs=num_epochs,
            model_arch=model_arch,
            sync_interval=sync_interval,
            debug=debug,
            log_tensorboard=log_tensorboard,
            run_tensorboard=run_tensorboard,
            rare_classes=rare_classes,
            desired_prob=desired_prob,
            augmentors=augmentors)
        return b

</source>
</class>

<class classid="4" nclones="3" nlines="11" similarity="72">
<source file="systems/raster-vision-0.11.0/rastervision/backend/keras_classification/utils.py" startline="16" endline="31" pcid="48">
def make_dir(path, check_empty=False, force_empty=False, use_dirname=False):
    directory = path
    if use_dirname:
        directory = os.path.dirname(path)

    if force_empty and os.path.isdir(directory):
        shutil.rmtree(directory)

    os.makedirs(directory, exist_ok=True)

    is_empty = len(os.listdir(directory)) == 0
    if check_empty and not is_empty:
        raise ValueError(
            '{} needs to be an empty directory!'.format(directory))


</source>
<source file="systems/raster-vision-0.11.0/rastervision/filesystem/local_filesystem.py" startline="9" endline="35" pcid="285">
def make_dir(path, check_empty=False, force_empty=False, use_dirname=False):
    """Make a local directory.

    Args:
        path: path to directory
        check_empty: if True, check that directory is empty
        force_empty: if True, delete files if necessary to make directory
            empty
        use_dirname: if True, use the the parent directory as path

    Raises:
        ValueError if check_empty is True and directory is not empty
    """
    directory = path
    if use_dirname:
        directory = os.path.abspath(os.path.dirname(path))

    if force_empty and os.path.isdir(directory):
        shutil.rmtree(directory)

    os.makedirs(directory, exist_ok=True)

    if check_empty and any(os.scandir(directory)):
        raise ValueError(
            '{} needs to be an empty directory!'.format(directory))


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/pipeline/file_system/local_file_system.py" startline="9" endline="35" pcid="1488">
def make_dir(path, check_empty=False, force_empty=False, use_dirname=False):
    """Make a local directory.

    Args:
        path: path to directory
        check_empty: if True, check that directory is empty
        force_empty: if True, delete files if necessary to make directory
            empty
        use_dirname: if True, use the the parent directory as path

    Raises:
        ValueError if check_empty is True and directory is not empty
    """
    directory = path
    if use_dirname:
        directory = os.path.abspath(os.path.dirname(path))

    if force_empty and os.path.isdir(directory):
        shutil.rmtree(directory)

    os.makedirs(directory, exist_ok=True)

    if check_empty and any(os.scandir(directory)):
        raise ValueError(
            '{} needs to be an empty directory!'.format(directory))


</source>
</class>

<class classid="5" nclones="2" nlines="18" similarity="94">
<source file="systems/raster-vision-0.11.0/rastervision/backend/torch_utils/semantic_segmentation/train.py" startline="8" endline="30" pcid="90">
def train_epoch(model, device, data_loader, opt, loss_fn, step_scheduler=None):
    model.train()
    total_loss = 0.0
    num_samples = 0

    with click.progressbar(data_loader, label='Training') as bar:
        for batch_ind, (x, y) in enumerate(bar):
            x = x.to(device)
            y = y.to(device)

            opt.zero_grad()
            out = model(x)['out']
            loss = loss_fn(out, y)
            loss.backward()
            total_loss += loss.item()
            opt.step()
            if step_scheduler:
                step_scheduler.step()
            num_samples += x.shape[0]

    return total_loss / num_samples


</source>
<source file="systems/raster-vision-0.11.0/rastervision/backend/torch_utils/chip_classification/train.py" startline="8" endline="30" pcid="147">
def train_epoch(model, device, data_loader, opt, loss_fn, step_scheduler=None):
    model.train()
    total_loss = 0.0
    num_samples = 0

    with click.progressbar(data_loader, label='Training') as bar:
        for batch_ind, (x, y) in enumerate(bar):
            x = x.to(device)
            y = y.to(device)

            opt.zero_grad()
            out = model(x)
            loss = loss_fn(out, y)
            loss.backward()
            total_loss += loss.item()
            opt.step()
            if step_scheduler:
                step_scheduler.step()
            num_samples += x.shape[0]

    return total_loss / num_samples


</source>
</class>

<class classid="6" nclones="2" nlines="12" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/backend/torch_utils/object_detection/model.py" startline="11" endline="29" pcid="95">
def get_out_channels(model):
    out = {}

    def make_save_output(layer_name):
        def save_output(layer, input, output):
            out[layer_name] = output.shape[1]

        return save_output

    model.layer1.register_forward_hook(make_save_output('layer1'))
    model.layer2.register_forward_hook(make_save_output('layer2'))
    model.layer3.register_forward_hook(make_save_output('layer3'))
    model.layer4.register_forward_hook(make_save_output('layer4'))

    model(torch.empty((1, 3, 128, 128)))
    return [out['layer1'], out['layer2'], out['layer3'], out['layer4']]


# This fixes a bug in torchvision.
</source>
<source file="systems/raster-vision-0.11.0/rastervision2/pytorch_learner/object_detection_utils.py" startline="325" endline="343" pcid="1399">
def get_out_channels(model):
    out = {}

    def make_save_output(layer_name):
        def save_output(layer, input, output):
            out[layer_name] = output.shape[1]

        return save_output

    model.layer1.register_forward_hook(make_save_output('layer1'))
    model.layer2.register_forward_hook(make_save_output('layer2'))
    model.layer3.register_forward_hook(make_save_output('layer3'))
    model.layer4.register_forward_hook(make_save_output('layer4'))

    model(torch.empty((1, 3, 128, 128)))
    return [out['layer1'], out['layer2'], out['layer3'], out['layer4']]


# This fixes a bug in torchvision.
</source>
</class>

<class classid="7" nclones="2" nlines="11" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/backend/torch_utils/object_detection/model.py" startline="30" endline="46" pcid="98">
def resnet_fpn_backbone(backbone_name, pretrained):
    backbone = resnet.__dict__[backbone_name](
        pretrained=pretrained, norm_layer=misc_nn_ops.FrozenBatchNorm2d)

    # freeze layers
    for name, parameter in backbone.named_parameters():
        if 'layer2' not in name and 'layer3' not in name and 'layer4' not in name:
            parameter.requires_grad_(False)

    return_layers = {'layer1': 0, 'layer2': 1, 'layer3': 2, 'layer4': 3}

    out_channels = 256
    in_channels_list = get_out_channels(backbone)
    return BackboneWithFPN(backbone, return_layers, in_channels_list,
                           out_channels)


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/pytorch_learner/object_detection_utils.py" startline="344" endline="360" pcid="1402">
def resnet_fpn_backbone(backbone_name, pretrained):
    backbone = resnet.__dict__[backbone_name](
        pretrained=pretrained, norm_layer=misc_nn_ops.FrozenBatchNorm2d)

    # freeze layers
    for name, parameter in backbone.named_parameters():
        if 'layer2' not in name and 'layer3' not in name and 'layer4' not in name:
            parameter.requires_grad_(False)

    return_layers = {'layer1': 0, 'layer2': 1, 'layer3': 2, 'layer4': 3}

    out_channels = 256
    in_channels_list = get_out_channels(backbone)
    return BackboneWithFPN(backbone, return_layers, in_channels_list,
                           out_channels)


</source>
</class>

<class classid="8" nclones="2" nlines="39" similarity="78">
<source file="systems/raster-vision-0.11.0/rastervision/backend/torch_utils/object_detection/model.py" startline="66" endline="128" pcid="100">
    def forward(self, input, targets=None):
        """Forward pass

        Args:
            input: tensor<n, 3, h, w> with batch of images
            targets: None or list<BoxList> of length n with boxes and labels

        Returns:
            if targets is None, returns list<BoxList> of length n, containing
            boxes, labels, and scores for boxes with score > 0.05. Further
            filtering based on score should be done before considering the
            prediction "final".

            if targets is a list, returns the losses as dict with keys from
            self.subloss_names.
        """
        if targets:
            # Add bogus background class box for each image to workaround
            # the inability of torchvision to train on images with
            # no ground truth boxes. This is important for being able
            # to handle negative chips generated by RV.
            new_targets = []
            for x, y in zip(input, targets):
                h, w = x.shape[1:]
                boxes = torch.cat(
                    [
                        y.boxes,
                        torch.tensor([[0., 0, h, w]], device=input.device)
                    ],
                    dim=0)
                labels = torch.cat(
                    [
                        y.get_field('labels'),
                        torch.tensor([0], device=input.device)
                    ],
                    dim=0)
                bl = BoxList(boxes, labels=labels)
                new_targets.append(bl)
            targets = new_targets

            _targets = [bl.xyxy() for bl in targets]
            _targets = [{
                'boxes': bl.boxes,
                'labels': bl.get_field('labels')
            } for bl in _targets]
            loss_dict = self.model(input, _targets)
            loss_dict['total_loss'] = sum(list(loss_dict.values()))
            return loss_dict

        out = self.model(input)
        boxlists = [
            BoxList(
                _out['boxes'], labels=_out['labels'],
                scores=_out['scores']).yxyx() for _out in out
        ]

        # Remove bogus background boxes.
        new_boxlists = []
        for bl in boxlists:
            labels = bl.get_field('labels')
            non_zero_inds = labels != 0
            new_boxlists.append(bl.ind_filter(non_zero_inds))
        return new_boxlists
</source>
<source file="systems/raster-vision-0.11.0/rastervision2/pytorch_learner/object_detection_utils.py" startline="422" endline="491" pcid="1405">
    def forward(self, input, targets=None):
        """Forward pass

        Args:
            input: tensor<n, 3, h, w> with batch of images
            targets: None or list<BoxList> of length n with boxes and class_ids

        Returns:
            if targets is None, returns list<BoxList> of length n, containing
            boxes, class_ids, and scores for boxes with score > 0.05. Further
            filtering based on score should be done before considering the
            prediction "final".

            if targets is a list, returns the losses as dict with keys from
            self.subloss_names.
        """
        if targets:
            # Add bogus background class box for each image to workaround
            # the inability of torchvision to train on images with
            # no ground truth boxes. This is important for being able
            # to handle negative chips generated by RV.
            # See https://github.com/pytorch/vision/issues/1598

            # Note class_ids must start at 1.
            new_targets = []
            for x, y in zip(input, targets):
                h, w = x.shape[1:]
                boxes = torch.cat(
                    [
                        y.boxes,
                        torch.tensor([[0., 0, h, w]], device=input.device)
                    ],
                    dim=0)
                class_ids = torch.cat(
                    [
                        y.get_field('class_ids') + 1,
                        torch.tensor(
                            [self.null_class_id + 1], device=input.device),
                    ],
                    dim=0)
                bl = BoxList(boxes, class_ids=class_ids)
                new_targets.append(bl)
            targets = new_targets

            _targets = [bl.xyxy() for bl in targets]
            _targets = [{
                'boxes': bl.boxes,
                'labels': bl.get_field('class_ids')
            } for bl in _targets]
            loss_dict = self.model(input, _targets)
            loss_dict['total_loss'] = sum(list(loss_dict.values()))

            return loss_dict

        out = self.model(input)
        boxlists = [
            BoxList(
                _out['boxes'], class_ids=_out['labels'],
                scores=_out['scores']).yxyx() for _out in out
        ]

        # Remove bogus background boxes.
        new_boxlists = []
        for bl in boxlists:
            class_ids = bl.get_field('class_ids') - 1
            non_null_inds = class_ids != self.null_class_id
            bl = bl.ind_filter(non_null_inds)
            bl.extras['class_ids'] -= 1
            new_boxlists.append(bl)
        return new_boxlists
</source>
</class>

<class classid="9" nclones="2" nlines="11" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/backend/torch_utils/object_detection/boxlist.py" startline="67" endline="78" pcid="112">
    def cat(box_lists):
        boxes = []
        extras = defaultdict(list)
        for bl in box_lists:
            boxes.append(bl.boxes)
            for k, v in bl.extras.items():
                extras[k].append(v)
        boxes = torch.cat(boxes)
        for k, v in extras.items():
            extras[k] = torch.cat(v)
        return BoxList(boxes, **extras)

</source>
<source file="systems/raster-vision-0.11.0/rastervision2/pytorch_learner/object_detection_utils.py" startline="185" endline="196" pcid="1387">
    def cat(box_lists):
        boxes = []
        extras = defaultdict(list)
        for bl in box_lists:
            boxes.append(bl.boxes)
            for k, v in bl.extras.items():
                extras[k].append(v)
        boxes = torch.cat(boxes)
        for k, v in extras.items():
            extras[k] = torch.cat(v)
        return BoxList(boxes, **extras)

</source>
</class>

<class classid="10" nclones="2" nlines="10" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/backend/torch_utils/object_detection/boxlist.py" startline="79" endline="94" pcid="113">
    def equal(self, other):
        if len(other) != len(self):
            return False

        # Ignore order of boxes.
        extras = [(v.float().unsqueeze(1) if v.ndim == 1 else v.float())
                  for v in self.extras.values()]
        cat_arr = torch.cat([self.boxes] + extras, 1)
        self_tups = set([tuple([x.item() for x in row]) for row in cat_arr])

        extras = [(v.float().unsqueeze(1) if v.ndim == 1 else v.float())
                  for v in other.extras.values()]
        cat_arr = torch.cat([other.boxes] + extras, 1)
        other_tups = set([tuple([x.item() for x in row]) for row in cat_arr])
        return self_tups == other_tups

</source>
<source file="systems/raster-vision-0.11.0/rastervision2/pytorch_learner/object_detection_utils.py" startline="197" endline="212" pcid="1388">
    def equal(self, other):
        if len(other) != len(self):
            return False

        # Ignore order of boxes.
        extras = [(v.float().unsqueeze(1) if v.ndim == 1 else v.float())
                  for v in self.extras.values()]
        cat_arr = torch.cat([self.boxes] + extras, 1)
        self_tups = set([tuple([x.item() for x in row]) for row in cat_arr])

        extras = [(v.float().unsqueeze(1) if v.ndim == 1 else v.float())
                  for v in other.extras.values()]
        cat_arr = torch.cat([other.boxes] + extras, 1)
        other_tups = set([tuple([x.item() for x in row]) for row in cat_arr])
        return self_tups == other_tups

</source>
</class>

<class classid="11" nclones="2" nlines="35" similarity="91">
<source file="systems/raster-vision-0.11.0/rastervision/backend/torch_utils/object_detection/metrics.py" startline="12" endline="54" pcid="136">
def get_coco_gt(targets, num_labels):
    images = []
    annotations = []
    ann_id = 1
    for img_id, target in enumerate(targets, 1):
        # Use fake height, width, and filename because they don't matter.
        images.append({
            'id': img_id,
            'height': 1000,
            'width': 1000,
            'file_name': '{}.png'.format(img_id)
        })
        boxes, labels = target.boxes, target.get_field('labels')
        for box, label in zip(boxes, labels):
            box = box.float().tolist()
            label = label.item()
            annotations.append({
                'id':
                ann_id,
                'image_id':
                img_id,
                'category_id':
                label,
                'area': (box[2] - box[0]) * (box[3] - box[1]),
                'bbox': [box[1], box[0], box[3] - box[1], box[2] - box[0]],
                'iscrowd':
                0
            })
            ann_id += 1

    categories = [{
        'id': label,
        'name': str(label),
        'supercategory': 'super'
    } for label in range(num_labels)]
    coco = {
        'images': images,
        'annotations': annotations,
        'categories': categories
    }
    return coco


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/pytorch_learner/object_detection_utils.py" startline="23" endline="65" pcid="1373">
def get_coco_gt(targets, num_class_ids):
    images = []
    annotations = []
    ann_id = 1
    for img_id, target in enumerate(targets, 1):
        # Use fake height, width, and filename because they don't matter.
        images.append({
            'id': img_id,
            'height': 1000,
            'width': 1000,
            'file_name': '{}.png'.format(img_id)
        })
        boxes, class_ids = target.boxes, target.get_field('class_ids')
        for box, class_id in zip(boxes, class_ids):
            box = box.float().tolist()
            class_id = class_id.item()
            annotations.append({
                'id':
                ann_id,
                'image_id':
                img_id,
                'category_id':
                class_id + 1,
                'area': (box[2] - box[0]) * (box[3] - box[1]),
                'bbox': [box[1], box[0], box[3] - box[1], box[2] - box[0]],
                'iscrowd':
                0
            })
            ann_id += 1

    categories = [{
        'id': class_id + 1,
        'name': str(class_id + 1),
        'supercategory': 'super'
    } for class_id in range(num_class_ids)]
    coco = {
        'images': images,
        'annotations': annotations,
        'categories': categories
    }
    return coco


</source>
</class>

<class classid="12" nclones="2" nlines="18" similarity="83">
<source file="systems/raster-vision-0.11.0/rastervision/backend/torch_utils/object_detection/metrics.py" startline="55" endline="74" pcid="137">
def get_coco_preds(outputs):
    preds = []
    for img_id, output in enumerate(outputs, 1):
        for box, label, score in zip(output.boxes, output.get_field('labels'),
                                     output.get_field('scores')):
            box = box.float().tolist()
            label = label.item()
            score = score.item()
            preds.append({
                'image_id':
                img_id,
                'category_id':
                label,
                'bbox': [box[1], box[0], box[3] - box[1], box[2] - box[0]],
                'score':
                score
            })
    return preds


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/pytorch_learner/object_detection_utils.py" startline="66" endline="86" pcid="1374">
def get_coco_preds(outputs):
    preds = []
    for img_id, output in enumerate(outputs, 1):
        for box, class_id, score in zip(output.boxes,
                                        output.get_field('class_ids'),
                                        output.get_field('scores')):
            box = box.float().tolist()
            class_id = class_id.item() + 1
            score = score.item()
            preds.append({
                'image_id':
                img_id,
                'category_id':
                class_id,
                'bbox': [box[1], box[0], box[3] - box[1], box[2] - box[0]],
                'score':
                score
            })
    return preds


</source>
</class>

<class classid="13" nclones="2" nlines="17" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/backend/torch_utils/object_detection/metrics.py" startline="75" endline="113" pcid="138">
def compute_coco_eval(outputs, targets, num_labels):
    """Return mAP averaged over 0.5-0.95 using pycocotools eval.

    Note: boxes are in (ymin, xmin, ymax, xmax) format with values ranging
        from 0 to h or w.

    Args:
        outputs: (list) of length m containing dicts of form
            {'boxes': <tensor with shape (n, 4)>,
             'labels': <tensor with shape (n,)>,
             'scores': <tensor with shape (n,)>}
        targets: (list) of length m containing dicts of form
            {'boxes': <tensor with shape (n, 4)>,
             'labels': <tensor with shape (n,)>}
    """
    with tempfile.TemporaryDirectory() as tmp_dir:
        preds = get_coco_preds(outputs)
        # ap is undefined when there are no predicted boxes
        if len(preds) == 0:
            return None

        gt = get_coco_gt(targets, num_labels)
        gt_path = join(tmp_dir, 'gt.json')
        json_to_file(gt, gt_path)
        coco_gt = COCO(gt_path)

        pycocotools.coco.unicode = None
        coco_preds = coco_gt.loadRes(preds)

        ann_type = 'bbox'
        coco_eval = COCOeval(coco_gt, coco_preds, ann_type)

        coco_eval.evaluate()
        coco_eval.accumulate()
        coco_eval.summarize()

        return coco_eval


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/pytorch_learner/object_detection_utils.py" startline="87" endline="125" pcid="1375">
def compute_coco_eval(outputs, targets, num_class_ids):
    """Return mAP averaged over 0.5-0.95 using pycocotools eval.

    Note: boxes are in (ymin, xmin, ymax, xmax) format with values ranging
        from 0 to h or w.

    Args:
        outputs: (list) of length m containing dicts of form
            {'boxes': <tensor with shape (n, 4)>,
             'class_ids': <tensor with shape (n,)>,
             'scores': <tensor with shape (n,)>}
        targets: (list) of length m containing dicts of form
            {'boxes': <tensor with shape (n, 4)>,
             'class_ids': <tensor with shape (n,)>}
    """
    with tempfile.TemporaryDirectory() as tmp_dir:
        preds = get_coco_preds(outputs)
        # ap is undefined when there are no predicted boxes
        if len(preds) == 0:
            return None

        gt = get_coco_gt(targets, num_class_ids)
        gt_path = join(tmp_dir, 'gt.json')
        json_to_file(gt, gt_path)
        coco_gt = COCO(gt_path)

        pycocotools.coco.unicode = None
        coco_preds = coco_gt.loadRes(preds)

        ann_type = 'bbox'
        coco_eval = COCOeval(coco_gt, coco_preds, ann_type)

        coco_eval.evaluate()
        coco_eval.accumulate()
        coco_eval.summarize()

        return coco_eval


</source>
</class>

<class classid="14" nclones="2" nlines="30" similarity="86">
<source file="systems/raster-vision-0.11.0/rastervision/backend/torch_utils/object_detection/plot.py" startline="4" endline="38" pcid="140">
def plot_xy(ax, x, y=None, label_names=None):
    ax.imshow(x.permute(1, 2, 0))

    if y is not None:
        scores = y.get_field('scores')
        for box_ind, (box, label) in enumerate(
                zip(y.boxes, y.get_field('labels'))):
            rect = patches.Rectangle(
                (box[1], box[0]),
                box[3] - box[1],
                box[2] - box[0],
                linewidth=1,
                edgecolor='cyan',
                facecolor='none')
            ax.add_patch(rect)

            label_name = label_names[label]
            if scores is not None:
                score = scores[box_ind]
                label_name += ' {:.2f}'.format(score)

            h, w = x.shape[1:]
            label_height = h * 0.03
            label_width = w * 0.15
            rect = patches.Rectangle(
                (box[1], box[0] - label_height),
                label_width,
                label_height,
                color='cyan')
            ax.add_patch(rect)

            ax.text(
                box[1] + w * 0.003, box[0] - h * 0.003, label_name, fontsize=7)

    ax.axis('off')
</source>
<source file="systems/raster-vision-0.11.0/rastervision2/pytorch_learner/object_detection_utils.py" startline="361" endline="396" pcid="1403">
def plot_xyz(ax, x, y, class_names, z=None):
    ax.imshow(x.permute(1, 2, 0))
    y = y if z is None else z

    scores = y.get_field('scores')
    for box_ind, (box, class_id) in enumerate(
            zip(y.boxes, y.get_field('class_ids'))):
        rect = patches.Rectangle(
            (box[1], box[0]),
            box[3] - box[1],
            box[2] - box[0],
            linewidth=1,
            edgecolor='cyan',
            facecolor='none')
        ax.add_patch(rect)

        box_label = class_names[class_id]
        if scores is not None:
            score = scores[box_ind]
            box_label += ' {:.2f}'.format(score)

        h, w = x.shape[1:]
        label_height = h * 0.03
        label_width = w * 0.15
        rect = patches.Rectangle(
            (box[1], box[0] - label_height),
            label_width,
            label_height,
            color='cyan')
        ax.add_patch(rect)

        ax.text(box[1] + w * 0.003, box[0] - h * 0.003, box_label, fontsize=7)

    ax.axis('off')


</source>
</class>

<class classid="15" nclones="3" nlines="19" similarity="94">
<source file="systems/raster-vision-0.11.0/rastervision/backend/pytorch_semantic_segmentation.py" startline="40" endline="78" pcid="152">
def make_debug_chips(databunch, class_map, tmp_dir, train_uri, max_count=30):
    """Save debug chips for a Databunch for a semantic segmentation dataset.

    This saves a plot for each example in the training and validation sets into
    train-debug-chips.zip and valid-debug-chips.zip under the train_uri. This
    is useful for making sure we are feeding correct data into the model.

    Args:
        databunch: DataBunch for semantic segmentation
        class_map: (rv.ClassMap) class map used to map class ids to colors
        tmp_dir: (str) path to temp directory
        train_uri: (str) URI of root of training output
        max_count: (int) maximum number of chips to generate. If None,
            generates all of them.
    """

    def _make_debug_chips(split):
        debug_chips_dir = join(tmp_dir, '{}-debug-chips'.format(split))
        zip_path = join(tmp_dir, '{}-debug-chips.zip'.format(split))
        zip_uri = join(train_uri, '{}-debug-chips.zip'.format(split))
        make_dir(debug_chips_dir)
        ds = databunch.train_ds if split == 'train' else databunch.valid_ds
        for i, (x, y) in enumerate(ds):
            if i >= max_count:
                break

            fig, ax = plt.subplots(1)
            plot_xy(ax, x, class_map, y=y)
            plt.savefig(
                join(debug_chips_dir, '{}.png'.format(i)), figsize=(6, 6))
            plt.close()

        zipdir(debug_chips_dir, zip_path)
        upload_or_copy(zip_path, zip_uri)

    _make_debug_chips('train')
    _make_debug_chips('valid')


</source>
<source file="systems/raster-vision-0.11.0/rastervision/backend/pytorch_object_detection.py" startline="37" endline="75" pcid="204">
def make_debug_chips(databunch, class_map, tmp_dir, train_uri, max_count=30):
    """Save debug chips for a DataBunch.

    This saves a plot for each example in the training and validation sets into
    train-debug-chips.zip and valid-debug-chips.zip under the train_uri. This
    is useful for making sure we are feeding correct data into the model.

    Args:
        data: DataBunch for an object detection problem
        class_map: (rv.ClassMap) class map used to map class ids to colors
        tmp_dir: (str) path to temp directory
        train_uri: (str) URI of root of training output
        max_count: (int) maximum number of chips to generate. If None,
            generates all of them.
    """

    def _make_debug_chips(split):
        debug_chips_dir = join(tmp_dir, '{}-debug-chips'.format(split))
        zip_path = join(tmp_dir, '{}-debug-chips.zip'.format(split))
        zip_uri = join(train_uri, '{}-debug-chips.zip'.format(split))
        make_dir(debug_chips_dir)
        ds = databunch.train_ds if split == 'train' else databunch.valid_ds
        for i, (x, y) in enumerate(ds):
            if i >= max_count:
                break

            fig, ax = plt.subplots(1)
            plot_xy(ax, x, y, ds.label_names)
            plt.savefig(
                join(debug_chips_dir, '{}.png'.format(i)), figsize=(6, 6))
            plt.close()

        zipdir(debug_chips_dir, zip_path)
        upload_or_copy(zip_path, zip_uri)

    _make_debug_chips('train')
    _make_debug_chips('val')


</source>
<source file="systems/raster-vision-0.11.0/rastervision/backend/pytorch_chip_classification.py" startline="39" endline="77" pcid="228">
def make_debug_chips(databunch, class_map, tmp_dir, train_uri, max_count=30):
    """Save debug chips for a Databunch for a chip classification dataset

    This saves a plot for each example in the training and validation sets into
    train-debug-chips.zip and valid-debug-chips.zip under the train_uri. This
    is useful for making sure we are feeding correct data into the model.

    Args:
        databunch: DataBunch for chip classification
        class_map: (rv.ClassMap) class map used to map class ids to colors
        tmp_dir: (str) path to temp directory
        train_uri: (str) URI of root of training output
        max_count: (int) maximum number of chips to generate. If None,
            generates all of them.
    """

    def _make_debug_chips(split):
        debug_chips_dir = join(tmp_dir, '{}-debug-chips'.format(split))
        zip_path = join(tmp_dir, '{}-debug-chips.zip'.format(split))
        zip_uri = join(train_uri, '{}-debug-chips.zip'.format(split))
        make_dir(debug_chips_dir)
        ds = databunch.train_ds if split == 'train' else databunch.valid_ds
        for i, (x, y) in enumerate(ds):
            if i >= max_count:
                break

            fig, ax = plt.subplots(1)
            plot_xy(ax, x, y, databunch.label_names)
            plt.savefig(
                join(debug_chips_dir, '{}.png'.format(i)), figsize=(6, 6))
            plt.close()

        zipdir(debug_chips_dir, zip_path)
        upload_or_copy(zip_path, zip_uri)

    _make_debug_chips('train')
    _make_debug_chips('valid')


</source>
</class>

<class classid="16" nclones="3" nlines="11" similarity="83">
<source file="systems/raster-vision-0.11.0/rastervision/backend/pytorch_semantic_segmentation.py" startline="82" endline="104" pcid="154">
    def __init__(self, task_config, backend_opts, train_opts):
        """Constructor.

        Args:
            task_config: (SemanticSegmentationConfig)
            backend_opts: (simple_backend_config.BackendOptions)
            train_opts: (pytorch_semantic_segmentation_backend_config.TrainOptions)
        """
        self.task_config = task_config
        self.backend_opts = backend_opts
        self.train_opts = train_opts
        self.inf_learner = None

        torch_cache_dir = '/opt/data/torch-cache'
        os.environ['TORCH_HOME'] = torch_cache_dir

        self.model = None
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        log.info('Device = {}'.format(self.device))
        # TODO move this into the SemanticSegmentation RV task
        self.class_map = self.task_config.class_map.copy()
        self.class_map.add_nodata_item()

</source>
<source file="systems/raster-vision-0.11.0/rastervision/backend/pytorch_object_detection.py" startline="79" endline="99" pcid="206">
    def __init__(self, task_config, backend_opts, train_opts):
        """Constructor.

        Args:
            task_config: (ChipClassificationConfig)
            backend_opts: (simple_backend_config.BackendOptions)
            train_opts: (pytorch_chip_classification_config.TrainOptions)
        """
        self.task_config = task_config
        self.backend_opts = backend_opts
        self.train_opts = train_opts
        self.inf_learner = None

        # Setup caching for torchvision pretrained models.
        torch_cache_dir = '/opt/data/torch-cache'
        os.environ['TORCH_HOME'] = torch_cache_dir

        self.model = None
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        log.info('Device = {}'.format(self.device))

</source>
<source file="systems/raster-vision-0.11.0/rastervision/backend/pytorch_chip_classification.py" startline="81" endline="100" pcid="230">
    def __init__(self, task_config, backend_opts, train_opts):
        """Constructor.

        Args:
            task_config: (ChipClassificationConfig)
            backend_opts: (simple_backend_config.BackendOptions)
            train_opts: (pytorch_chip_classification_config.TrainOptions)
        """
        self.task_config = task_config
        self.backend_opts = backend_opts
        self.train_opts = train_opts
        self.inf_learner = None

        torch_cache_dir = '/opt/data/torch-cache'
        os.environ['TORCH_HOME'] = torch_cache_dir

        self.model = None
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        log.info('Device = {}'.format(self.device))

</source>
</class>

<class classid="17" nclones="3" nlines="19" similarity="71">
<source file="systems/raster-vision-0.11.0/rastervision/backend/pytorch_semantic_segmentation.py" startline="142" endline="187" pcid="157">
    def process_sceneset_results(self, training_results, validation_results,
                                 tmp_dir):
        """Write zip file with chips for a set of scenes.

        This writes a zip file for a group of scenes at {chip_uri}/{uuid}.zip containing:
        train/img/{scene_id}-{ind}.png
        train/labels/{scene_id}-{ind}.png
        val/img/{scene_id}-{ind}.png
        val/labels/{scene_id}-{ind}.png

        This method is called once per instance of the chip command.
        A number of instances of the chip command can run simultaneously to
        process chips in parallel. The uuid in the path above is what allows
        separate instances to avoid overwriting each others' output.

        Args:
            training_results: list of directories generated by process_scene_data
                that all hold training chips
            validation_results: list of directories generated by process_scene_data
                that all hold validation chips
        """
        self.log_options()

        group = str(uuid.uuid4())
        group_uri = join(self.backend_opts.chip_uri, '{}.zip'.format(group))
        group_path = get_local_path(group_uri, tmp_dir)
        make_dir(group_path, use_dirname=True)

        with zipfile.ZipFile(group_path, 'w', zipfile.ZIP_DEFLATED) as zipf:

            def _write_zip(results, split):
                for scene_dir in results:
                    scene_paths = glob.glob(join(scene_dir, '**/*.png'))
                    for p in scene_paths:
                        zipf.write(
                            p,
                            join(
                                '{}/{}'.format(split,
                                               dirname(p).split('/')[-1]),
                                basename(p)))

            _write_zip(training_results, 'train')
            _write_zip(validation_results, 'valid')

        upload_or_copy(group_path, group_uri)

</source>
<source file="systems/raster-vision-0.11.0/rastervision/backend/pytorch_object_detection.py" startline="165" endline="200" pcid="209">
    def process_sceneset_results(self, training_results, validation_results,
                                 tmp_dir):
        """After all scenes have been processed, process the result set.

        This writes a zip file for a group of scenes at {chip_uri}/{uuid}.zip
        containing:
        train/{scene_id}-{ind}.png
        train/{scene_id}-labels.json
        valid/{scene_id}-{ind}.png
        valid/{scene_id}-labels.json

        Args:
            training_results: dependent on the ml_backend's process_scene_data
            validation_results: dependent on the ml_backend's
                process_scene_data
        """
        self.log_options()

        group = str(uuid.uuid4())
        group_uri = join(self.backend_opts.chip_uri, '{}.zip'.format(group))
        group_path = get_local_path(group_uri, tmp_dir)
        make_dir(group_path, use_dirname=True)

        with zipfile.ZipFile(group_path, 'w', zipfile.ZIP_DEFLATED) as zipf:

            def _write_zip(results, split):
                for scene_dir in results:
                    scene_paths = glob.glob(join(scene_dir, '*'))
                    for p in scene_paths:
                        zipf.write(p, join(split, basename(p)))

            _write_zip(training_results, 'train')
            _write_zip(validation_results, 'valid')

        upload_or_copy(group_path, group_uri)

</source>
<source file="systems/raster-vision-0.11.0/rastervision/backend/pytorch_chip_classification.py" startline="137" endline="176" pcid="233">
    def process_sceneset_results(self, training_results, validation_results,
                                 tmp_dir):
        """Write zip file with chips for a set of scenes.

        This writes a zip file for a group of scenes at {chip_uri}/{uuid}.zip containing:
        train-img/{class_name}/{scene_id}-{ind}.png
        valid-img/{class_name}/{scene_id}-{ind}.png

        This method is called once per instance of the chip command.
        A number of instances of the chip command can run simultaneously to
        process chips in parallel. The uuid in the path above is what allows
        separate instances to avoid overwriting each others' output.

        Args:
            training_results: list of directories generated by process_scene_data
                that all hold training chips
            validation_results: list of directories generated by process_scene_data
                that all hold validation chips
        """
        self.log_options()

        group = str(uuid.uuid4())
        group_uri = join(self.backend_opts.chip_uri, '{}.zip'.format(group))
        group_path = get_local_path(group_uri, tmp_dir)
        make_dir(group_path, use_dirname=True)

        with zipfile.ZipFile(group_path, 'w', zipfile.ZIP_DEFLATED) as zipf:

            def _write_zip(scene_dirs, split):
                for scene_dir in scene_dirs:
                    scene_paths = glob.glob(join(scene_dir, '**/*.png'))
                    for path in scene_paths:
                        class_name, fn = path.split('/')[-2:]
                        zipf.write(path, join(split, class_name, fn))

            _write_zip(training_results, 'train')
            _write_zip(validation_results, 'valid')

        upload_or_copy(group_path, group_uri)

</source>
</class>

<class classid="18" nclones="3" nlines="116" similarity="90">
<source file="systems/raster-vision-0.11.0/rastervision/backend/pytorch_semantic_segmentation.py" startline="188" endline="352" pcid="159">
    def train(self, tmp_dir):
        """Train a model.

        This downloads any previous output saved to the train_uri,
        starts training (or resumes from a checkpoint), periodically
        syncs contents of train_dir to train_uri and after training finishes.

        Args:
            tmp_dir: (str) path to temp directory
        """
        self.log_options()

        # Sync output of previous training run from cloud.
        train_uri = self.backend_opts.train_uri
        train_dir = get_local_path(train_uri, tmp_dir)
        make_dir(train_dir)
        sync_from_dir(train_uri, train_dir)

        # Get zip file for each group, and unzip them into chip_dir.
        chip_dir = join(tmp_dir, 'chips')
        make_dir(chip_dir)
        for zip_uri in list_paths(self.backend_opts.chip_uri, 'zip'):
            zip_path = download_if_needed(zip_uri, tmp_dir)
            with zipfile.ZipFile(zip_path, 'r') as zipf:
                zipf.extractall(chip_dir)

        # Setup data loader.
        batch_size = self.train_opts.batch_size
        chip_size = self.task_config.chip_size
        class_names = self.class_map.get_class_names()
        databunch = build_databunch(chip_dir, chip_size, batch_size,
                                    class_names)
        log.info(databunch)
        num_labels = len(databunch.label_names)
        if self.train_opts.debug:
            make_debug_chips(databunch, self.class_map, tmp_dir, train_uri)

        # Setup model
        num_labels = len(databunch.label_names)
        model = get_model(
            self.train_opts.model_arch, num_labels, pretrained=True)
        model = model.to(self.device)
        model_path = join(train_dir, 'model')

        # Load weights from a pretrained model.
        pretrained_uri = self.backend_opts.pretrained_uri
        if pretrained_uri:
            log.info('Loading weights from pretrained_uri: {}'.format(
                pretrained_uri))
            pretrained_path = download_if_needed(pretrained_uri, tmp_dir)
            model.load_state_dict(
                torch.load(pretrained_path, map_location=self.device))

        # Possibly resume training from checkpoint.
        start_epoch = 0
        train_state_path = join(train_dir, 'train_state.json')
        if isfile(train_state_path):
            log.info('Resuming from checkpoint: {}\n'.format(model_path))
            train_state = file_to_json(train_state_path)
            start_epoch = train_state['epoch'] + 1
            model.load_state_dict(
                torch.load(model_path, map_location=self.device))

        # Write header of log CSV file.
        metric_names = ['precision', 'recall', 'f1']
        log_path = join(train_dir, 'log.csv')
        if not isfile(log_path):
            with open(log_path, 'w') as log_file:
                log_writer = csv.writer(log_file)
                row = ['epoch', 'time', 'train_loss'] + metric_names
                log_writer.writerow(row)

        # Setup Tensorboard logging.
        if self.train_opts.log_tensorboard:
            log_dir = join(train_dir, 'tb-logs')
            make_dir(log_dir)
            tb_writer = SummaryWriter(log_dir=log_dir)
            if self.train_opts.run_tensorboard:
                log.info('Starting tensorboard process')
                tensorboard_process = Popen(
                    ['tensorboard', '--logdir={}'.format(log_dir)])
                terminate_at_exit(tensorboard_process)

        # Setup optimizer, loss, and LR scheduler.
        loss_fn = torch.nn.CrossEntropyLoss()
        lr = self.train_opts.lr
        opt = optim.Adam(model.parameters(), lr=lr)
        step_scheduler, epoch_scheduler = None, None
        num_epochs = self.train_opts.num_epochs

        if self.train_opts.one_cycle and num_epochs > 1:
            steps_per_epoch = len(databunch.train_ds) // batch_size
            total_steps = num_epochs * steps_per_epoch
            step_size_up = (num_epochs // 2) * steps_per_epoch
            step_size_down = total_steps - step_size_up
            step_scheduler = CyclicLR(
                opt,
                base_lr=lr / 10,
                max_lr=lr,
                step_size_up=step_size_up,
                step_size_down=step_size_down,
                cycle_momentum=False)
            for _ in range(start_epoch * steps_per_epoch):
                step_scheduler.step()

        # Training loop.
        for epoch in range(start_epoch, num_epochs):
            # Train one epoch.
            log.info('-----------------------------------------------------')
            log.info('epoch: {}'.format(epoch))
            start = time.time()
            train_loss = train_epoch(model, self.device, databunch.train_dl,
                                     opt, loss_fn, step_scheduler)
            if epoch_scheduler:
                epoch_scheduler.step()
            log.info('train loss: {}'.format(train_loss))

            # Validate one epoch.
            metrics = validate_epoch(model, self.device, databunch.valid_dl,
                                     num_labels)
            log.info('validation metrics: {}'.format(metrics))

            # Print elapsed time for epoch.
            end = time.time()
            epoch_time = datetime.timedelta(seconds=end - start)
            log.info('epoch elapsed time: {}'.format(epoch_time))

            # Save model and state.
            torch.save(model.state_dict(), model_path)
            train_state = {'epoch': epoch}
            json_to_file(train_state, train_state_path)

            # Append to log CSV file.
            with open(log_path, 'a') as log_file:
                log_writer = csv.writer(log_file)
                row = [epoch, epoch_time, train_loss]
                row += [metrics[k] for k in metric_names]
                log_writer.writerow(row)

            # Write to Tensorboard log.
            if self.train_opts.log_tensorboard:
                for key, val in metrics.items():
                    tb_writer.add_scalar(key, val, epoch)
                tb_writer.add_scalar('train_loss', train_loss, epoch)
                for name, param in model.named_parameters():
                    tb_writer.add_histogram(name, param, epoch)
                tb_writer.flush()

            if (train_uri.startswith('s3://')
                    and (((epoch + 1) % self.train_opts.sync_interval) == 0)):
                sync_to_dir(train_dir, train_uri)

        # Close Tensorboard.
        if self.train_opts.log_tensorboard:
            tb_writer.close()
            if self.train_opts.run_tensorboard:
                tensorboard_process.terminate()

        # Since model is exported every epoch, we need some other way to
        # show that training is finished.
        str_to_file('done!', self.backend_opts.train_done_uri)

        # Sync output to cloud.
        sync_to_dir(train_dir, self.backend_opts.train_uri)

</source>
<source file="systems/raster-vision-0.11.0/rastervision/backend/pytorch_chip_classification.py" startline="177" endline="344" pcid="235">
    def train(self, tmp_dir):
        """Train a model.

        This downloads any previous output saved to the train_uri,
        starts training (or resumes from a checkpoint), periodically
        syncs contents of train_dir to train_uri and after training finishes.

        Args:
            tmp_dir: (str) path to temp directory
        """
        self.log_options()

        # Sync output of previous training run from cloud.
        train_uri = self.backend_opts.train_uri
        train_dir = get_local_path(train_uri, tmp_dir)
        make_dir(train_dir)
        sync_from_dir(train_uri, train_dir)

        # Get zip file for each group, and unzip them into chip_dir.
        chip_dir = join(tmp_dir, 'chips')
        make_dir(chip_dir)
        for zip_uri in list_paths(self.backend_opts.chip_uri, 'zip'):
            zip_path = download_if_needed(zip_uri, tmp_dir)
            with zipfile.ZipFile(zip_path, 'r') as zipf:
                zipf.extractall(chip_dir)

        # Setup data loader.
        batch_size = self.train_opts.batch_size
        chip_size = self.task_config.chip_size
        augmentors = self.train_opts.augmentors
        databunch = build_databunch(
            chip_dir, chip_size, batch_size,
            self.task_config.class_map.get_class_names(),
            self.train_opts.rare_classes, self.train_opts.desired_prob,
            augmentors)
        log.info(databunch)
        num_labels = len(databunch.label_names)
        if self.train_opts.debug:
            make_debug_chips(databunch, self.task_config.class_map, tmp_dir,
                             train_uri)

        # Setup model
        num_labels = len(databunch.label_names)
        model = get_model(
            self.train_opts.model_arch, num_labels, pretrained=True)
        model = model.to(self.device)
        model_path = join(train_dir, 'model')

        # Load weights from a pretrained model.
        pretrained_uri = self.backend_opts.pretrained_uri
        if pretrained_uri:
            log.info('Loading weights from pretrained_uri: {}'.format(
                pretrained_uri))
            pretrained_path = download_if_needed(pretrained_uri, tmp_dir)
            model.load_state_dict(
                torch.load(pretrained_path, map_location=self.device))

        # Possibly resume training from checkpoint.
        start_epoch = 0
        train_state_path = join(train_dir, 'train_state.json')
        if isfile(train_state_path):
            log.info('Resuming from checkpoint: {}\n'.format(model_path))
            train_state = file_to_json(train_state_path)
            start_epoch = train_state['epoch'] + 1
            model.load_state_dict(
                torch.load(model_path, map_location=self.device))

        # Write header of log CSV file.
        metric_names = ['precision', 'recall', 'f1']
        log_path = join(train_dir, 'log.csv')
        if not isfile(log_path):
            with open(log_path, 'w') as log_file:
                log_writer = csv.writer(log_file)
                row = ['epoch', 'time', 'train_loss'] + metric_names
                log_writer.writerow(row)

        # Setup Tensorboard logging.
        if self.train_opts.log_tensorboard:
            log_dir = join(train_dir, 'tb-logs')
            make_dir(log_dir)
            tb_writer = SummaryWriter(log_dir=log_dir)
            if self.train_opts.run_tensorboard:
                log.info('Starting tensorboard process')
                tensorboard_process = Popen(
                    ['tensorboard', '--logdir={}'.format(log_dir)])
                terminate_at_exit(tensorboard_process)

        # Setup optimizer, loss, and LR scheduler.
        loss_fn = torch.nn.CrossEntropyLoss()
        lr = self.train_opts.lr
        opt = optim.Adam(model.parameters(), lr=lr)
        step_scheduler, epoch_scheduler = None, None
        num_epochs = self.train_opts.num_epochs

        if self.train_opts.one_cycle and num_epochs > 1:
            steps_per_epoch = len(databunch.train_ds) // batch_size
            total_steps = num_epochs * steps_per_epoch
            step_size_up = (num_epochs // 2) * steps_per_epoch
            step_size_down = total_steps - step_size_up
            step_scheduler = CyclicLR(
                opt,
                base_lr=lr / 10,
                max_lr=lr,
                step_size_up=step_size_up,
                step_size_down=step_size_down,
                cycle_momentum=False)
            for _ in range(start_epoch * steps_per_epoch):
                step_scheduler.step()

        # Training loop.
        for epoch in range(start_epoch, num_epochs):
            # Train one epoch.
            log.info('-----------------------------------------------------')
            log.info('epoch: {}'.format(epoch))
            start = time.time()
            train_loss = train_epoch(model, self.device, databunch.train_dl,
                                     opt, loss_fn, step_scheduler)
            if epoch_scheduler:
                epoch_scheduler.step()
            log.info('train loss: {}'.format(train_loss))

            # Validate one epoch.
            metrics = validate_epoch(model, self.device, databunch.valid_dl,
                                     num_labels)
            log.info('validation metrics: {}'.format(metrics))

            # Print elapsed time for epoch.
            end = time.time()
            epoch_time = datetime.timedelta(seconds=end - start)
            log.info('epoch elapsed time: {}'.format(epoch_time))

            # Save model and state.
            torch.save(model.state_dict(), model_path)
            train_state = {'epoch': epoch}
            json_to_file(train_state, train_state_path)

            # Append to log CSV file.
            with open(log_path, 'a') as log_file:
                log_writer = csv.writer(log_file)
                row = [epoch, epoch_time, train_loss]
                row += [metrics[k] for k in metric_names]
                log_writer.writerow(row)

            # Write to Tensorboard log.
            if self.train_opts.log_tensorboard:
                for key, val in metrics.items():
                    tb_writer.add_scalar(key, val, epoch)
                tb_writer.add_scalar('train_loss', train_loss, epoch)
                for name, param in model.named_parameters():
                    tb_writer.add_histogram(name, param, epoch)
                tb_writer.flush()

            if (train_uri.startswith('s3://')
                    and (((epoch + 1) % self.train_opts.sync_interval) == 0)):
                sync_to_dir(train_dir, train_uri)

        # Close Tensorboard.
        if self.train_opts.log_tensorboard:
            tb_writer.close()
            if self.train_opts.run_tensorboard:
                tensorboard_process.terminate()

        # Mark that the command has completed.
        str_to_file('done!', self.backend_opts.train_done_uri)

        # Sync output to cloud.
        sync_to_dir(train_dir, self.backend_opts.train_uri)

</source>
<source file="systems/raster-vision-0.11.0/rastervision/backend/pytorch_object_detection.py" startline="201" endline="363" pcid="211">
    def train(self, tmp_dir):
        """Train a model.

        This downloads any previous output saved to the train_uri,
        starts training (or resumes from a checkpoint), periodically
        syncs contents of train_dir to train_uri and after training finishes.

        Args:
            tmp_dir: (str) path to temp directory
        """
        self.log_options()

        # Sync output of previous training run from cloud.
        train_uri = self.backend_opts.train_uri
        train_dir = get_local_path(train_uri, tmp_dir)
        make_dir(train_dir)
        sync_from_dir(train_uri, train_dir)

        # Get zip file for each group, and unzip them into chip_dir.
        chip_dir = join(tmp_dir, 'chips')
        make_dir(chip_dir)
        for zip_uri in list_paths(self.backend_opts.chip_uri, 'zip'):
            zip_path = download_if_needed(zip_uri, tmp_dir)
            with zipfile.ZipFile(zip_path, 'r') as zipf:
                zipf.extractall(chip_dir)

        # Setup dataset and dataloaders.
        batch_size = self.train_opts.batch_size
        chip_size = self.task_config.chip_size
        databunch = build_databunch(chip_dir, chip_size, batch_size)
        log.info(databunch)
        num_labels = len(databunch.label_names)
        if self.train_opts.debug:
            make_debug_chips(databunch, self.task_config.class_map, tmp_dir,
                             train_uri)

        # Setup model
        num_labels = len(databunch.label_names)
        model = MyFasterRCNN(
            self.train_opts.model_arch, num_labels, chip_size, pretrained=True)
        model = model.to(self.device)
        model_path = join(train_dir, 'model')

        # Load weights from a pretrained model.
        pretrained_uri = self.backend_opts.pretrained_uri
        if pretrained_uri:
            log.info('Loading weights from pretrained_uri: {}'.format(
                pretrained_uri))
            pretrained_path = download_if_needed(pretrained_uri, tmp_dir)
            model.load_state_dict(
                torch.load(pretrained_path, map_location=self.device))

        # Possibly resume training from checkpoint.
        start_epoch = 0
        train_state_path = join(train_dir, 'train_state.json')
        if isfile(train_state_path):
            log.info('Resuming from checkpoint: {}\n'.format(model_path))
            train_state = file_to_json(train_state_path)
            start_epoch = train_state['epoch'] + 1
            model.load_state_dict(
                torch.load(model_path, map_location=self.device))

        # Write header of log CSV file.
        log_path = join(train_dir, 'log.csv')
        if not isfile(log_path):
            with open(log_path, 'w') as log_file:
                log_writer = csv.writer(log_file)
                row = ['epoch'] + ['map50', 'time'] + model.subloss_names
                log_writer.writerow(row)

        # Setup Tensorboard logging.
        if self.train_opts.log_tensorboard:
            log_dir = join(train_dir, 'tb-logs')
            make_dir(log_dir)
            tb_writer = SummaryWriter(log_dir=log_dir)
            if self.train_opts.run_tensorboard:
                log.info('Starting tensorboard process')
                tensorboard_process = Popen(
                    ['tensorboard', '--logdir={}'.format(log_dir)])
                terminate_at_exit(tensorboard_process)

        # Setup optimizer.
        lr = self.train_opts.lr
        opt = optim.Adam(model.parameters(), lr=lr)
        step_scheduler, epoch_scheduler = None, None
        num_epochs = self.train_opts.num_epochs

        if self.train_opts.one_cycle and num_epochs > 1:
            steps_per_epoch = len(databunch.train_ds) // batch_size
            total_steps = num_epochs * steps_per_epoch
            step_size_up = (num_epochs // 2) * steps_per_epoch
            step_size_down = total_steps - step_size_up
            step_scheduler = CyclicLR(
                opt,
                base_lr=lr / 10,
                max_lr=lr,
                step_size_up=step_size_up,
                step_size_down=step_size_down,
                cycle_momentum=False)
            for _ in range(start_epoch * steps_per_epoch):
                step_scheduler.step()

        # Training loop.
        for epoch in range(start_epoch, num_epochs):
            # Train one epoch.
            log.info('-----------------------------------------------------')
            log.info('epoch: {}'.format(epoch))
            start = time.time()
            train_loss = train_epoch(model, self.device, databunch.train_dl,
                                     opt, step_scheduler, epoch_scheduler)
            if epoch_scheduler:
                epoch_scheduler.step()
            log.info('train loss: {}'.format(train_loss))

            # Validate one epoch.
            metrics = validate_epoch(model, self.device, databunch.valid_dl,
                                     num_labels)
            log.info('validation metrics: {}'.format(metrics))

            # Print elapsed time for epoch.
            end = time.time()
            epoch_time = datetime.timedelta(seconds=end - start)
            log.info('epoch elapsed time: {}'.format(epoch_time))

            # Save model and state.
            torch.save(model.state_dict(), model_path)
            train_state = {'epoch': epoch}
            json_to_file(train_state, train_state_path)

            # Append to log CSV file.
            with open(log_path, 'a') as log_file:
                log_writer = csv.writer(log_file)
                row = [epoch]
                row += [metrics['map50'], epoch_time]
                row += [train_loss[k] for k in model.subloss_names]
                log_writer.writerow(row)

            # Write to Tensorboard log.
            if self.train_opts.log_tensorboard:
                for key, val in metrics.items():
                    tb_writer.add_scalar(key, val, epoch)
                for key, val in train_loss.items():
                    tb_writer.add_scalar(key, val, epoch)
                for name, param in model.named_parameters():
                    tb_writer.add_histogram(name, param, epoch)
                tb_writer.flush()

            if (train_uri.startswith('s3://')
                    and (((epoch + 1) % self.train_opts.sync_interval) == 0)):
                sync_to_dir(train_dir, train_uri)

        # Close Tensorboard.
        if self.train_opts.log_tensorboard:
            tb_writer.close()
            if self.train_opts.run_tensorboard:
                tensorboard_process.terminate()

        # Mark that the command has completed.
        str_to_file('done!', self.backend_opts.train_done_uri)

        # Sync output to cloud.
        sync_to_dir(train_dir, self.backend_opts.train_uri)

</source>
</class>

<class classid="19" nclones="2" nlines="11" similarity="90">
<source file="systems/raster-vision-0.11.0/rastervision/backend/pytorch_semantic_segmentation.py" startline="353" endline="366" pcid="160">
    def load_model(self, tmp_dir):
        """Load the model in preparation for one or more prediction calls."""
        if self.model is None:
            model_uri = self.backend_opts.model_uri
            model_path = download_if_needed(model_uri, tmp_dir)

            num_classes = len(self.class_map)
            model = get_model(
                self.train_opts.model_arch, num_classes, pretrained=False)
            model = model.to(self.device)
            model.load_state_dict(
                torch.load(model_path, map_location=self.device))
            self.model = model

</source>
<source file="systems/raster-vision-0.11.0/rastervision/backend/pytorch_chip_classification.py" startline="345" endline="358" pcid="236">
    def load_model(self, tmp_dir):
        """Load the model in preparation for one or more prediction calls."""
        if self.model is None:
            model_uri = self.backend_opts.model_uri
            model_path = download_if_needed(model_uri, tmp_dir)

            num_classes = len(self.task_config.class_map)
            model = get_model(
                self.train_opts.model_arch, num_classes, pretrained=False)
            model = model.to(self.device)
            model.load_state_dict(
                torch.load(model_path, map_location=self.device))
            self.model = model

</source>
</class>

<class classid="20" nclones="7" nlines="11" similarity="71">
<source file="systems/raster-vision-0.11.0/rastervision/backend/simple_backend_config.py" startline="16" endline="28" pcid="238">
    def __init__(self,
                 chip_uri=None,
                 train_uri=None,
                 train_done_uri=None,
                 model_uri=None,
                 pretrained_uri=None):
        self.chip_uri = chip_uri
        self.train_uri = train_uri
        self.train_done_uri = train_done_uri
        self.model_uri = model_uri
        self.pretrained_uri = pretrained_uri


</source>
<source file="systems/raster-vision-0.11.0/rastervision/task/task_config.py" startline="11" endline="22" pcid="1174">
    def __init__(self,
                 task_type,
                 predict_batch_size=10,
                 predict_package_uri=None,
                 debug=True,
                 predict_debug_uri=None):
        self.task_type = task_type
        self.predict_batch_size = predict_batch_size
        self.predict_package_uri = predict_package_uri
        self.debug = debug
        self.predict_debug_uri = predict_debug_uri

</source>
<source file="systems/raster-vision-0.11.0/rastervision/command/aux_command.py" startline="5" endline="43" pcid="458">
    def __init__(self,
                 split_on=None,
                 inputs=lambda config: None,
                 outputs=lambda config: None,
                 include_by_default=False,
                 required_fields=None):
        """Instantiate an AuxCommandOptions object.

        Args:
            split_on (str): The property of the configuration to use when splitting.
            The configuration at this property must be a list.

            inputs: A function that, given the configuration, returns a list of
            URIs that are inputs into the command. Along with outputs, this allows
            Raster Vision to correctly determine if there are any missing inputs, or
            if the command has already been run. It will also allow the command to
            be run in the right sequence if run with other commands that will produce
            this command's inputs as their outputs.

            outputs: A function that, given the configuration, returns a list of
            URIs that are outputs of the command. See the details on inputs.

            include_by_default: Set this to True if you want this command to run
            by default, meaning it will run every time no specific commands are issued
            on the command line (e.g. how a standard command would run).

            required_fields: Set this to properties of the configuration that are
            required. If the user of the command does not set values into those
            configuration properties, an error will be thrown at configuration building
            time.

        """
        self.split_on = split_on
        self.inputs = inputs
        self.outputs = outputs
        self.include_by_default = include_by_default
        self.required_fields = required_fields


</source>
<source file="systems/raster-vision-0.11.0/rastervision/data/scene_config.py" startline="15" endline="26" pcid="725">
class SceneConfig(BundledConfigMixin, Config):
    def __init__(self,
                 id,
                 raster_source,
                 label_source=None,
                 label_store=None,
                 aoi_uris=None):
        self.id = id
        self.raster_source = raster_source
        self.label_source = label_source
        self.label_store = label_store
        self.aoi_uris = aoi_uris
</source>
<source file="systems/raster-vision-0.11.0/rastervision/data/scene.py" startline="7" endline="30" pcid="623">
    def __init__(self,
                 id,
                 raster_source,
                 ground_truth_label_source=None,
                 prediction_label_store=None,
                 aoi_polygons=None):
        """Construct a new Scene.

        Args:
            id: ID for this scene
            raster_source: RasterSource for this scene
            ground_truth_label_store: optional LabelSource
            prediction_label_store: optional LabelStore
            aoi: Optional list of AOI polygons
        """
        self.id = id
        self.raster_source = raster_source
        self.ground_truth_label_source = ground_truth_label_source
        self.prediction_label_store = prediction_label_store
        if aoi_polygons is None:
            self.aoi_polygons = []
        else:
            self.aoi_polygons = aoi_polygons

</source>
<source file="systems/raster-vision-0.11.0/rastervision/data/vector_source/vector_source.py" startline="111" endline="138" pcid="767">
    def __init__(self,
                 crs_transformer,
                 line_bufs=None,
                 point_bufs=None,
                 class_inf_opts=None):
        """Constructor.

        Args:
            crs_transformer: (CRSTransformer)
            line_bufs: (dict or None) If none, uses default buffer value of 1. Otherwise,
                a map from class_id to number of pixels to buffer by. If the buffer value
                is None, then no buffering will be performed and the LineString or Point
                won't get converted to a Polygon. Not converting to Polygon is
                incompatible with the currently available LabelSources, but may be useful
                in the future.
            point_bufs: (dict or None) same as above, but used for buffering Points into
                Polygons.
            class_inf_opts: (ClassInferenceOptions)
        """
        self.crs_transformer = crs_transformer
        self.line_bufs = line_bufs
        self.point_bufs = point_bufs
        if class_inf_opts is None:
            class_inf_opts = ClassInferenceOptions()
        self.class_inference = ClassInference(class_inf_opts)

        self.geojson = None

</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/scene.py" startline="7" endline="30" pcid="1680">
    def __init__(self,
                 id,
                 raster_source,
                 ground_truth_label_source=None,
                 prediction_label_store=None,
                 aoi_polygons=None):
        """Construct a new Scene.

        Args:
            id: ID for this scene
            raster_source: RasterSource for this scene
            ground_truth_label_store: optional LabelSource
            prediction_label_store: optional LabelStore
            aoi: Optional list of AOI polygons
        """
        self.id = id
        self.raster_source = raster_source
        self.ground_truth_label_source = ground_truth_label_source
        self.prediction_label_store = prediction_label_store
        if aoi_polygons is None:
            self.aoi_polygons = []
        else:
            self.aoi_polygons = aoi_polygons

</source>
</class>

<class classid="21" nclones="2" nlines="17" similarity="88">
<source file="systems/raster-vision-0.11.0/rastervision/filesystem/local_filesystem.py" startline="72" endline="93" pcid="292">
    def sync_from_dir(src_dir_uri: str,
                      dest_dir_uri: str,
                      delete: bool = False) -> None:
        if src_dir_uri == dest_dir_uri:
            return

        if delete:
            shutil.rmtree(dest_dir_uri)

        # https://stackoverflow.com/a/15824216/841563
        def recursive_overwrite(src, dest):
            if os.path.isdir(src):
                if not os.path.isdir(dest):
                    os.makedirs(dest)
                    for entry in os.scandir(src):
                        recursive_overwrite(entry.path,
                                            os.path.join(dest, entry.name))
            else:
                shutil.copyfile(src, dest)

        recursive_overwrite(src_dir_uri, dest_dir_uri)

</source>
<source file="systems/raster-vision-0.11.0/rastervision2/pipeline/file_system/local_file_system.py" startline="74" endline="94" pcid="1495">
    def sync_from_dir(src_dir_uri: str, dst_dir: str,
                      delete: bool = False) -> None:
        if src_dir_uri == dst_dir:
            return

        if delete:
            shutil.rmtree(dst_dir)

        # https://stackoverflow.com/a/15824216/841563
        def recursive_overwrite(src, dest):
            if os.path.isdir(src):
                if not os.path.isdir(dest):
                    os.makedirs(dest)
                    for entry in os.scandir(src):
                        recursive_overwrite(entry.path,
                                            os.path.join(dest, entry.name))
            else:
                shutil.copyfile(src, dest)

        recursive_overwrite(src_dir_uri, dst_dir)

</source>
</class>

<class classid="22" nclones="4" nlines="10" similarity="70">
<source file="systems/raster-vision-0.11.0/rastervision/command/analyze_command_config.py" startline="26" endline="38" pcid="322">

    def to_proto(self):
        msg = super().to_proto()
        task = self.task.to_proto()
        scenes = list(map(lambda s: s.to_proto(), self.scenes))
        analyzers = list(map(lambda a: a.to_proto(), self.analyzers))

        msg.MergeFrom(
            CommandConfigMsg(
                analyze_config=CommandConfigMsg.AnalyzeConfig(
                    task=task, scenes=scenes, analyzers=analyzers)))

        return msg
</source>
<source file="systems/raster-vision-0.11.0/rastervision/command/predict_command_config.py" startline="37" endline="50" pcid="424">

    def to_proto(self):
        msg = super().to_proto()

        task = self.task.to_proto()
        backend = self.backend.to_proto()
        scenes = list(map(lambda s: s.to_proto(), self.scenes))

        msg.MergeFrom(
            CommandConfigMsg(
                predict_config=CommandConfigMsg.PredictConfig(
                    task=task, backend=backend, scenes=scenes)))

        return msg
</source>
<source file="systems/raster-vision-0.11.0/rastervision/command/eval_command_config.py" startline="33" endline="45" pcid="410">

    def to_proto(self):
        msg = super().to_proto()
        task = self.task.to_proto()
        scenes = list(map(lambda s: s.to_proto(), self.scenes))
        evaluators = list(map(lambda e: e.to_proto(), self.evaluators))

        msg.MergeFrom(
            CommandConfigMsg(
                eval_config=CommandConfigMsg.EvalConfig(
                    task=task, scenes=scenes, evaluators=evaluators)))

        return msg
</source>
<source file="systems/raster-vision-0.11.0/rastervision/command/bundle_command_config.py" startline="32" endline="46" pcid="440">

    def to_proto(self):
        msg = super().to_proto()

        task = self.task.to_proto()
        backend = self.backend.to_proto()
        scene = self.scene.to_proto()
        analyzers = list(map(lambda a: a.to_proto(), self.analyzers))

        b = CommandConfigMsg.BundleConfig(
            task=task, backend=backend, scene=scene, analyzers=analyzers)

        msg.MergeFrom(CommandConfigMsg(bundle_config=b))

        return msg
</source>
</class>

<class classid="23" nclones="5" nlines="11" similarity="71">
<source file="systems/raster-vision-0.11.0/rastervision/command/analyze_command_config.py" startline="50" endline="60" pcid="324">
class AnalyzeCommandConfigBuilder(CommandConfigBuilder):
    def __init__(self, command_type, prev=None):
        super().__init__(command_type, prev)
        if prev is None:
            self.task = None
            self.scenes = None
            self.analyzers = None
        else:
            self.task = prev.task
            self.scenes = prev.scenes
            self.analyzers = prev.analyzers
</source>
<source file="systems/raster-vision-0.11.0/rastervision/command/bundle_command_config.py" startline="58" endline="70" pcid="442">
class BundleCommandConfigBuilder(CommandConfigBuilder):
    def __init__(self, command_type, prev=None):
        super().__init__(command_type, prev)
        if prev is None:
            self.task = None
            self.backend = None
            self.scene = None
            self.analyzers = None
        else:
            self.task = prev.task
            self.backend = prev.backend
            self.scene = prev.scene
            self.analyzers = prev.analyzers
</source>
<source file="systems/raster-vision-0.11.0/rastervision/command/eval_command_config.py" startline="57" endline="67" pcid="412">
class EvalCommandConfigBuilder(CommandConfigBuilder):
    def __init__(self, command_type, prev=None):
        super().__init__(command_type, prev)
        if prev is None:
            self.task = None
            self.scenes = None
            self.evaluators = None
        else:
            self.task = prev.task
            self.scenes = prev.scenes
            self.evaluators = prev.evaluators
</source>
<source file="systems/raster-vision-0.11.0/rastervision/command/predict_command_config.py" startline="68" endline="78" pcid="427">
        return commands


class PredictCommandConfigBuilder(CommandConfigBuilder):
    def __init__(self, command_type, prev=None):
        super().__init__(command_type, prev)
        if prev is None:
            self.task = None
            self.backend = None
            self.scenes = []
        else:
</source>
<source file="systems/raster-vision-0.11.0/rastervision/command/chip_command_config.py" startline="85" endline="99" pcid="397">
            commands.append(c)
        return commands


class ChipCommandConfigBuilder(CommandConfigBuilder):
    def __init__(self, command_type, prev=None):
        super().__init__(command_type, prev)
        if prev is None:
            self.task = None
            self.backend = None
            self.augmentors = []
            self.train_scenes = []
            self.val_scenes = []
        else:
            self.task = prev.task
</source>
</class>

<class classid="24" nclones="5" nlines="10" similarity="71">
<source file="systems/raster-vision-0.11.0/rastervision/command/analyze_command_config.py" startline="77" endline="91" pcid="327">

    def from_proto(self, msg):
        b = super().from_proto(msg)

        conf = msg.analyze_config

        task = rv.TaskConfig.from_proto(conf.task)
        scenes = list(map(rv.SceneConfig.from_proto, conf.scenes))
        analyzers = list(map(rv.AnalyzerConfig.from_proto, conf.analyzers))

        b = b.with_task(task)
        b = b.with_scenes(scenes)
        b = b.with_analyzers(analyzers)

        return b
</source>
<source file="systems/raster-vision-0.11.0/rastervision/command/bundle_command_config.py" startline="99" endline="115" pcid="445">

    def from_proto(self, msg):
        b = super().from_proto(msg)

        conf = msg.bundle_config

        task = rv.TaskConfig.from_proto(conf.task)
        backend = rv.BackendConfig.from_proto(conf.backend)
        scene = rv.SceneConfig.from_proto(conf.scene)
        analyzers = list(map(rv.AnalyzerConfig.from_proto, conf.analyzers))

        b = b.with_task(task)
        b = b.with_backend(backend)
        b = b.with_scene(scene)
        b = b.with_analyzers(analyzers)

        return b
</source>
<source file="systems/raster-vision-0.11.0/rastervision/command/chip_command_config.py" startline="129" endline="147" pcid="400">
        self.validate()
        return ChipCommandConfig(self.root_uri, self.split_id, self.task,
                                 self.backend, self.augmentors,
                                 self.train_scenes, self.val_scenes)

    def from_proto(self, msg):
        b = super().from_proto(msg)

        conf = msg.chip_config

        task = rv.TaskConfig.from_proto(conf.task)
        backend = rv.BackendConfig.from_proto(conf.backend)
        augmentors = list(map(rv.AugmentorConfig.from_proto, conf.augmentors))
        train_scenes = list(map(rv.SceneConfig.from_proto, conf.train_scenes))
        val_scenes = list(map(rv.SceneConfig.from_proto, conf.val_scenes))

        b = b.with_task(task)
        b = b.with_backend(backend)
        b = b.with_augmentors(augmentors)
</source>
<source file="systems/raster-vision-0.11.0/rastervision/command/predict_command_config.py" startline="97" endline="111" pcid="430">
        self.validate()
        return PredictCommandConfig(self.root_uri, self.split_id, self.task,
                                    self.backend, self.scenes)

    def from_proto(self, msg):
        b = super().from_proto(msg)

        conf = msg.predict_config

        task = rv.TaskConfig.from_proto(conf.task)
        backend = rv.BackendConfig.from_proto(conf.backend)
        scenes = list(map(rv.SceneConfig.from_proto, conf.scenes))

        b = b.with_task(task)
        b = b.with_backend(backend)
</source>
<source file="systems/raster-vision-0.11.0/rastervision/command/eval_command_config.py" startline="99" endline="113" pcid="415">

    def from_proto(self, msg):
        b = super().from_proto(msg)

        conf = msg.eval_config

        task = rv.TaskConfig.from_proto(conf.task)
        scenes = list(map(rv.SceneConfig.from_proto, conf.scenes))
        evaluators = list(map(rv.EvaluatorConfig.from_proto, conf.evaluators))

        b = b.with_task(task)
        b = b.with_scenes(scenes)
        b = b.with_evaluators(evaluators)

        return b
</source>
</class>

<class classid="25" nclones="3" nlines="11" similarity="72">
<source file="systems/raster-vision-0.11.0/rastervision/command/predict_command.py" startline="10" endline="24" pcid="351">
    def run(self, tmp_dir=None):
        if not tmp_dir:
            tmp_dir = self.get_tmp_dir()
        msg = 'Making predictions...'

        cc = self.command_config

        backend = cc.backend.create_backend(cc.task)
        task = cc.task.create_task(backend)

        scenes = list(
            map(lambda s: s.create_scene(cc.task, tmp_dir), cc.scenes))

        click.echo(click.style(msg, fg='green'))
        task.predict(scenes, tmp_dir)
</source>
<source file="systems/raster-vision-0.11.0/rastervision/command/eval_command.py" startline="10" endline="24" pcid="461">
    def run(self, tmp_dir=None):
        if not tmp_dir:
            tmp_dir = self.get_tmp_dir()

        cc = self.command_config

        scenes = list(
            map(lambda s: s.create_scene(cc.task, tmp_dir), cc.scenes))
        evaluators = list(map(lambda a: a.create_evaluator(), cc.evaluators))

        for evaluator in evaluators:
            msg = 'Running evaluator: {}...'.format(type(evaluator).__name__)
            click.echo(click.style(msg, fg='green'))

            evaluator.process(scenes, tmp_dir)
</source>
<source file="systems/raster-vision-0.11.0/rastervision/command/analyze_command.py" startline="10" endline="24" pcid="437">
    def run(self, tmp_dir=None):
        if not tmp_dir:
            tmp_dir = self.get_tmp_dir()

        cc = self.command_config

        analyzers = list(map(lambda a: a.create_analyzer(), cc.analyzers))
        scenes = list(
            map(lambda s: s.create_scene(cc.task, tmp_dir), cc.scenes))

        for analyzer in analyzers:
            msg = 'Running analyzer: {}...'.format(type(analyzer).__name__)
            click.echo(click.style(msg, fg='green'))

            analyzer.process(scenes, tmp_dir)
</source>
</class>

<class classid="26" nclones="2" nlines="37" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/command/aux/cogify_command.py" startline="15" endline="73" pcid="372">
def gdal_cog_commands(input_path,
                      tmp_dir,
                      block_size=DEFAULT_BLOCK_SIZE,
                      resample_method=DEFAULT_RESAMPLE_METHOD,
                      compression=DEFAULT_COMPRESSION,
                      overviews=None):
    """
    GDAL commands to create a COG from an input file.
    Returns a tuple (commands, output_path)
    """

    if not overviews:
        overviews = DEFAULT_OVERVIEWS

    def get_output_path(command):
        fname = os.path.splitext(os.path.basename(input_path))[0]
        return os.path.join(tmp_dir, '{}-{}.tif'.format(fname, command))

    compression = compression.lower()

    def add_compression(cmd, overview=False):
        if compression != 'none':
            if not overview:
                return cmd[:1] + ['-co', 'compress={}'.format(compression)
                                  ] + cmd[1:]
            else:
                return cmd[:1] + [
                    '--config', 'COMPRESS_OVERVIEW', compression
                ] + cmd[1:]
        else:
            return cmd

    # Step 1: Translate to a GeoTiff.
    translate_path = get_output_path('translate')
    translate = add_compression([
        'gdal_translate', '-of', 'GTiff', '-co', 'tiled=YES', '-co',
        'BIGTIFF=IF_SAFER', input_path, translate_path
    ])

    # Step 2: Add overviews
    add_overviews = add_compression(
        ['gdaladdo', '-r', resample_method, translate_path] + list(
            map(lambda x: str(x), overviews)),
        overview=True)

    # Step 3: Translate to COG
    output_path = get_output_path('cog')

    create_cog = add_compression([
        'gdal_translate', '-co', 'TILED=YES', '-co', 'COPY_SRC_OVERVIEWS=YES',
        '-co', 'BLOCKXSIZE={}'.format(block_size), '-co',
        'BLOCKYSIZE={}'.format(block_size), '-co', 'BIGTIFF=IF_SAFER',
        '--config', 'GDAL_TIFF_OVR_BLOCKSIZE',
        str(block_size), translate_path, output_path
    ])

    return ([translate, add_overviews, create_cog], output_path)


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/utils/cog.py" startline="15" endline="73" pcid="1855">
def gdal_cog_commands(input_path,
                      tmp_dir,
                      block_size=DEFAULT_BLOCK_SIZE,
                      resample_method=DEFAULT_RESAMPLE_METHOD,
                      compression=DEFAULT_COMPRESSION,
                      overviews=None):
    """
    GDAL commands to create a COG from an input file.
    Returns a tuple (commands, output_path)
    """

    if not overviews:
        overviews = DEFAULT_OVERVIEWS

    def get_output_path(command):
        fname = os.path.splitext(os.path.basename(input_path))[0]
        return os.path.join(tmp_dir, '{}-{}.tif'.format(fname, command))

    compression = compression.lower()

    def add_compression(cmd, overview=False):
        if compression != 'none':
            if not overview:
                return cmd[:1] + ['-co', 'compress={}'.format(compression)
                                  ] + cmd[1:]
            else:
                return cmd[:1] + [
                    '--config', 'COMPRESS_OVERVIEW', compression
                ] + cmd[1:]
        else:
            return cmd

    # Step 1: Translate to a GeoTiff.
    translate_path = get_output_path('translate')
    translate = add_compression([
        'gdal_translate', '-of', 'GTiff', '-co', 'tiled=YES', '-co',
        'BIGTIFF=IF_SAFER', input_path, translate_path
    ])

    # Step 2: Add overviews
    add_overviews = add_compression(
        ['gdaladdo', '-r', resample_method, translate_path] + list(
            map(lambda x: str(x), overviews)),
        overview=True)

    # Step 3: Translate to COG
    output_path = get_output_path('cog')

    create_cog = add_compression([
        'gdal_translate', '-co', 'TILED=YES', '-co', 'COPY_SRC_OVERVIEWS=YES',
        '-co', 'BLOCKXSIZE={}'.format(block_size), '-co',
        'BLOCKYSIZE={}'.format(block_size), '-co', 'BIGTIFF=IF_SAFER',
        '--config', 'GDAL_TIFF_OVR_BLOCKSIZE',
        str(block_size), translate_path, output_path
    ])

    return ([translate, add_overviews, create_cog], output_path)


</source>
</class>

<class classid="27" nclones="2" nlines="11" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/command/aux/cogify_command.py" startline="74" endline="86" pcid="375">
def run_cmd(cmd):
    p = Popen(cmd)
    (out, err) = p.communicate(input)
    if p.returncode != 0:
        s = 'Command failed:\n'
        s += ' '.join(cmd) + '\n\n'
        if out:
            s += out + '\n\n'
        if err:
            s += err
        raise Exception(s)


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/utils/cog.py" startline="74" endline="86" pcid="1858">
def run_cmd(cmd):
    p = Popen(cmd)
    (out, err) = p.communicate(input)
    if p.returncode != 0:
        s = 'Command failed:\n'
        s += ' '.join(cmd) + '\n\n'
        if out:
            s += out + '\n\n'
        if err:
            s += err
        raise Exception(s)


</source>
</class>

<class classid="28" nclones="2" nlines="18" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/command/aux/cogify_command.py" startline="87" endline="108" pcid="376">
def create_cog(source_uri,
               dest_uri,
               local_dir,
               block_size=DEFAULT_BLOCK_SIZE,
               resample_method=DEFAULT_RESAMPLE_METHOD,
               compression=DEFAULT_COMPRESSION,
               overviews=None):
    local_path = download_or_copy(source_uri, local_dir)

    commands, output_path = gdal_cog_commands(
        local_path,
        local_dir,
        block_size=block_size,
        resample_method=resample_method,
        compression=compression,
        overviews=overviews)
    for command in commands:
        run_cmd(command)

    upload_or_copy(output_path, dest_uri)


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/utils/cog.py" startline="87" endline="106" pcid="1859">
def create_cog(source_uri,
               dest_uri,
               local_dir,
               block_size=DEFAULT_BLOCK_SIZE,
               resample_method=DEFAULT_RESAMPLE_METHOD,
               compression=DEFAULT_COMPRESSION,
               overviews=None):
    local_path = download_or_copy(source_uri, local_dir)

    commands, output_path = gdal_cog_commands(
        local_path,
        local_dir,
        block_size=block_size,
        resample_method=resample_method,
        compression=compression,
        overviews=overviews)
    for command in commands:
        run_cmd(command)

    upload_or_copy(output_path, dest_uri)
</source>
</class>

<class classid="29" nclones="3" nlines="11" similarity="90">
<source file="systems/raster-vision-0.11.0/rastervision/command/chip_command_config.py" startline="23" endline="36" pcid="393">

    def create_command(self, tmp_dir=None):
        if len(self.train_scenes) == 0 and len(self.val_scenes) == 0:
            return NoOpCommand()

        if not tmp_dir:
            _tmp_dir = RVConfig.get_tmp_dir()
            tmp_dir = _tmp_dir.name
        else:
            _tmp_dir = tmp_dir

        retval = ChipCommand(self)
        retval.set_tmp_dir(_tmp_dir)
        return retval
</source>
<source file="systems/raster-vision-0.11.0/rastervision/command/eval_command_config.py" startline="19" endline="32" pcid="409">

    def create_command(self, tmp_dir=None):
        if len(self.scenes) == 0 or len(self.evaluators) == 0:
            return NoOpCommand()

        if not tmp_dir:
            _tmp_dir = RVConfig.get_tmp_dir()
            tmp_dir = _tmp_dir.name
        else:
            _tmp_dir = tmp_dir

        retval = EvalCommand(self)
        retval.set_tmp_dir(_tmp_dir)
        return retval
</source>
<source file="systems/raster-vision-0.11.0/rastervision/command/predict_command_config.py" startline="23" endline="36" pcid="423">

    def create_command(self, tmp_dir=None):
        if len(self.scenes) == 0:
            return NoOpCommand()

        if not tmp_dir:
            _tmp_dir = RVConfig.get_tmp_dir()
            tmp_dir = _tmp_dir.name
        else:
            _tmp_dir = tmp_dir

        retval = PredictCommand(self)
        retval.set_tmp_dir(_tmp_dir)
        return retval
</source>
</class>

<class classid="30" nclones="2" nlines="10" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/data/label_source/object_detection_label_source_config.py" startline="75" endline="93" pcid="547">
    def with_vector_source(self, vector_source):
        """Set the vector_source.

        Args:
            vector_source (str or VectorSource) if a string, assume it is
                a URI and use the default provider to construct a VectorSource.
        """
        if isinstance(vector_source, str):
            return self.with_uri(vector_source)

        b = deepcopy(self)
        if isinstance(vector_source, VectorSourceConfig):
            b.config['vector_source'] = vector_source
        else:
            raise rv.ConfigError(
                'vector_source must be of type str or VectorSource')

        return b

</source>
<source file="systems/raster-vision-0.11.0/rastervision/data/raster_source/rasterized_source_config.py" startline="142" endline="160" pcid="644">
            vector_source = VectorSourceConfig.from_proto(
                msg.rasterized_source.vector_source)
            rasterizer_options = msg.rasterized_source.rasterizer_options

        return b \
            .with_vector_source(vector_source) \
            .with_rasterizer_options(
                rasterizer_options.background_class_id,
                rasterizer_options.all_touched)

    def with_vector_source(self, vector_source):
        """Set the vector_source.

        Args:
            vector_source (str or VectorSource) if a string, assume it is
                a URI and use the default provider to construct a VectorSource.
        """
        if isinstance(vector_source, str):
            return self.with_uri(vector_source)
</source>
</class>

<class classid="31" nclones="2" nlines="22" similarity="86">
<source file="systems/raster-vision-0.11.0/rastervision/data/label_source/segmentation_class_transformer.py" startline="8" endline="50" pcid="557">
    def __init__(self, class_map):
        color_to_class = dict(
            [(item.color, item.id) for item in class_map.get_items()])

        # color int to class
        color_int_to_class = dict(
            zip([color_to_integer(c) for c in color_to_class.keys()],
                color_to_class.values()))

        def color_int_to_class_fn(color: int) -> int:
            # Convert unspecified colors to class 0 which is "don't care"
            return color_int_to_class.get(color, 0x00)

        self.transform_color_int_to_class = \
            np.vectorize(color_int_to_class_fn, otypes=[np.uint8])

        # class to color triple
        class_to_color_triple = dict(
            zip(color_to_class.values(),
                [color_to_triple(c) for c in color_to_class.keys()]))

        def class_to_channel_color(channel: int, class_id: int) -> int:
            """Given a channel (red, green, or blue) and a class, return the
            intensity of that channel.

            Args:
                 channel: An integer with value 0, 1, or 2
                      representing the channel.
                 class_id: The class id represented as an integer.
            Returns:
                 The intensity of the channel for the color associated
                      with the given class.
            """
            default_triple = (0x00, 0x00, 0x00)
            return class_to_color_triple.get(class_id, default_triple)[channel]

        class_to_r = np.vectorize(
            lambda c: class_to_channel_color(0, c), otypes=[np.uint8])
        class_to_g = np.vectorize(
            lambda c: class_to_channel_color(1, c), otypes=[np.uint8])
        class_to_b = np.vectorize(
            lambda c: class_to_channel_color(2, c), otypes=[np.uint8])
        self.transform_class_to_color = [class_to_r, class_to_g, class_to_b]
</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/label_source/segmentation_class_transformer.py" startline="8" endline="48" pcid="1637">
    def __init__(self, class_config):
        color_to_class = class_config.get_color_to_class_id()
        color_int_to_class = dict(
            zip([color_to_integer(c) for c in color_to_class.keys()],
                color_to_class.values()))
        null_class_id = class_config.get_null_class_id()

        def color_int_to_class_fn(color: int) -> int:
            # Convert unspecified colors to null class
            return color_int_to_class.get(color, null_class_id)

        self.transform_color_int_to_class = \
            np.vectorize(color_int_to_class_fn, otypes=[np.uint8])

        # class to color triple
        class_to_color_triple = dict(
            zip(color_to_class.values(),
                [color_to_triple(c) for c in color_to_class.keys()]))

        def class_to_channel_color(channel: int, class_id: int) -> int:
            """Given a channel (red, green, or blue) and a class, return the
            intensity of that channel.

            Args:
                 channel: An integer with value 0, 1, or 2
                      representing the channel.
                 class_id: The class id represented as an integer.
            Returns:
                 The intensity of the channel for the color associated
                      with the given class.
            """
            default_triple = (0x00, 0x00, 0x00)
            return class_to_color_triple.get(class_id, default_triple)[channel]

        class_to_r = np.vectorize(
            lambda c: class_to_channel_color(0, c), otypes=[np.uint8])
        class_to_g = np.vectorize(
            lambda c: class_to_channel_color(1, c), otypes=[np.uint8])
        class_to_b = np.vectorize(
            lambda c: class_to_channel_color(2, c), otypes=[np.uint8])
        self.transform_class_to_color = [class_to_r, class_to_g, class_to_b]
</source>
</class>

<class classid="32" nclones="2" nlines="12" similarity="84">
<source file="systems/raster-vision-0.11.0/rastervision/data/label_source/semantic_segmentation_label_source.py" startline="33" endline="59" pcid="565">
    def enough_target_pixels(self, window: Box, target_count_threshold: int,
                             target_classes: List[int]) -> bool:
        """Given a window, answer whether the window contains enough pixels in
        the target classes.

        Args:
             window: The larger window from-which the sub-window will
                  be clipped.
             target_count_threshold:  Minimum number of target pixels.
             target_classes: The classes of interest.  The given
                  window is examined to make sure that it contains a
                  sufficient number of target pixels.
        Returns:
             True (the window does contain interesting pixels) or False.
        """
        raw_labels = self.source.get_raw_chip(window)
        if self.class_transformer is not None:
            labels = self.class_transformer.rgb_to_class(raw_labels)
        else:
            labels = np.squeeze(raw_labels)

        target_count = 0
        for class_id in target_classes:
            target_count = target_count + (labels == class_id).sum()

        return target_count >= target_count_threshold

</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/label_source/semantic_segmentation_label_source.py" startline="55" endline="85" pcid="1646">
    def enough_target_pixels(self, window: Box, target_count_threshold: int,
                             target_classes: List[int]) -> bool:
        """Given a window, answer whether the window contains enough pixels in
        the target classes.

        Args:
             window: The larger window from-which the sub-window will
                  be clipped.
             target_count_threshold:  Minimum number of target pixels.
             target_classes: The classes of interest.  The given
                  window is examined to make sure that it contains a
                  sufficient number of target pixels.
        Returns:
             True (the window does contain interesting pixels) or False.
        """
        raw_labels = self.raster_source.get_raw_chip(window)

        if self.class_transformer is not None:
            labels = self.class_transformer.rgb_to_class(raw_labels)
        else:
            labels = np.squeeze(raw_labels)

        labels = fill_edge(labels, window, self.raster_source.get_extent(),
                           self.null_class_id)

        target_count = 0
        for class_id in target_classes:
            target_count = target_count + (labels == class_id).sum()

        return target_count >= target_count_threshold

</source>
</class>

<class classid="33" nclones="2" nlines="26" similarity="96">
<source file="systems/raster-vision-0.11.0/rastervision/data/label_source/chip_classification_label_source.py" startline="11" endline="74" pcid="571">
def infer_cell(cell, str_tree, ioa_thresh, use_intersection_over_cell,
               background_class_id, pick_min_class_id):
    """Infer the class_id of a cell given a set of polygons.

    Given a cell and a set of polygons, the problem is to infer the class_id
    that best captures the content of the cell. This is non-trivial since there
    can be multiple polygons of differing classes overlapping with the cell.
    Any polygons that sufficiently overlaps with the cell are in the running for
    setting the class_id. If there are none in the running, the cell is either
    considered null or background. See args for more details.

    Args:
        cell: Box
        str_tree: (STRtree) collection of geoms in scene used for geometric queries.
            The geoms need to have class_id monkey-patched onto them.
        ioa_thresh: (float) the minimum IOA of a polygon and cell for that
            polygon to be a candidate for setting the class_id
        use_intersection_over_cell: (bool) If true, then use the area of the
            cell as the denominator in the IOA. Otherwise, use the area of the
            polygon.
        background_class_id: (None or int) If not None, class_id to use as the
            background class; ie. the one that is used when a window contains
            no boxes. If not set, empty windows have None set as their class_id
            which is considered a null value.
        pick_min_class_id: If true, the class_id for a cell is the minimum
            class_id of the boxes in that cell. Otherwise, pick the class_id of
            the box covering the greatest area.
    """
    cell_geom = cell.to_shapely()
    inter_polys = str_tree.query(cell_geom)

    inter_over_cells = []
    inter_over_polys = []
    class_ids = []

    # Find polygons whose intersection with the cell is big enough.
    for poly in inter_polys:
        inter = poly.intersection(cell_geom)
        inter_over_cell = inter.area / cell_geom.area
        inter_over_poly = inter.area / poly.area

        if use_intersection_over_cell:
            enough_inter = inter_over_cell >= ioa_thresh
        else:
            enough_inter = inter_over_poly >= ioa_thresh

        if enough_inter:
            inter_over_cells.append(inter_over_cell)
            inter_over_polys.append(inter_over_poly)
            class_ids.append(poly.class_id)

    # Infer class id for cell.
    if len(class_ids) == 0:
        class_id = (None if background_class_id == 0 else background_class_id)
    elif pick_min_class_id:
        class_id = min(class_ids)
    else:
        # Pick class_id of the polygon with the biggest intersection over
        # cell. If there is a tie, pick the first.
        class_id = class_ids[np.argmax(inter_over_cells)]

    return class_id


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/label_source/chip_classification_label_source.py" startline="18" endline="81" pcid="1651">
def infer_cell(cell, str_tree, ioa_thresh, use_intersection_over_cell,
               background_class_id, pick_min_class_id):
    """Infer the class_id of a cell given a set of polygons.

    Given a cell and a set of polygons, the problem is to infer the class_id
    that best captures the content of the cell. This is non-trivial since there
    can be multiple polygons of differing classes overlapping with the cell.
    Any polygons that sufficiently overlaps with the cell are in the running for
    setting the class_id. If there are none in the running, the cell is either
    considered null or background. See args for more details.

    Args:
        cell: Box
        str_tree: (STRtree) collection of geoms in scene used for geometric queries.
            The geoms need to have class_id monkey-patched onto them.
        ioa_thresh: (float) the minimum IOA of a polygon and cell for that
            polygon to be a candidate for setting the class_id
        use_intersection_over_cell: (bool) If true, then use the area of the
            cell as the denominator in the IOA. Otherwise, use the area of the
            polygon.
        background_class_id: (None or int) If not None, class_id to use as the
            background class; ie. the one that is used when a window contains
            no boxes. If not set, empty windows have None set as their class_id
            which is considered a null value.
        pick_min_class_id: If true, the class_id for a cell is the minimum
            class_id of the boxes in that cell. Otherwise, pick the class_id of
            the box covering the greatest area.
    """
    cell_geom = cell.to_shapely()
    inter_polys = str_tree.query(cell_geom)

    inter_over_cells = []
    inter_over_polys = []
    class_ids = []

    # Find polygons whose intersection with the cell is big enough.
    for poly in inter_polys:
        inter = poly.intersection(cell_geom)
        inter_over_cell = inter.area / cell_geom.area
        inter_over_poly = inter.area / poly.area

        if use_intersection_over_cell:
            enough_inter = inter_over_cell >= ioa_thresh
        else:
            enough_inter = inter_over_poly >= ioa_thresh

        if enough_inter:
            inter_over_cells.append(inter_over_cell)
            inter_over_polys.append(inter_over_poly)
            class_ids.append(poly.class_id)

    # Infer class id for cell.
    if len(class_ids) == 0:
        class_id = background_class_id
    elif pick_min_class_id:
        class_id = min(class_ids)
    else:
        # Pick class_id of the polygon with the biggest intersection over
        # cell. If there is a tie, pick the first.
        class_id = class_ids[np.argmax(inter_over_cells)]

    return class_id


</source>
</class>

<class classid="34" nclones="2" nlines="17" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/data/label_source/chip_classification_label_source.py" startline="75" endline="111" pcid="572">
def infer_labels(geojson, extent, cell_size, ioa_thresh,
                 use_intersection_over_cell, pick_min_class_id,
                 background_class_id):
    """Infer ChipClassificationLabels grid from GeoJSON containing polygons.

    Given GeoJSON with polygons associated with class_ids, infer a grid of
    cells and class_ids that best captures the contents of each cell. See infer_cell for
    info on the args.

    Args:
        geojson: dict in normalized GeoJSON format (see VectorSource)
        extent: Box representing the bounds of the grid

    Returns:
        ChipClassificationLabels
    """
    labels = ChipClassificationLabels()
    cells = extent.get_windows(cell_size, cell_size)

    # We need to associate class_id with each geom. Monkey-patching it onto the geom
    # seems like a bad idea, but it's the only straightforward way of doing this
    # that I've been able to find.
    geoms = []
    for f in geojson['features']:
        g = shape(f['geometry'])
        g.class_id = f['properties']['class_id']
        geoms.append(g)
    str_tree = STRtree(geoms)

    for cell in cells:
        class_id = infer_cell(cell, str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        labels.set_cell(cell, class_id)
    return labels


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/label_source/chip_classification_label_source.py" startline="82" endline="118" pcid="1652">
def infer_labels(geojson, extent, cell_sz, ioa_thresh,
                 use_intersection_over_cell, pick_min_class_id,
                 background_class_id):
    """Infer ChipClassificationLabels grid from GeoJSON containing polygons.

    Given GeoJSON with polygons associated with class_ids, infer a grid of
    cells and class_ids that best captures the contents of each cell. See infer_cell for
    info on the args.

    Args:
        geojson: dict in normalized GeoJSON format (see VectorSource)
        extent: Box representing the bounds of the grid

    Returns:
        ChipClassificationLabels
    """
    labels = ChipClassificationLabels()
    cells = extent.get_windows(cell_sz, cell_sz)

    # We need to associate class_id with each geom. Monkey-patching it onto the geom
    # seems like a bad idea, but it's the only straightforward way of doing this
    # that I've been able to find.
    geoms = []
    for f in geojson['features']:
        g = shape(f['geometry'])
        g.class_id = f['properties']['class_id']
        geoms.append(g)
    str_tree = STRtree(geoms)

    for cell in cells:
        class_id = infer_cell(cell, str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        labels.set_cell(cell, class_id)
    return labels


</source>
</class>

<class classid="35" nclones="2" nlines="14" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/data/label_source/chip_classification_label_source.py" startline="112" endline="144" pcid="573">
def read_labels(geojson, extent=None):
    """Convert GeoJSON to ChipClassificationLabels.

    If the GeoJSON already contains a grid of cells, then it can be constructed
    in a straightforward manner without having to infer the class of cells.

    If extent is given, only labels that intersect with the extent are returned.

    Args:
        geojson: dict in normalized GeoJSON format (see VectorSource)
        extent: Box in pixel coords

    Returns:
       ChipClassificationLabels
    """
    labels = ChipClassificationLabels()

    for f in geojson['features']:
        geom = shape(f['geometry'])
        (xmin, ymin, xmax, ymax) = geom.bounds
        cell = Box(ymin, xmin, ymax, xmax)
        if extent is not None and not cell.to_shapely().intersects(
                extent.to_shapely()):
            continue

        props = f['properties']
        class_id = props['class_id']
        scores = props.get('scores')
        labels.set_cell(cell, class_id, scores)

    return labels


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/label_source/chip_classification_label_source.py" startline="119" endline="151" pcid="1653">
def read_labels(geojson, extent=None):
    """Convert GeoJSON to ChipClassificationLabels.

    If the GeoJSON already contains a grid of cells, then it can be constructed
    in a straightforward manner without having to infer the class of cells.

    If extent is given, only labels that intersect with the extent are returned.

    Args:
        geojson: dict in normalized GeoJSON format (see VectorSource)
        extent: Box in pixel coords

    Returns:
       ChipClassificationLabels
    """
    labels = ChipClassificationLabels()

    for f in geojson['features']:
        geom = shape(f['geometry'])
        (xmin, ymin, xmax, ymax) = geom.bounds
        cell = Box(ymin, xmin, ymax, xmax)
        if extent is not None and not cell.to_shapely().intersects(
                extent.to_shapely()):
            continue

        props = f['properties']
        class_id = props['class_id']
        scores = props.get('scores')
        labels.set_cell(cell, class_id, scores)

    return labels


</source>
</class>

<class classid="36" nclones="2" nlines="18" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/data/activate_mixin.py" startline="46" endline="67" pcid="594">
    def activate(self):
        if hasattr(self, '_mixin_activated'):
            if self._mixin_activated:
                raise ActivationError('This {} is already activated'.format(
                    type(self)))

        def do_activate():
            self._mixin_activated = True
            self._activate()

        def do_deactivate():
            self._deactivate()
            self._mixin_activated = False

        a = ActivateMixin.ActivateContextManager(do_activate, do_deactivate)
        subcomponents = self._subcomponents_to_activate()
        if subcomponents:
            return ActivateMixin.CompositeContextManager(
                a, ActivateMixin.compose(*subcomponents))
        else:
            return a

</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/activate_mixin.py" startline="47" endline="68" pcid="1664">
    def activate(self):
        if hasattr(self, '_mixin_activated'):
            if self._mixin_activated:
                raise ActivationError('This {} is already activated'.format(
                    type(self)))

        def do_activate():
            self._mixin_activated = True
            self._activate()

        def do_deactivate():
            self._deactivate()
            self._mixin_activated = False

        a = ActivateMixin.ActivateContextManager(do_activate, do_deactivate)
        subcomponents = self._subcomponents_to_activate()
        if subcomponents:
            return ActivateMixin.CompositeContextManager(
                a, ActivateMixin.compose(*subcomponents))
        else:
            return a

</source>
</class>

<class classid="37" nclones="3" nlines="25" similarity="79">
<source file="systems/raster-vision-0.11.0/rastervision/data/utils.py" startline="1" endline="49" pcid="602">
def boxes_to_geojson(boxes, class_ids, crs_transformer, class_map,
                     scores=None):
    """Convert boxes and associated data into a GeoJSON dict.

    Args:
        boxes: list of Box in pixel row/col format.
        class_ids: list of int (one for each box)
        crs_transformer: CRSTransformer used to convert pixel coords to map
            coords in the GeoJSON
        class_map: ClassMap used to infer class_name from class_id
        scores: optional list of score or scores.
                If floats (one for each box), property name will be "score".
                If lists of floats, property name will be "scores".

    Returns:
        dict in GeoJSON format
    """
    features = []
    for box_ind, box in enumerate(boxes):
        polygon = box.geojson_coordinates()
        polygon = [list(crs_transformer.pixel_to_map(p)) for p in polygon]

        class_id = int(class_ids[box_ind])
        class_name = class_map.get_by_id(class_id).name

        feature = {
            'type': 'Feature',
            'geometry': {
                'type': 'Polygon',
                'coordinates': [polygon]
            },
            'properties': {
                'class_id': class_id,
                'class_name': class_name
            }
        }

        if scores is not None:
            box_scores = scores[box_ind]

            if box_scores is not None:
                if type(box_scores) is list:
                    feature['properties']['scores'] = box_scores
                else:
                    feature['properties']['score'] = box_scores

        features.append(feature)

    return {'type': 'FeatureCollection', 'features': features}
</source>
<source file="systems/raster-vision-0.11.0/rastervision/data/label_store/utils.py" startline="1" endline="49" pcid="939">
def boxes_to_geojson(boxes, class_ids, crs_transformer, class_map,
                     scores=None):
    """Convert boxes and associated data into a GeoJSON dict.

    Args:
        boxes: list of Box in pixel row/col format.
        class_ids: list of int (one for each box)
        crs_transformer: CRSTransformer used to convert pixel coords to map
            coords in the GeoJSON
        class_map: ClassMap used to infer class_name from class_id
        scores: optional list of score or scores.
                If floats (one for each box), property name will be "score".
                If lists of floats, property name will be "scores".

    Returns:
        dict in GeoJSON format
    """
    features = []
    for box_ind, box in enumerate(boxes):
        polygon = box.geojson_coordinates()
        polygon = [list(crs_transformer.pixel_to_map(p)) for p in polygon]

        class_id = int(class_ids[box_ind])
        class_name = class_map.get_by_id(class_id).name

        feature = {
            'type': 'Feature',
            'geometry': {
                'type': 'Polygon',
                'coordinates': [polygon]
            },
            'properties': {
                'class_id': class_id,
                'class_name': class_name
            }
        }

        if scores is not None:
            box_scores = scores[box_ind]

            if box_scores is not None:
                if type(box_scores) is list:
                    feature['properties']['scores'] = box_scores
                else:
                    feature['properties']['score'] = box_scores

        features.append(feature)

    return {'type': 'FeatureCollection', 'features': features}
</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/label_store/utils.py" startline="1" endline="53" pcid="1836">
def boxes_to_geojson(  # noqa
        boxes,  # noqa
        class_ids,
        crs_transformer,
        class_config,
        scores=None):
    """Convert boxes and associated data into a GeoJSON dict.

    Args:
        boxes: list of Box in pixel row/col format.
        class_ids: list of int (one for each box)
        crs_transformer: CRSTransformer used to convert pixel coords to map
            coords in the GeoJSON
        class_config: ClassConfig
        scores: optional list of score or scores.
                If floats (one for each box), property name will be "score".
                If lists of floats, property name will be "scores".

    Returns:
        dict in GeoJSON format
    """
    features = []
    for box_ind, box in enumerate(boxes):
        polygon = box.geojson_coordinates()
        polygon = [list(crs_transformer.pixel_to_map(p)) for p in polygon]

        class_id = int(class_ids[box_ind])
        class_name = class_config.get_name(class_id)

        feature = {
            'type': 'Feature',
            'geometry': {
                'type': 'Polygon',
                'coordinates': [polygon]
            },
            'properties': {
                'class_id': class_id,
                'class_name': class_name
            }
        }

        if scores is not None:
            box_scores = scores[box_ind]

            if box_scores is not None:
                if type(box_scores) is list:
                    feature['properties']['scores'] = box_scores
                else:
                    feature['properties']['score'] = box_scores

        features.append(feature)

    return {'type': 'FeatureCollection', 'features': features}
</source>
</class>

<class classid="38" nclones="2" nlines="23" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/data/raster_transformer/stats_transformer.py" startline="19" endline="66" pcid="611">

    def transform(self, chip, channel_order=None):
        """Transform a chip.

        Transforms non-uint8 to uint8 values using raster_stats.

        Args:
            chip: ndarray of shape [height, width, channels] This is assumed to already
                have the channel_order applied to it if channel_order is set. In other
                words, channels should be equal to len(channel_order).
            channel_order: list of indices of channels that were extracted from the
                raw imagery.

        Returns:
            [height, width, channels] uint8 numpy array

        """
        if chip.dtype != np.uint8:
            if self.raster_stats:
                if channel_order is None:
                    channel_order = np.arange(chip.shape[2])

                # Subtract mean and divide by std to get zscores.
                means = np.array(self.raster_stats.means)
                means = means[np.newaxis, np.newaxis, channel_order].astype(
                    np.float)
                stds = np.array(self.raster_stats.stds)
                stds = stds[np.newaxis, np.newaxis, channel_order].astype(
                    np.float)

                # Don't transform NODATA zero values.
                nodata = chip == 0

                chip = chip - means
                chip = chip / stds

                # Make zscores that fall between -3 and 3 span 0 to 255.
                chip += 3
                chip /= 6

                chip = np.clip(chip, 0, 1)
                chip *= 255
                chip = chip.astype(np.uint8)

                chip[nodata] = 0
            else:
                raise ValueError('raster_stats not defined.')

</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/raster_transformer/stats_transformer.py" startline="19" endline="66" pcid="1678">

    def transform(self, chip, channel_order=None):
        """Transform a chip.

        Transforms non-uint8 to uint8 values using raster_stats.

        Args:
            chip: ndarray of shape [height, width, channels] This is assumed to already
                have the channel_order applied to it if channel_order is set. In other
                words, channels should be equal to len(channel_order).
            channel_order: list of indices of channels that were extracted from the
                raw imagery.

        Returns:
            [height, width, channels] uint8 numpy array

        """
        if chip.dtype != np.uint8:
            if self.raster_stats:
                if channel_order is None:
                    channel_order = np.arange(chip.shape[2])

                # Subtract mean and divide by std to get zscores.
                means = np.array(self.raster_stats.means)
                means = means[np.newaxis, np.newaxis, channel_order].astype(
                    np.float)
                stds = np.array(self.raster_stats.stds)
                stds = stds[np.newaxis, np.newaxis, channel_order].astype(
                    np.float)

                # Don't transform NODATA zero values.
                nodata = chip == 0

                chip = chip - means
                chip = chip / stds

                # Make zscores that fall between -3 and 3 span 0 to 255.
                chip += 3
                chip /= 6

                chip = np.clip(chip, 0, 1)
                chip *= 255
                chip = chip.astype(np.uint8)

                chip[nodata] = 0
            else:
                raise ValueError('raster_stats not defined.')

</source>
</class>

<class classid="39" nclones="2" nlines="12" similarity="76">
<source file="systems/raster-vision-0.11.0/rastervision/data/raster_source/rasterized_source_config.py" startline="33" endline="44" pcid="633">
                all_touched=self.all_touched)

    def __init__(self,
                 vector_source,
                 rasterizer_options,
                 transformers=None,
                 channel_order=None):
        super().__init__(
            source_type=rv.RASTERIZED_SOURCE,
            transformers=transformers,
            channel_order=channel_order)
        self.vector_source = vector_source
</source>
<source file="systems/raster-vision-0.11.0/rastervision/data/raster_source/rasterio_source_config.py" startline="11" endline="24" pcid="671">

class RasterioSourceConfig(RasterSourceConfig):
    def __init__(self,
                 uris,
                 x_shift_meters=0.0,
                 y_shift_meters=0.0,
                 transformers=None,
                 channel_order=None):
        super().__init__(
            source_type=rv.RASTERIO_SOURCE,
            transformers=transformers,
            channel_order=channel_order)
        self.uris = uris
        self.x_shift_meters = x_shift_meters
</source>
</class>

<class classid="40" nclones="2" nlines="11" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/data/raster_source/rasterio_source.py" startline="40" endline="67" pcid="649">
def load_window(image_dataset, window=None, is_masked=False):
    """Load a window of an image using Rasterio.

    Args:
        image_dataset: a Rasterio dataset
        window: ((row_start, row_stop), (col_start, col_stop)) or
        ((y_min, y_max), (x_min, x_max))
        is_masked: If True, read a masked array from rasterio

    Returns:
        np.ndarray of shape (height, width, channels) where channels is the number of
            channels in the image_dataset.
    """
    if is_masked:
        im = image_dataset.read(window=window, boundless=True, masked=True)
        im = np.ma.filled(im, fill_value=0)
    else:
        im = image_dataset.read(window=window, boundless=True)

    # Handle non-zero NODATA values by setting the data to 0.
    for channel, nodata in enumerate(image_dataset.nodatavals):
        if nodata is not None and nodata != 0:
            im[channel, im[channel] == nodata] = 0

    im = np.transpose(im, axes=[1, 2, 0])
    return im


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/raster_source/rasterio_source.py" startline="40" endline="67" pcid="1686">
def load_window(image_dataset, window=None, is_masked=False):
    """Load a window of an image using Rasterio.

    Args:
        image_dataset: a Rasterio dataset
        window: ((row_start, row_stop), (col_start, col_stop)) or
        ((y_min, y_max), (x_min, x_max))
        is_masked: If True, read a masked array from rasterio

    Returns:
        np.ndarray of shape (height, width, channels) where channels is the number of
            channels in the image_dataset.
    """
    if is_masked:
        im = image_dataset.read(window=window, boundless=True, masked=True)
        im = np.ma.filled(im, fill_value=0)
    else:
        im = image_dataset.read(window=window, boundless=True)

    # Handle non-zero NODATA values by setting the data to 0.
    for channel, nodata in enumerate(image_dataset.nodatavals):
        if nodata is not None and nodata != 0:
            im[channel, im[channel] == nodata] = 0

    im = np.transpose(im, axes=[1, 2, 0])
    return im


</source>
</class>

<class classid="41" nclones="2" nlines="38" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/data/raster_source/rasterio_source.py" startline="69" endline="128" pcid="650">
    def __init__(self,
                 uris,
                 raster_transformers,
                 temp_dir,
                 channel_order=None,
                 x_shift_meters=0.0,
                 y_shift_meters=0.0):
        """Constructor.

        This RasterSource can read any file that can be opened by Rasterio/GDAL
        including georeferenced formats such as GeoTIFF and non-georeferenced formats
        such as JPG. See https://www.gdal.org/formats_list.html for more details.

        If channel_order is None, then use non-alpha channels. This also sets any
        masked or NODATA pixel values to be zeros.

        Args:
            channel_order: list of indices of channels to extract from raw imagery
        """
        self.uris = uris
        self.temp_dir = temp_dir
        self.image_temp_dir = None
        self.image_dataset = None
        self.x_shift_meters = x_shift_meters
        self.y_shift_meters = y_shift_meters

        num_channels = None

        # Activate in order to get information out of the raster
        with self.activate():
            num_channels = self.image_dataset.count
            if channel_order is None:
                colorinterp = self.image_dataset.colorinterp
                if colorinterp:
                    channel_order = [
                        i for i, color_interp in enumerate(colorinterp)
                        if color_interp != ColorInterp.alpha
                    ]
                else:
                    channel_order = list(range(0, num_channels))
            self.validate_channel_order(channel_order, num_channels)

            mask_flags = self.image_dataset.mask_flag_enums
            self.is_masked = any(
                [m for m in mask_flags if m != MaskFlags.all_valid])

            self.height = self.image_dataset.height
            self.width = self.image_dataset.width

            # Get 1x1 chip and apply raster transformers to test dtype.
            test_chip = self.get_raw_chip(Box.make_square(0, 0, 1))
            test_chip = test_chip[:, :, channel_order]
            for transformer in raster_transformers:
                test_chip = transformer.transform(test_chip, channel_order)
            self.dtype = test_chip.dtype

            self._set_crs_transformer()

        super().__init__(channel_order, num_channels, raster_transformers)

</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/raster_source/rasterio_source.py" startline="69" endline="128" pcid="1687">
    def __init__(self,
                 uris,
                 raster_transformers,
                 tmp_dir,
                 channel_order=None,
                 x_shift=0.0,
                 y_shift=0.0):
        """Constructor.

        This RasterSource can read any file that can be opened by Rasterio/GDAL
        including georeferenced formats such as GeoTIFF and non-georeferenced formats
        such as JPG. See https://www.gdal.org/formats_list.html for more details.

        If channel_order is None, then use non-alpha channels. This also sets any
        masked or NODATA pixel values to be zeros.

        Args:
            channel_order: list of indices of channels to extract from raw imagery
        """
        self.uris = uris
        self.tmp_dir = tmp_dir
        self.image_tmp_dir = None
        self.image_dataset = None
        self.x_shift = x_shift
        self.y_shift = y_shift

        num_channels = None

        # Activate in order to get information out of the raster
        with self.activate():
            num_channels = self.image_dataset.count
            if channel_order is None:
                colorinterp = self.image_dataset.colorinterp
                if colorinterp:
                    channel_order = [
                        i for i, color_interp in enumerate(colorinterp)
                        if color_interp != ColorInterp.alpha
                    ]
                else:
                    channel_order = list(range(0, num_channels))
            self.validate_channel_order(channel_order, num_channels)

            mask_flags = self.image_dataset.mask_flag_enums
            self.is_masked = any(
                [m for m in mask_flags if m != MaskFlags.all_valid])

            self.height = self.image_dataset.height
            self.width = self.image_dataset.width

            # Get 1x1 chip and apply raster transformers to test dtype.
            test_chip = self.get_raw_chip(Box.make_square(0, 0, 1))
            test_chip = test_chip[:, :, channel_order]
            for transformer in raster_transformers:
                test_chip = transformer.transform(test_chip, channel_order)
            self.dtype = test_chip.dtype

            self._set_crs_transformer()

        super().__init__(channel_order, num_channels, raster_transformers)

</source>
</class>

<class classid="42" nclones="2" nlines="27" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/data/raster_source/rasterio_source.py" startline="181" endline="222" pcid="659">
    def _get_shifted_window(self, window):
        do_shift = self.x_shift_meters != 0.0 or self.y_shift_meters != 0.0
        if do_shift:
            ymin, xmin, ymax, xmax = window.tuple_format()
            width = window.get_width()
            height = window.get_height()

            # Transform image coordinates into world coordinates
            transform = self.image_dataset.transform
            xmin2, ymin2 = transform * (xmin, ymin)

            # Transform from world coordinates to WGS84
            if self.crs != wgs84_proj4 and self.proj:
                lon, lat = pyproj.transform(self.proj, wgs84, xmin2, ymin2)
            else:
                lon, lat = xmin2, ymin2

            # Shift.  This is performed by computing the shifts in
            # meters to shifts in degrees.  Those shifts are then
            # applied to the WGS84 coordinate.
            #
            # Courtesy of https://gis.stackexchange.com/questions/2951/algorithm-for-offsetting-a-latitude-longitude-by-some-amount-of-meters  # noqa
            lat_radians = math.pi * lat / 180.0
            dlon = Decimal(self.x_shift_meters) / Decimal(
                meters_per_degree * math.cos(lat_radians))
            dlat = Decimal(self.y_shift_meters) / Decimal(meters_per_degree)
            lon = float(Decimal(lon) + dlon)
            lat = float(Decimal(lat) + dlat)

            # Transform from WGS84 to world coordinates
            if self.crs != wgs84_proj4 and self.proj:
                xmin3, ymin3 = pyproj.transform(wgs84, self.proj, lon, lat)
                xmin3 = int(round(xmin3))
                ymin3 = int(round(ymin3))
            else:
                xmin3, ymin3 = lon, lat

            # Trasnform from world coordinates back into image coordinates
            xmin4, ymin4 = ~transform * (xmin3, ymin3)

            window = Box(ymin4, xmin4, ymin4 + height, xmin4 + width)
        return window
</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/raster_source/rasterio_source.py" startline="181" endline="222" pcid="1696">
    def _get_shifted_window(self, window):
        do_shift = self.x_shift != 0.0 or self.y_shift != 0.0
        if do_shift:
            ymin, xmin, ymax, xmax = window.tuple_format()
            width = window.get_width()
            height = window.get_height()

            # Transform image coordinates into world coordinates
            transform = self.image_dataset.transform
            xmin2, ymin2 = transform * (xmin, ymin)

            # Transform from world coordinates to WGS84
            if self.crs != wgs84_proj4 and self.proj:
                lon, lat = pyproj.transform(self.proj, wgs84, xmin2, ymin2)
            else:
                lon, lat = xmin2, ymin2

            # Shift.  This is performed by computing the shifts in
            # meters to shifts in degrees.  Those shifts are then
            # applied to the WGS84 coordinate.
            #
            # Courtesy of https://gis.stackexchange.com/questions/2951/algorithm-for-offsetting-a-latitude-longitude-by-some-amount-of-meters  # noqa
            lat_radians = math.pi * lat / 180.0
            dlon = Decimal(self.x_shift) / Decimal(
                meters_per_degree * math.cos(lat_radians))
            dlat = Decimal(self.y_shift) / Decimal(meters_per_degree)
            lon = float(Decimal(lon) + dlon)
            lat = float(Decimal(lat) + dlat)

            # Transform from WGS84 to world coordinates
            if self.crs != wgs84_proj4 and self.proj:
                xmin3, ymin3 = pyproj.transform(wgs84, self.proj, lon, lat)
                xmin3 = int(round(xmin3))
                ymin3 = int(round(ymin3))
            else:
                xmin3, ymin3 = lon, lat

            # Trasnform from world coordinates back into image coordinates
            xmin4, ymin4 = ~transform * (xmin3, ymin3)

            window = Box(ymin4, xmin4, ymin4 + height, xmin4 + width)
        return window
</source>
</class>

<class classid="43" nclones="8" nlines="11" similarity="76">
<source file="systems/raster-vision-0.11.0/rastervision/data/raster_source/rasterio_source_config.py" startline="76" endline="88" pcid="678">

class RasterioSourceConfigBuilder(RasterSourceConfigBuilder):
    """This RasterSource can read any file that can be opened by Rasterio/GDAL.

    This includes georeferenced formats such as GeoTIFF and non-georeferenced formats
    such as JPG. See https://www.gdal.org/formats_list.html for more details.
    """

    def __init__(self, prev=None):
        config = {}
        if prev:
            config = {
                'uris': prev.uris,
</source>
<source file="systems/raster-vision-0.11.0/rastervision/data/vector_source/geojson_vector_source_config.py" startline="46" endline="58" pcid="780">
    def __init__(self, prev=None):
        config = {}
        if prev:
            config = {
                'uri': prev.uri,
                'class_id_to_filter': prev.class_id_to_filter,
                'default_class_id': prev.default_class_id,
                'line_bufs': prev.line_bufs,
                'point_bufs': prev.point_bufs
            }

        super().__init__(GeoJSONVectorSourceConfig, config)

</source>
<source file="systems/raster-vision-0.11.0/rastervision/task/semantic_segmentation_config.py" startline="82" endline="95" pcid="1167">
    def __init__(self, prev=None):
        config = {}
        if prev:
            config = {
                'predict_batch_size': prev.predict_batch_size,
                'predict_package_uri': prev.predict_package_uri,
                'debug': prev.debug,
                'class_map': prev.class_map,
                'chip_size': prev.chip_size,
                'predict_chip_size': prev.predict_chip_size,
                'chip_options': prev.chip_options
            }
        super().__init__(SemanticSegmentationConfig, config)

</source>
<source file="systems/raster-vision-0.11.0/rastervision/data/scene_config.py" startline="147" endline="159" pcid="737">
    def from_proto(msg):
        """Creates a SceneConfig from the specificed protobuf message
        """
        return SceneConfigBuilder().from_proto(msg).build()


class SceneConfigBuilder(ConfigBuilder):
    def __init__(self, prev=None):
        config = {}
        if prev:
            config = {
                'id': prev.id,
                'raster_source': prev.raster_source,
</source>
<source file="systems/raster-vision-0.11.0/rastervision/data/label_store/semantic_segmentation_raster_store_config.py" startline="146" endline="157" pcid="933">

class SemanticSegmentationRasterStoreConfigBuilder(LabelStoreConfigBuilder):
    def __init__(self, prev=None):
        config = {}
        if prev:
            config = {
                'uri': prev.uri,
                'vector_output': prev.vector_output,
                'rgb': prev.rgb,
            }

        super().__init__(SemanticSegmentationRasterStoreConfig, config)
</source>
<source file="systems/raster-vision-0.11.0/rastervision/task/chip_classification_config.py" startline="44" endline="56" pcid="1133">
    def __init__(self, prev=None):
        config = {}
        if prev:
            config = {
                'class_map': prev.class_map,
                'chip_size': prev.chip_size,
                'predict_batch_size': prev.predict_batch_size,
                'predict_package_uri': prev.predict_package_uri,
                'debug': prev.debug,
                'predict_debug_uri': prev.predict_debug_uri
            }
        super().__init__(ChipClassificationConfig, config)

</source>
<source file="systems/raster-vision-0.11.0/rastervision/task/object_detection_config.py" startline="80" endline="94" pcid="1194">
    def __init__(self, prev=None):
        config = {}
        if prev:
            config = {
                'predict_batch_size': prev.predict_batch_size,
                'predict_package_uri': prev.predict_package_uri,
                'debug': prev.debug,
                'predict_debug_uri': prev.predict_debug_uri,
                'class_map': prev.class_map,
                'chip_size': prev.chip_size,
                'chip_options': prev.chip_options,
                'predict_options': prev.predict_options
            }
        super().__init__(ObjectDetectionConfig, config)

</source>
<source file="systems/raster-vision-0.11.0/rastervision/data/vector_source/vector_tile_vector_source_config.py" startline="58" endline="72" pcid="753">
    def __init__(self, prev=None):
        config = {}
        if prev:
            config = {
                'uri': prev.uri,
                'zoom': prev.zoom,
                'id_field': prev.id_field,
                'class_id_to_filter': prev.class_id_to_filter,
                'default_class_id': prev.default_class_id,
                'line_bufs': prev.line_bufs,
                'point_bufs': prev.point_bufs
            }

        super().__init__(VectorTileVectorSourceConfig, config)

</source>
</class>

<class classid="44" nclones="2" nlines="30" similarity="70">
<source file="systems/raster-vision-0.11.0/rastervision/data/raster_source/rasterized_source.py" startline="16" endline="64" pcid="684">
def geoms_to_raster(str_tree, rasterizer_options, window, extent):
    background_class_id = rasterizer_options.background_class_id
    all_touched = rasterizer_options.all_touched

    log.debug('Cropping shapes to window...')
    # Crop shapes against window, remove empty shapes, and put in window frame of
    # reference.
    window_geom = window.to_shapely()
    shapes = str_tree.query(window_geom)
    shapes = [(s, s.class_id) for s in shapes]
    shapes = [(s.intersection(window_geom), c) for s, c in shapes]
    shapes = [(s, c) for s, c in shapes if not s.is_empty]

    def to_window_frame(x, y, z=None):
        return (x - window.xmin, y - window.ymin)

    shapes = [(shapely.ops.transform(to_window_frame, s), c)
              for s, c in shapes]
    log.debug('# of shapes in window: {}'.format(len(shapes)))

    out_shape = (window.get_height(), window.get_width())

    # rasterize needs to be passed >= 1 shapes.
    if shapes:
        log.debug('rasterio.rasterize()...')
        raster = rasterize(
            shapes,
            out_shape=out_shape,
            fill=background_class_id,
            dtype=np.uint8,
            all_touched=all_touched)
    else:
        raster = np.full(out_shape, background_class_id, dtype=np.uint8)

    # Ensure that parts of window outside of extent have zero values which are counted as
    # the don't-care class for segmentation.
    valid_window = window_geom.intersection(extent.to_shapely())
    if valid_window.is_empty:
        raster[:, :] = 0
    else:
        vw = shapely.ops.transform(to_window_frame, valid_window)
        vw = Box.from_shapely(vw).to_int()
        new_raster = np.zeros(out_shape)
        new_raster[vw.ymin:vw.ymax, vw.xmin:vw.xmax] = \
            raster[vw.ymin:vw.ymax, vw.xmin:vw.xmax]
        raster = new_raster

    return raster

</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/raster_source/rasterized_source.py" startline="15" endline="50" pcid="1708">
def geoms_to_raster(str_tree, rasterizer_config, window, extent):
    background_class_id = rasterizer_config.background_class_id
    all_touched = rasterizer_config.all_touched

    log.debug('Cropping shapes to window...')
    # Crop shapes against window, remove empty shapes, and put in window frame of
    # reference.
    window_geom = window.to_shapely()
    shapes = str_tree.query(window_geom)
    shapes = [(s, s.class_id) for s in shapes]
    shapes = [(s.intersection(window_geom), c) for s, c in shapes]
    shapes = [(s, c) for s, c in shapes if not s.is_empty]

    def to_window_frame(x, y, z=None):
        return (x - window.xmin, y - window.ymin)

    shapes = [(transform(to_window_frame, s), c) for s, c in shapes]
    log.debug('# of shapes in window: {}'.format(len(shapes)))

    out_shape = (window.get_height(), window.get_width())

    # rasterize needs to be passed >= 1 shapes.
    if shapes:
        log.debug('rasterio.rasterize()...')
        raster = rasterize(
            shapes,
            out_shape=out_shape,
            fill=background_class_id,
            dtype=np.uint8,
            all_touched=all_touched)
    else:
        raster = np.full(out_shape, background_class_id, dtype=np.uint8)

    return raster


</source>
</class>

<class classid="45" nclones="2" nlines="15" similarity="76">
<source file="systems/raster-vision-0.11.0/rastervision/data/vector_source/vector_tile_vector_source_config.py" startline="12" endline="29" pcid="749">
    def __init__(self,
                 uri,
                 zoom,
                 id_field,
                 class_id_to_filter=None,
                 default_class_id=1,
                 line_bufs=None,
                 point_bufs=None):
        self.uri = uri
        self.zoom = zoom
        self.id_field = id_field
        super().__init__(
            rv.VECTOR_TILE_SOURCE,
            class_id_to_filter=class_id_to_filter,
            default_class_id=default_class_id,
            line_bufs=line_bufs,
            point_bufs=point_bufs)

</source>
<source file="systems/raster-vision-0.11.0/rastervision/data/vector_source/geojson_vector_source_config.py" startline="11" endline="24" pcid="776">
    def __init__(self,
                 uri,
                 class_id_to_filter=None,
                 default_class_id=1,
                 line_bufs=None,
                 point_bufs=None):
        self.uri = uri
        super().__init__(
            rv.GEOJSON_SOURCE,
            class_id_to_filter=class_id_to_filter,
            default_class_id=default_class_id,
            line_bufs=line_bufs,
            point_bufs=point_bufs)

</source>
</class>

<class classid="46" nclones="2" nlines="12" similarity="76">
<source file="systems/raster-vision-0.11.0/rastervision/data/vector_source/vector_tile_vector_source_config.py" startline="37" endline="50" pcid="751">
    def create_source(self, crs_transformer=None, extent=None, class_map=None):
        return VectorTileVectorSource(
            self.uri,
            self.zoom,
            self.id_field,
            crs_transformer,
            extent,
            line_bufs=self.line_bufs,
            point_bufs=self.point_bufs,
            class_inf_opts=ClassInferenceOptions(
                class_map=class_map,
                class_id_to_filter=self.class_id_to_filter,
                default_class_id=self.default_class_id))

</source>
<source file="systems/raster-vision-0.11.0/rastervision/data/vector_source/geojson_vector_source_config.py" startline="30" endline="40" pcid="778">
    def create_source(self, crs_transformer=None, extent=None, class_map=None):
        return GeoJSONVectorSource(
            self.uri,
            crs_transformer,
            line_bufs=self.line_bufs,
            point_bufs=self.point_bufs,
            class_inf_opts=ClassInferenceOptions(
                class_map=class_map,
                class_id_to_filter=self.class_id_to_filter,
                default_class_id=self.default_class_id))

</source>
</class>

<class classid="47" nclones="2" nlines="12" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/data/vector_source/class_inference.py" startline="67" endline="84" pcid="762">
    def transform_geojson(self, geojson):
        """Transform GeoJSON by appending class_ids and removing features with no class.

        For each feature in geojson, the class_id is inferred and is set into
        feature['properties']. If the class_id is None (because none of the rules apply
        and the default_class_id is None), the feature is dropped.
        """
        new_features = []
        for feature in geojson['features']:
            class_id = self.infer_class_id(feature)
            if class_id is not None:
                feature = copy.deepcopy(feature)
                properties = feature.get('properties', {})
                properties['class_id'] = class_id
                feature['properties'] = properties
                new_features.append(feature)
        new_geojson = {'type': 'FeatureCollection', 'features': new_features}
        return new_geojson
</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/vector_source/class_inference.py" startline="57" endline="74" pcid="1732">
    def transform_geojson(self, geojson):
        """Transform GeoJSON by appending class_ids and removing features with no class.

        For each feature in geojson, the class_id is inferred and is set into
        feature['properties']. If the class_id is None (because none of the rules apply
        and the default_class_id is None), the feature is dropped.
        """
        new_features = []
        for feature in geojson['features']:
            class_id = self.infer_class_id(feature)
            if class_id is not None:
                feature = copy.deepcopy(feature)
                properties = feature.get('properties', {})
                properties['class_id'] = class_id
                feature['properties'] = properties
                new_features.append(feature)
        new_geojson = {'type': 'FeatureCollection', 'features': new_features}
        return new_geojson
</source>
</class>

<class classid="48" nclones="2" nlines="64" similarity="96">
<source file="systems/raster-vision-0.11.0/rastervision/data/vector_source/vector_source.py" startline="10" endline="107" pcid="763">
def transform_geojson(geojson,
                      crs_transformer,
                      line_bufs=None,
                      point_bufs=None,
                      to_map_coords=False):
    def is_empty_feat(f):
        # This was added to handle empty geoms which appear when using
        # OSM vector tiles.
        return ((not f.get('geometry'))
                or ((not f['geometry'].get('coordinates')) and
                    (not f['geometry'].get('geometries'))))

    new_features = []
    for f in geojson['features']:
        if is_empty_feat(f):
            continue

        geom = shape(f['geometry'])

        # Convert map to pixel coords. We need to convert to pixel coords before applying
        # buffering because those values are assumed to be in pixel units.
        def m2p(x, y, z=None):
            return crs_transformer.map_to_pixel((x, y))

        geom = shapely.ops.transform(m2p, geom)

        # Split GeometryCollection into list of geoms.
        geoms = [geom]
        if geom.geom_type == 'GeometryCollection':
            geoms = list(geom)

        # Split any MultiX to list of X.
        new_geoms = []
        for g in geoms:
            if g.geom_type in [
                    'MultiPolygon', 'MultiPoint', 'MultiLineString'
            ]:
                new_geoms.extend(list(g))
            else:
                new_geoms.append(g)
        geoms = new_geoms

        # Buffer geoms.
        class_id = f['properties']['class_id']
        new_geoms = []
        for g in geoms:
            if g.geom_type == 'LineString':
                line_buf = 1
                if line_bufs is not None:
                    line_buf = line_bufs.get(class_id, 1)
                # If line_buf for the class_id was explicitly set as None, then
                # don't buffer.
                if line_buf is not None:
                    g = g.buffer(line_buf)
                new_geoms.append(g)
            elif g.geom_type == 'Point':
                point_buf = 1
                if point_bufs is not None:
                    point_buf = point_bufs.get(class_id, 1)
                # If point_buf for the class_id was explicitly set as None, then
                # don't buffer.
                if point_buf is not None:
                    g = g.buffer(point_buf)
                new_geoms.append(g)
            else:
                # Use buffer trick to handle self-intersecting polygons. Buffer returns
                # a MultiPolygon if there is a bowtie, so we have to convert it to a
                # list of Polygons.
                poly_buf = g.buffer(0)
                if poly_buf.geom_type == 'MultiPolygon':
                    new_geoms.extend(list(poly_buf))
                else:
                    new_geoms.append(poly_buf)
        geoms = new_geoms

        # Convert back to map coords if desired. This is here so the QGIS plugin can
        # take the GeoJSON produced by a VectorSource and display it on a map.
        if to_map_coords:

            def p2m(x, y, z=None):
                return crs_transformer.pixel_to_map((x, y))

            geoms = [shapely.ops.transform(p2m, g) for g in geoms]

        for g in geoms:
            new_f = {
                'type': 'Feature',
                'geometry': mapping(g),
                'properties': f['properties']
            }
            # Have to check for empty features again which could have been introduced
            # when splitting apart multi-geoms.
            if not is_empty_feat(new_f):
                new_features.append(new_f)

    return {'type': 'FeatureCollection', 'features': new_features}


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/vector_source/vector_source.py" startline="16" endline="113" pcid="1733">
def transform_geojson(geojson,
                      crs_transformer,
                      line_bufs=None,
                      point_bufs=None,
                      to_map_coords=False):
    def is_empty_feat(f):
        # This was added to handle empty geoms which appear when using
        # OSM vector tiles.
        return ((not f.get('geometry'))
                or ((not f['geometry'].get('coordinates')) and
                    (not f['geometry'].get('geometries'))))

    new_features = []
    for f in geojson['features']:
        if is_empty_feat(f):
            continue

        geom = shape(f['geometry'])

        # Convert map to pixel coords. We need to convert to pixel coords before applying
        # buffering because those values are assumed to be in pixel units.
        def m2p(x, y, z=None):
            return crs_transformer.map_to_pixel((x, y))

        geom = transform(m2p, geom)

        # Split GeometryCollection into list of geoms.
        geoms = [geom]
        if geom.geom_type == 'GeometryCollection':
            geoms = list(geom)

        # Split any MultiX to list of X.
        new_geoms = []
        for g in geoms:
            if g.geom_type in [
                    'MultiPolygon', 'MultiPoint', 'MultiLineString'
            ]:
                new_geoms.extend(list(g))
            else:
                new_geoms.append(g)
        geoms = new_geoms

        # Buffer geoms.
        class_id = f['properties']['class_id']
        new_geoms = []
        for g in geoms:
            if g.geom_type == 'LineString':
                line_buf = 1
                if line_bufs is not None:
                    line_buf = line_bufs.get(class_id, 1)
                # If line_buf for the class_id was explicitly set as None, then
                # don't buffer.
                if line_buf is not None:
                    g = g.buffer(line_buf)
                new_geoms.append(g)
            elif g.geom_type == 'Point':
                point_buf = 1
                if point_bufs is not None:
                    point_buf = point_bufs.get(class_id, 1)
                # If point_buf for the class_id was explicitly set as None, then
                # don't buffer.
                if point_buf is not None:
                    g = g.buffer(point_buf)
                new_geoms.append(g)
            else:
                # Use buffer trick to handle self-intersecting polygons. Buffer returns
                # a MultiPolygon if there is a bowtie, so we have to convert it to a
                # list of Polygons.
                poly_buf = g.buffer(0)
                if poly_buf.geom_type == 'MultiPolygon':
                    new_geoms.extend(list(poly_buf))
                else:
                    new_geoms.append(poly_buf)
        geoms = new_geoms

        # Convert back to map coords if desired. This is here so the QGIS plugin can
        # take the GeoJSON produced by a VectorSource and display it on a map.
        if to_map_coords:

            def p2m(x, y, z=None):
                return crs_transformer.pixel_to_map((x, y))

            geoms = [transform(p2m, g) for g in geoms]

        for g in geoms:
            new_f = {
                'type': 'Feature',
                'geometry': mapping(g),
                'properties': f['properties']
            }
            # Have to check for empty features again which could have been introduced
            # when splitting apart multi-geoms.
            if not is_empty_feat(new_f):
                new_features.append(new_f)

    return {'type': 'FeatureCollection', 'features': new_features}


</source>
</class>

<class classid="49" nclones="2" nlines="10" similarity="80">
<source file="systems/raster-vision-0.11.0/rastervision/data/vector_source/vector_source.py" startline="139" endline="163" pcid="768">
    def get_geojson(self, to_map_coords=False):
        """Return normalized GeoJSON.

        This infers a class_id property for each feature, converts to pixels coords (by
        default), removes empty features, splits apart multi-geoms and geom collections
        into single geometries, and buffers lines and points into Polygons.

        Args:
            to_map_coords: If true, will return GeoJSON in map coordinates.

        Returns:
            dict in GeoJSON format
        """
        if self.geojson is None:
            self.geojson = self._get_geojson()

        geojson = transform_geojson(
            self.geojson,
            self.crs_transformer,
            self.line_bufs,
            self.point_bufs,
            to_map_coords=to_map_coords)

        return geojson

</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/vector_source/vector_source.py" startline="129" endline="153" pcid="1738">
    def get_geojson(self, to_map_coords=False):
        """Return normalized GeoJSON.

        This infers a class_id property for each feature, converts to pixels coords (by
        default), removes empty features, splits apart multi-geoms and geom collections
        into single geometries, and buffers lines and points into Polygons.

        Args:
            to_map_coords: If true, will return GeoJSON in map coordinates.

        Returns:
            dict in GeoJSON format
        """
        if self.geojson is None:
            self.geojson = self._get_geojson()

        geojson = transform_geojson(
            self.geojson,
            self.crs_transformer,
            self.vs_config.line_bufs,
            self.vs_config.point_bufs,
            to_map_coords=to_map_coords)

        return geojson

</source>
</class>

<class classid="50" nclones="2" nlines="23" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/data/vector_source/label_maker/filter.py" startline="38" endline="63" pcid="793">
def _compile(filt):
    """Return a string represented the compiled filter function"""
    if not filt:
        return 'True'
    op = filt[0]
    if len(filt) == 1:
        return 'False' if op == 'any' else 'True'
    if op in ['==', '!=', '<', '>', '<=', '>=']:
        return _compile_comparison_op(filt[1], filt[2], op)
    elif op == 'any':
        return _compile_logical_op(filt[1:], ' or ')
    elif op == 'all':
        return _compile_logical_op(filt[1:], ' and ')
    elif op == 'none':
        return _compile_negation(_compile_logical_op(filt[1:], ' or '))
    elif op == 'in':
        return _compile_in_op(filt[1], filt[2:])
    elif op == '!in':
        return _compile_negation(_compile_in_op(filt[1], filt[2:]))
    elif op == 'has':
        return _compile_has_op(filt[1])
    elif op == '!has':
        return _compile_negation(_compile_has_op(filt[1]))
    return 'True'


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/vector_source/label_maker/filter.py" startline="38" endline="63" pcid="1744">
def _compile(filt):
    """Return a string represented the compiled filter function"""
    if not filt:
        return 'True'
    op = filt[0]
    if len(filt) == 1:
        return 'False' if op == 'any' else 'True'
    if op in ['==', '!=', '<', '>', '<=', '>=']:
        return _compile_comparison_op(filt[1], filt[2], op)
    elif op == 'any':
        return _compile_logical_op(filt[1:], ' or ')
    elif op == 'all':
        return _compile_logical_op(filt[1:], ' and ')
    elif op == 'none':
        return _compile_negation(_compile_logical_op(filt[1:], ' or '))
    elif op == 'in':
        return _compile_in_op(filt[1], filt[2:])
    elif op == '!in':
        return _compile_negation(_compile_in_op(filt[1], filt[2:]))
    elif op == 'has':
        return _compile_has_op(filt[1])
    elif op == '!has':
        return _compile_negation(_compile_has_op(filt[1]))
    return 'True'


</source>
</class>

<class classid="51" nclones="2" nlines="10" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/data/label/chip_classification_labels.py" startline="24" endline="34" pcid="826">
    def filter_by_aoi(self, aoi_polygons):
        result = ChipClassificationLabels()
        for cell in self.cell_to_class_id:
            cell_box = Box.from_tuple(cell)
            cell_poly = cell_box.to_shapely()
            for aoi in aoi_polygons:
                if cell_poly.within(aoi):
                    (class_id, scores) = self.cell_to_class_id[cell]
                    result.set_cell(cell_box, class_id, scores)
        return result

</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/label/chip_classification_labels.py" startline="24" endline="34" pcid="1756">
    def filter_by_aoi(self, aoi_polygons):
        result = ChipClassificationLabels()
        for cell in self.cell_to_class_id:
            cell_box = Box.from_tuple(cell)
            cell_poly = cell_box.to_shapely()
            for aoi in aoi_polygons:
                if cell_poly.within(aoi):
                    (class_id, scores) = self.cell_to_class_id[cell]
                    result.set_cell(cell_box, class_id, scores)
        return result

</source>
</class>

<class classid="52" nclones="2" nlines="19" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/data/label/object_detection_labels.py" startline="53" endline="75" pcid="841">
    def filter_by_aoi(self, aoi_polygons):
        boxes = self.get_boxes()
        class_ids = self.get_class_ids()
        scores = self.get_scores()

        new_boxes = []
        new_class_ids = []
        new_scores = []
        for box, class_id, score in zip(boxes, class_ids, scores):
            box_poly = box.to_shapely()
            for aoi in aoi_polygons:
                if box_poly.within(aoi):
                    new_boxes.append(box.npbox_format())
                    new_class_ids.append(class_id)
                    new_scores.append(score)
                    break

        if len(new_boxes) == 0:
            return ObjectDetectionLabels.make_empty()

        return ObjectDetectionLabels(
            np.array(new_boxes), np.array(new_class_ids), np.array(new_scores))

</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/label/object_detection_labels.py" startline="53" endline="75" pcid="1771">
    def filter_by_aoi(self, aoi_polygons):
        boxes = self.get_boxes()
        class_ids = self.get_class_ids()
        scores = self.get_scores()

        new_boxes = []
        new_class_ids = []
        new_scores = []
        for box, class_id, score in zip(boxes, class_ids, scores):
            box_poly = box.to_shapely()
            for aoi in aoi_polygons:
                if box_poly.within(aoi):
                    new_boxes.append(box.npbox_format())
                    new_class_ids.append(class_id)
                    new_scores.append(score)
                    break

        if len(new_boxes) == 0:
            return ObjectDetectionLabels.make_empty()

        return ObjectDetectionLabels(
            np.array(new_boxes), np.array(new_class_ids), np.array(new_scores))

</source>
</class>

<class classid="53" nclones="2" nlines="23" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/data/label/object_detection_labels.py" startline="92" endline="131" pcid="844">
    def from_geojson(geojson, extent=None):
        """Convert GeoJSON to ObjectDetectionLabels object.

        If extent is provided, filter out the boxes that lie "more than a little
        bit" outside the extent.

        Args:
            geojson: (dict) normalized GeoJSON (see VectorSource)
            extent: (Box) in pixel coords

        Returns:
            ObjectDetectionLabels
        """
        boxes = []
        class_ids = []
        scores = []

        for f in geojson['features']:
            geom = shape(f['geometry'])
            (xmin, ymin, xmax, ymax) = geom.bounds
            boxes.append(Box(ymin, xmin, ymax, xmax))

            props = f['properties']
            class_ids.append(props['class_id'])
            scores.append(props.get('score', 1.0))

        if len(boxes):
            boxes = np.array(
                [box.npbox_format() for box in boxes], dtype=float)
            class_ids = np.array(class_ids)
            scores = np.array(scores)
            labels = ObjectDetectionLabels(boxes, class_ids, scores=scores)
        else:
            labels = ObjectDetectionLabels.make_empty()

        if extent is not None:
            labels = ObjectDetectionLabels.get_overlapping(
                labels, extent, ioa_thresh=0.8, clip=True)
        return labels

</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/label/object_detection_labels.py" startline="92" endline="131" pcid="1774">
    def from_geojson(geojson, extent=None):
        """Convert GeoJSON to ObjectDetectionLabels object.

        If extent is provided, filter out the boxes that lie "more than a little
        bit" outside the extent.

        Args:
            geojson: (dict) normalized GeoJSON (see VectorSource)
            extent: (Box) in pixel coords

        Returns:
            ObjectDetectionLabels
        """
        boxes = []
        class_ids = []
        scores = []

        for f in geojson['features']:
            geom = shape(f['geometry'])
            (xmin, ymin, xmax, ymax) = geom.bounds
            boxes.append(Box(ymin, xmin, ymax, xmax))

            props = f['properties']
            class_ids.append(props['class_id'])
            scores.append(props.get('score', 1.0))

        if len(boxes):
            boxes = np.array(
                [box.npbox_format() for box in boxes], dtype=float)
            class_ids = np.array(class_ids)
            scores = np.array(scores)
            labels = ObjectDetectionLabels(boxes, class_ids, scores=scores)
        else:
            labels = ObjectDetectionLabels.make_empty()

        if extent is not None:
            labels = ObjectDetectionLabels.get_overlapping(
                labels, extent, ioa_thresh=0.8, clip=True)
        return labels

</source>
</class>

<class classid="54" nclones="2" nlines="11" similarity="81">
<source file="systems/raster-vision-0.11.0/rastervision/data/label/tfod_utils/np_box_list.py" startline="31" endline="49" pcid="860">
  def __init__(self, data):
    """Constructs box collection.
    Args:
      data: a numpy array of shape [N, 4] representing box coordinates
    Raises:
      ValueError: if bbox data is not a numpy array
      ValueError: if invalid dimensions for bbox data
    """
    if not isinstance(data, np.ndarray):
      raise ValueError('data must be a numpy array.')
    if len(data.shape) != 2 or data.shape[1] != 4:
      raise ValueError('Invalid dimensions for box data.')
    if data.dtype != np.float32 and data.dtype != np.float64:
      raise ValueError('Invalid data type for box data: float is required.')
    if not self._is_valid_boxes(data):
      raise ValueError('Invalid box data. data must be a numpy array of '
                       'N*[y_min, x_min, y_max, x_max]')
    self.data = {'boxes': data}

</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/label/tfod_utils/np_box_list.py" startline="30" endline="49" pcid="1790">
    def __init__(self, data):
        """Constructs box collection.
    Args:
      data: a numpy array of shape [N, 4] representing box coordinates
    Raises:
      ValueError: if bbox data is not a numpy array
      ValueError: if invalid dimensions for bbox data
    """
        if not isinstance(data, np.ndarray):
            raise ValueError('data must be a numpy array.')
        if len(data.shape) != 2 or data.shape[1] != 4:
            raise ValueError('Invalid dimensions for box data.')
        if data.dtype != np.float32 and data.dtype != np.float64:
            raise ValueError(
                'Invalid data type for box data: float is required.')
        if not self._is_valid_boxes(data):
            raise ValueError('Invalid box data. data must be a numpy array of '
                             'N*[y_min, x_min, y_max, x_max]')
        self.data = {'boxes': data}

</source>
</class>

<class classid="55" nclones="2" nlines="11" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/data/label/tfod_utils/np_box_list_ops.py" startline="84" endline="114" pcid="873">
def gather(boxlist, indices, fields=None):
  """Gather boxes from BoxList according to indices and return new BoxList.
  By default, gather returns boxes corresponding to the input index list, as
  well as all additional fields stored in the boxlist (indexing into the
  first dimension).  However one can optionally only gather from a
  subset of fields.
  Args:
    boxlist: BoxList holding N boxes
    indices: a 1-d numpy array of type int_
    fields: (optional) list of fields to also gather from.  If None (default),
        all fields are gathered from.  Pass an empty fields list to only gather
        the box coordinates.
  Returns:
    subboxlist: a BoxList corresponding to the subset of the input BoxList
        specified by indices
  Raises:
    ValueError: if specified field is not contained in boxlist or if the
        indices are not of type int_
  """
  if indices.size:
    if np.amax(indices) >= boxlist.num_boxes() or np.amin(indices) < 0:
      raise ValueError('indices are out of valid range.')
  subboxlist = np_box_list.BoxList(boxlist.get()[indices, :])
  if fields is None:
    fields = boxlist.get_extra_fields()
  for field in fields:
    extra_field_data = boxlist.get_field(field)
    subboxlist.add_field(field, extra_field_data[indices, ...])
  return subboxlist


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/label/tfod_utils/np_box_list_ops.py" startline="83" endline="113" pcid="1803">
def gather(boxlist, indices, fields=None):
    """Gather boxes from BoxList according to indices and return new BoxList.
  By default, gather returns boxes corresponding to the input index list, as
  well as all additional fields stored in the boxlist (indexing into the
  first dimension).  However one can optionally only gather from a
  subset of fields.
  Args:
    boxlist: BoxList holding N boxes
    indices: a 1-d numpy array of type int_
    fields: (optional) list of fields to also gather from.  If None (default),
        all fields are gathered from.  Pass an empty fields list to only gather
        the box coordinates.
  Returns:
    subboxlist: a BoxList corresponding to the subset of the input BoxList
        specified by indices
  Raises:
    ValueError: if specified field is not contained in boxlist or if the
        indices are not of type int_
  """
    if indices.size:
        if np.amax(indices) >= boxlist.num_boxes() or np.amin(indices) < 0:
            raise ValueError('indices are out of valid range.')
    subboxlist = np_box_list.BoxList(boxlist.get()[indices, :])
    if fields is None:
        fields = boxlist.get_extra_fields()
    for field in fields:
        extra_field_data = boxlist.get_field(field)
        subboxlist.add_field(field, extra_field_data[indices, ...])
    return subboxlist


</source>
</class>

<class classid="56" nclones="2" nlines="12" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/data/label/tfod_utils/np_box_list_ops.py" startline="115" endline="141" pcid="874">
def sort_by_field(boxlist, field, order=SortOrder.DESCEND):
  """Sort boxes and associated fields according to a scalar field.
  A common use case is reordering the boxes according to descending scores.
  Args:
    boxlist: BoxList holding N boxes.
    field: A BoxList field for sorting and reordering the BoxList.
    order: (Optional) 'descend' or 'ascend'. Default is descend.
  Returns:
    sorted_boxlist: A sorted BoxList with the field in the specified order.
  Raises:
    ValueError: if specified field does not exist or is not of single dimension.
    ValueError: if the order is not either descend or ascend.
  """
  if not boxlist.has_field(field):
    raise ValueError('Field ' + field + ' does not exist')
  if len(boxlist.get_field(field).shape) != 1:
    raise ValueError('Field ' + field + 'should be single dimension.')
  if order != SortOrder.DESCEND and order != SortOrder.ASCEND:
    raise ValueError('Invalid sort order')

  field_to_sort = boxlist.get_field(field)
  sorted_indices = np.argsort(field_to_sort)
  if order == SortOrder.DESCEND:
    sorted_indices = sorted_indices[::-1]
  return gather(boxlist, sorted_indices)


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/label/tfod_utils/np_box_list_ops.py" startline="114" endline="140" pcid="1804">
def sort_by_field(boxlist, field, order=SortOrder.DESCEND):
    """Sort boxes and associated fields according to a scalar field.
  A common use case is reordering the boxes according to descending scores.
  Args:
    boxlist: BoxList holding N boxes.
    field: A BoxList field for sorting and reordering the BoxList.
    order: (Optional) 'descend' or 'ascend'. Default is descend.
  Returns:
    sorted_boxlist: A sorted BoxList with the field in the specified order.
  Raises:
    ValueError: if specified field does not exist or is not of single dimension.
    ValueError: if the order is not either descend or ascend.
  """
    if not boxlist.has_field(field):
        raise ValueError('Field ' + field + ' does not exist')
    if len(boxlist.get_field(field).shape) != 1:
        raise ValueError('Field ' + field + 'should be single dimension.')
    if order != SortOrder.DESCEND and order != SortOrder.ASCEND:
        raise ValueError('Invalid sort order')

    field_to_sort = boxlist.get_field(field)
    sorted_indices = np.argsort(field_to_sort)
    if order == SortOrder.DESCEND:
        sorted_indices = sorted_indices[::-1]
    return gather(boxlist, sorted_indices)


</source>
</class>

<class classid="57" nclones="2" nlines="42" similarity="95">
<source file="systems/raster-vision-0.11.0/rastervision/data/label/tfod_utils/np_box_list_ops.py" startline="142" endline="212" pcid="875">
def non_max_suppression(boxlist,
                        max_output_size=10000,
                        iou_threshold=1.0,
                        score_threshold=-10.0):
  """Non maximum suppression.
  This op greedily selects a subset of detection bounding boxes, pruning
  away boxes that have high IOU (intersection over union) overlap (> thresh)
  with already selected boxes. In each iteration, the detected bounding box with
  highest score in the available pool is selected.
  Args:
    boxlist: BoxList holding N boxes.  Must contain a 'scores' field
      representing detection scores. All scores belong to the same class.
    max_output_size: maximum number of retained boxes
    iou_threshold: intersection over union threshold.
    score_threshold: minimum score threshold. Remove the boxes with scores
                     less than this value. Default value is set to -10. A very
                     low threshold to pass pretty much all the boxes, unless
                     the user sets a different score threshold.
  Returns:
    a BoxList holding M boxes where M <= max_output_size
  Raises:
    ValueError: if 'scores' field does not exist
    ValueError: if threshold is not in [0, 1]
    ValueError: if max_output_size < 0
  """
  if not boxlist.has_field('scores'):
    raise ValueError('Field scores does not exist')
  if iou_threshold < 0. or iou_threshold > 1.0:
    raise ValueError('IOU threshold must be in [0, 1]')
  if max_output_size < 0:
    raise ValueError('max_output_size must be bigger than 0.')

  boxlist = filter_scores_greater_than(boxlist, score_threshold)
  if boxlist.num_boxes() == 0:
    return boxlist

  boxlist = sort_by_field(boxlist, 'scores')

  # Prevent further computation if NMS is disabled.
  if iou_threshold == 1.0:
    if boxlist.num_boxes() > max_output_size:
      selected_indices = np.arange(max_output_size)
      return gather(boxlist, selected_indices)
    else:
      return boxlist

  boxes = boxlist.get()
  num_boxes = boxlist.num_boxes()
  # is_index_valid is True only for all remaining valid boxes,
  is_index_valid = np.full(num_boxes, 1, dtype=bool)
  selected_indices = []
  num_output = 0
  for i in range(num_boxes):
    if num_output < max_output_size:
      if is_index_valid[i]:
        num_output += 1
        selected_indices.append(i)
        is_index_valid[i] = False
        valid_indices = np.where(is_index_valid)[0]
        if valid_indices.size == 0:
          break

        intersect_over_union = np_box_ops.iou(
            np.expand_dims(boxes[i, :], axis=0), boxes[valid_indices, :])
        intersect_over_union = np.squeeze(intersect_over_union, axis=0)
        is_index_valid[valid_indices] = np.logical_and(
            is_index_valid[valid_indices],
            intersect_over_union <= iou_threshold)
  return gather(boxlist, np.array(selected_indices))


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/label/tfod_utils/np_box_list_ops.py" startline="141" endline="212" pcid="1805">
def non_max_suppression(boxlist,
                        max_output_size=10000,
                        iou_threshold=1.0,
                        score_threshold=-10.0):
    """Non maximum suppression.
  This op greedily selects a subset of detection bounding boxes, pruning
  away boxes that have high IOU (intersection over union) overlap (> thresh)
  with already selected boxes. In each iteration, the detected bounding box with
  highest score in the available pool is selected.
  Args:
    boxlist: BoxList holding N boxes.  Must contain a 'scores' field
      representing detection scores. All scores belong to the same class.
    max_output_size: maximum number of retained boxes
    iou_threshold: intersection over union threshold.
    score_threshold: minimum score threshold. Remove the boxes with scores
                     less than this value. Default value is set to -10. A very
                     low threshold to pass pretty much all the boxes, unless
                     the user sets a different score threshold.
  Returns:
    a BoxList holding M boxes where M <= max_output_size
  Raises:
    ValueError: if 'scores' field does not exist
    ValueError: if threshold is not in [0, 1]
    ValueError: if max_output_size < 0
  """
    if not boxlist.has_field('scores'):
        raise ValueError('Field scores does not exist')
    if iou_threshold < 0. or iou_threshold > 1.0:
        raise ValueError('IOU threshold must be in [0, 1]')
    if max_output_size < 0:
        raise ValueError('max_output_size must be bigger than 0.')

    boxlist = filter_scores_greater_than(boxlist, score_threshold)
    if boxlist.num_boxes() == 0:
        return boxlist

    boxlist = sort_by_field(boxlist, 'scores')

    # Prevent further computation if NMS is disabled.
    if iou_threshold == 1.0:
        if boxlist.num_boxes() > max_output_size:
            selected_indices = np.arange(max_output_size)
            return gather(boxlist, selected_indices)
        else:
            return boxlist

    boxes = boxlist.get()
    num_boxes = boxlist.num_boxes()
    # is_index_valid is True only for all remaining valid boxes,
    is_index_valid = np.full(num_boxes, 1, dtype=bool)
    selected_indices = []
    num_output = 0
    for i in range(num_boxes):
        if num_output < max_output_size:
            if is_index_valid[i]:
                num_output += 1
                selected_indices.append(i)
                is_index_valid[i] = False
                valid_indices = np.where(is_index_valid)[0]
                if valid_indices.size == 0:
                    break

                intersect_over_union = np_box_ops.iou(
                    np.expand_dims(boxes[i, :], axis=0),
                    boxes[valid_indices, :])
                intersect_over_union = np.squeeze(intersect_over_union, axis=0)
                is_index_valid[valid_indices] = np.logical_and(
                    is_index_valid[valid_indices],
                    intersect_over_union <= iou_threshold)
    return gather(boxlist, np.array(selected_indices))


</source>
</class>

<class classid="58" nclones="2" nlines="40" similarity="85">
<source file="systems/raster-vision-0.11.0/rastervision/data/label/tfod_utils/np_box_list_ops.py" startline="213" endline="282" pcid="876">
def multi_class_non_max_suppression(boxlist, score_thresh, iou_thresh,
                                    max_output_size):
  """Multi-class version of non maximum suppression.
  This op greedily selects a subset of detection bounding boxes, pruning
  away boxes that have high IOU (intersection over union) overlap (> thresh)
  with already selected boxes.  It operates independently for each class for
  which scores are provided (via the scores field of the input box_list),
  pruning boxes with score less than a provided threshold prior to
  applying NMS.
  Args:
    boxlist: BoxList holding N boxes.  Must contain a 'scores' field
      representing detection scores.  This scores field is a tensor that can
      be 1 dimensional (in the case of a single class) or 2-dimensional, which
      which case we assume that it takes the shape [num_boxes, num_classes].
      We further assume that this rank is known statically and that
      scores.shape[1] is also known (i.e., the number of classes is fixed
      and known at graph construction time).
    score_thresh: scalar threshold for score (low scoring boxes are removed).
    iou_thresh: scalar threshold for IOU (boxes that that high IOU overlap
      with previously selected boxes are removed).
    max_output_size: maximum number of retained boxes per class.
  Returns:
    a BoxList holding M boxes with a rank-1 scores field representing
      corresponding scores for each box with scores sorted in decreasing order
      and a rank-1 classes field representing a class label for each box.
  Raises:
    ValueError: if iou_thresh is not in [0, 1] or if input boxlist does not have
      a valid scores field.
  """
  if not 0 <= iou_thresh <= 1.0:
    raise ValueError('thresh must be between 0 and 1')
  if not isinstance(boxlist, np_box_list.BoxList):
    raise ValueError('boxlist must be a BoxList')
  if not boxlist.has_field('scores'):
    raise ValueError('input boxlist must have \'scores\' field')
  scores = boxlist.get_field('scores')
  if len(scores.shape) == 1:
    scores = np.reshape(scores, [-1, 1])
  elif len(scores.shape) == 2:
    if scores.shape[1] is None:
      raise ValueError('scores field must have statically defined second '
                       'dimension')
  else:
    raise ValueError('scores field must be of rank 1 or 2')
  num_boxes = boxlist.num_boxes()
  num_scores = scores.shape[0]
  num_classes = scores.shape[1]

  if num_boxes != num_scores:
    raise ValueError('Incorrect scores field length: actual vs expected.')

  selected_boxes_list = []
  for class_idx in range(num_classes):
    boxlist_and_class_scores = np_box_list.BoxList(boxlist.get())
    class_scores = np.reshape(scores[0:num_scores, class_idx], [-1])
    boxlist_and_class_scores.add_field('scores', class_scores)
    boxlist_filt = filter_scores_greater_than(boxlist_and_class_scores,
                                              score_thresh)
    nms_result = non_max_suppression(boxlist_filt,
                                     max_output_size=max_output_size,
                                     iou_threshold=iou_thresh,
                                     score_threshold=score_thresh)
    nms_result.add_field(
        'classes', np.zeros_like(nms_result.get_field('scores')) + class_idx)
    selected_boxes_list.append(nms_result)
  selected_boxes = concatenate(selected_boxes_list)
  sorted_boxes = sort_by_field(selected_boxes, 'scores')
  return sorted_boxes


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/label/tfod_utils/np_box_list_ops.py" startline="213" endline="285" pcid="1806">
def multi_class_non_max_suppression(boxlist, score_thresh, iou_thresh,
                                    max_output_size):
    """Multi-class version of non maximum suppression.
  This op greedily selects a subset of detection bounding boxes, pruning
  away boxes that have high IOU (intersection over union) overlap (> thresh)
  with already selected boxes.  It operates independently for each class for
  which scores are provided (via the scores field of the input box_list),
  pruning boxes with score less than a provided threshold prior to
  applying NMS.
  Args:
    boxlist: BoxList holding N boxes.  Must contain a 'scores' field
      representing detection scores.  This scores field is a tensor that can
      be 1 dimensional (in the case of a single class) or 2-dimensional, which
      which case we assume that it takes the shape [num_boxes, num_classes].
      We further assume that this rank is known statically and that
      scores.shape[1] is also known (i.e., the number of classes is fixed
      and known at graph construction time).
    score_thresh: scalar threshold for score (low scoring boxes are removed).
    iou_thresh: scalar threshold for IOU (boxes that that high IOU overlap
      with previously selected boxes are removed).
    max_output_size: maximum number of retained boxes per class.
  Returns:
    a BoxList holding M boxes with a rank-1 scores field representing
      corresponding scores for each box with scores sorted in decreasing order
      and a rank-1 classes field representing a class label for each box.
  Raises:
    ValueError: if iou_thresh is not in [0, 1] or if input boxlist does not have
      a valid scores field.
  """
    if not 0 <= iou_thresh <= 1.0:
        raise ValueError('thresh must be between 0 and 1')
    if not isinstance(boxlist, np_box_list.BoxList):
        raise ValueError('boxlist must be a BoxList')
    if not boxlist.has_field('scores'):
        raise ValueError('input boxlist must have \'scores\' field')
    scores = boxlist.get_field('scores')
    if len(scores.shape) == 1:
        scores = np.reshape(scores, [-1, 1])
    elif len(scores.shape) == 2:
        if scores.shape[1] is None:
            raise ValueError(
                'scores field must have statically defined second '
                'dimension')
    else:
        raise ValueError('scores field must be of rank 1 or 2')
    num_boxes = boxlist.num_boxes()
    num_scores = scores.shape[0]
    num_classes = scores.shape[1]

    if num_boxes != num_scores:
        raise ValueError('Incorrect scores field length: actual vs expected.')

    selected_boxes_list = []
    for class_idx in range(num_classes):
        boxlist_and_class_scores = np_box_list.BoxList(boxlist.get())
        class_scores = np.reshape(scores[0:num_scores, class_idx], [-1])
        boxlist_and_class_scores.add_field('scores', class_scores)
        boxlist_filt = filter_scores_greater_than(boxlist_and_class_scores,
                                                  score_thresh)
        nms_result = non_max_suppression(
            boxlist_filt,
            max_output_size=max_output_size,
            iou_threshold=iou_thresh,
            score_threshold=score_thresh)
        nms_result.add_field(
            'classes',
            np.zeros_like(nms_result.get_field('scores')) + class_idx)
        selected_boxes_list.append(nms_result)
    selected_boxes = concatenate(selected_boxes_list)
    sorted_boxes = sort_by_field(selected_boxes, 'scores')
    return sorted_boxes


</source>
</class>

<class classid="59" nclones="2" nlines="13" similarity="84">
<source file="systems/raster-vision-0.11.0/rastervision/data/label/tfod_utils/np_box_list_ops.py" startline="283" endline="306" pcid="877">
def scale(boxlist, y_scale, x_scale):
  """Scale box coordinates in x and y dimensions.
  Args:
    boxlist: BoxList holding N boxes
    y_scale: float
    x_scale: float
  Returns:
    boxlist: BoxList holding N boxes
  """
  y_min, x_min, y_max, x_max = np.array_split(boxlist.get(), 4, axis=1)
  y_min = y_scale * y_min
  y_max = y_scale * y_max
  x_min = x_scale * x_min
  x_max = x_scale * x_max
  scaled_boxlist = np_box_list.BoxList(np.hstack([y_min, x_min, y_max, x_max]))

  fields = boxlist.get_extra_fields()
  for field in fields:
    extra_field_data = boxlist.get_field(field)
    scaled_boxlist.add_field(field, extra_field_data)

  return scaled_boxlist


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/label/tfod_utils/np_box_list_ops.py" startline="286" endline="310" pcid="1807">
def scale(boxlist, y_scale, x_scale):
    """Scale box coordinates in x and y dimensions.
  Args:
    boxlist: BoxList holding N boxes
    y_scale: float
    x_scale: float
  Returns:
    boxlist: BoxList holding N boxes
  """
    y_min, x_min, y_max, x_max = np.array_split(boxlist.get(), 4, axis=1)
    y_min = y_scale * y_min
    y_max = y_scale * y_max
    x_min = x_scale * x_min
    x_max = x_scale * x_max
    scaled_boxlist = np_box_list.BoxList(
        np.hstack([y_min, x_min, y_max, x_max]))

    fields = boxlist.get_extra_fields()
    for field in fields:
        extra_field_data = boxlist.get_field(field)
        scaled_boxlist.add_field(field, extra_field_data)

    return scaled_boxlist


</source>
</class>

<class classid="60" nclones="2" nlines="18" similarity="77">
<source file="systems/raster-vision-0.11.0/rastervision/data/label/tfod_utils/np_box_list_ops.py" startline="307" endline="337" pcid="878">
def clip_to_window(boxlist, window):
  """Clip bounding boxes to a window.
  This op clips input bounding boxes (represented by bounding box
  corners) to a window, optionally filtering out boxes that do not
  overlap at all with the window.
  Args:
    boxlist: BoxList holding M_in boxes
    window: a numpy array of shape [4] representing the
            [y_min, x_min, y_max, x_max] window to which the op
            should clip boxes.
  Returns:
    a BoxList holding M_out boxes where M_out <= M_in
  """
  y_min, x_min, y_max, x_max = np.array_split(boxlist.get(), 4, axis=1)
  win_y_min = window[0]
  win_x_min = window[1]
  win_y_max = window[2]
  win_x_max = window[3]
  y_min_clipped = np.fmax(np.fmin(y_min, win_y_max), win_y_min)
  y_max_clipped = np.fmax(np.fmin(y_max, win_y_max), win_y_min)
  x_min_clipped = np.fmax(np.fmin(x_min, win_x_max), win_x_min)
  x_max_clipped = np.fmax(np.fmin(x_max, win_x_max), win_x_min)
  clipped = np_box_list.BoxList(
      np.hstack([y_min_clipped, x_min_clipped, y_max_clipped, x_max_clipped]))
  clipped = _copy_extra_fields(clipped, boxlist)
  areas = area(clipped)
  nonzero_area_indices = np.reshape(np.nonzero(np.greater(areas, 0.0)),
                                    [-1]).astype(np.int32)
  return gather(clipped, nonzero_area_indices)


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/label/tfod_utils/np_box_list_ops.py" startline="311" endline="342" pcid="1808">
def clip_to_window(boxlist, window):
    """Clip bounding boxes to a window.
  This op clips input bounding boxes (represented by bounding box
  corners) to a window, optionally filtering out boxes that do not
  overlap at all with the window.
  Args:
    boxlist: BoxList holding M_in boxes
    window: a numpy array of shape [4] representing the
            [y_min, x_min, y_max, x_max] window to which the op
            should clip boxes.
  Returns:
    a BoxList holding M_out boxes where M_out <= M_in
  """
    y_min, x_min, y_max, x_max = np.array_split(boxlist.get(), 4, axis=1)
    win_y_min = window[0]
    win_x_min = window[1]
    win_y_max = window[2]
    win_x_max = window[3]
    y_min_clipped = np.fmax(np.fmin(y_min, win_y_max), win_y_min)
    y_max_clipped = np.fmax(np.fmin(y_max, win_y_max), win_y_min)
    x_min_clipped = np.fmax(np.fmin(x_min, win_x_max), win_x_min)
    x_max_clipped = np.fmax(np.fmin(x_max, win_x_max), win_x_min)
    clipped = np_box_list.BoxList(
        np.hstack([y_min_clipped, x_min_clipped, y_max_clipped,
                   x_max_clipped]))
    clipped = _copy_extra_fields(clipped, boxlist)
    areas = area(clipped)
    nonzero_area_indices = np.reshape(
        np.nonzero(np.greater(areas, 0.0)), [-1]).astype(np.int32)
    return gather(clipped, nonzero_area_indices)


</source>
</class>

<class classid="61" nclones="2" nlines="14" similarity="85">
<source file="systems/raster-vision-0.11.0/rastervision/data/label/tfod_utils/np_box_list_ops.py" startline="358" endline="387" pcid="880">
def prune_outside_window(boxlist, window):
  """Prunes bounding boxes that fall outside a given window.
  This function prunes bounding boxes that even partially fall outside the given
  window. See also ClipToWindow which only prunes bounding boxes that fall
  completely outside the window, and clips any bounding boxes that partially
  overflow.
  Args:
    boxlist: a BoxList holding M_in boxes.
    window: a numpy array of size 4, representing [ymin, xmin, ymax, xmax]
            of the window.
  Returns:
    pruned_corners: a tensor with shape [M_out, 4] where M_out <= M_in.
    valid_indices: a tensor with shape [M_out] indexing the valid bounding boxes
     in the input tensor.
  """

  y_min, x_min, y_max, x_max = np.array_split(boxlist.get(), 4, axis=1)
  win_y_min = window[0]
  win_x_min = window[1]
  win_y_max = window[2]
  win_x_max = window[3]
  coordinate_violations = np.hstack([np.less(y_min, win_y_min),
                                     np.less(x_min, win_x_min),
                                     np.greater(y_max, win_y_max),
                                     np.greater(x_max, win_x_max)])
  valid_indices = np.reshape(
      np.where(np.logical_not(np.max(coordinate_violations, axis=1))), [-1])
  return gather(boxlist, valid_indices), valid_indices


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/label/tfod_utils/np_box_list_ops.py" startline="364" endline="395" pcid="1810">
def prune_outside_window(boxlist, window):
    """Prunes bounding boxes that fall outside a given window.
  This function prunes bounding boxes that even partially fall outside the given
  window. See also ClipToWindow which only prunes bounding boxes that fall
  completely outside the window, and clips any bounding boxes that partially
  overflow.
  Args:
    boxlist: a BoxList holding M_in boxes.
    window: a numpy array of size 4, representing [ymin, xmin, ymax, xmax]
            of the window.
  Returns:
    pruned_corners: a tensor with shape [M_out, 4] where M_out <= M_in.
    valid_indices: a tensor with shape [M_out] indexing the valid bounding boxes
     in the input tensor.
  """

    y_min, x_min, y_max, x_max = np.array_split(boxlist.get(), 4, axis=1)
    win_y_min = window[0]
    win_x_min = window[1]
    win_y_max = window[2]
    win_x_max = window[3]
    coordinate_violations = np.hstack([
        np.less(y_min, win_y_min),
        np.less(x_min, win_x_min),
        np.greater(y_max, win_y_max),
        np.greater(x_max, win_x_max)
    ])
    valid_indices = np.reshape(
        np.where(np.logical_not(np.max(coordinate_violations, axis=1))), [-1])
    return gather(boxlist, valid_indices), valid_indices


</source>
</class>

<class classid="62" nclones="2" nlines="27" similarity="85">
<source file="systems/raster-vision-0.11.0/rastervision/data/label/tfod_utils/np_box_list_ops.py" startline="388" endline="433" pcid="881">
def concatenate(boxlists, fields=None):
  """Concatenate list of BoxLists.
  This op concatenates a list of input BoxLists into a larger BoxList.  It also
  handles concatenation of BoxList fields as long as the field tensor shapes
  are equal except for the first dimension.
  Args:
    boxlists: list of BoxList objects
    fields: optional list of fields to also concatenate.  By default, all
      fields from the first BoxList in the list are included in the
      concatenation.
  Returns:
    a BoxList with number of boxes equal to
      sum([boxlist.num_boxes() for boxlist in BoxList])
  Raises:
    ValueError: if boxlists is invalid (i.e., is not a list, is empty, or
      contains non BoxList objects), or if requested fields are not contained in
      all boxlists
  """
  if not isinstance(boxlists, list):
    raise ValueError('boxlists should be a list')
  if not boxlists:
    raise ValueError('boxlists should have nonzero length')
  for boxlist in boxlists:
    if not isinstance(boxlist, np_box_list.BoxList):
      raise ValueError('all elements of boxlists should be BoxList objects')
  concatenated = np_box_list.BoxList(
      np.vstack([boxlist.get() for boxlist in boxlists]))
  if fields is None:
    fields = boxlists[0].get_extra_fields()
  for field in fields:
    first_field_shape = boxlists[0].get_field(field).shape
    first_field_shape = first_field_shape[1:]
    for boxlist in boxlists:
      if not boxlist.has_field(field):
        raise ValueError('boxlist must contain all requested fields')
      field_shape = boxlist.get_field(field).shape
      field_shape = field_shape[1:]
      if field_shape != first_field_shape:
        raise ValueError('field %s must have same shape for all boxlists '
                         'except for the 0th dimension.' % field)
    concatenated_field = np.concatenate(
        [boxlist.get_field(field) for boxlist in boxlists], axis=0)
    concatenated.add_field(field, concatenated_field)
  return concatenated


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/label/tfod_utils/np_box_list_ops.py" startline="396" endline="443" pcid="1811">
def concatenate(boxlists, fields=None):
    """Concatenate list of BoxLists.
  This op concatenates a list of input BoxLists into a larger BoxList.  It also
  handles concatenation of BoxList fields as long as the field tensor shapes
  are equal except for the first dimension.
  Args:
    boxlists: list of BoxList objects
    fields: optional list of fields to also concatenate.  By default, all
      fields from the first BoxList in the list are included in the
      concatenation.
  Returns:
    a BoxList with number of boxes equal to
      sum([boxlist.num_boxes() for boxlist in BoxList])
  Raises:
    ValueError: if boxlists is invalid (i.e., is not a list, is empty, or
      contains non BoxList objects), or if requested fields are not contained in
      all boxlists
  """
    if not isinstance(boxlists, list):
        raise ValueError('boxlists should be a list')
    if not boxlists:
        raise ValueError('boxlists should have nonzero length')
    for boxlist in boxlists:
        if not isinstance(boxlist, np_box_list.BoxList):
            raise ValueError(
                'all elements of boxlists should be BoxList objects')
    concatenated = np_box_list.BoxList(
        np.vstack([boxlist.get() for boxlist in boxlists]))
    if fields is None:
        fields = boxlists[0].get_extra_fields()
    for field in fields:
        first_field_shape = boxlists[0].get_field(field).shape
        first_field_shape = first_field_shape[1:]
        for boxlist in boxlists:
            if not boxlist.has_field(field):
                raise ValueError('boxlist must contain all requested fields')
            field_shape = boxlist.get_field(field).shape
            field_shape = field_shape[1:]
            if field_shape != first_field_shape:
                raise ValueError(
                    'field %s must have same shape for all boxlists '
                    'except for the 0th dimension.' % field)
        concatenated_field = np.concatenate(
            [boxlist.get_field(field) for boxlist in boxlists], axis=0)
        concatenated.add_field(field, concatenated_field)
    return concatenated


</source>
</class>

<class classid="63" nclones="2" nlines="13" similarity="84">
<source file="systems/raster-vision-0.11.0/rastervision/data/label/tfod_utils/np_box_list_ops.py" startline="434" endline="462" pcid="882">
def filter_scores_greater_than(boxlist, thresh):
  """Filter to keep only boxes with score exceeding a given threshold.
  This op keeps the collection of boxes whose corresponding scores are
  greater than the input threshold.
  Args:
    boxlist: BoxList holding N boxes.  Must contain a 'scores' field
      representing detection scores.
    thresh: scalar threshold
  Returns:
    a BoxList holding M boxes where M <= N
  Raises:
    ValueError: if boxlist not a BoxList object or if it does not
      have a scores field
  """
  if not isinstance(boxlist, np_box_list.BoxList):
    raise ValueError('boxlist must be a BoxList')
  if not boxlist.has_field('scores'):
    raise ValueError('input boxlist must have \'scores\' field')
  scores = boxlist.get_field('scores')
  if len(scores.shape) > 2:
    raise ValueError('Scores should have rank 1 or 2')
  if len(scores.shape) == 2 and scores.shape[1] != 1:
    raise ValueError('Scores should have rank 1 or have shape '
                     'consistent with [None, 1]')
  high_score_indices = np.reshape(np.where(np.greater(scores, thresh)),
                                  [-1]).astype(np.int32)
  return gather(boxlist, high_score_indices)


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/label/tfod_utils/np_box_list_ops.py" startline="444" endline="472" pcid="1812">
def filter_scores_greater_than(boxlist, thresh):
    """Filter to keep only boxes with score exceeding a given threshold.
  This op keeps the collection of boxes whose corresponding scores are
  greater than the input threshold.
  Args:
    boxlist: BoxList holding N boxes.  Must contain a 'scores' field
      representing detection scores.
    thresh: scalar threshold
  Returns:
    a BoxList holding M boxes where M <= N
  Raises:
    ValueError: if boxlist not a BoxList object or if it does not
      have a scores field
  """
    if not isinstance(boxlist, np_box_list.BoxList):
        raise ValueError('boxlist must be a BoxList')
    if not boxlist.has_field('scores'):
        raise ValueError('input boxlist must have \'scores\' field')
    scores = boxlist.get_field('scores')
    if len(scores.shape) > 2:
        raise ValueError('Scores should have rank 1 or 2')
    if len(scores.shape) == 2 and scores.shape[1] != 1:
        raise ValueError('Scores should have rank 1 or have shape '
                         'consistent with [None, 1]')
    high_score_indices = np.reshape(
        np.where(np.greater(scores, thresh)), [-1]).astype(np.int32)
    return gather(boxlist, high_score_indices)


</source>
</class>

<class classid="64" nclones="2" nlines="14" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/data/label/tfod_utils/np_box_ops.py" startline="34" endline="57" pcid="887">
def intersection(boxes1, boxes2):
  """Compute pairwise intersection areas between boxes.
  Args:
    boxes1: a numpy array with shape [N, 4] holding N boxes
    boxes2: a numpy array with shape [M, 4] holding M boxes
  Returns:
    a numpy array with shape [N*M] representing pairwise intersection area
  """
  [y_min1, x_min1, y_max1, x_max1] = np.split(boxes1, 4, axis=1)
  [y_min2, x_min2, y_max2, x_max2] = np.split(boxes2, 4, axis=1)

  all_pairs_min_ymax = np.minimum(y_max1, np.transpose(y_max2))
  all_pairs_max_ymin = np.maximum(y_min1, np.transpose(y_min2))
  intersect_heights = np.maximum(
      np.zeros(all_pairs_max_ymin.shape),
      all_pairs_min_ymax - all_pairs_max_ymin)
  all_pairs_min_xmax = np.minimum(x_max1, np.transpose(x_max2))
  all_pairs_max_xmin = np.maximum(x_min1, np.transpose(x_min2))
  intersect_widths = np.maximum(
      np.zeros(all_pairs_max_xmin.shape),
      all_pairs_min_xmax - all_pairs_max_xmin)
  return intersect_heights * intersect_widths


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/label/tfod_utils/np_box_ops.py" startline="33" endline="56" pcid="1817">
def intersection(boxes1, boxes2):
    """Compute pairwise intersection areas between boxes.
  Args:
    boxes1: a numpy array with shape [N, 4] holding N boxes
    boxes2: a numpy array with shape [M, 4] holding M boxes
  Returns:
    a numpy array with shape [N*M] representing pairwise intersection area
  """
    [y_min1, x_min1, y_max1, x_max1] = np.split(boxes1, 4, axis=1)
    [y_min2, x_min2, y_max2, x_max2] = np.split(boxes2, 4, axis=1)

    all_pairs_min_ymax = np.minimum(y_max1, np.transpose(y_max2))
    all_pairs_max_ymin = np.maximum(y_min1, np.transpose(y_min2))
    intersect_heights = np.maximum(
        np.zeros(all_pairs_max_ymin.shape),
        all_pairs_min_ymax - all_pairs_max_ymin)
    all_pairs_min_xmax = np.minimum(x_max1, np.transpose(x_max2))
    all_pairs_max_xmin = np.maximum(x_min1, np.transpose(x_min2))
    intersect_widths = np.maximum(
        np.zeros(all_pairs_max_xmin.shape),
        all_pairs_min_xmax - all_pairs_max_xmin)
    return intersect_heights * intersect_widths


</source>
</class>

<class classid="65" nclones="4" nlines="11" similarity="81">
<source file="systems/raster-vision-0.11.0/rastervision/data/label_store/chip_classification_geojson_store.py" startline="27" endline="43" pcid="903">
    def save(self, labels):
        """Save labels to URI if writable.

        Note that if the grid is inferred from polygons, only the grid will be
        written, not the original polygons.
        """
        boxes = labels.get_cells()
        class_ids = labels.get_class_ids()
        scores = list(labels.get_scores())
        geojson = boxes_to_geojson(
            boxes,
            class_ids,
            self.crs_transformer,
            self.class_map,
            scores=scores)
        json_to_file(geojson, self.uri)

</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/label_store/object_detection_geojson_store.py" startline="25" endline="37" pcid="1844">
    def save(self, labels):
        """Save labels to URI."""
        boxes = labels.get_boxes()
        class_ids = labels.get_class_ids().tolist()
        scores = labels.get_scores().tolist()
        geojson = boxes_to_geojson(
            boxes,
            class_ids,
            self.crs_transformer,
            self.class_config,
            scores=scores)
        json_to_file(geojson, self.uri)

</source>
<source file="systems/raster-vision-0.11.0/rastervision/data/label_store/object_detection_geojson_store.py" startline="23" endline="35" pcid="947">
    def save(self, labels):
        """Save labels to URI."""
        boxes = labels.get_boxes()
        class_ids = labels.get_class_ids().tolist()
        scores = labels.get_scores().tolist()
        geojson = boxes_to_geojson(
            boxes,
            class_ids,
            self.crs_transformer,
            self.class_map,
            scores=scores)
        json_to_file(geojson, self.uri)

</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/label_store/chip_classification_geojson_store.py" startline="26" endline="42" pcid="1833">
    def save(self, labels):
        """Save labels to URI if writable.

        Note that if the grid is inferred from polygons, only the grid will be
        written, not the original polygons.
        """
        boxes = labels.get_cells()
        class_ids = labels.get_class_ids()
        scores = list(labels.get_scores())
        geojson = boxes_to_geojson(
            boxes,
            class_ids,
            self.crs_transformer,
            self.class_config,
            scores=scores)
        json_to_file(geojson, self.uri)

</source>
</class>

<class classid="66" nclones="2" nlines="14" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/data/label_store/object_detection_geojson_store_config.py" startline="27" endline="44" pcid="922">
                                           task_config.class_map)

    def update_for_command(self, command_type, experiment_config,
                           context=None):
        if command_type == rv.PREDICT:
            if not self.uri:
                # Construct the  URI for this prediction store,
                # using the scene ID.
                root = experiment_config.predict_uri
                uri = None
                for c in context:
                    if isinstance(c, rv.SceneConfig):
                        uri = os.path.join(root, '{}.json'.format(c.id))
                if uri:
                    self.uri = uri
                else:
                    raise rv.ConfigError(
                        'ObjectDetectionGeoJSONStoreConfig has no '
</source>
<source file="systems/raster-vision-0.11.0/rastervision/data/label_store/chip_classification_geojson_store_config.py" startline="27" endline="44" pcid="968">
                                              task_config.class_map)

    def update_for_command(self, command_type, experiment_config,
                           context=None):
        if command_type == rv.PREDICT:
            if not self.uri:
                # Construct the  URI for this prediction store,
                # using the scene ID.
                root = experiment_config.predict_uri
                uri = None
                for c in context:
                    if isinstance(c, rv.SceneConfig):
                        uri = os.path.join(root, '{}.json'.format(c.id))
                if uri:
                    self.uri = uri
                else:
                    raise rv.ConfigError(
                        'ChipClassificationGeoJSONStoreConfig has no '
</source>
</class>

<class classid="67" nclones="2" nlines="19" similarity="94">
<source file="systems/raster-vision-0.11.0/rastervision/data/label_store/semantic_segmentation_raster_store.py" startline="16" endline="50" pcid="957">
    def __init__(self,
                 uri,
                 extent,
                 crs_transformer,
                 tmp_dir,
                 vector_output=None,
                 class_map=None):
        """Constructor.

        Args:
            uri: (str) URI of GeoTIFF file used for storing predictions as RGB values
            extent: (Box) The extent of the scene
            crs_transformer: (CRSTransformer)
            tmp_dir: (str) temp directory to use
            vector_output: (None or array of dicts) containing vectorifiction
                configuration information
            class_map: (ClassMap) with color values used to convert class ids to
                RGB values

        """
        self.uri = uri
        self.vector_output = vector_output
        self.extent = extent
        self.crs_transformer = crs_transformer
        self.tmp_dir = tmp_dir
        # Note: can't name this class_transformer due to Python using that attribute
        if class_map:
            self.class_trans = SegmentationClassTransformer(class_map)
        else:
            self.class_trans = None

        self.source = None
        if file_exists(uri):
            self.source = rv.RasterSourceConfig.builder(rv.RASTERIO_SOURCE) \
                                               .with_uri(self.uri) \
</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/data/label_store/semantic_segmentation_label_store.py" startline="19" endline="52" pcid="1847">
    def __init__(self,
                 uri,
                 extent,
                 crs_transformer,
                 tmp_dir,
                 vector_output=None,
                 class_config=None):
        """Constructor.

        Args:
            uri: (str) URI of GeoTIFF file used for storing predictions as RGB values
            extent: (Box) The extent of the scene
            crs_transformer: (CRSTransformer)
            tmp_dir: (str) temp directory to use
            vector_output: (None or array of VectorOutputConfig) containing
                vectorifiction configuration information
            class_config: (ClassConfig) with color values used to convert
                class ids to RGB value
        """
        self.uri = uri
        self.vector_output = vector_output
        self.extent = extent
        self.crs_transformer = crs_transformer
        self.tmp_dir = tmp_dir
        # Note: can't name this class_transformer due to Python using that attribute
        if class_config:
            self.class_trans = SegmentationClassTransformer(class_config)
        else:
            self.class_trans = None

        self.source = None
        if file_exists(uri):
            self.source = RasterioSourceConfig(uris=[uri]).build(tmp_dir)

</source>
</class>

<class classid="68" nclones="2" nlines="14" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/utils/filter_geojson.py" startline="13" endline="31" pcid="973">
def filter_geojson(labels_uri, output_uri, class_names):
    """Remove features that aren't in class_names and remove class_ids."""
    labels_str = file_to_str(labels_uri)
    labels = json.loads(labels_str)
    filtered_features = []

    for feature in labels['features']:
        feature = copy.deepcopy(feature)
        properties = feature.get('properties')
        if properties:
            class_name = properties.get('class_name') or properties('label')
            if class_name in class_names:
                del properties['class_id']
                filtered_features.append(feature)

    new_labels = {'features': filtered_features}
    str_to_file(json.dumps(new_labels), output_uri)


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/utils/filter_geojson.py" startline="13" endline="31" pcid="1860">
def filter_geojson(labels_uri, output_uri, class_names):
    """Remove features that aren't in class_names and remove class_ids."""
    labels_str = file_to_str(labels_uri)
    labels = json.loads(labels_str)
    filtered_features = []

    for feature in labels['features']:
        feature = copy.deepcopy(feature)
        properties = feature.get('properties')
        if properties:
            class_name = properties.get('class_name') or properties('label')
            if class_name in class_names:
                del properties['class_id']
                filtered_features.append(feature)

    new_labels = {'features': filtered_features}
    str_to_file(json.dumps(new_labels), output_uri)


</source>
</class>

<class classid="69" nclones="2" nlines="73" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/utils/zxy2geotiff.py" startline="51" endline="161" pcid="987">
def _zxy2geotiff(tile_schema, zoom, bounds, output_uri, make_cog=False):
    """Generates a GeoTIFF of a bounded region from a ZXY tile server.

    Args:
        tile_schema: (str) the URI schema for zxy tiles (ie. a slippy map tile server)
            of the form /tileserver-uri/{z}/{x}/{y}.png. If {-y} is used, the tiles
            are assumed to be indexed using TMS coordinates, where the y axis starts
            at the southernmost point. The URI can be for http, S3, or the local
            file system.
        zoom: (int) the zoom level to use when retrieving tiles
        bounds: (list) a list of length 4 containing min_lat, min_lng,
            max_lat, max_lng
        output_uri: (str) where to save the GeoTIFF. The URI can be for http, S3, or the
            local file system
    """
    min_lat, min_lng, max_lat, max_lng = bounds
    if min_lat >= max_lat:
        raise ValueError('min_lat must be < max_lat')
    if min_lng >= max_lng:
        raise ValueError('min_lng must be < max_lng')

    is_tms = False
    if '{-y}' in tile_schema:
        tile_schema = tile_schema.replace('{-y}', '{y}')
        is_tms = True

    tmp_dir_obj = tempfile.TemporaryDirectory()
    tmp_dir = tmp_dir_obj.name

    # Get range of tiles that cover bounds.
    output_path = get_local_path(output_uri, tmp_dir)
    tile_sz = 256
    t = mercantile.tile(min_lng, max_lat, zoom)
    xmin, ymin = t.x, t.y
    t = mercantile.tile(max_lng, min_lat, zoom)
    xmax, ymax = t.x, t.y

    # The supplied bounds are contained within the "tile bounds" -- ie. the
    # bounds of the set of tiles that covers the supplied bounds. Therefore,
    # we need to crop out the imagery that lies within the supplied bounds.
    # We do this by computing a top, bottom, left, and right offset in pixel
    # units of the supplied bounds against the tile bounds. Getting the offsets
    # in pixel units involves converting lng/lat to web mercator units since we
    # assume that is the CRS of the tiles. These offsets are then used to crop
    # individual tiles and place them correctly into the output raster.
    nw_merc_x, nw_merc_y = lnglat2merc(min_lng, max_lat)
    left_pix_offset, top_pix_offset = merc2pixel(xmin, ymin, zoom, nw_merc_x,
                                                 nw_merc_y)

    se_merc_x, se_merc_y = lnglat2merc(max_lng, min_lat)
    se_left_pix_offset, se_top_pix_offset = merc2pixel(xmax, ymax, zoom,
                                                       se_merc_x, se_merc_y)
    right_pix_offset = tile_sz - se_left_pix_offset
    bottom_pix_offset = tile_sz - se_top_pix_offset

    uncropped_height = tile_sz * (ymax - ymin + 1)
    uncropped_width = tile_sz * (xmax - xmin + 1)
    height = uncropped_height - top_pix_offset - bottom_pix_offset
    width = uncropped_width - left_pix_offset - right_pix_offset

    transform = rasterio.transform.from_bounds(nw_merc_x, se_merc_y, se_merc_x,
                                               nw_merc_y, width, height)
    with rasterio.open(
            output_path,
            'w',
            driver='GTiff',
            height=height,
            width=width,
            count=3,
            crs='epsg:3857',
            transform=transform,
            dtype=rasterio.uint8) as dataset:
        out_x = 0
        for xi, x in enumerate(range(xmin, xmax + 1)):
            tile_xmin, tile_xmax = 0, tile_sz - 1
            if x == xmin:
                tile_xmin += left_pix_offset
            if x == xmax:
                tile_xmax -= right_pix_offset
            window_width = tile_xmax - tile_xmin + 1

            out_y = 0
            for yi, y in enumerate(range(ymin, ymax + 1)):
                tile_ymin, tile_ymax = 0, tile_sz - 1
                if y == ymin:
                    tile_ymin += top_pix_offset
                if y == ymax:
                    tile_ymax -= bottom_pix_offset
                window_height = tile_ymax - tile_ymin + 1

                # Convert from xyz to tms if needed.
                # https://gist.github.com/tmcw/4954720
                if is_tms:
                    y = (2**zoom) - y - 1
                tile_uri = tile_schema.format(x=x, y=y, z=zoom)
                tile_path = download_if_needed(tile_uri, tmp_dir)
                img = np.array(Image.open(tile_path))
                img = img[tile_ymin:tile_ymax + 1, tile_xmin:tile_xmax + 1, :]

                window = Window(out_x, out_y, window_width, window_height)
                dataset.write(
                    np.transpose(img[:, :, 0:3], (2, 0, 1)), window=window)
                out_y += window_height
            out_x += window_width

    if make_cog:
        create_cog(output_path, output_uri, tmp_dir)
    else:
        upload_or_copy(output_path, output_uri)


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/utils/zxy2geotiff.py" startline="51" endline="161" pcid="1867">
def _zxy2geotiff(tile_schema, zoom, bounds, output_uri, make_cog=False):
    """Generates a GeoTIFF of a bounded region from a ZXY tile server.

    Args:
        tile_schema: (str) the URI schema for zxy tiles (ie. a slippy map tile server)
            of the form /tileserver-uri/{z}/{x}/{y}.png. If {-y} is used, the tiles
            are assumed to be indexed using TMS coordinates, where the y axis starts
            at the southernmost point. The URI can be for http, S3, or the local
            file system.
        zoom: (int) the zoom level to use when retrieving tiles
        bounds: (list) a list of length 4 containing min_lat, min_lng,
            max_lat, max_lng
        output_uri: (str) where to save the GeoTIFF. The URI can be for http, S3, or the
            local file system
    """
    min_lat, min_lng, max_lat, max_lng = bounds
    if min_lat >= max_lat:
        raise ValueError('min_lat must be < max_lat')
    if min_lng >= max_lng:
        raise ValueError('min_lng must be < max_lng')

    is_tms = False
    if '{-y}' in tile_schema:
        tile_schema = tile_schema.replace('{-y}', '{y}')
        is_tms = True

    tmp_dir_obj = tempfile.TemporaryDirectory()
    tmp_dir = tmp_dir_obj.name

    # Get range of tiles that cover bounds.
    output_path = get_local_path(output_uri, tmp_dir)
    tile_sz = 256
    t = mercantile.tile(min_lng, max_lat, zoom)
    xmin, ymin = t.x, t.y
    t = mercantile.tile(max_lng, min_lat, zoom)
    xmax, ymax = t.x, t.y

    # The supplied bounds are contained within the "tile bounds" -- ie. the
    # bounds of the set of tiles that covers the supplied bounds. Therefore,
    # we need to crop out the imagery that lies within the supplied bounds.
    # We do this by computing a top, bottom, left, and right offset in pixel
    # units of the supplied bounds against the tile bounds. Getting the offsets
    # in pixel units involves converting lng/lat to web mercator units since we
    # assume that is the CRS of the tiles. These offsets are then used to crop
    # individual tiles and place them correctly into the output raster.
    nw_merc_x, nw_merc_y = lnglat2merc(min_lng, max_lat)
    left_pix_offset, top_pix_offset = merc2pixel(xmin, ymin, zoom, nw_merc_x,
                                                 nw_merc_y)

    se_merc_x, se_merc_y = lnglat2merc(max_lng, min_lat)
    se_left_pix_offset, se_top_pix_offset = merc2pixel(xmax, ymax, zoom,
                                                       se_merc_x, se_merc_y)
    right_pix_offset = tile_sz - se_left_pix_offset
    bottom_pix_offset = tile_sz - se_top_pix_offset

    uncropped_height = tile_sz * (ymax - ymin + 1)
    uncropped_width = tile_sz * (xmax - xmin + 1)
    height = uncropped_height - top_pix_offset - bottom_pix_offset
    width = uncropped_width - left_pix_offset - right_pix_offset

    transform = rasterio.transform.from_bounds(nw_merc_x, se_merc_y, se_merc_x,
                                               nw_merc_y, width, height)
    with rasterio.open(
            output_path,
            'w',
            driver='GTiff',
            height=height,
            width=width,
            count=3,
            crs='epsg:3857',
            transform=transform,
            dtype=rasterio.uint8) as dataset:
        out_x = 0
        for xi, x in enumerate(range(xmin, xmax + 1)):
            tile_xmin, tile_xmax = 0, tile_sz - 1
            if x == xmin:
                tile_xmin += left_pix_offset
            if x == xmax:
                tile_xmax -= right_pix_offset
            window_width = tile_xmax - tile_xmin + 1

            out_y = 0
            for yi, y in enumerate(range(ymin, ymax + 1)):
                tile_ymin, tile_ymax = 0, tile_sz - 1
                if y == ymin:
                    tile_ymin += top_pix_offset
                if y == ymax:
                    tile_ymax -= bottom_pix_offset
                window_height = tile_ymax - tile_ymin + 1

                # Convert from xyz to tms if needed.
                # https://gist.github.com/tmcw/4954720
                if is_tms:
                    y = (2**zoom) - y - 1
                tile_uri = tile_schema.format(x=x, y=y, z=zoom)
                tile_path = download_if_needed(tile_uri, tmp_dir)
                img = np.array(Image.open(tile_path))
                img = img[tile_ymin:tile_ymax + 1, tile_xmin:tile_xmax + 1, :]

                window = Window(out_x, out_y, window_width, window_height)
                dataset.write(
                    np.transpose(img[:, :, 0:3], (2, 0, 1)), window=window)
                out_y += window_height
            out_x += window_width

    if make_cog:
        create_cog(output_path, output_uri, tmp_dir)
    else:
        upload_or_copy(output_path, output_uri)


</source>
</class>

<class classid="70" nclones="2" nlines="10" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/evaluation/semantic_segmentation_evaluation.py" startline="14" endline="25" pcid="1045">
def is_geojson(data):
    if isinstance(data, dict):
        return True
    else:
        try:
            json.loads(data)
            retval = True
        except ValueError:
            retval = False
        return retval


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/evaluation/semantic_segmentation_evaluation.py" startline="14" endline="25" pcid="1908">
def is_geojson(data):
    if isinstance(data, dict):
        return True
    else:
        try:
            json.loads(data)
            retval = True
        except ValueError:
            retval = False
        return retval


</source>
</class>

<class classid="71" nclones="2" nlines="28" similarity="85">
<source file="systems/raster-vision-0.11.0/rastervision/evaluation/semantic_segmentation_evaluation.py" startline="26" endline="58" pcid="1046">
def get_class_eval_item(conf_mat, class_id, class_map):
    class_name = class_map.get_by_id(class_id).name

    if conf_mat.ravel().sum() == 0:
        return ClassEvaluationItem(None, None, None, 0, 0, class_id,
                                   class_name)

    true_pos = conf_mat[class_id, class_id]
    false_pos = conf_mat[1:, class_id].sum() - true_pos
    false_neg = conf_mat[class_id, :].sum() - true_pos
    precision = float(true_pos) / (true_pos + false_pos)
    recall = float(true_pos) / (true_pos + false_neg)
    f1 = 2 * (precision * recall) / (precision + recall)
    count_error = int(false_pos + false_neg)
    gt_count = conf_mat[class_id, :].sum()

    if math.isnan(precision):
        precision = None
    else:
        precision = float(precision)
    if math.isnan(recall):
        recall = None
    else:
        recall = float(recall)
    if math.isnan(f1):
        f1 = None
    else:
        f1 = float(f1)

    return ClassEvaluationItem(precision, recall, f1, count_error, gt_count,
                               class_id, class_name, conf_mat[class_id, :])


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/evaluation/semantic_segmentation_evaluation.py" startline="26" endline="59" pcid="1909">
def get_class_eval_item(conf_mat, class_id, class_name, null_class_id):
    if conf_mat.ravel().sum() == 0:
        return ClassEvaluationItem(None, None, None, 0, 0, class_id,
                                   class_name)

    non_null_class_ids = list(range(conf_mat.shape[0]))
    non_null_class_ids.remove(null_class_id)

    true_pos = conf_mat[class_id, class_id]
    false_pos = conf_mat[non_null_class_ids, class_id].sum() - true_pos
    false_neg = conf_mat[class_id, :].sum() - true_pos
    precision = float(true_pos) / (true_pos + false_pos)
    recall = float(true_pos) / (true_pos + false_neg)
    f1 = 2 * (precision * recall) / (precision + recall)
    count_error = int(false_pos + false_neg)
    gt_count = conf_mat[class_id, :].sum()

    if math.isnan(precision):
        precision = None
    else:
        precision = float(precision)
    if math.isnan(recall):
        recall = None
    else:
        recall = float(recall)
    if math.isnan(f1):
        f1 = None
    else:
        f1 = float(f1)

    return ClassEvaluationItem(precision, recall, f1, count_error, gt_count,
                               class_id, class_name, conf_mat[class_id, :])


</source>
</class>

<class classid="72" nclones="2" nlines="45" similarity="95">
<source file="systems/raster-vision-0.11.0/rastervision/evaluation/semantic_segmentation_evaluation.py" startline="85" endline="150" pcid="1049">
    def compute_vector(self, gt, pred, mode, class_id):
        """Compute evaluation over vector predictions.
            Args:
                gt: Ground-truth GeoJSON.  Either a string (containing
                    unparsed GeoJSON or a file name), or a dictionary
                    containing parsed GeoJSON.
                pred: GeoJSON for predictions.  Either a string
                    (containing unparsed GeoJSON or a file name), or a
                    dictionary containing parsed GeoJSON.
                mode: A string containing either 'buildings' or
                    'polygons'.
                class_id: An integer containing the class id of
                    interest.
        """
        import mask_to_polygons.vectorification as vectorification
        import mask_to_polygons.processing.score as score

        # Ground truth as list of geometries
        def get_geoms(x):
            if is_geojson(x):
                _x = x
                if 'features' in _x.keys():
                    _x = _x['features']
                geoms = []
                for feature in _x:
                    if 'geometry' in feature.keys():
                        geoms.append(feature['geometry'])
                    else:
                        geoms.append(feature)
            else:
                geoms = vectorification.geometries_from_geojson(x)

            return geoms

        gt = get_geoms(gt)
        pred = get_geoms(pred)

        if len(gt) > 0 and len(pred) > 0:
            results = score.spacenet(pred, gt)

            true_positives = results['tp']
            false_positives = results['fp']
            false_negatives = results['fn']
            precision = float(true_positives) / (
                true_positives + false_positives)
            recall = float(true_positives) / (true_positives + false_negatives)
            if precision + recall != 0:
                f1 = 2 * (precision * recall) / (precision + recall)
            else:
                f1 = 0.0
            count_error = int(false_positives + false_negatives)
            gt_count = len(gt)
            class_name = 'vector-{}-{}'.format(
                mode,
                self.class_map.get_by_id(class_id).name)

            evaluation_item = ClassEvaluationItem(precision, recall, f1,
                                                  count_error, gt_count,
                                                  class_id, class_name)

            if hasattr(self, 'class_to_eval_item') and isinstance(
                    self.class_to_eval_item, dict):
                self.class_to_eval_item[class_id] = evaluation_item
            else:
                self.class_to_eval_item = {class_id: evaluation_item}
            self.compute_avg()
</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/evaluation/semantic_segmentation_evaluation.py" startline="87" endline="151" pcid="1912">
    def compute_vector(self, gt, pred, mode, class_id):
        """Compute evaluation over vector predictions.
            Args:
                gt: Ground-truth GeoJSON.  Either a string (containing
                    unparsed GeoJSON or a file name), or a dictionary
                    containing parsed GeoJSON.
                pred: GeoJSON for predictions.  Either a string
                    (containing unparsed GeoJSON or a file name), or a
                    dictionary containing parsed GeoJSON.
                mode: A string containing either 'buildings' or
                    'polygons'.
                class_id: An integer containing the class id of
                    interest.
        """
        import mask_to_polygons.vectorification as vectorification
        import mask_to_polygons.processing.score as score

        # Ground truth as list of geometries
        def get_geoms(x):
            if is_geojson(x):
                _x = x
                if 'features' in _x.keys():
                    _x = _x['features']
                geoms = []
                for feature in _x:
                    if 'geometry' in feature.keys():
                        geoms.append(feature['geometry'])
                    else:
                        geoms.append(feature)
            else:
                geoms = vectorification.geometries_from_geojson(x)

            return geoms

        gt = get_geoms(gt)
        pred = get_geoms(pred)

        if len(gt) > 0 and len(pred) > 0:
            results = score.spacenet(pred, gt)

            true_positives = results['tp']
            false_positives = results['fp']
            false_negatives = results['fn']
            precision = float(true_positives) / (
                true_positives + false_positives)
            recall = float(true_positives) / (true_positives + false_negatives)
            if precision + recall != 0:
                f1 = 2 * (precision * recall) / (precision + recall)
            else:
                f1 = 0.0
            count_error = int(false_positives + false_negatives)
            gt_count = len(gt)
            class_name = 'vector-{}-{}'.format(
                mode, self.class_config.names[class_id])

            evaluation_item = ClassEvaluationItem(precision, recall, f1,
                                                  count_error, gt_count,
                                                  class_id, class_name)

            if hasattr(self, 'class_to_eval_item') and isinstance(
                    self.class_to_eval_item, dict):
                self.class_to_eval_item[class_id] = evaluation_item
            else:
                self.class_to_eval_item = {class_id: evaluation_item}
            self.compute_avg()
</source>
</class>

<class classid="73" nclones="2" nlines="26" similarity="81">
<source file="systems/raster-vision-0.11.0/rastervision/evaluation/chip_classification_evaluation.py" startline="20" endline="54" pcid="1053">
    def compute_eval_items(gt_labels, pred_labels, class_map):
        nb_classes = len(class_map)
        class_to_eval_item = {}

        gt_class_ids = []
        pred_class_ids = []

        gt_cells = gt_labels.get_cells()
        for gt_cell in gt_cells:
            gt_class_id = gt_labels.get_cell_class_id(gt_cell)
            pred_class_id = pred_labels.get_cell_class_id(gt_cell)

            if gt_class_id is not None and pred_class_id is not None:
                gt_class_ids.append(gt_class_id)
                pred_class_ids.append(pred_class_id)

        # Add 1 because class_ids start at 1.
        sklabels = np.arange(1 + nb_classes)
        precision, recall, f1, support = metrics.precision_recall_fscore_support(
            gt_class_ids, pred_class_ids, labels=sklabels, warn_for=())

        for class_map_item in class_map.get_items():
            class_id = class_map_item.id
            class_name = class_map_item.name

            eval_item = ClassEvaluationItem(
                float(precision[class_id]),
                float(recall[class_id]),
                float(f1[class_id]),
                gt_count=float(support[class_id]),
                class_id=class_id,
                class_name=class_name)
            class_to_eval_item[class_id] = eval_item

        return class_to_eval_item
</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/evaluation/chip_classification_evaluation.py" startline="20" endline="50" pcid="1916">
    def compute_eval_items(gt_labels, pred_labels, class_config):
        nb_classes = len(class_config.names)
        class_to_eval_item = {}

        gt_class_ids = []
        pred_class_ids = []

        gt_cells = gt_labels.get_cells()
        for gt_cell in gt_cells:
            gt_class_id = gt_labels.get_cell_class_id(gt_cell)
            pred_class_id = pred_labels.get_cell_class_id(gt_cell)

            if gt_class_id is not None and pred_class_id is not None:
                gt_class_ids.append(gt_class_id)
                pred_class_ids.append(pred_class_id)

        sklabels = np.arange(nb_classes)
        precision, recall, f1, support = metrics.precision_recall_fscore_support(
            gt_class_ids, pred_class_ids, labels=sklabels, warn_for=())

        for class_id, class_name in enumerate(class_config.names):
            eval_item = ClassEvaluationItem(
                float(precision[class_id]),
                float(recall[class_id]),
                float(f1[class_id]),
                gt_count=float(support[class_id]),
                class_id=class_id,
                class_name=class_name)
            class_to_eval_item[class_id] = eval_item

        return class_to_eval_item
</source>
</class>

<class classid="74" nclones="2" nlines="18" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/evaluation/classification_evaluator.py" startline="23" endline="43" pcid="1056">
    def process(self, scenes, tmp_dir):
        evaluation = self.create_evaluation()

        for scene in scenes:
            log.info('Computing evaluation for scene {}...'.format(scene.id))
            label_source = scene.ground_truth_label_source
            label_store = scene.prediction_label_store
            with ActivateMixin.compose(label_source, label_store):
                ground_truth = label_source.get_labels()
                predictions = label_store.get_labels()

                if scene.aoi_polygons:
                    # Filter labels based on AOI.
                    ground_truth = ground_truth.filter_by_aoi(
                        scene.aoi_polygons)
                    predictions = predictions.filter_by_aoi(scene.aoi_polygons)
                scene_evaluation = self.create_evaluation()
                scene_evaluation.compute(ground_truth, predictions)
                evaluation.merge(scene_evaluation, scene_id=scene.id)
        evaluation.save(self.output_uri)
        self.eval = evaluation
</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/evaluation/classification_evaluator.py" startline="22" endline="42" pcid="1919">
    def process(self, scenes, tmp_dir):
        evaluation = self.create_evaluation()

        for scene in scenes:
            log.info('Computing evaluation for scene {}...'.format(scene.id))
            label_source = scene.ground_truth_label_source
            label_store = scene.prediction_label_store
            with ActivateMixin.compose(label_source, label_store):
                ground_truth = label_source.get_labels()
                predictions = label_store.get_labels()

                if scene.aoi_polygons:
                    # Filter labels based on AOI.
                    ground_truth = ground_truth.filter_by_aoi(
                        scene.aoi_polygons)
                    predictions = predictions.filter_by_aoi(scene.aoi_polygons)
                scene_evaluation = self.create_evaluation()
                scene_evaluation.compute(ground_truth, predictions)
                evaluation.merge(scene_evaluation, scene_id=scene.id)
        evaluation.save(self.output_uri)
        self.eval = evaluation
</source>
</class>

<class classid="75" nclones="2" nlines="36" similarity="94">
<source file="systems/raster-vision-0.11.0/rastervision/evaluation/object_detection_evaluation.py" startline="11" endline="55" pcid="1060">
def compute_metrics(gt_labels: ObjectDetectionLabels,
                    pred_labels: ObjectDetectionLabels,
                    num_classes: int,
                    iou_thresh=0.5):
    gt_geoms = [b.to_shapely() for b in gt_labels.get_boxes()]
    gt_classes = gt_labels.get_class_ids() - 1
    pred_geoms = [b.to_shapely() for b in pred_labels.get_boxes()]
    pred_classes = pred_labels.get_class_ids() - 1

    for pred, class_id in zip(pred_geoms, pred_classes):
        pred.class_id = class_id
    pred_tree = shapely.strtree.STRtree(pred_geoms)

    def iou(a, b):
        return a.intersection(b).area / a.union(b).area

    def is_matched(geom):
        return hasattr(geom, 'iou_matched')

    tp = np.zeros((num_classes, ))
    fp = np.zeros((num_classes, ))
    fn = np.zeros((num_classes, ))

    for gt, gt_class in zip(gt_geoms, gt_classes):
        matches = list(
            filter(lambda g: (not is_matched(g)) and g.class_id == gt_class,
                   pred_tree.query(gt)))
        scores = [iou(m, gt) for m in matches]
        if len(scores) > 0:
            max_ind = np.argmax(scores)
            if scores[max_ind] > iou_thresh:
                matches[max_ind].iou_matched = True
                tp[gt_class] += 1
            else:
                fn[gt_class] += 1
        else:
            fn[gt_class] += 1

    for class_id in range(num_classes):
        pred_not_matched = np.array([not is_matched(g) for g in pred_geoms])
        fp[class_id] = np.sum(pred_not_matched[pred_classes == class_id])

    return tp, fp, fn


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/evaluation/object_detection_evaluation.py" startline="11" endline="55" pcid="1920">
def compute_metrics(gt_labels: ObjectDetectionLabels,
                    pred_labels: ObjectDetectionLabels,
                    num_classes: int,
                    iou_thresh=0.5):
    gt_geoms = [b.to_shapely() for b in gt_labels.get_boxes()]
    gt_classes = gt_labels.get_class_ids()
    pred_geoms = [b.to_shapely() for b in pred_labels.get_boxes()]
    pred_classes = pred_labels.get_class_ids()

    for pred, class_id in zip(pred_geoms, pred_classes):
        pred.class_id = class_id
    pred_tree = shapely.strtree.STRtree(pred_geoms)

    def iou(a, b):
        return a.intersection(b).area / a.union(b).area

    def is_matched(geom):
        return hasattr(geom, 'iou_matched')

    tp = np.zeros((num_classes, ))
    fp = np.zeros((num_classes, ))
    fn = np.zeros((num_classes, ))

    for gt, gt_class in zip(gt_geoms, gt_classes):
        matches = list(
            filter(lambda g: (not is_matched(g)) and g.class_id == gt_class,
                   pred_tree.query(gt)))
        scores = [iou(m, gt) for m in matches]
        if len(scores) > 0:
            max_ind = np.argmax(scores)
            if scores[max_ind] > iou_thresh:
                matches[max_ind].iou_matched = True
                tp[gt_class] += 1
            else:
                fn[gt_class] += 1
        else:
            fn[gt_class] += 1

    for class_id in range(num_classes):
        pred_not_matched = np.array([not is_matched(g) for g in pred_geoms])
        fp[class_id] = np.sum(pred_not_matched[pred_classes == class_id])

    return tp, fp, fn


</source>
</class>

<class classid="76" nclones="2" nlines="41" similarity="95">
<source file="systems/raster-vision-0.11.0/rastervision/evaluation/object_detection_evaluation.py" startline="67" endline="112" pcid="1065">
    def compute_eval_items(gt_labels, pred_labels, class_map):
        iou_thresh = 0.5
        num_classes = len(class_map)
        tps, fps, fns = compute_metrics(gt_labels, pred_labels, num_classes,
                                        iou_thresh)
        class_to_eval_item = {}

        for class_ind, (tp, fp, fn) in enumerate(zip(tps, fps, fns)):
            class_id = class_ind + 1
            gt_count = tp + fn
            pred_count = tp + fp
            class_name = class_map.get_by_id(class_id).name

            if gt_count == 0:
                eval_item = ClassEvaluationItem(
                    class_id=class_id, class_name=class_name)
            elif pred_count == 0:
                eval_item = ClassEvaluationItem(
                    precision=None,
                    recall=0,
                    gt_count=gt_count,
                    class_id=class_id,
                    class_name=class_name)
            else:
                prec = tp / (tp + fp)
                recall = tp / (tp + fn)
                f1 = 0.
                if prec + recall != 0.0:
                    f1 = 2 * (prec * recall) / (prec + recall)
                count_err = pred_count - gt_count
                norm_count_err = None
                if gt_count > 0:
                    norm_count_err = count_err / gt_count

                eval_item = ClassEvaluationItem(
                    precision=prec,
                    recall=recall,
                    f1=f1,
                    count_error=norm_count_err,
                    gt_count=gt_count,
                    class_id=class_id,
                    class_name=class_name)

            class_to_eval_item[class_id] = eval_item

        return class_to_eval_item
</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/evaluation/object_detection_evaluation.py" startline="67" endline="111" pcid="1925">
    def compute_eval_items(gt_labels, pred_labels, class_config):
        iou_thresh = 0.5
        num_classes = len(class_config)
        tps, fps, fns = compute_metrics(gt_labels, pred_labels, num_classes,
                                        iou_thresh)
        class_to_eval_item = {}

        for class_id, (tp, fp, fn) in enumerate(zip(tps, fps, fns)):
            gt_count = tp + fn
            pred_count = tp + fp
            class_name = class_config.get_name(class_id)

            if gt_count == 0:
                eval_item = ClassEvaluationItem(
                    class_id=class_id, class_name=class_name)
            elif pred_count == 0:
                eval_item = ClassEvaluationItem(
                    precision=None,
                    recall=0,
                    gt_count=gt_count,
                    class_id=class_id,
                    class_name=class_name)
            else:
                prec = tp / (tp + fp)
                recall = tp / (tp + fn)
                f1 = 0.
                if prec + recall != 0.0:
                    f1 = 2 * (prec * recall) / (prec + recall)
                count_err = pred_count - gt_count
                norm_count_err = None
                if gt_count > 0:
                    norm_count_err = count_err / gt_count

                eval_item = ClassEvaluationItem(
                    precision=prec,
                    recall=recall,
                    f1=f1,
                    count_error=norm_count_err,
                    gt_count=gt_count,
                    class_id=class_id,
                    class_name=class_name)

            class_to_eval_item[class_id] = eval_item

        return class_to_eval_item
</source>
</class>

<class classid="77" nclones="2" nlines="12" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/evaluation/semantic_segmentation_evaluator.py" startline="13" endline="31" pcid="1077">
def filter_geojson_by_aoi(geojson, aoi_polygons):
    # Note that this ignores class_id but that's ok because each prediction GeoJSON file
    # covers a single class_id. But, this may change in the future.
    tree = STRtree([shape(f['geometry']) for f in geojson['features']])
    filtered_shapes = []
    for aoi_poly in aoi_polygons:
        shapes_in_aoi = tree.query(aoi_poly)
        for s in shapes_in_aoi:
            s_int = s.intersection(aoi_poly)
            filtered_shapes.append(s_int)

    features = [{
        'type': 'feature',
        'geometry': mapping(s)
    } for s in filtered_shapes]

    return {'type': 'FeatureCollection', 'features': features}


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/evaluation/semantic_segmentation_evaluator.py" startline="14" endline="32" pcid="1926">
def filter_geojson_by_aoi(geojson, aoi_polygons):
    # Note that this ignores class_id but that's ok because each prediction GeoJSON file
    # covers a single class_id. But, this may change in the future.
    tree = STRtree([shape(f['geometry']) for f in geojson['features']])
    filtered_shapes = []
    for aoi_poly in aoi_polygons:
        shapes_in_aoi = tree.query(aoi_poly)
        for s in shapes_in_aoi:
            s_int = s.intersection(aoi_poly)
            filtered_shapes.append(s_int)

    features = [{
        'type': 'feature',
        'geometry': mapping(s)
    } for s in filtered_shapes]

    return {'type': 'FeatureCollection', 'features': features}


</source>
</class>

<class classid="78" nclones="2" nlines="45" similarity="76">
<source file="systems/raster-vision-0.11.0/rastervision/evaluation/semantic_segmentation_evaluator.py" startline="43" endline="92" pcid="1080">
    def process(self, scenes, tmp_dir):
        evaluation = self.create_evaluation()
        vect_evaluation = self.create_evaluation()

        for scene in scenes:
            log.info('Computing evaluation for scene {}...'.format(scene.id))
            label_source = scene.ground_truth_label_source
            label_store = scene.prediction_label_store
            with ActivateMixin.compose(label_source, label_store):
                ground_truth = label_source.get_labels()
                predictions = label_store.get_labels()

                if scene.aoi_polygons:
                    # Filter labels based on AOI.
                    ground_truth = ground_truth.filter_by_aoi(
                        scene.aoi_polygons)
                    predictions = predictions.filter_by_aoi(scene.aoi_polygons)
                scene_evaluation = self.create_evaluation()
                scene_evaluation.compute(ground_truth, predictions)
                evaluation.merge(scene_evaluation, scene_id=scene.id)

            if hasattr(label_source, 'source') and hasattr(
                    label_source.source, 'vector_source') and hasattr(
                        label_store, 'vector_output'):
                gt_geojson = label_source.source.vector_source.get_geojson()
                for vo in label_store.vector_output:
                    pred_geojson_uri = vo['uri']
                    mode = vo['mode']
                    class_id = vo['class_id']
                    pred_geojson_source = GeoJSONVectorSource(
                        pred_geojson_uri,
                        scene.raster_source.get_crs_transformer())
                    pred_geojson = pred_geojson_source.get_geojson()

                    if scene.aoi_polygons:
                        gt_geojson = filter_geojson_by_aoi(
                            gt_geojson, scene.aoi_polygons)
                        pred_geojson = filter_geojson_by_aoi(
                            pred_geojson, scene.aoi_polygons)

                    vect_scene_evaluation = self.create_evaluation()
                    vect_scene_evaluation.compute_vector(
                        gt_geojson, pred_geojson, mode, class_id)
                    vect_evaluation.merge(
                        vect_scene_evaluation, scene_id=scene.id)

        if not evaluation.is_empty():
            evaluation.save(self.output_uri)
        if not vect_evaluation.is_empty():
            vect_evaluation.save(self.vector_output_uri)
</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/evaluation/semantic_segmentation_evaluator.py" startline="44" endline="97" pcid="1929">
    def process(self, scenes, tmp_dir):
        evaluation = self.create_evaluation()
        vect_evaluation = self.create_evaluation()
        null_class_id = self.class_config.get_null_class_id()

        for scene in scenes:
            log.info('Computing evaluation for scene {}...'.format(scene.id))
            label_source = scene.ground_truth_label_source
            label_store = scene.prediction_label_store
            with ActivateMixin.compose(label_source, label_store):
                ground_truth = label_source.get_labels()
                predictions = label_store.get_labels()

                if scene.aoi_polygons:
                    # Filter labels based on AOI.
                    ground_truth = ground_truth.filter_by_aoi(
                        scene.aoi_polygons, null_class_id)
                    predictions = predictions.filter_by_aoi(
                        scene.aoi_polygons, null_class_id)
                scene_evaluation = self.create_evaluation()
                scene_evaluation.compute(ground_truth, predictions)
                evaluation.merge(scene_evaluation, scene_id=scene.id)

            if hasattr(label_source, 'raster_source') and hasattr(
                    label_source.raster_source, 'vector_source') and hasattr(
                        label_store, 'vector_output'):
                gt_geojson = label_source.raster_source.vector_source.get_geojson(
                )
                for vo in label_store.vector_output:
                    pred_geojson_uri = vo.uri
                    mode = vo.get_mode()
                    class_id = vo.class_id
                    pred_geojson_source = GeoJSONVectorSourceConfig(
                        uri=pred_geojson_uri, default_class_id=class_id).build(
                            self.class_config,
                            scene.raster_source.get_crs_transformer())
                    pred_geojson = pred_geojson_source.get_geojson()

                    if scene.aoi_polygons:
                        gt_geojson = filter_geojson_by_aoi(
                            gt_geojson, scene.aoi_polygons)
                        pred_geojson = filter_geojson_by_aoi(
                            pred_geojson, scene.aoi_polygons)

                    vect_scene_evaluation = self.create_evaluation()
                    vect_scene_evaluation.compute_vector(
                        gt_geojson, pred_geojson, mode, class_id)
                    vect_evaluation.merge(
                        vect_scene_evaluation, scene_id=scene.id)

        if not evaluation.is_empty():
            evaluation.save(self.output_uri)
        if not vect_evaluation.is_empty():
            vect_evaluation.save(self.vector_output_uri)
</source>
</class>

<class classid="79" nclones="2" nlines="13" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/evaluation/classification_evaluation.py" startline="41" endline="56" pcid="1102">
    def to_json(self):
        json_rep = []
        for eval_item in self.class_to_eval_item.values():
            json_rep.append(eval_item.to_json())
        if self.avg_item:
            json_rep.append(self.avg_item.to_json())

        if self.scene_to_eval:
            json_rep = {'overall': json_rep}
            scene_to_eval_json = {}
            for scene_id, eval in self.scene_to_eval.items():
                scene_to_eval_json[scene_id] = eval.to_json()
            json_rep['per_scene'] = scene_to_eval_json

        return json_rep

</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/evaluation/classification_evaluation.py" startline="41" endline="56" pcid="1944">
    def to_json(self):
        json_rep = []
        for eval_item in self.class_to_eval_item.values():
            json_rep.append(eval_item.to_json())
        if self.avg_item:
            json_rep.append(self.avg_item.to_json())

        if self.scene_to_eval:
            json_rep = {'overall': json_rep}
            scene_to_eval_json = {}
            for scene_id, eval in self.scene_to_eval.items():
                scene_to_eval_json[scene_id] = eval.to_json()
            json_rep['per_scene'] = scene_to_eval_json

        return json_rep

</source>
</class>

<class classid="80" nclones="2" nlines="13" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/evaluation/classification_evaluation.py" startline="66" endline="89" pcid="1104">
    def merge(self, evaluation, scene_id=None):
        """Merge Evaluation for another Scene into this one.

        This is useful for computing the average metrics of a set of scenes.
        The results of the averaging are stored in this Evaluation.

        Args:
            evaluation: Evaluation to merge into this one
        """
        if len(self.class_to_eval_item) == 0:
            self.class_to_eval_item = evaluation.class_to_eval_item
        else:
            for key, other_eval_item in \
                    evaluation.class_to_eval_item.items():
                if self.has_id(key):
                    self.get_by_id(key).merge(other_eval_item)
                else:
                    self.class_to_eval_item[key] = other_eval_item

        self._is_empty = False
        self.compute_avg()

        if scene_id is not None:
            self.scene_to_eval[scene_id] = copy.deepcopy(evaluation)
</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/evaluation/classification_evaluation.py" startline="66" endline="89" pcid="1946">
    def merge(self, evaluation, scene_id=None):
        """Merge Evaluation for another Scene into this one.

        This is useful for computing the average metrics of a set of scenes.
        The results of the averaging are stored in this Evaluation.

        Args:
            evaluation: Evaluation to merge into this one
        """
        if len(self.class_to_eval_item) == 0:
            self.class_to_eval_item = evaluation.class_to_eval_item
        else:
            for key, other_eval_item in \
                    evaluation.class_to_eval_item.items():
                if self.has_id(key):
                    self.get_by_id(key).merge(other_eval_item)
                else:
                    self.class_to_eval_item[key] = other_eval_item

        self._is_empty = False
        self.compute_avg()

        if scene_id is not None:
            self.scene_to_eval[scene_id] = copy.deepcopy(evaluation)
</source>
</class>

<class classid="81" nclones="2" nlines="29" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/evaluation/class_evaluation_item.py" startline="33" endline="74" pcid="1108">
    def merge(self, other):
        """Merges another item from a different scene into this one.

        This is used to average metrics over scenes. Merges by taking a
        weighted average (by gt_count) of the metrics.
        """
        if other.gt_count > 0:
            total_gt_count = self.gt_count + other.gt_count
            self_ratio = self.gt_count / total_gt_count
            other_ratio = other.gt_count / total_gt_count

            def weighted_avg(self_val, other_val):
                if self_val is None and other_val is None:
                    return 0.0
                # Handle a single None value by setting them to zero.
                return (self_ratio * (self_val or 0) +
                        other_ratio * (other_val or 0))

            self.precision = weighted_avg(self.precision, other.precision)
            self.recall = weighted_avg(self.recall, other.recall)
            self.f1 = weighted_avg(self.f1, other.f1)
            self.count_error = weighted_avg(self.count_error,
                                            other.count_error)
            self.gt_count = total_gt_count

        if other.conf_mat is not None:
            if self.class_name == 'average':
                if self.conf_mat is None:
                    # Make first row all zeros so that the array indices
                    # correspond to valid class ids (ie. >= 1).
                    self.conf_mat = np.concatenate(
                        [
                            np.zeros_like(other.conf_mat)[np.newaxis, :],
                            np.array(other.conf_mat)[np.newaxis, :]
                        ],
                        axis=0)
                else:
                    self.conf_mat = np.concatenate(
                        [self.conf_mat, other.conf_mat[np.newaxis, :]], axis=0)
            else:
                self.conf_mat += other.conf_mat

</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/evaluation/class_evaluation_item.py" startline="33" endline="74" pcid="1950">
    def merge(self, other):
        """Merges another item from a different scene into this one.

        This is used to average metrics over scenes. Merges by taking a
        weighted average (by gt_count) of the metrics.
        """
        if other.gt_count > 0:
            total_gt_count = self.gt_count + other.gt_count
            self_ratio = self.gt_count / total_gt_count
            other_ratio = other.gt_count / total_gt_count

            def weighted_avg(self_val, other_val):
                if self_val is None and other_val is None:
                    return 0.0
                # Handle a single None value by setting them to zero.
                return (self_ratio * (self_val or 0) +
                        other_ratio * (other_val or 0))

            self.precision = weighted_avg(self.precision, other.precision)
            self.recall = weighted_avg(self.recall, other.recall)
            self.f1 = weighted_avg(self.f1, other.f1)
            self.count_error = weighted_avg(self.count_error,
                                            other.count_error)
            self.gt_count = total_gt_count

        if other.conf_mat is not None:
            if self.class_name == 'average':
                if self.conf_mat is None:
                    # Make first row all zeros so that the array indices
                    # correspond to valid class ids (ie. >= 1).
                    self.conf_mat = np.concatenate(
                        [
                            np.zeros_like(other.conf_mat)[np.newaxis, :],
                            np.array(other.conf_mat)[np.newaxis, :]
                        ],
                        axis=0)
                else:
                    self.conf_mat = np.concatenate(
                        [self.conf_mat, other.conf_mat[np.newaxis, :]], axis=0)
            else:
                self.conf_mat += other.conf_mat

</source>
</class>

<class classid="82" nclones="2" nlines="28" similarity="77">
<source file="systems/raster-vision-0.11.0/rastervision/task/semantic_segmentation.py" startline="98" endline="154" pcid="1119">
    def make_chips(self, train_scenes, validation_scenes, augmentors, tmp_dir):
        """Make training chips.

        Convert Scenes with a ground_truth_label_store into training
        chips in MLBackend-specific format, and write to URI specified in
        options.

        Args:
            train_scenes: list of Scenes
            validation_scenes: list of Scenes
                (that is disjoint from train_scenes)
            augmentors: Augmentors used to augment training data
        """

        def _process_scene(scene, type_, augment):
            with scene.activate():
                data = TrainingData()
                log.info('Making {} chips for scene: {}'.format(
                    type_, scene.id))
                windows = self.get_train_windows(scene)
                for window in windows:
                    chip = scene.raster_source.get_chip(window)
                    labels = self.get_train_labels(window, scene)

                    # If chip has ignore labels, fill in those pixels with
                    # nodata.
                    label_arr = labels.get_label_arr(window)
                    zero_inds = label_arr.ravel() == 0
                    chip_shape = chip.shape
                    if np.any(zero_inds):
                        chip = np.reshape(chip, (-1, chip.shape[2]))
                        chip[zero_inds, :] = 0
                        chip = np.reshape(chip, chip_shape)

                    data.append(chip, window, labels)
                # Shuffle data so the first N samples which are displayed in
                # Tensorboard are more diverse.
                data.shuffle()

                # Process augmentation
                if augment:
                    for augmentor in augmentors:
                        data = augmentor.process(data, tmp_dir)

                return self.backend.process_scene_data(scene, data, tmp_dir)

        def _process_scenes(scenes, type_, augment):
            return [_process_scene(scene, type_, augment) for scene in scenes]

        processed_training_results = _process_scenes(
            train_scenes, TRAIN, augment=True)
        processed_validation_results = _process_scenes(
            validation_scenes, VALIDATION, augment=False)

        self.backend.process_sceneset_results(
            processed_training_results, processed_validation_results, tmp_dir)

</source>
<source file="systems/raster-vision-0.11.0/rastervision/task/task.py" startline="88" endline="133" pcid="1154">
    def make_chips(self, train_scenes, validation_scenes, augmentors, tmp_dir):
        """Make training chips.

        Convert Scenes with a ground_truth_label_store into training
        chips in MLBackend-specific format, and write to URI specified in
        options.

        Args:
            train_scenes: list of Scenes
            validation_scenes: list of Scenes
                (that is disjoint from train_scenes)
            augmentors: Augmentors used to augment training data
        """

        def _process_scene(scene, type_, augment):
            with scene.activate():
                data = TrainingData()
                log.info('Making {} chips for scene: {}'.format(
                    type_, scene.id))
                windows = self.get_train_windows(scene)
                for window in windows:
                    chip = scene.raster_source.get_chip(window)
                    labels = self.get_train_labels(window, scene)
                    data.append(chip, window, labels)
                # Shuffle data so the first N samples which are displayed in
                # Tensorboard are more diverse.
                data.shuffle()

                # Process augmentation
                if augment:
                    for augmentor in augmentors:
                        data = augmentor.process(data, tmp_dir)

                return self.backend.process_scene_data(scene, data, tmp_dir)

        def _process_scenes(scenes, type_, augment):
            return [_process_scene(scene, type_, augment) for scene in scenes]

        processed_training_results = _process_scenes(
            train_scenes, TRAIN, augment=True)
        processed_validation_results = _process_scenes(
            validation_scenes, VALIDATION, augment=False)

        self.backend.process_sceneset_results(
            processed_training_results, processed_validation_results, tmp_dir)

</source>
</class>

<class classid="83" nclones="2" nlines="19" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/task/object_detection.py" startline="11" endline="41" pcid="1138">
def _make_chip_pos_windows(image_extent, label_store, chip_size):
    chip_size = chip_size
    pos_windows = []
    boxes = label_store.get_labels().get_boxes()
    done_boxes = set()

    # Get a random window around each box. If a box was previously included
    # in a window, then it is skipped.
    for box in boxes:
        if box.tuple_format() not in done_boxes:
            # If this  object is bigger than the chip,
            # don't use this box.
            if chip_size < box.get_width() or chip_size < box.get_height():
                log.warning('Label is larger than chip size: {} '
                            'Skipping this label'.format(box.tuple_format()))
                continue

            window = box.make_random_square_container(chip_size)
            pos_windows.append(window)

            # Get boxes that lie completely within window
            window_boxes = label_store.get_labels(window=window)
            window_boxes = ObjectDetectionLabels.get_overlapping(
                window_boxes, window, ioa_thresh=1.0)
            window_boxes = window_boxes.get_boxes()
            window_boxes = [box.tuple_format() for box in window_boxes]
            done_boxes.update(window_boxes)

    return pos_windows


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/rv_pipeline/object_detection.py" startline="14" endline="44" pcid="1967">
def _make_chip_pos_windows(image_extent, label_store, chip_size):
    chip_size = chip_size
    pos_windows = []
    boxes = label_store.get_labels().get_boxes()
    done_boxes = set()

    # Get a random window around each box. If a box was previously included
    # in a window, then it is skipped.
    for box in boxes:
        if box.tuple_format() not in done_boxes:
            # If this  object is bigger than the chip,
            # don't use this box.
            if chip_size < box.get_width() or chip_size < box.get_height():
                log.warning('Label is larger than chip size: {} '
                            'Skipping this label'.format(box.tuple_format()))
                continue

            window = box.make_random_square_container(chip_size)
            pos_windows.append(window)

            # Get boxes that lie completely within window
            window_boxes = label_store.get_labels(window=window)
            window_boxes = ObjectDetectionLabels.get_overlapping(
                window_boxes, window, ioa_thresh=1.0)
            window_boxes = window_boxes.get_boxes()
            window_boxes = [box.tuple_format() for box in window_boxes]
            done_boxes.update(window_boxes)

    return pos_windows


</source>
</class>

<class classid="84" nclones="2" nlines="17" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/task/object_detection.py" startline="61" endline="83" pcid="1141">
def make_neg_windows(raster_source, label_store, chip_size, nb_windows,
                     max_attempts, filter_windows):
    extent = raster_source.get_extent()
    neg_windows = []
    for _ in range(max_attempts):
        for _ in range(max_attempts):
            window = extent.make_random_square(chip_size)
            if any(filter_windows([window])):
                break
        chip = raster_source.get_chip(window)
        labels = ObjectDetectionLabels.get_overlapping(
            label_store.get_labels(), window, ioa_thresh=0.2)

        # If no labels and not blank, append the chip
        if len(labels) == 0 and np.sum(chip.ravel()) > 0:
            neg_windows.append(window)

        if len(neg_windows) == nb_windows:
            break

    return list(neg_windows)


</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/rv_pipeline/object_detection.py" startline="64" endline="86" pcid="1970">
def make_neg_windows(raster_source, label_store, chip_size, nb_windows,
                     max_attempts, filter_windows):
    extent = raster_source.get_extent()
    neg_windows = []
    for _ in range(max_attempts):
        for _ in range(max_attempts):
            window = extent.make_random_square(chip_size)
            if any(filter_windows([window])):
                break
        chip = raster_source.get_chip(window)
        labels = ObjectDetectionLabels.get_overlapping(
            label_store.get_labels(), window, ioa_thresh=0.2)

        # If no labels and not blank, append the chip
        if len(labels) == 0 and np.sum(chip.ravel()) > 0:
            neg_windows.append(window)

        if len(neg_windows) == nb_windows:
            break

    return list(neg_windows)


</source>
</class>

<class classid="85" nclones="2" nlines="21" similarity="80">
<source file="systems/raster-vision-0.11.0/rastervision/task/semantic_segmentation_config.py" startline="56" endline="80" pcid="1166">
    def to_proto(self):
        msg = super().to_proto()
        chip_options = TaskConfigMsg.SemanticSegmentationConfig.ChipOptions(
            window_method=self.chip_options.window_method,
            target_classes=self.chip_options.target_classes,
            debug_chip_probability=self.chip_options.debug_chip_probability,
            negative_survival_probability=self.chip_options.
            negative_survival_probability,
            chips_per_scene=self.chip_options.chips_per_scene,
            target_count_threshold=self.chip_options.target_count_threshold,
            stride=self.chip_options.stride)

        conf = TaskConfigMsg.SemanticSegmentationConfig(
            chip_size=self.chip_size,
            predict_chip_size=self.predict_chip_size,
            class_items=self.class_map.to_proto(),
            chip_options=chip_options)
        msg.MergeFrom(
            TaskConfigMsg(
                semantic_segmentation_config=conf,
                predict_package_uri=self.predict_package_uri))

        return msg


</source>
<source file="systems/raster-vision-0.11.0/rastervision/task/object_detection_config.py" startline="48" endline="71" pcid="1191">
    def to_proto(self):
        msg = super().to_proto()
        chip_options = TaskConfigMsg.ObjectDetectionConfig.ChipOptions(
            neg_ratio=self.chip_options.neg_ratio,
            ioa_thresh=self.chip_options.ioa_thresh,
            window_method=self.chip_options.window_method,
            label_buffer=self.chip_options.label_buffer)

        predict_options = TaskConfigMsg.ObjectDetectionConfig.PredictOptions(
            merge_thresh=self.predict_options.merge_thresh,
            score_thresh=self.predict_options.score_thresh)

        conf = TaskConfigMsg.ObjectDetectionConfig(
            chip_size=self.chip_size,
            class_items=self.class_map.to_proto(),
            chip_options=chip_options,
            predict_options=predict_options)
        msg.MergeFrom(
            TaskConfigMsg(
                object_detection_config=conf,
                predict_package_uri=self.predict_package_uri))

        return msg

</source>
</class>

<class classid="86" nclones="2" nlines="13" similarity="92">
<source file="systems/raster-vision-0.11.0/rastervision/task/chip_classification.py" startline="32" endline="45" pcid="1202">
    def get_train_windows(self, scene):
        result = []
        extent = scene.raster_source.get_extent()
        chip_size = self.config.chip_size
        stride = chip_size
        windows = extent.get_windows(chip_size, stride)
        if scene.aoi_polygons:
            windows = Box.filter_by_aoi(windows, scene.aoi_polygons)
        for window in windows:
            chip = scene.raster_source.get_chip(window)
            if np.sum(chip.ravel()) > 0:
                result.append(window)
        return result

</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/rv_pipeline/chip_classification.py" startline="11" endline="24" pcid="1977">
def get_train_windows(scene, chip_size):
    train_windows = []
    extent = scene.raster_source.get_extent()
    stride = chip_size
    windows = extent.get_windows(chip_size, stride)
    if scene.aoi_polygons:
        windows = Box.filter_by_aoi(windows, scene.aoi_polygons)
    for window in windows:
        chip = scene.raster_source.get_chip(window)
        if np.sum(chip.ravel()) > 0:
            train_windows.append(window)
    return train_windows


</source>
</class>

<class classid="87" nclones="2" nlines="48" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/core/raster_stats.py" startline="59" endline="137" pcid="1225">
    def compute(self, raster_sources, sample_prob=None):
        """Compute the mean and stds over all the raster_sources.

        This ignores NODATA values.

        If sample_prob is set, then a subset of each scene is used to compute stats which
        speeds up the computation. Roughly speaking, if sample_prob=0.5, then half the
        pixels in the scene will be used. More precisely, the number of chips is equal to
        sample_prob * (width * height / 300^2), or 1, whichever is greater. Each chip is
        uniformly sampled from the scene with replacement. Otherwise, it uses a sliding
        window over the entire scene to compute stats.

        Args:
            raster_sources: list of RasterSource
            sample_prob: (float or None) between 0 and 1
        """
        stride = chip_size
        nb_channels = raster_sources[0].num_channels

        def get_chip(raster_source, window):
            """Return chip or None if all values are NODATA."""
            chip = raster_source.get_raw_chip(window).astype(np.float32)
            # Convert shape from [h,w,c] to [c,h*w]
            chip = np.reshape(np.transpose(chip, [2, 0, 1]), (nb_channels, -1))

            # Ignore NODATA values.
            chip[chip == 0.0] = np.nan
            if np.any(~np.isnan(chip)):
                return chip
            return None

        def sliding_chip_stream():
            """Get stream of chips using a sliding window of size 300."""
            for raster_source in raster_sources:
                with raster_source.activate():
                    windows = raster_source.get_extent().get_windows(
                        chip_size, stride)
                    for window in windows:
                        chip = get_chip(raster_source, window)
                        if chip is not None:
                            yield chip

        def random_chip_stream():
            """Get random stream of chips."""
            for raster_source in raster_sources:
                with raster_source.activate():
                    extent = raster_source.get_extent()
                    num_pixels = extent.get_width() * extent.get_height()
                    num_chips = round(
                        sample_prob * (num_pixels / (chip_size**2)))
                    num_chips = max(1, num_chips)
                    for _ in range(num_chips):
                        window = raster_source.get_extent().make_random_square(
                            chip_size)
                        chip = get_chip(raster_source, window)
                        if chip is not None:
                            yield chip

        # For each chip, compute the mean and var of that chip and then update the
        # running mean and var.
        count = 0
        mean = np.zeros((nb_channels, ))
        var = np.zeros((nb_channels, ))
        chip_stream = (sliding_chip_stream()
                       if sample_prob is None else random_chip_stream())

        for c in chip_stream:
            chip_means = np.nanmean(c, axis=1)
            chip_vars = np.nanvar(c, axis=1)
            chip_count = np.sum(c[0] != np.nan)

            var = parallel_variance(chip_means, chip_count, chip_vars, mean,
                                    count, var)
            mean = parallel_mean(chip_means, chip_count, mean, count)
            count += chip_count

        self.means = mean
        self.stds = np.sqrt(var)

</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/raster_stats.py" startline="59" endline="137" pcid="1615">
    def compute(self, raster_sources, sample_prob=None):
        """Compute the mean and stds over all the raster_sources.

        This ignores NODATA values.

        If sample_prob is set, then a subset of each scene is used to compute stats which
        speeds up the computation. Roughly speaking, if sample_prob=0.5, then half the
        pixels in the scene will be used. More precisely, the number of chips is equal to
        sample_prob * (width * height / 300^2), or 1, whichever is greater. Each chip is
        uniformly sampled from the scene with replacement. Otherwise, it uses a sliding
        window over the entire scene to compute stats.

        Args:
            raster_sources: list of RasterSource
            sample_prob: (float or None) between 0 and 1
        """
        stride = chip_sz
        nb_channels = raster_sources[0].num_channels

        def get_chip(raster_source, window):
            """Return chip or None if all values are NODATA."""
            chip = raster_source.get_raw_chip(window).astype(np.float32)
            # Convert shape from [h,w,c] to [c,h*w]
            chip = np.reshape(np.transpose(chip, [2, 0, 1]), (nb_channels, -1))

            # Ignore NODATA values.
            chip[chip == 0.0] = np.nan
            if np.any(~np.isnan(chip)):
                return chip
            return None

        def sliding_chip_stream():
            """Get stream of chips using a sliding window of size 300."""
            for raster_source in raster_sources:
                with raster_source.activate():
                    windows = raster_source.get_extent().get_windows(
                        chip_sz, stride)
                    for window in windows:
                        chip = get_chip(raster_source, window)
                        if chip is not None:
                            yield chip

        def random_chip_stream():
            """Get random stream of chips."""
            for raster_source in raster_sources:
                with raster_source.activate():
                    extent = raster_source.get_extent()
                    num_pixels = extent.get_width() * extent.get_height()
                    num_chips = round(
                        sample_prob * (num_pixels / (chip_sz**2)))
                    num_chips = max(1, num_chips)
                    for _ in range(num_chips):
                        window = raster_source.get_extent().make_random_square(
                            chip_sz)
                        chip = get_chip(raster_source, window)
                        if chip is not None:
                            yield chip

        # For each chip, compute the mean and var of that chip and then update the
        # running mean and var.
        count = 0
        mean = np.zeros((nb_channels, ))
        var = np.zeros((nb_channels, ))
        chip_stream = (sliding_chip_stream()
                       if sample_prob is None else random_chip_stream())

        for c in chip_stream:
            chip_means = np.nanmean(c, axis=1)
            chip_vars = np.nanvar(c, axis=1)
            chip_count = np.sum(c[0] != np.nan)

            var = parallel_variance(chip_means, chip_count, chip_vars, mean,
                                    count, var)
            mean = parallel_mean(chip_means, chip_count, mean, count)
            count += chip_count

        self.means = mean
        self.stds = np.sqrt(var)

</source>
</class>

<class classid="88" nclones="2" nlines="12" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/core/box.py" startline="102" endline="124" pcid="1275">
    def make_random_square_container(self, size):
        """Return a new square Box that contains this Box.

        Args:
            size: the width and height of the new Box

        """
        if size < self.get_width():
            raise BoxSizeError('size of random container cannot be < width')

        if size < self.get_height():  # pragma: no cover
            raise BoxSizeError('size of random container cannot be < height')

        lb = self.ymin - (size - self.get_height())
        ub = self.ymin
        rand_y = random.randint(int(lb), int(ub))

        lb = self.xmin - (size - self.get_width())
        ub = self.xmin
        rand_x = random.randint(int(lb), int(ub))

        return Box.make_square(rand_y, rand_x, size)

</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/box.py" startline="102" endline="124" pcid="1888">
    def make_random_square_container(self, size):
        """Return a new square Box that contains this Box.

        Args:
            size: the width and height of the new Box

        """
        if size < self.get_width():
            raise BoxSizeError('size of random container cannot be < width')

        if size < self.get_height():  # pragma: no cover
            raise BoxSizeError('size of random container cannot be < height')

        lb = self.ymin - (size - self.get_height())
        ub = self.ymin
        rand_y = random.randint(int(lb), int(ub))

        lb = self.xmin - (size - self.get_width())
        ub = self.xmin
        rand_x = random.randint(int(lb), int(ub))

        return Box.make_square(rand_y, rand_x, size)

</source>
</class>

<class classid="89" nclones="2" nlines="12" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/core/box.py" startline="125" endline="147" pcid="1276">
    def make_random_square(self, size):
        """Return new randomly positioned square Box that lies inside this Box.

        Args:
            size: the height and width of the new Box

        """
        if size >= self.get_width():
            raise BoxSizeError('size of random square cannot be >= width')

        if size >= self.get_height():  # pragma: no cover
            raise BoxSizeError('size of random square cannot be >= height')

        lb = self.ymin
        ub = self.ymax - size
        rand_y = random.randint(int(lb), int(ub))

        lb = self.xmin
        ub = self.xmax - size
        rand_x = random.randint(int(lb), int(ub))

        return Box.make_square(rand_y, rand_x, size)

</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/box.py" startline="125" endline="147" pcid="1889">
    def make_random_square(self, size):
        """Return new randomly positioned square Box that lies inside this Box.

        Args:
            size: the height and width of the new Box

        """
        if size >= self.get_width():
            raise BoxSizeError('size of random square cannot be >= width')

        if size >= self.get_height():  # pragma: no cover
            raise BoxSizeError('size of random square cannot be >= height')

        lb = self.ymin
        ub = self.ymax - size
        rand_y = random.randint(int(lb), int(ub))

        lb = self.xmin
        ub = self.xmax - size
        rand_x = random.randint(int(lb), int(ub))

        return Box.make_square(rand_y, rand_x, size)

</source>
</class>

<class classid="90" nclones="2" nlines="14" similarity="100">
<source file="systems/raster-vision-0.11.0/rastervision/core/box.py" startline="214" endline="236" pcid="1285">
    def make_buffer(self, buffer_size, max_extent):
        """Return new Box whose sides are buffered by buffer_size.

        The resulting box is clipped so that the values of the corners are
        always greater than zero and less than the height and width of
        max_extent.

        """
        buffer_size = max(0., buffer_size)
        if buffer_size < 1.:
            delta_width = int(round(buffer_size * self.get_width()))
            delta_height = int(round(buffer_size * self.get_height()))
        else:
            delta_height = delta_width = int(round(buffer_size))

        return Box(
            max(0, math.floor(self.ymin - delta_height)),
            max(0, math.floor(self.xmin - delta_width)),
            min(max_extent.get_height(),
                int(self.ymax) + delta_height),
            min(max_extent.get_width(),
                int(self.xmax) + delta_width))

</source>
<source file="systems/raster-vision-0.11.0/rastervision2/core/box.py" startline="214" endline="236" pcid="1898">
    def make_buffer(self, buffer_sz, max_extent):
        """Return new Box whose sides are buffered by buffer_sz.

        The resulting box is clipped so that the values of the corners are
        always greater than zero and less than the height and width of
        max_extent.

        """
        buffer_sz = max(0., buffer_sz)
        if buffer_sz < 1.:
            delta_width = int(round(buffer_sz * self.get_width()))
            delta_height = int(round(buffer_sz * self.get_height()))
        else:
            delta_height = delta_width = int(round(buffer_sz))

        return Box(
            max(0, math.floor(self.ymin - delta_height)),
            max(0, math.floor(self.xmin - delta_width)),
            min(max_extent.get_height(),
                int(self.ymax) + delta_height),
            min(max_extent.get_width(),
                int(self.xmax) + delta_width))

</source>
</class>

<class classid="91" nclones="2" nlines="16" similarity="81">
<source file="systems/raster-vision-0.11.0/rastervision2/pytorch_learner/examples/classification.py" startline="10" endline="26" pcid="1364">
def get_config(runner, test=False):
    base_uri = ('s3://raster-vision-lf-dev/learner/classification' if
                runner == 'aws_batch' else '/opt/data/learner/classification')
    root_uri = join(base_uri, 'output')
    data_uri = join(base_uri, 'tiny-buildings.zip')

    model = ModelConfig(backbone='resnet50')
    solver = SolverConfig(lr=2e-4, num_epochs=3, batch_sz=8, one_cycle=True)
    data = ClassificationDataConfig(
        data_format='image_folder',
        uri=data_uri,
        img_sz=200,
        labels=['building', 'no_building'])
    learner = ClassificationLearnerConfig(
        model=model, solver=solver, data=data, test_mode=test)
    pipeline = LearnerPipelineConfig(root_uri=root_uri, learner=learner)
    return pipeline
</source>
<source file="systems/raster-vision-0.11.0/rastervision2/pytorch_learner/examples/regression.py" startline="9" endline="26" pcid="1365">
def get_config(runner, test=False):
    base_uri = ('s3://raster-vision-lf-dev/learner/regression'
                if runner == 'aws_batch' else '/opt/data/learner/regression')
    root_uri = join(base_uri, 'output')
    data_uri = join(base_uri, 'tiny-buildings.zip')

    model = RegressionModelConfig(backbone='resnet50')
    solver = SolverConfig(lr=1e-4, num_epochs=10, batch_sz=8, one_cycle=True)
    data = RegressionDataConfig(
        data_format='image_csv',
        uri=data_uri,
        img_sz=200,
        labels=['has_buildings'])
    learner = RegressionLearnerConfig(
        model=model, solver=solver, data=data, test_mode=test)

    pipeline = LearnerPipelineConfig(root_uri=root_uri, learner=learner)
    return pipeline
</source>
</class>

<class classid="92" nclones="2" nlines="33" similarity="76">
<source file="systems/raster-vision-0.11.0/rastervision2/pytorch_learner/classification_learner.py" startline="32" endline="71" pcid="1367">
    def _get_datasets(self, uri):
        cfg = self.cfg
        class_names = cfg.data.class_names

        if cfg.data.data_format == ClassificationDataFormat.image_folder:
            data_dirs = self.unzip_data(uri)

        transform, aug_transform = self.get_data_transforms()

        train_ds, valid_ds, test_ds = [], [], []
        for data_dir in data_dirs:
            train_dir = join(data_dir, 'train')
            valid_dir = join(data_dir, 'valid')

            if isdir(train_dir):
                if cfg.overfit_mode:
                    train_ds.append(
                        AlbumentationsDataset(
                            ImageFolder(train_dir, classes=class_names),
                            transform=transform))
                else:
                    train_ds.append(
                        AlbumentationsDataset(
                            ImageFolder(train_dir, classes=class_names),
                            transform=aug_transform))

            if isdir(valid_dir):
                valid_ds.append(
                    AlbumentationsDataset(
                        ImageFolder(valid_dir, classes=class_names),
                        transform=transform))
                test_ds.append(
                    AlbumentationsDataset(
                        ImageFolder(valid_dir, classes=class_names),
                        transform=transform))

        train_ds, valid_ds, test_ds = \
            ConcatDataset(train_ds), ConcatDataset(valid_ds), ConcatDataset(test_ds)

        return train_ds, valid_ds, test_ds
</source>
<source file="systems/raster-vision-0.11.0/rastervision2/pytorch_learner/regression_learner.py" startline="86" endline="125" pcid="1412">
    def _get_datasets(self, uri):
        cfg = self.cfg
        data_dirs = self.unzip_data(uri)
        transform, aug_transform = self.get_data_transforms()

        train_ds, valid_ds, test_ds = [], [], []
        for data_dir in data_dirs:
            train_dir = join(data_dir, 'train')
            valid_dir = join(data_dir, 'valid')

            if isdir(train_dir):
                if cfg.overfit_mode:
                    train_ds.append(
                        AlbumentationsDataset(
                            ImageRegressionDataset(train_dir,
                                                   cfg.data.class_names),
                            transform=transform))
                else:
                    train_ds.append(
                        AlbumentationsDataset(
                            ImageRegressionDataset(train_dir,
                                                   cfg.data.class_names),
                            transform=aug_transform))

            if isdir(valid_dir):
                valid_ds.append(
                    AlbumentationsDataset(
                        ImageRegressionDataset(valid_dir,
                                               cfg.data.class_names),
                        transform=transform))
                test_ds.append(
                    AlbumentationsDataset(
                        ImageRegressionDataset(valid_dir,
                                               cfg.data.class_names),
                        transform=transform))

        train_ds, valid_ds, test_ds = \
            ConcatDataset(train_ds), ConcatDataset(valid_ds), ConcatDataset(test_ds)

        return train_ds, valid_ds, test_ds
</source>
</class>

<class classid="93" nclones="2" nlines="10" similarity="100">
<source file="systems/raster-vision-0.11.0/tests_v2/pipeline/test_utils.py" startline="7" endline="22" pcid="1991">
    def test_split_into_groups(self):
        lst = [1, 2, 3, 4, 5, 6]

        g1 = split_into_groups(lst[:5], 3)
        self.assertEqual(g1, [[1, 2], [3, 4], [5]])

        g2 = split_into_groups(lst, 7)
        self.assertEqual(g2, [[1], [2], [3], [4], [5], [6]])

        g3 = split_into_groups(lst[0:1], 7)
        self.assertEqual(g3, [[1]])

        g4 = split_into_groups(lst, 3)
        self.assertEqual(g4, [[1, 2], [3, 4], [5, 6]])


</source>
<source file="systems/raster-vision-0.11.0/tests/utils/test_misc.py" startline="213" endline="226" pcid="2743">
    def test_split_into_groups(self):
        lst = [1, 2, 3, 4, 5, 6]

        g1 = split_into_groups(lst[:5], 3)
        self.assertEqual(g1, [[1, 2], [3, 4], [5]])

        g2 = split_into_groups(lst, 7)
        self.assertEqual(g2, [[1], [2], [3], [4], [5], [6]])

        g3 = split_into_groups(lst[0:1], 7)
        self.assertEqual(g3, [[1]])

        g4 = split_into_groups(lst, 3)
        self.assertEqual(g4, [[1, 2], [3, 4], [5, 6]])
</source>
</class>

<class classid="94" nclones="6" nlines="11" similarity="81">
<source file="systems/raster-vision-0.11.0/tests_v2/pipeline/test_file_system.py" startline="136" endline="150" pcid="2005">
    def setUp(self):
        # Setup mock S3 bucket.
        self.mock_s3 = mock_s3()
        self.mock_s3.start()
        self.s3 = boto3.client('s3')
        self.bucket_name = 'mock_bucket'
        self.s3.create_bucket(Bucket=self.bucket_name)

        self.content_str = 'hello'
        self.file_name = 'hello.txt'
        self.s3_path = 's3://{}/{}'.format(self.bucket_name, self.file_name)

        self.tmp_dir = rv_config.get_tmp_dir()
        self.local_path = os.path.join(self.tmp_dir.name, self.file_name)

</source>
<source file="systems/raster-vision-0.11.0/tests_v2/pipeline/test_file_system.py" startline="459" endline="471" pcid="2039">
    def setUp(self):
        # Setup mock S3 bucket.
        self.mock_s3 = mock_s3()
        self.mock_s3.start()
        self.s3 = boto3.client('s3')
        self.bucket_name = 'mock_bucket'
        self.s3.create_bucket(Bucket=self.bucket_name)

        self.content_str = 'hello'
        self.file_name = 'hello.txt'
        self.tmp_dir = rv_config.get_tmp_dir()
        self.cache_dir = os.path.join(self.tmp_dir.name, 'cache')

</source>
<source file="systems/raster-vision-0.11.0/tests/utils/test_files.py" startline="529" endline="541" pcid="2804">
    def setUp(self):
        # Setup mock S3 bucket.
        self.mock_s3 = mock_s3()
        self.mock_s3.start()
        self.s3 = boto3.client('s3')
        self.bucket_name = 'mock_bucket'
        self.s3.create_bucket(Bucket=self.bucket_name)

        self.content_str = 'hello'
        self.file_name = 'hello.txt'
        self.temp_dir = RVConfig.get_tmp_dir()
        self.cache_dir = os.path.join(self.temp_dir.name, 'cache')

</source>
<source file="systems/raster-vision-0.11.0/tests_v2/pipeline/test_file_system.py" startline="181" endline="195" pcid="2009">
    def setUp(self):
        # Setup mock S3 bucket.
        self.mock_s3 = mock_s3()
        self.mock_s3.start()
        self.s3 = boto3.client('s3')
        self.bucket_name = 'mock_bucket'
        self.s3.create_bucket(Bucket=self.bucket_name)

        self.content_str = 'hello'
        self.file_name = 'hello.txt'
        self.s3_path = 's3://{}/{}'.format(self.bucket_name, self.file_name)

        self.tmp_dir = rv_config.get_tmp_dir()
        self.local_path = os.path.join(self.tmp_dir.name, self.file_name)

</source>
<source file="systems/raster-vision-0.11.0/tests/utils/test_files.py" startline="141" endline="155" pcid="2763">
    def setUp(self):
        # Setup mock S3 bucket.
        self.mock_s3 = mock_s3()
        self.mock_s3.start()
        self.s3 = boto3.client('s3')
        self.bucket_name = 'mock_bucket'
        self.s3.create_bucket(Bucket=self.bucket_name)

        self.content_str = 'hello'
        self.file_name = 'hello.txt'
        self.s3_path = 's3://{}/{}'.format(self.bucket_name, self.file_name)

        self.temp_dir = RVConfig.get_tmp_dir()
        self.local_path = os.path.join(self.temp_dir.name, self.file_name)

</source>
<source file="systems/raster-vision-0.11.0/tests/utils/test_files.py" startline="186" endline="200" pcid="2767">
    def setUp(self):
        # Setup mock S3 bucket.
        self.mock_s3 = mock_s3()
        self.mock_s3.start()
        self.s3 = boto3.client('s3')
        self.bucket_name = 'mock_bucket'
        self.s3.create_bucket(Bucket=self.bucket_name)

        self.content_str = 'hello'
        self.file_name = 'hello.txt'
        self.s3_path = 's3://{}/{}'.format(self.bucket_name, self.file_name)

        self.temp_dir = RVConfig.get_tmp_dir()
        self.local_path = os.path.join(self.temp_dir.name, self.file_name)

</source>
</class>

<class classid="95" nclones="2" nlines="11" similarity="90">
<source file="systems/raster-vision-0.11.0/tests_v2/pipeline/test_file_system.py" startline="209" endline="223" pcid="2012">
    def test_download_if_needed_s3(self):
        with self.assertRaises(NotReadableError):
            file_to_str(self.s3_path)

        str_to_file(self.content_str, self.local_path)
        upload_or_copy(self.local_path, self.s3_path)
        local_path = download_if_needed(self.s3_path, self.tmp_dir.name)
        content_str = file_to_str(local_path)
        self.assertEqual(self.content_str, content_str)

        wrong_path = 's3://wrongpath/x.txt'
        with self.assertRaises(NotWritableError):
            upload_or_copy(local_path, wrong_path)


</source>
<source file="systems/raster-vision-0.11.0/tests/utils/test_files.py" startline="214" endline="228" pcid="2770">
    def test_download_if_needed_s3(self):
        with self.assertRaises(NotReadableError):
            download_if_needed(self.s3_path, self.temp_dir.name)

        str_to_file(self.content_str, self.local_path)
        upload_or_copy(self.local_path, self.s3_path)
        local_path = download_if_needed(self.s3_path, self.temp_dir.name)
        content_str = file_to_str(local_path)
        self.assertEqual(self.content_str, content_str)

        wrong_path = 's3://wrongpath/x.txt'
        with self.assertRaises(NotWritableError):
            upload_or_copy(local_path, wrong_path)


</source>
</class>

<class classid="96" nclones="6" nlines="10" similarity="70">
<source file="systems/raster-vision-0.11.0/tests_v2/pipeline/test_file_system.py" startline="242" endline="255" pcid="2015">
    def test_last_modified_s3(self):
        path = os.path.join(self.tmp_dir.name, 'lorem', 'ipsum1.txt')
        s3_path = 's3://{}/lorem1.txt'.format(self.bucket_name)
        directory = os.path.dirname(path)
        make_dir(directory, check_empty=False)

        fs = FileSystem.get_file_system(s3_path, 'r')

        str_to_file(self.lorem, path)
        upload_or_copy(path, s3_path)
        stamp = fs.last_modified(s3_path)

        self.assertTrue(isinstance(stamp, datetime.datetime))

</source>
<source file="systems/raster-vision-0.11.0/tests/utils/test_files.py" startline="326" endline="338" pcid="2781">
    def test_list_paths_s3(self):
        path = os.path.join(self.temp_dir.name, 'lorem', 'ipsum.txt')
        s3_path = 's3://{}/xxx/lorem.txt'.format(self.bucket_name)
        s3_directory = 's3://{}/xxx/'.format(self.bucket_name)
        directory = os.path.dirname(path)
        make_dir(directory, check_empty=False)

        str_to_file(self.lorem, path)
        upload_or_copy(path, s3_path)

        list_paths(s3_directory)
        self.assertEqual(len(list_paths(s3_directory)), 1)

</source>
<source file="systems/raster-vision-0.11.0/tests/utils/test_files.py" startline="312" endline="325" pcid="2780">
    def test_last_modified_s3(self):
        path = os.path.join(self.temp_dir.name, 'lorem', 'ipsum1.txt')
        s3_path = 's3://{}/lorem1.txt'.format(self.bucket_name)
        directory = os.path.dirname(path)
        make_dir(directory, check_empty=False)

        fs = FileSystem.get_file_system(s3_path, 'r')

        str_to_file(self.lorem, path)
        upload_or_copy(path, s3_path)
        stamp = fs.last_modified(s3_path)

        self.assertTrue(isinstance(stamp, datetime.datetime))

</source>
<source file="systems/raster-vision-0.11.0/tests_v2/pipeline/test_file_system.py" startline="256" endline="268" pcid="2016">
    def test_list_paths_s3(self):
        path = os.path.join(self.tmp_dir.name, 'lorem', 'ipsum.txt')
        s3_path = 's3://{}/xxx/lorem.txt'.format(self.bucket_name)
        s3_directory = 's3://{}/xxx/'.format(self.bucket_name)
        directory = os.path.dirname(path)
        make_dir(directory, check_empty=False)

        str_to_file(self.lorem, path)
        upload_or_copy(path, s3_path)

        list_paths(s3_directory)
        self.assertEqual(len(list_paths(s3_directory)), 1)

</source>
<source file="systems/raster-vision-0.11.0/tests/utils/test_files.py" startline="420" endline="432" pcid="2790">
    def test_copy_to_local(self):
        path1 = os.path.join(self.temp_dir.name, 'lorem', 'ipsum.txt')
        path2 = os.path.join(self.temp_dir.name, 'yyy', 'ipsum.txt')
        dir1 = os.path.dirname(path1)
        dir2 = os.path.dirname(path2)
        make_dir(dir1, check_empty=False)
        make_dir(dir2, check_empty=False)

        str_to_file(self.lorem, path1)

        upload_or_copy(path1, path2)
        self.assertEqual(len(list_paths(dir2)), 1)

</source>
<source file="systems/raster-vision-0.11.0/tests_v2/pipeline/test_file_system.py" startline="350" endline="362" pcid="2025">
    def test_copy_to_local(self):
        path1 = os.path.join(self.tmp_dir.name, 'lorem', 'ipsum.txt')
        path2 = os.path.join(self.tmp_dir.name, 'yyy', 'ipsum.txt')
        dir1 = os.path.dirname(path1)
        dir2 = os.path.dirname(path2)
        make_dir(dir1, check_empty=False)
        make_dir(dir2, check_empty=False)

        str_to_file(self.lorem, path1)

        upload_or_copy(path1, path2)
        self.assertEqual(len(list_paths(dir2)), 1)

</source>
</class>

<class classid="97" nclones="2" nlines="14" similarity="100">
<source file="systems/raster-vision-0.11.0/tests_v2/pipeline/test_file_system.py" startline="269" endline="286" pcid="2017">
    def test_file_exists(self):
        path = os.path.join(self.tmp_dir.name, 'lorem', 'ipsum.txt')
        s3_path = 's3://{}/xxx/lorem.txt'.format(self.bucket_name)
        s3_path_prefix = 's3://{}/xxx/lorem'.format(self.bucket_name)
        s3_directory = 's3://{}/xxx/'.format(self.bucket_name)
        make_dir(path, check_empty=False, use_dirname=True)

        str_to_file(self.lorem, path)
        upload_or_copy(path, s3_path)

        self.assertTrue(file_exists(s3_directory, include_dir=True))
        self.assertTrue(file_exists(s3_path, include_dir=False))
        self.assertFalse(file_exists(s3_path_prefix, include_dir=True))
        self.assertFalse(file_exists(s3_directory, include_dir=False))
        self.assertFalse(
            file_exists(s3_directory + 'NOTPOSSIBLE', include_dir=False))


</source>
<source file="systems/raster-vision-0.11.0/tests/utils/test_files.py" startline="339" endline="356" pcid="2782">
    def test_file_exists(self):
        path = os.path.join(self.temp_dir.name, 'lorem', 'ipsum.txt')
        s3_path = 's3://{}/xxx/lorem.txt'.format(self.bucket_name)
        s3_path_prefix = 's3://{}/xxx/lorem'.format(self.bucket_name)
        s3_directory = 's3://{}/xxx/'.format(self.bucket_name)
        make_dir(path, check_empty=False, use_dirname=True)

        str_to_file(self.lorem, path)
        upload_or_copy(path, s3_path)

        self.assertTrue(file_exists(s3_directory, include_dir=True))
        self.assertTrue(file_exists(s3_path, include_dir=False))
        self.assertFalse(file_exists(s3_path_prefix, include_dir=True))
        self.assertFalse(file_exists(s3_directory, include_dir=False))
        self.assertFalse(
            file_exists(s3_directory + 'NOTPOSSIBLE', include_dir=False))


</source>
</class>

<class classid="98" nclones="4" nlines="10" similarity="100">
<source file="systems/raster-vision-0.11.0/tests_v2/pipeline/test_file_system.py" startline="313" endline="325" pcid="2022">
    def test_sync_from_dir_local(self):
        path = os.path.join(self.tmp_dir.name, 'lorem', 'ipsum.txt')
        src = os.path.dirname(path)
        dst = os.path.join(self.tmp_dir.name, 'xxx')
        make_dir(src, check_empty=False)
        make_dir(dst, check_empty=False)

        fs = FileSystem.get_file_system(path, 'r')
        fs.write_bytes(path, bytes([0x00, 0x01]))
        sync_from_dir(src, dst, delete=True)

        self.assertEqual(len(list_paths(dst)), 1)

</source>
<source file="systems/raster-vision-0.11.0/tests/utils/test_files.py" startline="407" endline="419" pcid="2789">
    def test_sync_to_dir_local(self):
        path = os.path.join(self.temp_dir.name, 'lorem', 'ipsum.txt')
        src = os.path.dirname(path)
        dst = os.path.join(self.temp_dir.name, 'xxx')
        make_dir(src, check_empty=False)
        make_dir(dst, check_empty=False)

        fs = FileSystem.get_file_system(path, 'r')
        fs.write_bytes(path, bytes([0x00, 0x01]))
        sync_to_dir(src, dst, delete=True)

        self.assertEqual(len(list_paths(dst)), 1)

</source>
<source file="systems/raster-vision-0.11.0/tests/utils/test_files.py" startline="383" endline="395" pcid="2787">
    def test_sync_from_dir_local(self):
        path = os.path.join(self.temp_dir.name, 'lorem', 'ipsum.txt')
        src = os.path.dirname(path)
        dst = os.path.join(self.temp_dir.name, 'xxx')
        make_dir(src, check_empty=False)
        make_dir(dst, check_empty=False)

        fs = FileSystem.get_file_system(path, 'r')
        fs.write_bytes(path, bytes([0x00, 0x01]))
        sync_from_dir(src, dst, delete=True)

        self.assertEqual(len(list_paths(dst)), 1)

</source>
<source file="systems/raster-vision-0.11.0/tests_v2/pipeline/test_file_system.py" startline="337" endline="349" pcid="2024">
    def test_sync_to_dir_local(self):
        path = os.path.join(self.tmp_dir.name, 'lorem', 'ipsum.txt')
        src = os.path.dirname(path)
        dst = os.path.join(self.tmp_dir.name, 'xxx')
        make_dir(src, check_empty=False)
        make_dir(dst, check_empty=False)

        fs = FileSystem.get_file_system(path, 'r')
        fs.write_bytes(path, bytes([0x00, 0x01]))
        sync_to_dir(src, dst, delete=True)

        self.assertEqual(len(list_paths(dst)), 1)

</source>
</class>

<class classid="99" nclones="2" nlines="11" similarity="100">
<source file="systems/raster-vision-0.11.0/tests_v2/pipeline/test_file_system.py" startline="375" endline="390" pcid="2027">
    def test_file_exists(self):
        fs = FileSystem.get_file_system(self.tmp_dir.name, 'r')

        path1 = os.path.join(self.tmp_dir.name, 'lorem', 'ipsum.txt')
        dir1 = os.path.dirname(path1)
        make_dir(dir1, check_empty=False)

        str_to_file(self.lorem, path1)

        self.assertTrue(fs.file_exists(dir1, include_dir=True))
        self.assertTrue(fs.file_exists(path1, include_dir=False))
        self.assertFalse(fs.file_exists(dir1, include_dir=False))
        self.assertFalse(
            fs.file_exists(dir1 + 'NOTPOSSIBLE', include_dir=False))


</source>
<source file="systems/raster-vision-0.11.0/tests/utils/test_files.py" startline="445" endline="460" pcid="2792">
    def test_file_exists(self):
        fs = FileSystem.get_file_system(self.temp_dir.name, 'r')

        path1 = os.path.join(self.temp_dir.name, 'lorem', 'ipsum.txt')
        dir1 = os.path.dirname(path1)
        make_dir(dir1, check_empty=False)

        str_to_file(self.lorem, path1)

        self.assertTrue(fs.file_exists(dir1, include_dir=True))
        self.assertTrue(fs.file_exists(path1, include_dir=False))
        self.assertFalse(fs.file_exists(dir1, include_dir=False))
        self.assertFalse(
            fs.file_exists(dir1 + 'NOTPOSSIBLE', include_dir=False))


</source>
</class>

<class classid="100" nclones="2" nlines="17" similarity="100">
<source file="systems/raster-vision-0.11.0/tests_v2/pipeline/test_file_system.py" startline="483" endline="503" pcid="2042">
    def test_local_zip(self):
        local_path = os.path.join(self.tmp_dir.name, self.file_name)
        local_gz_path = local_path + '.gz'
        with gzip.open(local_gz_path, 'wb') as f:
            f.write(bytes(self.content_str, encoding='utf-8'))

        with patch('gzip.open', side_effect=gzip.open) as patched_gzip_open:
            path = get_cached_file(self.cache_dir, local_gz_path)
            self.assertTrue(os.path.isfile(path))
            self.assertNotEqual(path, local_gz_path)
            with open(path, 'r') as f:
                self.assertEqual(f.read(), self.content_str)

            # Check that calling it again doesn't invoke the gzip.open method again.
            path = get_cached_file(self.cache_dir, local_gz_path)
            self.assertTrue(os.path.isfile(path))
            self.assertNotEqual(path, local_gz_path)
            with open(path, 'r') as f:
                self.assertEqual(f.read(), self.content_str)
            self.assertEqual(patched_gzip_open.call_count, 1)

</source>
<source file="systems/raster-vision-0.11.0/tests/utils/test_files.py" startline="553" endline="573" pcid="2807">
    def test_local_zip(self):
        local_path = os.path.join(self.temp_dir.name, self.file_name)
        local_gz_path = local_path + '.gz'
        with gzip.open(local_gz_path, 'wb') as f:
            f.write(bytes(self.content_str, encoding='utf-8'))

        with patch('gzip.open', side_effect=gzip.open) as patched_gzip_open:
            path = get_cached_file(self.cache_dir, local_gz_path)
            self.assertTrue(os.path.isfile(path))
            self.assertNotEqual(path, local_gz_path)
            with open(path, 'r') as f:
                self.assertEqual(f.read(), self.content_str)

            # Check that calling it again doesn't invoke the gzip.open method again.
            path = get_cached_file(self.cache_dir, local_gz_path)
            self.assertTrue(os.path.isfile(path))
            self.assertNotEqual(path, local_gz_path)
            with open(path, 'r') as f:
                self.assertEqual(f.read(), self.content_str)
            self.assertEqual(patched_gzip_open.call_count, 1)

</source>
</class>

<class classid="101" nclones="2" nlines="11" similarity="90">
<source file="systems/raster-vision-0.11.0/tests_v2/pipeline/test_file_system.py" startline="504" endline="517" pcid="2043">
    def test_remote(self):
        with patch(
                'rastervision2.pipeline.file_system.utils.download_if_needed',
                side_effect=download_if_needed) as patched_download:
            s3_path = 's3://{}/{}'.format(self.bucket_name, self.file_name)
            str_to_file(self.content_str, s3_path)
            path = get_cached_file(self.cache_dir, s3_path)
            self.assertTrue(os.path.isfile(path))

            # Check that calling it again doesn't invoke the download method again.
            self.assertTrue(os.path.isfile(path))
            self.assertEqual(patched_download.call_count, 1)


</source>
<source file="systems/raster-vision-0.11.0/tests/utils/test_files.py" startline="574" endline="588" pcid="2808">
    def test_remote(self):
        with patch(
                'rastervision.utils.files.download_if_needed',
                side_effect=download_if_needed) as patched_download:
            s3_path = 's3://{}/{}'.format(self.bucket_name, self.file_name)
            str_to_file(self.content_str, s3_path)
            path = get_cached_file(self.cache_dir, s3_path)
            self.assertTrue(os.path.isfile(path))

            # Check that calling it again doesn't invoke the download method again.
            path = get_cached_file(self.cache_dir, s3_path)
            self.assertTrue(os.path.isfile(path))
            self.assertEqual(patched_download.call_count, 1)


</source>
</class>

<class classid="102" nclones="2" nlines="11" similarity="81">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/label_source/test_semantic_segmentation_label_source.py" startline="11" endline="21" pcid="2044">
    def test_enough_target_pixels_true(self):
        data = np.zeros((10, 10, 1), dtype=np.uint8)
        data[4:, 4:, :] = 1
        null_class_id = 2
        raster_source = MockRasterSource([0], 1)
        raster_source.set_raster(data)
        label_source = SemanticSegmentationLabelSource(raster_source, null_class_id)
        with label_source.activate():
            extent = Box(0, 0, 10, 10)
            self.assertTrue(label_source.enough_target_pixels(extent, 30, [1]))

</source>
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/label_source/test_semantic_segmentation_label_source.py" startline="22" endline="33" pcid="2045">
    def test_enough_target_pixels_false(self):
        data = np.zeros((10, 10, 1), dtype=np.uint8)
        data[7:, 7:, :] = 1
        null_class_id = 2
        raster_source = MockRasterSource([0], 1)
        raster_source.set_raster(data)
        label_source = SemanticSegmentationLabelSource(raster_source, null_class_id)
        with label_source.activate():
            extent = Box(0, 0, 10, 10)
            self.assertFalse(
                label_source.enough_target_pixels(extent, 30, [1]))

</source>
</class>

<class classid="103" nclones="5" nlines="13" similarity="71">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/label_source/test_semantic_segmentation_label_source.py" startline="34" endline="47" pcid="2046">
    def test_get_labels(self):
        data = np.zeros((10, 10, 1), dtype=np.uint8)
        data[7:, 7:, 0] = 1
        null_class_id = 2
        raster_source = MockRasterSource([0], 1)
        raster_source.set_raster(data)
        label_source = SemanticSegmentationLabelSource(raster_source, null_class_id)
        with label_source.activate():
            window = Box.make_square(7, 7, 3)
            labels = label_source.get_labels(window=window)
            label_arr = labels.get_label_arr(window)
            expected_label_arr = np.ones((3, 3))
            np.testing.assert_array_equal(label_arr, expected_label_arr)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/label_source/test_semantic_segmentation_label_source.py" startline="39" endline="51" pcid="2603">
    def test_get_labels(self):
        data = np.zeros((10, 10, 1), dtype=np.uint8)
        data[7:, 7:, 0] = 1
        raster_source = MockRasterSource([0, 1, 2], 3)
        raster_source.set_raster(data)
        label_source = SemanticSegmentationLabelSource(source=raster_source)
        with label_source.activate():
            window = Box.make_square(7, 7, 3)
            labels = label_source.get_labels(window=window)
            label_arr = labels.get_label_arr(window)
            expected_label_arr = np.ones((3, 3))
            np.testing.assert_array_equal(label_arr, expected_label_arr)

</source>
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/label_source/test_semantic_segmentation_label_source.py" startline="48" endline="62" pcid="2047">
    def test_get_labels_off_edge(self):
        data = np.zeros((10, 10, 1), dtype=np.uint8)
        data[7:, 7:, 0] = 1
        null_class_id = 2
        raster_source = MockRasterSource([0], 1)
        raster_source.set_raster(data)
        label_source = SemanticSegmentationLabelSource(raster_source, null_class_id)
        with label_source.activate():
            window = Box.make_square(7, 7, 6)
            labels = label_source.get_labels(window=window)
            label_arr = labels.get_label_arr(window)
            expected_label_arr = np.full((6, 6), 2)
            expected_label_arr[0:3, 0:3] = 1
            np.testing.assert_array_equal(label_arr, expected_label_arr)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/label_source/test_semantic_segmentation_label_source.py" startline="52" endline="66" pcid="2604">
    def test_get_labels_rgb(self):
        data = np.zeros((10, 10, 3), dtype=np.uint8)
        data[7:, 7:, :] = [1, 1, 1]
        raster_source = MockRasterSource([0, 1, 2], 3)
        raster_source.set_raster(data)
        rgb_class_map = ClassMap([ClassItem(id=1, color='#010101')])
        label_source = SemanticSegmentationLabelSource(
            source=raster_source, rgb_class_map=rgb_class_map)
        with label_source.activate():
            window = Box.make_square(7, 7, 3)
            labels = label_source.get_labels(window=window)
            label_arr = labels.get_label_arr(window)
            expected_label_arr = np.ones((3, 3))
            np.testing.assert_array_equal(label_arr, expected_label_arr)

</source>
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/label_source/test_semantic_segmentation_label_source.py" startline="63" endline="80" pcid="2048">
    def test_get_labels_rgb(self):
        data = np.zeros((10, 10, 3), dtype=np.uint8)
        data[7:, 7:, :] = [1, 1, 1]
        null_class_id = 2
        raster_source = MockRasterSource([0, 1, 2], 3)
        raster_source.set_raster(data)
        rgb_class_config = ClassConfig(names=['a'], colors=['#010101'])
        rgb_class_config.ensure_null_class()
        label_source = SemanticSegmentationLabelSource(
            raster_source, null_class_id, rgb_class_config=rgb_class_config)
        with label_source.activate():
            window = Box.make_square(7, 7, 3)
            labels = label_source.get_labels(window=window)
            label_arr = labels.get_label_arr(window)
            expected_label_arr = np.zeros((3, 3))
            np.testing.assert_array_equal(label_arr, expected_label_arr)


</source>
</class>

<class classid="104" nclones="2" nlines="44" similarity="89">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/label_source/test_chip_classification_label_source.py" startline="18" endline="71" pcid="2049">
    def setUp(self):
        self.crs_transformer = DoubleCRSTransformer()
        self.geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'type': 'Feature',
                'geometry': {
                    'type':
                    'MultiPolygon',
                    'coordinates': [[[[0., 0.], [0., 2.], [2., 2.], [2., 0.],
                                      [0., 0.]]]]
                },
                'properties': {
                    'class_name': 'car',
                    'class_id': 0,
                    'score': 0.0
                }
            }, {
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[2., 2.], [2., 4.], [4., 4.], [4., 2.],
                                     [2., 2.]]]
                },
                'properties': {
                    'score': 0.0,
                    'class_name': 'house',
                    'class_id': 1
                }
            }]
        }

        self.class_config = ClassConfig(names=['car', 'house'])

        self.box1 = Box.make_square(0, 0, 4)
        self.box2 = Box.make_square(4, 4, 4)
        self.class_id1 = 0
        self.class_id2 = 1
        self.background_class_id = 2

        geoms = []
        for f in self.geojson['features']:
            g = shape(f['geometry'])
            g.class_id = f['properties']['class_id']
            geoms.append(g)
        self.str_tree = STRtree(geoms)

        self.file_name = 'labels.json'
        self.tmp_dir = rv_config.get_tmp_dir()
        self.uri = os.path.join(self.tmp_dir.name, self.file_name)
        json_to_file(self.geojson, self.uri)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/label_source/test_chip_classification_label_source.py" startline="18" endline="77" pcid="2608">
    def setUp(self):
        self.crs_transformer = DoubleCRSTransformer()
        self.geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'type': 'Feature',
                'geometry': {
                    'type':
                    'MultiPolygon',
                    'coordinates': [[[[0., 0.], [0., 2.], [2., 2.], [2., 0.],
                                      [0., 0.]]]]
                },
                'properties': {
                    'class_name': 'car',
                    'class_id': 1,
                    'score': 0.0
                }
            }, {
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[2., 2.], [2., 4.], [4., 4.], [4., 2.],
                                     [2., 2.]]]
                },
                'properties': {
                    'score': 0.0,
                    'class_name': 'house',
                    'class_id': 2
                }
            }]
        }

        self.class_map = ClassMap([ClassItem(1, 'car'), ClassItem(2, 'house')])

        class MockTaskConfig():
            def __init__(self, class_map):
                self.class_map = class_map

        self.task_config = MockTaskConfig(self.class_map)

        self.box1 = Box.make_square(0, 0, 4)
        self.box2 = Box.make_square(4, 4, 4)
        self.class_id1 = 1
        self.class_id2 = 2
        self.background_class_id = 3

        geoms = []
        for f in self.geojson['features']:
            g = shape(f['geometry'])
            g.class_id = f['properties']['class_id']
            geoms.append(g)
        self.str_tree = STRtree(geoms)

        self.file_name = 'labels.json'
        self.temp_dir = RVConfig.get_tmp_dir()
        self.uri = os.path.join(self.temp_dir.name, self.file_name)
        json_to_file(self.geojson, self.uri)

</source>
</class>

<class classid="105" nclones="16" nlines="10" similarity="90">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/label_source/test_chip_classification_label_source.py" startline="75" endline="87" pcid="2051">
    def test_infer_cell1(self):
        # More of box 1 is in cell.
        cell = Box.make_square(0, 0, 3)
        ioa_thresh = 0.5
        use_intersection_over_cell = False
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.class_id1)

</source>
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/label_source/test_chip_classification_label_source.py" startline="88" endline="100" pcid="2052">
    def test_infer_cell2(self):
        # More of box 2 is in cell.
        cell = Box.make_square(1, 1, 3)
        ioa_thresh = 0.5
        use_intersection_over_cell = False
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.class_id2)

</source>
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/label_source/test_chip_classification_label_source.py" startline="101" endline="113" pcid="2053">
    def test_infer_cell3(self):
        # Only box 2 is in cell, but IOA isn't high enough.
        cell = Box.make_square(3, 3, 3)
        ioa_thresh = 0.5
        use_intersection_over_cell = False
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, None)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/label_source/test_chip_classification_label_source.py" startline="94" endline="106" pcid="2612">
    def test_infer_cell2(self):
        # More of box 2 is in cell.
        cell = Box.make_square(1, 1, 3)
        ioa_thresh = 0.5
        use_intersection_over_cell = False
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.class_id2)

</source>
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/label_source/test_chip_classification_label_source.py" startline="114" endline="127" pcid="2054">
    def test_infer_cell4(self):
        # Both boxes inside cell, but using intersection_over_cell,
        # the IOA isn't high enough.
        cell = Box.make_square(0, 0, 10)
        ioa_thresh = 0.5
        use_intersection_over_cell = True
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, None)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/label_source/test_chip_classification_label_source.py" startline="81" endline="93" pcid="2611">
    def test_infer_cell1(self):
        # More of box 1 is in cell.
        cell = Box.make_square(0, 0, 3)
        ioa_thresh = 0.5
        use_intersection_over_cell = False
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.class_id1)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/label_source/test_chip_classification_label_source.py" startline="174" endline="187" pcid="2618">
    def test_infer_cell8(self):
        # box2 overlaps more than box1, but using pick_min_class_id, so
        # picks box1.
        cell = Box.make_square(1, 1, 3)
        ioa_thresh = 0.5
        use_intersection_over_cell = False
        background_class_id = None
        pick_min_class_id = True

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.class_id2)

</source>
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/label_source/test_chip_classification_label_source.py" startline="168" endline="181" pcid="2058">
    def test_infer_cell8(self):
        # box2 overlaps more than box1, but using pick_min_class_id, so
        # picks box1.
        cell = Box.make_square(1, 1, 3)
        ioa_thresh = 0.5
        use_intersection_over_cell = False
        background_class_id = None
        pick_min_class_id = True

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.class_id2)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/label_source/test_chip_classification_label_source.py" startline="134" endline="147" pcid="2615">
    def test_infer_cell5(self):
        # More of box1 in cell, using intersection_over_cell with the
        # IOA high enough.
        cell = Box.make_square(0, 0, 3)
        ioa_thresh = 0.4
        use_intersection_over_cell = True
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.class_id1)

</source>
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/label_source/test_chip_classification_label_source.py" startline="142" endline="154" pcid="2056">
    def test_infer_cell6(self):
        # No boxes overlap enough, use background_class_id
        cell = Box.make_square(0, 0, 10)
        ioa_thresh = 0.5
        use_intersection_over_cell = True
        background_class_id = self.background_class_id
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.background_class_id)

</source>
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/label_source/test_chip_classification_label_source.py" startline="128" endline="141" pcid="2055">
    def test_infer_cell5(self):
        # More of box1 in cell, using intersection_over_cell with the
        # IOA high enough.
        cell = Box.make_square(0, 0, 3)
        ioa_thresh = 0.4
        use_intersection_over_cell = True
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.class_id1)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/label_source/test_chip_classification_label_source.py" startline="161" endline="173" pcid="2617">
    def test_infer_cell7(self):
        # Cell doesn't overlap with any boxes.
        cell = Box.make_square(10, 10, 1)
        ioa_thresh = 0.5
        use_intersection_over_cell = True
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, None)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/label_source/test_chip_classification_label_source.py" startline="148" endline="160" pcid="2616">
    def test_infer_cell6(self):
        # No boxes overlap enough, use background_class_id
        cell = Box.make_square(0, 0, 10)
        ioa_thresh = 0.5
        use_intersection_over_cell = True
        background_class_id = self.background_class_id
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.background_class_id)

</source>
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/label_source/test_chip_classification_label_source.py" startline="155" endline="167" pcid="2057">
    def test_infer_cell7(self):
        # Cell doesn't overlap with any boxes.
        cell = Box.make_square(10, 10, 1)
        ioa_thresh = 0.5
        use_intersection_over_cell = True
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, None)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/label_source/test_chip_classification_label_source.py" startline="120" endline="133" pcid="2614">
    def test_infer_cell4(self):
        # Both boxes inside cell, but using intersection_over_cell,
        # the IOA isn't high enough.
        cell = Box.make_square(0, 0, 10)
        ioa_thresh = 0.5
        use_intersection_over_cell = True
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, None)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/label_source/test_chip_classification_label_source.py" startline="107" endline="119" pcid="2613">
    def test_infer_cell3(self):
        # Only box 2 is in cell, but IOA isn't high enough.
        cell = Box.make_square(3, 3, 3)
        ioa_thresh = 0.5
        use_intersection_over_cell = False
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, None)

</source>
</class>

<class classid="106" nclones="2" nlines="14" similarity="92">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/label_source/test_chip_classification_label_source.py" startline="209" endline="226" pcid="2060">
    def test_get_labels_small_extent(self):
        # Extent only has enough of first box in it.
        extent = Box.make_square(0, 0, 2)

        config = ChipClassificationLabelSourceConfig(
            vector_source=GeoJSONVectorSourceConfig(
                uri=self.uri, default_class_id=None))
        source = config.build(
            self.class_config, self.crs_transformer, extent, self.tmp_dir.name)
        labels = source.get_labels()

        cells = labels.get_cells()
        self.assertEqual(len(cells), 1)
        class_id = labels.get_cell_class_id(self.box1)
        self.assertEqual(class_id, self.class_id1)
        class_id = labels.get_cell_class_id(self.box2)
        self.assertEqual(class_id, None)

</source>
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/label_source/test_chip_classification_label_source.py" startline="227" endline="245" pcid="2061">
    def test_get_labels(self):
        # Extent contains both boxes.
        extent = Box.make_square(0, 0, 8)

        config = ChipClassificationLabelSourceConfig(
            vector_source=GeoJSONVectorSourceConfig(
                uri=self.uri, default_class_id=None))
        source = config.build(
            self.class_config, self.crs_transformer, extent, self.tmp_dir.name)
        labels = source.get_labels()

        cells = labels.get_cells()
        self.assertEqual(len(cells), 2)
        class_id = labels.get_cell_class_id(self.box1)
        self.assertEqual(class_id, self.class_id1)
        class_id = labels.get_cell_class_id(self.box2)
        self.assertEqual(class_id, self.class_id2)


</source>
</class>

<class classid="107" nclones="4" nlines="31" similarity="71">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/label_source/test_object_detection_label_source.py" startline="17" endline="56" pcid="2065">
    def setUp(self):
        self.file_name = 'labels.json'
        self.tmp_dir = rv_config.get_tmp_dir()
        self.file_path = os.path.join(self.tmp_dir.name, self.file_name)

        self.crs_transformer = DoubleCRSTransformer()
        self.geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[0., 0.], [0., 1.], [1., 1.], [1., 0.],
                                     [0., 0.]]]
                },
                'properties': {
                    'class_id': 0,
                    'score': 0.9
                }
            }, {
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[1., 1.], [1., 2.], [2., 2.], [2., 1.],
                                     [1., 1.]]]
                },
                'properties': {
                    'score': 0.9,
                    'class_id': 1
                }
            }]
        }

        self.extent = Box.make_square(0, 0, 10)
        self.class_config = ClassConfig(names=['car', 'house'])
        json_to_file(self.geojson, self.file_path)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/label_store/test_object_detection_geojson_store.py" startline="19" endline="59" pcid="2735">
    def setUp(self):
        self.file_name = 'labels.json'
        self.temp_dir = RVConfig.get_tmp_dir()
        self.file_path = os.path.join(self.temp_dir.name, self.file_name)

        self.crs_transformer = DoubleCRSTransformer()
        self.geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[0., 0.], [0., 1.], [1., 1.], [1., 0.],
                                     [0., 0.]]]
                },
                'properties': {
                    'class_id': 1,
                    'score': 0.9
                }
            }, {
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[1., 1.], [1., 2.], [2., 2.], [2., 1.],
                                     [1., 1.]]]
                },
                'properties': {
                    'score': 0.9,
                    'class_id': 2
                }
            }]
        }

        self.extent = Box.make_square(0, 0, 10)
        self.class_map = ClassMap([ClassItem(1, 'car'), ClassItem(2, 'house')])

        json_to_file(self.geojson, self.file_path)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/label_source/test_object_detection_label_source.py" startline="23" endline="70" pcid="2629">
    def setUp(self):
        self.prev_keys = (os.environ.get('AWS_ACCESS_KEY_ID'),
                          os.environ.get('AWS_SECRET_ACCESS_KEY'))
        os.environ['AWS_ACCESS_KEY_ID'] = 'DUMMY'
        os.environ['AWS_SECRET_ACCESS_KEY'] = 'DUMMY'
        self.mock_s3 = mock_s3()
        self.mock_s3.start()

        self.file_name = 'labels.json'
        self.temp_dir = RVConfig.get_tmp_dir()
        self.file_path = os.path.join(self.temp_dir.name, self.file_name)

        self.crs_transformer = DoubleCRSTransformer()
        self.geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[0., 0.], [0., 1.], [1., 1.], [1., 0.],
                                     [0., 0.]]]
                },
                'properties': {
                    'class_id': 1,
                    'score': 0.9
                }
            }, {
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[1., 1.], [1., 2.], [2., 2.], [2., 1.],
                                     [1., 1.]]]
                },
                'properties': {
                    'score': 0.9,
                    'class_id': 2
                }
            }]
        }

        self.extent = Box.make_square(0, 0, 10)
        self.class_map = ClassMap([ClassItem(1, 'car'), ClassItem(2, 'house')])

        json_to_file(self.geojson, self.file_path)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/label_store/test_chip_classification_geojson_store.py" startline="14" endline="57" pcid="2731">
    def setUp(self):
        self.crs_transformer = DoubleCRSTransformer()
        self.geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[0., 0.], [0., 1.], [1., 1.], [1., 0.],
                                     [0., 0.]]]
                },
                'properties': {
                    'class_name': 'car',
                    'class_id': 1
                }
            }, {
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[1., 1.], [1., 2.], [2., 2.], [2., 1.],
                                     [1., 1.]]]
                },
                'properties': {
                    'class_name': 'house',
                    'class_id': 2
                }
            }]
        }

        self.class_map = ClassMap([ClassItem(1, 'car'), ClassItem(2, 'house')])

        class MockTaskConfig():
            def __init__(self, class_map):
                self.class_map = class_map

        self.task_config = MockTaskConfig(self.class_map)
        self.temp_dir = RVConfig.get_tmp_dir()
        self.uri = os.path.join(self.temp_dir.name, 'labels.json')

        json_to_file(self.geojson, self.uri)

</source>
</class>

<class classid="108" nclones="2" nlines="27" similarity="70">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/label_source/test_object_detection_label_source.py" startline="76" endline="109" pcid="2068">
    def test_read_with_extent(self):
        # Extent only includes the first box.
        extent = Box.make_square(0, 0, 3)
        config = ObjectDetectionLabelSourceConfig(
            vector_source=GeoJSONVectorSourceConfig(
                uri=self.file_path, default_class_id=None))
        source = config.build(
            self.class_config, self.crs_transformer, extent, self.tmp_dir.name)
        labels = source.get_labels()

        npboxes = np.array([[0., 0., 2., 2.]])
        class_ids = np.array([0])
        scores = np.array([0.9])
        expected_labels = ObjectDetectionLabels(
            npboxes, class_ids, scores=scores)
        labels.assert_equal(expected_labels)

        # Extent includes both boxes, but clips the second.
        extent = Box.make_square(0, 0, 3.9)
        config = ObjectDetectionLabelSourceConfig(
            vector_source=GeoJSONVectorSourceConfig(
                uri=self.file_path, default_class_id=None))
        source = config.build(
            self.class_config, self.crs_transformer, extent, self.tmp_dir.name)
        labels = source.get_labels()

        npboxes = np.array([[0., 0., 2., 2.], [2., 2., 3.9, 3.9]])
        class_ids = np.array([0, 1])
        scores = np.array([0.9, 0.9])
        expected_labels = ObjectDetectionLabels(
            npboxes, class_ids, scores=scores)
        labels.assert_equal(expected_labels)


</source>
<source file="systems/raster-vision-0.11.0/tests/data/label_source/test_object_detection_label_source.py" startline="106" endline="138" pcid="2633">
    def test_read_with_extent(self):
        # Extent only includes the first box.
        extent = Box.make_square(0, 0, 3)
        store = ObjectDetectionLabelSource(
            self.file_path,
            self.crs_transformer,
            self.class_map,
            extent=extent)
        labels = store.get_labels()

        npboxes = np.array([[0., 0., 2., 2.]])
        class_ids = np.array([1])
        scores = np.array([0.9])
        expected_labels = ObjectDetectionLabels(
            npboxes, class_ids, scores=scores)
        labels.assert_equal(expected_labels)

        # Extent includes both boxes, but clips the second.
        extent = Box.make_square(0, 0, 3.9)
        store = ObjectDetectionLabelSource(
            self.file_path,
            self.crs_transformer,
            self.class_map,
            extent=extent)
        labels = store.get_labels()

        npboxes = np.array([[0., 0., 2., 2.], [2., 2., 3.9, 3.9]])
        class_ids = np.array([1, 2])
        scores = np.array([0.9, 0.9])
        expected_labels = ObjectDetectionLabels(
            npboxes, class_ids, scores=scores)
        labels.assert_equal(expected_labels)

</source>
</class>

<class classid="109" nclones="2" nlines="12" similarity="91">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/raster_transformer/test_raster_transformer.py" startline="11" endline="28" pcid="2069">
    def test_stats_transformer(self):
        raster_stats = RasterStats()
        raster_stats.means = list(np.ones((4, )))
        raster_stats.stds = list(np.ones((4, )) * 2)

        with rv_config.get_tmp_dir() as tmp_dir:
            stats_uri = os.path.join(tmp_dir, 'stats.json')
            raster_stats.save(stats_uri)

            # All values have z-score of 1, which translates to
            # uint8 value of 170.
            transformer = StatsTransformerConfig(stats_uri=stats_uri).build()
            chip = np.ones((2, 2, 4)) * 3
            out_chip = transformer.transform(chip)
            expected_out_chip = np.ones((2, 2, 4)) * 170
            np.testing.assert_equal(out_chip, expected_out_chip)


</source>
<source file="systems/raster-vision-0.11.0/tests/data/raster_transformer/test_raster_transformer.py" startline="12" endline="29" pcid="2639">
    def test_stats_transformer(self):
        raster_stats = RasterStats()
        raster_stats.means = list(np.ones((4, )))
        raster_stats.stds = list(np.ones((4, )) * 2)

        with RVConfig.get_tmp_dir() as tmp_dir:
            stats_uri = os.path.join(tmp_dir, 'stats.json')
            raster_stats.save(stats_uri)

            # All values have z-score of 1, which translates to
            # uint8 value of 170.
            transformer = rv.RasterTransformerConfig.builder(rv.STATS_TRANSFORMER) \
                                                    .with_stats_uri(stats_uri) \
                                                    .build() \
                                                    .create_transformer()
            chip = np.ones((2, 2, 4)) * 3
            out_chip = transformer.transform(chip)
            expected_out_chip = np.ones((2, 2, 4)) * 170
</source>
</class>

<class classid="110" nclones="4" nlines="24" similarity="76">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/raster_source/test_rasterio_source.py" startline="25" endline="51" pcid="2072">
    def test_nodata_val(self):
        # make geotiff filled with ones and zeros with nodata == 1
        img_path = join(self.tmp_dir, 'tmp.tif')
        height = 100
        width = 100
        nb_channels = 3
        with rasterio.open(
                img_path,
                'w',
                driver='GTiff',
                height=height,
                width=width,
                count=nb_channels,
                dtype=np.uint8,
                nodata=1) as img_dataset:
            im = np.random.randint(
                0, 2, (height, width, nb_channels)).astype(np.uint8)
            for channel in range(nb_channels):
                img_dataset.write(im[:, :, channel], channel + 1)

        config = RasterioSourceConfig(uris=[img_path])
        source = config.build(tmp_dir=self.tmp_dir)
        with source.activate():
            out_chip = source.get_image_array()
            expected_out_chip = np.zeros((height, width, nb_channels))
            np.testing.assert_equal(out_chip, expected_out_chip)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/raster_source/test_rasterio_source.py" startline="20" endline="46" pcid="2640">
    def test_nodata_val(self):
        with RVConfig.get_tmp_dir() as temp_dir:
            # make geotiff filled with ones and zeros with nodata == 1
            image_path = os.path.join(temp_dir, 'temp.tif')
            height = 100
            width = 100
            nb_channels = 3
            with rasterio.open(
                    image_path,
                    'w',
                    driver='GTiff',
                    height=height,
                    width=width,
                    count=nb_channels,
                    dtype=np.uint8,
                    nodata=1) as image_dataset:
                im = np.random.randint(
                    0, 2, (height, width, nb_channels)).astype(np.uint8)
                for channel in range(nb_channels):
                    image_dataset.write(im[:, :, channel], channel + 1)

            source = rv.RasterSourceConfig.builder(rv.RASTERIO_SOURCE) \
                                          .with_uri(image_path) \
                                          .build() \
                                          .create_source(tmp_dir=temp_dir)
            with source.activate():
                out_chip = source.get_image_array()
</source>
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/raster_source/test_rasterio_source.py" startline="52" endline="79" pcid="2073">
    def test_mask(self):
        # make geotiff filled with ones and zeros and mask the whole image
        img_path = join(self.tmp_dir, 'tmp.tif')
        height = 100
        width = 100
        nb_channels = 3
        with rasterio.open(
                img_path,
                'w',
                driver='GTiff',
                height=height,
                width=width,
                count=nb_channels,
                dtype=np.uint8) as img_dataset:
            im = np.random.randint(
                0, 2, (height, width, nb_channels)).astype(np.uint8)
            for channel in range(nb_channels):
                img_dataset.write(im[:, :, channel], channel + 1)
            img_dataset.write_mask(
                np.zeros(im.shape[0:2]).astype(np.bool))

        config = RasterioSourceConfig(uris=[img_path])
        source = config.build(tmp_dir=self.tmp_dir)
        with source.activate():
            out_chip = source.get_image_array()
            expected_out_chip = np.zeros((height, width, nb_channels))
            np.testing.assert_equal(out_chip, expected_out_chip)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/raster_source/test_rasterio_source.py" startline="47" endline="74" pcid="2641">
                expected_out_chip = np.zeros((height, width, nb_channels))
                np.testing.assert_equal(out_chip, expected_out_chip)

    def test_mask(self):
        with RVConfig.get_tmp_dir() as temp_dir:
            # make geotiff filled with ones and zeros and mask the whole image
            image_path = os.path.join(temp_dir, 'temp.tif')
            height = 100
            width = 100
            nb_channels = 3
            with rasterio.open(
                    image_path,
                    'w',
                    driver='GTiff',
                    height=height,
                    width=width,
                    count=nb_channels,
                    dtype=np.uint8) as image_dataset:
                im = np.random.randint(
                    0, 2, (height, width, nb_channels)).astype(np.uint8)
                for channel in range(nb_channels):
                    image_dataset.write(im[:, :, channel], channel + 1)
                image_dataset.write_mask(
                    np.zeros(im.shape[0:2]).astype(np.bool))

            source = rv.RasterSourceConfig.builder(rv.RASTERIO_SOURCE) \
                                          .with_uri(image_path) \
                                          .build() \
</source>
</class>

<class classid="111" nclones="2" nlines="13" similarity="92">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/raster_source/test_rasterio_source.py" startline="96" endline="113" pcid="2076">
    def test_shift_x(self):
        # Specially-engineered image w/ one meter per pixel resolution
        # in the x direction.
        img_path = data_file_path('ones.tif')
        channel_order = [0]

        config = RasterioSourceConfig(
            uris=[img_path], channel_order=channel_order,
            x_shift=1.0, y_shift=0.0)
        source = config.build(tmp_dir=self.tmp_dir)

        with source.activate():
            extent = source.get_extent()
            data = source.get_chip(extent)
            self.assertEqual(data.sum(), 2**16 - 256)
            column = data[:, 255, 0]
            self.assertEqual(column.sum(), 0)

</source>
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/raster_source/test_rasterio_source.py" startline="114" endline="131" pcid="2077">
    def test_shift_y(self):
        # Specially-engineered image w/ one meter per pixel resolution
        # in the y direction.
        img_path = data_file_path('ones.tif')
        channel_order = [0]

        config = RasterioSourceConfig(
            uris=[img_path], channel_order=channel_order,
            x_shift=0.0, y_shift=1.0)
        source = config.build(tmp_dir=self.tmp_dir)

        with source.activate():
            extent = source.get_extent()
            data = source.get_chip(extent)
            self.assertEqual(data.sum(), 2**16 - 256)
            row = data[0, :, 0]
            self.assertEqual(row.sum(), 0)

</source>
</class>

<class classid="112" nclones="2" nlines="15" similarity="73">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/raster_source/test_rasterio_source.py" startline="155" endline="172" pcid="2079">
    def test_uses_channel_order(self):
        img_path = join(self.tmp_dir, 'img.tif')
        chip = np.ones((2, 2, 4)).astype(np.uint8)
        chip[:, :, :] *= np.array([0, 1, 2, 3]).astype(np.uint8)
        save_img(chip, img_path)

        channel_order = [0, 1, 2]
        config = RasterioSourceConfig(
            uris=[img_path], channel_order=channel_order)
        source = config.build(tmp_dir=self.tmp_dir)

        with source.activate():
            out_chip = source.get_image_array()
            expected_out_chip = np.ones((2, 2, 3)).astype(np.uint8)
            expected_out_chip[:, :, :] *= np.array([0, 1,
                                                    2]).astype(np.uint8)
            np.testing.assert_equal(out_chip, expected_out_chip)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/raster_source/test_rasterio_source.py" startline="172" endline="187" pcid="2648">
            stats = RasterStats()
            stats.compute([
                rv.RasterSourceConfig.builder(rv.RASTERIO_SOURCE)
                .with_uri(img_path).build().create_source(temp_dir)
            ])
            stats.save(stats_uri)

            transformer = rv.RasterTransformerConfig.builder(rv.STATS_TRANSFORMER) \
                                                    .with_stats_uri(stats_uri) \
                                                    .build()

            msg = rv.RasterSourceConfig.builder(rv.RASTERIO_SOURCE) \
                                       .with_uri(img_path) \
                                       .with_channel_order(channel_order) \
                                       .with_transformer(transformer) \
                                       .build() \
</source>
</class>

<class classid="113" nclones="2" nlines="15" similarity="80">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/raster_source/test_rasterio_source.py" startline="185" endline="204" pcid="2081">
    def test_detects_alpha(self):
        # Set first channel to alpha. Expectation is that when omitting channel_order,
        # only the second and third channels will be in output.
        img_path = join(self.tmp_dir, 'img.tif')
        chip = np.ones((2, 2, 3)).astype(np.uint8)
        chip[:, :, :] *= np.array([0, 1, 2]).astype(np.uint8)
        save_img(chip, img_path)

        ci = (ColorInterp.alpha, ColorInterp.blue, ColorInterp.green)
        with rasterio.open(img_path, 'r+') as src:
            src.colorinterp = ci

        config = RasterioSourceConfig(uris=[img_path])
        source = config.build(tmp_dir=self.tmp_dir)
        with source.activate():
            out_chip = source.get_image_array()
            expected_out_chip = np.ones((2, 2, 2)).astype(np.uint8)
            expected_out_chip[:, :, :] *= np.array([1, 2]).astype(np.uint8)
            np.testing.assert_equal(out_chip, expected_out_chip)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/raster_source/test_rasterio_source.py" startline="199" endline="218" pcid="2650">
            img_path = os.path.join(tmp_dir, 'img.tif')
            chip = np.ones((2, 2, 4)).astype(np.uint8)
            chip[:, :, :] *= np.array([0, 1, 2, 3]).astype(np.uint8)
            save_img(chip, img_path)

            channel_order = [0, 1, 2]
            source = rv.RasterSourceConfig.builder(rv.RASTERIO_SOURCE) \
                                          .with_uri(img_path) \
                                          .with_channel_order(channel_order) \
                                          .build() \
                                          .create_source(tmp_dir=tmp_dir)
            with source.activate():
                out_chip = source.get_image_array()
                expected_out_chip = np.ones((2, 2, 3)).astype(np.uint8)
                expected_out_chip[:, :, :] *= np.array([0, 1,
                                                        2]).astype(np.uint8)
                np.testing.assert_equal(out_chip, expected_out_chip)

    def test_channel_order_error(self):
        with RVConfig.get_tmp_dir() as tmp_dir:
</source>
</class>

<class classid="114" nclones="2" nlines="14" similarity="78">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/raster_source/test_rasterio_source.py" startline="205" endline="224" pcid="2082">
    def test_non_geo(self):
        # Check if non-georeferenced image files can be read and CRSTransformer
        # implements the identity function.
        img_path = join(self.tmp_dir, 'img.png')
        chip = np.ones((2, 2, 3)).astype(np.uint8)
        save_img(chip, img_path)

        config = RasterioSourceConfig(uris=[img_path])
        source = config.build(tmp_dir=self.tmp_dir)
        with source.activate():
            out_chip = source.get_image_array()
            np.testing.assert_equal(out_chip, chip)

            p = (3, 4)
            out_p = source.get_crs_transformer().map_to_pixel(p)
            np.testing.assert_equal(out_p, p)

            out_p = source.get_crs_transformer().pixel_to_map(p)
            np.testing.assert_equal(out_p, p)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/raster_source/test_rasterio_source.py" startline="225" endline="244" pcid="2652">
            with self.assertRaises(ChannelOrderError):
                rv.RasterSourceConfig.builder(rv.RASTERIO_SOURCE) \
                                     .with_uri(img_path) \
                                     .with_channel_order(channel_order) \
                                     .build() \
                                     .create_source(tmp_dir=tmp_dir)

    def test_detects_alpha(self):
        # Set first channel to alpha. Expectation is that when omitting channel_order,
        # only the second and third channels will be in output.
        with RVConfig.get_tmp_dir() as tmp_dir:
            img_path = os.path.join(tmp_dir, 'img.tif')
            chip = np.ones((2, 2, 3)).astype(np.uint8)
            chip[:, :, :] *= np.array([0, 1, 2]).astype(np.uint8)
            save_img(chip, img_path)

            ci = (ColorInterp.alpha, ColorInterp.blue, ColorInterp.green)
            with rasterio.open(img_path, 'r+') as src:
                src.colorinterp = ci

</source>
</class>

<class classid="115" nclones="2" nlines="24" similarity="87">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/raster_source/test_rasterio_source.py" startline="225" endline="252" pcid="2083">
    def test_no_epsg(self):
        crs = rasterio.crs.CRS()
        img_path = join(self.tmp_dir, 'tmp.tif')
        height = 100
        width = 100
        nb_channels = 3
        with rasterio.open(
                img_path,
                'w',
                driver='GTiff',
                height=height,
                width=width,
                count=nb_channels,
                dtype=np.uint8,
                crs=crs) as img_dataset:
            im = np.zeros((height, width, nb_channels)).astype(np.uint8)
            for channel in range(nb_channels):
                img_dataset.write(im[:, :, channel], channel + 1)

        try:
            config = RasterioSourceConfig(uris=[img_path])
            config.build(tmp_dir=self.tmp_dir)
        except Exception:
            self.fail(
                'Creating RasterioSource with CRS with no EPSG attribute '
                'raised an exception when it should not have.')


</source>
<source file="systems/raster-vision-0.11.0/tests/data/raster_source/test_rasterio_source.py" startline="285" endline="311" pcid="2658">

    def test_with_stats_transformer(self):
        config = rv.RasterSourceConfig.builder(rv.RASTERIO_SOURCE) \
                                      .with_uri('dummy') \
                                      .with_stats_transformer() \
                                      .build()

        self.assertEqual(len(config.transformers), 1)
        self.assertIsInstance(config.transformers[0],
                              rv.data.StatsTransformerConfig)

    def test_missing_config_uri(self):
        with self.assertRaises(rv.ConfigError):
            rv.data.RasterSourceConfig.builder(rv.RASTERIO_SOURCE).build()

    def test_no_missing_config(self):
        try:
            rv.data.RasterSourceConfig.builder(
                rv.RASTERIO_SOURCE).with_uri('').build()
        except rv.ConfigError:
            self.fail('ConfigError raised unexpectedly')

    def test_backcompat_geotiff_source(self):
        msg = RasterSourceMsg()
        uris = ['a', 'b']
        x = 5
        y = 6
</source>
</class>

<class classid="116" nclones="2" nlines="29" similarity="100">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/raster_source/test_rasterized_source.py" startline="41" endline="78" pcid="2087">
    def test_get_chip(self):
        geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[0., 0.], [0., 5.], [5., 5.], [5., 0.],
                                     [0., 0.]]]
                },
                'properties': {
                    'class_id': self.class_id,
                }
            }, {
                'type': 'Feature',
                'geometry': {
                    'type': 'LineString',
                    'coordinates': [[7., 0.], [7., 9.]]
                },
                'properties': {
                    'class_id': self.class_id
                }
            }]
        }

        source = self.build_source(geojson)
        with source.activate():
            self.assertEqual(source.get_extent(), self.extent)
            chip = source.get_image_array()
            self.assertEqual(chip.shape, (10, 10, 1))

            expected_chip = self.background_class_id * np.ones((10, 10, 1))
            expected_chip[0:5, 0:5, 0] = self.class_id
            expected_chip[0:10, 6:8] = self.class_id
            np.testing.assert_array_equal(chip, expected_chip)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/raster_source/test_rasterized_source.py" startline="40" endline="77" pcid="2663">
        source = config.create_source(self.uri, self.crs_transformer,
                                      self.extent)

        return source

    def test_get_chip(self):
        geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[0., 0.], [0., 5.], [5., 5.], [5., 0.],
                                     [0., 0.]]]
                },
                'properties': {
                    'class_id': self.class_id,
                }
            }, {
                'type': 'Feature',
                'geometry': {
                    'type': 'LineString',
                    'coordinates': [[7., 0.], [7., 9.]]
                },
                'properties': {
                    'class_id': self.class_id
                }
            }]
        }

        source = self.build_source(geojson)
        with source.activate():
            self.assertEqual(source.get_extent(), self.extent)
            chip = source.get_image_array()
            self.assertEqual(chip.shape, (10, 10, 1))

</source>
</class>

<class classid="117" nclones="2" nlines="25" similarity="100">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/raster_source/test_rasterized_source.py" startline="93" endline="123" pcid="2089">
    def test_get_chip_all_touched(self):
        geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[0., 0.], [0., 0.4], [0.4, 0.4],
                                     [0.4, 0.], [0., 0.]]]
                },
                'properties': {
                    'class_id': self.class_id,
                }
            }]
        }

        false_source = self.build_source(geojson, all_touched=False)
        true_source = self.build_source(geojson, all_touched=True)
        with false_source.activate():
            chip = false_source.get_image_array()
            expected_chip = self.background_class_id * np.ones((10, 10, 1))
            np.testing.assert_array_equal(chip, expected_chip)

        with true_source.activate():
            chip = true_source.get_image_array()
            expected_chip = self.background_class_id * np.ones((10, 10, 1))
            expected_chip[0:1, 0:1, 0] = self.class_id
            np.testing.assert_array_equal(chip, expected_chip)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/raster_source/test_rasterized_source.py" startline="94" endline="124" pcid="2665">
            expected_chip = np.zeros((10, 10, 1))
            expected_chip[0:5, 0:5, :] = self.background_class_id

            np.testing.assert_array_equal(chip, expected_chip)

    def test_get_chip_all_touched(self):
        geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[0., 0.], [0., 0.4], [0.4, 0.4],
                                     [0.4, 0.], [0., 0.]]]
                },
                'properties': {
                    'class_id': self.class_id,
                }
            }]
        }

        false_source = self.build_source(geojson, all_touched=False)
        true_source = self.build_source(geojson, all_touched=True)
        with false_source.activate():
            chip = false_source.get_image_array()
            expected_chip = self.background_class_id * np.ones((10, 10, 1))
            np.testing.assert_array_equal(chip, expected_chip)

        with true_source.activate():
</source>
</class>

<class classid="118" nclones="2" nlines="13" similarity="100">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/mock_raster_source.py" startline="15" endline="31" pcid="2092">
    def set_return_vals(self, raster=None):
        self.mock.get_extent.return_value = Box.make_square(0, 0, 2)
        self.mock.get_dtype.return_value = np.uint8
        self.mock.get_crs_transformer.return_value = IdentityCRSTransformer()
        self.mock._get_chip.return_value = np.random.rand(1, 2, 2, 3)

        if raster is not None:
            self.mock.get_extent.return_value = Box(0, 0, raster.shape[0],
                                                    raster.shape[1])
            self.mock.get_dtype.return_value = raster.dtype

            def get_chip(window):
                return raster[window.ymin:window.ymax, window.xmin:
                              window.xmax, :]

            self.mock._get_chip.side_effect = get_chip

</source>
<source file="systems/raster-vision-0.11.0/tests/mock/raster_source.py" startline="23" endline="39" pcid="2261">

    def set_return_vals(self, raster=None):
        self.mock.get_extent.return_value = Box.make_square(0, 0, 2)
        self.mock.get_dtype.return_value = np.uint8
        self.mock.get_crs_transformer.return_value = IdentityCRSTransformer()
        self.mock._get_chip.return_value = np.random.rand(1, 2, 2, 3)

        if raster is not None:
            self.mock.get_extent.return_value = Box(0, 0, raster.shape[0],
                                                    raster.shape[1])
            self.mock.get_dtype.return_value = raster.dtype

            def get_chip(window):
                return raster[window.ymin:window.ymax, window.xmin:
                              window.xmax, :]

            self.mock._get_chip.side_effect = get_chip
</source>
</class>

<class classid="119" nclones="2" nlines="25" similarity="72">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/vector_source/test_geojson_vector_source.py" startline="24" endline="53" pcid="2103">
    def _test_class_inf(self, props, exp_class_ids, default_class_id=None):
        geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'properties': props,
                'geometry': {
                    'type': 'Point',
                    'coordinates': [1, 1]
                }
            }]
        }
        json_to_file(geojson, self.uri)

        class_config = ClassConfig(names=['building', 'car', 'tree'])
        class_id_to_filter = {
            0: ['==', 'type', 'building'],
            1: ['any', ['==', 'type', 'car'], ['==', 'type', 'auto']]
        }
        vs_cfg = GeoJSONVectorSourceConfig(
            uri=self.uri,
            class_id_to_filter=class_id_to_filter,
            default_class_id=default_class_id)
        vs = vs_cfg.build(class_config, IdentityCRSTransformer())
        trans_geojson = vs.get_geojson()
        class_ids = [
            f['properties']['class_id'] for f in trans_geojson['features']
        ]
        self.assertEqual(class_ids, exp_class_ids)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/vector_source/test_geojson_vector_source.py" startline="27" endline="57" pcid="2684">
    def _test_class_inf(self, props, exp_class_ids, default_class_id=None):
        geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'properties': props,
                'geometry': {
                    'type': 'Point',
                    'coordinates': [1, 1]
                }
            }]
        }
        json_to_file(geojson, self.uri)

        class_map = ClassMap.construct_from(['building', 'car', 'tree'])
        class_id_to_filter = {
            1: ['==', 'type', 'building'],
            2: ['any', ['==', 'type', 'car'], ['==', 'type', 'auto']]
        }
        b = GeoJSONVectorSourceConfigBuilder() \
            .with_class_inference(class_id_to_filter=class_id_to_filter,
                                  default_class_id=default_class_id) \
            .with_uri(self.uri) \
            .build()
        msg = b.to_proto()
        config = GeoJSONVectorSourceConfig.from_proto(msg)
        source = config.create_source(
            crs_transformer=IdentityCRSTransformer(), class_map=class_map)
        trans_geojson = source.get_geojson()
        class_ids = [
            f['properties']['class_id'] for f in trans_geojson['features']
</source>
</class>

<class classid="120" nclones="2" nlines="13" similarity="100">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/vector_source/test_geojson_vector_source.py" startline="97" endline="113" pcid="2112">
    def test_transform_geojson_geom_coll(self):
        geom = {
            'type':
            'GeometryCollection',
            'geometries': [{
                'type': 'MultiPoint',
                'coordinates': [[10, 10], [20, 20]]
            }]
        }
        geojson = self.geom_to_geojson(geom)
        trans_geojson = self.transform_geojson(geojson)

        feats = trans_geojson['features']
        self.assertEqual(len(feats), 2)
        self.assertEqual(feats[0]['geometry']['type'], 'Polygon')
        self.assertEqual(feats[1]['geometry']['type'], 'Polygon')

</source>
<source file="systems/raster-vision-0.11.0/tests/data/vector_source/test_geojson_vector_source.py" startline="100" endline="116" pcid="2693">
        geom = {'type': 'Point', 'coordinates': []}
        geojson = self.geom_to_geojson(geom)
        trans_geojson = self.transform_geojson(geojson)

        self.assertEqual(0, len(trans_geojson['features']))

    def test_transform_geojson_geom_coll(self):
        geom = {
            'type':
            'GeometryCollection',
            'geometries': [{
                'type': 'MultiPoint',
                'coordinates': [[10, 10], [20, 20]]
            }]
        }
        geojson = self.geom_to_geojson(geom)
        trans_geojson = self.transform_geojson(geojson)
</source>
</class>

<class classid="121" nclones="4" nlines="12" similarity="91">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/vector_source/test_geojson_vector_source.py" startline="124" endline="139" pcid="2114">
    def test_transform_geojson_line_buf(self):
        geom = {'type': 'LineString', 'coordinates': [[10, 10], [10, 20]]}
        geojson = self.geom_to_geojson(geom)

        trans_geojson = self.transform_geojson(geojson, line_bufs={0: 5.0})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).buffer(5.0).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(geojson, line_bufs={1: 5.0})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).buffer(1.0).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(geojson, line_bufs={0: None})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).equals(shape(trans_geom)))

</source>
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/vector_source/test_geojson_vector_source.py" startline="140" endline="155" pcid="2115">
    def test_transform_point_buf(self):
        geom = {'type': 'Point', 'coordinates': [10, 10]}
        geojson = self.geom_to_geojson(geom)

        trans_geojson = self.transform_geojson(geojson, point_bufs={0: 5.0})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).buffer(5.0).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(geojson, point_bufs={1: 5.0})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).buffer(1.0).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(geojson, point_bufs={0: None})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).equals(shape(trans_geom)))

</source>
<source file="systems/raster-vision-0.11.0/tests/data/vector_source/test_geojson_vector_source.py" startline="143" endline="158" pcid="2696">
        self.assertTrue(shape(geom).buffer(1.0).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(geojson, line_bufs={1: None})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).equals(shape(trans_geom)))

    def test_transform_point_buf(self):
        geom = {'type': 'Point', 'coordinates': [10, 10]}
        geojson = self.geom_to_geojson(geom)

        trans_geojson = self.transform_geojson(geojson, point_bufs={1: 5.0})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).buffer(5.0).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(geojson, point_bufs={2: 5.0})
        trans_geom = trans_geojson['features'][0]['geometry']
</source>
<source file="systems/raster-vision-0.11.0/tests/data/vector_source/test_geojson_vector_source.py" startline="127" endline="142" pcid="2695">

        feats = trans_geojson['features']
        self.assertEqual(len(feats), 2)
        self.assertEqual(feats[0]['geometry']['type'], 'Polygon')
        self.assertEqual(feats[1]['geometry']['type'], 'Polygon')

    def test_transform_geojson_line_buf(self):
        geom = {'type': 'LineString', 'coordinates': [[10, 10], [10, 20]]}
        geojson = self.geom_to_geojson(geom)

        trans_geojson = self.transform_geojson(geojson, line_bufs={1: 5.0})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).buffer(5.0).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(geojson, line_bufs={2: 5.0})
        trans_geom = trans_geojson['features'][0]['geometry']
</source>
</class>

<class classid="122" nclones="2" nlines="21" similarity="100">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/vector_source/test_geojson_vector_source.py" startline="156" endline="183" pcid="2116">
    def test_transform_polygon(self):
        geom = {
            'type': 'Polygon',
            'coordinates': [[[0, 0], [0, 10], [10, 10], [10, 0], [0, 0]]]
        }
        geojson = self.geom_to_geojson(geom)

        trans_geojson = self.transform_geojson(geojson)
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(
            geojson, crs_transformer=DoubleCRSTransformer())
        trans_geom = trans_geojson['features'][0]['geometry']
        exp_geom = {
            'type': 'Polygon',
            'coordinates': [[[0, 0], [0, 20], [20, 20], [20, 0], [0, 0]]]
        }
        self.assertTrue(shape(exp_geom).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(
            geojson,
            crs_transformer=DoubleCRSTransformer(),
            to_map_coords=True)
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).equals(shape(trans_geom)))


</source>
<source file="systems/raster-vision-0.11.0/tests/data/vector_source/test_geojson_vector_source.py" startline="159" endline="185" pcid="2697">
        self.assertTrue(shape(geom).buffer(1.0).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(geojson, point_bufs={1: None})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).equals(shape(trans_geom)))

    def test_transform_polygon(self):
        geom = {
            'type': 'Polygon',
            'coordinates': [[[0, 0], [0, 10], [10, 10], [10, 0], [0, 0]]]
        }
        geojson = self.geom_to_geojson(geom)

        trans_geojson = self.transform_geojson(geojson)
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(
            geojson, crs_transformer=DoubleCRSTransformer())
        trans_geom = trans_geojson['features'][0]['geometry']
        exp_geom = {
            'type': 'Polygon',
            'coordinates': [[[0, 0], [0, 20], [20, 20], [20, 0], [0, 0]]]
        }
        self.assertTrue(shape(exp_geom).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(
</source>
</class>

<class classid="123" nclones="2" nlines="10" similarity="90">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/label/test_object_detection_labels.py" startline="13" endline="23" pcid="2119">
    def setUp(self):
        self.class_config = ClassConfig(names=['car', 'house'])
        self.npboxes = np.array([
            [0., 0., 2., 2.],
            [2., 2., 4., 4.],
        ])
        self.class_ids = np.array([0, 1])
        self.scores = np.array([0.9, 0.9])
        self.labels = ObjectDetectionLabels(
            self.npboxes, self.class_ids, scores=self.scores)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/label/test_object_detection_labels.py" startline="12" endline="23" pcid="2706">
    def setUp(self):
        self.class_map = ClassMap([ClassItem(1, 'car'), ClassItem(2, 'house')])

        self.npboxes = np.array([
            [0., 0., 2., 2.],
            [2., 2., 4., 4.],
        ])
        self.class_ids = np.array([1, 2])
        self.scores = np.array([0.9, 0.9])
        self.labels = ObjectDetectionLabels(
            self.npboxes, self.class_ids, scores=self.scores)

</source>
</class>

<class classid="124" nclones="2" nlines="11" similarity="100">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/label/test_object_detection_labels.py" startline="41" endline="53" pcid="2122">
    def test_constructor(self):
        labels = ObjectDetectionLabels(
            self.npboxes, self.class_ids, scores=self.scores)
        expected_labels = ObjectDetectionLabels(self.npboxes, self.class_ids,
                                                self.scores)
        labels.assert_equal(expected_labels)

        labels = ObjectDetectionLabels(self.npboxes, self.class_ids)
        scores = np.ones(self.class_ids.shape)
        expected_labels = ObjectDetectionLabels(
            self.npboxes, self.class_ids, scores=scores)
        labels.assert_equal(expected_labels)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/label/test_object_detection_labels.py" startline="42" endline="54" pcid="2709">
    def test_constructor(self):
        labels = ObjectDetectionLabels(
            self.npboxes, self.class_ids, scores=self.scores)
        expected_labels = ObjectDetectionLabels(self.npboxes, self.class_ids,
                                                self.scores)
        labels.assert_equal(expected_labels)

        labels = ObjectDetectionLabels(self.npboxes, self.class_ids)
        scores = np.ones(self.class_ids.shape)
        expected_labels = ObjectDetectionLabels(
            self.npboxes, self.class_ids, scores=scores)
        labels.assert_equal(expected_labels)

</source>
</class>

<class classid="125" nclones="2" nlines="23" similarity="100">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/label/test_object_detection_labels.py" startline="104" endline="129" pcid="2129">
    def test_get_overlapping(self):
        window = Box.make_square(0, 0, 2.01)
        labels = ObjectDetectionLabels.get_overlapping(self.labels, window)
        labels.assert_equal(self.labels)

        window = Box.make_square(0, 0, 3)
        labels = ObjectDetectionLabels.get_overlapping(
            self.labels, window, ioa_thresh=0.5)
        npboxes = np.array([[0., 0., 2., 2.]])
        class_ids = np.array([0])
        scores = np.array([0.9])
        expected_labels = ObjectDetectionLabels(
            npboxes, class_ids, scores=scores)
        labels.assert_equal(expected_labels)

        window = Box.make_square(0, 0, 3)
        labels = ObjectDetectionLabels.get_overlapping(
            self.labels, window, ioa_thresh=0.1, clip=True)
        expected_npboxes = np.array([
            [0., 0., 2., 2.],
            [2., 2., 3., 3.],
        ])
        expected_labels = ObjectDetectionLabels(
            expected_npboxes, self.class_ids, scores=self.scores)
        labels.assert_equal(expected_labels)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/label/test_object_detection_labels.py" startline="105" endline="130" pcid="2716">
    def test_get_overlapping(self):
        window = Box.make_square(0, 0, 2.01)
        labels = ObjectDetectionLabels.get_overlapping(self.labels, window)
        labels.assert_equal(self.labels)

        window = Box.make_square(0, 0, 3)
        labels = ObjectDetectionLabels.get_overlapping(
            self.labels, window, ioa_thresh=0.5)
        npboxes = np.array([[0., 0., 2., 2.]])
        class_ids = np.array([1])
        scores = np.array([0.9])
        expected_labels = ObjectDetectionLabels(
            npboxes, class_ids, scores=scores)
        labels.assert_equal(expected_labels)

        window = Box.make_square(0, 0, 3)
        labels = ObjectDetectionLabels.get_overlapping(
            self.labels, window, ioa_thresh=0.1, clip=True)
        expected_npboxes = np.array([
            [0., 0., 2., 2.],
            [2., 2., 3., 3.],
        ])
        expected_labels = ObjectDetectionLabels(
            expected_npboxes, self.class_ids, scores=self.scores)
        labels.assert_equal(expected_labels)

</source>
</class>

<class classid="126" nclones="2" nlines="13" similarity="100">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/label/test_object_detection_labels.py" startline="130" endline="144" pcid="2130">
    def test_concatenate(self):
        npboxes = np.array([[4., 4., 5., 5.]])
        class_ids = np.array([1])
        scores = np.array([0.3])
        labels = ObjectDetectionLabels(npboxes, class_ids, scores=scores)
        new_labels = ObjectDetectionLabels.concatenate(self.labels, labels)

        npboxes = np.array([[0., 0., 2., 2.], [2., 2., 4., 4.],
                            [4., 4., 5., 5.]])
        class_ids = np.array([0, 1, 1])
        scores = np.array([0.9, 0.9, 0.3])
        expected_labels = ObjectDetectionLabels(
            npboxes, class_ids, scores=scores)
        new_labels.assert_equal(expected_labels)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/label/test_object_detection_labels.py" startline="131" endline="145" pcid="2717">
    def test_concatenate(self):
        npboxes = np.array([[4., 4., 5., 5.]])
        class_ids = np.array([2])
        scores = np.array([0.3])
        labels = ObjectDetectionLabels(npboxes, class_ids, scores=scores)
        new_labels = ObjectDetectionLabels.concatenate(self.labels, labels)

        npboxes = np.array([[0., 0., 2., 2.], [2., 2., 4., 4.],
                            [4., 4., 5., 5.]])
        class_ids = np.array([1, 2, 2])
        scores = np.array([0.9, 0.9, 0.3])
        expected_labels = ObjectDetectionLabels(
            npboxes, class_ids, scores=scores)
        new_labels.assert_equal(expected_labels)

</source>
</class>

<class classid="127" nclones="2" nlines="27" similarity="100">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/label/test_object_detection_labels.py" startline="145" endline="182" pcid="2131">
    def test_prune_duplicates(self):
        # This first box has a score below score_thresh so it should get
        # pruned. The third box overlaps with the second, but has higher score,
        # so the second one should get pruned. The fourth box overlaps with
        # the second less than merge_thresh, so it should not get pruned.
        npboxes = np.array([[0., 0., 2., 2.], [2., 2., 4., 4.],
                            [2.1, 2.1, 4.1, 4.1], [3.5, 3.5, 5.5, 5.5]])
        class_ids = np.array([0, 1, 0, 1])
        scores = np.array([0.2, 0.9, 0.9, 1.0])
        labels = ObjectDetectionLabels(npboxes, class_ids, scores=scores)
        score_thresh = 0.5
        merge_thresh = 0.5
        pruned_labels = ObjectDetectionLabels.prune_duplicates(
            labels, score_thresh, merge_thresh)

        self.assertEqual(len(pruned_labels), 2)

        expected_npboxes = np.array([[2.1, 2.1, 4.1, 4.1],
                                     [3.5, 3.5, 5.5, 5.5]])
        expected_class_ids = np.array([0, 1])
        expected_scores = np.array([0.9, 1.0])

        # prune_duplicates does not maintain ordering of boxes, so find match
        # between pruned boxes and expected_npboxes.
        pruned_npboxes = pruned_labels.get_npboxes()
        pruned_inds = [None, None]
        for box_ind, box in enumerate(expected_npboxes):
            for pruned_box_ind, pruned_box in enumerate(pruned_npboxes):
                if np.array_equal(pruned_box, box):
                    pruned_inds[box_ind] = pruned_box_ind
        self.assertTrue(np.all(pruned_inds is not None))

        expected_labels = ObjectDetectionLabels(
            expected_npboxes[pruned_inds],
            expected_class_ids[pruned_inds],
            scores=expected_scores[pruned_inds])
        pruned_labels.assert_equal(expected_labels)

</source>
<source file="systems/raster-vision-0.11.0/tests/data/label/test_object_detection_labels.py" startline="146" endline="183" pcid="2718">
    def test_prune_duplicates(self):
        # This first box has a score below score_thresh so it should get
        # pruned. The third box overlaps with the second, but has higher score,
        # so the second one should get pruned. The fourth box overlaps with
        # the second less than merge_thresh, so it should not get pruned.
        npboxes = np.array([[0., 0., 2., 2.], [2., 2., 4., 4.],
                            [2.1, 2.1, 4.1, 4.1], [3.5, 3.5, 5.5, 5.5]])
        class_ids = np.array([1, 2, 1, 2])
        scores = np.array([0.2, 0.9, 0.9, 1.0])
        labels = ObjectDetectionLabels(npboxes, class_ids, scores=scores)
        score_thresh = 0.5
        merge_thresh = 0.5
        pruned_labels = ObjectDetectionLabels.prune_duplicates(
            labels, score_thresh, merge_thresh)

        self.assertEqual(len(pruned_labels), 2)

        expected_npboxes = np.array([[2.1, 2.1, 4.1, 4.1],
                                     [3.5, 3.5, 5.5, 5.5]])
        expected_class_ids = np.array([1, 2])
        expected_scores = np.array([0.9, 1.0])

        # prune_duplicates does not maintain ordering of boxes, so find match
        # between pruned boxes and expected_npboxes.
        pruned_npboxes = pruned_labels.get_npboxes()
        pruned_inds = [None, None]
        for box_ind, box in enumerate(expected_npboxes):
            for pruned_box_ind, pruned_box in enumerate(pruned_npboxes):
                if np.array_equal(pruned_box, box):
                    pruned_inds[box_ind] = pruned_box_ind
        self.assertTrue(np.all(pruned_inds is not None))

        expected_labels = ObjectDetectionLabels(
            expected_npboxes[pruned_inds],
            expected_class_ids[pruned_inds],
            scores=expected_scores[pruned_inds])
        pruned_labels.assert_equal(expected_labels)

</source>
</class>

<class classid="128" nclones="2" nlines="12" similarity="100">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/label/test_object_detection_labels.py" startline="183" endline="198" pcid="2132">
    def test_filter_by_aoi(self):
        aois = [Box.make_square(0, 0, 2).to_shapely()]
        filt_labels = self.labels.filter_by_aoi(aois)

        npboxes = np.array([[0., 0., 2., 2.]])
        class_ids = np.array([0])
        scores = np.array([0.9])
        exp_labels = ObjectDetectionLabels(npboxes, class_ids, scores=scores)
        self.assertEqual(filt_labels, exp_labels)

        aois = [Box.make_square(4, 4, 2).to_shapely()]
        filt_labels = self.labels.filter_by_aoi(aois)
        exp_labels = ObjectDetectionLabels.make_empty()
        self.assertEqual(filt_labels, exp_labels)


</source>
<source file="systems/raster-vision-0.11.0/tests/data/label/test_object_detection_labels.py" startline="184" endline="199" pcid="2719">
    def test_filter_by_aoi(self):
        aois = [Box.make_square(0, 0, 2).to_shapely()]
        filt_labels = self.labels.filter_by_aoi(aois)

        npboxes = np.array([[0., 0., 2., 2.]])
        class_ids = np.array([1])
        scores = np.array([0.9])
        exp_labels = ObjectDetectionLabels(npboxes, class_ids, scores=scores)
        self.assertEqual(filt_labels, exp_labels)

        aois = [Box.make_square(4, 4, 2).to_shapely()]
        filt_labels = self.labels.filter_by_aoi(aois)
        exp_labels = ObjectDetectionLabels.make_empty()
        self.assertEqual(filt_labels, exp_labels)


</source>
</class>

<class classid="129" nclones="2" nlines="12" similarity="100">
<source file="systems/raster-vision-0.11.0/tests_v2/core/data/label/test_chip_classification_labels.py" startline="67" endline="83" pcid="2139">
    def test_filter_by_aoi(self):
        aois = [Box.make_square(0, 0, 2).to_shapely()]
        filt_labels = self.labels.filter_by_aoi(aois)

        exp_labels = ChipClassificationLabels()
        cell1 = Box.make_square(0, 0, 2)
        class_id1 = 1
        exp_labels.set_cell(cell1, class_id1)
        self.assertEqual(filt_labels, exp_labels)

        aois = [Box.make_square(4, 4, 2).to_shapely()]
        filt_labels = self.labels.filter_by_aoi(aois)

        exp_labels = ChipClassificationLabels()
        self.assertEqual(filt_labels, exp_labels)


</source>
<source file="systems/raster-vision-0.11.0/tests/data/label/test_chip_classification_labels.py" startline="66" endline="82" pcid="2726">
    def test_filter_by_aoi(self):
        aois = [Box.make_square(0, 0, 2).to_shapely()]
        filt_labels = self.labels.filter_by_aoi(aois)

        exp_labels = ChipClassificationLabels()
        cell1 = Box.make_square(0, 0, 2)
        class_id1 = 1
        exp_labels.set_cell(cell1, class_id1)
        self.assertEqual(filt_labels, exp_labels)

        aois = [Box.make_square(4, 4, 2).to_shapely()]
        filt_labels = self.labels.filter_by_aoi(aois)

        exp_labels = ChipClassificationLabels()
        self.assertEqual(filt_labels, exp_labels)


</source>
</class>

<class classid="130" nclones="2" nlines="11" similarity="100">
<source file="systems/raster-vision-0.11.0/tests_v2/core/test_box.py" startline="144" endline="156" pcid="2167">

    def test_make_buffer(self):
        buffer_size = 1
        max_extent = Box.make_square(0, 0, 3)
        buffer_box = Box(0, 0, 3, 3)
        output_buffer_box = self.box.make_buffer(buffer_size, max_extent)
        self.assertEqual(output_buffer_box, buffer_box)

        buffer_size = 0.5
        max_extent = Box.make_square(0, 0, 5)
        buffer_box = Box(0, 0, 3, 5)
        output_buffer_box = self.box.make_buffer(buffer_size, max_extent)
        self.assertEqual(output_buffer_box, buffer_box)
</source>
<source file="systems/raster-vision-0.11.0/tests/core/test_box.py" startline="144" endline="156" pcid="2911">

    def test_make_buffer(self):
        buffer_size = 1
        max_extent = Box.make_square(0, 0, 3)
        buffer_box = Box(0, 0, 3, 3)
        output_buffer_box = self.box.make_buffer(buffer_size, max_extent)
        self.assertEqual(output_buffer_box, buffer_box)

        buffer_size = 0.5
        max_extent = Box.make_square(0, 0, 5)
        buffer_box = Box(0, 0, 3, 5)
        output_buffer_box = self.box.make_buffer(buffer_size, max_extent)
        self.assertEqual(output_buffer_box, buffer_box)
</source>
</class>

<class classid="131" nclones="2" nlines="29" similarity="100">
<source file="systems/raster-vision-0.11.0/tests_v2/core/test_box.py" startline="162" endline="197" pcid="2169">

    def test_get_windows(self):
        extent = Box(0, 0, 100, 100)
        windows = list(extent.get_windows(10, 10))
        self.assertEqual(len(windows), 100)

        extent = Box(0, 0, 100, 100)
        windows = list(extent.get_windows(10, 5))
        self.assertEqual(len(windows), 400)

        extent = Box(0, 0, 20, 20)
        windows = set(
            [window.tuple_format() for window in extent.get_windows(10, 10)])
        expected_windows = [
            Box.make_square(0, 0, 10),
            Box.make_square(10, 0, 10),
            Box.make_square(0, 10, 10),
            Box.make_square(10, 10, 10)
        ]
        expected_windows = set(
            [window.tuple_format() for window in expected_windows])
        self.assertSetEqual(windows, expected_windows)

        extent = Box(10, 10, 20, 20)
        windows = set(
            [window.tuple_format() for window in extent.get_windows(6, 6)])
        expected_windows = [
            Box.make_square(10, 10, 6),
            Box.make_square(10, 16, 6),
            Box.make_square(16, 10, 6),
            Box.make_square(16, 16, 6)
        ]
        expected_windows = set(
            [window.tuple_format() for window in expected_windows])
        self.assertSetEqual(windows, expected_windows)

</source>
<source file="systems/raster-vision-0.11.0/tests/core/test_box.py" startline="162" endline="197" pcid="2913">

    def test_get_windows(self):
        extent = Box(0, 0, 100, 100)
        windows = list(extent.get_windows(10, 10))
        self.assertEqual(len(windows), 100)

        extent = Box(0, 0, 100, 100)
        windows = list(extent.get_windows(10, 5))
        self.assertEqual(len(windows), 400)

        extent = Box(0, 0, 20, 20)
        windows = set(
            [window.tuple_format() for window in extent.get_windows(10, 10)])
        expected_windows = [
            Box.make_square(0, 0, 10),
            Box.make_square(10, 0, 10),
            Box.make_square(0, 10, 10),
            Box.make_square(10, 10, 10)
        ]
        expected_windows = set(
            [window.tuple_format() for window in expected_windows])
        self.assertSetEqual(windows, expected_windows)

        extent = Box(10, 10, 20, 20)
        windows = set(
            [window.tuple_format() for window in extent.get_windows(6, 6)])
        expected_windows = [
            Box.make_square(10, 10, 6),
            Box.make_square(10, 16, 6),
            Box.make_square(16, 10, 6),
            Box.make_square(16, 16, 6)
        ]
        expected_windows = set(
            [window.tuple_format() for window in expected_windows])
        self.assertSetEqual(windows, expected_windows)

</source>
</class>

<class classid="132" nclones="2" nlines="40" similarity="82">
<source file="systems/raster-vision-0.11.0/tests_v2/core/evaluation/test_semantic_segmentation_evaluation.py" startline="13" endline="61" pcid="2170">
    def test_compute(self):
        class_config = ClassConfig(names=['one', 'two'])
        class_config.update()
        class_config.ensure_null_class()
        null_class_id = class_config.get_null_class_id()

        gt_array = np.zeros((4, 4, 1), dtype=np.uint8)
        gt_array[2, 2, 0] = 1
        gt_array[0, 0, 0] = 2
        gt_raster = MockRasterSource([0], 1)
        gt_raster.set_raster(gt_array)
        gt_label_source = SemanticSegmentationLabelSource(gt_raster, null_class_id)

        p_array = np.zeros((4, 4, 1), dtype=np.uint8)
        p_array[1, 1, 0] = 1
        p_raster = MockRasterSource([0], 1)
        p_raster.set_raster(p_array)
        p_label_source = SemanticSegmentationLabelSource(p_raster, null_class_id)

        eval = SemanticSegmentationEvaluation(class_config)
        eval.compute(gt_label_source.get_labels(), p_label_source.get_labels())

        tp0 = 16 - 3  # 4*4 - 3 true positives for class 0
        fp0 = 1  # 1 false positive (2,2) and one don't care at (0,0)
        fn0 = 1  # one false negative (1,1)
        precision0 = float(tp0) / (tp0 + fp0)
        recall0 = float(tp0) / (tp0 + fn0)
        f10 = 2 * float(precision0 * recall0) / (precision0 + recall0)

        tp1 = 0  # 0 true positives for class 1
        fn1 = 1  # one false negative (2,2)
        precision1 = 0  # float(tp1) / (tp1 + fp1) where fp1 == 1
        recall1 = float(tp1) / (tp1 + fn1)
        f11 = None

        self.assertAlmostEqual(precision0,
                               eval.class_to_eval_item[0].precision)
        self.assertAlmostEqual(recall0, eval.class_to_eval_item[0].recall)
        self.assertAlmostEqual(f10, eval.class_to_eval_item[0].f1)

        self.assertEqual(precision1, eval.class_to_eval_item[1].precision)
        self.assertAlmostEqual(recall1, eval.class_to_eval_item[1].recall)
        self.assertAlmostEqual(f11, eval.class_to_eval_item[1].f1)

        avg_conf_mat = np.array([[0, 0, 0], [13., 1, 0], [1, 0, 0]])
        avg_recall = (14 / 15) * recall0 + (1 / 15) * recall1
        self.assertTrue(np.array_equal(avg_conf_mat, eval.avg_item.conf_mat))
        self.assertEqual(avg_recall, eval.avg_item.recall)

</source>
<source file="systems/raster-vision-0.11.0/tests/evaluation/test_semantic_segmentation_evaluation.py" startline="15" endline="63" pcid="2830">
    def test_compute(self):
        class_map = ClassMap(
            [ClassItem(id=1, name='one'),
             ClassItem(id=2, name='two')])

        # Mismatches: 0 -> 1, 2 -> 1, 1 -> 0
        gt_array = np.ones((4, 4, 1), dtype=np.uint8)
        gt_array[0, 0, 0] = 0
        gt_array[2, 2, 0] = 2
        gt_raster = MockRasterSource([0], 1)
        gt_raster.set_raster(gt_array)
        gt_label_source = SemanticSegmentationLabelSource(source=gt_raster)

        p_array = np.ones((4, 4, 1), dtype=np.uint8)
        p_array[1, 1, 0] = 0
        p_raster = MockRasterSource([0], 1)
        p_raster.set_raster(p_array)
        p_label_source = SemanticSegmentationLabelSource(source=p_raster)

        eval = SemanticSegmentationEvaluation(class_map)
        eval.compute(gt_label_source.get_labels(), p_label_source.get_labels())

        tp1 = 16 - 3  # 4*4 - 3 true positives for class 1
        fp1 = 1  # 1 false positive (2,2) and one don't care at (0,0)
        fn1 = 1  # one false negative (1,1)
        precision1 = float(tp1) / (tp1 + fp1)
        recall1 = float(tp1) / (tp1 + fn1)
        f11 = 2 * float(precision1 * recall1) / (precision1 + recall1)

        tp2 = 0  # 0 true positives for class 2
        fn2 = 1  # one false negative (2,2)
        precision2 = None  # float(tp2) / (tp2 + fp2) where fp2 == 0
        recall2 = float(tp2) / (tp2 + fn2)
        f12 = None

        self.assertAlmostEqual(precision1,
                               eval.class_to_eval_item[1].precision)
        self.assertAlmostEqual(recall1, eval.class_to_eval_item[1].recall)
        self.assertAlmostEqual(f11, eval.class_to_eval_item[1].f1)

        self.assertEqual(precision2, eval.class_to_eval_item[2].precision)
        self.assertAlmostEqual(recall2, eval.class_to_eval_item[2].recall)
        self.assertAlmostEqual(f12, eval.class_to_eval_item[2].f1)

        avg_conf_mat = np.array([[0, 0, 0], [1., 13, 0], [0, 1, 0]])
        avg_recall = (14 / 15) * recall1 + (1 / 15) * recall2
        self.assertTrue(np.array_equal(avg_conf_mat, eval.avg_item.conf_mat))
        self.assertEqual(avg_recall, eval.avg_item.recall)

</source>
</class>

<class classid="133" nclones="2" nlines="14" similarity="80">
<source file="systems/raster-vision-0.11.0/tests_v2/core/evaluation/test_semantic_segmentation_evaluation.py" startline="86" endline="109" pcid="2172">
    def test_vector_compute(self):
        class_config = ClassConfig(names=['one', 'two'])
        class_config.update()
        class_config.ensure_null_class()

        gt_uri = data_file_path('2-gt-polygons.geojson')
        pred_uri = data_file_path('2-pred-polygons.geojson')

        eval = SemanticSegmentationEvaluation(class_config)
        eval.compute_vector(gt_uri, pred_uri, 'polygons', 0)

        # NOTE: The  two geojson files referenced  above contain three
        # unique geometries total, each  file contains two geometries,
        # and there is one geometry shared between the two.
        tp = 1.0
        fp = 1.0
        fn = 1.0
        precision = float(tp) / (tp + fp)
        recall = float(tp) / (tp + fn)

        self.assertAlmostEqual(precision, eval.class_to_eval_item[0].precision)
        self.assertAlmostEqual(recall, eval.class_to_eval_item[0].recall)


</source>
<source file="systems/raster-vision-0.11.0/tests/evaluation/test_semantic_segmentation_evaluation.py" startline="88" endline="108" pcid="2832">
    def test_vector_compute(self):
        class_map = ClassMap([ClassItem(id=1, name='one', color='#000021')])
        gt_uri = data_file_path('3-gt-polygons.geojson')
        pred_uri = data_file_path('3-pred-polygons.geojson')

        eval = SemanticSegmentationEvaluation(class_map)
        eval.compute_vector(gt_uri, pred_uri, 'polygons', 1)

        # NOTE: The  two geojson files referenced  above contain three
        # unique geometries total, each  file contains two geometries,
        # and there is one geometry shared between the two.
        tp = 1.0
        fp = 1.0
        fn = 1.0
        precision = float(tp) / (tp + fp)
        recall = float(tp) / (tp + fn)

        self.assertAlmostEqual(precision, eval.class_to_eval_item[1].precision)
        self.assertAlmostEqual(recall, eval.class_to_eval_item[1].recall)


</source>
</class>

<class classid="134" nclones="2" nlines="17" similarity="100">
<source file="systems/raster-vision-0.11.0/tests_v2/core/evaluation/test_chip_classification_evaluation.py" startline="13" endline="37" pcid="2174">
    def make_labels(self, class_ids):
        """Make 2x2 grid label store.

        Args:
            class_ids: 2x2 array of class_ids to use
        """
        cell_size = 200
        y_cells = 2
        x_cells = 2
        labels = ChipClassificationLabels()

        for yind in range(y_cells):
            for xind in range(x_cells):
                ymin = yind * cell_size
                xmin = xind * cell_size
                ymax = ymin + cell_size
                xmax = xmin + cell_size
                window = Box(ymin, xmin, ymax, xmax)
                class_id = class_ids[yind][xind]
                new_labels = ChipClassificationLabels()
                new_labels.set_cell(window, class_id)
                labels.extend(new_labels)

        return labels

</source>
<source file="systems/raster-vision-0.11.0/tests/evaluation/test_chip_classification_evaluation.py" startline="14" endline="38" pcid="2836">
    def make_labels(self, class_ids):
        """Make 2x2 grid label store.

        Args:
            class_ids: 2x2 array of class_ids to use
        """
        cell_size = 200
        y_cells = 2
        x_cells = 2
        labels = ChipClassificationLabels()

        for yind in range(y_cells):
            for xind in range(x_cells):
                ymin = yind * cell_size
                xmin = xind * cell_size
                ymax = ymin + cell_size
                xmax = xmin + cell_size
                window = Box(ymin, xmin, ymax, xmax)
                class_id = class_ids[yind][xind]
                new_labels = ChipClassificationLabels()
                new_labels.set_cell(window, class_id)
                labels.extend(new_labels)

        return labels

</source>
</class>

<class classid="135" nclones="2" nlines="16" similarity="100">
<source file="systems/raster-vision-0.11.0/tests_v2/core/evaluation/test_chip_classification_evaluation.py" startline="38" endline="56" pcid="2175">
    def assert_eval_single_null(self, eval):
        eval_item0 = eval.class_to_eval_item[0]
        self.assertEqual(eval_item0.gt_count, 2)
        self.assertEqual(eval_item0.precision, 1.0)
        self.assertEqual(eval_item0.recall, 0.5)
        self.assertAlmostEqual(eval_item0.f1, 2 / 3, places=2)

        eval_item1 = eval.class_to_eval_item[1]
        self.assertEqual(eval_item1.gt_count, 1)
        self.assertEqual(eval_item1.precision, 0.5)
        self.assertEqual(eval_item1.recall, 1.0)
        self.assertAlmostEqual(eval_item1.f1, 2 / 3, places=2)

        avg_item = eval.avg_item
        self.assertEqual(avg_item.gt_count, 3)
        self.assertAlmostEqual(avg_item.precision, 0.83, places=2)
        self.assertAlmostEqual(avg_item.recall, 2 / 3, places=2)
        self.assertAlmostEqual(avg_item.f1, 2 / 3, places=2)

</source>
<source file="systems/raster-vision-0.11.0/tests/evaluation/test_chip_classification_evaluation.py" startline="39" endline="57" pcid="2837">
    def assert_eval_single_null(self, eval):
        eval_item1 = eval.class_to_eval_item[1]
        self.assertEqual(eval_item1.gt_count, 2)
        self.assertEqual(eval_item1.precision, 1.0)
        self.assertEqual(eval_item1.recall, 0.5)
        self.assertAlmostEqual(eval_item1.f1, 2 / 3, places=2)

        eval_item2 = eval.class_to_eval_item[2]
        self.assertEqual(eval_item2.gt_count, 1)
        self.assertEqual(eval_item2.precision, 0.5)
        self.assertEqual(eval_item2.recall, 1.0)
        self.assertAlmostEqual(eval_item2.f1, 2 / 3, places=2)

        avg_item = eval.avg_item
        self.assertEqual(avg_item.gt_count, 3)
        self.assertAlmostEqual(avg_item.precision, 0.83, places=2)
        self.assertAlmostEqual(avg_item.recall, 2 / 3, places=2)
        self.assertAlmostEqual(avg_item.f1, 2 / 3, places=2)

</source>
</class>

<class classid="136" nclones="4" nlines="10" similarity="90">
<source file="systems/raster-vision-0.11.0/tests_v2/core/evaluation/test_class_evaluation_item.py" startline="20" endline="30" pcid="2180">
    def test_merge_first_empty(self):
        a = ClassEvaluationItem()
        b = ClassEvaluationItem(
            precision=1, recall=1, f1=1, count_error=0, gt_count=1)
        a.merge(b)
        self.assertEqual(a.precision, 1)
        self.assertEqual(a.recall, 1)
        self.assertEqual(a.f1, 1)
        self.assertEqual(a.count_error, 0)
        self.assertEqual(a.gt_count, 1)

</source>
<source file="systems/raster-vision-0.11.0/tests_v2/core/evaluation/test_class_evaluation_item.py" startline="31" endline="41" pcid="2181">
    def test_merge_second_empty(self):
        a = ClassEvaluationItem(
            precision=1, recall=1, f1=1, count_error=0, gt_count=1)
        b = ClassEvaluationItem()
        a.merge(b)
        self.assertEqual(a.precision, 1)
        self.assertEqual(a.recall, 1)
        self.assertEqual(a.f1, 1)
        self.assertEqual(a.count_error, 0)
        self.assertEqual(a.gt_count, 1)

</source>
<source file="systems/raster-vision-0.11.0/tests/evaluation/test_class_evaluation_item.py" startline="20" endline="30" pcid="2842">
    def test_merge_first_empty(self):
        a = ClassEvaluationItem()
        b = ClassEvaluationItem(
            precision=1, recall=1, f1=1, count_error=0, gt_count=1)
        a.merge(b)
        self.assertEqual(a.precision, 1)
        self.assertEqual(a.recall, 1)
        self.assertEqual(a.f1, 1)
        self.assertEqual(a.count_error, 0)
        self.assertEqual(a.gt_count, 1)

</source>
<source file="systems/raster-vision-0.11.0/tests/evaluation/test_class_evaluation_item.py" startline="31" endline="41" pcid="2843">
    def test_merge_second_empty(self):
        a = ClassEvaluationItem(
            precision=1, recall=1, f1=1, count_error=0, gt_count=1)
        b = ClassEvaluationItem()
        a.merge(b)
        self.assertEqual(a.precision, 1)
        self.assertEqual(a.recall, 1)
        self.assertEqual(a.f1, 1)
        self.assertEqual(a.count_error, 0)
        self.assertEqual(a.gt_count, 1)

</source>
</class>

<class classid="137" nclones="2" nlines="11" similarity="100">
<source file="systems/raster-vision-0.11.0/tests_v2/core/evaluation/test_class_evaluation_item.py" startline="42" endline="54" pcid="2182">
    def test_merge(self):
        a = ClassEvaluationItem(
            precision=1, recall=1, f1=1, count_error=0, gt_count=1)
        b = ClassEvaluationItem(
            precision=0, recall=0, f1=0, count_error=1, gt_count=2)
        a.merge(b)
        self.assertEqual(a.precision, 1 / 3)
        self.assertEqual(a.recall, 1 / 3)
        self.assertEqual(a.f1, 1 / 3)
        self.assertEqual(a.count_error, 2 / 3)
        self.assertEqual(a.gt_count, 3)


</source>
<source file="systems/raster-vision-0.11.0/tests/evaluation/test_class_evaluation_item.py" startline="42" endline="54" pcid="2844">
    def test_merge(self):
        a = ClassEvaluationItem(
            precision=1, recall=1, f1=1, count_error=0, gt_count=1)
        b = ClassEvaluationItem(
            precision=0, recall=0, f1=0, count_error=1, gt_count=2)
        a.merge(b)
        self.assertEqual(a.precision, 1 / 3)
        self.assertEqual(a.recall, 1 / 3)
        self.assertEqual(a.f1, 1 / 3)
        self.assertEqual(a.count_error, 2 / 3)
        self.assertEqual(a.gt_count, 3)


</source>
</class>

<class classid="138" nclones="6" nlines="21" similarity="76">
<source file="systems/raster-vision-0.11.0/tests_v2/core/evaluation/test_object_detection_evaluation.py" startline="36" endline="60" pcid="2187">
    def test_compute(self):
        class_config = self.make_class_config()
        eval = ObjectDetectionEvaluation(class_config)
        gt_labels = self.make_ground_truth_labels()
        pred_labels = self.make_predicted_labels()

        eval.compute(gt_labels, pred_labels)
        eval_item1 = eval.class_to_eval_item[0]
        self.assertEqual(eval_item1.gt_count, 2)
        self.assertEqual(eval_item1.precision, 1.0)
        self.assertEqual(eval_item1.recall, 1.0)
        self.assertEqual(eval_item1.f1, 1.0)

        eval_item2 = eval.class_to_eval_item[1]
        self.assertEqual(eval_item2.gt_count, 2)
        self.assertEqual(eval_item2.precision, 1.0)
        self.assertEqual(eval_item2.recall, 0.5)
        self.assertEqual(eval_item2.f1, 2 / 3)

        avg_item = eval.avg_item
        self.assertEqual(avg_item.gt_count, 4)
        self.assertAlmostEqual(avg_item.precision, 1.0)
        self.assertEqual(avg_item.recall, 0.75)
        self.assertAlmostEqual(avg_item.f1, 0.83, places=2)

</source>
<source file="systems/raster-vision-0.11.0/tests_v2/core/evaluation/test_object_detection_evaluation.py" startline="61" endline="85" pcid="2188">
    def test_compute_no_preds(self):
        class_config = self.make_class_config()
        eval = ObjectDetectionEvaluation(class_config)
        gt_labels = self.make_ground_truth_labels()
        pred_labels = ObjectDetectionLabels.make_empty()

        eval.compute(gt_labels, pred_labels)
        eval_item1 = eval.class_to_eval_item[0]
        self.assertEqual(eval_item1.gt_count, 2)
        self.assertEqual(eval_item1.precision, None)
        self.assertEqual(eval_item1.recall, 0.0)
        self.assertEqual(eval_item1.f1, None)

        eval_item2 = eval.class_to_eval_item[1]
        self.assertEqual(eval_item2.gt_count, 2)
        self.assertEqual(eval_item2.precision, None)
        self.assertEqual(eval_item2.recall, 0.0)
        self.assertEqual(eval_item2.f1, None)

        avg_item = eval.avg_item
        self.assertEqual(avg_item.gt_count, 4)
        self.assertEqual(avg_item.precision, 0.0)
        self.assertEqual(avg_item.recall, 0.0)
        self.assertEqual(avg_item.f1, 0.0)

</source>
<source file="systems/raster-vision-0.11.0/tests/evaluation/test_object_detection_evaluation.py" startline="63" endline="87" pcid="2850">
    def test_compute_no_preds(self):
        class_map = self.make_class_map()
        eval = ObjectDetectionEvaluation(class_map)
        gt_labels = self.make_ground_truth_labels()
        pred_labels = ObjectDetectionLabels.make_empty()

        eval.compute(gt_labels, pred_labels)
        eval_item1 = eval.class_to_eval_item[1]
        self.assertEqual(eval_item1.gt_count, 2)
        self.assertEqual(eval_item1.precision, None)
        self.assertEqual(eval_item1.recall, 0.0)
        self.assertEqual(eval_item1.f1, None)

        eval_item2 = eval.class_to_eval_item[2]
        self.assertEqual(eval_item2.gt_count, 2)
        self.assertEqual(eval_item2.precision, None)
        self.assertEqual(eval_item2.recall, 0.0)
        self.assertEqual(eval_item2.f1, None)

        avg_item = eval.avg_item
        self.assertEqual(avg_item.gt_count, 4)
        self.assertEqual(avg_item.precision, 0.0)
        self.assertEqual(avg_item.recall, 0.0)
        self.assertEqual(avg_item.f1, 0.0)

</source>
<source file="systems/raster-vision-0.11.0/tests/evaluation/test_object_detection_evaluation.py" startline="38" endline="62" pcid="2849">
    def test_compute(self):
        class_map = self.make_class_map()
        eval = ObjectDetectionEvaluation(class_map)
        gt_labels = self.make_ground_truth_labels()
        pred_labels = self.make_predicted_labels()

        eval.compute(gt_labels, pred_labels)
        eval_item1 = eval.class_to_eval_item[1]
        self.assertEqual(eval_item1.gt_count, 2)
        self.assertEqual(eval_item1.precision, 1.0)
        self.assertEqual(eval_item1.recall, 1.0)
        self.assertEqual(eval_item1.f1, 1.0)

        eval_item2 = eval.class_to_eval_item[2]
        self.assertEqual(eval_item2.gt_count, 2)
        self.assertEqual(eval_item2.precision, 1.0)
        self.assertEqual(eval_item2.recall, 0.5)
        self.assertEqual(eval_item2.f1, 2 / 3)

        avg_item = eval.avg_item
        self.assertEqual(avg_item.gt_count, 4)
        self.assertAlmostEqual(avg_item.precision, 1.0)
        self.assertEqual(avg_item.recall, 0.75)
        self.assertAlmostEqual(avg_item.f1, 0.83, places=2)

</source>
<source file="systems/raster-vision-0.11.0/tests/evaluation/test_object_detection_evaluation.py" startline="88" endline="113" pcid="2851">
    def test_compute_no_ground_truth(self):
        class_map = self.make_class_map()
        eval = ObjectDetectionEvaluation(class_map)
        gt_labels = ObjectDetectionLabels.make_empty()
        pred_labels = self.make_predicted_labels()

        eval.compute(gt_labels, pred_labels)
        eval_item1 = eval.class_to_eval_item[1]
        self.assertEqual(eval_item1.gt_count, 0)
        self.assertEqual(eval_item1.precision, None)
        self.assertEqual(eval_item1.recall, None)
        self.assertEqual(eval_item1.f1, None)

        eval_item2 = eval.class_to_eval_item[2]
        self.assertEqual(eval_item2.gt_count, 0)
        self.assertEqual(eval_item2.precision, None)
        self.assertEqual(eval_item2.recall, None)
        self.assertEqual(eval_item2.f1, None)

        avg_item = eval.avg_item
        self.assertEqual(avg_item.gt_count, 0)
        self.assertEqual(avg_item.precision, None)
        self.assertEqual(avg_item.recall, None)
        self.assertEqual(avg_item.f1, None)


</source>
<source file="systems/raster-vision-0.11.0/tests_v2/core/evaluation/test_object_detection_evaluation.py" startline="86" endline="111" pcid="2189">
    def test_compute_no_ground_truth(self):
        class_config = self.make_class_config()
        eval = ObjectDetectionEvaluation(class_config)
        gt_labels = ObjectDetectionLabels.make_empty()
        pred_labels = self.make_predicted_labels()

        eval.compute(gt_labels, pred_labels)
        eval_item1 = eval.class_to_eval_item[0]
        self.assertEqual(eval_item1.gt_count, 0)
        self.assertEqual(eval_item1.precision, None)
        self.assertEqual(eval_item1.recall, None)
        self.assertEqual(eval_item1.f1, None)

        eval_item2 = eval.class_to_eval_item[1]
        self.assertEqual(eval_item2.gt_count, 0)
        self.assertEqual(eval_item2.precision, None)
        self.assertEqual(eval_item2.recall, None)
        self.assertEqual(eval_item2.f1, None)

        avg_item = eval.avg_item
        self.assertEqual(avg_item.gt_count, 0)
        self.assertEqual(avg_item.precision, None)
        self.assertEqual(avg_item.recall, None)
        self.assertEqual(avg_item.f1, None)


</source>
</class>

<class classid="139" nclones="2" nlines="14" similarity="85">
<source file="systems/raster-vision-0.11.0/tests_v2/core/evaluation/test_semantic_segmentation_evaluator.py" startline="33" endline="52" pcid="2192">
    def get_scene(self, class_id):
        # Make scene where ground truth is all set to class_id
        # and predictions are set to half 0's and half 1's
        scene_id = str(class_id)
        rs = MockRasterSource(channel_order=[0, 1, 2], num_channels=3)
        rs.set_raster(np.zeros((10, 10, 3)))

        gt_rs = MockRasterSource(channel_order=[0], num_channels=1)
        gt_arr = np.full((10, 10, 1), class_id)
        gt_rs.set_raster(gt_arr)
        gt_ls = SemanticSegmentationLabelSource(gt_rs, self.null_class_id)

        pred_rs = MockRasterSource(channel_order=[0], num_channels=1)
        pred_arr = np.zeros((10, 10, 1))
        pred_arr[5:10, :, :] = 1
        pred_rs.set_raster(pred_arr)
        pred_ls = SemanticSegmentationLabelSource(pred_rs, self.null_class_id)

        return Scene(scene_id, rs, gt_ls, pred_ls)

</source>
<source file="systems/raster-vision-0.11.0/tests/evaluation/test_semantic_segmentation_evaluator.py" startline="29" endline="48" pcid="2854">
    def get_scene(self, class_id):
        # Make scene where ground truth is all set to class_id
        # and predictions are set to half 1's and half 2's
        scene_id = str(class_id)
        rs = MockRasterSource(channel_order=[0, 1, 2], num_channels=3)
        rs.set_raster(np.zeros((10, 10, 3)))

        gt_rs = MockRasterSource(channel_order=[0], num_channels=1)
        gt_arr = np.full((10, 10, 1), class_id)
        gt_rs.set_raster(gt_arr)
        gt_ls = SemanticSegmentationLabelSource(source=gt_rs)

        pred_rs = MockRasterSource(channel_order=[0], num_channels=1)
        pred_arr = np.ones((10, 10, 1))
        pred_arr[5:10, :, :] = 2
        pred_rs.set_raster(pred_arr)
        pred_ls = SemanticSegmentationLabelSource(source=pred_rs)

        return Scene(scene_id, rs, gt_ls, pred_ls)

</source>
</class>

<class classid="140" nclones="2" nlines="11" similarity="72">
<source file="systems/raster-vision-0.11.0/tests_v2/core/evaluation/test_semantic_segmentation_evaluator.py" startline="101" endline="116" pcid="2195">
    def test_vector_evaluator(self):
        output_uri = join(self.tmp_dir.name, 'raster-out.json')
        vector_output_uri = join(self.tmp_dir.name, 'vector-out.json')
        scenes = [self.get_vector_scene(0), self.get_vector_scene(1)]
        evaluator = SemanticSegmentationEvaluator(
            self.class_config, output_uri, vector_output_uri)
        evaluator.process(scenes, self.tmp_dir.name)
        vector_eval_json = file_to_json(vector_output_uri)
        exp_vector_eval_json = file_to_json(data_file_path('expected-vector-eval.json'))

        # NOTE:  The precision  and recall  values found  in the  file
        # `expected-vector-eval.json`  are equal to fractions of  the
        # form (n-1)/n for  n <= 7 which  can be seen to  be (and have
        # been manually verified to be) correct.
        self.assertDictEqual(vector_eval_json, exp_vector_eval_json)

</source>
<source file="systems/raster-vision-0.11.0/tests_v2/core/evaluation/test_semantic_segmentation_evaluator.py" startline="117" endline="134" pcid="2196">
    def test_vector_evaluator_with_aoi(self):
        output_uri = join(self.tmp_dir.name, 'raster-out.json')
        vector_output_uri = join(self.tmp_dir.name, 'vector-out.json')
        scenes = [self.get_vector_scene(0, use_aoi=True)]
        evaluator = SemanticSegmentationEvaluator(
            self.class_config, output_uri, vector_output_uri)
        evaluator.process(scenes, self.tmp_dir.name)
        vector_eval_json = file_to_json(vector_output_uri)
        exp_vector_eval_json = file_to_json(
            data_file_path('expected-vector-eval-with-aoi.json'))

        # NOTE:  The precision  and recall  values found  in the  file
        # `expected-vector-eval.json`  are equal to fractions of  the
        # form (n-1)/n for  n <= 7 which  can be seen to  be (and have
        # been manually verified to be) correct.
        self.assertDictEqual(vector_eval_json, exp_vector_eval_json)


</source>
</class>

<class classid="141" nclones="2" nlines="42" similarity="81">
<source file="systems/raster-vision-0.11.0/tests_v2/core/test_stats_analyzer.py" startline="20" endline="64" pcid="2199">
    def _test(self, is_random=False):
        stats_uri = os.path.join(self.tmp_dir.name, 'stats.json')
        scenes = []
        raster_sources = []
        imgs = []
        sample_prob = 0.5
        for i in range(3):
            rs = MockRasterSource([0, 1, 2], 3)
            img = np.zeros((600, 600, 3))
            img[:, :, 0] = 1 + i
            img[:, :, 1] = 2 + i
            img[:, :, 2] = 3 + i
            if not is_random:
                img[300:, 300:, :] = np.nan

            imgs.append(img)
            rs.set_raster(img)
            raster_sources.append(rs)
            scenes.append(Scene(str(i), rs))

        channel_vals = list(map(lambda x: np.expand_dims(x, axis=0), imgs))
        channel_vals = np.concatenate(channel_vals, axis=0)
        channel_vals = np.transpose(channel_vals, [3, 0, 1, 2])
        channel_vals = np.reshape(channel_vals, (3, -1))
        exp_means = np.nanmean(channel_vals, axis=1)
        exp_stds = np.nanstd(channel_vals, axis=1)

        analyzer_cfg = StatsAnalyzerConfig(output_uri=stats_uri, sample_prob=None)
        if is_random:
            analyzer_cfg = StatsAnalyzerConfig(
                output_uri=stats_uri, sample_prob=sample_prob)
        analyzer = analyzer_cfg.build()
        analyzer.process(scenes, self.tmp_dir.name)

        stats = RasterStats.load(stats_uri)
        np.testing.assert_array_almost_equal(stats.means, exp_means, decimal=3)
        np.testing.assert_array_almost_equal(stats.stds, exp_stds, decimal=3)
        if is_random:
            for rs in raster_sources:
                width = rs.get_extent().get_width()
                height = rs.get_extent().get_height()
                exp_num_chips = round(
                    ((width * height) / (chip_sz**2)) * sample_prob)
                self.assertEqual(rs.mock._get_chip.call_count, exp_num_chips)

</source>
<source file="systems/raster-vision-0.11.0/tests/core/test_stats_analyzer.py" startline="20" endline="69" pcid="2921">
    def _test(self, is_random=False, is_backcompat=False):
        stats_uri = os.path.join(self.temp_dir.name, 'stats.json')
        scenes = []
        raster_sources = []
        imgs = []
        sample_prob = 0.5
        for i in range(3):
            rs = MockRasterSource([0, 1, 2], 3)
            img = np.zeros((600, 600, 3))
            img[:, :, 0] = 1 + i
            img[:, :, 1] = 2 + i
            img[:, :, 2] = 3 + i
            if not is_random:
                img[300:, 300:, :] = np.nan

            imgs.append(img)
            rs.set_raster(img)
            raster_sources.append(rs)
            scenes.append(Scene(str(i), rs))

        channel_vals = list(map(lambda x: np.expand_dims(x, axis=0), imgs))
        channel_vals = np.concatenate(channel_vals, axis=0)
        channel_vals = np.transpose(channel_vals, [3, 0, 1, 2])
        channel_vals = np.reshape(channel_vals, (3, -1))
        exp_means = np.nanmean(channel_vals, axis=1)
        exp_stds = np.nanstd(channel_vals, axis=1)

        analyzer_builder = rv.AnalyzerConfig.builder(rv.STATS_ANALYZER)
        if is_random:
            analyzer_builder = analyzer_builder.with_sample_prob(sample_prob)
        analyzer_msg = analyzer_builder.with_stats_uri(stats_uri) \
                                       .build().to_proto()
        if is_backcompat:
            analyzer_msg.stats_analyzer_config.stats_uri = ''
            analyzer_msg.stats_uri = stats_uri

        analyzer_config = rv.AnalyzerConfig.builder(rv.STATS_ANALYZER) \
                            .from_proto(analyzer_msg).build()
        analyzer = analyzer_config.create_analyzer()
        analyzer.process(scenes, self.temp_dir.name)

        stats = RasterStats.load(stats_uri)
        np.testing.assert_array_almost_equal(stats.means, exp_means, decimal=3)
        np.testing.assert_array_almost_equal(stats.stds, exp_stds, decimal=3)
        if is_random:
            for rs in raster_sources:
                width = rs.get_extent().get_width()
                height = rs.get_extent().get_height()
                exp_num_chips = round(
                    ((width * height) / (chip_size**2)) * sample_prob)
</source>
</class>

<class classid="142" nclones="2" nlines="59" similarity="88">
<source file="systems/raster-vision-0.11.0/integration_tests2/semantic_segmentation/config.py" startline="15" endline="82" pcid="2203">
def get_config(runner, root_uri, data_uri=None, full_train=False):
    def get_path(part):
        if full_train:
            return join(data_uri, part)
        else:
            return join(dirname(__file__), part)

    class_config = ClassConfig(
        names=['red', 'green'],
        colors=['red', 'green'])

    def make_scene(id, img_path, label_path):
        raster_source = RasterioSourceConfig(
            channel_order=[0, 1, 2], uris=[img_path])
        label_source = SemanticSegmentationLabelSourceConfig(
            rgb_class_config=class_config,
            raster_source=RasterioSourceConfig(uris=[label_path]))
        label_store = SemanticSegmentationLabelStoreConfig(
            rgb=True, vector_output=[
                PolygonVectorOutputConfig(class_id=0),
                BuildingVectorOutputConfig(class_id=1)])

        return SceneConfig(
            id=id,
            raster_source=raster_source,
            label_source=label_source,
            label_store=label_store)

    if full_train:
        model = SemanticSegmentationModelConfig(backbone=Backbone.resnet50)
        solver = SolverConfig(
            lr=1e-4, num_epochs=300, batch_sz=8, one_cycle=True,
            sync_interval=300)
    else:
        pretrained_uri = (
            's3://raster-vision-lf-dev/integration_tests/semantic_segmentation/output/'
            'train/last-model.pth')
        model = SemanticSegmentationModelConfig(
            backbone=Backbone.resnet50, init_weights=pretrained_uri)
        solver = SolverConfig(
            lr=1e-9, num_epochs=1, batch_sz=2, one_cycle=True, sync_interval=200)
    backend = PyTorchSemanticSegmentationConfig(
        model=model,
        solver=solver,
        log_tensorboard=False,
        run_tensorboard=False,
        augmentors=[])

    scenes = [
        make_scene(
            'test-scene', get_path('scene/image.tif'), get_path('scene/labels.tif')),
        make_scene(
            'test-scene2', get_path('scene/image2.tif'), get_path('scene/labels2.tif'))]
    dataset = DatasetConfig(
        class_config=class_config,
        train_scenes=scenes,
        validation_scenes=scenes)

    chip_options = SemanticSegmentationChipOptions(
        window_method=SemanticSegmentationWindowMethod.sliding, stride=300)

    return SemanticSegmentationConfig(
        root_uri=root_uri,
        dataset=dataset,
        backend=backend,
        train_chip_sz=300,
        predict_chip_sz=300,
        chip_options=chip_options)
</source>
<source file="systems/raster-vision-0.11.0/integration_tests2/object_detection/config.py" startline="13" endline="76" pcid="2221">
def get_config(runner, root_uri, data_uri=None, full_train=False):
    def get_path(part):
        if full_train:
            return join(data_uri, part)
        else:
            return join(dirname(__file__), part)

    class_config = ClassConfig(
        names=['car', 'building'],
        colors=['blue', 'red'])

    def make_scene(scene_id, img_path, label_path):
        raster_source = RasterioSourceConfig(
            channel_order=[0, 1, 2], uris=[img_path])
        label_source = ObjectDetectionLabelSourceConfig(
            vector_source=GeoJSONVectorSourceConfig(
                uri=label_path, default_class_id=None))
        return SceneConfig(
            id=scene_id,
            raster_source=raster_source,
            label_source=label_source)

    if full_train:
        model = ObjectDetectionModelConfig(backbone=Backbone.resnet18)
        solver = SolverConfig(
            lr=1e-4, num_epochs=300, batch_sz=8, one_cycle=True,
            sync_interval=300)
    else:
        pretrained_uri = (
            's3://raster-vision-lf-dev/integration_tests/object_detection/output/train/'
            'last-model.pth')
        model = ObjectDetectionModelConfig(
            backbone=Backbone.resnet18, init_weights=pretrained_uri)
        solver = SolverConfig(
            lr=1e-9, num_epochs=1, batch_sz=2, one_cycle=True, sync_interval=200)
    backend = PyTorchObjectDetectionConfig(
        model=model,
        solver=solver,
        log_tensorboard=False,
        run_tensorboard=False,
        augmentors=[])

    scenes = [
        make_scene(
            'od_test', get_path('scene/image.tif'), get_path('scene/labels.json')),
        make_scene(
            'od_test-2', get_path('scene/image2.tif'), get_path('scene/labels2.json'))]
    dataset = DatasetConfig(
        class_config=class_config,
        train_scenes=scenes,
        validation_scenes=scenes)

    chip_options = ObjectDetectionChipOptions(neg_ratio=1.0, ioa_thresh=1.0)
    predict_options = ObjectDetectionPredictOptions(
        merge_thresh=0.1, score_thresh=0.5)

    return ObjectDetectionConfig(
        root_uri=root_uri,
        dataset=dataset,
        backend=backend,
        train_chip_sz=300,
        predict_chip_sz=300,
        chip_options=chip_options,
        predict_options=predict_options)
</source>
</class>

<class classid="143" nclones="2" nlines="13" similarity="100">
<source file="systems/raster-vision-0.11.0/integration_tests2/integration_tests.py" startline="62" endline="78" pcid="2214">
def check_eval_item(test, expected_item, actual_item):
    errors = []
    f1_threshold = 0.05
    class_name = expected_item['class_name']

    expected_f1 = expected_item['f1'] or 0.0
    actual_f1 = actual_item['f1'] or 0.0
    if math.fabs(expected_f1 - actual_f1) > f1_threshold:
        errors.append(
            TestError(
                test, 'F1 scores are not close enough',
                'for class_name: {} expected f1: {}, actual f1: {}'.format(
                    class_name, expected_item['f1'], actual_item['f1'])))

    return errors


</source>
<source file="systems/raster-vision-0.11.0/integration_tests/integration_tests.py" startline="89" endline="105" pcid="2937">
        return json.load(file)


def check_eval_item(test, expected_item, actual_item):
    errors = []
    f1_threshold = 0.01
    class_name = expected_item['class_name']

    expected_f1 = expected_item['f1'] or 0.0
    actual_f1 = actual_item['f1'] or 0.0
    if math.fabs(expected_f1 - actual_f1) > f1_threshold:
        errors.append(
            TestError(
                test, 'F1 scores are not close enough',
                'for class_name: {} expected f1: {}, actual f1: {}'.format(
                    class_name, expected_item['f1'], actual_item['f1'])))

</source>
</class>

<class classid="144" nclones="2" nlines="17" similarity="94">
<source file="systems/raster-vision-0.11.0/integration_tests2/integration_tests.py" startline="79" endline="101" pcid="2215">
def check_eval(test, tmp_dir):
    errors = []

    actual_eval_path = get_actual_eval_path(test, tmp_dir)
    expected_eval_path = get_expected_eval_path(test)

    if isfile(actual_eval_path):
        expected_eval = file_to_json(expected_eval_path)['overall']
        actual_eval = file_to_json(actual_eval_path)['overall']

        for expected_item in expected_eval:
            class_name = expected_item['class_name']
            actual_item = \
                next(filter(
                    lambda x: x['class_name'] == class_name, actual_eval))
            errors.extend(check_eval_item(test, expected_item, actual_item))
    else:
        errors.append(
            TestError(test, 'actual eval file does not exist',
                      actual_eval_path))

    return errors

</source>
<source file="systems/raster-vision-0.11.0/integration_tests/integration_tests.py" startline="106" endline="128" pcid="2938">
    return errors


def check_eval(test, temp_dir):
    errors = []

    actual_eval_path = get_actual_eval_path(test, temp_dir)
    expected_eval_path = get_expected_eval_path(test)

    if os.path.isfile(actual_eval_path):
        expected_eval = open_json(expected_eval_path)['overall']
        actual_eval = open_json(actual_eval_path)['overall']

        for expected_item in expected_eval:
            class_name = expected_item['class_name']
            actual_item = \
                next(filter(
                    lambda x: x['class_name'] == class_name, actual_eval))
            errors.extend(check_eval_item(test, expected_item, actual_item))
    else:
        errors.append(
            TestError(test, 'actual eval file does not exist',
                      actual_eval_path))
</source>
</class>

<class classid="145" nclones="2" nlines="24" similarity="80">
<source file="systems/raster-vision-0.11.0/integration_tests2/integration_tests.py" startline="232" endline="264" pcid="2220">
    '--verbose', '-v', is_flag=True, help=('Sets the logging level to DEBUG.'))
def main(tests, root_uri, verbose):
    """Runs RV end-to-end and checks that evaluation metrics are correct."""
    if len(tests) == 0:
        tests = all_tests

    if verbose:
        rv_config.set(verbosity=Verbosity.DEBUG)

    with rv_config.get_tmp_dir() as tmp_dir:
        if root_uri:
            tmp_dir = root_uri

        errors = []
        for test in tests:
            if test not in all_tests:
                print('{} is not a valid test.'.format(test))
                return

            errors.extend(run_test(test, tmp_dir))

            for error in errors:
                print(error)

        for test in tests:
            nb_test_errors = len(
                list(filter(lambda error: error.test == test, errors)))
            if nb_test_errors == 0:
                print('{} test passed!'.format(test))

        if errors:
            exit(1)

</source>
<source file="systems/raster-vision-0.11.0/integration_tests/integration_tests.py" startline="293" endline="328" pcid="2944">
    '-t',
    help=('Sets the rv_root directory used. '
          'If set, test will not clean this directory up.'))
@click.option(
    '--verbose', '-v', is_flag=True, help=('Sets the logging level to DEBUG.'))
@click.option(
    '--use-tf', '-v', is_flag=True, help=('Run using TF-based backends.'))
def main(tests, rv_root, verbose, use_tf):
    """Runs RV end-to-end and checks that evaluation metrics are correct."""
    if len(tests) == 0:
        tests = all_tests

    if verbose:
        rv._registry.initialize_config(
            verbosity=rv.cli.verbosity.Verbosity.DEBUG)

    tests = list(map(lambda x: x.upper(), tests))

    with RVConfig.get_tmp_dir() as temp_dir:
        if rv_root:
            temp_dir = rv_root

        errors = []
        for test in tests:
            if test not in all_tests:
                print('{} is not a valid test.'.format(test))
                return

            errors.extend(run_test(test, use_tf, temp_dir))

            for error in errors:
                print(error)

        for test in tests:
            nb_test_errors = len(
                list(filter(lambda error: error.test == test, errors)))
</source>
</class>

<class classid="146" nclones="2" nlines="17" similarity="100">
<source file="systems/raster-vision-0.11.0/integration_tests2/util/flip_scene.py" startline="8" endline="31" pcid="2227">
def flip_geom(m, b, geom):
    """Flips a geom along a straight line y = mx + b.
    """

    def traverse_coords(coords, dst_coords):
        for p in coords:
            if type(p[0]) is list:
                lst = []
                traverse_coords(p, lst)
                dst_coords.append(lst)
            else:
                x, y = p[0], p[1]
                d = (x + (y - b) * m) / (1 + m * m)
                x2 = 2 * d - x
                y2 = 2 * d * m - y + 2 * b
                dst_coords.append((x2, y2))
        return dst_coords

    return {
        'type': geom['type'],
        'coordinates': traverse_coords(geom['coordinates'], [])
    }


</source>
<source file="systems/raster-vision-0.11.0/integration_tests/util/flip_scene.py" startline="8" endline="31" pcid="2952">
def flip_geom(m, b, geom):
    """Flips a geom along a straight line y = mx + b.
    """

    def traverse_coords(coords, dst_coords):
        for p in coords:
            if type(p[0]) is list:
                lst = []
                traverse_coords(p, lst)
                dst_coords.append(lst)
            else:
                x, y = p[0], p[1]
                d = (x + (y - b) * m) / (1 + m * m)
                x2 = 2 * d - x
                y2 = 2 * d * m - y + 2 * b
                dst_coords.append((x2, y2))
        return dst_coords

    return {
        'type': geom['type'],
        'coordinates': traverse_coords(geom['coordinates'], [])
    }


</source>
</class>

<class classid="147" nclones="2" nlines="59" similarity="100">
<source file="systems/raster-vision-0.11.0/integration_tests2/util/flip_scene.py" startline="37" endline="120" pcid="2229">
def flip_scene(src_tiff_path, src_labels_path, dst_tiff_path, dst_labels_path):
    """Flips a scene and it's labels.

    Useful for generating multiple training scenes for integration test usage.
    """

    labels_are_tif = src_labels_path.endswith('.tif')

    with rasterio.open(src_tiff_path) as src:
        profile = src.profile
        bands = src.read()

        with rasterio.open(dst_tiff_path, 'w', **profile) as dst:
            fbands = np.flip(bands, 1)
            dst.write(fbands)

        if not labels_are_tif:

            img_crs = pyproj.Proj(init=src.crs['init'])
            map_crs = pyproj.Proj(init='epsg:4326')

            def t(x, y):
                return pyproj.transform(img_crs, map_crs, x, y)

            # Find the center horizontal line through the image.

            ll = (src.bounds.left, src.bounds.bottom)
            ul = (src.bounds.left, src.bounds.top)
            ur = (src.bounds.right, src.bounds.top)
            lr = (src.bounds.right, src.bounds.bottom)

            left = t(ul[0] - ((ul[0] - ll[0]) / 2),
                     ul[1] - ((ul[1] - ll[1]) / 2))

            right = t(ur[0] - ((ur[0] - lr[0]) / 2),
                      ur[1] - ((ur[1] - lr[1]) / 2))

            m = abs(left[1] - right[1]) / abs(left[0] - right[0])
            b = left[1] - (m * left[0])

    if labels_are_tif:
        with rasterio.open(src_labels_path) as src:
            profile = src.profile
            bands = src.read()

            with rasterio.open(dst_labels_path, 'w', **profile) as dst:
                fbands = np.flip(bands, 1)
                dst.write(fbands)
    else:

        def traverse_labels(src, dst):
            for key in src:
                e = src[key]
                if type(e) is dict:
                    if key == 'geometry':
                        dst[key] = flip_geom(m, b, src[key])
                    else:
                        dst[key] = {}
                        traverse_labels(e, dst[key])
                elif type(e) is list:
                    d_list = []
                    for x in e:
                        if type(x) is dict:
                            ne = {}
                            traverse_labels(x, ne)
                            d_list.append(ne)
                        else:
                            d_list.append(x)
                    dst[key] = d_list
                else:
                    dst[key] = e
            return dst

        with open(src_labels_path) as src_labels_file:
            source_labels = json.loads(src_labels_file.read())

        dst_labels = traverse_labels(source_labels, {})

        with open(dst_labels_path, 'w') as dst_labels_file:
            dst_labels_file.write(json.dumps(dst_labels, indent=4))

    print('done.')


</source>
<source file="systems/raster-vision-0.11.0/integration_tests/util/flip_scene.py" startline="37" endline="120" pcid="2954">
def flip_scene(src_tiff_path, src_labels_path, dst_tiff_path, dst_labels_path):
    """Flips a scene and it's labels.

    Useful for generating multiple training scenes for integration test usage.
    """

    labels_are_tif = src_labels_path.endswith('.tif')

    with rasterio.open(src_tiff_path) as src:
        profile = src.profile
        bands = src.read()

        with rasterio.open(dst_tiff_path, 'w', **profile) as dst:
            fbands = np.flip(bands, 1)
            dst.write(fbands)

        if not labels_are_tif:

            img_crs = pyproj.Proj(init=src.crs['init'])
            map_crs = pyproj.Proj(init='epsg:4326')

            def t(x, y):
                return pyproj.transform(img_crs, map_crs, x, y)

            # Find the center horizontal line through the image.

            ll = (src.bounds.left, src.bounds.bottom)
            ul = (src.bounds.left, src.bounds.top)
            ur = (src.bounds.right, src.bounds.top)
            lr = (src.bounds.right, src.bounds.bottom)

            left = t(ul[0] - ((ul[0] - ll[0]) / 2),
                     ul[1] - ((ul[1] - ll[1]) / 2))

            right = t(ur[0] - ((ur[0] - lr[0]) / 2),
                      ur[1] - ((ur[1] - lr[1]) / 2))

            m = abs(left[1] - right[1]) / abs(left[0] - right[0])
            b = left[1] - (m * left[0])

    if labels_are_tif:
        with rasterio.open(src_labels_path) as src:
            profile = src.profile
            bands = src.read()

            with rasterio.open(dst_labels_path, 'w', **profile) as dst:
                fbands = np.flip(bands, 1)
                dst.write(fbands)
    else:

        def traverse_labels(src, dst):
            for key in src:
                e = src[key]
                if type(e) is dict:
                    if key == 'geometry':
                        dst[key] = flip_geom(m, b, src[key])
                    else:
                        dst[key] = {}
                        traverse_labels(e, dst[key])
                elif type(e) is list:
                    d_list = []
                    for x in e:
                        if type(x) is dict:
                            ne = {}
                            traverse_labels(x, ne)
                            d_list.append(ne)
                        else:
                            d_list.append(x)
                    dst[key] = d_list
                else:
                    dst[key] = e
            return dst

        with open(src_labels_path) as src_labels_file:
            source_labels = json.loads(src_labels_file.read())

        dst_labels = traverse_labels(source_labels, {})

        with open(dst_labels_path, 'w') as dst_labels_file:
            dst_labels_file.write(json.dumps(dst_labels, indent=4))

    print('done.')


</source>
</class>

<class classid="148" nclones="2" nlines="60" similarity="100">
<source file="systems/raster-vision-0.11.0/integration_tests2/util/generate_scene.py" startline="24" endline="112" pcid="2232">
def generate_scene(task, tiff_path, labels_path, chip_size,
                   chips_per_dimension):
    """Generate a synthetic object detection scene.

    Randomly generates a GeoTIFF with red and greed boxes denoting two
    classes and a corresponding label file. This is useful for generating
    synthetic scenes for testing purposes.
    """
    class_map = ClassMap([ClassItem(1, 'car'), ClassItem(2, 'building')])

    # make extent that's divisible by chip_size
    chip_size = chip_size
    ymax = chip_size * chips_per_dimension
    xmax = chip_size * chips_per_dimension
    extent = Box(0, 0, ymax, xmax)

    # make windows along grid
    windows = extent.get_windows(chip_size, chip_size)

    # for each window, make some random boxes within it and render to image
    nb_channels = 3
    image = np.zeros((ymax, xmax, nb_channels)).astype(np.uint8)
    boxes = []
    class_ids = []
    for window in windows:
        # leave some windows blank
        if random.uniform(0, 1) > 0.3:
            # pick a random class
            class_id = random.randint(1, 2)
            box = window.make_random_square(50).to_int()

            boxes.append(box)
            class_ids.append(class_id)

            image[box.ymin:box.ymax, box.xmin:box.xmax, class_id - 1] = 255

    # save image as geotiff centered in philly
    transform = from_origin(-75.163506, 39.952536, 0.000001, 0.000001)

    print('Generated {} boxes with {} different classes.'.format(
        len(boxes), len(set(class_ids))))

    with rasterio.open(
            tiff_path,
            'w',
            driver='GTiff',
            height=ymax,
            transform=transform,
            crs='EPSG:4326',
            compression=rasterio.enums.Compression.none,
            width=xmax,
            count=nb_channels,
            dtype='uint8') as dst:
        for channel_ind in range(0, nb_channels):
            dst.write(image[:, :, channel_ind], channel_ind + 1)

    if task == 'object_detection':
        # make OD labels and make boxes
        npboxes = Box.to_npboxes(boxes)
        class_ids = np.array(class_ids)
        labels = ObjectDetectionLabels(npboxes, class_ids)

        # save labels to geojson
        with rasterio.open(tiff_path) as image_dataset:
            crs_transformer = RasterioCRSTransformer(image_dataset)
            od_file = ObjectDetectionGeoJSONStore(labels_path, crs_transformer,
                                                  class_map)
            od_file.save(labels)
    elif task == 'semantic_segmentation':
        label_image = np.zeros((ymax, xmax, 1)).astype(np.uint8)

        for box, class_id in zip(boxes, class_ids):
            label_image[box.ymin:box.ymax, box.xmin:box.xmax, 0] = class_id

        # save labels to raster
        with rasterio.open(
                labels_path,
                'w',
                driver='GTiff',
                height=ymax,
                transform=transform,
                crs='EPSG:4326',
                compression=rasterio.enums.Compression.none,
                width=xmax,
                count=1,
                dtype='uint8') as dst:
            dst.write(label_image[:, :, 0], 1)


</source>
<source file="systems/raster-vision-0.11.0/integration_tests/util/generate_scene.py" startline="24" endline="112" pcid="2957">
def generate_scene(task, tiff_path, labels_path, chip_size,
                   chips_per_dimension):
    """Generate a synthetic object detection scene.

    Randomly generates a GeoTIFF with red and greed boxes denoting two
    classes and a corresponding label file. This is useful for generating
    synthetic scenes for testing purposes.
    """
    class_map = ClassMap([ClassItem(1, 'car'), ClassItem(2, 'building')])

    # make extent that's divisible by chip_size
    chip_size = chip_size
    ymax = chip_size * chips_per_dimension
    xmax = chip_size * chips_per_dimension
    extent = Box(0, 0, ymax, xmax)

    # make windows along grid
    windows = extent.get_windows(chip_size, chip_size)

    # for each window, make some random boxes within it and render to image
    nb_channels = 3
    image = np.zeros((ymax, xmax, nb_channels)).astype(np.uint8)
    boxes = []
    class_ids = []
    for window in windows:
        # leave some windows blank
        if random.uniform(0, 1) > 0.3:
            # pick a random class
            class_id = random.randint(1, 2)
            box = window.make_random_square(50).to_int()

            boxes.append(box)
            class_ids.append(class_id)

            image[box.ymin:box.ymax, box.xmin:box.xmax, class_id - 1] = 255

    # save image as geotiff centered in philly
    transform = from_origin(-75.163506, 39.952536, 0.000001, 0.000001)

    print('Generated {} boxes with {} different classes.'.format(
        len(boxes), len(set(class_ids))))

    with rasterio.open(
            tiff_path,
            'w',
            driver='GTiff',
            height=ymax,
            transform=transform,
            crs='EPSG:4326',
            compression=rasterio.enums.Compression.none,
            width=xmax,
            count=nb_channels,
            dtype='uint8') as dst:
        for channel_ind in range(0, nb_channels):
            dst.write(image[:, :, channel_ind], channel_ind + 1)

    if task == 'object_detection':
        # make OD labels and make boxes
        npboxes = Box.to_npboxes(boxes)
        class_ids = np.array(class_ids)
        labels = ObjectDetectionLabels(npboxes, class_ids)

        # save labels to geojson
        with rasterio.open(tiff_path) as image_dataset:
            crs_transformer = RasterioCRSTransformer(image_dataset)
            od_file = ObjectDetectionGeoJSONStore(labels_path, crs_transformer,
                                                  class_map)
            od_file.save(labels)
    elif task == 'semantic_segmentation':
        label_image = np.zeros((ymax, xmax, 1)).astype(np.uint8)

        for box, class_id in zip(boxes, class_ids):
            label_image[box.ymin:box.ymax, box.xmin:box.xmax, 0] = class_id

        # save labels to raster
        with rasterio.open(
                labels_path,
                'w',
                driver='GTiff',
                height=ymax,
                transform=transform,
                crs='EPSG:4326',
                compression=rasterio.enums.Compression.none,
                width=xmax,
                count=1,
                dtype='uint8') as dst:
            dst.write(label_image[:, :, 0], 1)


</source>
</class>

<class classid="149" nclones="2" nlines="10" similarity="80">
<source file="systems/raster-vision-0.11.0/tests/mock/raster_source.py" startline="63" endline="73" pcid="2270">
class MockRasterSourceConfig(SupressDeepCopyMixin, RasterSourceConfig):
    def __init__(self, transformers=None, channel_order=None):
        super().__init__(MOCK_SOURCE, transformers, channel_order)
        self.mock = Mock()
        self.mock.to_proto.return_value = None
        self.mock.create_source.return_value = None
        self.mock.update_for_command.return_value = None
        self.mock.save_bundle_files.return_value = (self, [])
        self.mock.load_bundle_files.return_value = self
        self.mock.for_prediction.return_value = self
        self.mock.create_local.return_value = self
</source>
<source file="systems/raster-vision-0.11.0/tests/mock/raster_transformer.py" startline="29" endline="40" pcid="2330">
                                  RasterTransformerConfig):
    def __init__(self):
        super().__init__(MOCK_TRANSFORMER)
        self.mock = Mock()

        self.mock.to_proto.return_value = None
        self.mock.create_transformer.return_value = None
        self.mock.update_for_command.return_value = None
        self.mock.save_bundle_files.return_value = (self, [])
        self.mock.load_bundle_files.return_value = self
        self.mock.for_prediction.return_value = self
        self.mock.create_local.return_value = self
</source>
</class>

<class classid="150" nclones="2" nlines="11" similarity="100">
<source file="systems/raster-vision-0.11.0/tests/mock/command.py" startline="75" endline="88" pcid="2360">

    def get_root_uri(self, experiment_config):
        mock_key = experiment_config.custom_config.get('mock_key')
        if not mock_key:
            mock_uri = experiment_config.custom_config.get('mock_uri')
            if not mock_uri:
                raise rv.ConfigError(
                    'MockCommand requires a mock_key or mock_uri '
                    'be set in the experiment custom_config')
        else:
            mock_uri = os.path.join(experiment_config.root_uri, 'mock',
                                    mock_key)

        return mock_uri
</source>
<source file="systems/raster-vision-0.11.0/tests/data-files/plugins/noop_command.py" startline="53" endline="66" pcid="2399">

    def get_root_uri(self, experiment_config):
        noop_key = experiment_config.custom_config.get('noop_key')
        if not noop_key:
            noop_uri = experiment_config.custom_config.get('noop_uri')
            if not noop_uri:
                raise rv.ConfigError(
                    'NoopCommand requires a noop_key or noop_uri '
                    'be set in the experiment custom_config')
        else:
            noop_uri = os.path.join(experiment_config.root_uri, 'noop',
                                    noop_key)

        return noop_uri
</source>
</class>

<class classid="151" nclones="2" nlines="10" similarity="100">
<source file="systems/raster-vision-0.11.0/tests/command/test_aux_command.py" startline="26" endline="43" pcid="2541">

            self.assertTrue(cmd.mock.run.called)

    def test_command_from_experiment(self):
        with RVConfig.get_tmp_dir() as tmp_dir:
            uris = [('one', '1'), ('two', '2'), ('three', '3'), ('four', '4')]

            e = mk.create_mock_experiment().to_builder() \
                                           .with_root_uri(tmp_dir) \
                                           .with_custom_config({
                                               'mock_aux_command': {
                                                   'key': 'mock',
                                                   'config': {
                                                       'uris': uris
                                                   }
                                               }
                                           }) \
                                           .build()
</source>
<source file="systems/raster-vision-0.11.0/tests/command/test_aux_command.py" startline="44" endline="61" pcid="2542">

            rv.ExperimentRunner.get_runner(rv.LOCAL).run(
                e, splits=2, commands_to_run=[mk.MOCK_AUX_COMMAND])

            # Nothing to assert here, just ensures code path runs.

    def test_command_from_experiment_case_insensitive(self):
        with RVConfig.get_tmp_dir() as tmp_dir:
            uris = [('one', '1'), ('two', '2'), ('three', '3'), ('four', '4')]

            e = mk.create_mock_experiment().to_builder() \
                                           .with_root_uri(tmp_dir) \
                                           .with_custom_config({
                                               'MOCK_AUX_COMMAND': {
                                                   'key': 'mock',
                                                   'config': {
                                                       'uris': uris
                                                   }
</source>
</class>

<class classid="152" nclones="2" nlines="15" similarity="80">
<source file="systems/raster-vision-0.11.0/tests/command/test_analyze_command.py" startline="14" endline="35" pcid="2545">
    def test_command_create(self):
        task = rv.TaskConfig.builder(mk.MOCK_TASK).build()
        with RVConfig.get_tmp_dir() as tmp_dir:
            img_path = os.path.join(tmp_dir, 'img.tif')
            chip = np.ones((2, 2, 4)).astype(np.uint8)
            chip[:, :, :] *= np.array([0, 1, 2, 3]).astype(np.uint8)
            save_img(chip, img_path)

            source = rv.data.RasterioSourceConfig(img_path)

            scenes = [rv.data.SceneConfig('', source)]
            analyzers = [
                rv.analyzer.StatsAnalyzerConfig(stats_uri='dummy_path')
            ]

            cmd_conf = rv.CommandConfig.builder(rv.ANALYZE) \
                                       .with_task(task) \
                                       .with_root_uri(tmp_dir) \
                                       .with_scenes(scenes) \
                                       .with_analyzers(analyzers) \
                                       .build()

</source>
<source file="systems/raster-vision-0.11.0/tests/command/test_eval_command.py" startline="14" endline="33" pcid="2580">
    def test_command_create(self):
        task = rv.TaskConfig.builder(mk.MOCK_TASK).build()
        with RVConfig.get_tmp_dir() as tmp_dir:
            img_path = os.path.join(tmp_dir, 'img.tif')
            chip = np.ones((2, 2, 4)).astype(np.uint8)
            chip[:, :, :] *= np.array([0, 1, 2, 3]).astype(np.uint8)
            save_img(chip, img_path)

            source = rv.data.RasterioSourceConfig(img_path)

            scenes = [rv.data.SceneConfig('scene_id', source)]
            evaluator = rv.EvaluatorConfig.builder(mk.MOCK_EVALUATOR).build()

            cmd_conf = rv.CommandConfig.builder(rv.EVAL) \
                                       .with_task(task) \
                                       .with_root_uri(tmp_dir) \
                                       .with_scenes(scenes) \
                                       .with_evaluators([evaluator]) \
                                       .build()

</source>
</class>

<class classid="153" nclones="2" nlines="12" similarity="75">
<source file="systems/raster-vision-0.11.0/tests/command/test_predict_command.py" startline="44" endline="60" pcid="2556">
            rv.CommandConfig.builder(rv.PREDICT) \
                            .with_task('') \
                            .with_backend('') \
                            .build()

    def test_no_config_error(self):
        task = rv.task.ChipClassificationConfig({})
        backend = rv.backend.KerasClassificationConfig('')
        try:
            with RVConfig.get_tmp_dir() as tmp_dir:
                rv.CommandConfig.builder(rv.PREDICT) \
                                .with_task(task) \
                                .with_root_uri(tmp_dir) \
                                .with_backend(backend) \
                                .with_scenes(['']) \
                                .build()
        except rv.ConfigError:
</source>
<source file="systems/raster-vision-0.11.0/tests/command/test_chip_command.py" startline="47" endline="61" pcid="2563">
                            .with_task('') \
                            .with_backend('') \
                            .with_val_scenes('') \
                            .build()

    def test_missing_config_val_scenes(self):
        with self.assertRaises(rv.ConfigError):
            rv.CommandConfig.builder(rv.CHIP) \
                            .with_task('') \
                            .with_backend('') \
                            .with_train_scenes('') \
                            .build()

    def test_no_config_error(self):
        task = rv.task.ChipClassificationConfig({})
</source>
</class>

<class classid="154" nclones="2" nlines="16" similarity="81">
<source file="systems/raster-vision-0.11.0/tests/command/aux/test_cogify_command.py" startline="13" endline="34" pcid="2564">
    def test_command_create(self):
        src_path = data_file_path('small-rgb-tile.tif')
        with RVConfig.get_tmp_dir() as tmp_dir:
            cog_path = os.path.join(tmp_dir, 'cog.tif')

            cmd_conf = rv.CommandConfig.builder(rv.COGIFY) \
                                       .with_root_uri(tmp_dir) \
                                       .with_config(uris=[(src_path, cog_path)],
                                                    block_size=128) \
                                       .build()

            cmd_conf = rv.command.CommandConfig.from_proto(cmd_conf.to_proto())
            cmd = cmd_conf.create_command()

            self.assertTrue(cmd, rv.command.aux.CogifyCommand)

            cmd.run(tmp_dir)

            # Check that it's cogified
            with rasterio.open(cog_path) as ds:
                self.assertEqual(ds.block_shapes, [(128, 128), (128, 128),
                                                   (128, 128)])
</source>
<source file="systems/raster-vision-0.11.0/tests/command/aux/test_cogify_command.py" startline="35" endline="57" pcid="2565">
                self.assertEqual(ds.overviews(1), [2, 4, 8, 16, 32])
                self.assertEqual(ds.compression.value, 'DEFLATE')

    def test_command_create_no_compression(self):
        src_path = data_file_path('small-rgb-tile.tif')
        with RVConfig.get_tmp_dir() as tmp_dir:
            cog_path = os.path.join(tmp_dir, 'cog.tif')

            cmd_conf = rv.CommandConfig.builder(rv.COGIFY) \
                                       .with_root_uri(tmp_dir) \
                                       .with_config(uris=[(src_path, cog_path)],
                                                    block_size=128,
                                                    compression='none') \
                                       .build()

            cmd_conf = rv.command.CommandConfig.from_proto(cmd_conf.to_proto())
            cmd = cmd_conf.create_command()

            self.assertTrue(cmd, rv.command.aux.CogifyCommand)

            cmd.run(tmp_dir)

            # Check that it's cogified
</source>
</class>

<class classid="155" nclones="2" nlines="31" similarity="87">
<source file="systems/raster-vision-0.11.0/tests/command/test_bundle_command.py" startline="32" endline="70" pcid="2569">
        raster_source = rv.RasterSourceConfig \
                          .builder(rv.RASTERIO_SOURCE) \
                          .with_uri('TEST') \
                          .with_transformer(transformer) \
                          .build()

        scene = rv.SceneConfig.builder() \
                              .with_id('TEST') \
                              .with_raster_source(raster_source) \
                              .build()
        return scene

    def test_bundle_cc_command(self):
        def get_task(tmp_dir):
            predict_package_uri = os.path.join(tmp_dir, 'predict_package.zip')
            t = rv.TaskConfig.builder(rv.CHIP_CLASSIFICATION) \
                             .with_predict_package_uri(predict_package_uri) \
                             .with_classes(['class1']) \
                             .build()
            return t

        def get_backend(task, tmp_dir):
            model_uri = os.path.join(tmp_dir, 'model')
            with open(model_uri, 'w') as f:
                f.write('DUMMY')
            b = rv.BackendConfig.builder(rv.KERAS_CLASSIFICATION) \
                                .with_task(task) \
                                .with_model_defaults(rv.RESNET50_IMAGENET) \
                                .with_model_uri(model_uri) \
                                .build()
            return b

        with RVConfig.get_tmp_dir() as tmp_dir:
            task = get_task(tmp_dir)
            backend = get_backend(task, tmp_dir)
            analyzer = self.get_analyzer(tmp_dir)
            scene = self.get_scene(tmp_dir)
            cmd = rv.CommandConfig.builder(rv.BUNDLE) \
                                  .with_task(task) \
</source>
<source file="systems/raster-vision-0.11.0/tests/command/test_bundle_command.py" startline="71" endline="111" pcid="2572">
                                  .with_root_uri(tmp_dir) \
                                  .with_backend(backend) \
                                  .with_analyzers([analyzer]) \
                                  .with_scene(scene) \
                                  .build() \
                                  .create_command(tmp_dir)

            cmd.run(tmp_dir)

            package_dir = os.path.join(tmp_dir, 'package')
            make_dir(package_dir)
            with zipfile.ZipFile(task.predict_package_uri, 'r') as package_zip:
                package_zip.extractall(path=package_dir)

            bundle_config_path = os.path.join(package_dir,
                                              'bundle_config.json')
            bundle_config = load_json_config(bundle_config_path,
                                             CommandConfigMsg())

            self.assertEqual(bundle_config.command_type, rv.BUNDLE)

            actual = set(os.listdir(package_dir))
            expected = set(['stats.json', 'model', 'bundle_config.json'])

            self.assertEqual(actual, expected)

    def test_bundle_od_command(self):
        def get_task(tmp_dir):
            predict_package_uri = os.path.join(tmp_dir, 'predict_package.zip')
            t = rv.TaskConfig.builder(rv.OBJECT_DETECTION) \
                             .with_predict_package_uri(predict_package_uri) \
                             .with_classes(['class1']) \
                             .build()
            return t

        def get_backend(task, tmp_dir):
            model_uri = os.path.join(tmp_dir, 'model')
            template_uri = data_file_path(
                'tf_object_detection/embedded_ssd_mobilenet_v1_coco.config')
            with open(model_uri, 'w') as f:
                f.write('DUMMY')
</source>
</class>

<class classid="156" nclones="2" nlines="12" similarity="83">
<source file="systems/raster-vision-0.11.0/tests/data/label_source/test_semantic_segmentation_label_source.py" startline="14" endline="25" pcid="2601">
    def test_enough_target_pixels_true(self):
        data = np.zeros((10, 10, 3), dtype=np.uint8)
        data[4:, 4:, :] = [1, 1, 1]
        raster_source = MockRasterSource([0, 1, 2], 3)
        raster_source.set_raster(data)
        rgb_class_map = ClassMap([ClassItem(id=1, color='#010101')])
        label_source = SemanticSegmentationLabelSource(
            source=raster_source, rgb_class_map=rgb_class_map)
        with label_source.activate():
            extent = Box(0, 0, 10, 10)
            self.assertTrue(label_source.enough_target_pixels(extent, 30, [1]))

</source>
<source file="systems/raster-vision-0.11.0/tests/data/label_source/test_semantic_segmentation_label_source.py" startline="26" endline="38" pcid="2602">
    def test_enough_target_pixels_false(self):
        data = np.zeros((10, 10, 3), dtype=np.uint8)
        data[7:, 7:, :] = [1, 1, 1]
        raster_source = MockRasterSource([0, 1, 2], 3)
        raster_source.set_raster(data)
        rgb_class_map = ClassMap([ClassItem(id=1, color='#010101')])
        label_source = SemanticSegmentationLabelSource(
            source=raster_source, rgb_class_map=rgb_class_map)
        with label_source.activate():
            extent = Box(0, 0, 10, 10)
            self.assertFalse(
                label_source.enough_target_pixels(extent, 30, [1]))

</source>
</class>

<class classid="157" nclones="2" nlines="13" similarity="92">
<source file="systems/raster-vision-0.11.0/tests/data/label_source/test_chip_classification_label_source.py" startline="209" endline="225" pcid="2620">
        self.assertEqual(labels.get_cell_class_id(self.box1), self.class_id1)
        self.assertEqual(labels.get_cell_class_id(self.box2), self.class_id2)
        self.assertEqual(
            labels.get_cell_class_id(Box.make_square(0, 4, 4)),
            self.background_class_id)
        self.assertEqual(
            labels.get_cell_class_id(Box.make_square(4, 0, 4)),
            self.background_class_id)

    def test_get_labels_small_extent(self):
        # Extent only has enough of first box in it.
        extent = Box.make_square(0, 0, 2)

        msg = rv.LabelSourceConfig.builder(rv.CHIP_CLASSIFICATION) \
                .with_uri(self.uri) \
                .build().to_proto()
        config = rv.LabelSourceConfig.builder(rv.CHIP_CLASSIFICATION) \
</source>
<source file="systems/raster-vision-0.11.0/tests/data/label_source/test_chip_classification_label_source.py" startline="226" endline="242" pcid="2621">
                   .from_proto(msg).build()
        source = config.create_source(self.task_config, extent,
                                      self.crs_transformer, self.temp_dir.name)
        labels = source.get_labels()

        cells = labels.get_cells()
        self.assertEqual(len(cells), 1)
        class_id = labels.get_cell_class_id(self.box1)
        self.assertEqual(class_id, self.class_id1)
        class_id = labels.get_cell_class_id(self.box2)
        self.assertEqual(class_id, None)

    def test_get_labels(self):
        # Extent contains both boxes.
        extent = Box.make_square(0, 0, 8)

        msg = rv.LabelSourceConfig.builder(rv.CHIP_CLASSIFICATION) \
</source>
</class>

<class classid="158" nclones="2" nlines="16" similarity="93">
<source file="systems/raster-vision-0.11.0/tests/data/raster_source/test_rasterio_source.py" startline="93" endline="114" pcid="2644">
        source = rv.data.RasterioSourceConfig(uris=[img_path],
                                              channel_order=channel_order) \
                        .create_source(tmp_dir=None)

        with source.activate():
            out_chip = source.get_raw_image_array()
            self.assertEqual(out_chip.shape[2], 3)

    def test_shift_x(self):
        # Specially-engineered image w/ one meter per pixel resolution
        # in the x direction.
        img_path = data_file_path('ones.tif')
        channel_order = [0]

        msg = rv.data.RasterioSourceConfig(uris=[img_path],
                                           x_shift_meters=1.0,
                                           y_shift_meters=0.0,
                                           channel_order=channel_order) \
                     .to_proto()

        tmp_dir = RVConfig.get_tmp_dir().name
        make_dir(tmp_dir)
</source>
<source file="systems/raster-vision-0.11.0/tests/data/raster_source/test_rasterio_source.py" startline="115" endline="136" pcid="2645">
        source = rv.RasterSourceConfig.from_proto(msg) \
                                      .create_source(tmp_dir=tmp_dir)

        with source.activate():
            extent = source.get_extent()
            data = source.get_chip(extent)
            self.assertEqual(data.sum(), 2**16 - 256)
            column = data[:, 255, 0]
            self.assertEqual(column.sum(), 0)

    def test_shift_y(self):
        # Specially-engineered image w/ one meter per pixel resolution
        # in the y direction.
        img_path = data_file_path('ones.tif')
        channel_order = [0]

        msg = rv.data.RasterioSourceConfig(uris=[img_path],
                                           x_shift_meters=0.0,
                                           y_shift_meters=1.0,
                                           channel_order=channel_order) \
                     .to_proto()

</source>
</class>

<class classid="159" nclones="3" nlines="35" similarity="89">
<source file="systems/raster-vision-0.11.0/tests/utils/test_misc.py" startline="57" endline="107" pcid="2740">
    def test_set_nested_keys_finds_nested(self):
        d = {
            'one': 1,
            'two': 2,
            'three': {
                'four': 4,
                'five': 5,
                'six': [
                    {
                        'seven': 7
                    },
                    {
                        'eight': 8
                    },
                    {
                        'nine': 9
                    },
                ],
                'ten': {
                    'eleven': 11
                }
            }
        }

        expected = {
            'one': 1,
            'two': 2,
            'three': {
                'four': 4,
                'five': 55,
                'six': [
                    {
                        'seven': 7
                    },
                    {
                        'eight': 8
                    },
                    {
                        'nine': 9
                    },
                ],
                'ten': {
                    'eleven': 11
                }
            }
        }

        set_nested_keys(d, {'five': 55})

        self.assertEqual(d, expected)

</source>
<source file="systems/raster-vision-0.11.0/tests/utils/test_misc.py" startline="159" endline="212" pcid="2742">
    def test_set_nested_keys_sets_missing_keys_in_dict(self):
        d = {
            'one': 1,
            'two': 2,
            'three': {
                'four': 4,
                'five': 5,
                'six': [
                    {
                        'seven': 7
                    },
                    {
                        'eight': 8
                    },
                    {
                        'nine': 9
                    },
                ],
                'ten': {
                    'eleven': 11
                }
            }
        }

        expected = {
            'one': 1,
            'two': 2,
            'three': {
                'four': 4,
                'five': 5,
                'six': [
                    {
                        'seven': 7
                    },
                    {
                        'eight': 8
                    },
                    {
                        'nine': 9
                    },
                ],
                'ten': {
                    'eleven': 11
                },
                'twelve': 12
            }
        }

        mod = {'three': {'twelve': 12}}

        set_nested_keys(d, mod, set_missing_keys=True)

        self.assertEqual(d, expected)

</source>
<source file="systems/raster-vision-0.11.0/tests/utils/test_misc.py" startline="108" endline="158" pcid="2741">
    def test_set_nested_keys_ignores_missing_keys(self):
        d = {
            'one': 1,
            'two': 2,
            'three': {
                'four': 4,
                'five': 5,
                'six': [
                    {
                        'seven': 7
                    },
                    {
                        'eight': 8
                    },
                    {
                        'nine': 9
                    },
                ],
                'ten': {
                    'eleven': 11
                }
            }
        }

        expected = {
            'one': 1,
            'two': 2,
            'three': {
                'four': 4,
                'five': 5,
                'six': [
                    {
                        'seven': 7
                    },
                    {
                        'eight': 8
                    },
                    {
                        'nine': 9
                    },
                ],
                'ten': {
                    'eleven': 11
                }
            }
        }

        set_nested_keys(d, {'twenty': 20}, ignore_missing_keys=True)

        self.assertEqual(d, expected)

</source>
</class>

<class classid="160" nclones="3" nlines="14" similarity="71">
<source file="systems/raster-vision-0.11.0/tests/evaluation/test_semantic_segmentation_evaluator.py" startline="86" endline="99" pcid="2856">
    def test_evaluator(self):
        class_map = ClassMap([
            ClassItem(id=1, name='one'),
            ClassItem(id=2, name='two'),
        ])
        output_uri = join(self.tmp_dir.name, 'out.json')
        scenes = [self.get_scene(1), self.get_scene(2)]
        evaluator = SemanticSegmentationEvaluator(class_map, output_uri, None)
        evaluator.process(scenes, self.tmp_dir.name)
        eval_json = json.loads(file_to_str(output_uri))
        exp_eval_json = json.loads(
            file_to_str(data_file_path('expected-eval.json')))
        self.assertDictEqual(eval_json, exp_eval_json)

</source>
<source file="systems/raster-vision-0.11.0/tests/evaluation/test_semantic_segmentation_evaluator.py" startline="120" endline="140" pcid="2858">
    def test_vector_evaluator_with_aoi(self):
        class_map = ClassMap([
            ClassItem(id=1, name='one'),
        ])
        output_uri = join(self.tmp_dir.name, 'raster-out.json')
        vector_output_uri = join(self.tmp_dir.name, 'vector-out.json')
        scenes = [self.get_vector_scene(1, use_aoi=True)]
        evaluator = SemanticSegmentationEvaluator(class_map, output_uri,
                                                  vector_output_uri)
        evaluator.process(scenes, self.tmp_dir.name)
        vector_eval_json = json.loads(file_to_str(vector_output_uri))
        exp_vector_eval_json = json.loads(
            file_to_str(data_file_path('expected-vector-eval-with-aoi.json')))

        # NOTE:  The precision  and recall  values found  in the  file
        # `expected-vector-eval.json`  are equal to fractions of  the
        # form (n-1)/n for  n <= 7 which  can be seen to  be (and have
        # been manually verified to be) correct.
        self.assertDictEqual(vector_eval_json, exp_vector_eval_json)


</source>
<source file="systems/raster-vision-0.11.0/tests/evaluation/test_semantic_segmentation_evaluator.py" startline="100" endline="119" pcid="2857">
    def test_vector_evaluator(self):
        class_map = ClassMap([
            ClassItem(id=1, name='one'),
            ClassItem(id=2, name='two'),
        ])
        output_uri = join(self.tmp_dir.name, 'raster-out.json')
        vector_output_uri = join(self.tmp_dir.name, 'vector-out.json')
        scenes = [self.get_vector_scene(1), self.get_vector_scene(2)]
        evaluator = SemanticSegmentationEvaluator(class_map, output_uri,
                                                  vector_output_uri)
        evaluator.process(scenes, self.tmp_dir.name)
        vector_eval_json = json.loads(file_to_str(vector_output_uri))
        exp_vector_eval_json = json.loads(
            file_to_str(data_file_path('expected-vector-eval.json')))
        # NOTE:  The precision  and recall  values found  in the  file
        # `expected-vector-eval.json`  are equal to fractions of  the
        # form (n-1)/n for  n <= 7 which  can be seen to  be (and have
        # been manually verified to be) correct.
        self.assertDictEqual(vector_eval_json, exp_vector_eval_json)

</source>
</class>

<class classid="161" nclones="3" nlines="20" similarity="85">
<source file="systems/raster-vision-0.11.0/tests/task/test_semantic_segmentation_config.py" startline="22" endline="48" pcid="2863">
        self.assertListEqual(t.class_map.get_items(), expected)
        self.assertListEqual(t.chip_options.target_classes, [1, 2])

    def test_build_task_from_proto(self):
        task_config = {
            'task_type': rv.SEMANTIC_SEGMENTATION,
            'semantic_segmentation_config': {
                'chip_options': {
                    'debug_chip_probability': 0.75
                },
                'chip_size':
                500,
                'class_items': [{
                    'id': 1,
                    'name': 'car',
                    'color': 'red'
                }, {
                    'id': 2,
                    'name': 'building',
                    'color': 'blue'
                }]
            }
        }
        msg = json_format.Parse(json.dumps(task_config), TaskConfigMsg())
        task = rv.TaskConfig.from_proto(msg)

        self.assertEqual(task.class_map.get_by_name('building').id, 2)
</source>
<source file="systems/raster-vision-0.11.0/tests/task/test_object_detection_config.py" startline="21" endline="47" pcid="2872">
        self.assertListEqual(t.class_map.get_items(), expected)

    def test_build_task_from_proto(self):
        task_config = {
            'task_type': rv.OBJECT_DETECTION,
            'object_detection_config': {
                'chip_size':
                500,
                'class_items': [{
                    'id': 1,
                    'name': 'car',
                    'color': 'red'
                }, {
                    'id': 2,
                    'name': 'building',
                    'color': 'blue'
                }, {
                    'id': 3,
                    'name': 'background',
                    'color': 'black'
                }]
            }
        }
        msg = json_format.Parse(json.dumps(task_config), TaskConfigMsg())
        task = rv.TaskConfig.from_proto(msg)

        self.assertEqual(task.class_map.get_by_name('building').id, 2)
</source>
<source file="systems/raster-vision-0.11.0/tests/task/test_chip_classification_config.py" startline="21" endline="48" pcid="2867">
        self.assertListEqual(t.class_map.get_items(), expected)

    def test_build_task_from_proto(self):
        task_config = {
            'task_type': rv.CHIP_CLASSIFICATION,
            'chip_classification_config': {
                'chip_size':
                500,
                'class_items': [{
                    'id': 1,
                    'name': 'car',
                    'color': 'red'
                }, {
                    'id': 2,
                    'name': 'building',
                    'color': 'blue'
                }, {
                    'id': 3,
                    'name': 'background',
                    'color': 'black'
                }]
            }
        }
        msg = json_format.Parse(json.dumps(task_config), TaskConfigMsg())

        task = rv.TaskConfig.from_proto(msg)

        self.assertEqual(task.class_map.get_by_name('building').id, 2)
</source>
</class>

<class classid="162" nclones="3" nlines="12" similarity="100">
<source file="systems/raster-vision-0.11.0/tests/task/test_semantic_segmentation_config.py" startline="49" endline="68" pcid="2864">
        self.assertEqual(task.chip_size, 500)
        self.assertEqual(task.chip_options.debug_chip_probability, 0.75)

    def test_create_proto_from_task(self):
        t = rv.TaskConfig.builder(rv.SEMANTIC_SEGMENTATION) \
                         .with_classes(['car', 'boat']) \
                         .with_chip_size(500) \
                         .build()

        msg = t.to_proto()

        expected_classes = [
            ClassItemMsg(name='car', id=1),
            ClassItemMsg(name='boat', id=2)
        ]

        self.assertEqual(msg.task_type, rv.SEMANTIC_SEGMENTATION)
        self.assertEqual(msg.semantic_segmentation_config.chip_size, 500)

        actual_class_items = dict(
</source>
<source file="systems/raster-vision-0.11.0/tests/task/test_chip_classification_config.py" startline="49" endline="67" pcid="2868">
        self.assertEqual(task.chip_size, 500)

    def test_create_proto_from_task(self):
        t = rv.TaskConfig.builder(rv.CHIP_CLASSIFICATION) \
                         .with_classes(['car', 'boat']) \
                         .with_chip_size(500) \
                         .build()

        msg = t.to_proto()

        expected_classes = [
            ClassItemMsg(name='car', id=1),
            ClassItemMsg(name='boat', id=2)
        ]

        self.assertEqual(msg.task_type, rv.CHIP_CLASSIFICATION)
        self.assertEqual(msg.chip_classification_config.chip_size, 500)

        actual_class_items = dict(
</source>
<source file="systems/raster-vision-0.11.0/tests/task/test_object_detection_config.py" startline="48" endline="66" pcid="2873">
        self.assertEqual(task.chip_size, 500)

    def test_create_proto_from_task(self):
        t = rv.TaskConfig.builder(rv.OBJECT_DETECTION) \
                         .with_classes(['car', 'boat']) \
                         .with_chip_size(500) \
                         .build()

        msg = t.to_proto()

        expected_classes = [
            ClassItemMsg(name='car', id=1),
            ClassItemMsg(name='boat', id=2)
        ]

        self.assertEqual(msg.task_type, rv.OBJECT_DETECTION)
        self.assertEqual(msg.object_detection_config.chip_size, 500)

        actual_class_items = dict(
</source>
</class>

<class classid="163" nclones="2" nlines="10" similarity="90">
<source file="systems/raster-vision-0.11.0/tests/core/test_class_map.py" startline="57" endline="68" pcid="2883">

    def test_construct_from_protos(self):
        source = [
            ClassItemMsg(id=1, name='one', color='red'),
            ClassItemMsg(id=2, name='two', color='green'),
            ClassItemMsg(id=3, name='three', color='blue')
        ]
        cm = ClassMap.construct_from(source)
        for i, msg in enumerate(source):
            expected = ClassItem.from_proto(msg)
            actual = cm.get_by_id(i + 1)
            self.assertEqual(actual, expected)
</source>
<source file="systems/raster-vision-0.11.0/tests/core/test_class_map.py" startline="69" endline="80" pcid="2884">

    def test_construct_from_class_items(self):
        source = [
            ClassItem(id=1, name='one', color='red'),
            ClassItem(id=2, name='two', color='green'),
            ClassItem(id=3, name='three', color='blue')
        ]
        cm = ClassMap.construct_from(source)
        for i, item in enumerate(source):
            expected = item
            actual = cm.get_by_id(i + 1)
            self.assertEqual(actual, expected)
</source>
</class>

<class classid="164" nclones="2" nlines="45" similarity="76">
<source file="systems/raster-vision-0.11.0/integration_tests/chip_classification_tests/experiment.py" startline="8" endline="73" pcid="2945">
    def exp_main(self, root_uri, data_uri=None, full_train=False,
                 use_tf=False):
        full_train = str_to_bool(full_train)
        use_tf = str_to_bool(use_tf)

        def get_path(part):
            if full_train:
                return os.path.join(data_uri, part)
            else:
                return os.path.join(os.path.dirname(__file__), part)

        img_path = get_path('scene/image.tif')
        label_path = get_path('scene/labels.json')

        img2_path = get_path('scene/image2.tif')
        label2_path = get_path('scene/labels2.json')

        backend_conf_path = get_path('configs/backend.config')

        task = rv.TaskConfig.builder(rv.CHIP_CLASSIFICATION) \
                            .with_chip_size(200) \
                            .with_classes({
                                'car': (1, 'red'),
                                'building': (2, 'blue'),
                                'background': (3, 'black')
                            }) \
                            .with_debug(True) \
                            .build()

        if use_tf:
            pretrained_model = (
                'https://github.com/azavea/raster-vision-data/'
                'releases/download/v0.0.7/chip-classification-test-weights.hdf5'
            )

            backend = rv.BackendConfig.builder(rv.KERAS_CLASSIFICATION) \
                .with_task(task) \
                .with_debug(True) \
                .with_template(backend_conf_path) \
                .with_num_epochs(8) \
                .with_pretrained_model(pretrained_model) \
                .with_train_options(sync_interval=None,
                                    do_monitoring=False,
                                    replace_model=True) \
                .build()
        else:
            if full_train:
                backend = rv.BackendConfig.builder(rv.PYTORCH_CHIP_CLASSIFICATION) \
                    .with_task(task) \
                    .with_train_options(
                        batch_size=16,
                        num_epochs=10,
                        sync_interval=200) \
                    .build()
            else:
                pretrained_uri = (
                    'https://github.com/azavea/raster-vision-data/releases/download/'
                    'v0.9.0/pytorch_chip_classification_test.pth')
                backend = rv.BackendConfig.builder(rv.PYTORCH_CHIP_CLASSIFICATION) \
                    .with_task(task) \
                    .with_train_options(
                        batch_size=2,
                        num_epochs=1,
                        lr=1e-9) \
                    .with_pretrained_uri(pretrained_uri) \
                    .build()
</source>
<source file="systems/raster-vision-0.11.0/integration_tests/object_detection_tests/experiment.py" startline="8" endline="67" pcid="2950">
    def exp_main(self, root_uri, data_uri=None, full_train=False,
                 use_tf=False):
        full_train = str_to_bool(full_train)
        use_tf = str_to_bool(use_tf)

        def get_path(part):
            if full_train:
                return os.path.join(data_uri, part)
            else:
                return os.path.join(os.path.dirname(__file__), part)

        img_path = get_path('scene/image.tif')
        label_path = get_path('scene/labels.json')
        img2_path = get_path('scene/image2.tif')
        label2_path = get_path('scene/labels2.json')
        backend_conf_path = get_path('configs/backend.config')

        task = rv.TaskConfig.builder(rv.OBJECT_DETECTION) \
                            .with_chip_size(300) \
                            .with_classes({
                                'car': (1, 'blue'),
                                'building': (2, 'red')
                            }) \
                            .with_chip_options(neg_ratio=1.0,
                                               ioa_thresh=1.0,
                                               window_method='sliding') \
                            .with_predict_options(merge_thresh=0.1,
                                                  score_thresh=0.5) \
                            .build()

        if use_tf:
            pretrained_model = (
                'https://github.com/azavea/raster-vision-data/'
                'releases/download/v0.0.7/object-detection-test.tar.gz')

            backend = rv.BackendConfig.builder(rv.TF_OBJECT_DETECTION) \
                                    .with_task(task) \
                                    .with_num_steps(200) \
                                    .with_template(backend_conf_path) \
                                    .with_pretrained_model(pretrained_model) \
                                    .with_train_options(sync_interval=None,
                                                        do_monitoring=False,
                                                        replace_model=True) \
                                    .with_debug(True) \
                                    .build()
        else:
            if full_train:
                backend = rv.BackendConfig.builder(rv.PYTORCH_OBJECT_DETECTION) \
                    .with_task(task) \
                    .with_train_options(
                        batch_size=8,
                        num_epochs=200,
                        sync_interval=200) \
                    .build()
            else:
                pretrained_uri = (
                    'https://github.com/azavea/raster-vision-data/releases/download/'
                    'v0.9.0/pytorch_object_detection_test.pth')

                backend = rv.BackendConfig.builder(rv.PYTORCH_OBJECT_DETECTION) \
</source>
</class>

</clones>
