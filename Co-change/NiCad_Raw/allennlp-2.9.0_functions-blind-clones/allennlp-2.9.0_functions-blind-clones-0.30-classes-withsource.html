<html>
<head>
    <title>NiCad6 Clone Report</title>
    <style type="text/css">
        body {font-family:sans-serif;}
        table {background-color:white; border:0px; padding:0px; border-spacing:4px; width:auto; margin-left:30px; margin-right:auto;}
        td {background-color:rgba(192,212,238,0.8); border:0px; padding:8px; width:auto; vertical-align:top; border-radius:8px}
        pre {background-color:white; padding:4px;}
        a {color:darkblue;}
    </style>
</head>
<body>
<h2>NiCad6 Clone Report</h2>
<table>
<tr style="font-size:14pt">
<td><b>System:</b> &nbsp; allennlp-2.9.0</td>
<td><b>Clone pairs:</b> &nbsp; 333</td>
<td><b>Clone classes:</b> &nbsp; 88</td>
</tr>
<tr style="font-size:12pt">
<td style="background-color:white">Clone type: &nbsp; 3-2</td>
<td style="background-color:white">Granularity: &nbsp; functions-blind</td>
<td style="background-color:white">Max diff threshold: &nbsp; 30%</td>
<td style="background-color:white">Clone size: &nbsp; 10 - 2500 lines</td>
<td style="background-color:white">Total functions-blind: &nbsp; 1677</td>
</tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 1:</b> &nbsp; 2 fragments, nominal size 20 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag15')" href="javascript:;">
allennlp-2.9.0/scripts/tests/ai2_internal/resume_daemon_test.py: 69-91
</a>
<div class="mid" id="frag15" style="display:none"><pre>
    def test_respects_upper_bound_on_resumes(self):
        beaker = Mock()
        experiment_id = "foo"
        start_autoresume(self.connection, experiment_id, 5)
        beaker.get_status.return_value = BeakerStatus.preempted
        for i in range(10):
            beaker.resume.return_value = f"foo{i}"
            resume(self.connection, beaker)
        calls = [
            call.get_status("foo"),
            call.resume("foo"),
            call.get_status("foo0"),
            call.resume("foo0"),
            call.get_status("foo1"),
            call.resume("foo1"),
            call.get_status("foo2"),
            call.resume("foo2"),
            call.get_status("foo3"),
            call.resume("foo3"),
            call.get_status("foo4"),
        ]
        beaker.assert_has_calls(calls)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag16')" href="javascript:;">
allennlp-2.9.0/scripts/tests/ai2_internal/resume_daemon_test.py: 92-109
</a>
<div class="mid" id="frag16" style="display:none"><pre>
    def test_handles_a_realistic_scenario(self):
        beaker = Mock()
        experiment_id = "foo"
        start_autoresume(self.connection, experiment_id, 5)
        beaker.get_status.return_value = BeakerStatus.preempted
        for i in range(10):
            beaker.resume.return_value = f"foo{i}"
            if i == 2:
                beaker.get_status.return_value = BeakerStatus.succeeded
            resume(self.connection, beaker)
        calls = [
            call.get_status("foo"),
            call.resume("foo"),
            call.get_status("foo0"),
            call.resume("foo0"),
            call.get_status("foo1"),
        ]
        beaker.assert_has_calls(calls)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 2:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 83%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag35')" href="javascript:;">
allennlp-2.9.0/allennlp/training/momentum_schedulers/inverted_triangular.py: 21-33
</a>
<div class="mid" id="frag35" style="display:none"><pre>
    def __init__(
        self,
        optimizer: torch.optim.Optimizer,
        cool_down: int,
        warm_up: int,
        ratio: int = 10,
        last_epoch: int = -1,
    ) -&gt; None:
        self.cool_down = cool_down
        self.warm_up = warm_up
        self.ratio = ratio
        super().__init__(optimizer, last_epoch)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag63')" href="javascript:;">
allennlp-2.9.0/allennlp/training/learning_rate_schedulers/noam.py: 60-72
</a>
<div class="mid" id="frag63" style="display:none"><pre>
    def __init__(
        self,
        optimizer: torch.optim.Optimizer,
        model_size: int,
        warmup_steps: int,
        factor: float = 1.0,
        last_epoch: int = -1,
    ) -&gt; None:
        self.warmup_steps = warmup_steps
        self.factor = factor
        self.model_size = model_size
        super().__init__(optimizer, last_epoch=last_epoch)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 3:</b> &nbsp; 14 fragments, nominal size 18 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag77')" href="javascript:;">
allennlp-2.9.0/allennlp/training/learning_rate_schedulers/learning_rate_scheduler.py: 158-175
</a>
<div class="mid" id="frag77" style="display:none"><pre>
    def __init__(
        self,
        optimizer: Optimizer,
        num_warmup_steps: int,
        num_training_steps: int,
        num_cycles: float = 0.5,
        last_epoch: int = -1,
    ) -&gt; None:
        lr_scheduler = get_cosine_schedule_with_warmup(
            optimizer=optimizer,
            num_warmup_steps=num_warmup_steps,
            num_training_steps=num_training_steps,
            num_cycles=num_cycles,
            last_epoch=last_epoch,
        )
        super().__init__(lr_scheduler)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag544')" href="javascript:;">
allennlp-2.9.0/allennlp/modules/seq2vec_encoders/pytorch_seq2vec_wrapper.py: 234-253
</a>
<div class="mid" id="frag544" style="display:none"><pre>
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        num_layers: int,
        recurrent_dropout_probability: float = 0.0,
        use_highway: bool = True,
        use_input_projection_bias: bool = True,
    ) -&gt; None:
        module = StackedAlternatingLstm(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            recurrent_dropout_probability=recurrent_dropout_probability,
            use_highway=use_highway,
            use_input_projection_bias=use_input_projection_bias,
        )
        super().__init__(module=module)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag545')" href="javascript:;">
allennlp-2.9.0/allennlp/modules/seq2vec_encoders/pytorch_seq2vec_wrapper.py: 260-277
</a>
<div class="mid" id="frag545" style="display:none"><pre>
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        num_layers: int,
        recurrent_dropout_probability: float = 0.0,
        layer_dropout_probability: float = 0.0,
        use_highway: bool = True,
    ) -&gt; None:
        module = StackedBidirectionalLstm(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            recurrent_dropout_probability=recurrent_dropout_probability,
            layer_dropout_probability=layer_dropout_probability,
            use_highway=use_highway,
        )
        super().__init__(module=module)
</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag577')" href="javascript:;">
allennlp-2.9.0/allennlp/modules/seq2seq_encoders/pytorch_seq2seq_wrapper.py: 271-289
</a>
<div class="mid" id="frag577" style="display:none"><pre>
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        num_layers: int,
        recurrent_dropout_probability: float = 0.0,
        layer_dropout_probability: float = 0.0,
        use_highway: bool = True,
        stateful: bool = False,
    ) -&gt; None:
        module = StackedBidirectionalLstm(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            recurrent_dropout_probability=recurrent_dropout_probability,
            layer_dropout_probability=layer_dropout_probability,
            use_highway=use_highway,
        )
        super().__init__(module=module, stateful=stateful)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag576')" href="javascript:;">
allennlp-2.9.0/allennlp/modules/seq2seq_encoders/pytorch_seq2seq_wrapper.py: 244-264
</a>
<div class="mid" id="frag576" style="display:none"><pre>
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        num_layers: int,
        recurrent_dropout_probability: float = 0.0,
        use_highway: bool = True,
        use_input_projection_bias: bool = True,
        stateful: bool = False,
    ) -&gt; None:
        module = StackedAlternatingLstm(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            recurrent_dropout_probability=recurrent_dropout_probability,
            use_highway=use_highway,
            use_input_projection_bias=use_input_projection_bias,
        )
        super().__init__(module=module, stateful=stateful)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag78')" href="javascript:;">
allennlp-2.9.0/allennlp/training/learning_rate_schedulers/learning_rate_scheduler.py: 202-217
</a>
<div class="mid" id="frag78" style="display:none"><pre>
    def __init__(
        self,
        optimizer: Optimizer,
        num_warmup_steps: int,
        num_training_steps: int,
        num_cycles: int = 1,
        last_epoch: int = -1,
    ) -&gt; None:
        lr_scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(
            optimizer=optimizer,
            num_warmup_steps=num_warmup_steps,
            num_training_steps=num_training_steps,
            num_cycles=num_cycles,
            last_epoch=last_epoch,
        )
        super().__init__(lr_scheduler)
</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag543')" href="javascript:;">
allennlp-2.9.0/allennlp/modules/seq2vec_encoders/pytorch_seq2vec_wrapper.py: 208-227
</a>
<div class="mid" id="frag543" style="display:none"><pre>
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        go_forward: bool = True,
        recurrent_dropout_probability: float = 0.0,
        use_highway: bool = True,
        use_input_projection_bias: bool = True,
    ) -&gt; None:
        module = AugmentedLstm(
            input_size=input_size,
            hidden_size=hidden_size,
            go_forward=go_forward,
            recurrent_dropout_probability=recurrent_dropout_probability,
            use_highway=use_highway,
            use_input_projection_bias=use_input_projection_bias,
        )
        super().__init__(module=module)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag572')" href="javascript:;">
allennlp-2.9.0/allennlp/modules/seq2seq_encoders/pytorch_seq2seq_wrapper.py: 131-152
</a>
<div class="mid" id="frag572" style="display:none"><pre>
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        num_layers: int = 1,
        bias: bool = True,
        dropout: float = 0.0,
        bidirectional: bool = False,
        stateful: bool = False,
    ):
        module = torch.nn.GRU(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            bias=bias,
            batch_first=True,
            dropout=dropout,
            bidirectional=bidirectional,
        )
        super().__init__(module=module, stateful=stateful)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag575')" href="javascript:;">
allennlp-2.9.0/allennlp/modules/seq2seq_encoders/pytorch_seq2seq_wrapper.py: 217-237
</a>
<div class="mid" id="frag575" style="display:none"><pre>
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        go_forward: bool = True,
        recurrent_dropout_probability: float = 0.0,
        use_highway: bool = True,
        use_input_projection_bias: bool = True,
        stateful: bool = False,
    ) -&gt; None:
        module = AugmentedLstm(
            input_size=input_size,
            hidden_size=hidden_size,
            go_forward=go_forward,
            recurrent_dropout_probability=recurrent_dropout_probability,
            use_highway=use_highway,
            use_input_projection_bias=use_input_projection_bias,
        )
        super().__init__(module=module, stateful=stateful)


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag541')" href="javascript:;">
allennlp-2.9.0/allennlp/modules/seq2vec_encoders/pytorch_seq2vec_wrapper.py: 152-172
</a>
<div class="mid" id="frag541" style="display:none"><pre>
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        num_layers: int = 1,
        bias: bool = True,
        dropout: float = 0.0,
        bidirectional: bool = False,
    ):
        module = torch.nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            bias=bias,
            batch_first=True,
            dropout=dropout,
            bidirectional=bidirectional,
        )
        super().__init__(module=module)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag573')" href="javascript:;">
allennlp-2.9.0/allennlp/modules/seq2seq_encoders/pytorch_seq2seq_wrapper.py: 159-180
</a>
<div class="mid" id="frag573" style="display:none"><pre>
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        num_layers: int = 1,
        bias: bool = True,
        dropout: float = 0.0,
        bidirectional: bool = False,
        stateful: bool = False,
    ):
        module = torch.nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            bias=bias,
            batch_first=True,
            dropout=dropout,
            bidirectional=bidirectional,
        )
        super().__init__(module=module, stateful=stateful)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag540')" href="javascript:;">
allennlp-2.9.0/allennlp/modules/seq2vec_encoders/pytorch_seq2vec_wrapper.py: 125-145
</a>
<div class="mid" id="frag540" style="display:none"><pre>
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        num_layers: int = 1,
        bias: bool = True,
        dropout: float = 0.0,
        bidirectional: bool = False,
    ):
        module = torch.nn.GRU(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            bias=bias,
            batch_first=True,
            dropout=dropout,
            bidirectional=bidirectional,
        )
        super().__init__(module=module)


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag542')" href="javascript:;">
allennlp-2.9.0/allennlp/modules/seq2vec_encoders/pytorch_seq2vec_wrapper.py: 179-201
</a>
<div class="mid" id="frag542" style="display:none"><pre>
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        num_layers: int = 1,
        nonlinearity: str = "tanh",
        bias: bool = True,
        dropout: float = 0.0,
        bidirectional: bool = False,
    ):
        module = torch.nn.RNN(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            nonlinearity=nonlinearity,
            bias=bias,
            batch_first=True,
            dropout=dropout,
            bidirectional=bidirectional,
        )
        super().__init__(module=module)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag574')" href="javascript:;">
allennlp-2.9.0/allennlp/modules/seq2seq_encoders/pytorch_seq2seq_wrapper.py: 187-210
</a>
<div class="mid" id="frag574" style="display:none"><pre>
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        num_layers: int = 1,
        nonlinearity: str = "tanh",
        bias: bool = True,
        dropout: float = 0.0,
        bidirectional: bool = False,
        stateful: bool = False,
    ):
        module = torch.nn.RNN(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            nonlinearity=nonlinearity,
            bias=bias,
            batch_first=True,
            dropout=dropout,
            bidirectional=bidirectional,
        )
        super().__init__(module=module, stateful=stateful)


</pre></div>
</td>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 4:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 71%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag177')" href="javascript:;">
allennlp-2.9.0/allennlp/data/tokenizers/spacy_tokenizer.py: 124-137
</a>
<div class="mid" id="frag177" style="display:none"><pre>
    def _to_params(self):
        return {
            "type": "spacy",
            "language": self._language,
            "pos_tags": self._pos_tags,
            "parse": self._parse,
            "ner": self._ner,
            "keep_spacy_tokens": self._keep_spacy_tokens,
            "split_on_spaces": self._split_on_spaces,
            "start_tokens": self._start_tokens,
            "end_tokens": self._end_tokens,
        }


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag909')" href="javascript:;">
allennlp-2.9.0/tests/data/tokenizers/spacy_tokenizer_test.py: 123-137
</a>
<div class="mid" id="frag909" style="display:none"><pre>
    def test_to_params(self):
        tokenizer = SpacyTokenizer()
        params = tokenizer.to_params()
        assert isinstance(params, Params)
        assert params.params == {
            "type": "spacy",
            "language": tokenizer._language,
            "pos_tags": tokenizer._pos_tags,
            "parse": tokenizer._parse,
            "ner": tokenizer._ner,
            "keep_spacy_tokens": tokenizer._keep_spacy_tokens,
            "split_on_spaces": tokenizer._split_on_spaces,
            "start_tokens": tokenizer._start_tokens,
            "end_tokens": tokenizer._end_tokens,
        }
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 5:</b> &nbsp; 2 fragments, nominal size 35 lines, similarity 86%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag416')" href="javascript:;">
allennlp-2.9.0/allennlp/modules/maxout.py: 35-76
</a>
<div class="mid" id="frag416" style="display:none"><pre>
    def __init__(
        self,
        input_dim: int,
        num_layers: int,
        output_dims: Union[int, Sequence[int]],
        pool_sizes: Union[int, Sequence[int]],
        dropout: Union[float, Sequence[float]] = 0.0,
    ) -&gt; None:
        super().__init__()
        if not isinstance(output_dims, list):
            output_dims = [output_dims] * num_layers  # type: ignore
        if not isinstance(pool_sizes, list):
            pool_sizes = [pool_sizes] * num_layers  # type: ignore
        if not isinstance(dropout, list):
            dropout = [dropout] * num_layers  # type: ignore
        if len(output_dims) != num_layers:
            raise ConfigurationError(
                "len(output_dims) (%d) != num_layers (%d)" % (len(output_dims), num_layers)
            )
        if len(pool_sizes) != num_layers:
            raise ConfigurationError(
                "len(pool_sizes) (%d) != num_layers (%d)" % (len(pool_sizes), num_layers)
            )
        if len(dropout) != num_layers:
            raise ConfigurationError(
                "len(dropout) (%d) != num_layers (%d)" % (len(dropout), num_layers)
            )

        self._pool_sizes = pool_sizes
        input_dims = [input_dim] + output_dims[:-1]
        linear_layers = []
        for layer_input_dim, layer_output_dim, pool_size in zip(
            input_dims, output_dims, pool_sizes
        ):
            linear_layers.append(torch.nn.Linear(layer_input_dim, layer_output_dim * pool_size))
        self._linear_layers = torch.nn.ModuleList(linear_layers)
        dropout_layers = [torch.nn.Dropout(p=value) for value in dropout]
        self._dropout = torch.nn.ModuleList(dropout_layers)
        self._output_dims = output_dims
        self._output_dim = output_dims[-1]
        self._input_dim = input_dim

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag522')" href="javascript:;">
allennlp-2.9.0/allennlp/modules/feedforward.py: 57-95
</a>
<div class="mid" id="frag522" style="display:none"><pre>
    def __init__(
        self,
        input_dim: int,
        num_layers: int,
        hidden_dims: Union[int, List[int]],
        activations: Union[Activation, List[Activation]],
        dropout: Union[float, List[float]] = 0.0,
    ) -&gt; None:

        super().__init__()
        if not isinstance(hidden_dims, list):
            hidden_dims = [hidden_dims] * num_layers  # type: ignore
        if not isinstance(activations, list):
            activations = [activations] * num_layers  # type: ignore
        if not isinstance(dropout, list):
            dropout = [dropout] * num_layers  # type: ignore
        if len(hidden_dims) != num_layers:
            raise ConfigurationError(
                "len(hidden_dims) (%d) != num_layers (%d)" % (len(hidden_dims), num_layers)
            )
        if len(activations) != num_layers:
            raise ConfigurationError(
                "len(activations) (%d) != num_layers (%d)" % (len(activations), num_layers)
            )
        if len(dropout) != num_layers:
            raise ConfigurationError(
                "len(dropout) (%d) != num_layers (%d)" % (len(dropout), num_layers)
            )
        self._activations = torch.nn.ModuleList(activations)
        input_dims = [input_dim] + hidden_dims[:-1]
        linear_layers = []
        for layer_input_dim, layer_output_dim in zip(input_dims, hidden_dims):
            linear_layers.append(torch.nn.Linear(layer_input_dim, layer_output_dim))
        self._linear_layers = torch.nn.ModuleList(linear_layers)
        dropout_layers = [torch.nn.Dropout(p=value) for value in dropout]
        self._dropout = torch.nn.ModuleList(dropout_layers)
        self._output_dim = hidden_dims[-1]
        self.input_dim = input_dim

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 6:</b> &nbsp; 3 fragments, nominal size 14 lines, similarity 73%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag428')" href="javascript:;">
allennlp-2.9.0/allennlp/modules/matrix_attention/linear_matrix_attention.py: 50-64
</a>
<div class="mid" id="frag428" style="display:none"><pre>
    def __init__(
        self,
        tensor_1_dim: int,
        tensor_2_dim: int,
        combination: str = "x,y",
        activation: Activation = None,
    ) -&gt; None:
        super().__init__()
        self._combination = combination
        combined_dim = util.get_combined_dim(combination, [tensor_1_dim, tensor_2_dim])
        self._weight_vector = Parameter(torch.Tensor(combined_dim))
        self._bias = Parameter(torch.Tensor(1))
        self._activation = activation or Activation.by_name("linear")()
        self.reset_parameters()

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag466')" href="javascript:;">
allennlp-2.9.0/allennlp/modules/attention/linear_attention.py: 49-64
</a>
<div class="mid" id="frag466" style="display:none"><pre>
    def __init__(
        self,
        tensor_1_dim: int,
        tensor_2_dim: int,
        combination: str = "x,y",
        activation: Activation = None,
        normalize: bool = True,
    ) -&gt; None:
        super().__init__(normalize)
        self._combination = combination
        combined_dim = util.get_combined_dim(combination, [tensor_1_dim, tensor_2_dim])
        self._weight_vector = Parameter(torch.Tensor(combined_dim))
        self._bias = Parameter(torch.Tensor(1))
        self._activation = activation or Activation.by_name("linear")()
        self.reset_parameters()

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag471')" href="javascript:;">
allennlp-2.9.0/allennlp/modules/attention/bilinear_attention.py: 35-47
</a>
<div class="mid" id="frag471" style="display:none"><pre>
    def __init__(
        self,
        vector_dim: int,
        matrix_dim: int,
        activation: Activation = None,
        normalize: bool = True,
    ) -&gt; None:
        super().__init__(normalize)
        self._weight_matrix = Parameter(torch.Tensor(vector_dim, matrix_dim))
        self._bias = Parameter(torch.Tensor(1))
        self._activation = activation or Activation.by_name("linear")()
        self.reset_parameters()

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 7:</b> &nbsp; 2 fragments, nominal size 49 lines, similarity 71%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag436')" href="javascript:;">
allennlp-2.9.0/allennlp/modules/transformer/bimodal_connection_layer.py: 36-87
</a>
<div class="mid" id="frag436" style="display:none"><pre>
    def __init__(
        self,
        hidden_size1: int,
        hidden_size2: int,
        combined_hidden_size: int,
        intermediate_size1: int,
        intermediate_size2: int,
        num_attention_heads: int,
        dropout1: float,
        dropout2: float,
        activation: str,
    ):
        super().__init__()
        self.bimodal_attention = BiModalAttention(
            hidden_size1=hidden_size1,
            hidden_size2=hidden_size2,
            combined_hidden_size=combined_hidden_size,
            num_attention_heads=num_attention_heads,
            dropout1=dropout1,
            dropout2=dropout2,
        )

        self.bimodal_output = BiModalOutput(
            hidden_size1=hidden_size1,
            hidden_size2=hidden_size2,
            combined_hidden_size=combined_hidden_size,
            dropout1=dropout1,
            dropout2=dropout2,
        )

        self.intermediate1 = ActivationLayer(
            hidden_size=hidden_size1,
            intermediate_size=intermediate_size1,
            activation=activation,
        )
        self.output1 = OutputLayer(
            hidden_size=hidden_size1,
            input_size=intermediate_size1,
            dropout=dropout1,
        )

        self.intermediate2 = ActivationLayer(
            hidden_size=hidden_size2,
            intermediate_size=intermediate_size2,
            activation=activation,
        )
        self.output2 = OutputLayer(
            hidden_size=hidden_size2,
            input_size=intermediate_size2,
            dropout=dropout2,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag511')" href="javascript:;">
allennlp-2.9.0/allennlp/modules/backbones/vilbert_backbone.py: 53-105
</a>
<div class="mid" id="frag511" style="display:none"><pre>
    def from_huggingface_model_name(
        cls,
        vocab: Vocabulary,
        model_name: str,
        image_feature_dim: int,
        image_num_hidden_layers: int,
        image_hidden_size: int,
        image_num_attention_heads: int,
        combined_hidden_size: int,
        combined_num_attention_heads: int,
        pooled_output_dim: int,
        image_intermediate_size: int,
        image_attention_dropout: float,
        image_hidden_dropout: float,
        image_biattention_id: List[int],
        text_biattention_id: List[int],
        text_fixed_layer: int,
        image_fixed_layer: int,
        fusion_method: str = "sum",
    ):
        text_embeddings = TransformerEmbeddings.from_pretrained_module(model_name)

        image_embeddings = ImageFeatureEmbeddings(
            feature_size=image_feature_dim,
            embedding_size=image_hidden_size,
            dropout=image_hidden_dropout,
        )

        encoder = BiModalEncoder.from_pretrained_module(
            model_name,
            num_hidden_layers2=image_num_hidden_layers,
            hidden_size2=image_hidden_size,
            num_attention_heads2=image_num_attention_heads,
            combined_hidden_size=combined_hidden_size,
            combined_num_attention_heads=combined_num_attention_heads,
            intermediate_size2=image_intermediate_size,
            attention_dropout2=image_attention_dropout,
            hidden_dropout2=image_hidden_dropout,
            biattention_id1=text_biattention_id,
            biattention_id2=image_biattention_id,
            fixed_layer1=text_fixed_layer,
            fixed_layer2=image_fixed_layer,
        )

        return cls(
            vocab=vocab,
            text_embeddings=text_embeddings,
            image_embeddings=image_embeddings,
            encoder=encoder,
            pooled_output_dim=pooled_output_dim,
            fusion_method=fusion_method,
        )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 8:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 92%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag493')" href="javascript:;">
allennlp-2.9.0/allennlp/modules/span_extractors/self_attentive_span_extractor.py: 46-60
</a>
<div class="mid" id="frag493" style="display:none"><pre>
    def __init__(
        self,
        input_dim: int,
        num_width_embeddings: int = None,
        span_width_embedding_dim: int = None,
        bucket_widths: bool = False,
    ) -&gt; None:
        super().__init__(
            input_dim=input_dim,
            num_width_embeddings=num_width_embeddings,
            span_width_embedding_dim=span_width_embedding_dim,
            bucket_widths=bucket_widths,
        )
        self._global_attention = TimeDistributed(torch.nn.Linear(input_dim, 1))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag502')" href="javascript:;">
allennlp-2.9.0/allennlp/modules/span_extractors/max_pooling_span_extractor.py: 44-57
</a>
<div class="mid" id="frag502" style="display:none"><pre>
    def __init__(
        self,
        input_dim: int,
        num_width_embeddings: int = None,
        span_width_embedding_dim: int = None,
        bucket_widths: bool = False,
    ) -&gt; None:
        super().__init__(
            input_dim=input_dim,
            num_width_embeddings=num_width_embeddings,
            span_width_embedding_dim=span_width_embedding_dim,
            bucket_widths=bucket_widths,
        )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 9:</b> &nbsp; 2 fragments, nominal size 22 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag496')" href="javascript:;">
allennlp-2.9.0/allennlp/modules/span_extractors/endpoint_span_extractor.py: 53-73
</a>
<div class="mid" id="frag496" style="display:none"><pre>
    def __init__(
        self,
        input_dim: int,
        combination: str = "x,y",
        num_width_embeddings: int = None,
        span_width_embedding_dim: int = None,
        bucket_widths: bool = False,
        use_exclusive_start_indices: bool = False,
    ) -&gt; None:
        super().__init__(
            input_dim=input_dim,
            num_width_embeddings=num_width_embeddings,
            span_width_embedding_dim=span_width_embedding_dim,
            bucket_widths=bucket_widths,
        )
        self._combination = combination

        self._use_exclusive_start_indices = use_exclusive_start_indices
        if use_exclusive_start_indices:
            self._start_sentinel = Parameter(torch.randn([1, 1, int(input_dim)]))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag499')" href="javascript:;">
allennlp-2.9.0/allennlp/modules/span_extractors/bidirectional_endpoint_span_extractor.py: 71-101
</a>
<div class="mid" id="frag499" style="display:none"><pre>
    def __init__(
        self,
        input_dim: int,
        forward_combination: str = "y-x",
        backward_combination: str = "x-y",
        num_width_embeddings: int = None,
        span_width_embedding_dim: int = None,
        bucket_widths: bool = False,
        use_sentinels: bool = True,
    ) -&gt; None:
        super().__init__(
            input_dim=input_dim,
            num_width_embeddings=num_width_embeddings,
            span_width_embedding_dim=span_width_embedding_dim,
            bucket_widths=bucket_widths,
        )
        self._forward_combination = forward_combination
        self._backward_combination = backward_combination

        if self._input_dim % 2 != 0:
            raise ConfigurationError(
                "The input dimension is not divisible by 2, but the "
                "BidirectionalEndpointSpanExtractor assumes the embedded representation "
                "is bidirectional (and hence divisible by 2)."
            )

        self._use_sentinels = use_sentinels
        if use_sentinels:
            self._start_sentinel = Parameter(torch.randn([1, 1, int(input_dim / 2)]))
            self._end_sentinel = Parameter(torch.randn([1, 1, int(input_dim / 2)]))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 10:</b> &nbsp; 3 fragments, nominal size 17 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag604')" href="javascript:;">
allennlp-2.9.0/tests/training/util_test.py: 79-95
</a>
<div class="mid" id="frag604" style="display:none"><pre>
    def test_only_train_read_for_vocab(self, caplog):
        params = Params(
            {
                "dataset_reader": {"type": "train-util-test-reader"},
                "train_data_path": "path-to-training-file",
                "data_loader": {"batch_size": 2},
            }
        )
        _ = make_vocab_from_params(params, str(self.TEST_DIR))
        log_messages = "\n".join([rec.message for rec in caplog.records])
        assert "...train-util-test-reader reading from path-to-training-file" in log_messages
        assert "...train-util-test-reader reading from path-to-validation-file" not in log_messages
        assert "...train-util-test-reader reading from path-to-test-file" not in log_messages
        assert "Reading training data" in log_messages
        assert "Reading validation data" not in log_messages
        assert "Reading test data" not in log_messages

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag606')" href="javascript:;">
allennlp-2.9.0/tests/training/util_test.py: 115-134
</a>
<div class="mid" id="frag606" style="display:none"><pre>
    def test_only_specified_datasets_read_for_vocab(self, caplog):
        params = Params(
            {
                "dataset_reader": {"type": "train-util-test-reader"},
                "train_data_path": "path-to-training-file",
                "validation_data_path": "path-to-validation-file",
                "test_data_path": "path-to-test-file",
                "datasets_for_vocab_creation": ["train", "validation"],
                "data_loader": {"batch_size": 2},
            }
        )
        _ = make_vocab_from_params(params, str(self.TEST_DIR))
        log_messages = "\n".join([rec.message for rec in caplog.records])
        assert "...train-util-test-reader reading from path-to-training-file" in log_messages
        assert "...train-util-test-reader reading from path-to-validation-file" in log_messages
        assert "...train-util-test-reader reading from path-to-test-file" not in log_messages
        assert "Reading training data" in log_messages
        assert "Reading validation data" in log_messages
        assert "Reading test data" not in log_messages

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag605')" href="javascript:;">
allennlp-2.9.0/tests/training/util_test.py: 96-114
</a>
<div class="mid" id="frag605" style="display:none"><pre>
    def test_all_datasets_read_for_vocab(self, caplog):
        params = Params(
            {
                "dataset_reader": {"type": "train-util-test-reader"},
                "train_data_path": "path-to-training-file",
                "validation_data_path": "path-to-validation-file",
                "test_data_path": "path-to-test-file",
                "data_loader": {"batch_size": 2},
            }
        )
        _ = make_vocab_from_params(params, str(self.TEST_DIR))
        log_messages = "\n".join([rec.message for rec in caplog.records])
        assert "...train-util-test-reader reading from path-to-training-file" in log_messages
        assert "...train-util-test-reader reading from path-to-validation-file" in log_messages
        assert "...train-util-test-reader reading from path-to-test-file" in log_messages
        assert "Reading training data" in log_messages
        assert "Reading validation data" in log_messages
        assert "Reading test data" in log_messages

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 11:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag608')" href="javascript:;">
allennlp-2.9.0/tests/training/util_test.py: 149-161
</a>
<div class="mid" id="frag608" style="display:none"><pre>
    def test_invalid_datasets_for_vocab_creation(self):
        params = Params(
            {
                "dataset_reader": {"type": "train-util-test-reader"},
                "train_data_path": "path-to-training-file",
                "validation_data_path": "path-to-validation-file",
                "datasets_for_vocab_creation": ["train", "validation", "test"],
                "data_loader": {"batch_size": 2},
            }
        )
        with pytest.raises(ConfigurationError, match="invalid 'datasets_for_vocab_creation' test"):
            make_vocab_from_params(params, str(self.TEST_DIR))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag609')" href="javascript:;">
allennlp-2.9.0/tests/training/util_test.py: 162-176
</a>
<div class="mid" id="frag609" style="display:none"><pre>
    def test_raise_error_if_directory_non_empty(self):
        params = Params(
            {
                "dataset_reader": {"type": "train-util-test-reader"},
                "train_data_path": "path-to-training-file",
                "validation_data_path": "path-to-validation-file",
                "data_loader": {"batch_size": 2},
            }
        )
        os.makedirs(self.TEST_DIR / "vocabulary")
        with open(self.TEST_DIR / "vocabulary" / "blah", "w") as random_file:
            random_file.write("BLAH!")
        with pytest.raises(ConfigurationError, match="The 'vocabulary' directory in the provided"):
            make_vocab_from_params(params, str(self.TEST_DIR))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 12:</b> &nbsp; 3 fragments, nominal size 13 lines, similarity 84%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag635')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/boolean_accuracy_test.py: 73-86
</a>
<div class="mid" id="frag635" style="display:none"><pre>
    def test_distributed_accuracy(self):
        predictions = [torch.tensor([[0, 1], [2, 3]]), torch.tensor([[4, 5], [6, 7]])]
        targets = [torch.tensor([[0, 1], [2, 2]]), torch.tensor([[4, 5], [7, 7]])]
        metric_kwargs = {"predictions": predictions, "gold_labels": targets}
        desired_values = 0.5
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            BooleanAccuracy(),
            metric_kwargs,
            desired_values,
            exact=True,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag636')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/boolean_accuracy_test.py: 87-100
</a>
<div class="mid" id="frag636" style="display:none"><pre>
    def test_distributed_accuracy_unequal_batches(self):
        predictions = [torch.tensor([[0, 1], [2, 3], [4, 5]]), torch.tensor([[6, 7]])]
        targets = [torch.tensor([[0, 1], [2, 2], [4, 5]]), torch.tensor([[7, 7]])]
        metric_kwargs = {"predictions": predictions, "gold_labels": targets}
        desired_values = 0.5
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            BooleanAccuracy(),
            metric_kwargs,
            desired_values,
            exact=True,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag637')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/boolean_accuracy_test.py: 101-115
</a>
<div class="mid" id="frag637" style="display:none"><pre>
    def test_multiple_distributed_runs(self):
        predictions = [torch.tensor([[0, 1], [2, 3]]), torch.tensor([[4, 5], [6, 7]])]
        targets = [torch.tensor([[0, 1], [2, 2]]), torch.tensor([[4, 5], [7, 7]])]
        metric_kwargs = {"predictions": predictions, "gold_labels": targets}
        desired_values = 0.5
        run_distributed_test(
            [-1, -1],
            multiple_runs,
            BooleanAccuracy(),
            metric_kwargs,
            desired_values,
            exact=True,
        )


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 13:</b> &nbsp; 9 fragments, nominal size 15 lines, similarity 82%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag638')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/boolean_accuracy_test.py: 116-134
</a>
<div class="mid" id="frag638" style="display:none"><pre>
def multiple_runs(
    global_rank: int,
    world_size: int,
    gpu_id: Union[int, torch.device],
    metric: BooleanAccuracy,
    metric_kwargs: Dict[str, List[Any]],
    desired_values: Dict[str, Any],
    exact: Union[bool, Tuple[float, float]] = True,
):

    kwargs = {}
    # Use the arguments meant for the process with rank `global_rank`.
    for argname in metric_kwargs:
        kwargs[argname] = metric_kwargs[argname][global_rank]

    for i in range(200):
        metric(**kwargs)

    assert desired_values == metric.get_metric()
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag721')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/sequence_accuracy_test.py: 126-144
</a>
<div class="mid" id="frag721" style="display:none"><pre>
def multiple_runs(
    global_rank: int,
    world_size: int,
    gpu_id: Union[int, torch.device],
    metric: SequenceAccuracy,
    metric_kwargs: Dict[str, List[Any]],
    desired_values: Dict[str, Any],
    exact: Union[bool, Tuple[float, float]] = True,
):

    kwargs = {}
    # Use the arguments meant for the process with rank `global_rank`.
    for argname in metric_kwargs:
        kwargs[argname] = metric_kwargs[argname][global_rank]

    for i in range(200):
        metric(**kwargs)

    assert desired_values["accuracy"] == metric.get_metric()["accuracy"]
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag660')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/unigram_recall_test.py: 126-144
</a>
<div class="mid" id="frag660" style="display:none"><pre>
def multiple_runs(
    global_rank: int,
    world_size: int,
    gpu_id: Union[int, torch.device],
    metric: UnigramRecall,
    metric_kwargs: Dict[str, List[Any]],
    desired_values: Dict[str, Any],
    exact: Union[bool, Tuple[float, float]] = True,
):

    kwargs = {}
    # Use the arguments meant for the process with rank `global_rank`.
    for argname in metric_kwargs:
        kwargs[argname] = metric_kwargs[argname][global_rank]

    for i in range(200):
        metric(**kwargs)

    assert desired_values["unigram_recall"] == metric.get_metric()["unigram_recall"]
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag693')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/mean_absolute_error_test.py: 156-174
</a>
<div class="mid" id="frag693" style="display:none"><pre>
def multiple_runs(
    global_rank: int,
    world_size: int,
    gpu_id: Union[int, torch.device],
    metric: MeanAbsoluteError,
    metric_kwargs: Dict[str, List[Any]],
    desired_values: Dict[str, Any],
    exact: Union[bool, Tuple[float, float]] = True,
):

    kwargs = {}
    # Use the arguments meant for the process with rank `global_rank`.
    for argname in metric_kwargs:
        kwargs[argname] = metric_kwargs[argname][global_rank]

    for i in range(200):
        metric(**kwargs)

    assert desired_values["mae"] == metric.get_metric()["mae"]
</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag647')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/evalb_bracketing_scorer_test.py: 109-130
</a>
<div class="mid" id="frag647" style="display:none"><pre>
def multiple_runs(
    global_rank: int,
    world_size: int,
    gpu_id: Union[int, torch.device],
    metric: EvalbBracketingScorer,
    metric_kwargs: Dict[str, List[Any]],
    desired_values: Dict[str, Any],
    exact: Union[bool, Tuple[float, float]] = True,
):

    kwargs = {}
    # Use the arguments meant for the process with rank `global_rank`.
    for argname in metric_kwargs:
        kwargs[argname] = metric_kwargs[argname][global_rank]

    for i in range(200):
        metric(**kwargs)

    metric_values = metric.get_metric()

    for key in desired_values:
        assert desired_values[key] == metric_values[key]
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag714')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/attachment_scores_test.py: 194-215
</a>
<div class="mid" id="frag714" style="display:none"><pre>
def multiple_runs(
    global_rank: int,
    world_size: int,
    gpu_id: Union[int, torch.device],
    metric: AttachmentScores,
    metric_kwargs: Dict[str, List[Any]],
    desired_values: Dict[str, Any],
    exact: Union[bool, Tuple[float, float]] = True,
):

    kwargs = {}
    # Use the arguments meant for the process with rank `global_rank`.
    for argname in metric_kwargs:
        kwargs[argname] = metric_kwargs[argname][global_rank]

    for i in range(200):
        metric(**kwargs)

    metrics = metric.get_metric()

    for key in metrics:
        assert desired_values[key] == metrics[key]
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag759')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 483-504
</a>
<div class="mid" id="frag759" style="display:none"><pre>
def multiple_runs(
    global_rank: int,
    world_size: int,
    gpu_id: Union[int, torch.device],
    metric: FBetaMultiLabelMeasure,
    metric_kwargs: Dict[str, List[Any]],
    desired_values: Dict[str, Any],
    exact: Union[bool, Tuple[float, float]] = True,
):

    kwargs = {}
    # Use the arguments meant for the process with rank `global_rank`.
    for argname in metric_kwargs:
        kwargs[argname] = metric_kwargs[argname][global_rank]

    for i in range(200):
        metric(**kwargs)

    metric_values = metric.get_metric()

    for key in desired_values:
        assert_allclose(desired_values[key], metric_values[key])
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag666')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/entropy_test.py: 82-100
</a>
<div class="mid" id="frag666" style="display:none"><pre>
def multiple_runs(
    global_rank: int,
    world_size: int,
    gpu_id: Union[int, torch.device],
    metric: Entropy,
    metric_kwargs: Dict[str, List[Any]],
    desired_values: Dict[str, Any],
    exact: Union[bool, Tuple[float, float]] = True,
):

    kwargs = {}
    # Use the arguments meant for the process with rank `global_rank`.
    for argname in metric_kwargs:
        kwargs[argname] = metric_kwargs[argname][global_rank]

    for i in range(200):
        metric(**kwargs)

    assert_allclose(desired_values["entropy"], metric.get_metric()["entropy"])
</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag686')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_measure_test.py: 423-444
</a>
<div class="mid" id="frag686" style="display:none"><pre>
def multiple_runs(
    global_rank: int,
    world_size: int,
    gpu_id: Union[int, torch.device],
    metric: FBetaMeasure,
    metric_kwargs: Dict[str, List[Any]],
    desired_values: Dict[str, Any],
    exact: Union[bool, Tuple[float, float]] = True,
):

    kwargs = {}
    # Use the arguments meant for the process with rank `global_rank`.
    for argname in metric_kwargs:
        kwargs[argname] = metric_kwargs[argname][global_rank]

    for i in range(200):
        metric(**kwargs)

    metric_values = metric.get_metric()

    for key in desired_values:
        assert_allclose(desired_values[key], metric_values[key])
</pre></div>
</td>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 14:</b> &nbsp; 2 fragments, nominal size 19 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag645')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/evalb_bracketing_scorer_test.py: 68-87
</a>
<div class="mid" id="frag645" style="display:none"><pre>
    def test_distributed_evalb(self):
        tree1 = Tree.fromstring("(S (VP (D the) (NP dog)) (VP (V chased) (NP (D the) (N cat))))")
        tree2 = Tree.fromstring("(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))")
        predicted_trees = [[tree1], [tree2]]
        gold_trees = [[tree2], [tree2]]
        metric_kwargs = {"predicted_trees": predicted_trees, "gold_trees": gold_trees}
        desired_values = {
            "evalb_recall": 0.875,
            "evalb_precision": 0.875,
            "evalb_f1_measure": 0.875,
        }
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            EvalbBracketingScorer(),
            metric_kwargs,
            desired_values,
            exact=True,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag646')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/evalb_bracketing_scorer_test.py: 88-108
</a>
<div class="mid" id="frag646" style="display:none"><pre>
    def test_multiple_distributed_runs(self):
        tree1 = Tree.fromstring("(S (VP (D the) (NP dog)) (VP (V chased) (NP (D the) (N cat))))")
        tree2 = Tree.fromstring("(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))")
        predicted_trees = [[tree1], [tree2]]
        gold_trees = [[tree2], [tree2]]
        metric_kwargs = {"predicted_trees": predicted_trees, "gold_trees": gold_trees}
        desired_values = {
            "evalb_recall": 0.875,
            "evalb_precision": 0.875,
            "evalb_f1_measure": 0.875,
        }
        run_distributed_test(
            [-1, -1],
            multiple_runs,
            EvalbBracketingScorer(),
            metric_kwargs,
            desired_values,
            exact=False,
        )


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 15:</b> &nbsp; 2 fragments, nominal size 20 lines, similarity 95%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag652')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/auc_test.py: 98-122
</a>
<div class="mid" id="frag652" style="display:none"><pre>
    def test_distributed_auc(self):
        predictions = torch.randn(8)
        labels = torch.randint(3, 5, (8,), dtype=torch.long)
        # We make sure that the positive label is always present.
        labels[0] = 4
        labels[4] = 4

        false_positive_rates, true_positive_rates, _ = metrics.roc_curve(
            labels.cpu().numpy(), predictions.cpu().numpy(), pos_label=4
        )

        predictions = [predictions[:4], predictions[4:]]
        labels = [labels[:4], labels[4:]]

        metric_kwargs = {"predictions": predictions, "gold_labels": labels}
        desired_auc = metrics.auc(false_positive_rates, true_positive_rates)
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            Auc(positive_label=4),
            metric_kwargs,
            desired_auc,
            exact=False,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag653')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/auc_test.py: 123-147
</a>
<div class="mid" id="frag653" style="display:none"><pre>
    def test_distributed_auc_unequal_batches(self):
        predictions = torch.randn(8)
        labels = torch.randint(3, 5, (8,), dtype=torch.long)
        # We make sure that the positive label is always present.
        labels[0] = 4
        labels[4] = 4

        false_positive_rates, true_positive_rates, _ = metrics.roc_curve(
            labels.cpu().numpy(), predictions.cpu().numpy(), pos_label=4
        )

        predictions = [predictions[:2], predictions[2:]]
        labels = [labels[:2], labels[2:]]

        metric_kwargs = {"predictions": predictions, "gold_labels": labels}
        desired_auc = metrics.auc(false_positive_rates, true_positive_rates)
        with pytest.raises(Exception) as _:
            run_distributed_test(
                [-1, -1],
                global_distributed_metric,
                Auc(positive_label=4),
                metric_kwargs,
                desired_auc,
                exact=False,
            )
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 16:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 90%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag654')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/unigram_recall_test.py: 16-27
</a>
<div class="mid" id="frag654" style="display:none"><pre>
    def test_sequence_recall(self, device: str):
        recall = UnigramRecall()
        gold = torch.tensor([[1, 2, 3], [2, 4, 8], [7, 1, 1]], device=device)
        predictions = torch.tensor(
            [[[1, 2, 3], [1, 2, -1]], [[2, 4, 8], [2, 5, 9]], [[-1, -1, -1], [7, 1, -1]]],
            device=device,
        )

        recall(predictions, gold)
        actual_recall = recall.get_metric()["unigram_recall"]
        assert_allclose(actual_recall, 1)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag715')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/sequence_accuracy_test.py: 16-27
</a>
<div class="mid" id="frag715" style="display:none"><pre>
    def test_sequence_accuracy(self, device: str):
        accuracy = SequenceAccuracy()
        gold = torch.tensor([[1, 2, 3], [2, 4, 8], [0, 1, 1]], device=device)
        predictions = torch.tensor(
            [[[1, 2, 3], [1, 2, -1]], [[2, 4, 8], [2, 5, 9]], [[-1, -1, -1], [0, 1, -1]]],
            device=device,
        )

        accuracy(predictions, gold)
        actual_accuracy = accuracy.get_metric()["accuracy"]
        assert_allclose(actual_accuracy, 2 / 3)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 17:</b> &nbsp; 2 fragments, nominal size 19 lines, similarity 94%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag655')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/unigram_recall_test.py: 29-49
</a>
<div class="mid" id="frag655" style="display:none"><pre>
    def test_sequence_recall_respects_mask(self, device: str):
        recall = UnigramRecall()
        gold = torch.tensor([[2, 4, 8], [1, 2, 3], [7, 1, 1], [11, 14, 17]], device=device)
        predictions = torch.tensor(
            [
                [[2, 4, 8], [2, 5, 9]],  # 3/3
                [[-1, 2, 4], [3, 8, -1]],  # 2/2
                [[-1, -1, -1], [7, 2, -1]],  # 1/2
                [[12, 13, 17], [11, 13, 18]],  # 2/2
            ],
            device=device,
        )
        mask = torch.tensor(
            [[True, True, True], [False, True, True], [True, True, False], [True, False, True]],
            device=device,
        )

        recall(predictions, gold, mask)
        actual_recall = recall.get_metric()["unigram_recall"]
        assert_allclose(actual_recall, 7 / 8)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag716')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/sequence_accuracy_test.py: 29-49
</a>
<div class="mid" id="frag716" style="display:none"><pre>
    def test_sequence_accuracy_respects_mask(self, device: str):
        accuracy = SequenceAccuracy()
        gold = torch.tensor([[1, 2, 3], [2, 4, 8], [0, 1, 1], [11, 13, 17]], device=device)
        predictions = torch.tensor(
            [
                [[1, 2, 3], [1, 2, -1]],
                [[2, 4, 8], [2, 5, 9]],
                [[-1, -1, -1], [0, 1, -1]],
                [[12, 13, 17], [11, 13, 18]],
            ],
            device=device,
        )
        mask = torch.tensor(
            [[False, True, True], [True, True, True], [True, True, False], [True, False, True]],
            device=device,
        )

        accuracy(predictions, gold, mask)
        actual_accuracy = accuracy.get_metric()["accuracy"]
        assert_allclose(actual_accuracy, 3 / 4)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 18:</b> &nbsp; 4 fragments, nominal size 24 lines, similarity 88%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag658')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/unigram_recall_test.py: 69-96
</a>
<div class="mid" id="frag658" style="display:none"><pre>
    def test_distributed_accuracy(self):
        gold = torch.tensor([[2, 4, 8], [1, 2, 3], [7, 1, 1], [11, 14, 17]])
        predictions = torch.tensor(
            [
                [[2, 4, 8], [2, 5, 9]],  # 3/3
                [[-1, 2, 4], [3, 8, -1]],  # 2/2
                [[-1, -1, -1], [7, 2, -1]],  # 1/2
                [[12, 13, 17], [11, 13, 18]],  # 2/2
            ]
        )
        mask = torch.tensor(
            [[True, True, True], [False, True, True], [True, True, False], [True, False, True]]
        )
        gold = [gold[:2], gold[2:]]
        predictions = [predictions[:2], predictions[2:]]
        mask = [mask[:2], mask[2:]]

        metric_kwargs = {"predictions": predictions, "gold_labels": gold, "mask": mask}
        desired_values = {"unigram_recall": 7 / 8}
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            UnigramRecall(),
            metric_kwargs,
            desired_values,
            exact=False,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag720')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/sequence_accuracy_test.py: 97-125
</a>
<div class="mid" id="frag720" style="display:none"><pre>
    def test_multiple_distributed_runs(self):
        gold = torch.tensor([[1, 2, 3], [2, 4, 8], [0, 1, 1], [11, 13, 17]])
        predictions = torch.tensor(
            [
                [[1, 2, 3], [1, 2, -1]],
                [[2, 4, 8], [2, 5, 9]],
                [[-1, -1, -1], [0, 1, -1]],
                [[12, 13, 17], [11, 13, 18]],
            ]
        )
        mask = torch.tensor(
            [[False, True, True], [True, True, True], [True, True, False], [True, False, True]],
        )
        gold = [gold[:2], gold[2:]]
        predictions = [predictions[:2], predictions[2:]]
        mask = [mask[:2], mask[2:]]

        metric_kwargs = {"predictions": predictions, "gold_labels": gold, "mask": mask}
        desired_values = {"accuracy": 3 / 4}
        run_distributed_test(
            [-1, -1],
            multiple_runs,
            SequenceAccuracy(),
            metric_kwargs,
            desired_values,
            exact=True,
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag719')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/sequence_accuracy_test.py: 69-96
</a>
<div class="mid" id="frag719" style="display:none"><pre>
    def test_distributed_sequence_accuracy(self):
        gold = torch.tensor([[1, 2, 3], [2, 4, 8], [0, 1, 1], [11, 13, 17]])
        predictions = torch.tensor(
            [
                [[1, 2, 3], [1, 2, -1]],
                [[2, 4, 8], [2, 5, 9]],
                [[-1, -1, -1], [0, 1, -1]],
                [[12, 13, 17], [11, 13, 18]],
            ]
        )
        mask = torch.tensor(
            [[False, True, True], [True, True, True], [True, True, False], [True, False, True]],
        )
        gold = [gold[:2], gold[2:]]
        predictions = [predictions[:2], predictions[2:]]
        mask = [mask[:2], mask[2:]]

        metric_kwargs = {"predictions": predictions, "gold_labels": gold, "mask": mask}
        desired_values = {"accuracy": 3 / 4}
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            SequenceAccuracy(),
            metric_kwargs,
            desired_values,
            exact=False,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag659')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/unigram_recall_test.py: 97-125
</a>
<div class="mid" id="frag659" style="display:none"><pre>
    def test_multiple_distributed_runs(self):
        gold = torch.tensor([[2, 4, 8], [1, 2, 3], [7, 1, 1], [11, 14, 17]])
        predictions = torch.tensor(
            [
                [[2, 4, 8], [2, 5, 9]],  # 3/3
                [[-1, 2, 4], [3, 8, -1]],  # 2/2
                [[-1, -1, -1], [7, 2, -1]],  # 1/2
                [[12, 13, 17], [11, 13, 18]],  # 2/2
            ]
        )
        mask = torch.tensor(
            [[True, True, True], [False, True, True], [True, True, False], [True, False, True]]
        )
        gold = [gold[:2], gold[2:]]
        predictions = [predictions[:2], predictions[2:]]
        mask = [mask[:2], mask[2:]]

        metric_kwargs = {"predictions": predictions, "gold_labels": gold, "mask": mask}
        desired_values = {"unigram_recall": 7 / 8}
        run_distributed_test(
            [-1, -1],
            multiple_runs,
            UnigramRecall(),
            metric_kwargs,
            desired_values,
            exact=True,
        )


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 19:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag664')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/entropy_test.py: 53-66
</a>
<div class="mid" id="frag664" style="display:none"><pre>
    def test_distributed_entropy(self):
        logits = torch.tensor([[1, 1, 1, 1], [1, 1, 1, 1]], dtype=torch.float)
        logits = [logits[0], logits[1]]
        metric_kwargs = {"logits": logits}
        desired_values = {"entropy": 1.38629436}
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            Entropy(),
            metric_kwargs,
            desired_values,
            exact=False,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag665')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/entropy_test.py: 67-81
</a>
<div class="mid" id="frag665" style="display:none"><pre>
    def test_multiple_distributed_runs(self):
        logits = torch.tensor([[1, 1, 1, 1], [1, 1, 1, 1]], dtype=torch.float)
        logits = [logits[0], logits[1]]
        metric_kwargs = {"logits": logits}
        desired_values = {"entropy": 1.38629436}
        run_distributed_test(
            [-1, -1],
            multiple_runs,
            Entropy(),
            metric_kwargs,
            desired_values,
            exact=False,
        )


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 20:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag670')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_measure_test.py: 69-82
</a>
<div class="mid" id="frag670" style="display:none"><pre>
    def test_fbeta_multiclass_state(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        fbeta = FBetaMeasure()
        fbeta(self.predictions, self.targets)

        # check state
        assert_allclose(fbeta._pred_sum.tolist(), self.pred_sum)
        assert_allclose(fbeta._true_sum.tolist(), self.true_sum)
        assert_allclose(fbeta._true_positive_sum.tolist(), self.true_positive_sum)
        assert_allclose(fbeta._true_negative_sum.tolist(), self.true_negative_sum)
        assert_allclose(fbeta._total_sum.tolist(), self.total_sum)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag742')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 79-92
</a>
<div class="mid" id="frag742" style="display:none"><pre>
    def test_fbeta_multilabel_state(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        fbeta = FBetaMultiLabelMeasure()
        fbeta(self.predictions, self.targets)

        # check state
        assert_allclose(fbeta._pred_sum.tolist(), self.pred_sum)
        assert_allclose(fbeta._true_sum.tolist(), self.true_sum)
        assert_allclose(fbeta._true_positive_sum.tolist(), self.true_positive_sum)
        assert_allclose(fbeta._true_negative_sum.tolist(), self.true_negative_sum)
        assert_allclose(fbeta._total_sum.tolist(), self.total_sum)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 21:</b> &nbsp; 3 fragments, nominal size 15 lines, similarity 93%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag671')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_measure_test.py: 84-104
</a>
<div class="mid" id="frag671" style="display:none"><pre>
    def test_fbeta_multiclass_metric(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        fbeta = FBetaMeasure()
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        # check value
        assert_allclose(precisions, self.desired_precisions)
        assert_allclose(recalls, self.desired_recalls)
        assert_allclose(fscores, self.desired_fscores)

        # check type
        assert isinstance(precisions, List)
        assert isinstance(recalls, List)
        assert isinstance(fscores, List)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag744')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 116-136
</a>
<div class="mid" id="frag744" style="display:none"><pre>
    def test_fbeta_multilable_with_extra_dimensions(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        fbeta = FBetaMultiLabelMeasure()
        fbeta(self.predictions.unsqueeze(1), self.targets.unsqueeze(1))
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        # check value
        assert_allclose(precisions, self.desired_precisions)
        assert_allclose(recalls, self.desired_recalls)
        assert_allclose(fscores, self.desired_fscores)

        # check type
        assert isinstance(precisions, List)
        assert isinstance(recalls, List)
        assert isinstance(fscores, List)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag743')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 94-114
</a>
<div class="mid" id="frag743" style="display:none"><pre>
    def test_fbeta_multilabel_metric(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        fbeta = FBetaMultiLabelMeasure()
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        # check value
        assert_allclose(precisions, self.desired_precisions)
        assert_allclose(recalls, self.desired_recalls)
        assert_allclose(fscores, self.desired_fscores)

        # check type
        assert isinstance(precisions, List)
        assert isinstance(recalls, List)
        assert isinstance(fscores, List)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 22:</b> &nbsp; 2 fragments, nominal size 21 lines, similarity 85%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag672')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_measure_test.py: 106-132
</a>
<div class="mid" id="frag672" style="display:none"><pre>
    def test_fbeta_multiclass_with_mask(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        mask = torch.tensor([True, True, True, True, True, False], device=device)

        fbeta = FBetaMeasure()
        fbeta(self.predictions, self.targets, mask)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        assert_allclose(fbeta._pred_sum.tolist(), [1, 3, 0, 1, 0])
        assert_allclose(fbeta._true_sum.tolist(), [2, 1, 0, 1, 1])
        assert_allclose(fbeta._true_positive_sum.tolist(), [1, 1, 0, 1, 0])

        desired_precisions = [1.00, 1 / 3, 0.00, 1.00, 0.00]
        desired_recalls = [0.50, 1.00, 0.00, 1.00, 0.00]
        desired_fscores = [
            (2 * p * r) / (p + r) if p + r != 0.0 else 0.0
            for p, r in zip(desired_precisions, desired_recalls)
        ]
        assert_allclose(precisions, desired_precisions)
        assert_allclose(recalls, desired_recalls)
        assert_allclose(fscores, desired_fscores)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag745')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 138-164
</a>
<div class="mid" id="frag745" style="display:none"><pre>
    def test_fbeta_multilabel_with_mask(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        mask = torch.tensor([True, True, True, True, True, False], device=device).unsqueeze(-1)

        fbeta = FBetaMultiLabelMeasure()
        fbeta(self.predictions, self.targets, mask)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        assert_allclose(fbeta._pred_sum.tolist(), [3, 3, 3, 4, 1])
        assert_allclose(fbeta._true_sum.tolist(), [4, 5, 2, 4, 0])
        assert_allclose(fbeta._true_positive_sum.tolist(), [3, 3, 2, 4, 0])

        desired_precisions = [3 / 3, 3 / 3, 2 / 3, 4 / 4, 0 / 1]
        desired_recalls = [3 / 4, 3 / 5, 2 / 2, 4 / 4, 0.00]
        desired_fscores = [
            (2 * p * r) / (p + r) if p + r != 0.0 else 0.0
            for p, r in zip(desired_precisions, desired_recalls)
        ]
        assert_allclose(precisions, desired_precisions)
        assert_allclose(recalls, desired_recalls)
        assert_allclose(fscores, desired_fscores)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 23:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag673')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_measure_test.py: 134-158
</a>
<div class="mid" id="frag673" style="display:none"><pre>
    def test_fbeta_multiclass_macro_average_metric(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        fbeta = FBetaMeasure(average="macro")
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        # We keep the expected values in CPU because FBetaMeasure returns them in CPU.
        macro_precision = torch.tensor(self.desired_precisions).mean()
        macro_recall = torch.tensor(self.desired_recalls).mean()
        macro_fscore = torch.tensor(self.desired_fscores).mean()
        # check value
        assert_allclose(precisions, macro_precision)
        assert_allclose(recalls, macro_recall)
        assert_allclose(fscores, macro_fscore)

        # check type
        assert isinstance(precisions, float)
        assert isinstance(recalls, float)
        assert isinstance(fscores, float)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag746')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 166-190
</a>
<div class="mid" id="frag746" style="display:none"><pre>
    def test_fbeta_multilabel_macro_average_metric(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        fbeta = FBetaMultiLabelMeasure(average="macro")
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        # We keep the expected values in CPU because FBetaMeasure returns them in CPU.
        macro_precision = torch.tensor(self.desired_precisions).mean()
        macro_recall = torch.tensor(self.desired_recalls).mean()
        macro_fscore = torch.tensor(self.desired_fscores).mean()
        # check value
        assert_allclose(precisions, macro_precision)
        assert_allclose(recalls, macro_recall)
        assert_allclose(fscores, macro_fscore)

        # check type
        assert isinstance(precisions, float)
        assert isinstance(recalls, float)
        assert isinstance(fscores, float)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 24:</b> &nbsp; 4 fragments, nominal size 21 lines, similarity 77%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag674')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_measure_test.py: 160-186
</a>
<div class="mid" id="frag674" style="display:none"><pre>
    def test_fbeta_multiclass_micro_average_metric(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        fbeta = FBetaMeasure(average="micro")
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        # We keep the expected values in CPU because FBetaMeasure returns them in CPU.
        true_positives = torch.tensor([1, 1, 0, 1, 0], dtype=torch.float32)
        false_positives = torch.tensor([0, 3, 0, 0, 0], dtype=torch.float32)
        false_negatives = torch.tensor([2, 0, 0, 0, 1], dtype=torch.float32)
        mean_true_positive = true_positives.mean()
        mean_false_positive = false_positives.mean()
        mean_false_negative = false_negatives.mean()

        micro_precision = mean_true_positive / (mean_true_positive + mean_false_positive)
        micro_recall = mean_true_positive / (mean_true_positive + mean_false_negative)
        micro_fscore = (2 * micro_precision * micro_recall) / (micro_precision + micro_recall)
        # check value
        assert_allclose(precisions, micro_precision)
        assert_allclose(recalls, micro_recall)
        assert_allclose(fscores, micro_fscore)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag747')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 192-218
</a>
<div class="mid" id="frag747" style="display:none"><pre>
    def test_fbeta_multilabel_micro_average_metric(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        fbeta = FBetaMultiLabelMeasure(average="micro")
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        # We keep the expected values in CPU because FBetaMeasure returns them in CPU.
        true_positives = torch.tensor([3, 3, 2, 4, 0], dtype=torch.float32)
        false_positives = torch.tensor([1, 0, 1, 0, 1], dtype=torch.float32)
        false_negatives = torch.tensor([1, 2, 0, 0, 0], dtype=torch.float32)
        mean_true_positive = true_positives.mean()
        mean_false_positive = false_positives.mean()
        mean_false_negative = false_negatives.mean()

        micro_precision = mean_true_positive / (mean_true_positive + mean_false_positive)
        micro_recall = mean_true_positive / (mean_true_positive + mean_false_negative)
        micro_fscore = (2 * micro_precision * micro_recall) / (micro_precision + micro_recall)
        # check value
        assert_allclose(precisions, micro_precision)
        assert_allclose(recalls, micro_recall)
        assert_allclose(fscores, micro_fscore)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag677')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_measure_test.py: 232-259
</a>
<div class="mid" id="frag677" style="display:none"><pre>
    def test_fbeta_multiclass_with_micro_average(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        labels = [1, 3]
        fbeta = FBetaMeasure(average="micro", labels=labels)
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        # We keep the expected values in CPU because FBetaMeasure returns them in CPU.
        true_positives = torch.tensor([1, 1], dtype=torch.float32)
        false_positives = torch.tensor([3, 0], dtype=torch.float32)
        false_negatives = torch.tensor([0, 0], dtype=torch.float32)
        mean_true_positive = true_positives.mean()
        mean_false_positive = false_positives.mean()
        mean_false_negative = false_negatives.mean()

        micro_precision = mean_true_positive / (mean_true_positive + mean_false_positive)
        micro_recall = mean_true_positive / (mean_true_positive + mean_false_negative)
        micro_fscore = (2 * micro_precision * micro_recall) / (micro_precision + micro_recall)
        # check value
        assert_allclose(precisions, micro_precision)
        assert_allclose(recalls, micro_recall)
        assert_allclose(fscores, micro_fscore)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag750')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 264-291
</a>
<div class="mid" id="frag750" style="display:none"><pre>
    def test_fbeta_multilabel_with_micro_average(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        labels = [1, 3]
        fbeta = FBetaMultiLabelMeasure(average="micro", labels=labels)
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        # We keep the expected values in CPU because FBetaMeasure returns them in CPU.
        true_positives = torch.tensor([3, 4], dtype=torch.float32)
        false_positives = torch.tensor([0, 0], dtype=torch.float32)
        false_negatives = torch.tensor([2, 0], dtype=torch.float32)
        mean_true_positive = true_positives.mean()
        mean_false_positive = false_positives.mean()
        mean_false_negative = false_negatives.mean()

        micro_precision = mean_true_positive / (mean_true_positive + mean_false_positive)
        micro_recall = mean_true_positive / (mean_true_positive + mean_false_negative)
        micro_fscore = (2 * micro_precision * micro_recall) / (micro_precision + micro_recall)
        # check value
        assert_allclose(precisions, micro_precision)
        assert_allclose(recalls, micro_recall)
        assert_allclose(fscores, micro_fscore)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 25:</b> &nbsp; 2 fragments, nominal size 15 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag675')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_measure_test.py: 188-207
</a>
<div class="mid" id="frag675" style="display:none"><pre>
    def test_fbeta_multiclass_with_explicit_labels(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        # same prediction but with and explicit label ordering
        fbeta = FBetaMeasure(labels=[4, 3, 2, 1, 0])
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        desired_precisions = self.desired_precisions[::-1]
        desired_recalls = self.desired_recalls[::-1]
        desired_fscores = self.desired_fscores[::-1]
        # check value
        assert_allclose(precisions, desired_precisions)
        assert_allclose(recalls, desired_recalls)
        assert_allclose(fscores, desired_fscores)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag748')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 220-239
</a>
<div class="mid" id="frag748" style="display:none"><pre>
    def test_fbeta_multilabel_with_explicit_labels(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        # same prediction but with and explicit label ordering
        fbeta = FBetaMultiLabelMeasure(labels=[4, 3, 2, 1, 0])
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        desired_precisions = self.desired_precisions[::-1]
        desired_recalls = self.desired_recalls[::-1]
        desired_fscores = self.desired_fscores[::-1]
        # check value
        assert_allclose(precisions, desired_precisions)
        assert_allclose(recalls, desired_recalls)
        assert_allclose(fscores, desired_fscores)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 26:</b> &nbsp; 2 fragments, nominal size 16 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag676')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_measure_test.py: 209-230
</a>
<div class="mid" id="frag676" style="display:none"><pre>
    def test_fbeta_multiclass_with_macro_average(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        labels = [0, 1]
        fbeta = FBetaMeasure(average="macro", labels=labels)
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        # We keep the expected values in CPU because FBetaMeasure returns them in CPU.
        macro_precision = torch.tensor(self.desired_precisions)[labels].mean()
        macro_recall = torch.tensor(self.desired_recalls)[labels].mean()
        macro_fscore = torch.tensor(self.desired_fscores)[labels].mean()

        # check value
        assert_allclose(precisions, macro_precision)
        assert_allclose(recalls, macro_recall)
        assert_allclose(fscores, macro_fscore)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag749')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 241-262
</a>
<div class="mid" id="frag749" style="display:none"><pre>
    def test_fbeta_multilabel_with_macro_average(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        labels = [0, 1]
        fbeta = FBetaMultiLabelMeasure(average="macro", labels=labels)
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        # We keep the expected values in CPU because FBetaMeasure returns them in CPU.
        macro_precision = torch.tensor(self.desired_precisions)[labels].mean()
        macro_recall = torch.tensor(self.desired_recalls)[labels].mean()
        macro_fscore = torch.tensor(self.desired_fscores)[labels].mean()

        # check value
        assert_allclose(precisions, macro_precision)
        assert_allclose(recalls, macro_recall)
        assert_allclose(fscores, macro_fscore)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 27:</b> &nbsp; 2 fragments, nominal size 22 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag678')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_measure_test.py: 261-284
</a>
<div class="mid" id="frag678" style="display:none"><pre>
    def test_fbeta_multiclass_with_weighted_average(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        labels = [0, 1]
        fbeta = FBetaMeasure(average="weighted", labels=labels)
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        weighted_precision, weighted_recall, weighted_fscore, _ = precision_recall_fscore_support(
            self.targets.cpu().numpy(),
            self.predictions.argmax(dim=1).cpu().numpy(),
            labels=labels,
            average="weighted",
        )

        # check value
        assert_allclose(precisions, weighted_precision)
        assert_allclose(recalls, weighted_recall)
        assert_allclose(fscores, weighted_fscore)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag751')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 293-322
</a>
<div class="mid" id="frag751" style="display:none"><pre>
    def test_fbeta_multilabel_with_weighted_average(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        labels = [0, 1]
        fbeta = FBetaMultiLabelMeasure(average="weighted", labels=labels)
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        weighted_precision, weighted_recall, weighted_fscore, _ = precision_recall_fscore_support(
            self.targets.cpu().numpy(),
            torch.where(
                self.predictions &gt;= fbeta._threshold,
                torch.ones_like(self.predictions),
                torch.zeros_like(self.predictions),
            )
            .cpu()
            .numpy(),
            labels=labels,
            average="weighted",
        )

        # check value
        assert_allclose(precisions, weighted_precision)
        assert_allclose(recalls, weighted_recall)
        assert_allclose(fscores, weighted_fscore)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 28:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 81%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag679')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_measure_test.py: 286-299
</a>
<div class="mid" id="frag679" style="display:none"><pre>
    def test_fbeta_handles_batch_size_of_one(self, device: str):
        predictions = torch.tensor([[0.2862, 0.3479, 0.1627, 0.2033]], device=device)
        targets = torch.tensor([1], device=device)
        mask = torch.tensor([True], device=device)

        fbeta = FBetaMeasure()
        fbeta(predictions, targets, mask)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]

        assert_allclose(precisions, [0.0, 1.0, 0.0, 0.0])
        assert_allclose(recalls, [0.0, 1.0, 0.0, 0.0])

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag752')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 324-337
</a>
<div class="mid" id="frag752" style="display:none"><pre>
    def test_fbeta_multilabel_handles_batch_size_of_one(self, device: str):
        predictions = torch.tensor([[0.2862, 0.5479, 0.1627, 0.2033]], device=device)
        targets = torch.tensor([[0, 1, 0, 0]], device=device)
        mask = torch.tensor([[True]], device=device)

        fbeta = FBetaMultiLabelMeasure()
        fbeta(predictions, targets, mask)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]

        assert_allclose(precisions, [0.0, 1.0, 0.0, 0.0])
        assert_allclose(recalls, [0.0, 1.0, 0.0, 0.0])

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 29:</b> &nbsp; 8 fragments, nominal size 12 lines, similarity 91%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag680')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_measure_test.py: 301-317
</a>
<div class="mid" id="frag680" style="display:none"><pre>
    def test_fbeta_handles_no_prediction_false_last_class(self, device: str):

        predictions = torch.tensor([[0.65, 0.35], [0.0, 0.0]], device=device)
        # preds = [0, NA]
        targets = torch.tensor([0, 0], device=device)

        fbeta = FBetaMeasure()
        fbeta(predictions, targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        assert_allclose(precisions, [1.0, 0.0])
        assert_allclose(recalls, [0.5, 0.0])
        assert_allclose(fscores, [0.6667, 0.0])

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag682')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_measure_test.py: 337-353
</a>
<div class="mid" id="frag682" style="display:none"><pre>
    def test_fbeta_handles_no_prediction_true_other_class(self, device: str):

        predictions = torch.tensor([[0.65, 0.35], [0.0, 0.0]], device=device)
        # preds = [0, NA]
        targets = torch.tensor([1, 0], device=device)

        fbeta = FBetaMeasure()
        fbeta(predictions, targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        assert_allclose(precisions, [0.0, 0.0])
        assert_allclose(recalls, [0.0, 0.0])
        assert_allclose(fscores, [0.0, 0.0])

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag683')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_measure_test.py: 355-371
</a>
<div class="mid" id="frag683" style="display:none"><pre>
    def test_fbeta_handles_no_prediction_true_all_class(self, device: str):

        predictions = torch.tensor([[0.65, 0.35], [0.0, 0.0]], device=device)
        # preds = [0, NA]
        targets = torch.tensor([1, 1], device=device)

        fbeta = FBetaMeasure()
        fbeta(predictions, targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        assert_allclose(precisions, [0.0, 0.0])
        assert_allclose(recalls, [0.0, 0.0])
        assert_allclose(fscores, [0.0, 0.0])

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag754')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 357-373
</a>
<div class="mid" id="frag754" style="display:none"><pre>
    def test_fbeta_multilabel_handles_no_prediction_true_last_class(self, device: str):

        predictions = torch.tensor([[0.65, 0.35], [0.0, 0.0]], device=device)
        # preds = [0, NA]
        targets = torch.tensor([[1, 0], [0, 1]], device=device)

        fbeta = FBetaMultiLabelMeasure()
        fbeta(predictions, targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        assert_allclose(precisions, [1.0, 0.0])
        assert_allclose(recalls, [1.0, 0.0])
        assert_allclose(fscores, [1.0, 0.0])

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag755')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 375-390
</a>
<div class="mid" id="frag755" style="display:none"><pre>
    def test_fbeta_multilabel_handles_no_prediction_true_other_class(self, device: str):
        predictions = torch.tensor([[0.65, 0.35], [0.0, 0.0]], device=device)
        # preds = [0, NA]
        targets = torch.tensor([[0, 1], [1, 0]], device=device)

        fbeta = FBetaMultiLabelMeasure()
        fbeta(predictions, targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        assert_allclose(precisions, [0.0, 0.0])
        assert_allclose(recalls, [0.0, 0.0])
        assert_allclose(fscores, [0.0, 0.0])

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag681')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_measure_test.py: 319-335
</a>
<div class="mid" id="frag681" style="display:none"><pre>
    def test_fbeta_handles_no_prediction_true_last_class(self, device: str):

        predictions = torch.tensor([[0.65, 0.35], [0.0, 0.0]], device=device)
        # preds = [0, NA]
        targets = torch.tensor([0, 1], device=device)

        fbeta = FBetaMeasure()
        fbeta(predictions, targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        assert_allclose(precisions, [1.0, 0.0])
        assert_allclose(recalls, [1.0, 0.0])
        assert_allclose(fscores, [1.0, 0.0])

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag756')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 392-407
</a>
<div class="mid" id="frag756" style="display:none"><pre>
    def test_fbeta_multilabel_handles_no_prediction_true_all_class(self, device: str):
        predictions = torch.tensor([[0.65, 0.35], [0.0, 0.0]], device=device)
        # preds = [0, NA]
        targets = torch.tensor([[0, 1], [0, 1]], device=device)

        fbeta = FBetaMultiLabelMeasure()
        fbeta(predictions, targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        assert_allclose(precisions, [0.0, 0.0])
        assert_allclose(recalls, [0.0, 0.0])
        assert_allclose(fscores, [0.0, 0.0])

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag753')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 339-355
</a>
<div class="mid" id="frag753" style="display:none"><pre>
    def test_fbeta_multilabel_handles_no_prediction_false_last_class(self, device: str):

        predictions = torch.tensor([[0.65, 0.35], [0.0, 0.0]], device=device)
        # preds = [0, NA]
        targets = torch.tensor([[1, 0], [1, 0]], device=device)

        fbeta = FBetaMultiLabelMeasure()
        fbeta(predictions, targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        assert_allclose(precisions, [1.0, 0.0])
        assert_allclose(recalls, [0.5, 0.0])
        assert_allclose(fscores, [0.6667, 0.0])

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 30:</b> &nbsp; 3 fragments, nominal size 22 lines, similarity 80%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag684')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_measure_test.py: 372-396
</a>
<div class="mid" id="frag684" style="display:none"><pre>
    def test_distributed_fbeta_measure(self):
        predictions = [
            torch.tensor(
                [[0.35, 0.25, 0.1, 0.1, 0.2], [0.1, 0.6, 0.1, 0.2, 0.0], [0.1, 0.6, 0.1, 0.2, 0.0]]
            ),
            torch.tensor(
                [[0.1, 0.5, 0.1, 0.2, 0.0], [0.1, 0.2, 0.1, 0.7, 0.0], [0.1, 0.6, 0.1, 0.2, 0.0]]
            ),
        ]
        targets = [torch.tensor([0, 4, 1]), torch.tensor([0, 3, 0])]
        metric_kwargs = {"predictions": predictions, "gold_labels": targets}
        desired_metrics = {
            "precision": self.desired_precisions,
            "recall": self.desired_recalls,
            "fscore": self.desired_fscores,
        }
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            FBetaMeasure(),
            metric_kwargs,
            desired_metrics,
            exact=False,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag705')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/f1_measure_test.py: 190-213
</a>
<div class="mid" id="frag705" style="display:none"><pre>
    def test_distributed_fbeta_measure(self):
        predictions = [
            torch.tensor(
                [[0.35, 0.25, 0.1, 0.1, 0.2], [0.1, 0.6, 0.1, 0.2, 0.0], [0.1, 0.6, 0.1, 0.2, 0.0]]
            ),
            torch.tensor(
                [[0.1, 0.5, 0.1, 0.2, 0.0], [0.1, 0.2, 0.1, 0.7, 0.0], [0.1, 0.6, 0.1, 0.2, 0.0]]
            ),
        ]
        targets = [torch.tensor([0, 4, 1]), torch.tensor([0, 3, 0])]
        metric_kwargs = {"predictions": predictions, "gold_labels": targets}
        desired_metrics = {
            "precision": 1.0,
            "recall": 0.333333333,
            "f1": 0.499999999,
        }
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            F1Measure(positive_label=0),
            metric_kwargs,
            desired_metrics,
            exact=False,
        )
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag685')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_measure_test.py: 397-422
</a>
<div class="mid" id="frag685" style="display:none"><pre>
    def test_multiple_distributed_runs(self):
        predictions = [
            torch.tensor(
                [[0.35, 0.25, 0.1, 0.1, 0.2], [0.1, 0.6, 0.1, 0.2, 0.0], [0.1, 0.6, 0.1, 0.2, 0.0]]
            ),
            torch.tensor(
                [[0.1, 0.5, 0.1, 0.2, 0.0], [0.1, 0.2, 0.1, 0.7, 0.0], [0.1, 0.6, 0.1, 0.2, 0.0]]
            ),
        ]
        targets = [torch.tensor([0, 4, 1]), torch.tensor([0, 3, 0])]
        metric_kwargs = {"predictions": predictions, "gold_labels": targets}
        desired_metrics = {
            "precision": self.desired_precisions,
            "recall": self.desired_recalls,
            "fscore": self.desired_fscores,
        }
        run_distributed_test(
            [-1, -1],
            multiple_runs,
            FBetaMeasure(),
            metric_kwargs,
            desired_metrics,
            exact=False,
        )


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 31:</b> &nbsp; 2 fragments, nominal size 32 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag688')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/pearson_correlation_test.py: 30-66
</a>
<div class="mid" id="frag688" style="display:none"><pre>
    def test_pearson_correlation_unmasked_computation(self, device: str):
        pearson_correlation = PearsonCorrelation()
        batch_size = 100
        num_labels = 10
        predictions_1 = torch.randn(batch_size, num_labels, device=device)
        labels_1 = 0.5 * predictions_1 + torch.randn(batch_size, num_labels, device=device)

        predictions_2 = torch.randn(1, device=device).expand(num_labels)
        predictions_2 = predictions_2.unsqueeze(0).expand(batch_size, -1)
        labels_2 = torch.randn(1, device=device).expand(num_labels)
        labels_2 = 0.5 * predictions_2 + labels_2.unsqueeze(0).expand(batch_size, -1)

        # in most cases, the data is constructed like predictions_1, the data of such a batch different.
        # but in a few cases, for example, predictions_2, the data of such a batch is exactly the same.
        predictions_labels = [(predictions_1, labels_1), (predictions_2, labels_2)]

        stride = 10

        for predictions, labels in predictions_labels:
            pearson_correlation.reset()
            for i in range(batch_size // stride):
                timestep_predictions = predictions[stride * i : stride * (i + 1), :]
                timestep_labels = labels[stride * i : stride * (i + 1), :]
                expected_pearson_correlation = pearson_corrcoef(
                    predictions[: stride * (i + 1), :].view(-1).cpu().numpy(),
                    labels[: stride * (i + 1), :].view(-1).cpu().numpy(),
                )
                pearson_correlation(timestep_predictions, timestep_labels)
                assert_allclose(expected_pearson_correlation, pearson_correlation.get_metric())
            # Test reset
            pearson_correlation.reset()
            pearson_correlation(predictions, labels)
            assert_allclose(
                pearson_corrcoef(predictions.view(-1).cpu().numpy(), labels.view(-1).cpu().numpy()),
                pearson_correlation.get_metric(),
            )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag689')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/pearson_correlation_test.py: 68-132
</a>
<div class="mid" id="frag689" style="display:none"><pre>
    def test_pearson_correlation_masked_computation(self, device: str):
        pearson_correlation = PearsonCorrelation()
        batch_size = 100
        num_labels = 10
        predictions_1 = torch.randn(batch_size, num_labels, device=device)
        labels_1 = 0.5 * predictions_1 + torch.randn(batch_size, num_labels, device=device)

        predictions_2 = torch.randn(1, device=device).expand(num_labels)
        predictions_2 = predictions_2.unsqueeze(0).expand(batch_size, -1)
        labels_2 = torch.randn(1, device=device).expand(num_labels)
        labels_2 = 0.5 * predictions_2 + labels_2.unsqueeze(0).expand(batch_size, -1)

        predictions_labels = [(predictions_1, labels_1), (predictions_2, labels_2)]

        # Random binary mask
        mask = torch.randint(0, 2, size=(batch_size, num_labels), device=device).bool()
        stride = 10

        for predictions, labels in predictions_labels:
            pearson_correlation.reset()
            for i in range(batch_size // stride):
                timestep_predictions = predictions[stride * i : stride * (i + 1), :]
                timestep_labels = labels[stride * i : stride * (i + 1), :]
                timestep_mask = mask[stride * i : stride * (i + 1), :]
                expected_pearson_correlation = pearson_corrcoef(
                    predictions[: stride * (i + 1), :].view(-1).cpu().numpy(),
                    labels[: stride * (i + 1), :].view(-1).cpu().numpy(),
                    fweights=mask[: stride * (i + 1), :].view(-1).cpu().numpy(),
                )

                pearson_correlation(timestep_predictions, timestep_labels, timestep_mask)
                assert_allclose(expected_pearson_correlation, pearson_correlation.get_metric())
            # Test reset
            pearson_correlation.reset()
            pearson_correlation(predictions, labels, mask)
            expected_pearson_correlation = pearson_corrcoef(
                predictions.view(-1).cpu().numpy(),
                labels.view(-1).cpu().numpy(),
                fweights=mask.view(-1).cpu().numpy(),
            )

            assert_allclose(expected_pearson_correlation, pearson_correlation.get_metric())

    # Commenting in order to revisit distributed covariance (on which PearsonCorrelation depends) later.

    # def test_distributed_pearson(self):
    #     batch_size = 10
    #     num_labels = 10
    #     predictions = torch.randn(batch_size, num_labels)
    #     labels = 0.5 * predictions + torch.randn(batch_size, num_labels)

    #     expected_pearson_correlation = pearson_corrcoef(
    #         predictions.view(-1).cpu().numpy(), labels.view(-1).cpu().numpy(),
    #     )
    #     predictions = [predictions[:5], predictions[5:]]
    #     labels = [labels[:5], labels[5:]]
    #     metric_kwargs = {"predictions": predictions, "gold_labels": labels}
    #     run_distributed_test(
    #         [-1, -1],
    #         global_distributed_metric,
    #         PearsonCorrelation(),
    #         metric_kwargs,
    #         expected_pearson_correlation,
    #         exact=(0.0001, 1e-01),
    #     )
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 32:</b> &nbsp; 2 fragments, nominal size 35 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag691')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/mean_absolute_error_test.py: 75-114
</a>
<div class="mid" id="frag691" style="display:none"><pre>
    def test_distributed_accuracy(self):
        predictions = [
            torch.tensor(
                [
                    [1.0, 1.5, 1.0],
                    [2.0, 3.0, 3.5],
                ]
            ),
            torch.tensor(
                [
                    [4.0, 5.0, 5.5],
                    [6.0, 7.0, 7.5],
                ]
            ),
        ]
        targets = [
            torch.tensor(
                [
                    [0.0, 1.0, 0.0],
                    [2.0, 2.0, 0.0],
                ]
            ),
            torch.tensor(
                [
                    [4.0, 5.0, 0.0],
                    [7.0, 7.0, 0.0],
                ]
            ),
        ]
        metric_kwargs = {"predictions": predictions, "gold_labels": targets}
        desired_values = {"mae": 21.0 / 12.0}
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            MeanAbsoluteError(),
            metric_kwargs,
            desired_values,
            exact=True,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag692')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/mean_absolute_error_test.py: 115-155
</a>
<div class="mid" id="frag692" style="display:none"><pre>
    def test_multiple_distributed_runs(self):
        predictions = [
            torch.tensor(
                [
                    [1.0, 1.5, 1.0],
                    [2.0, 3.0, 3.5],
                ]
            ),
            torch.tensor(
                [
                    [4.0, 5.0, 5.5],
                    [6.0, 7.0, 7.5],
                ]
            ),
        ]
        targets = [
            torch.tensor(
                [
                    [0.0, 1.0, 0.0],
                    [2.0, 2.0, 0.0],
                ]
            ),
            torch.tensor(
                [
                    [4.0, 5.0, 0.0],
                    [7.0, 7.0, 0.0],
                ]
            ),
        ]
        metric_kwargs = {"predictions": predictions, "gold_labels": targets}
        desired_values = {"mae": 21.0 / 12.0}
        run_distributed_test(
            [-1, -1],
            multiple_runs,
            MeanAbsoluteError(),
            metric_kwargs,
            desired_values,
            exact=True,
        )


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 33:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag695')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/spearman_correlation_test.py: 50-73
</a>
<div class="mid" id="frag695" style="display:none"><pre>
    def test_unmasked_computation(self, device: str):
        spearman_correlation = SpearmanCorrelation()
        batch_size = 10
        num_labels = 10
        predictions1 = torch.randn(batch_size, num_labels, device=device)
        labels1 = 0.5 * predictions1 + torch.randn(batch_size, num_labels, device=device)

        predictions2 = torch.randn(1, device=device).repeat(num_labels)
        predictions2 = predictions2.unsqueeze(0).expand(batch_size, -1)
        labels2 = torch.randn(1, device=device).expand(num_labels)
        labels2 = 0.5 * predictions2 + labels2.unsqueeze(0).expand(batch_size, -1)

        # in most cases, the data is constructed like predictions_1, the data of such a batch different.
        # but in a few cases, for example, predictions_2, the data of such a batch is exactly the same.
        predictions_labels_ = [(predictions1, labels1), (predictions2, labels2)]

        for predictions, labels in predictions_labels_:
            spearman_correlation.reset()
            spearman_correlation(predictions, labels)
            assert_allclose(
                spearman_formula(predictions.reshape(-1), labels.reshape(-1)),
                spearman_correlation.get_metric(),
            )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag696')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/spearman_correlation_test.py: 75-107
</a>
<div class="mid" id="frag696" style="display:none"><pre>
    def test_masked_computation(self, device: str):
        spearman_correlation = SpearmanCorrelation()
        batch_size = 10
        num_labels = 10
        predictions1 = torch.randn(batch_size, num_labels, device=device)
        labels1 = 0.5 * predictions1 + torch.randn(batch_size, num_labels, device=device)

        predictions2 = torch.randn(1, device=device).expand(num_labels)
        predictions2 = predictions2.unsqueeze(0).expand(batch_size, -1)
        labels2 = torch.randn(1, device=device).expand(num_labels)
        labels2 = 0.5 * predictions2 + labels2.unsqueeze(0).expand(batch_size, -1)

        # in most cases, the data is constructed like predictions_1, the data of such a batch different.
        # but in a few cases, for example, predictions_2, the data of such a batch is exactly the same.
        predictions_labels_ = [(predictions1, labels1), (predictions2, labels2)]

        # Random binary mask
        mask = torch.randint(0, 2, size=(batch_size, num_labels), device=device).bool()

        for predictions, labels in predictions_labels_:
            spearman_correlation.reset()
            spearman_correlation(predictions, labels, mask)
            expected_spearman_correlation = spearman_formula(
                predictions.view(-1), labels.view(-1), mask=mask.view(-1)
            )

            # because add mask, a batch of predictions or labels will have many 0,
            # spearman correlation algorithm will dependence the sorting position of a set of numbers,
            # too many identical numbers will result in different calculation results each time
            # but the positive and negative results are the same,
            # so here we only test the positive and negative results of the results.
            assert (expected_spearman_correlation * spearman_correlation.get_metric()) &gt; 0

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 34:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 94%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag698')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/spearman_correlation_test.py: 133-150
</a>
<div class="mid" id="frag698" style="display:none"><pre>
    def test_distributed_spearman(self):
        batch_size = 10
        num_labels = 10
        predictions = torch.randn(batch_size, num_labels)
        labels = 0.5 * predictions + torch.randn(batch_size, num_labels)
        desired_spearman = spearman_formula(predictions.reshape(-1), labels.reshape(-1))
        predictions = [predictions[:5], predictions[5:]]
        labels = [labels[:5], labels[5:]]
        metric_kwargs = {"predictions": predictions, "gold_labels": labels}
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            SpearmanCorrelation(),
            metric_kwargs,
            desired_spearman,
            exact=False,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag699')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/spearman_correlation_test.py: 151-168
</a>
<div class="mid" id="frag699" style="display:none"><pre>
    def test_distributed_spearman_unequal_batches(self):
        batch_size = 10
        num_labels = 10
        predictions = torch.randn(batch_size, num_labels)
        labels = 0.5 * predictions + torch.randn(batch_size, num_labels)
        desired_spearman = spearman_formula(predictions.reshape(-1), labels.reshape(-1))
        predictions = [predictions[:6], predictions[6:]]
        labels = [labels[:6], labels[6:]]
        metric_kwargs = {"predictions": predictions, "gold_labels": labels}
        with pytest.raises(Exception) as _:
            run_distributed_test(
                [-1, -1],
                global_distributed_metric,
                SpearmanCorrelation(),
                metric_kwargs,
                desired_spearman,
                exact=False,
            )
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 35:</b> &nbsp; 4 fragments, nominal size 36 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag701')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/f1_measure_test.py: 25-75
</a>
<div class="mid" id="frag701" style="display:none"><pre>
    def test_f1_measure(self, device: str):
        f1_measure = F1Measure(positive_label=0)
        predictions = torch.tensor(
            [
                [0.35, 0.25, 0.1, 0.1, 0.2],
                [0.1, 0.6, 0.1, 0.2, 0.0],
                [0.1, 0.6, 0.1, 0.2, 0.0],
                [0.1, 0.5, 0.1, 0.2, 0.0],
                [0.1, 0.2, 0.1, 0.7, 0.0],
                [0.1, 0.6, 0.1, 0.2, 0.0],
            ],
            device=device,
        )
        # [True Positive, True Negative, True Negative,
        #  False Negative, True Negative, False Negative]
        targets = torch.tensor([0, 4, 1, 0, 3, 0], device=device)
        f1_measure(predictions, targets)
        metrics = f1_measure.get_metric()
        precision = metrics["precision"]
        recall = metrics["recall"]
        f1 = metrics["f1"]
        assert f1_measure._true_positives == 1.0
        assert f1_measure._true_negatives == 3.0
        assert f1_measure._false_positives == 0.0
        assert f1_measure._false_negatives == 2.0
        f1_measure.reset()
        # check value
        assert_allclose(precision, 1.0)
        assert_allclose(recall, 0.333333333)
        assert_allclose(f1, 0.499999999)
        # check type
        assert isinstance(precision, float)
        assert isinstance(recall, float)
        assert isinstance(f1, float)

        # Test the same thing with a mask:
        mask = torch.tensor([True, False, True, True, True, False], device=device)
        f1_measure(predictions, targets, mask)
        metrics = f1_measure.get_metric()
        precision = metrics["precision"]
        recall = metrics["recall"]
        f1 = metrics["f1"]
        assert f1_measure._true_positives == 1.0
        assert f1_measure._true_negatives == 2.0
        assert f1_measure._false_positives == 0.0
        assert f1_measure._false_negatives == 1.0
        f1_measure.reset()
        assert_allclose(precision, 1.0)
        assert_allclose(recall, 0.5)
        assert_allclose(f1, 0.6666666666)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag703')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/f1_measure_test.py: 113-147
</a>
<div class="mid" id="frag703" style="display:none"><pre>
    def test_f1_measure_accumulates_and_resets_correctly(self, device: str):
        f1_measure = F1Measure(positive_label=0)
        predictions = torch.tensor(
            [
                [0.35, 0.25, 0.1, 0.1, 0.2],
                [0.1, 0.6, 0.1, 0.2, 0.0],
                [0.1, 0.6, 0.1, 0.2, 0.0],
                [0.1, 0.5, 0.1, 0.2, 0.0],
                [0.1, 0.2, 0.1, 0.7, 0.0],
                [0.1, 0.6, 0.1, 0.2, 0.0],
            ],
            device=device,
        )
        # [True Positive, True Negative, True Negative,
        #  False Negative, True Negative, False Negative]
        targets = torch.tensor([0, 4, 1, 0, 3, 0], device=device)
        f1_measure(predictions, targets)
        f1_measure(predictions, targets)
        metrics = f1_measure.get_metric()
        precision = metrics["precision"]
        recall = metrics["recall"]
        f1 = metrics["f1"]
        assert f1_measure._true_positives == 2.0
        assert f1_measure._true_negatives == 6.0
        assert f1_measure._false_positives == 0.0
        assert f1_measure._false_negatives == 4.0
        f1_measure.reset()
        assert_allclose(precision, 1.0)
        assert_allclose(recall, 0.333333333)
        assert_allclose(f1, 0.499999999)
        assert f1_measure._true_positives == 0.0
        assert f1_measure._true_negatives == 0.0
        assert f1_measure._false_positives == 0.0
        assert f1_measure._false_negatives == 0.0

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag704')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/f1_measure_test.py: 149-189
</a>
<div class="mid" id="frag704" style="display:none"><pre>
    def test_f1_measure_works_for_sequences(self, device: str):
        f1_measure = F1Measure(positive_label=0)
        predictions = torch.tensor(
            [
                [[0.35, 0.25, 0.1, 0.1, 0.2], [0.1, 0.6, 0.1, 0.2, 0.0], [0.1, 0.6, 0.1, 0.2, 0.0]],
                [[0.35, 0.25, 0.1, 0.1, 0.2], [0.1, 0.6, 0.1, 0.2, 0.0], [0.1, 0.6, 0.1, 0.2, 0.0]],
            ],
            device=device,
        )
        # [[True Positive, True Negative, True Negative],
        #  [True Positive, True Negative, False Negative]]
        targets = torch.tensor([[0, 3, 4], [0, 1, 0]], device=device)
        f1_measure(predictions, targets)
        metrics = f1_measure.get_metric()
        precision = metrics["precision"]
        recall = metrics["recall"]
        f1 = metrics["f1"]
        assert f1_measure._true_positives == 2.0
        assert f1_measure._true_negatives == 3.0
        assert f1_measure._false_positives == 0.0
        assert f1_measure._false_negatives == 1.0
        f1_measure.reset()
        assert_allclose(precision, 1.0)
        assert_allclose(recall, 0.666666666)
        assert_allclose(f1, 0.8)

        # Test the same thing with a mask:
        mask = torch.tensor([[False, True, False], [True, True, True]], device=device)
        f1_measure(predictions, targets, mask)
        metrics = f1_measure.get_metric()
        precision = metrics["precision"]
        recall = metrics["recall"]
        f1 = metrics["f1"]
        assert f1_measure._true_positives == 1.0
        assert f1_measure._true_negatives == 2.0
        assert f1_measure._false_positives == 0.0
        assert f1_measure._false_negatives == 1.0
        assert_allclose(precision, 1.0)
        assert_allclose(recall, 0.5)
        assert_allclose(f1, 0.66666666666)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag702')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/f1_measure_test.py: 77-111
</a>
<div class="mid" id="frag702" style="display:none"><pre>
    def test_f1_measure_other_positive_label(self, device: str):
        f1_measure = F1Measure(positive_label=1)
        predictions = torch.tensor(
            [
                [0.35, 0.25, 0.1, 0.1, 0.2],
                [0.1, 0.6, 0.1, 0.2, 0.0],
                [0.1, 0.6, 0.1, 0.2, 0.0],
                [0.1, 0.5, 0.1, 0.2, 0.0],
                [0.1, 0.2, 0.1, 0.7, 0.0],
                [0.1, 0.6, 0.1, 0.2, 0.0],
            ],
            device=device,
        )
        # [True Negative, False Positive, True Positive,
        #  False Positive, True Negative, False Positive]
        targets = torch.tensor([0, 4, 1, 0, 3, 0], device=device)
        f1_measure(predictions, targets)
        metrics = f1_measure.get_metric()
        precision = metrics["precision"]
        recall = metrics["recall"]
        f1 = metrics["f1"]
        assert f1_measure._true_positives == 1.0
        assert f1_measure._true_negatives == 2.0
        assert f1_measure._false_positives == 3.0
        assert f1_measure._false_negatives == 0.0
        f1_measure.reset()
        # check value
        assert_allclose(precision, 0.25)
        assert_allclose(recall, 1.0)
        assert_allclose(f1, 0.4)
        # check type
        assert isinstance(precision, float)
        assert isinstance(recall, float)
        assert isinstance(f1, float)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 36:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 84%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag709')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/attachment_scores_test.py: 49-70
</a>
<div class="mid" id="frag709" style="display:none"><pre>
    def test_unlabeled_accuracy_ignores_incorrect_labels(self, device: str):
        self._send_tensors_to_device(device)

        label_predictions = self.label_predictions
        # Change some stuff so our 4 of our label predictions are wrong.
        label_predictions[0, 3:] = 3
        label_predictions[1, 0] = 7
        self.scorer(
            self.predictions, label_predictions, self.gold_indices, self.gold_labels, self.mask
        )

        metrics = self.scorer.get_metric()

        assert metrics["UAS"] == 1.0
        assert metrics["UEM"] == 1.0

        # 4 / 12 labels were wrong and 2 positions
        # are masked, so 6/10 = 0.6 LAS.
        assert metrics["LAS"] == 0.6
        # Neither should have labeled exact match.
        assert metrics["LEM"] == 0.0

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag710')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/attachment_scores_test.py: 72-97
</a>
<div class="mid" id="frag710" style="display:none"><pre>
    def test_labeled_accuracy_is_affected_by_incorrect_heads(self, device: str):
        self._send_tensors_to_device(device)

        predictions = self.predictions
        # Change some stuff so our 4 of our predictions are wrong.
        predictions[0, 3:] = 3
        predictions[1, 0] = 7
        # This one is in the padded part, so it shouldn't affect anything.
        predictions[1, 5] = 7
        self.scorer(
            predictions, self.label_predictions, self.gold_indices, self.gold_labels, self.mask
        )

        metrics = self.scorer.get_metric()

        # 4 heads are incorrect, so the unlabeled score should be
        # 6/10 = 0.6 LAS.
        assert metrics["UAS"] == 0.6
        # All the labels were correct, but some heads
        # were wrong, so the LAS should equal the UAS.
        assert metrics["LAS"] == 0.6

        # Neither batch element had a perfect labeled or unlabeled EM.
        assert metrics["LEM"] == 0.0
        assert metrics["UEM"] == 0.0

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 37:</b> &nbsp; 2 fragments, nominal size 33 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag712')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/attachment_scores_test.py: 113-152
</a>
<div class="mid" id="frag712" style="display:none"><pre>
    def test_distributed_attachment_scores(self):
        predictions = [torch.Tensor([[0, 1, 3, 5, 2, 4]]), torch.Tensor([[0, 3, 2, 1, 0, 0]])]

        gold_indices = [torch.Tensor([[0, 1, 3, 5, 2, 4]]), torch.Tensor([[0, 3, 2, 1, 0, 0]])]

        label_predictions = [
            torch.Tensor([[0, 5, 2, 3, 3, 3]]),
            torch.Tensor([[7, 4, 8, 2, 0, 0]]),
        ]

        gold_labels = [torch.Tensor([[0, 5, 2, 1, 4, 2]]), torch.Tensor([[0, 4, 8, 2, 0, 0]])]

        mask = [
            torch.tensor([[True, True, True, True, True, True]]),
            torch.tensor([[True, True, True, True, False, False]]),
        ]

        metric_kwargs = {
            "predicted_indices": predictions,
            "gold_indices": gold_indices,
            "predicted_labels": label_predictions,
            "gold_labels": gold_labels,
            "mask": mask,
        }

        desired_metrics = {
            "UAS": 1.0,
            "LAS": 0.6,
            "UEM": 1.0,
            "LEM": 0.0,
        }
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            AttachmentScores(),
            metric_kwargs,
            desired_metrics,
            exact=True,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag713')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/attachment_scores_test.py: 153-193
</a>
<div class="mid" id="frag713" style="display:none"><pre>
    def test_multiple_distributed_runs(self):
        predictions = [torch.Tensor([[0, 1, 3, 5, 2, 4]]), torch.Tensor([[0, 3, 2, 1, 0, 0]])]

        gold_indices = [torch.Tensor([[0, 1, 3, 5, 2, 4]]), torch.Tensor([[0, 3, 2, 1, 0, 0]])]

        label_predictions = [
            torch.Tensor([[0, 5, 2, 3, 3, 3]]),
            torch.Tensor([[7, 4, 8, 2, 0, 0]]),
        ]

        gold_labels = [torch.Tensor([[0, 5, 2, 1, 4, 2]]), torch.Tensor([[0, 4, 8, 2, 0, 0]])]

        mask = [
            torch.tensor([[True, True, True, True, True, True]]),
            torch.tensor([[True, True, True, True, False, False]]),
        ]

        metric_kwargs = {
            "predicted_indices": predictions,
            "gold_indices": gold_indices,
            "predicted_labels": label_predictions,
            "gold_labels": gold_labels,
            "mask": mask,
        }

        desired_metrics = {
            "UAS": 1.0,
            "LAS": 0.6,
            "UEM": 1.0,
            "LEM": 0.0,
        }
        run_distributed_test(
            [-1, -1],
            multiple_runs,
            AttachmentScores(),
            metric_kwargs,
            desired_metrics,
            exact=True,
        )


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 38:</b> &nbsp; 3 fragments, nominal size 17 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag736')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/categorical_accuracy_test.py: 152-168
</a>
<div class="mid" id="frag736" style="display:none"><pre>
    def test_distributed_accuracy(self):
        predictions = [
            torch.tensor([[0.35, 0.25, 0.1, 0.1, 0.2]]),
            torch.tensor([[0.1, 0.6, 0.1, 0.2, 0.0]]),
        ]
        targets = [torch.tensor([0]), torch.tensor([3])]
        metric_kwargs = {"predictions": predictions, "gold_labels": targets}
        desired_accuracy = 0.5
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            CategoricalAccuracy(),
            metric_kwargs,
            desired_accuracy,
            exact=False,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag738')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/categorical_accuracy_test.py: 187-203
</a>
<div class="mid" id="frag738" style="display:none"><pre>
    def test_multiple_distributed_runs(self):
        predictions = [
            torch.tensor([[0.35, 0.25, 0.1, 0.1, 0.2]]),
            torch.tensor([[0.1, 0.6, 0.1, 0.2, 0.0]]),
        ]
        targets = [torch.tensor([0]), torch.tensor([3])]
        metric_kwargs = {"predictions": predictions, "gold_labels": targets}
        desired_accuracy = 0.5
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            CategoricalAccuracy(),
            metric_kwargs,
            desired_accuracy,
            exact=True,
            number_of_runs=200,
        )
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag737')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/categorical_accuracy_test.py: 169-186
</a>
<div class="mid" id="frag737" style="display:none"><pre>
    def test_distributed_accuracy_unequal_batches(self):
        predictions = [
            torch.tensor([[0.35, 0.25, 0.1, 0.1, 0.2], [0.1, 0.6, 0.1, 0.2, 0.0]]),
            torch.tensor([[0.1, 0.2, 0.5, 0.2, 0.0]]),
        ]
        targets = [torch.tensor([0, 3]), torch.tensor([0])]
        mask = [torch.tensor([False, True]), torch.tensor([True])]
        metric_kwargs = {"predictions": predictions, "gold_labels": targets, "mask": mask}
        desired_accuracy = 0.5
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            CategoricalAccuracy(top_k=2),
            metric_kwargs,
            desired_accuracy,
            exact=False,
        )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 39:</b> &nbsp; 2 fragments, nominal size 33 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag757')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 408-445
</a>
<div class="mid" id="frag757" style="display:none"><pre>
    def test_distributed_fbeta_multilabel_measure(self):
        predictions = [
            torch.tensor(
                [
                    [0.55, 0.25, 0.10, 0.10, 0.20],
                    [0.10, 0.60, 0.10, 0.95, 0.00],
                    [0.90, 0.80, 0.75, 0.80, 0.00],
                ]
            ),
            torch.tensor(
                [
                    [0.49, 0.50, 0.95, 0.55, 0.00],
                    [0.60, 0.49, 0.60, 0.65, 0.85],
                    [0.85, 0.40, 0.10, 0.20, 0.00],
                ]
            ),
        ]

        targets = [
            torch.tensor([[1, 1, 0, 0, 0], [0, 1, 0, 1, 0], [1, 1, 0, 1, 0]]),
            torch.tensor([[1, 1, 1, 1, 0], [1, 1, 1, 1, 0], [0, 0, 0, 0, 0]]),
        ]

        metric_kwargs = {"predictions": predictions, "gold_labels": targets}
        desired_metrics = {
            "precision": self.desired_precisions,
            "recall": self.desired_recalls,
            "fscore": self.desired_fscores,
        }
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            FBetaMultiLabelMeasure(),
            metric_kwargs,
            desired_metrics,
            exact=False,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag758')" href="javascript:;">
allennlp-2.9.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 446-482
</a>
<div class="mid" id="frag758" style="display:none"><pre>
    def test_multiple_distributed_runs(self):
        predictions = [
            torch.tensor(
                [
                    [0.55, 0.25, 0.10, 0.10, 0.20],
                    [0.10, 0.60, 0.10, 0.95, 0.00],
                    [0.90, 0.80, 0.75, 0.80, 0.00],
                ]
            ),
            torch.tensor(
                [
                    [0.49, 0.50, 0.95, 0.55, 0.00],
                    [0.60, 0.49, 0.60, 0.65, 0.85],
                    [0.85, 0.40, 0.10, 0.20, 0.00],
                ]
            ),
        ]
        targets = [
            torch.tensor([[1, 1, 0, 0, 0], [0, 1, 0, 1, 0], [1, 1, 0, 1, 0]]),
            torch.tensor([[1, 1, 1, 1, 0], [1, 1, 1, 1, 0], [0, 0, 0, 0, 0]]),
        ]
        metric_kwargs = {"predictions": predictions, "gold_labels": targets}
        desired_metrics = {
            "precision": self.desired_precisions,
            "recall": self.desired_recalls,
            "fscore": self.desired_fscores,
        }
        run_distributed_test(
            [-1, -1],
            multiple_runs,
            FBetaMultiLabelMeasure(),
            metric_kwargs,
            desired_metrics,
            exact=False,
        )


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 40:</b> &nbsp; 2 fragments, nominal size 27 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag786')" href="javascript:;">
allennlp-2.9.0/tests/nn/beam_search_test.py: 154-186
</a>
<div class="mid" id="frag786" style="display:none"><pre>
    def test_finished_state(self):
        state = {}
        state["foo"] = torch.tensor([[1, 0, 1], [2, 0, 1], [0, 0, 1], [1, 1, 1], [0, 0, 0]])
        # shape: (batch_size, 3)

        expected_finished_state = {}
        expected_finished_state["foo"] = np.array(
            [
                [1, 0, 1],
                [1, 0, 1],
                [1, 0, 1],
                [2, 0, 1],
                [2, 0, 1],
                [2, 0, 1],
                [0, 0, 1],
                [0, 0, 1],
                [0, 0, 1],
                [1, 1, 1],
                [1, 1, 1],
                [1, 1, 1],
                [0, 0, 0],
                [0, 0, 0],
                [0, 0, 0],
            ]
        )
        # shape: (batch_size x beam_size, 3)

        self._check_results(state=state)

        # check finished state.
        for key, array in expected_finished_state.items():
            np.testing.assert_allclose(state[key].numpy(), array)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag787')" href="javascript:;">
allennlp-2.9.0/tests/nn/beam_search_test.py: 187-222
</a>
<div class="mid" id="frag787" style="display:none"><pre>
    def test_diff_shape_state(self):
        state = {}
        state["decoder_hidden"] = torch.tensor(
            [[1, 0, 1], [2, 0, 1], [0, 0, 1], [1, 1, 1], [0, 0, 0]]
        )
        state["decoder_hidden"] = state["decoder_hidden"].unsqueeze(0).repeat(2, 1, 1)
        # shape: (2, batch_size, 3)

        seq = [
            [1, 0, 1],
            [1, 0, 1],
            [1, 0, 1],
            [2, 0, 1],
            [2, 0, 1],
            [2, 0, 1],
            [0, 0, 1],
            [0, 0, 1],
            [0, 0, 1],
            [1, 1, 1],
            [1, 1, 1],
            [1, 1, 1],
            [0, 0, 0],
            [0, 0, 0],
            [0, 0, 0],
        ]
        seq = [seq] * 2
        expected_finished_state = {}
        expected_finished_state["decoder_hidden"] = np.array(seq)
        # shape: (2, batch_size x beam_size, 3)

        self._check_results(state=state)

        # check finished state.
        for key, array in expected_finished_state.items():
            np.testing.assert_allclose(state[key].numpy(), array)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 41:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 91%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag799')" href="javascript:;">
allennlp-2.9.0/tests/nn/beam_search_test.py: 368-388
</a>
<div class="mid" id="frag799" style="display:none"><pre>
    def test_top_p_search(self):
        initial_predictions = torch.tensor([0] * 5)
        beam_size = 3
        take_step = take_step_with_timestep
        p_sampler = TopPSampler(p=0.8)

        top_p, log_probs = BeamSearch(
            self.end_index, beam_size=beam_size, max_steps=10, sampler=p_sampler
        ).search(initial_predictions, {}, take_step)

        beam_size = beam_size or 1
        batch_size = 5

        # top_p should be shape `(batch_size, beam_size, max_predicted_length)`.
        assert list(top_p.size())[:-1] == [batch_size, beam_size]

        assert ((0 &lt;= top_p) &amp; (top_p &lt;= 5)).all()

        # log_probs should be shape `(batch_size, beam_size, max_predicted_length)`.
        assert list(log_probs.size()) == [batch_size, beam_size]

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag801')" href="javascript:;">
allennlp-2.9.0/tests/nn/beam_search_test.py: 401-421
</a>
<div class="mid" id="frag801" style="display:none"><pre>
    def test_top_k_search(self):
        initial_predictions = torch.tensor([0] * 5)
        beam_size = 3
        take_step = take_step_with_timestep
        k_sampler = TopKSampler(k=5, with_replacement=True)

        top_k, log_probs = BeamSearch(
            self.end_index, beam_size=beam_size, max_steps=10, sampler=k_sampler
        ).search(initial_predictions, {}, take_step)

        beam_size = beam_size or 1
        batch_size = 5

        # top_p should be shape `(batch_size, beam_size, max_predicted_length)`.
        assert list(top_k.size())[:-1] == [batch_size, beam_size]

        assert ((0 &lt;= top_k) &amp; (top_k &lt;= 5)).all()

        # log_probs should be shape `(batch_size, beam_size, max_predicted_length)`.
        assert list(log_probs.size()) == [batch_size, beam_size]

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 42:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 92%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag804')" href="javascript:;">
allennlp-2.9.0/tests/nn/beam_search_test.py: 465-481
</a>
<div class="mid" id="frag804" style="display:none"><pre>
    def test_params_sampling(self):
        beam_search = BeamSearch.from_params(
            Params(
                {
                    "sampler": {
                        "type": "top-k",
                        "k": 4,
                    },
                    "beam_size": 2,
                    "end_index": 7,
                }
            )
        )
        assert beam_search.beam_size == 2
        assert beam_search._end_index == 7
        assert beam_search.sampler is not None

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag805')" href="javascript:;">
allennlp-2.9.0/tests/nn/beam_search_test.py: 482-498
</a>
<div class="mid" id="frag805" style="display:none"><pre>
    def test_params_p_sampling(self):
        beam_search = BeamSearch.from_params(
            Params(
                {
                    "sampler": {
                        "type": "top-p",
                        "p": 0.8,
                    },
                    "beam_size": 2,
                    "end_index": 7,
                }
            )
        )
        assert beam_search.beam_size == 2
        assert beam_search._end_index == 7
        assert beam_search.sampler is not None

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 43:</b> &nbsp; 4 fragments, nominal size 11 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag814')" href="javascript:;">
allennlp-2.9.0/tests/nn/beam_search_test.py: 682-747
</a>
<div class="mid" id="frag814" style="display:none"><pre>
    def test_take_repeated_ngram_step(self):
        """
        Tests to ensure the top-k from the `repeated_ngram_transition_probabilities_0`
        transition matrix is expected. The transitions are:

            - p(1|start) = 1.0
            - p(2|1) = 0.4
            - p(3|1) = 0.6
            - p(end|1) = 1e-9
            - p(3|2) = 1.0
            - p(end|2) = 1e-9
            - p(1|3) = 1.0
            - p(end|3) = 1e-9

        The probabilities don't add up 1 because of the 1e-9 transitions to end. That doesn't
        really matter. Each state just needed some transition to the end probability with a very
        small probability to ensure it's possible to reach the end state from there and that it
        isn't selected by beam search without a constraint.

        Below is the beam search tracing for beam size 2. Any sequence below the
        line is not selected by beam search. The number that comes before the sequence
        is the probability of the sequence.

        Step 1
        1.0: [1]

        Step 2
        0.6: [1, 3]
        0.4: [1, 2]
        -----
        1e-9: [1, 2, end]

        Step 3
        0.6: [1, 3, 1]
        0.4: [1, 2, 3]
        -----
        0.6 * 1e-9: [1, 3, end]
        0.4 * 1e-9: [1, 2, end]

        Step 4
        0.4:  [1, 2, 3, 1]
        0.36: [1, 3, 1, 3]
        -----
        0.24:       [1, 3, 1, 2]
        0.6 * 1e-9: [1, 3, 1, end]
        0.4 * 1e-9: [1, 2, 3, end]

        Step 5
        0.36: [1, 3, 1, 3, 1]
        0.24: [1, 2, 3, 1, 3]
        -----
        0.16:        [1, 2, 3, 1, 2]
        0.4 * 1e-9:  [1, 2, 3, 1, end]
        0.36 * 1e-9: [1, 3, 1, 3, end]
        """
        step_function = get_step_function(repeated_ngram_transition_probabilities_0)
        self.beam_search.beam_size = 2
        self.beam_search.max_steps = 5
        expected_top_k = np.array([[1, 3, 1, 3, 1], [1, 2, 3, 1, 3]])
        expected_log_probs = np.log(np.array([0.36, 0.24]))
        self._check_results(
            expected_top_k=expected_top_k,
            expected_log_probs=expected_log_probs,
            take_step=step_function,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag818')" href="javascript:;">
allennlp-2.9.0/tests/nn/beam_search_test.py: 805-821
</a>
<div class="mid" id="frag818" style="display:none"><pre>
    def test_repeated_ngram_blocking_end_indices(self):
        """
        Ensures that the ngram blocking does not mess up when one sequence is shorter
        than another, which would result in repeated "end" symbols.
        """
        # We block unigrams, but 5 (the end symbol) is repeated and it does not mess
        # up the sequence's probability
        step_function = get_step_function(repeated_ngram_transition_probabilities_0)
        self.beam_search.beam_size = 2
        self.beam_search.constraints = [RepeatedNGramBlockingConstraint(ngram_size=1)]
        expected_top_k = np.array([[1, 3, 5, 5], [1, 2, 3, 5]])
        expected_log_probs = np.log(np.array([0.6 * 1e-9, 0.4 * 1e-9]))
        self._check_results(
            expected_top_k=expected_top_k,
            expected_log_probs=expected_log_probs,
            take_step=step_function,
        )
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag817')" href="javascript:;">
allennlp-2.9.0/tests/nn/beam_search_test.py: 790-804
</a>
<div class="mid" id="frag817" style="display:none"><pre>
    def test_repeated_ngram_blocking_end_to_end_trigrams(self):
        step_function = get_step_function(repeated_ngram_transition_probabilities_0)
        self.beam_search.beam_size = 2

        # Trigrams: On step 5, [1, 3, 1, 3, 1] will be blocked and [1, 2, 3, 1, 2] will take its place
        self.beam_search.max_steps = 5
        self.beam_search.constraints = [RepeatedNGramBlockingConstraint(ngram_size=3)]
        expected_top_k = np.array([[1, 2, 3, 1, 3], [1, 2, 3, 1, 2]])
        expected_log_probs = np.log(np.array([0.24, 0.16]))
        self._check_results(
            expected_top_k=expected_top_k,
            expected_log_probs=expected_log_probs,
            take_step=step_function,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag816')" href="javascript:;">
allennlp-2.9.0/tests/nn/beam_search_test.py: 775-789
</a>
<div class="mid" id="frag816" style="display:none"><pre>
    def test_repeated_ngram_blocking_end_to_end_bigrams(self):
        step_function = get_step_function(repeated_ngram_transition_probabilities_0)
        self.beam_search.beam_size = 2

        # Bigrams: On step 4, [1, 3, 1, 3] will be blocked and [1, 3, 1, 2] will take its place
        self.beam_search.max_steps = 4
        self.beam_search.constraints = [RepeatedNGramBlockingConstraint(ngram_size=2)]
        expected_top_k = np.array([[1, 2, 3, 1], [1, 3, 1, 2]])
        expected_log_probs = np.log(np.array([0.4, 0.24]))
        self._check_results(
            expected_top_k=expected_top_k,
            expected_log_probs=expected_log_probs,
            take_step=step_function,
        )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 44:</b> &nbsp; 2 fragments, nominal size 16 lines, similarity 87%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag835')" href="javascript:;">
allennlp-2.9.0/tests/models/archival_test.py: 53-72
</a>
<div class="mid" id="frag835" style="display:none"><pre>
    def setup_method(self):
        super().setup_method()

        self.params = Params(
            {
                "model": {
                    "type": "simple_tagger",
                    "text_field_embedder": {
                        "token_embedders": {"tokens": {"type": "embedding", "embedding_dim": 5}}
                    },
                    "encoder": {"type": "lstm", "input_size": 5, "hidden_size": 7, "num_layers": 2},
                },
                "dataset_reader": {"type": "sequence_tagging"},
                "train_data_path": str(self.FIXTURES_ROOT / "data" / "sequence_tagging.tsv"),
                "validation_data_path": str(self.FIXTURES_ROOT / "data" / "sequence_tagging.tsv"),
                "data_loader": {"batch_size": 2},
                "trainer": {"num_epochs": 2, "optimizer": "adam", "cuda_device": -1},
            }
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1337')" href="javascript:;">
allennlp-2.9.0/tests/commands/find_learning_rate_test.py: 30-48
</a>
<div class="mid" id="frag1337" style="display:none"><pre>
    def setup_method(self):
        super().setup_method()
        self.params = lambda: Params(
            {
                "model": {
                    "type": "simple_tagger",
                    "text_field_embedder": {
                        "token_embedders": {"tokens": {"type": "embedding", "embedding_dim": 5}}
                    },
                    "encoder": {"type": "lstm", "input_size": 5, "hidden_size": 7, "num_layers": 2},
                },
                "dataset_reader": {"type": "sequence_tagging"},
                "train_data_path": str(self.FIXTURES_ROOT / "data" / "sequence_tagging.tsv"),
                "validation_data_path": str(self.FIXTURES_ROOT / "data" / "sequence_tagging.tsv"),
                "data_loader": {"batch_size": 2},
                "trainer": {"cuda_device": -1, "num_epochs": 2, "optimizer": "adam"},
            }
        )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 45:</b> &nbsp; 4 fragments, nominal size 56 lines, similarity 89%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag869')" href="javascript:;">
allennlp-2.9.0/tests/data/token_indexers/elmo_indexer_test.py: 12-68
</a>
<div class="mid" id="frag869" style="display:none"><pre>
    def test_bos_to_char_ids(self):
        indexer = ELMoTokenCharactersIndexer()
        indices = indexer.tokens_to_indices([Token("&lt;S&gt;")], Vocabulary())
        expected_indices = [
            259,
            257,
            260,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
        ]
        assert indices == {"elmo_tokens": [expected_indices]}

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag870')" href="javascript:;">
allennlp-2.9.0/tests/data/token_indexers/elmo_indexer_test.py: 69-125
</a>
<div class="mid" id="frag870" style="display:none"><pre>
    def test_eos_to_char_ids(self):
        indexer = ELMoTokenCharactersIndexer()
        indices = indexer.tokens_to_indices([Token("&lt;/S&gt;")], Vocabulary())
        expected_indices = [
            259,
            258,
            260,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
        ]
        assert indices == {"elmo_tokens": [expected_indices]}

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag873')" href="javascript:;">
allennlp-2.9.0/tests/data/token_indexers/elmo_indexer_test.py: 349-408
</a>
<div class="mid" id="frag873" style="display:none"><pre>
    def test_elmo_indexer_with_additional_tokens(self):
        indexer = ELMoTokenCharactersIndexer(tokens_to_add={"&lt;first&gt;": 1})
        tokens = [Token("&lt;first&gt;")]
        indices = indexer.tokens_to_indices(tokens, Vocabulary())
        expected_indices = [
            [
                259,
                2,
                260,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
            ]
        ]
        assert indices["elmo_tokens"] == expected_indices

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag871')" href="javascript:;">
allennlp-2.9.0/tests/data/token_indexers/elmo_indexer_test.py: 126-182
</a>
<div class="mid" id="frag871" style="display:none"><pre>
    def test_unicode_to_char_ids(self):
        indexer = ELMoTokenCharactersIndexer()
        indices = indexer.tokens_to_indices([Token(chr(256) + "t")], Vocabulary())
        expected_indices = [
            259,
            197,
            129,
            117,
            260,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
        ]
        assert indices == {"elmo_tokens": [expected_indices]}

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 46:</b> &nbsp; 15 fragments, nominal size 19 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag882')" href="javascript:;">
allennlp-2.9.0/tests/data/tokenizers/pretrained_transformer_tokenizer_test.py: 10-28
</a>
<div class="mid" id="frag882" style="display:none"><pre>
    def test_splits_roberta(self):
        tokenizer = PretrainedTransformerTokenizer("roberta-base")

        sentence = "A, &lt;mask&gt; AllenNLP sentence."
        expected_tokens = [
            "&lt;s&gt;",
            "A",
            ",",
            "&lt;mask&gt;",
            "Allen",
            "N",
            "LP",
            "sentence",
            ".",
            "&lt;/s&gt;",
        ]
        tokens = [t.text for t in tokenizer.tokenize(sentence)]
        assert tokens == expected_tokens

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag883')" href="javascript:;">
allennlp-2.9.0/tests/data/tokenizers/pretrained_transformer_tokenizer_test.py: 29-47
</a>
<div class="mid" id="frag883" style="display:none"><pre>
    def test_splits_cased_bert(self):
        tokenizer = PretrainedTransformerTokenizer("bert-base-cased")

        sentence = "A, [MASK] AllenNLP sentence."
        expected_tokens = [
            "[CLS]",
            "A",
            ",",
            "[MASK]",
            "Allen",
            "##NL",
            "##P",
            "sentence",
            ".",
            "[SEP]",
        ]
        tokens = [t.text for t in tokenizer.tokenize(sentence)]
        assert tokens == expected_tokens

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag902')" href="javascript:;">
allennlp-2.9.0/tests/data/tokenizers/spacy_tokenizer_test.py: 37-54
</a>
<div class="mid" id="frag902" style="display:none"><pre>
    def test_tokenize_handles_contraction(self):
        # note that "would've" is kept together, while "ain't" is not.
        sentence = "it ain't joe's problem; would been yesterday"
        expected_tokens = [
            "it",
            "ai",
            "n't",
            "joe",
            "'s",
            "problem",
            ";",
            "would",
            "been",
            "yesterday",
        ]
        tokens = [t.text for t in self.word_tokenizer.tokenize(sentence)]
        assert tokens == expected_tokens

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag884')" href="javascript:;">
allennlp-2.9.0/tests/data/tokenizers/pretrained_transformer_tokenizer_test.py: 48-65
</a>
<div class="mid" id="frag884" style="display:none"><pre>
    def test_splits_uncased_bert(self):
        sentence = "A, [MASK] AllenNLP sentence."
        expected_tokens = [
            "[CLS]",
            "a",
            ",",
            "[MASK]",
            "allen",
            "##nl",
            "##p",
            "sentence",
            ".",
            "[SEP]",
        ]
        tokenizer = PretrainedTransformerTokenizer("bert-base-uncased")
        tokens = [t.text for t in tokenizer.tokenize(sentence)]
        assert tokens == expected_tokens

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag921')" href="javascript:;">
allennlp-2.9.0/tests/data/tokenizers/letters_digits_tokenizer_test.py: 10-28
</a>
<div class="mid" id="frag921" style="display:none"><pre>
    def test_tokenize_handles_complex_punctuation(self):
        sentence = "this (sentence) has 'crazy' \"punctuation\"."
        expected_tokens = [
            "this",
            "(",
            "sentence",
            ")",
            "has",
            "'",
            "crazy",
            "'",
            '"',
            "punctuation",
            '"',
            ".",
        ]
        tokens = [t.text for t in self.word_tokenizer.tokenize(sentence)]
        assert tokens == expected_tokens

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag906')" href="javascript:;">
allennlp-2.9.0/tests/data/tokenizers/spacy_tokenizer_test.py: 73-95
</a>
<div class="mid" id="frag906" style="display:none"><pre>
    def test_tokenize_handles_special_cases(self):
        # note that the etc. doesn't quite work --- we can special case this if we want.
        sentence = "Mr. and Mrs. Jones, etc., went to, e.g., the store"
        expected_tokens = [
            "Mr.",
            "and",
            "Mrs.",
            "Jones",
            ",",
            "etc",
            ".",
            ",",
            "went",
            "to",
            ",",
            "e.g.",
            ",",
            "the",
            "store",
        ]
        tokens = [t.text for t in self.word_tokenizer.tokenize(sentence)]
        assert tokens == expected_tokens

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag897')" href="javascript:;">
allennlp-2.9.0/tests/data/tokenizers/pretrained_transformer_tokenizer_test.py: 308-325
</a>
<div class="mid" id="frag897" style="display:none"><pre>
    def test_tokenizer_kwargs_default(self):
        text = "Hello there! General Kenobi."
        tokenizer = PretrainedTransformerTokenizer("bert-base-cased")
        original_tokens = [
            "[CLS]",
            "Hello",
            "there",
            "!",
            "General",
            "Ken",
            "##ob",
            "##i",
            ".",
            "[SEP]",
        ]
        tokenized = [token.text for token in tokenizer.tokenize(text)]
        assert tokenized == original_tokens

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag893')" href="javascript:;">
allennlp-2.9.0/tests/data/tokenizers/pretrained_transformer_tokenizer_test.py: 245-266
</a>
<div class="mid" id="frag893" style="display:none"><pre>
    def test_intra_word_tokenize_whitespaces(self):
        tokenizer = PretrainedTransformerTokenizer("bert-base-cased")

        sentence = ["A,", " ", "[MASK]", "AllenNLP", "\u007f", "sentence."]
        expected_tokens = [
            "[CLS]",
            "A",
            ",",
            "[MASK]",
            "Allen",
            "##NL",
            "##P",
            "sentence",
            ".",
            "[SEP]",
        ]
        expected_offsets = [(1, 2), None, (3, 3), (4, 6), None, (7, 8)]
        tokens, offsets = tokenizer.intra_word_tokenize(sentence)
        tokens = [t.text for t in tokens]
        assert tokens == expected_tokens
        assert offsets == expected_offsets

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag923')" href="javascript:;">
allennlp-2.9.0/tests/data/tokenizers/letters_digits_tokenizer_test.py: 41-62
</a>
<div class="mid" id="frag923" style="display:none"><pre>
    def test_tokenize_handles_splits_all_punctuation(self):
        sentence = "wouldn't.[have] -3.45(m^2)"
        expected_tokens = [
            "wouldn",
            "'",
            "t",
            ".",
            "[",
            "have",
            "]",
            "-",
            "3",
            ".",
            "45",
            "(",
            "m",
            "^",
            "2",
            ")",
        ]
        tokens = [t.text for t in self.word_tokenizer.tokenize(sentence)]
        assert tokens == expected_tokens
</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag886')" href="javascript:;">
allennlp-2.9.0/tests/data/tokenizers/pretrained_transformer_tokenizer_test.py: 94-116
</a>
<div class="mid" id="frag886" style="display:none"><pre>
    def test_token_idx_bert_uncased(self):
        sentence = "A, nave [MASK] AllenNLP sentence."
        expected_tokens = [
            "[CLS]",
            "a",
            ",",
            "naive",  # BERT normalizes this away
            "[MASK]",
            "allen",
            "##nl",
            "##p",
            "sentence",
            ".",
            "[SEP]",
        ]
        expected_idxs = [None, 0, 1, 3, 9, 16, 21, 23, 25, 33, None]
        tokenizer = PretrainedTransformerTokenizer("bert-base-uncased")
        tokenized = tokenizer.tokenize(sentence)
        tokens = [t.text for t in tokenized]
        assert tokens == expected_tokens
        idxs = [t.idx for t in tokenized]
        assert idxs == expected_idxs

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag890')" href="javascript:;">
allennlp-2.9.0/tests/data/tokenizers/pretrained_transformer_tokenizer_test.py: 160-182
</a>
<div class="mid" id="frag890" style="display:none"><pre>
    def test_token_idx_roberta(self):
        sentence = "A, nave &lt;mask&gt; AllenNLP sentence."
        expected_tokens = [
            "&lt;s&gt;",
            "A",
            ",",
            "nave",  # RoBERTa mangles this. Or maybe it "encodes"?
            "&lt;mask&gt;",
            "Allen",
            "N",
            "LP",
            "sentence",
            ".",
            "&lt;/s&gt;",
        ]
        expected_idxs = [None, 0, 1, 3, 9, 16, 21, 22, 25, 33, None]
        tokenizer = PretrainedTransformerTokenizer("roberta-base")
        tokenized = tokenizer.tokenize(sentence)
        tokens = [t.text for t in tokenized]
        assert tokens == expected_tokens
        idxs = [t.idx for t in tokenized]
        assert idxs == expected_idxs

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag901')" href="javascript:;">
allennlp-2.9.0/tests/data/tokenizers/spacy_tokenizer_test.py: 13-36
</a>
<div class="mid" id="frag901" style="display:none"><pre>
    def test_tokenize_handles_complex_punctuation(self):
        sentence = "this (sentence) has 'crazy' \"punctuation\"."
        expected_tokens = [
            "this",
            "(",
            "sentence",
            ")",
            "has",
            "'",
            "crazy",
            "'",
            '"',
            "punctuation",
            '"',
            ".",
        ]
        tokens = self.word_tokenizer.tokenize(sentence)
        token_text = [t.text for t in tokens]
        assert token_text == expected_tokens
        for token in tokens:
            start = token.idx
            end = start + len(token.text)
            assert sentence[start:end] == token.text

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag887')" href="javascript:;">
allennlp-2.9.0/tests/data/tokenizers/pretrained_transformer_tokenizer_test.py: 117-141
</a>
<div class="mid" id="frag887" style="display:none"><pre>
    def test_token_idx_bert_cased(self):
        sentence = "A, nave [MASK] AllenNLP sentence."
        expected_tokens = [
            "[CLS]",
            "A",
            ",",
            "na",
            "##",
            "##ve",
            "[MASK]",
            "Allen",
            "##NL",
            "##P",
            "sentence",
            ".",
            "[SEP]",
        ]
        expected_idxs = [None, 0, 1, 3, 5, 6, 9, 16, 21, 23, 25, 33, None]
        tokenizer = PretrainedTransformerTokenizer("bert-base-cased")
        tokenized = tokenizer.tokenize(sentence)
        tokens = [t.text for t in tokenized]
        assert tokens == expected_tokens
        idxs = [t.idx for t in tokenized]
        assert idxs == expected_idxs

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag885')" href="javascript:;">
allennlp-2.9.0/tests/data/tokenizers/pretrained_transformer_tokenizer_test.py: 66-93
</a>
<div class="mid" id="frag885" style="display:none"><pre>
    def test_splits_reformer_small(self):
        sentence = "A, [MASK] AllenNLP sentence."
        expected_tokens = [
            "A",
            ",",
            "",
            "&lt;unk&gt;",
            "M",
            "A",
            "S",
            "K",
            "&lt;unk&gt;",
            "A",
            "ll",
            "en",
            "N",
            "L",
            "P",
            "s",
            "ent",
            "en",
            "ce",
            ".",
        ]
        tokenizer = PretrainedTransformerTokenizer("google/reformer-crime-and-punishment")
        tokens = [t.text for t in tokenizer.tokenize(sentence)]
        assert tokens == expected_tokens

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag916')" href="javascript:;">
allennlp-2.9.0/tests/data/tokenizers/character_tokenizer_test.py: 7-36
</a>
<div class="mid" id="frag916" style="display:none"><pre>
    def test_splits_into_characters(self):
        tokenizer = CharacterTokenizer(start_tokens=["&lt;S1&gt;", "&lt;S2&gt;"], end_tokens=["&lt;/S2&gt;", "&lt;/S1&gt;"])
        sentence = "A, small sentence."
        tokens = [t.text for t in tokenizer.tokenize(sentence)]
        expected_tokens = [
            "&lt;S1&gt;",
            "&lt;S2&gt;",
            "A",
            ",",
            " ",
            "s",
            "m",
            "a",
            "l",
            "l",
            " ",
            "s",
            "e",
            "n",
            "t",
            "e",
            "n",
            "c",
            "e",
            ".",
            "&lt;/S2&gt;",
            "&lt;/S1&gt;",
        ]
        assert tokens == expected_tokens

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 47:</b> &nbsp; 4 fragments, nominal size 13 lines, similarity 78%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag907')" href="javascript:;">
allennlp-2.9.0/tests/data/tokenizers/spacy_tokenizer_test.py: 96-109
</a>
<div class="mid" id="frag907" style="display:none"><pre>
    def test_batch_tokenization(self):
        sentences = [
            "This is     a sentence",
            "This isn't a sentence.",
            "This is the 3rd     sentence." "Here's the 'fourth' sentence.",
        ]
        batch_split = self.word_tokenizer.batch_tokenize(sentences)
        separately_split = [self.word_tokenizer.tokenize(sentence) for sentence in sentences]
        assert len(batch_split) == len(separately_split)
        for batch_sentence, separate_sentence in zip(batch_split, separately_split):
            assert len(batch_sentence) == len(separate_sentence)
            for batch_word, separate_word in zip(batch_sentence, separate_sentence):
                assert batch_word.text == separate_word.text

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag914')" href="javascript:;">
allennlp-2.9.0/tests/data/tokenizers/sentence_splitter_test.py: 37-49
</a>
<div class="mid" id="frag914" style="display:none"><pre>
    def test_batch_dep_parse_sentence_splitting(self):
        text = [
            "This is a sentence. This is a second sentence.",
            "This isn't a sentence. This is a second sentence! This is a third sentence.",
        ]
        batch_split = self.dep_parse_splitter.batch_split_sentences(text)
        separately_split = [self.dep_parse_splitter.split_sentences(doc) for doc in text]
        assert len(batch_split) == len(separately_split)
        for batch_doc, separate_doc in zip(batch_split, separately_split):
            assert len(batch_doc) == len(separate_doc)
            for batch_sentence, separate_sentence in zip(batch_doc, separate_doc):
                assert batch_sentence == separate_sentence

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag917')" href="javascript:;">
allennlp-2.9.0/tests/data/tokenizers/character_tokenizer_test.py: 37-51
</a>
<div class="mid" id="frag917" style="display:none"><pre>
    def test_batch_tokenization(self):
        tokenizer = CharacterTokenizer()
        sentences = [
            "This is a sentence",
            "This isn't a sentence.",
            "This is the 3rd sentence." "Here's the 'fourth' sentence.",
        ]
        batch_tokenized = tokenizer.batch_tokenize(sentences)
        separately_tokenized = [tokenizer.tokenize(sentence) for sentence in sentences]
        assert len(batch_tokenized) == len(separately_tokenized)
        for batch_sentence, separate_sentence in zip(batch_tokenized, separately_tokenized):
            assert len(batch_sentence) == len(separate_sentence)
            for batch_word, separate_word in zip(batch_sentence, separate_sentence):
                assert batch_word.text == separate_word.text

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag913')" href="javascript:;">
allennlp-2.9.0/tests/data/tokenizers/sentence_splitter_test.py: 24-36
</a>
<div class="mid" id="frag913" style="display:none"><pre>
    def test_batch_rule_based_sentence_splitting(self):
        text = [
            "This is a sentence. This is a second sentence.",
            "This isn't a sentence. This is a second sentence! This is a third sentence.",
        ]
        batch_split = self.rule_based_splitter.batch_split_sentences(text)
        separately_split = [self.rule_based_splitter.split_sentences(doc) for doc in text]
        assert len(batch_split) == len(separately_split)
        for batch_doc, separate_doc in zip(batch_split, separately_split):
            assert len(batch_doc) == len(separate_doc)
            for batch_sentence, separate_sentence in zip(batch_doc, separate_doc):
                assert batch_sentence == separate_sentence

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 48:</b> &nbsp; 2 fragments, nominal size 17 lines, similarity 82%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag924')" href="javascript:;">
allennlp-2.9.0/tests/data/dataset_readers/sequence_tagging_test.py: 6-25
</a>
<div class="mid" id="frag924" style="display:none"><pre>
    def test_default_format(self):
        reader = SequenceTaggingDatasetReader(max_instances=4)
        instances = list(
            reader.read(AllenNlpTestCase.FIXTURES_ROOT / "data" / "sequence_tagging.tsv")
        )

        assert len(instances) == 4
        fields = instances[0].fields
        assert [t.text for t in fields["tokens"].tokens] == ["cats", "are", "animals", "."]
        assert fields["tags"].labels == ["N", "V", "N", "N"]
        fields = instances[1].fields
        assert [t.text for t in fields["tokens"].tokens] == ["dogs", "are", "animals", "."]
        assert fields["tags"].labels == ["N", "V", "N", "N"]
        fields = instances[2].fields
        assert [t.text for t in fields["tokens"].tokens] == ["snakes", "are", "animals", "."]
        assert fields["tags"].labels == ["N", "V", "N", "N"]
        fields = instances[3].fields
        assert [t.text for t in fields["tokens"].tokens] == ["birds", "are", "animals", "."]
        assert fields["tags"].labels == ["N", "V", "N", "N"]

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag925')" href="javascript:;">
allennlp-2.9.0/tests/data/dataset_readers/sequence_tagging_test.py: 26-42
</a>
<div class="mid" id="frag925" style="display:none"><pre>
    def test_brown_corpus_format(self):
        reader = SequenceTaggingDatasetReader(word_tag_delimiter="/")
        instances = list(reader.read(AllenNlpTestCase.FIXTURES_ROOT / "data" / "brown_corpus.txt"))

        assert len(instances) == 4
        fields = instances[0].fields
        assert [t.text for t in fields["tokens"].tokens] == ["cats", "are", "animals", "."]
        assert fields["tags"].labels == ["N", "V", "N", "N"]
        fields = instances[1].fields
        assert [t.text for t in fields["tokens"].tokens] == ["dogs", "are", "animals", "."]
        assert fields["tags"].labels == ["N", "V", "N", "N"]
        fields = instances[2].fields
        assert [t.text for t in fields["tokens"].tokens] == ["snakes", "are", "animals", "."]
        assert fields["tags"].labels == ["N", "V", "N", "N"]
        fields = instances[3].fields
        assert [t.text for t in fields["tokens"].tokens] == ["birds", "are", "animals", "."]
        assert fields["tags"].labels == ["N", "V", "N", "N"]
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 49:</b> &nbsp; 2 fragments, nominal size 16 lines, similarity 93%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag934')" href="javascript:;">
allennlp-2.9.0/tests/data/dataset_readers/conll2003_test.py: 12-32
</a>
<div class="mid" id="frag934" style="display:none"><pre>
    def test_read_from_file_with_deprecated_parameter(self, coding_scheme):
        conll_reader = Conll2003DatasetReader(coding_scheme=coding_scheme)
        instances = ensure_list(
            conll_reader.read(AllenNlpTestCase.FIXTURES_ROOT / "data" / "conll2003.txt")
        )

        if coding_scheme == "IOB1":
            expected_labels = ["I-ORG", "O", "I-PER", "O", "O", "I-LOC", "O"]
        else:
            expected_labels = ["U-ORG", "O", "U-PER", "O", "O", "U-LOC", "O"]

        fields = instances[0].fields
        tokens = [t.text for t in fields["tokens"].tokens]
        assert tokens == ["U.N.", "official", "Ekeus", "heads", "for", "Baghdad", "."]
        assert fields["tags"].labels == expected_labels

        fields = instances[1].fields
        tokens = [t.text for t in fields["tokens"].tokens]
        assert tokens == ["AI2", "engineer", "Joel", "lives", "in", "Seattle", "."]
        assert fields["tags"].labels == expected_labels

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag935')" href="javascript:;">
allennlp-2.9.0/tests/data/dataset_readers/conll2003_test.py: 34-54
</a>
<div class="mid" id="frag935" style="display:none"><pre>
    def test_read_from_file(self, convert_to_coding_scheme):
        conll_reader = Conll2003DatasetReader(convert_to_coding_scheme=convert_to_coding_scheme)
        instances = ensure_list(
            conll_reader.read(AllenNlpTestCase.FIXTURES_ROOT / "data" / "conll2003.txt")
        )

        if convert_to_coding_scheme is None:
            expected_labels = ["I-ORG", "O", "I-PER", "O", "O", "I-LOC", "O"]
        else:
            expected_labels = ["U-ORG", "O", "U-PER", "O", "O", "U-LOC", "O"]

        fields = instances[0].fields
        tokens = [t.text for t in fields["tokens"].tokens]
        assert tokens == ["U.N.", "official", "Ekeus", "heads", "for", "Baghdad", "."]
        assert fields["tags"].labels == expected_labels

        fields = instances[1].fields
        tokens = [t.text for t in fields["tokens"].tokens]
        assert tokens == ["AI2", "engineer", "Joel", "lives", "in", "Seattle", "."]
        assert fields["tags"].labels == expected_labels

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 50:</b> &nbsp; 2 fragments, nominal size 40 lines, similarity 73%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag957')" href="javascript:;">
allennlp-2.9.0/tests/data/fields/list_field_test.py: 174-228
</a>
<div class="mid" id="frag957" style="display:none"><pre>
    def test_as_tensor_can_handle_multiple_token_indexers(self):

        self.field1._token_indexers = self.words_and_characters_indexers
        self.field2._token_indexers = self.words_and_characters_indexers
        self.field3._token_indexers = self.words_and_characters_indexers

        list_field = ListField([self.field1, self.field2, self.field3])
        list_field.index(self.vocab)
        padding_lengths = list_field.get_padding_lengths()
        tensor_dict = list_field.as_tensor(padding_lengths)
        words = tensor_dict["words"]["tokens"].detach().cpu().numpy()
        characters = tensor_dict["characters"]["token_characters"].detach().cpu().numpy()
        numpy.testing.assert_array_almost_equal(
            words, numpy.array([[2, 3, 4, 5, 0], [2, 3, 4, 1, 5], [2, 3, 1, 5, 0]])
        )

        numpy.testing.assert_array_almost_equal(
            characters[0],
            numpy.array(
                [
                    [5, 1, 1, 2, 0, 0, 0, 0, 0],
                    [1, 2, 0, 0, 0, 0, 0, 0, 0],
                    [1, 0, 0, 0, 0, 0, 0, 0, 0],
                    [2, 3, 4, 5, 3, 4, 6, 3, 0],
                    [0, 0, 0, 0, 0, 0, 0, 0, 0],
                ]
            ),
        )

        numpy.testing.assert_array_almost_equal(
            characters[1],
            numpy.array(
                [
                    [5, 1, 1, 2, 0, 0, 0, 0, 0],
                    [1, 2, 0, 0, 0, 0, 0, 0, 0],
                    [1, 0, 0, 0, 0, 0, 0, 0, 0],
                    [1, 1, 1, 1, 3, 1, 3, 4, 5],
                    [2, 3, 4, 5, 3, 4, 6, 3, 0],
                ]
            ),
        )

        numpy.testing.assert_array_almost_equal(
            characters[2],
            numpy.array(
                [
                    [5, 1, 1, 2, 0, 0, 0, 0, 0],
                    [1, 2, 0, 0, 0, 0, 0, 0, 0],
                    [1, 4, 1, 5, 1, 3, 1, 0, 0],
                    [2, 3, 4, 5, 3, 4, 6, 3, 0],
                    [0, 0, 0, 0, 0, 0, 0, 0, 0],
                ]
            ),
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag958')" href="javascript:;">
allennlp-2.9.0/tests/data/fields/list_field_test.py: 229-273
</a>
<div class="mid" id="frag958" style="display:none"><pre>
    def test_as_tensor_can_handle_multiple_token_indexers_and_empty_fields(self):

        self.field1._token_indexers = self.words_and_characters_indexers
        self.field2._token_indexers = self.words_and_characters_indexers
        self.field3._token_indexers = self.words_and_characters_indexers

        list_field = ListField([self.field1.empty_field(), self.field1, self.field2])
        list_field.index(self.vocab)
        padding_lengths = list_field.get_padding_lengths()
        tensor_dict = list_field.as_tensor(padding_lengths)
        words = tensor_dict["words"]["tokens"].detach().cpu().numpy()
        characters = tensor_dict["characters"]["token_characters"].detach().cpu().numpy()

        numpy.testing.assert_array_almost_equal(
            words, numpy.array([[0, 0, 0, 0, 0], [2, 3, 4, 5, 0], [2, 3, 4, 1, 5]])
        )

        numpy.testing.assert_array_almost_equal(characters[0], numpy.zeros([5, 9]))

        numpy.testing.assert_array_almost_equal(
            characters[1],
            numpy.array(
                [
                    [5, 1, 1, 2, 0, 0, 0, 0, 0],
                    [1, 2, 0, 0, 0, 0, 0, 0, 0],
                    [1, 0, 0, 0, 0, 0, 0, 0, 0],
                    [2, 3, 4, 5, 3, 4, 6, 3, 0],
                    [0, 0, 0, 0, 0, 0, 0, 0, 0],
                ]
            ),
        )

        numpy.testing.assert_array_almost_equal(
            characters[2],
            numpy.array(
                [
                    [5, 1, 1, 2, 0, 0, 0, 0, 0],
                    [1, 2, 0, 0, 0, 0, 0, 0, 0],
                    [1, 0, 0, 0, 0, 0, 0, 0, 0],
                    [1, 1, 1, 1, 3, 1, 3, 4, 5],
                    [2, 3, 4, 5, 3, 4, 6, 3, 0],
                ]
            ),
        )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 51:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1011')" href="javascript:;">
allennlp-2.9.0/tests/data/samplers/max_tokens_batch_sampler_test.py: 10-25
</a>
<div class="mid" id="frag1011" style="display:none"><pre>
    def test_create_batches_groups_correctly(self):
        sampler = MaxTokensBatchSampler(max_tokens=8, padding_noise=0, sorting_keys=["text"])

        grouped_instances = []
        for indices in sampler.get_batch_indices(self.instances):
            grouped_instances.append([self.instances[idx] for idx in indices])
        expected_groups = [
            [self.instances[4], self.instances[2]],
            [self.instances[0], self.instances[1]],
            [self.instances[3]],
        ]
        for group in grouped_instances:
            assert group in expected_groups
            expected_groups.remove(group)
        assert expected_groups == []

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1024')" href="javascript:;">
allennlp-2.9.0/tests/data/samplers/bucket_batch_sampler_test.py: 11-26
</a>
<div class="mid" id="frag1024" style="display:none"><pre>
    def test_create_batches_groups_correctly(self):
        sampler = BucketBatchSampler(batch_size=2, padding_noise=0, sorting_keys=["text"])

        grouped_instances = []
        for indices in sampler.get_batch_indices(self.instances):
            grouped_instances.append([self.instances[idx] for idx in indices])
        expected_groups = [
            [self.instances[4], self.instances[2]],
            [self.instances[0], self.instances[1]],
            [self.instances[3]],
        ]
        for group in grouped_instances:
            assert group in expected_groups
            expected_groups.remove(group)
        assert expected_groups == []

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 52:</b> &nbsp; 2 fragments, nominal size 26 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1012')" href="javascript:;">
allennlp-2.9.0/tests/data/samplers/max_tokens_batch_sampler_test.py: 26-58
</a>
<div class="mid" id="frag1012" style="display:none"><pre>
    def test_guess_sorting_key_picks_the_longest_key(self):
        sampler = MaxTokensBatchSampler(max_tokens=8, padding_noise=0)
        instances = []
        short_tokens = [Token(t) for t in ["what", "is", "this", "?"]]
        long_tokens = [Token(t) for t in ["this", "is", "a", "not", "very", "long", "passage"]]
        instances.append(
            Instance(
                {
                    "question": TextField(short_tokens, self.token_indexers),
                    "passage": TextField(long_tokens, self.token_indexers),
                }
            )
        )
        instances.append(
            Instance(
                {
                    "question": TextField(short_tokens, self.token_indexers),
                    "passage": TextField(long_tokens, self.token_indexers),
                }
            )
        )
        instances.append(
            Instance(
                {
                    "question": TextField(short_tokens, self.token_indexers),
                    "passage": TextField(long_tokens, self.token_indexers),
                }
            )
        )
        assert sampler.sorting_keys is None
        sampler._guess_sorting_keys(instances)
        assert sampler.sorting_keys == ["passage"]

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1026')" href="javascript:;">
allennlp-2.9.0/tests/data/samplers/bucket_batch_sampler_test.py: 41-73
</a>
<div class="mid" id="frag1026" style="display:none"><pre>
    def test_guess_sorting_key_picks_the_longest_key(self):
        sampler = BucketBatchSampler(batch_size=2, padding_noise=0)
        instances = []
        short_tokens = [Token(t) for t in ["what", "is", "this", "?"]]
        long_tokens = [Token(t) for t in ["this", "is", "a", "not", "very", "long", "passage"]]
        instances.append(
            Instance(
                {
                    "question": TextField(short_tokens, self.token_indexers),
                    "passage": TextField(long_tokens, self.token_indexers),
                }
            )
        )
        instances.append(
            Instance(
                {
                    "question": TextField(short_tokens, self.token_indexers),
                    "passage": TextField(long_tokens, self.token_indexers),
                }
            )
        )
        instances.append(
            Instance(
                {
                    "question": TextField(short_tokens, self.token_indexers),
                    "passage": TextField(long_tokens, self.token_indexers),
                }
            )
        )
        assert sampler.sorting_keys is None
        sampler._guess_sorting_keys(instances)
        assert sampler.sorting_keys == ["passage"]

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 53:</b> &nbsp; 2 fragments, nominal size 25 lines, similarity 88%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1034')" href="javascript:;">
allennlp-2.9.0/tests/data/data_loaders/multitask_data_loader_test.py: 30-55
</a>
<div class="mid" id="frag1034" style="display:none"><pre>
    def test_loading(self):
        reader = MultiTaskDatasetReader(
            readers={"a": FakeDatasetReaderA(), "b": FakeDatasetReaderB()}
        )
        data_path = {"a": "ignored", "b": "ignored"}
        scheduler = RoundRobinScheduler(batch_size=4)
        sampler = UniformSampler()
        loader = MultiTaskDataLoader(
            reader=reader,
            data_path=data_path,
            scheduler=scheduler,
            sampler=sampler,
            instances_per_epoch=8,
            max_instances_in_memory={"a": 10, "b": 10},
        )
        vocab = Vocabulary()
        vocab.add_tokens_to_namespace(["A", "B"], "labels")
        loader.index_with(vocab)
        iterator = iter(loader)
        batch = next(iterator)
        assert torch.all(batch["label"] == torch.IntTensor([0, 1, 0, 1]))
        batch = next(iterator)
        assert torch.all(batch["label"] == torch.IntTensor([0, 1, 0, 1]))
        with pytest.raises(StopIteration):
            next(iterator)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1035')" href="javascript:;">
allennlp-2.9.0/tests/data/data_loaders/multitask_data_loader_test.py: 56-81
</a>
<div class="mid" id="frag1035" style="display:none"><pre>
    def test_loading_with_sampler(self):
        reader = MultiTaskDatasetReader(
            readers={"a": FakeDatasetReaderA(), "b": FakeDatasetReaderB()}
        )
        data_path = {"a": "ignored", "b": "ignored"}
        scheduler = RoundRobinScheduler(batch_size=4)
        sampler = WeightedSampler({"a": 1, "b": 2})
        loader = MultiTaskDataLoader(
            reader=reader,
            data_path=data_path,
            scheduler=scheduler,
            sampler=sampler,
            instances_per_epoch=9,
        )
        vocab = Vocabulary()
        vocab.add_tokens_to_namespace(["A", "B"], "labels")
        loader.index_with(vocab)
        iterator = iter(loader)
        batch = next(iterator)
        assert torch.all(batch["label"] == torch.IntTensor([0, 1, 0, 1]))
        batch = next(iterator)
        assert torch.all(batch["label"] == torch.IntTensor([0, 1, 1, 1]))
        batch = next(iterator)
        assert torch.all(batch["label"] == torch.IntTensor([1]))
        with pytest.raises(StopIteration):
            next(iterator)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 54:</b> &nbsp; 3 fragments, nominal size 17 lines, similarity 88%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1071')" href="javascript:;">
allennlp-2.9.0/tests/common/push_to_hub_test.py: 67-88
</a>
<div class="mid" id="frag1071" style="display:none"><pre>
    def test_push_to_hub_archive_path(self):
        archive_path = self.FIXTURES_ROOT / "simple_tagger" / "serialization_full" / "model.tar.gz"
        url = push_to_hf(
            repo_name=REPO_NAME,
            archive_path=archive_path,
            local_repo_path=self.local_repo_path,
            use_auth_token=self.token,
        )

        # Check that the returned commit url
        # actually exists.
        r = requests.head(url)
        r.raise_for_status()

        Repository(
            self.clone_path,
            clone_from=f"{ENDPOINT_STAGING}/{USER}/{REPO_NAME}",
            use_auth_token=self.token,
        )
        load_archive(self.clone_path)
        shutil.rmtree(self.clone_path)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1073')" href="javascript:;">
allennlp-2.9.0/tests/common/push_to_hub_test.py: 113-135
</a>
<div class="mid" id="frag1073" style="display:none"><pre>
    def test_push_to_hub_to_org(self):
        serialization_dir = self.FIXTURES_ROOT / "simple_tagger" / "serialization_full"
        url = push_to_hf(
            repo_name=REPO_NAME,
            serialization_dir=serialization_dir,
            organization=ORG_NAME,
            local_repo_path=self.local_repo_path,
            use_auth_token=self.token,
        )

        # Check that the returned commit url
        # actually exists.
        r = requests.head(url)
        r.raise_for_status()

        Repository(
            self.clone_path,
            clone_from=f"{ENDPOINT_STAGING}/{ORG_NAME}/{REPO_NAME}",
            use_auth_token=self.token,
        )
        load_archive(self.clone_path)
        shutil.rmtree(self.clone_path)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1072')" href="javascript:;">
allennlp-2.9.0/tests/common/push_to_hub_test.py: 90-111
</a>
<div class="mid" id="frag1072" style="display:none"><pre>
    def test_push_to_hub_serialization_dir(self):
        serialization_dir = self.FIXTURES_ROOT / "simple_tagger" / "serialization_full"
        url = push_to_hf(
            repo_name=REPO_NAME,
            serialization_dir=serialization_dir,
            local_repo_path=self.local_repo_path,
            use_auth_token=self.token,
        )

        # Check that the returned commit url
        # actually exists.
        r = requests.head(url)
        r.raise_for_status()

        Repository(
            self.clone_path,
            clone_from=f"{ENDPOINT_STAGING}/{USER}/{REPO_NAME}",
            use_auth_token=self.token,
        )
        load_archive(self.clone_path)
        shutil.rmtree(self.clone_path)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 55:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 89%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1081')" href="javascript:;">
allennlp-2.9.0/tests/common/file_utils_test.py: 131-150
</a>
<div class="mid" id="frag1081" style="display:none"><pre>
    def test_resource_to_filename_with_etags(self):
        for url in [
            "http://allenai.org",
            "http://allennlp.org",
            "https://www.google.com",
            "http://pytorch.org",
        ]:
            filename = _resource_to_filename(url, etag="mytag")
            assert "http" not in filename
            pathlib.Path(os.path.join(self.TEST_DIR, filename)).touch()
            json.dump(
                {"url": url, "etag": "mytag"},
                open(os.path.join(self.TEST_DIR, filename + ".json"), "w"),
            )
            back_to_url, etag = filename_to_url(filename, cache_dir=self.TEST_DIR)
            assert back_to_url == url
            assert etag == "mytag"
        baseurl = "http://allenai.org/"
        assert _resource_to_filename(baseurl + "1") != _resource_to_filename(baseurl, etag="1")

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1082')" href="javascript:;">
allennlp-2.9.0/tests/common/file_utils_test.py: 151-168
</a>
<div class="mid" id="frag1082" style="display:none"><pre>
    def test_resource_to_filename_with_etags_eliminates_quotes(self):
        for url in [
            "http://allenai.org",
            "http://allennlp.org",
            "https://www.google.com",
            "http://pytorch.org",
        ]:
            filename = _resource_to_filename(url, etag='"mytag"')
            assert "http" not in filename
            pathlib.Path(os.path.join(self.TEST_DIR, filename)).touch()
            json.dump(
                {"url": url, "etag": "mytag"},
                open(os.path.join(self.TEST_DIR, filename + ".json"), "w"),
            )
            back_to_url, etag = filename_to_url(filename, cache_dir=self.TEST_DIR)
            assert back_to_url == url
            assert etag == "mytag"

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 56:</b> &nbsp; 2 fragments, nominal size 21 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1096')" href="javascript:;">
allennlp-2.9.0/tests/common/file_utils_test.py: 350-373
</a>
<div class="mid" id="frag1096" style="display:none"><pre>
    def test_cached_path_extract_remote_tar(self):
        url = "http://fake.datastore.com/utf-8.tar.gz"
        byt = open(self.tar_file, "rb").read()

        responses.add(
            responses.GET,
            url,
            body=byt,
            status=200,
            content_type="application/tar+gzip",
            stream=True,
            headers={"Content-Length": str(len(byt))},
        )
        responses.add(
            responses.HEAD,
            url,
            status=200,
            headers={"ETag": "fake-etag"},
        )

        extracted = cached_path(url, cache_dir=self.TEST_DIR, extract_archive=True)
        assert extracted.endswith("-extracted")
        self.check_extracted(extracted)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1097')" href="javascript:;">
allennlp-2.9.0/tests/common/file_utils_test.py: 375-399
</a>
<div class="mid" id="frag1097" style="display:none"><pre>
    def test_cached_path_extract_remote_zip(self):
        url = "http://fake.datastore.com/utf-8.zip"
        byt = open(self.zip_file, "rb").read()

        responses.add(
            responses.GET,
            url,
            body=byt,
            status=200,
            content_type="application/zip",
            stream=True,
            headers={"Content-Length": str(len(byt))},
        )
        responses.add(
            responses.HEAD,
            url,
            status=200,
            headers={"ETag": "fake-etag"},
        )

        extracted = cached_path(url, cache_dir=self.TEST_DIR, extract_archive=True)
        assert extracted.endswith("-extracted")
        self.check_extracted(extracted)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 57:</b> &nbsp; 2 fragments, nominal size 26 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1153')" href="javascript:;">
allennlp-2.9.0/tests/common/from_params_test.py: 356-390
</a>
<div class="mid" id="frag1153" style="display:none"><pre>
    def test_dict(self):

        from allennlp.common.registrable import Registrable

        class A(Registrable):
            pass

        @A.register("b")
        class B(A):
            def __init__(self, size: int) -&gt; None:
                self.size = size

        class C(Registrable):
            pass

        @C.register("d")
        class D(C):
            def __init__(self, items: Dict[str, A]) -&gt; None:
                self.items = items

        params = Params(
            {
                "type": "d",
                "items": {"first": {"type": "b", "size": 1}, "second": {"type": "b", "size": 2}},
            }
        )
        d = C.from_params(params)

        assert isinstance(d.items, dict)
        assert len(d.items) == 2
        assert all(isinstance(key, str) for key in d.items.keys())
        assert all(isinstance(value, B) for value in d.items.values())
        assert d.items["first"].size == 1
        assert d.items["second"].size == 2

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1198')" href="javascript:;">
allennlp-2.9.0/tests/common/from_params_test.py: 814-847
</a>
<div class="mid" id="frag1198" style="display:none"><pre>
    def test_mapping(self):
        from allennlp.common.registrable import Registrable

        class A(Registrable):
            pass

        @A.register("b")
        class B(A):
            def __init__(self, size: int) -&gt; None:
                self.size = size

        class C(Registrable):
            pass

        @C.register("d")
        class D(C):
            def __init__(self, items: Mapping[str, A]) -&gt; None:
                self.items = items

        params = Params(
            {
                "type": "d",
                "items": {"first": {"type": "b", "size": 1}, "second": {"type": "b", "size": 2}},
            }
        )
        d = C.from_params(params)

        assert isinstance(d.items, Mapping)
        assert len(d.items) == 2
        assert all(isinstance(key, str) for key in d.items.keys())
        assert all(isinstance(value, B) for value in d.items.values())
        assert d.items["first"].size == 1
        assert d.items["second"].size == 2

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 58:</b> &nbsp; 2 fragments, nominal size 23 lines, similarity 78%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1158')" href="javascript:;">
allennlp-2.9.0/tests/common/from_params_test.py: 402-432
</a>
<div class="mid" id="frag1158" style="display:none"><pre>
    def test_list(self):

        from allennlp.common.registrable import Registrable

        class A(Registrable):
            pass

        @A.register("b")
        class B(A):
            def __init__(self, size: int) -&gt; None:
                self.size = size

        class C(Registrable):
            pass

        @C.register("d")
        class D(C):
            def __init__(self, items: List[A]) -&gt; None:
                self.items = items

        params = Params(
            {"type": "d", "items": [{"type": "b", "size": 1}, {"type": "b", "size": 2}]}
        )
        d = C.from_params(params)

        assert isinstance(d.items, list)
        assert len(d.items) == 2
        assert all(isinstance(item, B) for item in d.items)
        assert d.items[0].size == 1
        assert d.items[1].size == 2

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1195')" href="javascript:;">
allennlp-2.9.0/tests/common/from_params_test.py: 783-813
</a>
<div class="mid" id="frag1195" style="display:none"><pre>
    def test_iterable(self):
        from allennlp.common.registrable import Registrable

        class A(Registrable):
            pass

        @A.register("b")
        class B(A):
            def __init__(self, size: int) -&gt; None:
                self.size = size

        class C(Registrable):
            pass

        @C.register("d")
        class D(C):
            def __init__(self, items: Iterable[A]) -&gt; None:
                self.items = items

        params = Params(
            {"type": "d", "items": [{"type": "b", "size": 1}, {"type": "b", "size": 2}]}
        )
        d = C.from_params(params)

        assert isinstance(d.items, Iterable)
        items = list(d.items)
        assert len(items) == 2
        assert all(isinstance(item, B) for item in items)
        assert items[0].size == 1
        assert items[1].size == 2

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 59:</b> &nbsp; 2 fragments, nominal size 21 lines, similarity 71%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1218')" href="javascript:;">
allennlp-2.9.0/tests/common/from_params_test.py: 976-1000
</a>
<div class="mid" id="frag1218" style="display:none"><pre>
    def test_from_params_handles_kwargs_in_non_from_params_registered_class(self):
        class Bar(Registrable):
            pass

        class Baz:
            def __init__(self, a: int) -&gt; None:
                self.a = a

        @Bar.register("foo")
        class Foo(Baz):
            def __init__(self, a: int, b: str = None, **kwargs) -&gt; None:
                super().__init__(a)
                self.b = b
                for key, value in kwargs.items():
                    setattr(self, key, value)

        foo = Bar.from_params(Params({"type": "foo", "a": 2, "b": "hi"}))
        assert foo.a == 2
        assert foo.b == "hi"

        foo = Bar.from_params(Params({"type": "foo", "a": 2, "b": "hi", "c": {"2": "3"}}))
        assert foo.a == 2
        assert foo.b == "hi"
        assert foo.c == {"2": "3"}

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1221')" href="javascript:;">
allennlp-2.9.0/tests/common/from_params_test.py: 1001-1027
</a>
<div class="mid" id="frag1221" style="display:none"><pre>
    def test_from_params_does_not_pass_extras_to_non_from_params_registered_class(self):
        class Bar(Registrable):
            pass

        class Baz:
            def __init__(self, a: int, c: Dict[str, str] = None) -&gt; None:
                self.a = a
                self.c = c

        @Bar.register("foo")
        class Foo(Baz):
            def __init__(self, a: int, b: str = None, **kwargs) -&gt; None:
                super().__init__(a, **kwargs)
                self.b = b

        foo = Bar.from_params(Params({"type": "foo", "a": 2, "b": "hi"}))
        assert foo.a == 2
        assert foo.b == "hi"
        assert foo.c is None

        foo = Bar.from_params(
            params=Params({"type": "foo", "a": 2, "b": "hi", "c": {"2": "3"}}), extra="4"
        )
        assert foo.a == 2
        assert foo.b == "hi"
        assert foo.c == {"2": "3"}

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 60:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 85%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1234')" href="javascript:;">
allennlp-2.9.0/tests/common/model_card_test.py: 21-40
</a>
<div class="mid" id="frag1234" style="display:none"><pre>
    def test_init_registered_model(self):
        @Model.register("fake-model")
        class FakeModel(Model):
            """
            This is a fake model with a docstring.

            # Parameters

            fake_param1: str
            fake_param2: int
            """

            def forward(self, **kwargs):
                return {}

        model_card = ModelCard(**{"id": "this-fake-model", "registered_model_name": "fake-model"})

        assert model_card.display_name == "FakeModel"
        assert model_card.model_details.description == "This is a fake model with a docstring."

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1236')" href="javascript:;">
allennlp-2.9.0/tests/common/model_card_test.py: 41-59
</a>
<div class="mid" id="frag1236" style="display:none"><pre>
    def test_init_dict_model(self):
        class FakeModel(Model):
            """
            This is a fake model with a docstring.

            # Parameters

            fake_param1: str
            fake_param2: int
            """

            def forward(self, **kwargs):
                return {}

        model_card = ModelCard(**{"id": "this-fake-model", "model_class": FakeModel})

        assert model_card.display_name == "FakeModel"
        assert model_card.model_details.description == "This is a fake model with a docstring."

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 61:</b> &nbsp; 2 fragments, nominal size 28 lines, similarity 80%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1263')" href="javascript:;">
allennlp-2.9.0/tests/predictors/text_classifier_test.py: 11-44
</a>
<div class="mid" id="frag1263" style="display:none"><pre>
    def test_uses_named_inputs(self):
        inputs = {
            "sentence": "It was the ending that I hated. I was disappointed that it was so bad."
        }

        archive = load_archive(
            self.FIXTURES_ROOT / "basic_classifier" / "serialization" / "model.tar.gz"
        )
        predictor = Predictor.from_archive(archive, "text_classifier")
        result = predictor.predict_json(inputs)

        logits = result.get("logits")
        assert logits is not None
        assert isinstance(logits, list)
        assert len(logits) == 2
        assert all(isinstance(x, float) for x in logits)

        probs = result.get("probs")
        assert probs is not None
        assert isinstance(probs, list)
        assert len(probs) == 2
        assert all(isinstance(x, float) for x in probs)
        assert all(x &gt;= 0 for x in probs)
        assert sum(probs) == approx(1.0)

        label = result.get("label")
        assert label is not None
        assert label in predictor._model.vocab.get_token_to_index_vocabulary(namespace="labels")

        exps = [math.exp(x) for x in logits]
        sum_exps = sum(exps)
        for e, p in zip(exps, probs):
            assert e / sum_exps == approx(p)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1264')" href="javascript:;">
allennlp-2.9.0/tests/predictors/text_classifier_test.py: 45-81
</a>
<div class="mid" id="frag1264" style="display:none"><pre>
    def test_batch_prediction(self):
        batch_inputs = [
            {"sentence": "It was the ending that I hated. I was disappointed that it was so bad."},
            {"sentence": "This one is honestly the worst movie I've ever watched."},
        ]

        archive = load_archive(
            self.FIXTURES_ROOT / "basic_classifier" / "serialization" / "model.tar.gz"
        )
        predictor = Predictor.from_archive(archive, "text_classifier")
        results = predictor.predict_batch_json(batch_inputs)
        assert len(results) == 2

        for result in results:
            logits = result.get("logits")
            assert logits is not None
            assert isinstance(logits, list)
            assert len(logits) == 2
            assert all(isinstance(x, float) for x in logits)

            probs = result.get("probs")
            assert probs is not None
            assert isinstance(probs, list)
            assert len(probs) == 2
            assert all(isinstance(x, float) for x in probs)
            assert all(x &gt;= 0 for x in probs)
            assert sum(probs) == approx(1.0)

            label = result.get("label")
            assert label is not None
            assert label in predictor._model.vocab.get_token_to_index_vocabulary(namespace="labels")

            exps = [math.exp(x) for x in logits]
            sum_exps = sum(exps)
            for e, p in zip(exps, probs):
                assert e / sum_exps == approx(p)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 62:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 80%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1297')" href="javascript:;">
allennlp-2.9.0/tests/fairness/bias_mitigators_test.py: 229-239
</a>
<div class="mid" id="frag1297" style="display:none"><pre>
    def test_invalid_dims(self):
        ibm = INLPBiasMitigator()
        with pytest.raises(ConfigurationError):
            ibm(torch.zeros(2), torch.zeros(2), torch.zeros(2))
        with pytest.raises(ConfigurationError):
            ibm(torch.zeros(2), torch.zeros((2, 2)), torch.zeros((2, 3)))
        with pytest.raises(ConfigurationError):
            ibm(torch.zeros(2), torch.zeros((2, 2)), torch.zeros((2, 2)))
        with pytest.raises(ConfigurationError):
            ibm(torch.zeros((2, 3)), torch.zeros((2, 2)), torch.zeros((2, 2)))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1300')" href="javascript:;">
allennlp-2.9.0/tests/fairness/bias_mitigators_test.py: 278-288
</a>
<div class="mid" id="frag1300" style="display:none"><pre>
    def test_invalid_dims(self):
        ibm = INLPBiasMitigator()
        with pytest.raises(ConfigurationError):
            ibm(torch.zeros(2), torch.zeros(2), torch.zeros(2))
        with pytest.raises(ConfigurationError):
            ibm(torch.zeros(2), torch.zeros((2, 2)), torch.zeros((2, 3)))
        with pytest.raises(ConfigurationError):
            ibm(torch.zeros((2, 3)), torch.zeros(2), torch.zeros(2))
        with pytest.raises(ConfigurationError):
            ibm(torch.zeros((2, 1)), torch.zeros(1), torch.zeros(1))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 63:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1298')" href="javascript:;">
allennlp-2.9.0/tests/fairness/bias_mitigators_test.py: 241-255
</a>
<div class="mid" id="frag1298" style="display:none"><pre>
    def test_inlp(self, device: str):
        self.seed_embeddings1 = self.seed_embeddings1.to(device)
        self.seed_embeddings2 = self.seed_embeddings2.to(device)
        self.evaluation_embeddings = self.evaluation_embeddings.to(device)
        self.expected_bias_mitigated_embeddings = self.expected_bias_mitigated_embeddings.to(device)

        ibm = INLPBiasMitigator()
        test_bias_mitigated_embeddings = ibm(
            self.evaluation_embeddings, self.seed_embeddings1, self.seed_embeddings2
        )
        assert allclose(
            self.expected_bias_mitigated_embeddings, test_bias_mitigated_embeddings, atol=1e-6
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1301')" href="javascript:;">
allennlp-2.9.0/tests/fairness/bias_mitigators_test.py: 290-303
</a>
<div class="mid" id="frag1301" style="display:none"><pre>
    def test_oscar_without_grad(self, device: str):
        self.bias_direction1 = self.bias_direction1.to(device)
        self.bias_direction2 = self.bias_direction2.to(device)
        self.evaluation_embeddings = self.evaluation_embeddings.to(device)
        self.expected_bias_mitigated_embeddings = self.expected_bias_mitigated_embeddings.to(device)

        obm = OSCaRBiasMitigator()
        test_bias_mitigated_embeddings = obm(
            self.evaluation_embeddings, self.bias_direction1, self.bias_direction2
        )
        assert allclose(
            self.expected_bias_mitigated_embeddings, test_bias_mitigated_embeddings, atol=1e-6
        )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 64:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1308')" href="javascript:;">
allennlp-2.9.0/tests/fairness/bias_direction_test.py: 72-88
</a>
<div class="mid" id="frag1308" style="display:none"><pre>
    def test_paired_pca_with_grad(self, device: str):
        # add noise to avoid "RuntimeError: triangular_solve_cpu: U(2,2) is zero, singular U."
        torch.manual_seed(0)
        seed_embeddings1 = torch.tensor([[1.0, 1.0], [1.0, 1.0]], device=device)
        seed_embeddings2 = (1 - torch.eye(2, device=device)) * 9e-1
        seed_embeddings1 = seed_embeddings1.requires_grad_()
        seed_embeddings2 = seed_embeddings2.requires_grad_()
        assert seed_embeddings1.grad is None
        assert seed_embeddings2.grad is None

        paired_pca = PairedPCABiasDirection(requires_grad=True)
        test_bias_direction = paired_pca(seed_embeddings1, seed_embeddings2)
        test_bias_direction.sum().backward()
        assert seed_embeddings1.grad is not None
        assert seed_embeddings2.grad is not None


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1311')" href="javascript:;">
allennlp-2.9.0/tests/fairness/bias_direction_test.py: 111-125
</a>
<div class="mid" id="frag1311" style="display:none"><pre>
    def test_two_means_with_grad(self, device: str):
        seed_embeddings1 = torch.eye(2, device=device)
        seed_embeddings2 = 1 - torch.eye(2, device=device)
        seed_embeddings1 = seed_embeddings1.requires_grad_()
        seed_embeddings2 = seed_embeddings2.requires_grad_()
        assert seed_embeddings1.grad is None
        assert seed_embeddings2.grad is None

        two_means = TwoMeansBiasDirection(requires_grad=True)
        test_bias_direction = two_means(seed_embeddings1, seed_embeddings2)
        test_bias_direction.sum().backward()
        assert seed_embeddings1.grad is not None
        assert seed_embeddings2.grad is not None


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 65:</b> &nbsp; 6 fragments, nominal size 12 lines, similarity 71%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1314')" href="javascript:;">
allennlp-2.9.0/tests/commands/main_test.py: 16-30
</a>
<div class="mid" id="frag1314" style="display:none"><pre>
    def test_fails_on_unknown_command(self):
        sys.argv = [
            "bogus",  # command
            "unknown_model",  # model_name
            "bogus file",  # input_file
            "--output-file",
            "bogus out file",
            "--silent",
        ]

        with pytest.raises(SystemExit) as cm:
            main()

        assert cm.value.code == 2  # argparse code for incorrect usage

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1326')" href="javascript:;">
allennlp-2.9.0/tests/commands/cached_path_test.py: 35-47
</a>
<div class="mid" id="frag1326" style="display:none"><pre>
    def test_remove_with_bad_options(self, capsys):
        sys.argv = [
            "allennlp",
            "cached-path",
            "--cache-dir",
            str(self.TEST_DIR),
            "--remove",
            "--extract-archive",
            "*",
        ]
        with pytest.raises(RuntimeError, match="--extract-archive"):
            main()

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1347')" href="javascript:;">
allennlp-2.9.0/tests/commands/checklist_test.py: 44-59
</a>
<div class="mid" id="frag1347" style="display:none"><pre>
    def test_works_with_known_model(self):

        sys.argv = [
            "__main__.py",  # executable
            "checklist",  # command
            str(self.archive_file),
            str(self.task),
            "--task-suite-args",
            '{"positive": 1, "negative": 0}',
            "--max-examples",
            "1",
            "--cuda-device",
            "0",
        ]

        main()
</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1328')" href="javascript:;">
allennlp-2.9.0/tests/commands/cached_path_test.py: 59-70
</a>
<div class="mid" id="frag1328" style="display:none"><pre>
    def test_remove_empty_cache(self, capsys):
        sys.argv = [
            "allennlp",
            "cached-path",
            "--cache-dir",
            str(self.TEST_DIR),
            "--remove",
            "*",
        ]
        main()
        captured = capsys.readouterr()
        assert "Reclaimed 0B of space" in captured.out
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1327')" href="javascript:;">
allennlp-2.9.0/tests/commands/cached_path_test.py: 48-58
</a>
<div class="mid" id="frag1327" style="display:none"><pre>
    def test_remove_with_missing_positionals(self, capsys):
        sys.argv = [
            "allennlp",
            "cached-path",
            "--cache-dir",
            str(self.TEST_DIR),
            "--remove",
        ]
        with pytest.raises(RuntimeError, match="Missing positional"):
            main()

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1325')" href="javascript:;">
allennlp-2.9.0/tests/commands/cached_path_test.py: 23-34
</a>
<div class="mid" id="frag1325" style="display:none"><pre>
    def test_inspect_with_bad_options(self, capsys):
        sys.argv = [
            "allennlp",
            "cached-path",
            "--cache-dir",
            str(self.TEST_DIR),
            "--inspect",
            "--extract-archive",
        ]
        with pytest.raises(RuntimeError, match="--extract-archive"):
            main()

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 66:</b> &nbsp; 2 fragments, nominal size 16 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1348')" href="javascript:;">
allennlp-2.9.0/tests/interpret/simple_gradient_test.py: 17-37
</a>
<div class="mid" id="frag1348" style="display:none"><pre>
    def test_simple_gradient_basic_text(self):
        inputs = {"sentence": "It was the ending that I hated"}
        archive = load_archive(
            self.FIXTURES_ROOT / "basic_classifier" / "serialization" / "model.tar.gz"
        )
        predictor = Predictor.from_archive(archive, "text_classifier")

        interpreter = SimpleGradient(predictor)
        interpretation = interpreter.saliency_interpret_from_json(inputs)
        assert interpretation is not None
        assert "instance_1" in interpretation
        assert "grad_input_1" in interpretation["instance_1"]
        grad_input_1 = interpretation["instance_1"]["grad_input_1"]
        assert len(grad_input_1) == 7  # 7 words in input

        # two interpretations should be identical for gradient
        repeat_interpretation = interpreter.saliency_interpret_from_json(inputs)
        repeat_grad_input_1 = repeat_interpretation["instance_1"]["grad_input_1"]
        for grad, repeat_grad in zip(grad_input_1, repeat_grad_input_1):
            assert grad == approx(repeat_grad)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1351')" href="javascript:;">
allennlp-2.9.0/tests/interpret/integrated_gradient_test.py: 17-37
</a>
<div class="mid" id="frag1351" style="display:none"><pre>
    def test_integrated_gradient(self):
        inputs = {"sentence": "It was the ending that I hated"}
        archive = load_archive(
            self.FIXTURES_ROOT / "basic_classifier" / "serialization" / "model.tar.gz"
        )
        predictor = Predictor.from_archive(archive, "text_classifier")

        interpreter = IntegratedGradient(predictor)
        interpretation = interpreter.saliency_interpret_from_json(inputs)
        assert interpretation is not None
        assert "instance_1" in interpretation
        assert "grad_input_1" in interpretation["instance_1"]
        grad_input_1 = interpretation["instance_1"]["grad_input_1"]
        assert len(grad_input_1) == 7  # 7 words in input

        # two interpretations should be identical for integrated gradients
        repeat_interpretation = interpreter.saliency_interpret_from_json(inputs)
        repeat_grad_input_1 = repeat_interpretation["instance_1"]["grad_input_1"]
        for grad, repeat_grad in zip(grad_input_1, repeat_grad_input_1):
            assert grad == approx(repeat_grad)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 67:</b> &nbsp; 3 fragments, nominal size 13 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1350')" href="javascript:;">
allennlp-2.9.0/tests/interpret/simple_gradient_test.py: 49-63
</a>
<div class="mid" id="frag1350" style="display:none"><pre>
    def test_interpret_works_with_custom_embedding_layer(self):
        inputs = {"sentence": "It was the ending that I hated"}
        vocab = Vocabulary()
        vocab.add_tokens_to_namespace([w for w in inputs["sentence"].split(" ")])
        model = FakeModelForTestingInterpret(vocab, max_tokens=len(inputs["sentence"].split(" ")))
        predictor = FakePredictorForTestingInterpret(model, TextClassificationJsonReader())
        interpreter = SimpleGradient(predictor)

        interpretation = interpreter.saliency_interpret_from_json(inputs)

        assert interpretation is not None
        assert "instance_1" in interpretation
        assert "grad_input_1" in interpretation["instance_1"]
        grad_input_1 = interpretation["instance_1"]["grad_input_1"]
        assert len(grad_input_1) == 7  # 7 words in input
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1353')" href="javascript:;">
allennlp-2.9.0/tests/interpret/integrated_gradient_test.py: 49-63
</a>
<div class="mid" id="frag1353" style="display:none"><pre>
    def test_interpret_works_with_custom_embedding_layer(self):
        inputs = {"sentence": "It was the ending that I hated"}
        vocab = Vocabulary()
        vocab.add_tokens_to_namespace([w for w in inputs["sentence"].split(" ")])
        model = FakeModelForTestingInterpret(vocab, max_tokens=len(inputs["sentence"].split(" ")))
        predictor = FakePredictorForTestingInterpret(model, TextClassificationJsonReader())
        interpreter = IntegratedGradient(predictor)

        interpretation = interpreter.saliency_interpret_from_json(inputs)

        assert interpretation is not None
        assert "instance_1" in interpretation
        assert "grad_input_1" in interpretation["instance_1"]
        grad_input_1 = interpretation["instance_1"]["grad_input_1"]
        assert len(grad_input_1) == 7  # 7 words in input
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1361')" href="javascript:;">
allennlp-2.9.0/tests/interpret/smooth_gradient_test.py: 42-56
</a>
<div class="mid" id="frag1361" style="display:none"><pre>
    def test_interpret_works_with_custom_embedding_layer(self):
        inputs = {"sentence": "It was the ending that I hated"}
        vocab = Vocabulary()
        vocab.add_tokens_to_namespace([w for w in inputs["sentence"].split(" ")])
        model = FakeModelForTestingInterpret(vocab, max_tokens=len(inputs["sentence"].split(" ")))
        predictor = FakePredictorForTestingInterpret(model, TextClassificationJsonReader())
        interpreter = SmoothGradient(predictor)

        interpretation = interpreter.saliency_interpret_from_json(inputs)

        assert interpretation is not None
        assert "instance_1" in interpretation
        assert "grad_input_1" in interpretation["instance_1"]
        grad_input_1 = interpretation["instance_1"]["grad_input_1"]
        assert len(grad_input_1) == 7  # 7 words in input
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 68:</b> &nbsp; 2 fragments, nominal size 15 lines, similarity 73%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1355')" href="javascript:;">
allennlp-2.9.0/tests/interpret/hotflip_test.py: 20-38
</a>
<div class="mid" id="frag1355" style="display:none"><pre>
    def test_hotflip(self):
        inputs = {"sentence": "I always write unit tests for my code."}

        archive = load_archive(
            self.FIXTURES_ROOT / "basic_classifier" / "serialization" / "model.tar.gz"
        )
        predictor = Predictor.from_archive(archive)

        hotflipper = Hotflip(predictor)
        hotflipper.initialize()
        attack = hotflipper.attack_from_json(inputs, "tokens", "grad_input_1")
        assert attack is not None
        assert "final" in attack
        assert "original" in attack
        assert "outputs" in attack
        assert len(attack["final"][0]) == len(
            attack["original"]
        )  # hotflip replaces words without removing

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1358')" href="javascript:;">
allennlp-2.9.0/tests/interpret/hotflip_test.py: 83-99
</a>
<div class="mid" id="frag1358" style="display:none"><pre>
    def test_interpret_works_with_custom_embedding_layer(self):
        inputs = {"sentence": "I always write unit tests for my code"}
        vocab = Vocabulary()
        vocab.add_tokens_to_namespace([w for w in inputs["sentence"].split(" ")])
        model = FakeModelForTestingInterpret(vocab, max_tokens=len(inputs["sentence"].split(" ")))
        predictor = FakePredictorForTestingInterpret(model, TextClassificationJsonReader())

        hotflipper = Hotflip(predictor)
        hotflipper.initialize()
        attack = hotflipper.attack_from_json(inputs, "tokens", "grad_input_1")
        assert attack is not None
        assert "final" in attack
        assert "original" in attack
        assert "outputs" in attack
        assert len(attack["final"][0]) == len(
            attack["original"]
        )  # hotflip replaces words without removing
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 69:</b> &nbsp; 5 fragments, nominal size 31 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1376')" href="javascript:;">
allennlp-2.9.0/tests/modules/token_embedders/pretrained_transformer_mismatched_embedder_test.py: 22-65
</a>
<div class="mid" id="frag1376" style="display:none"><pre>
    def test_end_to_end(self, train_parameters: bool):
        token_indexer = PretrainedTransformerMismatchedIndexer("bert-base-uncased")

        sentence1 = ["A", ",", "AllenNLP", "sentence", "."]
        sentence2 = ["AllenNLP", "is", "great"]
        tokens1 = [Token(word) for word in sentence1]
        tokens2 = [Token(word) for word in sentence2]

        vocab = Vocabulary()

        params = Params(
            {
                "token_embedders": {
                    "bert": {
                        "type": "pretrained_transformer_mismatched",
                        "model_name": "bert-base-uncased",
                        "train_parameters": train_parameters,
                    }
                }
            }
        )
        token_embedder = BasicTextFieldEmbedder.from_params(vocab=vocab, params=params)

        instance1 = Instance({"tokens": TextField(tokens1, {"bert": token_indexer})})
        instance2 = Instance({"tokens": TextField(tokens2, {"bert": token_indexer})})

        batch = Batch([instance1, instance2])
        batch.index_instances(vocab)

        padding_lengths = batch.get_padding_lengths()
        tensor_dict = batch.as_tensor_dict(padding_lengths)
        tokens = tensor_dict["tokens"]

        assert tokens["bert"]["offsets"].tolist() == [
            [[1, 1], [2, 2], [3, 5], [6, 6], [7, 7]],
            [[1, 3], [4, 4], [5, 5], [0, 0], [0, 0]],
        ]

        # Attention mask
        bert_vectors = token_embedder(tokens)
        assert bert_vectors.size() == (2, max(len(sentence1), len(sentence2)), 768)
        assert not torch.isnan(bert_vectors).any()
        assert bert_vectors.requires_grad == train_parameters

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1378')" href="javascript:;">
allennlp-2.9.0/tests/modules/token_embedders/pretrained_transformer_mismatched_embedder_test.py: 112-152
</a>
<div class="mid" id="frag1378" style="display:none"><pre>
    def test_token_without_wordpieces(self):
        token_indexer = PretrainedTransformerMismatchedIndexer("bert-base-uncased")

        sentence1 = ["A", "", "AllenNLP", "sentence", "."]
        sentence2 = ["AllenNLP", "", "great"]
        tokens1 = [Token(word) for word in sentence1]
        tokens2 = [Token(word) for word in sentence2]
        vocab = Vocabulary()
        params = Params(
            {
                "token_embedders": {
                    "bert": {
                        "type": "pretrained_transformer_mismatched",
                        "model_name": "bert-base-uncased",
                    }
                }
            }
        )
        token_embedder = BasicTextFieldEmbedder.from_params(vocab=vocab, params=params)

        instance1 = Instance({"tokens": TextField(tokens1, {"bert": token_indexer})})
        instance2 = Instance({"tokens": TextField(tokens2, {"bert": token_indexer})})

        batch = Batch([instance1, instance2])
        batch.index_instances(vocab)

        padding_lengths = batch.get_padding_lengths()
        tensor_dict = batch.as_tensor_dict(padding_lengths)
        tokens = tensor_dict["tokens"]

        assert tokens["bert"]["offsets"].tolist() == [
            [[1, 1], [-1, -1], [2, 4], [5, 5], [6, 6]],
            [[1, 3], [-1, -1], [4, 4], [0, 0], [0, 0]],
        ]

        bert_vectors = token_embedder(tokens)
        assert bert_vectors.size() == (2, max(len(sentence1), len(sentence2)), 768)
        assert not torch.isnan(bert_vectors).any()
        assert all(bert_vectors[0, 1] == 0)
        assert all(bert_vectors[1, 1] == 0)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1380')" href="javascript:;">
allennlp-2.9.0/tests/modules/token_embedders/pretrained_transformer_mismatched_embedder_test.py: 187-236
</a>
<div class="mid" id="frag1380" style="display:none"><pre>
    def test_end_to_end_for_first_sub_token_embedding(self, sub_token_mode: str):
        token_indexer = PretrainedTransformerMismatchedIndexer("bert-base-uncased")

        sentence1 = ["A", ",", "AllenNLP", "sentence", "."]
        sentence2 = ["AllenNLP", "is", "open", "source", "NLP", "library"]

        tokens1 = [Token(word) for word in sentence1]
        tokens2 = [Token(word) for word in sentence2]

        vocab = Vocabulary()

        params = Params(
            {
                "token_embedders": {
                    "bert": {
                        "type": "pretrained_transformer_mismatched",
                        "model_name": "bert-base-uncased",
                        "sub_token_mode": sub_token_mode,
                    }
                }
            }
        )
        token_embedder = BasicTextFieldEmbedder.from_params(vocab=vocab, params=params)

        instance1 = Instance({"tokens": TextField(tokens1, {"bert": token_indexer})})
        instance2 = Instance({"tokens": TextField(tokens2, {"bert": token_indexer})})

        batch = Batch([instance1, instance2])
        batch.index_instances(vocab)

        padding_lengths = batch.get_padding_lengths()
        tensor_dict = batch.as_tensor_dict(padding_lengths)
        tokens = tensor_dict["tokens"]

        assert tokens["bert"]["mask"].tolist() == [
            [True, True, True, True, True, False],
            [True, True, True, True, True, True],
        ]

        assert tokens["bert"]["offsets"].tolist() == [
            [[1, 1], [2, 2], [3, 5], [6, 6], [7, 7], [0, 0]],
            [[1, 3], [4, 4], [5, 5], [6, 6], [7, 8], [9, 9]],
        ]

        # Attention mask
        bert_vectors = token_embedder(tokens)

        assert bert_vectors.size() == (2, max(len(sentence1), len(sentence2)), 768)
        assert not torch.isnan(bert_vectors).any()

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1377')" href="javascript:;">
allennlp-2.9.0/tests/modules/token_embedders/pretrained_transformer_mismatched_embedder_test.py: 66-111
</a>
<div class="mid" id="frag1377" style="display:none"><pre>
    def test_long_sequence_splitting_end_to_end(self):
        token_indexer = PretrainedTransformerMismatchedIndexer("bert-base-uncased", max_length=4)

        sentence1 = ["A", ",", "AllenNLP", "sentence", "."]
        sentence2 = ["AllenNLP", "is", "great"]
        tokens1 = [Token(word) for word in sentence1]
        tokens2 = [Token(word) for word in sentence2]

        vocab = Vocabulary()

        params = Params(
            {
                "token_embedders": {
                    "bert": {
                        "type": "pretrained_transformer_mismatched",
                        "model_name": "bert-base-uncased",
                        "max_length": 4,
                    }
                }
            }
        )
        token_embedder = BasicTextFieldEmbedder.from_params(vocab=vocab, params=params)

        instance1 = Instance({"tokens": TextField(tokens1, {"bert": token_indexer})})
        instance2 = Instance({"tokens": TextField(tokens2, {"bert": token_indexer})})

        batch = Batch([instance1, instance2])
        batch.index_instances(vocab)

        padding_lengths = batch.get_padding_lengths()
        tensor_dict = batch.as_tensor_dict(padding_lengths)
        tokens = tensor_dict["tokens"]

        assert tokens["bert"]["mask"].tolist() == [
            [True, True, True, True, True],
            [True, True, True, False, False],
        ]
        assert tokens["bert"]["offsets"].tolist() == [
            [[1, 1], [2, 2], [3, 5], [6, 6], [7, 7]],
            [[1, 3], [4, 4], [5, 5], [0, 0], [0, 0]],
        ]

        bert_vectors = token_embedder(tokens)
        assert bert_vectors.size() == (2, max(len(sentence1), len(sentence2)), 768)
        assert not torch.isnan(bert_vectors).any()

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1381')" href="javascript:;">
allennlp-2.9.0/tests/modules/token_embedders/pretrained_transformer_mismatched_embedder_test.py: 238-273
</a>
<div class="mid" id="frag1381" style="display:none"><pre>
    def test_throws_error_on_incorrect_sub_token_mode(self, sub_token_mode: str):
        token_indexer = PretrainedTransformerMismatchedIndexer("bert-base-uncased")

        sentence1 = ["A", ",", "AllenNLP", "sentence", "."]
        sentence2 = ["AllenNLP", "is", "open", "source", "NLP", "library"]

        tokens1 = [Token(word) for word in sentence1]
        tokens2 = [Token(word) for word in sentence2]

        vocab = Vocabulary()

        params = Params(
            {
                "token_embedders": {
                    "bert": {
                        "type": "pretrained_transformer_mismatched",
                        "model_name": "bert-base-uncased",
                        "sub_token_mode": sub_token_mode,
                    }
                }
            }
        )
        token_embedder = BasicTextFieldEmbedder.from_params(vocab=vocab, params=params)

        instance1 = Instance({"tokens": TextField(tokens1, {"bert": token_indexer})})
        instance2 = Instance({"tokens": TextField(tokens2, {"bert": token_indexer})})

        batch = Batch([instance1, instance2])
        batch.index_instances(vocab)

        padding_lengths = batch.get_padding_lengths()
        tensor_dict = batch.as_tensor_dict(padding_lengths)
        tokens = tensor_dict["tokens"]

        with pytest.raises(ConfigurationError):
            token_embedder(tokens)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 70:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1403')" href="javascript:;">
allennlp-2.9.0/tests/modules/stacked_bidirectional_lstm_test.py: 15-27
</a>
<div class="mid" id="frag1403" style="display:none"><pre>
    def test_stacked_bidirectional_lstm_completes_forward_pass(self):
        input_tensor = torch.rand(4, 5, 3)
        input_tensor[1, 4:, :] = 0.0
        input_tensor[2, 2:, :] = 0.0
        input_tensor[3, 1:, :] = 0.0
        input_tensor = pack_padded_sequence(input_tensor, [5, 4, 2, 1], batch_first=True)
        lstm = StackedBidirectionalLstm(3, 7, 3)
        output, _ = lstm(input_tensor)
        output_sequence, _ = pad_packed_sequence(output, batch_first=True)
        numpy.testing.assert_array_equal(output_sequence.data[1, 4:, :].numpy(), 0.0)
        numpy.testing.assert_array_equal(output_sequence.data[2, 2:, :].numpy(), 0.0)
        numpy.testing.assert_array_equal(output_sequence.data[3, 1:, :].numpy(), 0.0)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1437')" href="javascript:;">
allennlp-2.9.0/tests/modules/stacked_alternating_lstm_test.py: 10-22
</a>
<div class="mid" id="frag1437" style="display:none"><pre>
    def test_stacked_alternating_lstm_completes_forward_pass(self):
        input_tensor = torch.rand(4, 5, 3)
        input_tensor[1, 4:, :] = 0.0
        input_tensor[2, 2:, :] = 0.0
        input_tensor[3, 1:, :] = 0.0
        input_tensor = pack_padded_sequence(input_tensor, [5, 4, 2, 1], batch_first=True)
        lstm = StackedAlternatingLstm(3, 7, 3)
        output, _ = lstm(input_tensor)
        output_sequence, _ = pad_packed_sequence(output, batch_first=True)
        numpy.testing.assert_array_equal(output_sequence.data[1, 4:, :].numpy(), 0.0)
        numpy.testing.assert_array_equal(output_sequence.data[2, 2:, :].numpy(), 0.0)
        numpy.testing.assert_array_equal(output_sequence.data[3, 1:, :].numpy(), 0.0)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 71:</b> &nbsp; 6 fragments, nominal size 12 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1404')" href="javascript:;">
allennlp-2.9.0/tests/modules/stacked_bidirectional_lstm_test.py: 28-42
</a>
<div class="mid" id="frag1404" style="display:none"><pre>
    def test_stacked_bidirectional_lstm_can_build_from_params(self):
        params = Params(
            {
                "type": "stacked_bidirectional_lstm",
                "input_size": 5,
                "hidden_size": 9,
                "num_layers": 3,
            }
        )
        encoder = Seq2SeqEncoder.from_params(params)

        assert encoder.get_input_dim() == 5
        assert encoder.get_output_dim() == 18
        assert encoder.is_bidirectional

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1568')" href="javascript:;">
allennlp-2.9.0/tests/modules/span_extractors/self_attentive_span_extractor_test.py: 9-21
</a>
<div class="mid" id="frag1568" style="display:none"><pre>
    def test_locally_normalised_span_extractor_can_build_from_params(self):
        params = Params(
            {
                "type": "self_attentive",
                "input_dim": 7,
                "num_width_embeddings": 5,
                "span_width_embedding_dim": 3,
            }
        )
        extractor = SpanExtractor.from_params(params)
        assert isinstance(extractor, SelfAttentiveSpanExtractor)
        assert extractor.get_output_dim() == 10  # input_dim + span_width_embedding_dim

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1571')" href="javascript:;">
allennlp-2.9.0/tests/modules/span_extractors/max_pooling_span_extractor_test.py: 10-22
</a>
<div class="mid" id="frag1571" style="display:none"><pre>
    def test_locally_span_extractor_can_build_from_params(self):
        params = Params(
            {
                "type": "max_pooling",
                "input_dim": 3,
                "num_width_embeddings": 5,
                "span_width_embedding_dim": 3,
            }
        )
        extractor = SpanExtractor.from_params(params)
        assert isinstance(extractor, MaxPoolingSpanExtractor)
        assert extractor.get_output_dim() == 6

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1405')" href="javascript:;">
allennlp-2.9.0/tests/modules/stacked_bidirectional_lstm_test.py: 43-56
</a>
<div class="mid" id="frag1405" style="display:none"><pre>
    def test_stacked_bidirectional_lstm_can_build_from_params_seq2vec(self):
        params = Params(
            {
                "type": "stacked_bidirectional_lstm",
                "input_size": 5,
                "hidden_size": 9,
                "num_layers": 3,
            }
        )
        encoder = Seq2VecEncoder.from_params(params)

        assert encoder.get_input_dim() == 5
        assert encoder.get_output_dim() == 18

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1562')" href="javascript:;">
allennlp-2.9.0/tests/modules/span_extractors/bidirectional_endpoint_span_extractor_test.py: 12-24
</a>
<div class="mid" id="frag1562" style="display:none"><pre>
    def test_bidirectional_endpoint_span_extractor_can_build_from_params(self):
        params = Params(
            {
                "type": "bidirectional_endpoint",
                "input_dim": 4,
                "num_width_embeddings": 5,
                "span_width_embedding_dim": 3,
            }
        )
        extractor = SpanExtractor.from_params(params)
        assert isinstance(extractor, BidirectionalEndpointSpanExtractor)
        assert extractor.get_output_dim() == 2 + 2 + 3

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1558')" href="javascript:;">
allennlp-2.9.0/tests/modules/span_extractors/endpoint_span_extractor_test.py: 10-22
</a>
<div class="mid" id="frag1558" style="display:none"><pre>
    def test_endpoint_span_extractor_can_build_from_params(self):
        params = Params(
            {
                "type": "endpoint",
                "input_dim": 7,
                "num_width_embeddings": 5,
                "span_width_embedding_dim": 3,
            }
        )
        extractor = SpanExtractor.from_params(params)
        assert isinstance(extractor, EndpointSpanExtractor)
        assert extractor.get_output_dim() == 17  # 2 * input_dim + span_width_embedding_dim

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 72:</b> &nbsp; 2 fragments, nominal size 20 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1416')" href="javascript:;">
allennlp-2.9.0/tests/modules/text_field_embedders/basic_text_field_embedder_test.py: 98-120
</a>
<div class="mid" id="frag1416" style="display:none"><pre>
    def test_forward_runs_with_non_bijective_mapping(self):
        elmo_fixtures_path = self.FIXTURES_ROOT / "elmo"
        options_file = str(elmo_fixtures_path / "options.json")
        weight_file = str(elmo_fixtures_path / "lm_weights.hdf5")
        params = Params(
            {
                "token_embedders": {
                    "words": {"type": "embedding", "num_embeddings": 20, "embedding_dim": 2},
                    "elmo": {
                        "type": "elmo_token_embedder",
                        "options_file": options_file,
                        "weight_file": weight_file,
                    },
                }
            }
        )
        token_embedder = BasicTextFieldEmbedder.from_params(vocab=self.vocab, params=params)
        inputs = {
            "words": {"tokens": (torch.rand(3, 6) * 20).long()},
            "elmo": {"elmo_tokens": (torch.rand(3, 6, 50) * 15).long()},
        }
        token_embedder(inputs)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1418')" href="javascript:;">
allennlp-2.9.0/tests/modules/text_field_embedders/basic_text_field_embedder_test.py: 140-162
</a>
<div class="mid" id="frag1418" style="display:none"><pre>
    def test_forward_runs_with_non_bijective_mapping_with_dict(self):
        elmo_fixtures_path = self.FIXTURES_ROOT / "elmo"
        options_file = str(elmo_fixtures_path / "options.json")
        weight_file = str(elmo_fixtures_path / "lm_weights.hdf5")
        params = Params(
            {
                "token_embedders": {
                    "words": {"type": "embedding", "num_embeddings": 20, "embedding_dim": 2},
                    "elmo": {
                        "type": "elmo_token_embedder",
                        "options_file": options_file,
                        "weight_file": weight_file,
                    },
                }
            }
        )
        token_embedder = BasicTextFieldEmbedder.from_params(vocab=self.vocab, params=params)
        inputs = {
            "words": {"tokens": (torch.rand(3, 6) * 20).long()},
            "elmo": {"elmo_tokens": (torch.rand(3, 6, 50) * 15).long()},
        }
        token_embedder(inputs)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 73:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1434')" href="javascript:;">
allennlp-2.9.0/tests/modules/maxout_test.py: 25-45
</a>
<div class="mid" id="frag1434" style="display:none"><pre>
    def test_forward_gives_correct_output(self):
        params = Params(
            {"input_dim": 2, "output_dims": 3, "pool_sizes": 4, "dropout": 0.0, "num_layers": 2}
        )
        maxout = Maxout.from_params(params)

        constant_init = Initializer.from_params(Params({"type": "constant", "val": 1.0}))
        initializer = InitializerApplicator([(".*", constant_init)])
        initializer(maxout)

        input_tensor = torch.FloatTensor([[-3, 1]])
        output = maxout(input_tensor).data.numpy()
        assert output.shape == (1, 3)
        # This output was checked by hand
        # The output of the first maxout layer is [-1, -1, -1], since the
        # matrix multiply gives us [-2]*12. Reshaping and maxing
        # produces [-2, -2, -2] and the bias increments these values.
        # The second layer output is [-2, -2, -2], since the matrix
        # matrix multiply gives us [-3]*12. Reshaping and maxing
        # produces [-3, -3, -3] and the bias increments these values.
        assert_almost_equal(output, [[-2, -2, -2]])
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1550')" href="javascript:;">
allennlp-2.9.0/tests/modules/feedforward_test.py: 55-69
</a>
<div class="mid" id="frag1550" style="display:none"><pre>
    def test_forward_gives_correct_output(self):
        params = Params({"input_dim": 2, "hidden_dims": 3, "activations": "relu", "num_layers": 2})
        feedforward = FeedForward.from_params(params)

        constant_init = Initializer.from_params(Params({"type": "constant", "val": 1.0}))
        initializer = InitializerApplicator([(".*", constant_init)])
        initializer(feedforward)

        input_tensor = torch.FloatTensor([[-3, 1]])
        output = feedforward(input_tensor).data.numpy()
        assert output.shape == (1, 3)
        # This output was checked by hand - ReLU makes output after first hidden layer [0, 0, 0],
        # which then gets a bias added in the second layer to be [1, 1, 1].
        assert_almost_equal(output, [[1, 1, 1]])

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 74:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1441')" href="javascript:;">
allennlp-2.9.0/tests/modules/transformer/transformer_stack_test.py: 69-84
</a>
<div class="mid" id="frag1441" style="display:none"><pre>
def test_transformer_stack_with_cross_attention(params):
    params["add_cross_attention"] = True

    transformer_stack = TransformerStack.from_params(params).eval()
    modules = dict(transformer_stack.named_modules())

    assert hasattr(modules["layers.0"], "cross_attention")

    attention_mask = torch.tensor([[0, 1, 0], [1, 1, 0]])
    transformer_stack.forward(
        torch.randn(2, 3, 6),
        attention_mask=attention_mask,
        encoder_hidden_states=torch.randn(2, 3, 6),
    )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1500')" href="javascript:;">
allennlp-2.9.0/tests/modules/transformer/transformer_layer_test.py: 204-217
</a>
<div class="mid" id="frag1500" style="display:none"><pre>
def test_layer_with_cross_attention(layer_params):
    layer_params["add_cross_attention"] = True

    transformer_layer = TransformerLayer.from_params(layer_params).eval()
    assert hasattr(transformer_layer, "cross_attention")

    attention_mask = torch.tensor([[0, 1, 0], [1, 1, 0]])
    transformer_layer(
        torch.randn(2, 3, 6),
        attention_mask=attention_mask,
        encoder_hidden_states=torch.randn(2, 3, 6),
    )


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 75:</b> &nbsp; 2 fragments, nominal size 22 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1491')" href="javascript:;">
allennlp-2.9.0/tests/modules/transformer/self_attention_test.py: 61-94
</a>
<div class="mid" id="frag1491" style="display:none"><pre>
def test_loading_from_pretrained_weights_using_model_name(pretrained_name, relevant_module):
    torch.manual_seed(1234)
    module = SelfAttention.from_pretrained_module(pretrained_name, relevant_module=relevant_module)

    torch.manual_seed(1234)
    pretrained_module = dict(AutoModel.from_pretrained(pretrained_name).named_modules())[
        # Module name will exclude the top-level part (e.g. 'bert.', 'electra.') for some reason.
        relevant_module[relevant_module.index(".") + 1 :]
    ]

    batch_size = 2
    seq_len = 3
    dim = module.query.in_features
    hidden_states = torch.randn(batch_size, seq_len, dim)
    attention_mask = torch.tensor([[1, 1, 0], [1, 0, 1]])[:, None, None, :]

    # setting to eval mode to avoid non-deterministic dropout.
    module = module.eval()
    pretrained_module = pretrained_module.eval()

    torch.manual_seed(1234)
    output = module(hidden_states, attention_mask=attention_mask.squeeze()).hidden_states
    if "distilbert" in pretrained_name:
        torch.manual_seed(1234)
        hf_output = pretrained_module(
            hidden_states, hidden_states, hidden_states, mask=attention_mask
        )[0]
    else:
        # The attn_mask is processed outside the self attention module in HF bert models.
        attention_mask = (~(attention_mask == 1)) * min_value_of_dtype(hidden_states.dtype)
        torch.manual_seed(1234)
        hf_output = pretrained_module(hidden_states, attention_mask=attention_mask)[0]

    assert torch.allclose(output, hf_output)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1529')" href="javascript:;">
allennlp-2.9.0/tests/modules/transformer/t5_self_attention_test.py: 98-126
</a>
<div class="mid" id="frag1529" style="display:none"><pre>
def test_loading_from_pretrained_weights_using_model_name(pretrained_name, relevant_module):

    torch.manual_seed(1234)
    module = T5Attention.from_pretrained_module(pretrained_name, relevant_module=relevant_module)

    torch.manual_seed(1234)
    pretrained_module = dict(AutoModel.from_pretrained(pretrained_name).named_modules())[
        relevant_module
    ]

    batch_size = 2
    seq_len = 3
    dim = module.query.in_features
    hidden_states = torch.randn(batch_size, seq_len, dim)
    attention_mask = torch.tensor([[1, 1, 0], [1, 0, 1]])[:, None, None, :]

    # setting to eval mode to avoid non-deterministic dropout.
    module = module.eval()
    pretrained_module = pretrained_module.eval()

    torch.manual_seed(1234)
    output = module(hidden_states, mask=attention_mask.squeeze()).hidden_states

    # The attn_mask is processed outside the self attention module in HF bert models.
    attention_mask = (~(attention_mask == 1)) * min_value_of_dtype(hidden_states.dtype)
    torch.manual_seed(1234)
    hf_output = pretrained_module(hidden_states, mask=attention_mask)[0]

    assert torch.allclose(output, hf_output)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 76:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 90%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1495')" href="javascript:;">
allennlp-2.9.0/tests/modules/transformer/transformer_layer_test.py: 62-76
</a>
<div class="mid" id="frag1495" style="display:none"><pre>
def get_attention_modules():
    params = copy.deepcopy(ATTENTION_PARAMS_DICT)
    params["attention_probs_dropout_prob"] = params.pop("attention_dropout")
    params["hidden_dropout_prob"] = params.pop("hidden_dropout")

    torch.manual_seed(1234)
    yield "bert", BertAttention(BertConfig(**params)).eval()

    torch.manual_seed(1234)
    yield "roberta", RobertaAttention(RobertaConfig(**params)).eval()

    torch.manual_seed(1234)
    yield "electra", ElectraAttention(ElectraConfig(**params)).eval()


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1501')" href="javascript:;">
allennlp-2.9.0/tests/modules/transformer/transformer_layer_test.py: 218-233
</a>
<div class="mid" id="frag1501" style="display:none"><pre>
def get_layer_modules():
    params = copy.deepcopy(LAYER_PARAMS_DICT)
    params["attention_probs_dropout_prob"] = params.pop("attention_dropout")
    params["hidden_dropout_prob"] = params.pop("hidden_dropout")
    params["hidden_act"] = params.pop("activation")

    torch.manual_seed(1234)
    yield "bert", BertLayer(BertConfig(**params)).eval()

    torch.manual_seed(1234)
    yield "roberta", RobertaLayer(RobertaConfig(**params)).eval()

    torch.manual_seed(1234)
    yield "electra", ElectraLayer(ElectraConfig(**params)).eval()


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 77:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 83%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1496')" href="javascript:;">
allennlp-2.9.0/tests/modules/transformer/transformer_layer_test.py: 78-96
</a>
<div class="mid" id="frag1496" style="display:none"><pre>
def test_attention_matches_huggingface(attention_params, module_name, hf_module):
    hidden_states = torch.randn(2, 3, 6)
    attention_mask = torch.tensor([[0, 1, 0], [1, 1, 0]])

    attention = AttentionLayer.from_params(attention_params).eval()
    state_dict = attention._get_mapped_state_dict(hf_module.state_dict())
    attention.load_state_dict(state_dict)

    torch.manual_seed(1234)
    output = attention(hidden_states, attention_mask=attention_mask)
    # We do this because bert, roberta, electra process the attention_mask at the model level.
    attention_mask_hf = (attention_mask == 0).view((2, 1, 1, 3)).expand(2, 2, 3, 3) * -10e5

    torch.manual_seed(1234)
    hf_output = hf_module(hidden_states, attention_mask=attention_mask_hf)

    assert torch.allclose(output.hidden_states, hf_output[0])


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1502')" href="javascript:;">
allennlp-2.9.0/tests/modules/transformer/transformer_layer_test.py: 235-252
</a>
<div class="mid" id="frag1502" style="display:none"><pre>
def test_layer_matches_huggingface(layer_params, module_name, hf_module):
    layer = TransformerLayer.from_params(layer_params).eval()
    state_dict = layer._get_mapped_state_dict(hf_module.state_dict())
    layer.load_state_dict(state_dict)

    hidden_states = torch.randn(2, 3, 6)
    attention_mask = torch.tensor([[0, 1, 0], [1, 1, 0]])

    torch.manual_seed(1234)
    output = layer(hidden_states, attention_mask=attention_mask)
    # We do this because bert, roberta, electra process the attention_mask at the model level.
    attention_mask_hf = (attention_mask == 0).view((2, 1, 1, 3)).expand(2, 2, 3, 3) * -10e5
    torch.manual_seed(1234)
    hf_output = hf_module(hidden_states, attention_mask=attention_mask_hf)

    assert torch.allclose(output.hidden_states, hf_output[0])


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 78:</b> &nbsp; 2 fragments, nominal size 26 lines, similarity 92%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1497')" href="javascript:;">
allennlp-2.9.0/tests/modules/transformer/transformer_layer_test.py: 104-140
</a>
<div class="mid" id="frag1497" style="display:none"><pre>
def test_attention_from_pretrained(pretrained_name, relevant_top_level_module):
    torch.manual_seed(1234)
    pretrained = cached_transformers.get(pretrained_name, False).eval()

    if "distilbert" in pretrained_name:
        encoder = pretrained.transformer
    else:
        encoder = pretrained.encoder
    # Hacky way to get a bert layer.
    pretrained_module = list(encoder.layer.modules())[1].attention

    torch.manual_seed(1234)
    module = AttentionLayer.from_pretrained_module(
        pretrained_name,
        relevant_module=None
        if relevant_top_level_module is None
        else f"{relevant_top_level_module}.encoder.layer.0.attention",
    ).eval()

    batch_size = 2
    seq_length = 15
    hidden_size = module.self.query.in_features

    hidden_states = torch.randn(batch_size, seq_length, hidden_size)
    attention_mask = torch.randint(0, 2, (batch_size, seq_length))
    attention_mask_hf = attention_mask[:, None, None, :]
    attention_mask_hf = (1.0 - attention_mask_hf) * -10e5

    torch.manual_seed(1234)
    output = module(hidden_states, attention_mask=attention_mask.squeeze()).hidden_states

    torch.manual_seed(1234)
    hf_output = pretrained_module(hidden_states, attention_mask=attention_mask_hf)[0]

    assert torch.allclose(output, hf_output, atol=1e-04)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1503')" href="javascript:;">
allennlp-2.9.0/tests/modules/transformer/transformer_layer_test.py: 260-296
</a>
<div class="mid" id="frag1503" style="display:none"><pre>
def test_layer_from_pretrained(pretrained_name, relevant_top_level_module):
    torch.manual_seed(1234)
    pretrained = cached_transformers.get(pretrained_name, False).eval()

    if "distilbert" in pretrained_name:
        encoder = pretrained.transformer
    else:
        encoder = pretrained.encoder
    # Hacky way to get a bert layer.
    pretrained_module = list(encoder.layer.modules())[1]

    torch.manual_seed(1234)
    module = TransformerLayer.from_pretrained_module(
        pretrained_name,
        relevant_module=None
        if relevant_top_level_module is None
        else f"{relevant_top_level_module}.encoder.layer.0",
    ).eval()

    batch_size = 2
    seq_length = 15
    hidden_size = module.attention.self.query.in_features

    hidden_states = torch.randn(batch_size, seq_length, hidden_size)
    attention_mask = torch.randint(0, 2, (batch_size, seq_length))
    attention_mask_hf = attention_mask[:, None, None, :]
    attention_mask_hf = (1.0 - attention_mask_hf) * -10e5

    torch.manual_seed(1234)
    output = module(hidden_states, attention_mask=attention_mask.squeeze()).hidden_states

    torch.manual_seed(1234)
    hf_output = pretrained_module(hidden_states, attention_mask=attention_mask_hf)[0]

    assert torch.allclose(output, hf_output, atol=1e-04)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 79:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 89%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1540')" href="javascript:;">
allennlp-2.9.0/tests/modules/seq2vec_encoder_test.py: 10-31
</a>
<div class="mid" id="frag1540" style="display:none"><pre>
    def test_from_params_builders_encoder_correctly(self):
        # We're just making sure parameters get passed through correctly here, and that the basic
        # API works.
        params = Params(
            {
                "type": "lstm",
                "bidirectional": True,
                "num_layers": 3,
                "input_size": 5,
                "hidden_size": 7,
            }
        )
        encoder = Seq2VecEncoder.from_params(params)

        assert encoder.__class__.__name__ == "LstmSeq2VecEncoder"
        assert encoder._module.__class__.__name__ == "LSTM"
        assert encoder._module.num_layers == 3
        assert encoder._module.input_size == 5
        assert encoder._module.hidden_size == 7
        assert encoder._module.bidirectional is True
        assert encoder._module.batch_first is True

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1544')" href="javascript:;">
allennlp-2.9.0/tests/modules/seq2seq_encoder_test.py: 10-33
</a>
<div class="mid" id="frag1544" style="display:none"><pre>
    def test_from_params_builders_encoder_correctly(self):
        # We're just making sure parameters get passed through correctly here, and that the basic
        # API works.
        params = Params(
            {
                "type": "lstm",
                "bidirectional": True,
                "num_layers": 3,
                "input_size": 5,
                "hidden_size": 7,
                "stateful": True,
            }
        )
        encoder = Seq2SeqEncoder.from_params(params)

        assert encoder.__class__.__name__ == "LstmSeq2SeqEncoder"
        assert encoder._module.__class__.__name__ == "LSTM"
        assert encoder._module.num_layers == 3
        assert encoder._module.input_size == 5
        assert encoder._module.hidden_size == 7
        assert encoder._module.bidirectional is True
        assert encoder._module.batch_first is True
        assert encoder.stateful is True

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 80:</b> &nbsp; 2 fragments, nominal size 44 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1564')" href="javascript:;">
allennlp-2.9.0/tests/modules/span_extractors/bidirectional_endpoint_span_extractor_test.py: 29-108
</a>
<div class="mid" id="frag1564" style="display:none"><pre>
    def test_correct_sequence_elements_are_embedded(self):
        sequence_tensor = torch.randn([2, 5, 8])
        # concatentate start and end points together to form our representation
        # for both the forward and backward directions.
        extractor = BidirectionalEndpointSpanExtractor(
            input_dim=8, forward_combination="x,y", backward_combination="x,y"
        )
        indices = torch.LongTensor([[[1, 3], [2, 4]], [[0, 2], [3, 4]]])

        span_representations = extractor(sequence_tensor, indices)

        assert list(span_representations.size()) == [2, 2, 16]
        assert extractor.get_output_dim() == 16
        assert extractor.get_input_dim() == 8

        # We just concatenated the start and end embeddings together, so
        # we can check they match the original indices if we split them apart.
        (
            forward_start_embeddings,
            forward_end_embeddings,
            backward_start_embeddings,
            backward_end_embeddings,
        ) = span_representations.split(4, -1)

        forward_sequence_tensor, backward_sequence_tensor = sequence_tensor.split(4, -1)

        # Forward direction =&gt; subtract 1 from start indices to make them exlusive.
        correct_forward_start_indices = torch.LongTensor([[0, 1], [-1, 2]])
        # This index should be -1, so it will be replaced with a sentinel. Here,
        # we'll set it to a value other than -1 so we can index select the indices and
        # replace it later.
        correct_forward_start_indices[1, 0] = 1

        # Forward direction =&gt; end indices are the same.
        correct_forward_end_indices = torch.LongTensor([[3, 4], [2, 4]])

        # Backward direction =&gt; start indices are exclusive, so add 1 to the end indices.
        correct_backward_start_indices = torch.LongTensor([[4, 5], [3, 5]])
        # These exclusive end indices are outside the tensor, so will be replaced with the end sentinel.
        # Here we replace them with ones so we can index select using these indices without torch
        # complaining.
        correct_backward_start_indices[0, 1] = 1
        correct_backward_start_indices[1, 1] = 1
        # Backward direction =&gt; end indices are inclusive and equal to the forward start indices.
        correct_backward_end_indices = torch.LongTensor([[1, 2], [0, 3]])

        correct_forward_start_embeddings = batched_index_select(
            forward_sequence_tensor.contiguous(), correct_forward_start_indices
        )
        # This element had sequence_tensor index of 0, so it's exclusive index is the start sentinel.
        correct_forward_start_embeddings[1, 0] = extractor._start_sentinel.data
        numpy.testing.assert_array_equal(
            forward_start_embeddings.data.numpy(), correct_forward_start_embeddings.data.numpy()
        )

        correct_forward_end_embeddings = batched_index_select(
            forward_sequence_tensor.contiguous(), correct_forward_end_indices
        )
        numpy.testing.assert_array_equal(
            forward_end_embeddings.data.numpy(), correct_forward_end_embeddings.data.numpy()
        )

        correct_backward_end_embeddings = batched_index_select(
            backward_sequence_tensor.contiguous(), correct_backward_end_indices
        )
        numpy.testing.assert_array_equal(
            backward_end_embeddings.data.numpy(), correct_backward_end_embeddings.data.numpy()
        )

        correct_backward_start_embeddings = batched_index_select(
            backward_sequence_tensor.contiguous(), correct_backward_start_indices
        )
        # This element had sequence_tensor index == sequence_tensor.size(1),
        # so it's exclusive index is the end sentinel.
        correct_backward_start_embeddings[0, 1] = extractor._end_sentinel.data
        correct_backward_start_embeddings[1, 1] = extractor._end_sentinel.data
        numpy.testing.assert_array_equal(
            backward_start_embeddings.data.numpy(), correct_backward_start_embeddings.data.numpy()
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1565')" href="javascript:;">
allennlp-2.9.0/tests/modules/span_extractors/bidirectional_endpoint_span_extractor_test.py: 109-199
</a>
<div class="mid" id="frag1565" style="display:none"><pre>
    def test_correct_sequence_elements_are_embedded_with_a_masked_sequence(self):
        sequence_tensor = torch.randn([2, 5, 8])
        # concatentate start and end points together to form our representation
        # for both the forward and backward directions.
        extractor = BidirectionalEndpointSpanExtractor(
            input_dim=8, forward_combination="x,y", backward_combination="x,y"
        )
        indices = torch.LongTensor(
            [
                [[1, 3], [2, 4]],
                # This span has an end index at the
                # end of the padded sequence.
                [[0, 2], [0, 1]],
            ]
        )
        sequence_mask = torch.tensor(
            [[True, True, True, True, True], [True, True, True, False, False]]
        )

        span_representations = extractor(sequence_tensor, indices, sequence_mask=sequence_mask)

        # We just concatenated the start and end embeddings together, so
        # we can check they match the original indices if we split them apart.
        (
            forward_start_embeddings,
            forward_end_embeddings,
            backward_start_embeddings,
            backward_end_embeddings,
        ) = span_representations.split(4, -1)

        forward_sequence_tensor, backward_sequence_tensor = sequence_tensor.split(4, -1)

        # Forward direction =&gt; subtract 1 from start indices to make them exlusive.
        correct_forward_start_indices = torch.LongTensor([[0, 1], [-1, -1]])
        # These indices should be -1, so they'll be replaced with a sentinel. Here,
        # we'll set them to a value other than -1 so we can index select the indices and
        # replace them later.
        correct_forward_start_indices[1, 0] = 1
        correct_forward_start_indices[1, 1] = 1

        # Forward direction =&gt; end indices are the same.
        correct_forward_end_indices = torch.LongTensor([[3, 4], [2, 1]])

        # Backward direction =&gt; start indices are exclusive, so add 1 to the end indices.
        correct_backward_start_indices = torch.LongTensor([[4, 5], [3, 2]])
        # These exclusive backward start indices are outside the tensor, so will be replaced
        # with the end sentinel. Here we replace them with ones so we can index select using
        # these indices without torch complaining.
        correct_backward_start_indices[0, 1] = 1

        # Backward direction =&gt; end indices are inclusive and equal to the forward start indices.
        correct_backward_end_indices = torch.LongTensor([[1, 2], [0, 0]])

        correct_forward_start_embeddings = batched_index_select(
            forward_sequence_tensor.contiguous(), correct_forward_start_indices
        )
        # This element had sequence_tensor index of 0, so it's exclusive index is the start sentinel.
        correct_forward_start_embeddings[1, 0] = extractor._start_sentinel.data
        correct_forward_start_embeddings[1, 1] = extractor._start_sentinel.data
        numpy.testing.assert_array_equal(
            forward_start_embeddings.data.numpy(), correct_forward_start_embeddings.data.numpy()
        )

        correct_forward_end_embeddings = batched_index_select(
            forward_sequence_tensor.contiguous(), correct_forward_end_indices
        )
        numpy.testing.assert_array_equal(
            forward_end_embeddings.data.numpy(), correct_forward_end_embeddings.data.numpy()
        )

        correct_backward_end_embeddings = batched_index_select(
            backward_sequence_tensor.contiguous(), correct_backward_end_indices
        )
        numpy.testing.assert_array_equal(
            backward_end_embeddings.data.numpy(), correct_backward_end_embeddings.data.numpy()
        )

        correct_backward_start_embeddings = batched_index_select(
            backward_sequence_tensor.contiguous(), correct_backward_start_indices
        )
        # This element had sequence_tensor index == sequence_tensor.size(1),
        # so it's exclusive index is the end sentinel.
        correct_backward_start_embeddings[0, 1] = extractor._end_sentinel.data
        # This element has sequence_tensor index == the masked length of the batch element,
        # so it should be the end_sentinel even though it isn't greater than sequence_tensor.size(1).
        correct_backward_start_embeddings[1, 0] = extractor._end_sentinel.data

        numpy.testing.assert_array_equal(
            backward_start_embeddings.data.numpy(), correct_backward_start_embeddings.data.numpy()
        )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 81:</b> &nbsp; 2 fragments, nominal size 17 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1572')" href="javascript:;">
allennlp-2.9.0/tests/modules/span_extractors/max_pooling_span_extractor_test.py: 23-62
</a>
<div class="mid" id="frag1572" style="display:none"><pre>
    def test_max_values_extracted(self):
        # Test if max_pooling is correctly applied
        # We use a high dimensional random vector and assume that a randomly correct result is too unlikely
        sequence_tensor = torch.randn([2, 10, 30])
        extractor = MaxPoolingSpanExtractor(30)

        indices = torch.LongTensor([[[1, 1], [2, 4], [9, 9]], [[0, 1], [4, 4], [0, 9]]])
        span_representations = extractor(sequence_tensor, indices)

        assert list(span_representations.size()) == [2, 3, 30]
        assert extractor.get_output_dim() == 30
        assert extractor.get_input_dim() == 30

        # We iterate over the tensor to compare the span extractors's results
        # with the results of python max operation over each dimension for each span and for each batch
        # For each batch
        for batch, X in enumerate(indices):
            # For each defined span index
            for indices_ind, span_def in enumerate(X):

                # original features of current tested span
                # span_width x embedding dim (30)
                span_features_complete = sequence_tensor[batch][span_def[0] : span_def[1] + 1]

                # comparison for each dimension
                for i in range(extractor.get_output_dim()):
                    # get the features for dimension i of current span
                    features_from_span = span_features_complete[:, i]
                    real_max_value = max(features_from_span)

                    extracted_max_value = span_representations[batch, indices_ind, i]

                    assert real_max_value == extracted_max_value, (
                        f"Error extracting max value for "
                        f"batch {batch}, span {indices_ind} on dimension {i}."
                        f"expected {real_max_value} "
                        f"but got {extracted_max_value} which is "
                        f"not the maximum element."
                    )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1573')" href="javascript:;">
allennlp-2.9.0/tests/modules/span_extractors/max_pooling_span_extractor_test.py: 63-98
</a>
<div class="mid" id="frag1573" style="display:none"><pre>
    def test_sequence_mask_correct_excluded(self):
        # Check if span indices masked out by the sequence mask are ignored when computing
        # the span representations. For this test span_start is valid, but span_end is masked out.

        sequence_tensor = torch.randn([2, 6, 30])

        extractor = MaxPoolingSpanExtractor(30)
        indices = torch.LongTensor([[[1, 1], [3, 5], [2, 5]], [[0, 0], [0, 3], [4, 5]]])
        # define sequence mak
        seq_mask = torch.BoolTensor([[True] * 4 + [False] * 2, [True] * 5 + [False] * 1])

        span_representations = extractor(sequence_tensor, indices, sequence_mask=seq_mask)

        # After we computed the representations we set values to -inf
        # to compute the "real" max-pooling with python's max function.
        sequence_tensor[torch.logical_not(seq_mask)] = float("-inf")

        # Comparison is similar to test_max_values_extracted
        for batch, X in enumerate(indices):
            for indices_ind, span_def in enumerate(X):

                span_features_complete = sequence_tensor[batch][span_def[0] : span_def[1] + 1]

                for i, _ in enumerate(span_features_complete):
                    features_from_span = span_features_complete[:, i]
                    real_max_value = max(features_from_span)
                    extracted_max_value = span_representations[batch, indices_ind, i]

                    assert real_max_value == extracted_max_value, (
                        f"Error extracting max value for "
                        f"batch {batch}, span {indices_ind} on dimension {i}."
                        f"expected {real_max_value} "
                        f"but got {extracted_max_value} which is "
                        f"not the maximum element."
                    )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 82:</b> &nbsp; 2 fragments, nominal size 16 lines, similarity 87%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1590')" href="javascript:;">
allennlp-2.9.0/tests/modules/time_distributed_test.py: 39-59
</a>
<div class="mid" id="frag1590" style="display:none"><pre>
    def test_time_distributed_reshapes_multiple_inputs_with_pass_through_tensor_correctly(self):
        class FakeModule(Module):
            def forward(self, input_tensor, tensor_to_pass_through=None, another_tensor=None):

                return input_tensor + tensor_to_pass_through + another_tensor

        module = FakeModule()
        distributed_module = TimeDistributed(module)

        input_tensor1 = torch.LongTensor([[[1, 2], [3, 4]]])
        input_to_pass_through = torch.LongTensor([3, 7])
        input_tensor2 = torch.LongTensor([[[4, 2], [9, 1]]])

        output = distributed_module(
            input_tensor1,
            tensor_to_pass_through=input_to_pass_through,
            another_tensor=input_tensor2,
            pass_through=["tensor_to_pass_through"],
        )
        assert_almost_equal(output.data.numpy(), [[[8, 11], [15, 12]]])

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1592')" href="javascript:;">
allennlp-2.9.0/tests/modules/time_distributed_test.py: 60-79
</a>
<div class="mid" id="frag1592" style="display:none"><pre>
    def test_time_distributed_reshapes_multiple_inputs_with_pass_through_non_tensor_correctly(self):
        class FakeModule(Module):
            def forward(self, input_tensor, number=0, another_tensor=None):

                return input_tensor + number + another_tensor

        module = FakeModule()
        distributed_module = TimeDistributed(module)

        input_tensor1 = torch.LongTensor([[[1, 2], [3, 4]]])
        input_number = 5
        input_tensor2 = torch.LongTensor([[[4, 2], [9, 1]]])

        output = distributed_module(
            input_tensor1,
            number=input_number,
            another_tensor=input_tensor2,
            pass_through=["number"],
        )
        assert_almost_equal(output.data.numpy(), [[[10, 9], [17, 10]]])
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 83:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 91%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1595')" href="javascript:;">
allennlp-2.9.0/tests/modules/augmented_lstm_test.py: 28-43
</a>
<div class="mid" id="frag1595" style="display:none"><pre>
    def test_variable_length_sequences_return_correctly_padded_outputs(self):
        sorted_tensor, sorted_sequence, _, _ = sort_batch_by_length(
            self.random_tensor, self.sequence_lengths
        )
        tensor = pack_padded_sequence(
            sorted_tensor, sorted_sequence.data.tolist(), batch_first=True
        )
        lstm = AugmentedLstm(10, 11)
        output, _ = lstm(tensor)
        output_sequence, _ = pad_packed_sequence(output, batch_first=True)

        numpy.testing.assert_array_equal(output_sequence.data[1, 6:, :].numpy(), 0.0)
        numpy.testing.assert_array_equal(output_sequence.data[2, 4:, :].numpy(), 0.0)
        numpy.testing.assert_array_equal(output_sequence.data[3, 3:, :].numpy(), 0.0)
        numpy.testing.assert_array_equal(output_sequence.data[4, 2:, :].numpy(), 0.0)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1596')" href="javascript:;">
allennlp-2.9.0/tests/modules/augmented_lstm_test.py: 44-59
</a>
<div class="mid" id="frag1596" style="display:none"><pre>
    def test_variable_length_sequences_run_backward_return_correctly_padded_outputs(self):
        sorted_tensor, sorted_sequence, _, _ = sort_batch_by_length(
            self.random_tensor, self.sequence_lengths
        )
        tensor = pack_padded_sequence(
            sorted_tensor, sorted_sequence.data.tolist(), batch_first=True
        )
        lstm = AugmentedLstm(10, 11, go_forward=False)
        output, _ = lstm(tensor)
        output_sequence, _ = pad_packed_sequence(output, batch_first=True)

        numpy.testing.assert_array_equal(output_sequence.data[1, 6:, :].numpy(), 0.0)
        numpy.testing.assert_array_equal(output_sequence.data[2, 4:, :].numpy(), 0.0)
        numpy.testing.assert_array_equal(output_sequence.data[3, 3:, :].numpy(), 0.0)
        numpy.testing.assert_array_equal(output_sequence.data[4, 2:, :].numpy(), 0.0)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 84:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1613')" href="javascript:;">
allennlp-2.9.0/tests/modules/seq2vec_encoders/pytorch_seq2vec_wrapper_test.py: 15-26
</a>
<div class="mid" id="frag1613" style="display:none"><pre>
    def test_get_dimensions_is_correct(self):
        lstm = LSTM(bidirectional=True, num_layers=3, input_size=2, hidden_size=7, batch_first=True)
        encoder = PytorchSeq2VecWrapper(lstm)
        assert encoder.get_output_dim() == 14
        assert encoder.get_input_dim() == 2
        lstm = LSTM(
            bidirectional=False, num_layers=3, input_size=2, hidden_size=7, batch_first=True
        )
        encoder = PytorchSeq2VecWrapper(lstm)
        assert encoder.get_output_dim() == 7
        assert encoder.get_input_dim() == 2

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1641')" href="javascript:;">
allennlp-2.9.0/tests/modules/seq2seq_encoders/pytorch_seq2seq_wrapper_test.py: 15-26
</a>
<div class="mid" id="frag1641" style="display:none"><pre>
    def test_get_dimension_is_correct(self):
        lstm = LSTM(bidirectional=True, num_layers=3, input_size=2, hidden_size=7, batch_first=True)
        encoder = PytorchSeq2SeqWrapper(lstm)
        assert encoder.get_output_dim() == 14
        assert encoder.get_input_dim() == 2
        lstm = LSTM(
            bidirectional=False, num_layers=3, input_size=2, hidden_size=7, batch_first=True
        )
        encoder = PytorchSeq2SeqWrapper(lstm)
        assert encoder.get_output_dim() == 7
        assert encoder.get_input_dim() == 2

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 85:</b> &nbsp; 4 fragments, nominal size 23 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1615')" href="javascript:;">
allennlp-2.9.0/tests/modules/seq2vec_encoders/pytorch_seq2vec_wrapper_test.py: 35-63
</a>
<div class="mid" id="frag1615" style="display:none"><pre>
    def test_forward_pulls_out_correct_tensor_with_sequence_lengths(self):
        lstm = LSTM(bidirectional=True, num_layers=3, input_size=3, hidden_size=7, batch_first=True)
        encoder = PytorchSeq2VecWrapper(lstm)

        input_tensor = torch.rand([5, 7, 3])
        input_tensor[1, 6:, :] = 0
        input_tensor[2, 4:, :] = 0
        input_tensor[3, 2:, :] = 0
        input_tensor[4, 1:, :] = 0
        mask = torch.ones(5, 7).bool()
        mask[1, 6:] = False
        mask[2, 4:] = False
        mask[3, 2:] = False
        mask[4, 1:] = False

        sequence_lengths = get_lengths_from_binary_sequence_mask(mask)
        packed_sequence = pack_padded_sequence(
            input_tensor, sequence_lengths.tolist(), batch_first=True
        )
        _, state = lstm(packed_sequence)
        # Transpose output state, extract the last forward and backward states and
        # reshape to be of dimension (batch_size, 2 * hidden_size).
        reshaped_state = state[0].transpose(0, 1)[:, -2:, :].contiguous()
        explicitly_concatenated_state = torch.cat(
            [reshaped_state[:, 0, :].squeeze(1), reshaped_state[:, 1, :].squeeze(1)], -1
        )
        encoder_output = encoder(input_tensor, mask)
        assert_almost_equal(encoder_output.data.numpy(), explicitly_concatenated_state.data.numpy())

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1617')" href="javascript:;">
allennlp-2.9.0/tests/modules/seq2vec_encoders/pytorch_seq2vec_wrapper_test.py: 88-120
</a>
<div class="mid" id="frag1617" style="display:none"><pre>
    def test_forward_pulls_out_correct_tensor_with_unsorted_batches(self):
        lstm = LSTM(bidirectional=True, num_layers=3, input_size=3, hidden_size=7, batch_first=True)
        encoder = PytorchSeq2VecWrapper(lstm)

        input_tensor = torch.rand([5, 7, 3])
        input_tensor[0, 3:, :] = 0
        input_tensor[1, 4:, :] = 0
        input_tensor[2, 2:, :] = 0
        input_tensor[3, 6:, :] = 0
        mask = torch.ones(5, 7).bool()
        mask[0, 3:] = False
        mask[1, 4:] = False
        mask[2, 2:] = False
        mask[3, 6:] = False

        sequence_lengths = get_lengths_from_binary_sequence_mask(mask)
        sorted_inputs, sorted_sequence_lengths, restoration_indices, _ = sort_batch_by_length(
            input_tensor, sequence_lengths
        )
        packed_sequence = pack_padded_sequence(
            sorted_inputs, sorted_sequence_lengths.tolist(), batch_first=True
        )
        _, state = lstm(packed_sequence)
        # Transpose output state, extract the last forward and backward states and
        # reshape to be of dimension (batch_size, 2 * hidden_size).
        sorted_transposed_state = state[0].transpose(0, 1).index_select(0, restoration_indices)
        reshaped_state = sorted_transposed_state[:, -2:, :].contiguous()
        explicitly_concatenated_state = torch.cat(
            [reshaped_state[:, 0, :].squeeze(1), reshaped_state[:, 1, :].squeeze(1)], -1
        )
        encoder_output = encoder(input_tensor, mask)
        assert_almost_equal(encoder_output.data.numpy(), explicitly_concatenated_state.data.numpy())

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1644')" href="javascript:;">
allennlp-2.9.0/tests/modules/seq2seq_encoders/pytorch_seq2seq_wrapper_test.py: 57-79
</a>
<div class="mid" id="frag1644" style="display:none"><pre>
    def test_forward_pulls_out_correct_tensor_with_sequence_lengths(self):
        lstm = LSTM(bidirectional=True, num_layers=3, input_size=3, hidden_size=7, batch_first=True)
        encoder = PytorchSeq2SeqWrapper(lstm)
        input_tensor = torch.rand([5, 7, 3])
        input_tensor[1, 6:, :] = 0
        input_tensor[2, 4:, :] = 0
        input_tensor[3, 2:, :] = 0
        input_tensor[4, 1:, :] = 0
        mask = torch.ones(5, 7).bool()
        mask[1, 6:] = False
        mask[2, 4:] = False
        mask[3, 2:] = False
        mask[4, 1:] = False

        sequence_lengths = get_lengths_from_binary_sequence_mask(mask)
        packed_sequence = pack_padded_sequence(
            input_tensor, sequence_lengths.data.tolist(), batch_first=True
        )
        lstm_output, _ = lstm(packed_sequence)
        encoder_output = encoder(input_tensor, mask)
        lstm_tensor, _ = pad_packed_sequence(lstm_output, batch_first=True)
        assert_almost_equal(encoder_output.data.numpy(), lstm_tensor.data.numpy())

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1645')" href="javascript:;">
allennlp-2.9.0/tests/modules/seq2seq_encoders/pytorch_seq2seq_wrapper_test.py: 80-108
</a>
<div class="mid" id="frag1645" style="display:none"><pre>
    def test_forward_pulls_out_correct_tensor_for_unsorted_batches(self):
        lstm = LSTM(bidirectional=True, num_layers=3, input_size=3, hidden_size=7, batch_first=True)
        encoder = PytorchSeq2SeqWrapper(lstm)
        input_tensor = torch.rand([5, 7, 3])
        input_tensor[0, 3:, :] = 0
        input_tensor[1, 4:, :] = 0
        input_tensor[2, 2:, :] = 0
        input_tensor[3, 6:, :] = 0
        mask = torch.ones(5, 7).bool()
        mask[0, 3:] = False
        mask[1, 4:] = False
        mask[2, 2:] = False
        mask[3, 6:] = False

        sequence_lengths = get_lengths_from_binary_sequence_mask(mask)
        sorted_inputs, sorted_sequence_lengths, restoration_indices, _ = sort_batch_by_length(
            input_tensor, sequence_lengths
        )
        packed_sequence = pack_padded_sequence(
            sorted_inputs, sorted_sequence_lengths.data.tolist(), batch_first=True
        )
        lstm_output, _ = lstm(packed_sequence)
        encoder_output = encoder(input_tensor, mask)
        lstm_tensor, _ = pad_packed_sequence(lstm_output, batch_first=True)
        assert_almost_equal(
            encoder_output.data.numpy(),
            lstm_tensor.index_select(0, restoration_indices).data.numpy(),
        )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 86:</b> &nbsp; 2 fragments, nominal size 19 lines, similarity 89%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1616')" href="javascript:;">
allennlp-2.9.0/tests/modules/seq2vec_encoders/pytorch_seq2vec_wrapper_test.py: 64-87
</a>
<div class="mid" id="frag1616" style="display:none"><pre>
    def test_forward_works_even_with_empty_sequences(self):
        lstm = LSTM(
            bidirectional=True, num_layers=3, input_size=3, hidden_size=11, batch_first=True
        )
        encoder = PytorchSeq2VecWrapper(lstm)

        tensor = torch.rand([5, 7, 3])
        tensor[1, 6:, :] = 0
        tensor[2, :, :] = 0
        tensor[3, 2:, :] = 0
        tensor[4, :, :] = 0
        mask = torch.ones(5, 7).bool()
        mask[1, 6:] = False
        mask[2, :] = False
        mask[3, 2:] = False
        mask[4, :] = False

        results = encoder(tensor, mask)

        for i in (0, 1, 3):
            assert not (results[i] == 0.0).data.all()
        for i in (2, 4):
            assert (results[i] == 0.0).data.all()

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1642')" href="javascript:;">
allennlp-2.9.0/tests/modules/seq2seq_encoders/pytorch_seq2seq_wrapper_test.py: 27-48
</a>
<div class="mid" id="frag1642" style="display:none"><pre>
    def test_forward_works_even_with_empty_sequences(self):
        lstm = LSTM(bidirectional=True, num_layers=3, input_size=3, hidden_size=7, batch_first=True)
        encoder = PytorchSeq2SeqWrapper(lstm)

        tensor = torch.rand([5, 7, 3])
        tensor[1, 6:, :] = 0
        tensor[2, :, :] = 0
        tensor[3, 2:, :] = 0
        tensor[4, :, :] = 0
        mask = torch.ones(5, 7).bool()
        mask[1, 6:] = False
        mask[2, :] = False
        mask[3, 2:] = False
        mask[4, :] = False

        results = encoder(tensor, mask)

        for i in (0, 1, 3):
            assert not (results[i] == 0.0).data.all()
        for i in (2, 4):
            assert (results[i] == 0.0).data.all()

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 87:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 71%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1638')" href="javascript:;">
allennlp-2.9.0/tests/modules/seq2seq_encoders/gated_cnn_encoder_test.py: 8-21
</a>
<div class="mid" id="frag1638" style="display:none"><pre>
    def test_gated_cnn_encoder(self):
        cnn_encoder = GatedCnnEncoder(
            input_dim=32,
            layers=[[[4, 32]], [[1, 16], [5, 16], [1, 32]], [[1, 64], [5, 64], [1, 32]]],
        )

        token_embeddings = torch.rand(5, 10, 32)
        mask = torch.ones(5, 10).bool()
        mask[0, 7:] = False
        mask[1, 5:] = False

        output = cnn_encoder(token_embeddings, mask)
        assert list(output.size()) == [5, 10, 64]

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1640')" href="javascript:;">
allennlp-2.9.0/tests/modules/seq2seq_encoders/gated_cnn_encoder_test.py: 35-50
</a>
<div class="mid" id="frag1640" style="display:none"><pre>
    def test_gated_cnn_encoder_layers(self):
        cnn_encoder = GatedCnnEncoder(
            input_dim=32,
            layers=[[[4, 32]], [[1, 16], [5, 16], [1, 32]], [[1, 64], [5, 64], [1, 32]]],
            return_all_layers=True,
        )

        token_embeddings = torch.rand(5, 10, 32)
        mask = torch.ones(5, 10).bool()
        mask[0, 7:] = False
        mask[1, 5:] = False

        output = cnn_encoder(token_embeddings, mask)
        assert len(output) == 3
        concat_layers = torch.cat([layer.unsqueeze(1) for layer in output], dim=1)
        assert list(concat_layers.size()) == [5, 3, 10, 64]
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 88:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1648')" href="javascript:;">
allennlp-2.9.0/tests/modules/seq2seq_encoders/pytorch_seq2seq_wrapper_test.py: 127-141
</a>
<div class="mid" id="frag1648" style="display:none"><pre>
    def test_wrapper_works_when_passed_state_with_zero_length_sequences(self):
        lstm = LSTM(bidirectional=True, num_layers=3, input_size=3, hidden_size=7, batch_first=True)
        encoder = PytorchSeq2SeqWrapper(lstm)
        input_tensor = torch.rand([5, 7, 3])
        mask = torch.ones(5, 7).bool()
        mask[0, 3:] = False
        mask[1, 4:] = False
        mask[2, 0:] = False
        mask[3, 6:] = False

        # Initial states are of shape (num_layers * num_directions, batch_size, hidden_dim)
        initial_states = torch.randn(6, 5, 7), torch.randn(6, 5, 7)

        _ = encoder(input_tensor, mask, initial_states)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1649')" href="javascript:;">
allennlp-2.9.0/tests/modules/seq2seq_encoders/pytorch_seq2seq_wrapper_test.py: 142-155
</a>
<div class="mid" id="frag1649" style="display:none"><pre>
    def test_wrapper_can_call_backward_with_zero_length_sequences(self):
        lstm = LSTM(bidirectional=True, num_layers=3, input_size=3, hidden_size=7, batch_first=True)
        encoder = PytorchSeq2SeqWrapper(lstm)
        input_tensor = torch.rand([5, 7, 3])
        mask = torch.ones(5, 7).bool()
        mask[0, 3:] = False
        mask[1, 4:] = False
        mask[2, 0:] = 0  # zero length False
        mask[3, 6:] = False

        output = encoder(input_tensor, mask)

        output.sum().backward()

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<script language="JavaScript">
function ShowHide(divId) { 
    if(document.getElementById(divId).style.display == 'none') {
        document.getElementById(divId).style.display='block';
    } else { 
        document.getElementById(divId).style.display = 'none';
    } 
}
</script>
</body>
</html>
