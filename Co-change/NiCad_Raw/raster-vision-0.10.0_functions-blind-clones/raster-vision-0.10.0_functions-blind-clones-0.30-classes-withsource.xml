<clones>
<systeminfo processor="nicad6" system="raster-vision-0.10.0" granularity="functions-blind" threshold="30%" minlines="10" maxlines="2500"/>
<cloneinfo npcs="2011" npairs="165"/>
<runinfo ncompares="55440" cputime="68789"/>
<classinfo nclasses="53"/>

<class classid="1" nclones="4" nlines="18" similarity="84">
<source file="systems/raster-vision-0.10.0/rastervision/backend/pytorch_semantic_segmentation_config.py" startline="13" endline="32" pcid="33">
    def __init__(self,
                 batch_size=None,
                 lr=None,
                 one_cycle=None,
                 num_epochs=None,
                 model_arch=None,
                 sync_interval=None,
                 debug=None,
                 log_tensorboard=None,
                 run_tensorboard=None):
        self.batch_size = batch_size
        self.lr = lr
        self.one_cycle = one_cycle
        self.num_epochs = num_epochs
        self.model_arch = model_arch
        self.sync_interval = sync_interval
        self.debug = debug
        self.log_tensorboard = log_tensorboard
        self.run_tensorboard = run_tensorboard

</source>
<source file="systems/raster-vision-0.10.0/rastervision/backend/pytorch_chip_classification_config.py" startline="13" endline="32" pcid="158">
    def __init__(self,
                 batch_size=None,
                 lr=None,
                 one_cycle=None,
                 num_epochs=None,
                 model_arch=None,
                 sync_interval=None,
                 debug=None,
                 log_tensorboard=None,
                 run_tensorboard=None):
        self.batch_size = batch_size
        self.lr = lr
        self.one_cycle = one_cycle
        self.num_epochs = num_epochs
        self.model_arch = model_arch
        self.sync_interval = sync_interval
        self.debug = debug
        self.log_tensorboard = log_tensorboard
        self.run_tensorboard = run_tensorboard

</source>
<source file="systems/raster-vision-0.10.0/rastervision/backend/pytorch_object_detection_config.py" startline="13" endline="32" pcid="38">
    def __init__(self,
                 batch_size=None,
                 lr=None,
                 one_cycle=None,
                 num_epochs=None,
                 model_arch=None,
                 sync_interval=None,
                 log_tensorboard=None,
                 run_tensorboard=None,
                 debug=None):
        self.batch_size = batch_size
        self.lr = lr
        self.one_cycle = one_cycle
        self.num_epochs = num_epochs
        self.model_arch = model_arch
        self.sync_interval = sync_interval
        self.log_tensorboard = log_tensorboard
        self.run_tensorboard = run_tensorboard
        self.debug = debug

</source>
<source file="systems/raster-vision-0.10.0/rastervision/evaluation/class_evaluation_item.py" startline="13" endline="32" pcid="1102">
    def __init__(self,
                 precision=None,
                 recall=None,
                 f1=None,
                 count_error=None,
                 gt_count=0,
                 class_id=None,
                 class_name=None,
                 conf_mat=None):
        self.precision = precision
        self.recall = recall
        self.f1 = f1
        self.count_error = count_error
        # Ground truth count of elements (boxes for object detection, pixels
        # for segmentation, cells for classification).
        self.gt_count = gt_count
        self.conf_mat = conf_mat
        self.class_id = class_id
        self.class_name = class_name

</source>
</class>

<class classid="2" nclones="3" nlines="22" similarity="100">
<source file="systems/raster-vision-0.10.0/rastervision/backend/pytorch_semantic_segmentation_config.py" startline="51" endline="100" pcid="36">
    def with_train_options(self,
                           batch_size=8,
                           lr=1e-4,
                           one_cycle=True,
                           num_epochs=5,
                           model_arch='resnet50',
                           sync_interval=1,
                           debug=False,
                           log_tensorboard=True,
                           run_tensorboard=True):
        """Set options for training models.

        Args:
            batch_size: (int) the batch size
            lr: (float) the learning rate if using a fixed LR
                (ie. one_cycle is False),
                or the maximum LR to use if one_cycle is True
            one_cycle: (bool) True if cyclic learning rate scheduler should
                be used. This
                cycles the LR once during the course of training and seems to
                result in a pretty consistent improvement. See lr for more
                details.
            num_epochs: (int) number of epochs (sweeps through training set) to
                train model for
            model_arch: (str) classification model backbone to use for DeepLabV3
                architecture. Currently, only Resnet50 works.
            sync_interval: (int) sync training directory to cloud every
                sync_interval epochs.
            debug: (bool) if True, save debug chips (ie. visualizations of
                input to model during training) during training and use
                single-core for creating minibatches.
            log_tensorboard: (bool) if True, write events to Tensorboard log
                file
            run_tensorboard: (bool) if True, run a Tensorboard server at
                port 6006 that uses the logs generated by the log_tensorboard
                option
        """
        b = deepcopy(self)
        b.train_opts = TrainOptions(
            batch_size=batch_size,
            lr=lr,
            one_cycle=one_cycle,
            num_epochs=num_epochs,
            model_arch=model_arch,
            sync_interval=sync_interval,
            debug=debug,
            log_tensorboard=log_tensorboard,
            run_tensorboard=run_tensorboard)
        return b

</source>
<source file="systems/raster-vision-0.10.0/rastervision/backend/pytorch_object_detection_config.py" startline="52" endline="102" pcid="41">
    def with_train_options(self,
                           batch_size=8,
                           lr=1e-4,
                           one_cycle=True,
                           num_epochs=5,
                           model_arch='resnet18',
                           sync_interval=1,
                           log_tensorboard=True,
                           run_tensorboard=True,
                           debug=False):
        """Set options for training models.

        Args:
            batch_size: (int) the batch size
            lr: (float) the learning rate if using a fixed LR
                (ie. one_cycle is False),
                or the maximum LR to use if one_cycle is True
            one_cycle: (bool) True if cyclic learning rate scheduler should
                be used. This
                cycles the LR once during the course of training and seems to
                result in a pretty consistent improvement. See lr for more
                details.
            num_epochs: (int) number of epochs (sweeps through training set) to
                train model for
            model_arch: (str) classification model backbone to use.
                Any Resnet option in torchvision.models is valid,
                for example, resnet18.
            sync_interval: (int) sync training directory to cloud every
                sync_interval epochs.
            log_tensorboard: (bool) if True, write events to Tensorboard log
                file
            run_tensorboard: (bool) if True, run a Tensorboard server at
                port 6006 that uses the logs generated by the log_tensorboard
                option
            debug: (bool) if True, save debug chips (ie. visualizations of
                input to model during training) during training and use
                single-core for creating minibatches.
        """
        b = deepcopy(self)
        b.train_opts = TrainOptions(
            batch_size=batch_size,
            lr=lr,
            one_cycle=one_cycle,
            num_epochs=num_epochs,
            model_arch=model_arch,
            sync_interval=sync_interval,
            log_tensorboard=log_tensorboard,
            run_tensorboard=run_tensorboard,
            debug=debug)
        return b

</source>
<source file="systems/raster-vision-0.10.0/rastervision/backend/pytorch_chip_classification_config.py" startline="51" endline="102" pcid="161">
    def with_train_options(self,
                           batch_size=8,
                           lr=1e-4,
                           one_cycle=True,
                           num_epochs=1,
                           model_arch='resnet18',
                           sync_interval=1,
                           debug=False,
                           log_tensorboard=True,
                           run_tensorboard=True):
        """Set options for training models.

        Args:
            batch_size: (int) the batch size
            weight_decay: (float) the weight decay
            lr: (float) the learning rate if using a fixed LR
                (ie. one_cycle is False),
                or the maximum LR to use if one_cycle is True
            one_cycle: (bool) True if cyclic learning rate scheduler should
                be used. This
                cycles the LR once during the course of training and seems to
                result in a pretty consistent improvement. See lr for more
                details.
            num_epochs: (int) number of epochs (sweeps through training set) to
                train model for
            model_arch: (str) classification model backbone to use for UNet
                architecture. Any option in torchvision.models is valid, for
                example, resnet18.
            sync_interval: (int) sync training directory to cloud every
                sync_interval epochs.
            debug: (bool) if True, save debug chips (ie. visualizations of
                input to model during training) during training and use
                single-core for creating minibatches.
            log_tensorboard: (bool) if True, write events to Tensorboard log
                file
            run_tensorboard: (bool) if True, run a Tensorboard server at
                port 6006 that uses the logs generated by the log_tensorboard
                option
        """
        b = deepcopy(self)
        b.train_opts = TrainOptions(
            batch_size=batch_size,
            lr=lr,
            one_cycle=one_cycle,
            num_epochs=num_epochs,
            model_arch=model_arch,
            sync_interval=sync_interval,
            debug=debug,
            log_tensorboard=log_tensorboard,
            run_tensorboard=run_tensorboard)
        return b

</source>
</class>

<class classid="3" nclones="2" nlines="11" similarity="72">
<source file="systems/raster-vision-0.10.0/rastervision/backend/keras_classification/utils.py" startline="16" endline="31" pcid="48">
def make_dir(path, check_empty=False, force_empty=False, use_dirname=False):
    directory = path
    if use_dirname:
        directory = os.path.dirname(path)

    if force_empty and os.path.isdir(directory):
        shutil.rmtree(directory)

    os.makedirs(directory, exist_ok=True)

    is_empty = len(os.listdir(directory)) == 0
    if check_empty and not is_empty:
        raise ValueError(
            '{} needs to be an empty directory!'.format(directory))


</source>
<source file="systems/raster-vision-0.10.0/rastervision/filesystem/local_filesystem.py" startline="9" endline="35" pcid="280">
def make_dir(path, check_empty=False, force_empty=False, use_dirname=False):
    """Make a local directory.

    Args:
        path: path to directory
        check_empty: if True, check that directory is empty
        force_empty: if True, delete files if necessary to make directory
            empty
        use_dirname: if path is a file, use the the parent directory as path

    Raises:
        ValueError if check_empty is True and directory is not empty
    """
    directory = path
    if use_dirname:
        directory = os.path.abspath(os.path.dirname(path))

    if force_empty and os.path.isdir(directory):
        shutil.rmtree(directory)

    os.makedirs(directory, exist_ok=True)

    if check_empty and any(os.scandir(directory)):
        raise ValueError(
            '{} needs to be an empty directory!'.format(directory))


</source>
</class>

<class classid="4" nclones="2" nlines="22" similarity="86">
<source file="systems/raster-vision-0.10.0/rastervision/backend/torch_utils/semantic_segmentation/data.py" startline="49" endline="76" pcid="89">
def build_databunch(data_dir, img_sz, batch_sz, class_names):
    # set to zero to prevent "dataloader is killed by signal"
    # TODO fix this
    num_workers = 0

    train_dir = join(data_dir, 'train')
    valid_dir = join(data_dir, 'valid')

    aug_transforms = ComposeTransforms([ToTensor()])
    transforms = ComposeTransforms([ToTensor()])

    train_ds = SegmentationDataset(train_dir, transforms=aug_transforms)
    valid_ds = SegmentationDataset(valid_dir, transforms=transforms)

    train_dl = DataLoader(
        train_ds,
        shuffle=True,
        batch_size=batch_sz,
        num_workers=num_workers,
        drop_last=True,
        pin_memory=True)
    valid_dl = DataLoader(
        valid_ds,
        batch_size=batch_sz,
        num_workers=num_workers,
        pin_memory=True)

    return DataBunch(train_ds, train_dl, valid_ds, valid_dl, class_names)
</source>
<source file="systems/raster-vision-0.10.0/rastervision/backend/torch_utils/chip_classification/data.py" startline="11" endline="37" pcid="142">
def build_databunch(data_dir, img_sz, batch_sz, class_names):
    num_workers = 4

    train_dir = join(data_dir, 'train')
    valid_dir = join(data_dir, 'valid')

    aug_transform = Compose([ToTensor()])
    transform = Compose([ToTensor()])

    train_ds = ImageFolder(
        train_dir, transform=aug_transform, classes=class_names)
    valid_ds = ImageFolder(valid_dir, transform=transform, classes=class_names)

    train_dl = DataLoader(
        train_ds,
        shuffle=True,
        batch_size=batch_sz,
        num_workers=num_workers,
        drop_last=True,
        pin_memory=True)
    valid_dl = DataLoader(
        valid_ds,
        batch_size=batch_sz,
        num_workers=num_workers,
        pin_memory=True)

    return DataBunch(train_ds, train_dl, valid_ds, valid_dl, class_names)
</source>
</class>

<class classid="5" nclones="2" nlines="18" similarity="94">
<source file="systems/raster-vision-0.10.0/rastervision/backend/torch_utils/semantic_segmentation/train.py" startline="7" endline="29" pcid="90">
def train_epoch(model, device, data_loader, opt, loss_fn, step_scheduler=None):
    model.train()
    total_loss = 0.0
    num_samples = 0

    with click.progressbar(data_loader, label='Training') as bar:
        for batch_ind, (x, y) in enumerate(bar):
            x = x.to(device)
            y = y.to(device)

            opt.zero_grad()
            out = model(x)['out']
            loss = loss_fn(out, y)
            loss.backward()
            total_loss += loss.item()
            opt.step()
            if step_scheduler:
                step_scheduler.step()
            num_samples += x.shape[0]

    return total_loss / num_samples


</source>
<source file="systems/raster-vision-0.10.0/rastervision/backend/torch_utils/chip_classification/train.py" startline="7" endline="29" pcid="143">
def train_epoch(model, device, data_loader, opt, loss_fn, step_scheduler=None):
    model.train()
    total_loss = 0.0
    num_samples = 0

    with click.progressbar(data_loader, label='Training') as bar:
        for batch_ind, (x, y) in enumerate(bar):
            x = x.to(device)
            y = y.to(device)

            opt.zero_grad()
            out = model(x)
            loss = loss_fn(out, y)
            loss.backward()
            total_loss += loss.item()
            opt.step()
            if step_scheduler:
                step_scheduler.step()
            num_samples += x.shape[0]

    return total_loss / num_samples


</source>
</class>

<class classid="6" nclones="2" nlines="17" similarity="76">
<source file="systems/raster-vision-0.10.0/rastervision/backend/torch_utils/semantic_segmentation/train.py" startline="30" endline="51" pcid="91">
def validate_epoch(model, device, data_loader, num_labels):
    model.eval()

    conf_mat = torch.zeros((num_labels, num_labels))
    with torch.no_grad():
        with click.progressbar(data_loader, label='Validating') as bar:
            for batch_ind, (x, y) in enumerate(bar):
                x = x.to(device)
                out = model(x)['out']

                out = out.argmax(1).view(-1).cpu()
                y = y.view(-1).cpu()
                if batch_ind == 0:
                    labels = torch.arange(0, num_labels)

                conf_mat += ((out == labels[:, None]) &
                             (y == labels[:, None, None])).sum(
                                 dim=2, dtype=torch.float32)

    # Ignore index zero.
    conf_mat = conf_mat[1:, 1:]
    return compute_conf_mat_metrics(conf_mat)
</source>
<source file="systems/raster-vision-0.10.0/rastervision/backend/torch_utils/chip_classification/train.py" startline="30" endline="49" pcid="144">
def validate_epoch(model, device, data_loader, num_labels):
    model.eval()

    conf_mat = torch.zeros((num_labels, num_labels))
    with torch.no_grad():
        with click.progressbar(data_loader, label='Validating') as bar:
            for batch_ind, (x, y) in enumerate(bar):
                x = x.to(device)
                out = model(x)

                out = out.argmax(-1).view(-1).cpu()
                y = y.cpu()
                if batch_ind == 0:
                    labels = torch.arange(0, num_labels)

                conf_mat += ((out == labels[:, None]) &
                             (y == labels[:, None, None])).sum(
                                 dim=2, dtype=torch.float32)

    return compute_conf_mat_metrics(conf_mat)
</source>
</class>

<class classid="7" nclones="3" nlines="19" similarity="94">
<source file="systems/raster-vision-0.10.0/rastervision/backend/pytorch_semantic_segmentation.py" startline="40" endline="78" pcid="147">
def make_debug_chips(databunch, class_map, tmp_dir, train_uri, max_count=30):
    """Save debug chips for a Databunch for a semantic segmentation dataset.

    This saves a plot for each example in the training and validation sets into
    train-debug-chips.zip and valid-debug-chips.zip under the train_uri. This
    is useful for making sure we are feeding correct data into the model.

    Args:
        databunch: DataBunch for semantic segmentation
        class_map: (rv.ClassMap) class map used to map class ids to colors
        tmp_dir: (str) path to temp directory
        train_uri: (str) URI of root of training output
        max_count: (int) maximum number of chips to generate. If None,
            generates all of them.
    """

    def _make_debug_chips(split):
        debug_chips_dir = join(tmp_dir, '{}-debug-chips'.format(split))
        zip_path = join(tmp_dir, '{}-debug-chips.zip'.format(split))
        zip_uri = join(train_uri, '{}-debug-chips.zip'.format(split))
        make_dir(debug_chips_dir)
        ds = databunch.train_ds if split == 'train' else databunch.valid_ds
        for i, (x, y) in enumerate(ds):
            if i >= max_count:
                break

            fig, ax = plt.subplots(1)
            plot_xy(ax, x, class_map, y=y)
            plt.savefig(
                join(debug_chips_dir, '{}.png'.format(i)), figsize=(6, 6))
            plt.close()

        zipdir(debug_chips_dir, zip_path)
        upload_or_copy(zip_path, zip_uri)

    _make_debug_chips('train')
    _make_debug_chips('valid')


</source>
<source file="systems/raster-vision-0.10.0/rastervision/backend/pytorch_chip_classification.py" startline="39" endline="77" pcid="223">
def make_debug_chips(databunch, class_map, tmp_dir, train_uri, max_count=30):
    """Save debug chips for a Databunch for a chip classification dataset

    This saves a plot for each example in the training and validation sets into
    train-debug-chips.zip and valid-debug-chips.zip under the train_uri. This
    is useful for making sure we are feeding correct data into the model.

    Args:
        databunch: DataBunch for chip classification
        class_map: (rv.ClassMap) class map used to map class ids to colors
        tmp_dir: (str) path to temp directory
        train_uri: (str) URI of root of training output
        max_count: (int) maximum number of chips to generate. If None,
            generates all of them.
    """

    def _make_debug_chips(split):
        debug_chips_dir = join(tmp_dir, '{}-debug-chips'.format(split))
        zip_path = join(tmp_dir, '{}-debug-chips.zip'.format(split))
        zip_uri = join(train_uri, '{}-debug-chips.zip'.format(split))
        make_dir(debug_chips_dir)
        ds = databunch.train_ds if split == 'train' else databunch.valid_ds
        for i, (x, y) in enumerate(ds):
            if i >= max_count:
                break

            fig, ax = plt.subplots(1)
            plot_xy(ax, x, y, databunch.label_names)
            plt.savefig(
                join(debug_chips_dir, '{}.png'.format(i)), figsize=(6, 6))
            plt.close()

        zipdir(debug_chips_dir, zip_path)
        upload_or_copy(zip_path, zip_uri)

    _make_debug_chips('train')
    _make_debug_chips('valid')


</source>
<source file="systems/raster-vision-0.10.0/rastervision/backend/pytorch_object_detection.py" startline="37" endline="75" pcid="199">
def make_debug_chips(databunch, class_map, tmp_dir, train_uri, max_count=30):
    """Save debug chips for a DataBunch.

    This saves a plot for each example in the training and validation sets into
    train-debug-chips.zip and valid-debug-chips.zip under the train_uri. This
    is useful for making sure we are feeding correct data into the model.

    Args:
        data: DataBunch for an object detection problem
        class_map: (rv.ClassMap) class map used to map class ids to colors
        tmp_dir: (str) path to temp directory
        train_uri: (str) URI of root of training output
        max_count: (int) maximum number of chips to generate. If None,
            generates all of them.
    """

    def _make_debug_chips(split):
        debug_chips_dir = join(tmp_dir, '{}-debug-chips'.format(split))
        zip_path = join(tmp_dir, '{}-debug-chips.zip'.format(split))
        zip_uri = join(train_uri, '{}-debug-chips.zip'.format(split))
        make_dir(debug_chips_dir)
        ds = databunch.train_ds if split == 'train' else databunch.valid_ds
        for i, (x, y) in enumerate(ds):
            if i >= max_count:
                break

            fig, ax = plt.subplots(1)
            plot_xy(ax, x, y, ds.label_names)
            plt.savefig(
                join(debug_chips_dir, '{}.png'.format(i)), figsize=(6, 6))
            plt.close()

        zipdir(debug_chips_dir, zip_path)
        upload_or_copy(zip_path, zip_uri)

    _make_debug_chips('train')
    _make_debug_chips('val')


</source>
</class>

<class classid="8" nclones="3" nlines="11" similarity="83">
<source file="systems/raster-vision-0.10.0/rastervision/backend/pytorch_semantic_segmentation.py" startline="82" endline="104" pcid="149">
    def __init__(self, task_config, backend_opts, train_opts):
        """Constructor.

        Args:
            task_config: (SemanticSegmentationConfig)
            backend_opts: (simple_backend_config.BackendOptions)
            train_opts: (pytorch_semantic_segmentation_backend_config.TrainOptions)
        """
        self.task_config = task_config
        self.backend_opts = backend_opts
        self.train_opts = train_opts
        self.inf_learner = None

        torch_cache_dir = '/opt/data/torch-cache'
        os.environ['TORCH_HOME'] = torch_cache_dir

        self.model = None
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        log.info('Device = {}'.format(self.device))
        # TODO move this into the SemanticSegmentation RV task
        self.class_map = self.task_config.class_map.copy()
        self.class_map.add_nodata_item()

</source>
<source file="systems/raster-vision-0.10.0/rastervision/backend/pytorch_object_detection.py" startline="79" endline="99" pcid="201">
    def __init__(self, task_config, backend_opts, train_opts):
        """Constructor.

        Args:
            task_config: (ChipClassificationConfig)
            backend_opts: (simple_backend_config.BackendOptions)
            train_opts: (pytorch_chip_classification_config.TrainOptions)
        """
        self.task_config = task_config
        self.backend_opts = backend_opts
        self.train_opts = train_opts
        self.inf_learner = None

        # Setup caching for torchvision pretrained models.
        torch_cache_dir = '/opt/data/torch-cache'
        os.environ['TORCH_HOME'] = torch_cache_dir

        self.model = None
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        log.info('Device = {}'.format(self.device))

</source>
<source file="systems/raster-vision-0.10.0/rastervision/backend/pytorch_chip_classification.py" startline="81" endline="100" pcid="225">
    def __init__(self, task_config, backend_opts, train_opts):
        """Constructor.

        Args:
            task_config: (ChipClassificationConfig)
            backend_opts: (simple_backend_config.BackendOptions)
            train_opts: (pytorch_chip_classification_config.TrainOptions)
        """
        self.task_config = task_config
        self.backend_opts = backend_opts
        self.train_opts = train_opts
        self.inf_learner = None

        torch_cache_dir = '/opt/data/torch-cache'
        os.environ['TORCH_HOME'] = torch_cache_dir

        self.model = None
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        log.info('Device = {}'.format(self.device))

</source>
</class>

<class classid="9" nclones="3" nlines="19" similarity="71">
<source file="systems/raster-vision-0.10.0/rastervision/backend/pytorch_semantic_segmentation.py" startline="142" endline="187" pcid="152">
    def process_sceneset_results(self, training_results, validation_results,
                                 tmp_dir):
        """Write zip file with chips for a set of scenes.

        This writes a zip file for a group of scenes at {chip_uri}/{uuid}.zip containing:
        train/img/{scene_id}-{ind}.png
        train/labels/{scene_id}-{ind}.png
        val/img/{scene_id}-{ind}.png
        val/labels/{scene_id}-{ind}.png

        This method is called once per instance of the chip command.
        A number of instances of the chip command can run simultaneously to
        process chips in parallel. The uuid in the path above is what allows
        separate instances to avoid overwriting each others' output.

        Args:
            training_results: list of directories generated by process_scene_data
                that all hold training chips
            validation_results: list of directories generated by process_scene_data
                that all hold validation chips
        """
        self.log_options()

        group = str(uuid.uuid4())
        group_uri = join(self.backend_opts.chip_uri, '{}.zip'.format(group))
        group_path = get_local_path(group_uri, tmp_dir)
        make_dir(group_path, use_dirname=True)

        with zipfile.ZipFile(group_path, 'w', zipfile.ZIP_DEFLATED) as zipf:

            def _write_zip(results, split):
                for scene_dir in results:
                    scene_paths = glob.glob(join(scene_dir, '**/*.png'))
                    for p in scene_paths:
                        zipf.write(
                            p,
                            join(
                                '{}/{}'.format(split,
                                               dirname(p).split('/')[-1]),
                                basename(p)))

            _write_zip(training_results, 'train')
            _write_zip(validation_results, 'valid')

        upload_or_copy(group_path, group_uri)

</source>
<source file="systems/raster-vision-0.10.0/rastervision/backend/pytorch_chip_classification.py" startline="137" endline="176" pcid="228">
    def process_sceneset_results(self, training_results, validation_results,
                                 tmp_dir):
        """Write zip file with chips for a set of scenes.

        This writes a zip file for a group of scenes at {chip_uri}/{uuid}.zip containing:
        train-img/{class_name}/{scene_id}-{ind}.png
        valid-img/{class_name}/{scene_id}-{ind}.png

        This method is called once per instance of the chip command.
        A number of instances of the chip command can run simultaneously to
        process chips in parallel. The uuid in the path above is what allows
        separate instances to avoid overwriting each others' output.

        Args:
            training_results: list of directories generated by process_scene_data
                that all hold training chips
            validation_results: list of directories generated by process_scene_data
                that all hold validation chips
        """
        self.log_options()

        group = str(uuid.uuid4())
        group_uri = join(self.backend_opts.chip_uri, '{}.zip'.format(group))
        group_path = get_local_path(group_uri, tmp_dir)
        make_dir(group_path, use_dirname=True)

        with zipfile.ZipFile(group_path, 'w', zipfile.ZIP_DEFLATED) as zipf:

            def _write_zip(scene_dirs, split):
                for scene_dir in scene_dirs:
                    scene_paths = glob.glob(join(scene_dir, '**/*.png'))
                    for path in scene_paths:
                        class_name, fn = path.split('/')[-2:]
                        zipf.write(path, join(split, class_name, fn))

            _write_zip(training_results, 'train')
            _write_zip(validation_results, 'valid')

        upload_or_copy(group_path, group_uri)

</source>
<source file="systems/raster-vision-0.10.0/rastervision/backend/pytorch_object_detection.py" startline="165" endline="200" pcid="204">
    def process_sceneset_results(self, training_results, validation_results,
                                 tmp_dir):
        """After all scenes have been processed, process the result set.

        This writes a zip file for a group of scenes at {chip_uri}/{uuid}.zip
        containing:
        train/{scene_id}-{ind}.png
        train/{scene_id}-labels.json
        valid/{scene_id}-{ind}.png
        valid/{scene_id}-labels.json

        Args:
            training_results: dependent on the ml_backend's process_scene_data
            validation_results: dependent on the ml_backend's
                process_scene_data
        """
        self.log_options()

        group = str(uuid.uuid4())
        group_uri = join(self.backend_opts.chip_uri, '{}.zip'.format(group))
        group_path = get_local_path(group_uri, tmp_dir)
        make_dir(group_path, use_dirname=True)

        with zipfile.ZipFile(group_path, 'w', zipfile.ZIP_DEFLATED) as zipf:

            def _write_zip(results, split):
                for scene_dir in results:
                    scene_paths = glob.glob(join(scene_dir, '*'))
                    for p in scene_paths:
                        zipf.write(p, join(split, basename(p)))

            _write_zip(training_results, 'train')
            _write_zip(validation_results, 'valid')

        upload_or_copy(group_path, group_uri)

</source>
</class>

<class classid="10" nclones="3" nlines="114" similarity="90">
<source file="systems/raster-vision-0.10.0/rastervision/backend/pytorch_semantic_segmentation.py" startline="188" endline="351" pcid="154">
    def train(self, tmp_dir):
        """Train a model.

        This downloads any previous output saved to the train_uri,
        starts training (or resumes from a checkpoint), periodically
        syncs contents of train_dir to train_uri and after training finishes.

        Args:
            tmp_dir: (str) path to temp directory
        """
        self.log_options()

        # Sync output of previous training run from cloud.
        train_uri = self.backend_opts.train_uri
        train_dir = get_local_path(train_uri, tmp_dir)
        make_dir(train_dir)
        sync_from_dir(train_uri, train_dir)

        # Get zip file for each group, and unzip them into chip_dir.
        chip_dir = join(tmp_dir, 'chips')
        make_dir(chip_dir)
        for zip_uri in list_paths(self.backend_opts.chip_uri, 'zip'):
            zip_path = download_if_needed(zip_uri, tmp_dir)
            with zipfile.ZipFile(zip_path, 'r') as zipf:
                zipf.extractall(chip_dir)

        # Setup data loader.
        batch_size = self.train_opts.batch_size
        chip_size = self.task_config.chip_size
        class_names = self.class_map.get_class_names()
        databunch = build_databunch(chip_dir, chip_size, batch_size,
                                    class_names)
        log.info(databunch)
        num_labels = len(databunch.label_names)
        if self.train_opts.debug:
            make_debug_chips(databunch, self.class_map, tmp_dir, train_uri)

        # Setup model
        num_labels = len(databunch.label_names)
        model = get_model(
            self.train_opts.model_arch, num_labels, pretrained=True)
        model = model.to(self.device)
        model_path = join(train_dir, 'model')

        # Load weights from a pretrained model.
        pretrained_uri = self.backend_opts.pretrained_uri
        if pretrained_uri:
            log.info('Loading weights from pretrained_uri: {}'.format(
                pretrained_uri))
            pretrained_path = download_if_needed(pretrained_uri, tmp_dir)
            model.load_state_dict(
                torch.load(pretrained_path, map_location=self.device))

        # Possibly resume training from checkpoint.
        start_epoch = 0
        train_state_path = join(train_dir, 'train_state.json')
        if isfile(train_state_path):
            log.info('Resuming from checkpoint: {}\n'.format(model_path))
            train_state = file_to_json(train_state_path)
            start_epoch = train_state['epoch'] + 1
            model.load_state_dict(
                torch.load(model_path, map_location=self.device))

        # Write header of log CSV file.
        metric_names = ['precision', 'recall', 'f1']
        log_path = join(train_dir, 'log.csv')
        if not isfile(log_path):
            with open(log_path, 'w') as log_file:
                log_writer = csv.writer(log_file)
                row = ['epoch', 'time', 'train_loss'] + metric_names
                log_writer.writerow(row)

        # Setup Tensorboard logging.
        if self.train_opts.log_tensorboard:
            log_dir = join(train_dir, 'tb-logs')
            make_dir(log_dir)
            tb_writer = SummaryWriter(log_dir=log_dir)
            if self.train_opts.run_tensorboard:
                log.info('Starting tensorboard process')
                tensorboard_process = Popen(
                    ['tensorboard', '--logdir={}'.format(log_dir)])
                terminate_at_exit(tensorboard_process)

        # Setup optimizer, loss, and LR scheduler.
        loss_fn = torch.nn.CrossEntropyLoss()
        lr = self.train_opts.lr
        opt = optim.Adam(model.parameters(), lr=lr)
        step_scheduler, epoch_scheduler = None, None
        num_epochs = self.train_opts.num_epochs

        if self.train_opts.one_cycle and num_epochs > 1:
            steps_per_epoch = len(databunch.train_ds) // batch_size
            total_steps = num_epochs * steps_per_epoch
            step_size_up = (num_epochs // 2) * steps_per_epoch
            step_size_down = total_steps - step_size_up
            step_scheduler = CyclicLR(
                opt,
                base_lr=lr / 10,
                max_lr=lr,
                step_size_up=step_size_up,
                step_size_down=step_size_down,
                cycle_momentum=False)
            for _ in range(start_epoch * steps_per_epoch):
                step_scheduler.step()

        # Training loop.
        for epoch in range(start_epoch, num_epochs):
            # Train one epoch.
            log.info('-----------------------------------------------------')
            log.info('epoch: {}'.format(epoch))
            start = time.time()
            train_loss = train_epoch(model, self.device, databunch.train_dl,
                                     opt, loss_fn, step_scheduler)
            if epoch_scheduler:
                epoch_scheduler.step()
            log.info('train loss: {}'.format(train_loss))

            # Validate one epoch.
            metrics = validate_epoch(model, self.device, databunch.valid_dl,
                                     num_labels)
            log.info('validation metrics: {}'.format(metrics))

            # Print elapsed time for epoch.
            end = time.time()
            epoch_time = datetime.timedelta(seconds=end - start)
            log.info('epoch elapsed time: {}'.format(epoch_time))

            # Save model and state.
            torch.save(model.state_dict(), model_path)
            train_state = {'epoch': epoch}
            json_to_file(train_state, train_state_path)

            # Append to log CSV file.
            with open(log_path, 'a') as log_file:
                log_writer = csv.writer(log_file)
                row = [epoch, epoch_time, train_loss]
                row += [metrics[k] for k in metric_names]
                log_writer.writerow(row)

            # Write to Tensorboard log.
            if self.train_opts.log_tensorboard:
                for key, val in metrics.items():
                    tb_writer.add_scalar(key, val, epoch)
                tb_writer.add_scalar('train_loss', train_loss, epoch)
                for name, param in model.named_parameters():
                    tb_writer.add_histogram(name, param, epoch)

            if (train_uri.startswith('s3://')
                    and (((epoch + 1) % self.train_opts.sync_interval) == 0)):
                sync_to_dir(train_dir, train_uri)

        # Close Tensorboard.
        if self.train_opts.log_tensorboard:
            tb_writer.close()
            if self.train_opts.run_tensorboard:
                tensorboard_process.terminate()

        # Since model is exported every epoch, we need some other way to
        # show that training is finished.
        str_to_file('done!', self.backend_opts.train_done_uri)

        # Sync output to cloud.
        sync_to_dir(train_dir, self.backend_opts.train_uri)

</source>
<source file="systems/raster-vision-0.10.0/rastervision/backend/pytorch_object_detection.py" startline="201" endline="362" pcid="206">
    def train(self, tmp_dir):
        """Train a model.

        This downloads any previous output saved to the train_uri,
        starts training (or resumes from a checkpoint), periodically
        syncs contents of train_dir to train_uri and after training finishes.

        Args:
            tmp_dir: (str) path to temp directory
        """
        self.log_options()

        # Sync output of previous training run from cloud.
        train_uri = self.backend_opts.train_uri
        train_dir = get_local_path(train_uri, tmp_dir)
        make_dir(train_dir)
        sync_from_dir(train_uri, train_dir)

        # Get zip file for each group, and unzip them into chip_dir.
        chip_dir = join(tmp_dir, 'chips')
        make_dir(chip_dir)
        for zip_uri in list_paths(self.backend_opts.chip_uri, 'zip'):
            zip_path = download_if_needed(zip_uri, tmp_dir)
            with zipfile.ZipFile(zip_path, 'r') as zipf:
                zipf.extractall(chip_dir)

        # Setup dataset and dataloaders.
        batch_size = self.train_opts.batch_size
        chip_size = self.task_config.chip_size
        databunch = build_databunch(chip_dir, chip_size, batch_size)
        log.info(databunch)
        num_labels = len(databunch.label_names)
        if self.train_opts.debug:
            make_debug_chips(databunch, self.task_config.class_map, tmp_dir,
                             train_uri)

        # Setup model
        num_labels = len(databunch.label_names)
        model = MyFasterRCNN(
            self.train_opts.model_arch, num_labels, chip_size, pretrained=True)
        model = model.to(self.device)
        model_path = join(train_dir, 'model')

        # Load weights from a pretrained model.
        pretrained_uri = self.backend_opts.pretrained_uri
        if pretrained_uri:
            log.info('Loading weights from pretrained_uri: {}'.format(
                pretrained_uri))
            pretrained_path = download_if_needed(pretrained_uri, tmp_dir)
            model.load_state_dict(
                torch.load(pretrained_path, map_location=self.device))

        # Possibly resume training from checkpoint.
        start_epoch = 0
        train_state_path = join(train_dir, 'train_state.json')
        if isfile(train_state_path):
            log.info('Resuming from checkpoint: {}\n'.format(model_path))
            train_state = file_to_json(train_state_path)
            start_epoch = train_state['epoch'] + 1
            model.load_state_dict(
                torch.load(model_path, map_location=self.device))

        # Write header of log CSV file.
        log_path = join(train_dir, 'log.csv')
        if not isfile(log_path):
            with open(log_path, 'w') as log_file:
                log_writer = csv.writer(log_file)
                row = ['epoch'] + ['map50', 'time'] + model.subloss_names
                log_writer.writerow(row)

        # Setup Tensorboard logging.
        if self.train_opts.log_tensorboard:
            log_dir = join(train_dir, 'tb-logs')
            make_dir(log_dir)
            tb_writer = SummaryWriter(log_dir=log_dir)
            if self.train_opts.run_tensorboard:
                log.info('Starting tensorboard process')
                tensorboard_process = Popen(
                    ['tensorboard', '--logdir={}'.format(log_dir)])
                terminate_at_exit(tensorboard_process)

        # Setup optimizer.
        lr = self.train_opts.lr
        opt = optim.Adam(model.parameters(), lr=lr)
        step_scheduler, epoch_scheduler = None, None
        num_epochs = self.train_opts.num_epochs

        if self.train_opts.one_cycle and num_epochs > 1:
            steps_per_epoch = len(databunch.train_ds) // batch_size
            total_steps = num_epochs * steps_per_epoch
            step_size_up = (num_epochs // 2) * steps_per_epoch
            step_size_down = total_steps - step_size_up
            step_scheduler = CyclicLR(
                opt,
                base_lr=lr / 10,
                max_lr=lr,
                step_size_up=step_size_up,
                step_size_down=step_size_down,
                cycle_momentum=False)
            for _ in range(start_epoch * steps_per_epoch):
                step_scheduler.step()

        # Training loop.
        for epoch in range(start_epoch, num_epochs):
            # Train one epoch.
            log.info('-----------------------------------------------------')
            log.info('epoch: {}'.format(epoch))
            start = time.time()
            train_loss = train_epoch(model, self.device, databunch.train_dl,
                                     opt, step_scheduler, epoch_scheduler)
            if epoch_scheduler:
                epoch_scheduler.step()
            log.info('train loss: {}'.format(train_loss))

            # Validate one epoch.
            metrics = validate_epoch(model, self.device, databunch.valid_dl,
                                     num_labels)
            log.info('validation metrics: {}'.format(metrics))

            # Print elapsed time for epoch.
            end = time.time()
            epoch_time = datetime.timedelta(seconds=end - start)
            log.info('epoch elapsed time: {}'.format(epoch_time))

            # Save model and state.
            torch.save(model.state_dict(), model_path)
            train_state = {'epoch': epoch}
            json_to_file(train_state, train_state_path)

            # Append to log CSV file.
            with open(log_path, 'a') as log_file:
                log_writer = csv.writer(log_file)
                row = [epoch]
                row += [metrics['map50'], epoch_time]
                row += [train_loss[k] for k in model.subloss_names]
                log_writer.writerow(row)

            # Write to Tensorboard log.
            if self.train_opts.log_tensorboard:
                for key, val in metrics.items():
                    tb_writer.add_scalar(key, val, epoch)
                for key, val in train_loss.items():
                    tb_writer.add_scalar(key, val, epoch)
                for name, param in model.named_parameters():
                    tb_writer.add_histogram(name, param, epoch)

            if (train_uri.startswith('s3://')
                    and (((epoch + 1) % self.train_opts.sync_interval) == 0)):
                sync_to_dir(train_dir, train_uri)

        # Close Tensorboard.
        if self.train_opts.log_tensorboard:
            tb_writer.close()
            if self.train_opts.run_tensorboard:
                tensorboard_process.terminate()

        # Mark that the command has completed.
        str_to_file('done!', self.backend_opts.train_done_uri)

        # Sync output to cloud.
        sync_to_dir(train_dir, self.backend_opts.train_uri)

</source>
<source file="systems/raster-vision-0.10.0/rastervision/backend/pytorch_chip_classification.py" startline="177" endline="340" pcid="230">
    def train(self, tmp_dir):
        """Train a model.

        This downloads any previous output saved to the train_uri,
        starts training (or resumes from a checkpoint), periodically
        syncs contents of train_dir to train_uri and after training finishes.

        Args:
            tmp_dir: (str) path to temp directory
        """
        self.log_options()

        # Sync output of previous training run from cloud.
        train_uri = self.backend_opts.train_uri
        train_dir = get_local_path(train_uri, tmp_dir)
        make_dir(train_dir)
        sync_from_dir(train_uri, train_dir)

        # Get zip file for each group, and unzip them into chip_dir.
        chip_dir = join(tmp_dir, 'chips')
        make_dir(chip_dir)
        for zip_uri in list_paths(self.backend_opts.chip_uri, 'zip'):
            zip_path = download_if_needed(zip_uri, tmp_dir)
            with zipfile.ZipFile(zip_path, 'r') as zipf:
                zipf.extractall(chip_dir)

        # Setup data loader.
        batch_size = self.train_opts.batch_size
        chip_size = self.task_config.chip_size
        databunch = build_databunch(
            chip_dir, chip_size, batch_size,
            self.task_config.class_map.get_class_names())
        log.info(databunch)
        num_labels = len(databunch.label_names)
        if self.train_opts.debug:
            make_debug_chips(databunch, self.task_config.class_map, tmp_dir,
                             train_uri)

        # Setup model
        num_labels = len(databunch.label_names)
        model = get_model(
            self.train_opts.model_arch, num_labels, pretrained=True)
        model = model.to(self.device)
        model_path = join(train_dir, 'model')

        # Load weights from a pretrained model.
        pretrained_uri = self.backend_opts.pretrained_uri
        if pretrained_uri:
            log.info('Loading weights from pretrained_uri: {}'.format(
                pretrained_uri))
            pretrained_path = download_if_needed(pretrained_uri, tmp_dir)
            model.load_state_dict(
                torch.load(pretrained_path, map_location=self.device))

        # Possibly resume training from checkpoint.
        start_epoch = 0
        train_state_path = join(train_dir, 'train_state.json')
        if isfile(train_state_path):
            log.info('Resuming from checkpoint: {}\n'.format(model_path))
            train_state = file_to_json(train_state_path)
            start_epoch = train_state['epoch'] + 1
            model.load_state_dict(
                torch.load(model_path, map_location=self.device))

        # Write header of log CSV file.
        metric_names = ['precision', 'recall', 'f1']
        log_path = join(train_dir, 'log.csv')
        if not isfile(log_path):
            with open(log_path, 'w') as log_file:
                log_writer = csv.writer(log_file)
                row = ['epoch', 'time', 'train_loss'] + metric_names
                log_writer.writerow(row)

        # Setup Tensorboard logging.
        if self.train_opts.log_tensorboard:
            log_dir = join(train_dir, 'tb-logs')
            make_dir(log_dir)
            tb_writer = SummaryWriter(log_dir=log_dir)
            if self.train_opts.run_tensorboard:
                log.info('Starting tensorboard process')
                tensorboard_process = Popen(
                    ['tensorboard', '--logdir={}'.format(log_dir)])
                terminate_at_exit(tensorboard_process)

        # Setup optimizer, loss, and LR scheduler.
        loss_fn = torch.nn.CrossEntropyLoss()
        lr = self.train_opts.lr
        opt = optim.Adam(model.parameters(), lr=lr)
        step_scheduler, epoch_scheduler = None, None
        num_epochs = self.train_opts.num_epochs

        if self.train_opts.one_cycle and num_epochs > 1:
            steps_per_epoch = len(databunch.train_ds) // batch_size
            total_steps = num_epochs * steps_per_epoch
            step_size_up = (num_epochs // 2) * steps_per_epoch
            step_size_down = total_steps - step_size_up
            step_scheduler = CyclicLR(
                opt,
                base_lr=lr / 10,
                max_lr=lr,
                step_size_up=step_size_up,
                step_size_down=step_size_down,
                cycle_momentum=False)
            for _ in range(start_epoch * steps_per_epoch):
                step_scheduler.step()

        # Training loop.
        for epoch in range(start_epoch, num_epochs):
            # Train one epoch.
            log.info('-----------------------------------------------------')
            log.info('epoch: {}'.format(epoch))
            start = time.time()
            train_loss = train_epoch(model, self.device, databunch.train_dl,
                                     opt, loss_fn, step_scheduler)
            if epoch_scheduler:
                epoch_scheduler.step()
            log.info('train loss: {}'.format(train_loss))

            # Validate one epoch.
            metrics = validate_epoch(model, self.device, databunch.valid_dl,
                                     num_labels)
            log.info('validation metrics: {}'.format(metrics))

            # Print elapsed time for epoch.
            end = time.time()
            epoch_time = datetime.timedelta(seconds=end - start)
            log.info('epoch elapsed time: {}'.format(epoch_time))

            # Save model and state.
            torch.save(model.state_dict(), model_path)
            train_state = {'epoch': epoch}
            json_to_file(train_state, train_state_path)

            # Append to log CSV file.
            with open(log_path, 'a') as log_file:
                log_writer = csv.writer(log_file)
                row = [epoch, epoch_time, train_loss]
                row += [metrics[k] for k in metric_names]
                log_writer.writerow(row)

            # Write to Tensorboard log.
            if self.train_opts.log_tensorboard:
                for key, val in metrics.items():
                    tb_writer.add_scalar(key, val, epoch)
                tb_writer.add_scalar('train_loss', train_loss, epoch)
                for name, param in model.named_parameters():
                    tb_writer.add_histogram(name, param, epoch)

            if (train_uri.startswith('s3://')
                    and (((epoch + 1) % self.train_opts.sync_interval) == 0)):
                sync_to_dir(train_dir, train_uri)

        # Close Tensorboard.
        if self.train_opts.log_tensorboard:
            tb_writer.close()
            if self.train_opts.run_tensorboard:
                tensorboard_process.terminate()

        # Mark that the command has completed.
        str_to_file('done!', self.backend_opts.train_done_uri)

        # Sync output to cloud.
        sync_to_dir(train_dir, self.backend_opts.train_uri)

</source>
</class>

<class classid="11" nclones="2" nlines="11" similarity="90">
<source file="systems/raster-vision-0.10.0/rastervision/backend/pytorch_semantic_segmentation.py" startline="352" endline="365" pcid="155">
    def load_model(self, tmp_dir):
        """Load the model in preparation for one or more prediction calls."""
        if self.model is None:
            model_uri = self.backend_opts.model_uri
            model_path = download_if_needed(model_uri, tmp_dir)

            num_classes = len(self.class_map)
            model = get_model(
                self.train_opts.model_arch, num_classes, pretrained=True)
            model = model.to(self.device)
            model.load_state_dict(
                torch.load(model_path, map_location=self.device))
            self.model = model

</source>
<source file="systems/raster-vision-0.10.0/rastervision/backend/pytorch_chip_classification.py" startline="341" endline="354" pcid="231">
    def load_model(self, tmp_dir):
        """Load the model in preparation for one or more prediction calls."""
        if self.model is None:
            model_uri = self.backend_opts.model_uri
            model_path = download_if_needed(model_uri, tmp_dir)

            num_classes = len(self.task_config.class_map)
            model = get_model(
                self.train_opts.model_arch, num_classes, pretrained=True)
            model = model.to(self.device)
            model.load_state_dict(
                torch.load(model_path, map_location=self.device))
            self.model = model

</source>
</class>

<class classid="12" nclones="6" nlines="11" similarity="71">
<source file="systems/raster-vision-0.10.0/rastervision/backend/simple_backend_config.py" startline="16" endline="28" pcid="233">
    def __init__(self,
                 chip_uri=None,
                 train_uri=None,
                 train_done_uri=None,
                 model_uri=None,
                 pretrained_uri=None):
        self.chip_uri = chip_uri
        self.train_uri = train_uri
        self.train_done_uri = train_done_uri
        self.model_uri = model_uri
        self.pretrained_uri = pretrained_uri


</source>
<source file="systems/raster-vision-0.10.0/rastervision/command/aux_command.py" startline="5" endline="43" pcid="453">
    def __init__(self,
                 split_on=None,
                 inputs=lambda config: None,
                 outputs=lambda config: None,
                 include_by_default=False,
                 required_fields=None):
        """Instantiate an AuxCommandOptions object.

        Args:
            split_on (str): The property of the configuration to use when splitting.
            The configuration at this property must be a list.

            inputs: A function that, given the configuration, returns a list of
            URIs that are inputs into the command. Along with outputs, this allows
            Raster Vision to correctly determine if there are any missing inputs, or
            if the command has already been run. It will also allow the command to
            be run in the right sequence if run with other commands that will produce
            this command's inputs as their outputs.

            outputs: A function that, given the configuration, returns a list of
            URIs that are outputs of the command. See the details on inputs.

            include_by_default: Set this to True if you want this command to run
            by default, meaning it will run every time no specific commands are issued
            on the command line (e.g. how a standard command would run).

            required_fields: Set this to properties of the configuration that are
            required. If the user of the command does not set values into those
            configuration properties, an error will be thrown at configuration building
            time.

        """
        self.split_on = split_on
        self.inputs = inputs
        self.outputs = outputs
        self.include_by_default = include_by_default
        self.required_fields = required_fields


</source>
<source file="systems/raster-vision-0.10.0/rastervision/task/task_config.py" startline="11" endline="22" pcid="1169">
    def __init__(self,
                 task_type,
                 predict_batch_size=10,
                 predict_package_uri=None,
                 debug=True,
                 predict_debug_uri=None):
        self.task_type = task_type
        self.predict_batch_size = predict_batch_size
        self.predict_package_uri = predict_package_uri
        self.debug = debug
        self.predict_debug_uri = predict_debug_uri

</source>
<source file="systems/raster-vision-0.10.0/rastervision/data/scene_config.py" startline="15" endline="26" pcid="720">
class SceneConfig(BundledConfigMixin, Config):
    def __init__(self,
                 id,
                 raster_source,
                 label_source=None,
                 label_store=None,
                 aoi_uris=None):
        self.id = id
        self.raster_source = raster_source
        self.label_source = label_source
        self.label_store = label_store
        self.aoi_uris = aoi_uris
</source>
<source file="systems/raster-vision-0.10.0/rastervision/data/scene.py" startline="7" endline="30" pcid="618">
    def __init__(self,
                 id,
                 raster_source,
                 ground_truth_label_source=None,
                 prediction_label_store=None,
                 aoi_polygons=None):
        """Construct a new Scene.

        Args:
            id: ID for this scene
            raster_source: RasterSource for this scene
            ground_truth_label_store: optional LabelSource
            prediction_label_store: optional LabelStore
            aoi: Optional list of AOI polygons
        """
        self.id = id
        self.raster_source = raster_source
        self.ground_truth_label_source = ground_truth_label_source
        self.prediction_label_store = prediction_label_store
        if aoi_polygons is None:
            self.aoi_polygons = []
        else:
            self.aoi_polygons = aoi_polygons

</source>
<source file="systems/raster-vision-0.10.0/rastervision/data/vector_source/vector_source.py" startline="111" endline="138" pcid="762">
    def __init__(self,
                 crs_transformer,
                 line_bufs=None,
                 point_bufs=None,
                 class_inf_opts=None):
        """Constructor.

        Args:
            crs_transformer: (CRSTransformer)
            line_bufs: (dict or None) If none, uses default buffer value of 1. Otherwise,
                a map from class_id to number of pixels to buffer by. If the buffer value
                is None, then no buffering will be performed and the LineString or Point
                won't get converted to a Polygon. Not converting to Polygon is
                incompatible with the currently available LabelSources, but may be useful
                in the future.
            point_bufs: (dict or None) same as above, but used for buffering Points into
                Polygons.
            class_inf_opts: (ClassInferenceOptions)
        """
        self.crs_transformer = crs_transformer
        self.line_bufs = line_bufs
        self.point_bufs = point_bufs
        if class_inf_opts is None:
            class_inf_opts = ClassInferenceOptions()
        self.class_inference = ClassInference(class_inf_opts)

        self.geojson = None

</source>
</class>

<class classid="13" nclones="4" nlines="10" similarity="70">
<source file="systems/raster-vision-0.10.0/rastervision/command/analyze_command_config.py" startline="26" endline="38" pcid="317">

    def to_proto(self):
        msg = super().to_proto()
        task = self.task.to_proto()
        scenes = list(map(lambda s: s.to_proto(), self.scenes))
        analyzers = list(map(lambda a: a.to_proto(), self.analyzers))

        msg.MergeFrom(
            CommandConfigMsg(
                analyze_config=CommandConfigMsg.AnalyzeConfig(
                    task=task, scenes=scenes, analyzers=analyzers)))

        return msg
</source>
<source file="systems/raster-vision-0.10.0/rastervision/command/eval_command_config.py" startline="33" endline="45" pcid="405">

    def to_proto(self):
        msg = super().to_proto()
        task = self.task.to_proto()
        scenes = list(map(lambda s: s.to_proto(), self.scenes))
        evaluators = list(map(lambda e: e.to_proto(), self.evaluators))

        msg.MergeFrom(
            CommandConfigMsg(
                eval_config=CommandConfigMsg.EvalConfig(
                    task=task, scenes=scenes, evaluators=evaluators)))

        return msg
</source>
<source file="systems/raster-vision-0.10.0/rastervision/command/predict_command_config.py" startline="37" endline="50" pcid="419">

    def to_proto(self):
        msg = super().to_proto()

        task = self.task.to_proto()
        backend = self.backend.to_proto()
        scenes = list(map(lambda s: s.to_proto(), self.scenes))

        msg.MergeFrom(
            CommandConfigMsg(
                predict_config=CommandConfigMsg.PredictConfig(
                    task=task, backend=backend, scenes=scenes)))

        return msg
</source>
<source file="systems/raster-vision-0.10.0/rastervision/command/bundle_command_config.py" startline="32" endline="46" pcid="435">

    def to_proto(self):
        msg = super().to_proto()

        task = self.task.to_proto()
        backend = self.backend.to_proto()
        scene = self.scene.to_proto()
        analyzers = list(map(lambda a: a.to_proto(), self.analyzers))

        b = CommandConfigMsg.BundleConfig(
            task=task, backend=backend, scene=scene, analyzers=analyzers)

        msg.MergeFrom(CommandConfigMsg(bundle_config=b))

        return msg
</source>
</class>

<class classid="14" nclones="5" nlines="10" similarity="71">
<source file="systems/raster-vision-0.10.0/rastervision/command/analyze_command_config.py" startline="50" endline="60" pcid="319">
class AnalyzeCommandConfigBuilder(CommandConfigBuilder):
    def __init__(self, command_type, prev=None):
        super().__init__(command_type, prev)
        if prev is None:
            self.task = None
            self.scenes = None
            self.analyzers = None
        else:
            self.task = prev.task
            self.scenes = prev.scenes
            self.analyzers = prev.analyzers
</source>
<source file="systems/raster-vision-0.10.0/rastervision/command/eval_command_config.py" startline="57" endline="67" pcid="407">
class EvalCommandConfigBuilder(CommandConfigBuilder):
    def __init__(self, command_type, prev=None):
        super().__init__(command_type, prev)
        if prev is None:
            self.task = None
            self.scenes = None
            self.evaluators = None
        else:
            self.task = prev.task
            self.scenes = prev.scenes
            self.evaluators = prev.evaluators
</source>
<source file="systems/raster-vision-0.10.0/rastervision/command/bundle_command_config.py" startline="58" endline="70" pcid="437">
class BundleCommandConfigBuilder(CommandConfigBuilder):
    def __init__(self, command_type, prev=None):
        super().__init__(command_type, prev)
        if prev is None:
            self.task = None
            self.backend = None
            self.scene = None
            self.analyzers = None
        else:
            self.task = prev.task
            self.backend = prev.backend
            self.scene = prev.scene
            self.analyzers = prev.analyzers
</source>
<source file="systems/raster-vision-0.10.0/rastervision/command/predict_command_config.py" startline="68" endline="78" pcid="422">
        return commands


class PredictCommandConfigBuilder(CommandConfigBuilder):
    def __init__(self, command_type, prev=None):
        super().__init__(command_type, prev)
        if prev is None:
            self.task = None
            self.backend = None
            self.scenes = []
        else:
</source>
<source file="systems/raster-vision-0.10.0/rastervision/command/chip_command_config.py" startline="83" endline="97" pcid="392">
            commands.append(c)
        return commands


class ChipCommandConfigBuilder(CommandConfigBuilder):
    def __init__(self, command_type, prev=None):
        super().__init__(command_type, prev)
        if prev is None:
            self.task = None
            self.backend = None
            self.augmentors = []
            self.train_scenes = []
            self.val_scenes = []
        else:
            self.task = prev.task
</source>
</class>

<class classid="15" nclones="5" nlines="10" similarity="71">
<source file="systems/raster-vision-0.10.0/rastervision/command/analyze_command_config.py" startline="77" endline="91" pcid="322">

    def from_proto(self, msg):
        b = super().from_proto(msg)

        conf = msg.analyze_config

        task = rv.TaskConfig.from_proto(conf.task)
        scenes = list(map(rv.SceneConfig.from_proto, conf.scenes))
        analyzers = list(map(rv.AnalyzerConfig.from_proto, conf.analyzers))

        b = b.with_task(task)
        b = b.with_scenes(scenes)
        b = b.with_analyzers(analyzers)

        return b
</source>
<source file="systems/raster-vision-0.10.0/rastervision/command/bundle_command_config.py" startline="99" endline="115" pcid="440">

    def from_proto(self, msg):
        b = super().from_proto(msg)

        conf = msg.bundle_config

        task = rv.TaskConfig.from_proto(conf.task)
        backend = rv.BackendConfig.from_proto(conf.backend)
        scene = rv.SceneConfig.from_proto(conf.scene)
        analyzers = list(map(rv.AnalyzerConfig.from_proto, conf.analyzers))

        b = b.with_task(task)
        b = b.with_backend(backend)
        b = b.with_scene(scene)
        b = b.with_analyzers(analyzers)

        return b
</source>
<source file="systems/raster-vision-0.10.0/rastervision/command/chip_command_config.py" startline="127" endline="145" pcid="395">
        self.validate()
        return ChipCommandConfig(self.root_uri, self.split_id, self.task,
                                 self.backend, self.augmentors,
                                 self.train_scenes, self.val_scenes)

    def from_proto(self, msg):
        b = super().from_proto(msg)

        conf = msg.chip_config

        task = rv.TaskConfig.from_proto(conf.task)
        backend = rv.BackendConfig.from_proto(conf.backend)
        augmentors = list(map(rv.AugmentorConfig.from_proto, conf.augmentors))
        train_scenes = list(map(rv.SceneConfig.from_proto, conf.train_scenes))
        val_scenes = list(map(rv.SceneConfig.from_proto, conf.val_scenes))

        b = b.with_task(task)
        b = b.with_backend(backend)
        b = b.with_augmentors(augmentors)
</source>
<source file="systems/raster-vision-0.10.0/rastervision/command/eval_command_config.py" startline="99" endline="113" pcid="410">

    def from_proto(self, msg):
        b = super().from_proto(msg)

        conf = msg.eval_config

        task = rv.TaskConfig.from_proto(conf.task)
        scenes = list(map(rv.SceneConfig.from_proto, conf.scenes))
        evaluators = list(map(rv.EvaluatorConfig.from_proto, conf.evaluators))

        b = b.with_task(task)
        b = b.with_scenes(scenes)
        b = b.with_evaluators(evaluators)

        return b
</source>
<source file="systems/raster-vision-0.10.0/rastervision/command/predict_command_config.py" startline="97" endline="111" pcid="425">
        self.validate()
        return PredictCommandConfig(self.root_uri, self.split_id, self.task,
                                    self.backend, self.scenes)

    def from_proto(self, msg):
        b = super().from_proto(msg)

        conf = msg.predict_config

        task = rv.TaskConfig.from_proto(conf.task)
        backend = rv.BackendConfig.from_proto(conf.backend)
        scenes = list(map(rv.SceneConfig.from_proto, conf.scenes))

        b = b.with_task(task)
        b = b.with_backend(backend)
</source>
</class>

<class classid="16" nclones="3" nlines="11" similarity="72">
<source file="systems/raster-vision-0.10.0/rastervision/command/predict_command.py" startline="10" endline="24" pcid="346">
    def run(self, tmp_dir=None):
        if not tmp_dir:
            tmp_dir = self.get_tmp_dir()
        msg = 'Making predictions...'

        cc = self.command_config

        backend = cc.backend.create_backend(cc.task)
        task = cc.task.create_task(backend)

        scenes = list(
            map(lambda s: s.create_scene(cc.task, tmp_dir), cc.scenes))

        click.echo(click.style(msg, fg='green'))
        task.predict(scenes, tmp_dir)
</source>
<source file="systems/raster-vision-0.10.0/rastervision/command/eval_command.py" startline="10" endline="24" pcid="456">
    def run(self, tmp_dir=None):
        if not tmp_dir:
            tmp_dir = self.get_tmp_dir()

        cc = self.command_config

        scenes = list(
            map(lambda s: s.create_scene(cc.task, tmp_dir), cc.scenes))
        evaluators = list(map(lambda a: a.create_evaluator(), cc.evaluators))

        for evaluator in evaluators:
            msg = 'Running evaluator: {}...'.format(type(evaluator).__name__)
            click.echo(click.style(msg, fg='green'))

            evaluator.process(scenes, tmp_dir)
</source>
<source file="systems/raster-vision-0.10.0/rastervision/command/analyze_command.py" startline="10" endline="24" pcid="432">
    def run(self, tmp_dir=None):
        if not tmp_dir:
            tmp_dir = self.get_tmp_dir()

        cc = self.command_config

        analyzers = list(map(lambda a: a.create_analyzer(), cc.analyzers))
        scenes = list(
            map(lambda s: s.create_scene(cc.task, tmp_dir), cc.scenes))

        for analyzer in analyzers:
            msg = 'Running analyzer: {}...'.format(type(analyzer).__name__)
            click.echo(click.style(msg, fg='green'))

            analyzer.process(scenes, tmp_dir)
</source>
</class>

<class classid="17" nclones="3" nlines="11" similarity="90">
<source file="systems/raster-vision-0.10.0/rastervision/command/chip_command_config.py" startline="23" endline="36" pcid="388">

    def create_command(self, tmp_dir=None):
        if len(self.train_scenes) == 0 and len(self.val_scenes) == 0:
            return NoOpCommand()

        if not tmp_dir:
            _tmp_dir = RVConfig.get_tmp_dir()
            tmp_dir = _tmp_dir.name
        else:
            _tmp_dir = tmp_dir

        retval = ChipCommand(self)
        retval.set_tmp_dir(_tmp_dir)
        return retval
</source>
<source file="systems/raster-vision-0.10.0/rastervision/command/eval_command_config.py" startline="19" endline="32" pcid="404">

    def create_command(self, tmp_dir=None):
        if len(self.scenes) == 0 or len(self.evaluators) == 0:
            return NoOpCommand()

        if not tmp_dir:
            _tmp_dir = RVConfig.get_tmp_dir()
            tmp_dir = _tmp_dir.name
        else:
            _tmp_dir = tmp_dir

        retval = EvalCommand(self)
        retval.set_tmp_dir(_tmp_dir)
        return retval
</source>
<source file="systems/raster-vision-0.10.0/rastervision/command/predict_command_config.py" startline="23" endline="36" pcid="418">

    def create_command(self, tmp_dir=None):
        if len(self.scenes) == 0:
            return NoOpCommand()

        if not tmp_dir:
            _tmp_dir = RVConfig.get_tmp_dir()
            tmp_dir = _tmp_dir.name
        else:
            _tmp_dir = tmp_dir

        retval = PredictCommand(self)
        retval.set_tmp_dir(_tmp_dir)
        return retval
</source>
</class>

<class classid="18" nclones="2" nlines="10" similarity="100">
<source file="systems/raster-vision-0.10.0/rastervision/data/label_source/object_detection_label_source_config.py" startline="75" endline="93" pcid="542">
    def with_vector_source(self, vector_source):
        """Set the vector_source.

        Args:
            vector_source (str or VectorSource) if a string, assume it is
                a URI and use the default provider to construct a VectorSource.
        """
        if isinstance(vector_source, str):
            return self.with_uri(vector_source)

        b = deepcopy(self)
        if isinstance(vector_source, VectorSourceConfig):
            b.config['vector_source'] = vector_source
        else:
            raise rv.ConfigError(
                'vector_source must be of type str or VectorSource')

        return b

</source>
<source file="systems/raster-vision-0.10.0/rastervision/data/raster_source/rasterized_source_config.py" startline="142" endline="160" pcid="639">
            vector_source = VectorSourceConfig.from_proto(
                msg.rasterized_source.vector_source)
            rasterizer_options = msg.rasterized_source.rasterizer_options

        return b \
            .with_vector_source(vector_source) \
            .with_rasterizer_options(
                rasterizer_options.background_class_id,
                rasterizer_options.all_touched)

    def with_vector_source(self, vector_source):
        """Set the vector_source.

        Args:
            vector_source (str or VectorSource) if a string, assume it is
                a URI and use the default provider to construct a VectorSource.
        """
        if isinstance(vector_source, str):
            return self.with_uri(vector_source)
</source>
</class>

<class classid="19" nclones="2" nlines="25" similarity="100">
<source file="systems/raster-vision-0.10.0/rastervision/data/utils.py" startline="1" endline="49" pcid="597">
def boxes_to_geojson(boxes, class_ids, crs_transformer, class_map,
                     scores=None):
    """Convert boxes and associated data into a GeoJSON dict.

    Args:
        boxes: list of Box in pixel row/col format.
        class_ids: list of int (one for each box)
        crs_transformer: CRSTransformer used to convert pixel coords to map
            coords in the GeoJSON
        class_map: ClassMap used to infer class_name from class_id
        scores: optional list of score or scores.
                If floats (one for each box), property name will be "score".
                If lists of floats, property name will be "scores".

    Returns:
        dict in GeoJSON format
    """
    features = []
    for box_ind, box in enumerate(boxes):
        polygon = box.geojson_coordinates()
        polygon = [list(crs_transformer.pixel_to_map(p)) for p in polygon]

        class_id = int(class_ids[box_ind])
        class_name = class_map.get_by_id(class_id).name

        feature = {
            'type': 'Feature',
            'geometry': {
                'type': 'Polygon',
                'coordinates': [polygon]
            },
            'properties': {
                'class_id': class_id,
                'class_name': class_name
            }
        }

        if scores is not None:
            box_scores = scores[box_ind]

            if box_scores is not None:
                if type(box_scores) is list:
                    feature['properties']['scores'] = box_scores
                else:
                    feature['properties']['score'] = box_scores

        features.append(feature)

    return {'type': 'FeatureCollection', 'features': features}
</source>
<source file="systems/raster-vision-0.10.0/rastervision/data/label_store/utils.py" startline="1" endline="49" pcid="934">
def boxes_to_geojson(boxes, class_ids, crs_transformer, class_map,
                     scores=None):
    """Convert boxes and associated data into a GeoJSON dict.

    Args:
        boxes: list of Box in pixel row/col format.
        class_ids: list of int (one for each box)
        crs_transformer: CRSTransformer used to convert pixel coords to map
            coords in the GeoJSON
        class_map: ClassMap used to infer class_name from class_id
        scores: optional list of score or scores.
                If floats (one for each box), property name will be "score".
                If lists of floats, property name will be "scores".

    Returns:
        dict in GeoJSON format
    """
    features = []
    for box_ind, box in enumerate(boxes):
        polygon = box.geojson_coordinates()
        polygon = [list(crs_transformer.pixel_to_map(p)) for p in polygon]

        class_id = int(class_ids[box_ind])
        class_name = class_map.get_by_id(class_id).name

        feature = {
            'type': 'Feature',
            'geometry': {
                'type': 'Polygon',
                'coordinates': [polygon]
            },
            'properties': {
                'class_id': class_id,
                'class_name': class_name
            }
        }

        if scores is not None:
            box_scores = scores[box_ind]

            if box_scores is not None:
                if type(box_scores) is list:
                    feature['properties']['scores'] = box_scores
                else:
                    feature['properties']['score'] = box_scores

        features.append(feature)

    return {'type': 'FeatureCollection', 'features': features}
</source>
</class>

<class classid="20" nclones="2" nlines="12" similarity="76">
<source file="systems/raster-vision-0.10.0/rastervision/data/raster_source/rasterized_source_config.py" startline="33" endline="44" pcid="628">
                all_touched=self.all_touched)

    def __init__(self,
                 vector_source,
                 rasterizer_options,
                 transformers=None,
                 channel_order=None):
        super().__init__(
            source_type=rv.RASTERIZED_SOURCE,
            transformers=transformers,
            channel_order=channel_order)
        self.vector_source = vector_source
</source>
<source file="systems/raster-vision-0.10.0/rastervision/data/raster_source/rasterio_source_config.py" startline="11" endline="24" pcid="666">

class RasterioSourceConfig(RasterSourceConfig):
    def __init__(self,
                 uris,
                 x_shift_meters=0.0,
                 y_shift_meters=0.0,
                 transformers=None,
                 channel_order=None):
        super().__init__(
            source_type=rv.RASTERIO_SOURCE,
            transformers=transformers,
            channel_order=channel_order)
        self.uris = uris
        self.x_shift_meters = x_shift_meters
</source>
</class>

<class classid="21" nclones="8" nlines="11" similarity="76">
<source file="systems/raster-vision-0.10.0/rastervision/data/raster_source/rasterio_source_config.py" startline="76" endline="88" pcid="673">

class RasterioSourceConfigBuilder(RasterSourceConfigBuilder):
    """This RasterSource can read any file that can be opened by Rasterio/GDAL.

    This includes georeferenced formats such as GeoTIFF and non-georeferenced formats
    such as JPG. See https://www.gdal.org/formats_list.html for more details.
    """

    def __init__(self, prev=None):
        config = {}
        if prev:
            config = {
                'uris': prev.uris,
</source>
<source file="systems/raster-vision-0.10.0/rastervision/task/semantic_segmentation_config.py" startline="82" endline="95" pcid="1162">
    def __init__(self, prev=None):
        config = {}
        if prev:
            config = {
                'predict_batch_size': prev.predict_batch_size,
                'predict_package_uri': prev.predict_package_uri,
                'debug': prev.debug,
                'class_map': prev.class_map,
                'chip_size': prev.chip_size,
                'predict_chip_size': prev.predict_chip_size,
                'chip_options': prev.chip_options
            }
        super().__init__(SemanticSegmentationConfig, config)

</source>
<source file="systems/raster-vision-0.10.0/rastervision/data/scene_config.py" startline="147" endline="159" pcid="732">
    def from_proto(msg):
        """Creates a SceneConfig from the specificed protobuf message
        """
        return SceneConfigBuilder().from_proto(msg).build()


class SceneConfigBuilder(ConfigBuilder):
    def __init__(self, prev=None):
        config = {}
        if prev:
            config = {
                'id': prev.id,
                'raster_source': prev.raster_source,
</source>
<source file="systems/raster-vision-0.10.0/rastervision/task/chip_classification_config.py" startline="44" endline="56" pcid="1128">
    def __init__(self, prev=None):
        config = {}
        if prev:
            config = {
                'class_map': prev.class_map,
                'chip_size': prev.chip_size,
                'predict_batch_size': prev.predict_batch_size,
                'predict_package_uri': prev.predict_package_uri,
                'debug': prev.debug,
                'predict_debug_uri': prev.predict_debug_uri
            }
        super().__init__(ChipClassificationConfig, config)

</source>
<source file="systems/raster-vision-0.10.0/rastervision/data/vector_source/vector_tile_vector_source_config.py" startline="58" endline="72" pcid="748">
    def __init__(self, prev=None):
        config = {}
        if prev:
            config = {
                'uri': prev.uri,
                'zoom': prev.zoom,
                'id_field': prev.id_field,
                'class_id_to_filter': prev.class_id_to_filter,
                'default_class_id': prev.default_class_id,
                'line_bufs': prev.line_bufs,
                'point_bufs': prev.point_bufs
            }

        super().__init__(VectorTileVectorSourceConfig, config)

</source>
<source file="systems/raster-vision-0.10.0/rastervision/data/vector_source/geojson_vector_source_config.py" startline="46" endline="58" pcid="775">
    def __init__(self, prev=None):
        config = {}
        if prev:
            config = {
                'uri': prev.uri,
                'class_id_to_filter': prev.class_id_to_filter,
                'default_class_id': prev.default_class_id,
                'line_bufs': prev.line_bufs,
                'point_bufs': prev.point_bufs
            }

        super().__init__(GeoJSONVectorSourceConfig, config)

</source>
<source file="systems/raster-vision-0.10.0/rastervision/task/object_detection_config.py" startline="80" endline="94" pcid="1189">
    def __init__(self, prev=None):
        config = {}
        if prev:
            config = {
                'predict_batch_size': prev.predict_batch_size,
                'predict_package_uri': prev.predict_package_uri,
                'debug': prev.debug,
                'predict_debug_uri': prev.predict_debug_uri,
                'class_map': prev.class_map,
                'chip_size': prev.chip_size,
                'chip_options': prev.chip_options,
                'predict_options': prev.predict_options
            }
        super().__init__(ObjectDetectionConfig, config)

</source>
<source file="systems/raster-vision-0.10.0/rastervision/data/label_store/semantic_segmentation_raster_store_config.py" startline="146" endline="157" pcid="928">

class SemanticSegmentationRasterStoreConfigBuilder(LabelStoreConfigBuilder):
    def __init__(self, prev=None):
        config = {}
        if prev:
            config = {
                'uri': prev.uri,
                'vector_output': prev.vector_output,
                'rgb': prev.rgb,
            }

        super().__init__(SemanticSegmentationRasterStoreConfig, config)
</source>
</class>

<class classid="22" nclones="2" nlines="15" similarity="76">
<source file="systems/raster-vision-0.10.0/rastervision/data/vector_source/vector_tile_vector_source_config.py" startline="12" endline="29" pcid="744">
    def __init__(self,
                 uri,
                 zoom,
                 id_field,
                 class_id_to_filter=None,
                 default_class_id=1,
                 line_bufs=None,
                 point_bufs=None):
        self.uri = uri
        self.zoom = zoom
        self.id_field = id_field
        super().__init__(
            rv.VECTOR_TILE_SOURCE,
            class_id_to_filter=class_id_to_filter,
            default_class_id=default_class_id,
            line_bufs=line_bufs,
            point_bufs=point_bufs)

</source>
<source file="systems/raster-vision-0.10.0/rastervision/data/vector_source/geojson_vector_source_config.py" startline="11" endline="24" pcid="771">
    def __init__(self,
                 uri,
                 class_id_to_filter=None,
                 default_class_id=1,
                 line_bufs=None,
                 point_bufs=None):
        self.uri = uri
        super().__init__(
            rv.GEOJSON_SOURCE,
            class_id_to_filter=class_id_to_filter,
            default_class_id=default_class_id,
            line_bufs=line_bufs,
            point_bufs=point_bufs)

</source>
</class>

<class classid="23" nclones="2" nlines="12" similarity="76">
<source file="systems/raster-vision-0.10.0/rastervision/data/vector_source/vector_tile_vector_source_config.py" startline="37" endline="50" pcid="746">
    def create_source(self, crs_transformer=None, extent=None, class_map=None):
        return VectorTileVectorSource(
            self.uri,
            self.zoom,
            self.id_field,
            crs_transformer,
            extent,
            line_bufs=self.line_bufs,
            point_bufs=self.point_bufs,
            class_inf_opts=ClassInferenceOptions(
                class_map=class_map,
                class_id_to_filter=self.class_id_to_filter,
                default_class_id=self.default_class_id))

</source>
<source file="systems/raster-vision-0.10.0/rastervision/data/vector_source/geojson_vector_source_config.py" startline="30" endline="40" pcid="773">
    def create_source(self, crs_transformer=None, extent=None, class_map=None):
        return GeoJSONVectorSource(
            self.uri,
            crs_transformer,
            line_bufs=self.line_bufs,
            point_bufs=self.point_bufs,
            class_inf_opts=ClassInferenceOptions(
                class_map=class_map,
                class_id_to_filter=self.class_id_to_filter,
                default_class_id=self.default_class_id))

</source>
</class>

<class classid="24" nclones="2" nlines="11" similarity="81">
<source file="systems/raster-vision-0.10.0/rastervision/data/label_store/chip_classification_geojson_store.py" startline="27" endline="43" pcid="898">
    def save(self, labels):
        """Save labels to URI if writable.

        Note that if the grid is inferred from polygons, only the grid will be
        written, not the original polygons.
        """
        boxes = labels.get_cells()
        class_ids = labels.get_class_ids()
        scores = list(labels.get_scores())
        geojson = boxes_to_geojson(
            boxes,
            class_ids,
            self.crs_transformer,
            self.class_map,
            scores=scores)
        json_to_file(geojson, self.uri)

</source>
<source file="systems/raster-vision-0.10.0/rastervision/data/label_store/object_detection_geojson_store.py" startline="23" endline="35" pcid="942">
    def save(self, labels):
        """Save labels to URI."""
        boxes = labels.get_boxes()
        class_ids = labels.get_class_ids().tolist()
        scores = labels.get_scores().tolist()
        geojson = boxes_to_geojson(
            boxes,
            class_ids,
            self.crs_transformer,
            self.class_map,
            scores=scores)
        json_to_file(geojson, self.uri)

</source>
</class>

<class classid="25" nclones="2" nlines="14" similarity="100">
<source file="systems/raster-vision-0.10.0/rastervision/data/label_store/object_detection_geojson_store_config.py" startline="27" endline="44" pcid="917">
                                           task_config.class_map)

    def update_for_command(self, command_type, experiment_config,
                           context=None):
        if command_type == rv.PREDICT:
            if not self.uri:
                # Construct the  URI for this prediction store,
                # using the scene ID.
                root = experiment_config.predict_uri
                uri = None
                for c in context:
                    if isinstance(c, rv.SceneConfig):
                        uri = os.path.join(root, '{}.json'.format(c.id))
                if uri:
                    self.uri = uri
                else:
                    raise rv.ConfigError(
                        'ObjectDetectionGeoJSONStoreConfig has no '
</source>
<source file="systems/raster-vision-0.10.0/rastervision/data/label_store/chip_classification_geojson_store_config.py" startline="27" endline="44" pcid="963">
                                              task_config.class_map)

    def update_for_command(self, command_type, experiment_config,
                           context=None):
        if command_type == rv.PREDICT:
            if not self.uri:
                # Construct the  URI for this prediction store,
                # using the scene ID.
                root = experiment_config.predict_uri
                uri = None
                for c in context:
                    if isinstance(c, rv.SceneConfig):
                        uri = os.path.join(root, '{}.json'.format(c.id))
                if uri:
                    self.uri = uri
                else:
                    raise rv.ConfigError(
                        'ChipClassificationGeoJSONStoreConfig has no '
</source>
</class>

<class classid="26" nclones="2" nlines="28" similarity="77">
<source file="systems/raster-vision-0.10.0/rastervision/task/semantic_segmentation.py" startline="98" endline="154" pcid="1114">
    def make_chips(self, train_scenes, validation_scenes, augmentors, tmp_dir):
        """Make training chips.

        Convert Scenes with a ground_truth_label_store into training
        chips in MLBackend-specific format, and write to URI specified in
        options.

        Args:
            train_scenes: list of Scenes
            validation_scenes: list of Scenes
                (that is disjoint from train_scenes)
            augmentors: Augmentors used to augment training data
        """

        def _process_scene(scene, type_, augment):
            with scene.activate():
                data = TrainingData()
                log.info('Making {} chips for scene: {}'.format(
                    type_, scene.id))
                windows = self.get_train_windows(scene)
                for window in windows:
                    chip = scene.raster_source.get_chip(window)
                    labels = self.get_train_labels(window, scene)

                    # If chip has ignore labels, fill in those pixels with
                    # nodata.
                    label_arr = labels.get_label_arr(window)
                    zero_inds = label_arr.ravel() == 0
                    chip_shape = chip.shape
                    if np.any(zero_inds):
                        chip = np.reshape(chip, (-1, chip.shape[2]))
                        chip[zero_inds, :] = 0
                        chip = np.reshape(chip, chip_shape)

                    data.append(chip, window, labels)
                # Shuffle data so the first N samples which are displayed in
                # Tensorboard are more diverse.
                data.shuffle()

                # Process augmentation
                if augment:
                    for augmentor in augmentors:
                        data = augmentor.process(data, tmp_dir)

                return self.backend.process_scene_data(scene, data, tmp_dir)

        def _process_scenes(scenes, type_, augment):
            return [_process_scene(scene, type_, augment) for scene in scenes]

        processed_training_results = _process_scenes(
            train_scenes, TRAIN, augment=True)
        processed_validation_results = _process_scenes(
            validation_scenes, VALIDATION, augment=False)

        self.backend.process_sceneset_results(
            processed_training_results, processed_validation_results, tmp_dir)

</source>
<source file="systems/raster-vision-0.10.0/rastervision/task/task.py" startline="88" endline="133" pcid="1149">
    def make_chips(self, train_scenes, validation_scenes, augmentors, tmp_dir):
        """Make training chips.

        Convert Scenes with a ground_truth_label_store into training
        chips in MLBackend-specific format, and write to URI specified in
        options.

        Args:
            train_scenes: list of Scenes
            validation_scenes: list of Scenes
                (that is disjoint from train_scenes)
            augmentors: Augmentors used to augment training data
        """

        def _process_scene(scene, type_, augment):
            with scene.activate():
                data = TrainingData()
                log.info('Making {} chips for scene: {}'.format(
                    type_, scene.id))
                windows = self.get_train_windows(scene)
                for window in windows:
                    chip = scene.raster_source.get_chip(window)
                    labels = self.get_train_labels(window, scene)
                    data.append(chip, window, labels)
                # Shuffle data so the first N samples which are displayed in
                # Tensorboard are more diverse.
                data.shuffle()

                # Process augmentation
                if augment:
                    for augmentor in augmentors:
                        data = augmentor.process(data, tmp_dir)

                return self.backend.process_scene_data(scene, data, tmp_dir)

        def _process_scenes(scenes, type_, augment):
            return [_process_scene(scene, type_, augment) for scene in scenes]

        processed_training_results = _process_scenes(
            train_scenes, TRAIN, augment=True)
        processed_validation_results = _process_scenes(
            validation_scenes, VALIDATION, augment=False)

        self.backend.process_sceneset_results(
            processed_training_results, processed_validation_results, tmp_dir)

</source>
</class>

<class classid="27" nclones="2" nlines="21" similarity="80">
<source file="systems/raster-vision-0.10.0/rastervision/task/semantic_segmentation_config.py" startline="56" endline="80" pcid="1161">
    def to_proto(self):
        msg = super().to_proto()
        chip_options = TaskConfigMsg.SemanticSegmentationConfig.ChipOptions(
            window_method=self.chip_options.window_method,
            target_classes=self.chip_options.target_classes,
            debug_chip_probability=self.chip_options.debug_chip_probability,
            negative_survival_probability=self.chip_options.
            negative_survival_probability,
            chips_per_scene=self.chip_options.chips_per_scene,
            target_count_threshold=self.chip_options.target_count_threshold,
            stride=self.chip_options.stride)

        conf = TaskConfigMsg.SemanticSegmentationConfig(
            chip_size=self.chip_size,
            predict_chip_size=self.predict_chip_size,
            class_items=self.class_map.to_proto(),
            chip_options=chip_options)
        msg.MergeFrom(
            TaskConfigMsg(
                semantic_segmentation_config=conf,
                predict_package_uri=self.predict_package_uri))

        return msg


</source>
<source file="systems/raster-vision-0.10.0/rastervision/task/object_detection_config.py" startline="48" endline="71" pcid="1186">
    def to_proto(self):
        msg = super().to_proto()
        chip_options = TaskConfigMsg.ObjectDetectionConfig.ChipOptions(
            neg_ratio=self.chip_options.neg_ratio,
            ioa_thresh=self.chip_options.ioa_thresh,
            window_method=self.chip_options.window_method,
            label_buffer=self.chip_options.label_buffer)

        predict_options = TaskConfigMsg.ObjectDetectionConfig.PredictOptions(
            merge_thresh=self.predict_options.merge_thresh,
            score_thresh=self.predict_options.score_thresh)

        conf = TaskConfigMsg.ObjectDetectionConfig(
            chip_size=self.chip_size,
            class_items=self.class_map.to_proto(),
            chip_options=chip_options,
            predict_options=predict_options)
        msg.MergeFrom(
            TaskConfigMsg(
                object_detection_config=conf,
                predict_package_uri=self.predict_package_uri))

        return msg

</source>
</class>

<class classid="28" nclones="2" nlines="10" similarity="80">
<source file="systems/raster-vision-0.10.0/tests/mock/raster_source.py" startline="63" endline="73" pcid="1327">
class MockRasterSourceConfig(SupressDeepCopyMixin, RasterSourceConfig):
    def __init__(self, transformers=None, channel_order=None):
        super().__init__(MOCK_SOURCE, transformers, channel_order)
        self.mock = Mock()
        self.mock.to_proto.return_value = None
        self.mock.create_source.return_value = None
        self.mock.update_for_command.return_value = None
        self.mock.save_bundle_files.return_value = (self, [])
        self.mock.load_bundle_files.return_value = self
        self.mock.for_prediction.return_value = self
        self.mock.create_local.return_value = self
</source>
<source file="systems/raster-vision-0.10.0/tests/mock/raster_transformer.py" startline="29" endline="40" pcid="1387">
                                  RasterTransformerConfig):
    def __init__(self):
        super().__init__(MOCK_TRANSFORMER)
        self.mock = Mock()

        self.mock.to_proto.return_value = None
        self.mock.create_transformer.return_value = None
        self.mock.update_for_command.return_value = None
        self.mock.save_bundle_files.return_value = (self, [])
        self.mock.load_bundle_files.return_value = self
        self.mock.for_prediction.return_value = self
        self.mock.create_local.return_value = self
</source>
</class>

<class classid="29" nclones="2" nlines="11" similarity="100">
<source file="systems/raster-vision-0.10.0/tests/mock/command.py" startline="75" endline="88" pcid="1417">

    def get_root_uri(self, experiment_config):
        mock_key = experiment_config.custom_config.get('mock_key')
        if not mock_key:
            mock_uri = experiment_config.custom_config.get('mock_uri')
            if not mock_uri:
                raise rv.ConfigError(
                    'MockCommand requires a mock_key or mock_uri '
                    'be set in the experiment custom_config')
        else:
            mock_uri = os.path.join(experiment_config.root_uri, 'mock',
                                    mock_key)

        return mock_uri
</source>
<source file="systems/raster-vision-0.10.0/tests/data-files/plugins/noop_command.py" startline="53" endline="66" pcid="1456">

    def get_root_uri(self, experiment_config):
        noop_key = experiment_config.custom_config.get('noop_key')
        if not noop_key:
            noop_uri = experiment_config.custom_config.get('noop_uri')
            if not noop_uri:
                raise rv.ConfigError(
                    'NoopCommand requires a noop_key or noop_uri '
                    'be set in the experiment custom_config')
        else:
            noop_uri = os.path.join(experiment_config.root_uri, 'noop',
                                    noop_key)

        return noop_uri
</source>
</class>

<class classid="30" nclones="2" nlines="10" similarity="100">
<source file="systems/raster-vision-0.10.0/tests/command/test_aux_command.py" startline="26" endline="43" pcid="1593">

            self.assertTrue(cmd.mock.run.called)

    def test_command_from_experiment(self):
        with RVConfig.get_tmp_dir() as tmp_dir:
            uris = [('one', '1'), ('two', '2'), ('three', '3'), ('four', '4')]

            e = mk.create_mock_experiment().to_builder() \
                                           .with_root_uri(tmp_dir) \
                                           .with_custom_config({
                                               'mock_aux_command': {
                                                   'key': 'mock',
                                                   'config': {
                                                       'uris': uris
                                                   }
                                               }
                                           }) \
                                           .build()
</source>
<source file="systems/raster-vision-0.10.0/tests/command/test_aux_command.py" startline="44" endline="61" pcid="1594">

            rv.ExperimentRunner.get_runner(rv.LOCAL).run(
                e, splits=2, commands_to_run=[mk.MOCK_AUX_COMMAND])

            # Nothing to assert here, just ensures code path runs.

    def test_command_from_experiment_case_insensitive(self):
        with RVConfig.get_tmp_dir() as tmp_dir:
            uris = [('one', '1'), ('two', '2'), ('three', '3'), ('four', '4')]

            e = mk.create_mock_experiment().to_builder() \
                                           .with_root_uri(tmp_dir) \
                                           .with_custom_config({
                                               'MOCK_AUX_COMMAND': {
                                                   'key': 'mock',
                                                   'config': {
                                                       'uris': uris
                                                   }
</source>
</class>

<class classid="31" nclones="2" nlines="15" similarity="80">
<source file="systems/raster-vision-0.10.0/tests/command/test_analyze_command.py" startline="14" endline="35" pcid="1597">
    def test_command_create(self):
        task = rv.TaskConfig.builder(mk.MOCK_TASK).build()
        with RVConfig.get_tmp_dir() as tmp_dir:
            img_path = os.path.join(tmp_dir, 'img.tif')
            chip = np.ones((2, 2, 4)).astype(np.uint8)
            chip[:, :, :] *= np.array([0, 1, 2, 3]).astype(np.uint8)
            save_img(chip, img_path)

            source = rv.data.RasterioSourceConfig(img_path)

            scenes = [rv.data.SceneConfig('', source)]
            analyzers = [
                rv.analyzer.StatsAnalyzerConfig(stats_uri='dummy_path')
            ]

            cmd_conf = rv.CommandConfig.builder(rv.ANALYZE) \
                                       .with_task(task) \
                                       .with_root_uri(tmp_dir) \
                                       .with_scenes(scenes) \
                                       .with_analyzers(analyzers) \
                                       .build()

</source>
<source file="systems/raster-vision-0.10.0/tests/command/test_eval_command.py" startline="14" endline="33" pcid="1632">
    def test_command_create(self):
        task = rv.TaskConfig.builder(mk.MOCK_TASK).build()
        with RVConfig.get_tmp_dir() as tmp_dir:
            img_path = os.path.join(tmp_dir, 'img.tif')
            chip = np.ones((2, 2, 4)).astype(np.uint8)
            chip[:, :, :] *= np.array([0, 1, 2, 3]).astype(np.uint8)
            save_img(chip, img_path)

            source = rv.data.RasterioSourceConfig(img_path)

            scenes = [rv.data.SceneConfig('scene_id', source)]
            evaluator = rv.EvaluatorConfig.builder(mk.MOCK_EVALUATOR).build()

            cmd_conf = rv.CommandConfig.builder(rv.EVAL) \
                                       .with_task(task) \
                                       .with_root_uri(tmp_dir) \
                                       .with_scenes(scenes) \
                                       .with_evaluators([evaluator]) \
                                       .build()

</source>
</class>

<class classid="32" nclones="2" nlines="12" similarity="75">
<source file="systems/raster-vision-0.10.0/tests/command/test_predict_command.py" startline="44" endline="60" pcid="1608">
            rv.CommandConfig.builder(rv.PREDICT) \
                            .with_task('') \
                            .with_backend('') \
                            .build()

    def test_no_config_error(self):
        task = rv.task.ChipClassificationConfig({})
        backend = rv.backend.KerasClassificationConfig('')
        try:
            with RVConfig.get_tmp_dir() as tmp_dir:
                rv.CommandConfig.builder(rv.PREDICT) \
                                .with_task(task) \
                                .with_root_uri(tmp_dir) \
                                .with_backend(backend) \
                                .with_scenes(['']) \
                                .build()
        except rv.ConfigError:
</source>
<source file="systems/raster-vision-0.10.0/tests/command/test_chip_command.py" startline="47" endline="61" pcid="1615">
                            .with_task('') \
                            .with_backend('') \
                            .with_val_scenes('') \
                            .build()

    def test_missing_config_val_scenes(self):
        with self.assertRaises(rv.ConfigError):
            rv.CommandConfig.builder(rv.CHIP) \
                            .with_task('') \
                            .with_backend('') \
                            .with_train_scenes('') \
                            .build()

    def test_no_config_error(self):
        task = rv.task.ChipClassificationConfig({})
</source>
</class>

<class classid="33" nclones="2" nlines="16" similarity="81">
<source file="systems/raster-vision-0.10.0/tests/command/aux/test_cogify_command.py" startline="13" endline="34" pcid="1616">
    def test_command_create(self):
        src_path = data_file_path('small-rgb-tile.tif')
        with RVConfig.get_tmp_dir() as tmp_dir:
            cog_path = os.path.join(tmp_dir, 'cog.tif')

            cmd_conf = rv.CommandConfig.builder(rv.COGIFY) \
                                       .with_root_uri(tmp_dir) \
                                       .with_config(uris=[(src_path, cog_path)],
                                                    block_size=128) \
                                       .build()

            cmd_conf = rv.command.CommandConfig.from_proto(cmd_conf.to_proto())
            cmd = cmd_conf.create_command()

            self.assertTrue(cmd, rv.command.aux.CogifyCommand)

            cmd.run(tmp_dir)

            # Check that it's cogified
            with rasterio.open(cog_path) as ds:
                self.assertEqual(ds.block_shapes, [(128, 128), (128, 128),
                                                   (128, 128)])
</source>
<source file="systems/raster-vision-0.10.0/tests/command/aux/test_cogify_command.py" startline="35" endline="57" pcid="1617">
                self.assertEqual(ds.overviews(1), [2, 4, 8, 16, 32])
                self.assertEqual(ds.compression.value, 'DEFLATE')

    def test_command_create_no_compression(self):
        src_path = data_file_path('small-rgb-tile.tif')
        with RVConfig.get_tmp_dir() as tmp_dir:
            cog_path = os.path.join(tmp_dir, 'cog.tif')

            cmd_conf = rv.CommandConfig.builder(rv.COGIFY) \
                                       .with_root_uri(tmp_dir) \
                                       .with_config(uris=[(src_path, cog_path)],
                                                    block_size=128,
                                                    compression='none') \
                                       .build()

            cmd_conf = rv.command.CommandConfig.from_proto(cmd_conf.to_proto())
            cmd = cmd_conf.create_command()

            self.assertTrue(cmd, rv.command.aux.CogifyCommand)

            cmd.run(tmp_dir)

            # Check that it's cogified
</source>
</class>

<class classid="34" nclones="2" nlines="31" similarity="87">
<source file="systems/raster-vision-0.10.0/tests/command/test_bundle_command.py" startline="32" endline="70" pcid="1621">
        raster_source = rv.RasterSourceConfig \
                          .builder(rv.RASTERIO_SOURCE) \
                          .with_uri('TEST') \
                          .with_transformer(transformer) \
                          .build()

        scene = rv.SceneConfig.builder() \
                              .with_id('TEST') \
                              .with_raster_source(raster_source) \
                              .build()
        return scene

    def test_bundle_cc_command(self):
        def get_task(tmp_dir):
            predict_package_uri = os.path.join(tmp_dir, 'predict_package.zip')
            t = rv.TaskConfig.builder(rv.CHIP_CLASSIFICATION) \
                             .with_predict_package_uri(predict_package_uri) \
                             .with_classes(['class1']) \
                             .build()
            return t

        def get_backend(task, tmp_dir):
            model_uri = os.path.join(tmp_dir, 'model')
            with open(model_uri, 'w') as f:
                f.write('DUMMY')
            b = rv.BackendConfig.builder(rv.KERAS_CLASSIFICATION) \
                                .with_task(task) \
                                .with_model_defaults(rv.RESNET50_IMAGENET) \
                                .with_model_uri(model_uri) \
                                .build()
            return b

        with RVConfig.get_tmp_dir() as tmp_dir:
            task = get_task(tmp_dir)
            backend = get_backend(task, tmp_dir)
            analyzer = self.get_analyzer(tmp_dir)
            scene = self.get_scene(tmp_dir)
            cmd = rv.CommandConfig.builder(rv.BUNDLE) \
                                  .with_task(task) \
</source>
<source file="systems/raster-vision-0.10.0/tests/command/test_bundle_command.py" startline="71" endline="111" pcid="1624">
                                  .with_root_uri(tmp_dir) \
                                  .with_backend(backend) \
                                  .with_analyzers([analyzer]) \
                                  .with_scene(scene) \
                                  .build() \
                                  .create_command(tmp_dir)

            cmd.run(tmp_dir)

            package_dir = os.path.join(tmp_dir, 'package')
            make_dir(package_dir)
            with zipfile.ZipFile(task.predict_package_uri, 'r') as package_zip:
                package_zip.extractall(path=package_dir)

            bundle_config_path = os.path.join(package_dir,
                                              'bundle_config.json')
            bundle_config = load_json_config(bundle_config_path,
                                             CommandConfigMsg())

            self.assertEqual(bundle_config.command_type, rv.BUNDLE)

            actual = set(os.listdir(package_dir))
            expected = set(['stats.json', 'model', 'bundle_config.json'])

            self.assertEqual(actual, expected)

    def test_bundle_od_command(self):
        def get_task(tmp_dir):
            predict_package_uri = os.path.join(tmp_dir, 'predict_package.zip')
            t = rv.TaskConfig.builder(rv.OBJECT_DETECTION) \
                             .with_predict_package_uri(predict_package_uri) \
                             .with_classes(['class1']) \
                             .build()
            return t

        def get_backend(task, tmp_dir):
            model_uri = os.path.join(tmp_dir, 'model')
            template_uri = data_file_path(
                'tf_object_detection/embedded_ssd_mobilenet_v1_coco.config')
            with open(model_uri, 'w') as f:
                f.write('DUMMY')
</source>
</class>

<class classid="35" nclones="2" nlines="12" similarity="83">
<source file="systems/raster-vision-0.10.0/tests/data/label_source/test_semantic_segmentation_label_source.py" startline="14" endline="25" pcid="1653">
    def test_enough_target_pixels_true(self):
        data = np.zeros((10, 10, 3), dtype=np.uint8)
        data[4:, 4:, :] = [1, 1, 1]
        raster_source = MockRasterSource([0, 1, 2], 3)
        raster_source.set_raster(data)
        rgb_class_map = ClassMap([ClassItem(id=1, color='#010101')])
        label_source = SemanticSegmentationLabelSource(
            source=raster_source, rgb_class_map=rgb_class_map)
        with label_source.activate():
            extent = Box(0, 0, 10, 10)
            self.assertTrue(label_source.enough_target_pixels(extent, 30, [1]))

</source>
<source file="systems/raster-vision-0.10.0/tests/data/label_source/test_semantic_segmentation_label_source.py" startline="26" endline="38" pcid="1654">
    def test_enough_target_pixels_false(self):
        data = np.zeros((10, 10, 3), dtype=np.uint8)
        data[7:, 7:, :] = [1, 1, 1]
        raster_source = MockRasterSource([0, 1, 2], 3)
        raster_source.set_raster(data)
        rgb_class_map = ClassMap([ClassItem(id=1, color='#010101')])
        label_source = SemanticSegmentationLabelSource(
            source=raster_source, rgb_class_map=rgb_class_map)
        with label_source.activate():
            extent = Box(0, 0, 10, 10)
            self.assertFalse(
                label_source.enough_target_pixels(extent, 30, [1]))

</source>
</class>

<class classid="36" nclones="2" nlines="13" similarity="71">
<source file="systems/raster-vision-0.10.0/tests/data/label_source/test_semantic_segmentation_label_source.py" startline="39" endline="51" pcid="1655">
    def test_get_labels(self):
        data = np.zeros((10, 10, 1), dtype=np.uint8)
        data[7:, 7:, 0] = 1
        raster_source = MockRasterSource([0, 1, 2], 3)
        raster_source.set_raster(data)
        label_source = SemanticSegmentationLabelSource(source=raster_source)
        with label_source.activate():
            window = Box.make_square(7, 7, 3)
            labels = label_source.get_labels(window=window)
            label_arr = labels.get_label_arr(window)
            expected_label_arr = np.ones((3, 3))
            np.testing.assert_array_equal(label_arr, expected_label_arr)

</source>
<source file="systems/raster-vision-0.10.0/tests/data/label_source/test_semantic_segmentation_label_source.py" startline="52" endline="66" pcid="1656">
    def test_get_labels_rgb(self):
        data = np.zeros((10, 10, 3), dtype=np.uint8)
        data[7:, 7:, :] = [1, 1, 1]
        raster_source = MockRasterSource([0, 1, 2], 3)
        raster_source.set_raster(data)
        rgb_class_map = ClassMap([ClassItem(id=1, color='#010101')])
        label_source = SemanticSegmentationLabelSource(
            source=raster_source, rgb_class_map=rgb_class_map)
        with label_source.activate():
            window = Box.make_square(7, 7, 3)
            labels = label_source.get_labels(window=window)
            label_arr = labels.get_label_arr(window)
            expected_label_arr = np.ones((3, 3))
            np.testing.assert_array_equal(label_arr, expected_label_arr)

</source>
</class>

<class classid="37" nclones="8" nlines="10" similarity="90">
<source file="systems/raster-vision-0.10.0/tests/data/label_source/test_chip_classification_label_source.py" startline="81" endline="93" pcid="1663">
    def test_infer_cell1(self):
        # More of box 1 is in cell.
        cell = Box.make_square(0, 0, 3)
        ioa_thresh = 0.5
        use_intersection_over_cell = False
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.class_id1)

</source>
<source file="systems/raster-vision-0.10.0/tests/data/label_source/test_chip_classification_label_source.py" startline="148" endline="160" pcid="1668">
    def test_infer_cell6(self):
        # No boxes overlap enough, use background_class_id
        cell = Box.make_square(0, 0, 10)
        ioa_thresh = 0.5
        use_intersection_over_cell = True
        background_class_id = self.background_class_id
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.background_class_id)

</source>
<source file="systems/raster-vision-0.10.0/tests/data/label_source/test_chip_classification_label_source.py" startline="107" endline="119" pcid="1665">
    def test_infer_cell3(self):
        # Only box 2 is in cell, but IOA isn't high enough.
        cell = Box.make_square(3, 3, 3)
        ioa_thresh = 0.5
        use_intersection_over_cell = False
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, None)

</source>
<source file="systems/raster-vision-0.10.0/tests/data/label_source/test_chip_classification_label_source.py" startline="120" endline="133" pcid="1666">
    def test_infer_cell4(self):
        # Both boxes inside cell, but using intersection_over_cell,
        # the IOA isn't high enough.
        cell = Box.make_square(0, 0, 10)
        ioa_thresh = 0.5
        use_intersection_over_cell = True
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, None)

</source>
<source file="systems/raster-vision-0.10.0/tests/data/label_source/test_chip_classification_label_source.py" startline="174" endline="187" pcid="1670">
    def test_infer_cell8(self):
        # box2 overlaps more than box1, but using pick_min_class_id, so
        # picks box1.
        cell = Box.make_square(1, 1, 3)
        ioa_thresh = 0.5
        use_intersection_over_cell = False
        background_class_id = None
        pick_min_class_id = True

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.class_id2)

</source>
<source file="systems/raster-vision-0.10.0/tests/data/label_source/test_chip_classification_label_source.py" startline="134" endline="147" pcid="1667">
    def test_infer_cell5(self):
        # More of box1 in cell, using intersection_over_cell with the
        # IOA high enough.
        cell = Box.make_square(0, 0, 3)
        ioa_thresh = 0.4
        use_intersection_over_cell = True
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.class_id1)

</source>
<source file="systems/raster-vision-0.10.0/tests/data/label_source/test_chip_classification_label_source.py" startline="94" endline="106" pcid="1664">
    def test_infer_cell2(self):
        # More of box 2 is in cell.
        cell = Box.make_square(1, 1, 3)
        ioa_thresh = 0.5
        use_intersection_over_cell = False
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.class_id2)

</source>
<source file="systems/raster-vision-0.10.0/tests/data/label_source/test_chip_classification_label_source.py" startline="161" endline="173" pcid="1669">
    def test_infer_cell7(self):
        # Cell doesn't overlap with any boxes.
        cell = Box.make_square(10, 10, 1)
        ioa_thresh = 0.5
        use_intersection_over_cell = True
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, None)

</source>
</class>

<class classid="38" nclones="2" nlines="13" similarity="92">
<source file="systems/raster-vision-0.10.0/tests/data/label_source/test_chip_classification_label_source.py" startline="209" endline="225" pcid="1672">
        self.assertEqual(labels.get_cell_class_id(self.box1), self.class_id1)
        self.assertEqual(labels.get_cell_class_id(self.box2), self.class_id2)
        self.assertEqual(
            labels.get_cell_class_id(Box.make_square(0, 4, 4)),
            self.background_class_id)
        self.assertEqual(
            labels.get_cell_class_id(Box.make_square(4, 0, 4)),
            self.background_class_id)

    def test_get_labels_small_extent(self):
        # Extent only has enough of first box in it.
        extent = Box.make_square(0, 0, 2)

        msg = rv.LabelSourceConfig.builder(rv.CHIP_CLASSIFICATION) \
                .with_uri(self.uri) \
                .build().to_proto()
        config = rv.LabelSourceConfig.builder(rv.CHIP_CLASSIFICATION) \
</source>
<source file="systems/raster-vision-0.10.0/tests/data/label_source/test_chip_classification_label_source.py" startline="226" endline="242" pcid="1673">
                   .from_proto(msg).build()
        source = config.create_source(self.task_config, extent,
                                      self.crs_transformer, self.temp_dir.name)
        labels = source.get_labels()

        cells = labels.get_cells()
        self.assertEqual(len(cells), 1)
        class_id = labels.get_cell_class_id(self.box1)
        self.assertEqual(class_id, self.class_id1)
        class_id = labels.get_cell_class_id(self.box2)
        self.assertEqual(class_id, None)

    def test_get_labels(self):
        # Extent contains both boxes.
        extent = Box.make_square(0, 0, 8)

        msg = rv.LabelSourceConfig.builder(rv.CHIP_CLASSIFICATION) \
</source>
</class>

<class classid="39" nclones="3" nlines="32" similarity="71">
<source file="systems/raster-vision-0.10.0/tests/data/label_source/test_object_detection_label_source.py" startline="23" endline="70" pcid="1681">
    def setUp(self):
        self.prev_keys = (os.environ.get('AWS_ACCESS_KEY_ID'),
                          os.environ.get('AWS_SECRET_ACCESS_KEY'))
        os.environ['AWS_ACCESS_KEY_ID'] = 'DUMMY'
        os.environ['AWS_SECRET_ACCESS_KEY'] = 'DUMMY'
        self.mock_s3 = mock_s3()
        self.mock_s3.start()

        self.file_name = 'labels.json'
        self.temp_dir = RVConfig.get_tmp_dir()
        self.file_path = os.path.join(self.temp_dir.name, self.file_name)

        self.crs_transformer = DoubleCRSTransformer()
        self.geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[0., 0.], [0., 1.], [1., 1.], [1., 0.],
                                     [0., 0.]]]
                },
                'properties': {
                    'class_id': 1,
                    'score': 0.9
                }
            }, {
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[1., 1.], [1., 2.], [2., 2.], [2., 1.],
                                     [1., 1.]]]
                },
                'properties': {
                    'score': 0.9,
                    'class_id': 2
                }
            }]
        }

        self.extent = Box.make_square(0, 0, 10)
        self.class_map = ClassMap([ClassItem(1, 'car'), ClassItem(2, 'house')])

        json_to_file(self.geojson, self.file_path)

</source>
<source file="systems/raster-vision-0.10.0/tests/data/label_store/test_object_detection_geojson_store.py" startline="19" endline="59" pcid="1787">
    def setUp(self):
        self.file_name = 'labels.json'
        self.temp_dir = RVConfig.get_tmp_dir()
        self.file_path = os.path.join(self.temp_dir.name, self.file_name)

        self.crs_transformer = DoubleCRSTransformer()
        self.geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[0., 0.], [0., 1.], [1., 1.], [1., 0.],
                                     [0., 0.]]]
                },
                'properties': {
                    'class_id': 1,
                    'score': 0.9
                }
            }, {
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[1., 1.], [1., 2.], [2., 2.], [2., 1.],
                                     [1., 1.]]]
                },
                'properties': {
                    'score': 0.9,
                    'class_id': 2
                }
            }]
        }

        self.extent = Box.make_square(0, 0, 10)
        self.class_map = ClassMap([ClassItem(1, 'car'), ClassItem(2, 'house')])

        json_to_file(self.geojson, self.file_path)

</source>
<source file="systems/raster-vision-0.10.0/tests/data/label_store/test_chip_classification_geojson_store.py" startline="14" endline="57" pcid="1783">
    def setUp(self):
        self.crs_transformer = DoubleCRSTransformer()
        self.geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[0., 0.], [0., 1.], [1., 1.], [1., 0.],
                                     [0., 0.]]]
                },
                'properties': {
                    'class_name': 'car',
                    'class_id': 1
                }
            }, {
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[1., 1.], [1., 2.], [2., 2.], [2., 1.],
                                     [1., 1.]]]
                },
                'properties': {
                    'class_name': 'house',
                    'class_id': 2
                }
            }]
        }

        self.class_map = ClassMap([ClassItem(1, 'car'), ClassItem(2, 'house')])

        class MockTaskConfig():
            def __init__(self, class_map):
                self.class_map = class_map

        self.task_config = MockTaskConfig(self.class_map)
        self.temp_dir = RVConfig.get_tmp_dir()
        self.uri = os.path.join(self.temp_dir.name, 'labels.json')

        json_to_file(self.geojson, self.uri)

</source>
</class>

<class classid="40" nclones="2" nlines="25" similarity="88">
<source file="systems/raster-vision-0.10.0/tests/data/raster_source/test_rasterio_source.py" startline="20" endline="46" pcid="1692">
    def test_nodata_val(self):
        with RVConfig.get_tmp_dir() as temp_dir:
            # make geotiff filled with ones and zeros with nodata == 1
            image_path = os.path.join(temp_dir, 'temp.tif')
            height = 100
            width = 100
            nb_channels = 3
            with rasterio.open(
                    image_path,
                    'w',
                    driver='GTiff',
                    height=height,
                    width=width,
                    count=nb_channels,
                    dtype=np.uint8,
                    nodata=1) as image_dataset:
                im = np.random.randint(
                    0, 2, (height, width, nb_channels)).astype(np.uint8)
                for channel in range(nb_channels):
                    image_dataset.write(im[:, :, channel], channel + 1)

            source = rv.RasterSourceConfig.builder(rv.RASTERIO_SOURCE) \
                                          .with_uri(image_path) \
                                          .build() \
                                          .create_source(tmp_dir=temp_dir)
            with source.activate():
                out_chip = source.get_image_array()
</source>
<source file="systems/raster-vision-0.10.0/tests/data/raster_source/test_rasterio_source.py" startline="47" endline="74" pcid="1693">
                expected_out_chip = np.zeros((height, width, nb_channels))
                np.testing.assert_equal(out_chip, expected_out_chip)

    def test_mask(self):
        with RVConfig.get_tmp_dir() as temp_dir:
            # make geotiff filled with ones and zeros and mask the whole image
            image_path = os.path.join(temp_dir, 'temp.tif')
            height = 100
            width = 100
            nb_channels = 3
            with rasterio.open(
                    image_path,
                    'w',
                    driver='GTiff',
                    height=height,
                    width=width,
                    count=nb_channels,
                    dtype=np.uint8) as image_dataset:
                im = np.random.randint(
                    0, 2, (height, width, nb_channels)).astype(np.uint8)
                for channel in range(nb_channels):
                    image_dataset.write(im[:, :, channel], channel + 1)
                image_dataset.write_mask(
                    np.zeros(im.shape[0:2]).astype(np.bool))

            source = rv.RasterSourceConfig.builder(rv.RASTERIO_SOURCE) \
                                          .with_uri(image_path) \
                                          .build() \
</source>
</class>

<class classid="41" nclones="2" nlines="16" similarity="93">
<source file="systems/raster-vision-0.10.0/tests/data/raster_source/test_rasterio_source.py" startline="93" endline="114" pcid="1696">
        source = rv.data.RasterioSourceConfig(uris=[img_path],
                                              channel_order=channel_order) \
                        .create_source(tmp_dir=None)

        with source.activate():
            out_chip = source.get_raw_image_array()
            self.assertEqual(out_chip.shape[2], 3)

    def test_shift_x(self):
        # Specially-engineered image w/ one meter per pixel resolution
        # in the x direction.
        img_path = data_file_path('ones.tif')
        channel_order = [0]

        msg = rv.data.RasterioSourceConfig(uris=[img_path],
                                           x_shift_meters=1.0,
                                           y_shift_meters=0.0,
                                           channel_order=channel_order) \
                     .to_proto()

        tmp_dir = RVConfig.get_tmp_dir().name
        make_dir(tmp_dir)
</source>
<source file="systems/raster-vision-0.10.0/tests/data/raster_source/test_rasterio_source.py" startline="115" endline="136" pcid="1697">
        source = rv.RasterSourceConfig.from_proto(msg) \
                                      .create_source(tmp_dir=tmp_dir)

        with source.activate():
            extent = source.get_extent()
            data = source.get_chip(extent)
            self.assertEqual(data.sum(), 2**16 - 256)
            column = data[:, 255, 0]
            self.assertEqual(column.sum(), 0)

    def test_shift_y(self):
        # Specially-engineered image w/ one meter per pixel resolution
        # in the y direction.
        img_path = data_file_path('ones.tif')
        channel_order = [0]

        msg = rv.data.RasterioSourceConfig(uris=[img_path],
                                           x_shift_meters=0.0,
                                           y_shift_meters=1.0,
                                           channel_order=channel_order) \
                     .to_proto()

</source>
</class>

<class classid="42" nclones="2" nlines="12" similarity="91">
<source file="systems/raster-vision-0.10.0/tests/data/vector_source/test_geojson_vector_source.py" startline="127" endline="142" pcid="1747">

        feats = trans_geojson['features']
        self.assertEqual(len(feats), 2)
        self.assertEqual(feats[0]['geometry']['type'], 'Polygon')
        self.assertEqual(feats[1]['geometry']['type'], 'Polygon')

    def test_transform_geojson_line_buf(self):
        geom = {'type': 'LineString', 'coordinates': [[10, 10], [10, 20]]}
        geojson = self.geom_to_geojson(geom)

        trans_geojson = self.transform_geojson(geojson, line_bufs={1: 5.0})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).buffer(5.0).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(geojson, line_bufs={2: 5.0})
        trans_geom = trans_geojson['features'][0]['geometry']
</source>
<source file="systems/raster-vision-0.10.0/tests/data/vector_source/test_geojson_vector_source.py" startline="143" endline="158" pcid="1748">
        self.assertTrue(shape(geom).buffer(1.0).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(geojson, line_bufs={1: None})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).equals(shape(trans_geom)))

    def test_transform_point_buf(self):
        geom = {'type': 'Point', 'coordinates': [10, 10]}
        geojson = self.geom_to_geojson(geom)

        trans_geojson = self.transform_geojson(geojson, point_bufs={1: 5.0})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).buffer(5.0).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(geojson, point_bufs={2: 5.0})
        trans_geom = trans_geojson['features'][0]['geometry']
</source>
</class>

<class classid="43" nclones="3" nlines="35" similarity="89">
<source file="systems/raster-vision-0.10.0/tests/utils/test_misc.py" startline="57" endline="107" pcid="1792">
    def test_set_nested_keys_finds_nested(self):
        d = {
            'one': 1,
            'two': 2,
            'three': {
                'four': 4,
                'five': 5,
                'six': [
                    {
                        'seven': 7
                    },
                    {
                        'eight': 8
                    },
                    {
                        'nine': 9
                    },
                ],
                'ten': {
                    'eleven': 11
                }
            }
        }

        expected = {
            'one': 1,
            'two': 2,
            'three': {
                'four': 4,
                'five': 55,
                'six': [
                    {
                        'seven': 7
                    },
                    {
                        'eight': 8
                    },
                    {
                        'nine': 9
                    },
                ],
                'ten': {
                    'eleven': 11
                }
            }
        }

        set_nested_keys(d, {'five': 55})

        self.assertEqual(d, expected)

</source>
<source file="systems/raster-vision-0.10.0/tests/utils/test_misc.py" startline="159" endline="212" pcid="1794">
    def test_set_nested_keys_sets_missing_keys_in_dict(self):
        d = {
            'one': 1,
            'two': 2,
            'three': {
                'four': 4,
                'five': 5,
                'six': [
                    {
                        'seven': 7
                    },
                    {
                        'eight': 8
                    },
                    {
                        'nine': 9
                    },
                ],
                'ten': {
                    'eleven': 11
                }
            }
        }

        expected = {
            'one': 1,
            'two': 2,
            'three': {
                'four': 4,
                'five': 5,
                'six': [
                    {
                        'seven': 7
                    },
                    {
                        'eight': 8
                    },
                    {
                        'nine': 9
                    },
                ],
                'ten': {
                    'eleven': 11
                },
                'twelve': 12
            }
        }

        mod = {'three': {'twelve': 12}}

        set_nested_keys(d, mod, set_missing_keys=True)

        self.assertEqual(d, expected)

</source>
<source file="systems/raster-vision-0.10.0/tests/utils/test_misc.py" startline="108" endline="158" pcid="1793">
    def test_set_nested_keys_ignores_missing_keys(self):
        d = {
            'one': 1,
            'two': 2,
            'three': {
                'four': 4,
                'five': 5,
                'six': [
                    {
                        'seven': 7
                    },
                    {
                        'eight': 8
                    },
                    {
                        'nine': 9
                    },
                ],
                'ten': {
                    'eleven': 11
                }
            }
        }

        expected = {
            'one': 1,
            'two': 2,
            'three': {
                'four': 4,
                'five': 5,
                'six': [
                    {
                        'seven': 7
                    },
                    {
                        'eight': 8
                    },
                    {
                        'nine': 9
                    },
                ],
                'ten': {
                    'eleven': 11
                }
            }
        }

        set_nested_keys(d, {'twenty': 20}, ignore_missing_keys=True)

        self.assertEqual(d, expected)

</source>
</class>

<class classid="44" nclones="3" nlines="11" similarity="81">
<source file="systems/raster-vision-0.10.0/tests/utils/test_files.py" startline="136" endline="150" pcid="1815">
    def setUp(self):
        # Setup mock S3 bucket.
        self.mock_s3 = mock_s3()
        self.mock_s3.start()
        self.s3 = boto3.client('s3')
        self.bucket_name = 'mock_bucket'
        self.s3.create_bucket(Bucket=self.bucket_name)

        self.content_str = 'hello'
        self.file_name = 'hello.txt'
        self.s3_path = 's3://{}/{}'.format(self.bucket_name, self.file_name)

        self.temp_dir = RVConfig.get_tmp_dir()
        self.local_path = os.path.join(self.temp_dir.name, self.file_name)

</source>
<source file="systems/raster-vision-0.10.0/tests/utils/test_files.py" startline="524" endline="536" pcid="1856">
    def setUp(self):
        # Setup mock S3 bucket.
        self.mock_s3 = mock_s3()
        self.mock_s3.start()
        self.s3 = boto3.client('s3')
        self.bucket_name = 'mock_bucket'
        self.s3.create_bucket(Bucket=self.bucket_name)

        self.content_str = 'hello'
        self.file_name = 'hello.txt'
        self.temp_dir = RVConfig.get_tmp_dir()
        self.cache_dir = os.path.join(self.temp_dir.name, 'cache')

</source>
<source file="systems/raster-vision-0.10.0/tests/utils/test_files.py" startline="181" endline="195" pcid="1819">
    def setUp(self):
        # Setup mock S3 bucket.
        self.mock_s3 = mock_s3()
        self.mock_s3.start()
        self.s3 = boto3.client('s3')
        self.bucket_name = 'mock_bucket'
        self.s3.create_bucket(Bucket=self.bucket_name)

        self.content_str = 'hello'
        self.file_name = 'hello.txt'
        self.s3_path = 's3://{}/{}'.format(self.bucket_name, self.file_name)

        self.temp_dir = RVConfig.get_tmp_dir()
        self.local_path = os.path.join(self.temp_dir.name, self.file_name)

</source>
</class>

<class classid="45" nclones="3" nlines="10" similarity="70">
<source file="systems/raster-vision-0.10.0/tests/utils/test_files.py" startline="307" endline="320" pcid="1832">
    def test_last_modified_s3(self):
        path = os.path.join(self.temp_dir.name, 'lorem', 'ipsum1.txt')
        s3_path = 's3://{}/lorem1.txt'.format(self.bucket_name)
        directory = os.path.dirname(path)
        make_dir(directory, check_empty=False)

        fs = FileSystem.get_file_system(s3_path, 'r')

        str_to_file(self.lorem, path)
        upload_or_copy(path, s3_path)
        stamp = fs.last_modified(s3_path)

        self.assertTrue(isinstance(stamp, datetime.datetime))

</source>
<source file="systems/raster-vision-0.10.0/tests/utils/test_files.py" startline="321" endline="333" pcid="1833">
    def test_list_paths_s3(self):
        path = os.path.join(self.temp_dir.name, 'lorem', 'ipsum.txt')
        s3_path = 's3://{}/xxx/lorem.txt'.format(self.bucket_name)
        s3_directory = 's3://{}/xxx/'.format(self.bucket_name)
        directory = os.path.dirname(path)
        make_dir(directory, check_empty=False)

        str_to_file(self.lorem, path)
        upload_or_copy(path, s3_path)

        list_paths(s3_directory)
        self.assertEqual(len(list_paths(s3_directory)), 1)

</source>
<source file="systems/raster-vision-0.10.0/tests/utils/test_files.py" startline="415" endline="427" pcid="1842">
    def test_copy_to_local(self):
        path1 = os.path.join(self.temp_dir.name, 'lorem', 'ipsum.txt')
        path2 = os.path.join(self.temp_dir.name, 'yyy', 'ipsum.txt')
        dir1 = os.path.dirname(path1)
        dir2 = os.path.dirname(path2)
        make_dir(dir1, check_empty=False)
        make_dir(dir2, check_empty=False)

        str_to_file(self.lorem, path1)

        upload_or_copy(path1, path2)
        self.assertEqual(len(list_paths(dir2)), 1)

</source>
</class>

<class classid="46" nclones="2" nlines="10" similarity="100">
<source file="systems/raster-vision-0.10.0/tests/utils/test_files.py" startline="378" endline="390" pcid="1839">
    def test_sync_from_dir_local(self):
        path = os.path.join(self.temp_dir.name, 'lorem', 'ipsum.txt')
        src = os.path.dirname(path)
        dst = os.path.join(self.temp_dir.name, 'xxx')
        make_dir(src, check_empty=False)
        make_dir(dst, check_empty=False)

        fs = FileSystem.get_file_system(path, 'r')
        fs.write_bytes(path, bytes([0x00, 0x01]))
        sync_from_dir(src, dst, delete=True)

        self.assertEqual(len(list_paths(dst)), 1)

</source>
<source file="systems/raster-vision-0.10.0/tests/utils/test_files.py" startline="402" endline="414" pcid="1841">
    def test_sync_to_dir_local(self):
        path = os.path.join(self.temp_dir.name, 'lorem', 'ipsum.txt')
        src = os.path.dirname(path)
        dst = os.path.join(self.temp_dir.name, 'xxx')
        make_dir(src, check_empty=False)
        make_dir(dst, check_empty=False)

        fs = FileSystem.get_file_system(path, 'r')
        fs.write_bytes(path, bytes([0x00, 0x01]))
        sync_to_dir(src, dst, delete=True)

        self.assertEqual(len(list_paths(dst)), 1)

</source>
</class>

<class classid="47" nclones="2" nlines="10" similarity="90">
<source file="systems/raster-vision-0.10.0/tests/evaluation/test_class_evaluation_item.py" startline="20" endline="30" pcid="1894">
    def test_merge_first_empty(self):
        a = ClassEvaluationItem()
        b = ClassEvaluationItem(
            precision=1, recall=1, f1=1, count_error=0, gt_count=1)
        a.merge(b)
        self.assertEqual(a.precision, 1)
        self.assertEqual(a.recall, 1)
        self.assertEqual(a.f1, 1)
        self.assertEqual(a.count_error, 0)
        self.assertEqual(a.gt_count, 1)

</source>
<source file="systems/raster-vision-0.10.0/tests/evaluation/test_class_evaluation_item.py" startline="31" endline="41" pcid="1895">
    def test_merge_second_empty(self):
        a = ClassEvaluationItem(
            precision=1, recall=1, f1=1, count_error=0, gt_count=1)
        b = ClassEvaluationItem()
        a.merge(b)
        self.assertEqual(a.precision, 1)
        self.assertEqual(a.recall, 1)
        self.assertEqual(a.f1, 1)
        self.assertEqual(a.count_error, 0)
        self.assertEqual(a.gt_count, 1)

</source>
</class>

<class classid="48" nclones="3" nlines="21" similarity="76">
<source file="systems/raster-vision-0.10.0/tests/evaluation/test_object_detection_evaluation.py" startline="38" endline="62" pcid="1901">
    def test_compute(self):
        class_map = self.make_class_map()
        eval = ObjectDetectionEvaluation(class_map)
        gt_labels = self.make_ground_truth_labels()
        pred_labels = self.make_predicted_labels()

        eval.compute(gt_labels, pred_labels)
        eval_item1 = eval.class_to_eval_item[1]
        self.assertEqual(eval_item1.gt_count, 2)
        self.assertEqual(eval_item1.precision, 1.0)
        self.assertEqual(eval_item1.recall, 1.0)
        self.assertEqual(eval_item1.f1, 1.0)

        eval_item2 = eval.class_to_eval_item[2]
        self.assertEqual(eval_item2.gt_count, 2)
        self.assertEqual(eval_item2.precision, 1.0)
        self.assertEqual(eval_item2.recall, 0.5)
        self.assertEqual(eval_item2.f1, 2 / 3)

        avg_item = eval.avg_item
        self.assertEqual(avg_item.gt_count, 4)
        self.assertAlmostEqual(avg_item.precision, 1.0)
        self.assertEqual(avg_item.recall, 0.75)
        self.assertAlmostEqual(avg_item.f1, 0.83, places=2)

</source>
<source file="systems/raster-vision-0.10.0/tests/evaluation/test_object_detection_evaluation.py" startline="63" endline="87" pcid="1902">
    def test_compute_no_preds(self):
        class_map = self.make_class_map()
        eval = ObjectDetectionEvaluation(class_map)
        gt_labels = self.make_ground_truth_labels()
        pred_labels = ObjectDetectionLabels.make_empty()

        eval.compute(gt_labels, pred_labels)
        eval_item1 = eval.class_to_eval_item[1]
        self.assertEqual(eval_item1.gt_count, 2)
        self.assertEqual(eval_item1.precision, None)
        self.assertEqual(eval_item1.recall, 0.0)
        self.assertEqual(eval_item1.f1, None)

        eval_item2 = eval.class_to_eval_item[2]
        self.assertEqual(eval_item2.gt_count, 2)
        self.assertEqual(eval_item2.precision, None)
        self.assertEqual(eval_item2.recall, 0.0)
        self.assertEqual(eval_item2.f1, None)

        avg_item = eval.avg_item
        self.assertEqual(avg_item.gt_count, 4)
        self.assertEqual(avg_item.precision, 0.0)
        self.assertEqual(avg_item.recall, 0.0)
        self.assertEqual(avg_item.f1, 0.0)

</source>
<source file="systems/raster-vision-0.10.0/tests/evaluation/test_object_detection_evaluation.py" startline="88" endline="113" pcid="1903">
    def test_compute_no_ground_truth(self):
        class_map = self.make_class_map()
        eval = ObjectDetectionEvaluation(class_map)
        gt_labels = ObjectDetectionLabels.make_empty()
        pred_labels = self.make_predicted_labels()

        eval.compute(gt_labels, pred_labels)
        eval_item1 = eval.class_to_eval_item[1]
        self.assertEqual(eval_item1.gt_count, 0)
        self.assertEqual(eval_item1.precision, None)
        self.assertEqual(eval_item1.recall, None)
        self.assertEqual(eval_item1.f1, None)

        eval_item2 = eval.class_to_eval_item[2]
        self.assertEqual(eval_item2.gt_count, 0)
        self.assertEqual(eval_item2.precision, None)
        self.assertEqual(eval_item2.recall, None)
        self.assertEqual(eval_item2.f1, None)

        avg_item = eval.avg_item
        self.assertEqual(avg_item.gt_count, 0)
        self.assertEqual(avg_item.precision, None)
        self.assertEqual(avg_item.recall, None)
        self.assertEqual(avg_item.f1, None)


</source>
</class>

<class classid="49" nclones="3" nlines="14" similarity="71">
<source file="systems/raster-vision-0.10.0/tests/evaluation/test_semantic_segmentation_evaluator.py" startline="86" endline="99" pcid="1908">
    def test_evaluator(self):
        class_map = ClassMap([
            ClassItem(id=1, name='one'),
            ClassItem(id=2, name='two'),
        ])
        output_uri = join(self.tmp_dir.name, 'out.json')
        scenes = [self.get_scene(1), self.get_scene(2)]
        evaluator = SemanticSegmentationEvaluator(class_map, output_uri, None)
        evaluator.process(scenes, self.tmp_dir.name)
        eval_json = json.loads(file_to_str(output_uri))
        exp_eval_json = json.loads(
            file_to_str(data_file_path('expected-eval.json')))
        self.assertDictEqual(eval_json, exp_eval_json)

</source>
<source file="systems/raster-vision-0.10.0/tests/evaluation/test_semantic_segmentation_evaluator.py" startline="120" endline="140" pcid="1910">
    def test_vector_evaluator_with_aoi(self):
        class_map = ClassMap([
            ClassItem(id=1, name='one'),
        ])
        output_uri = join(self.tmp_dir.name, 'raster-out.json')
        vector_output_uri = join(self.tmp_dir.name, 'vector-out.json')
        scenes = [self.get_vector_scene(1, use_aoi=True)]
        evaluator = SemanticSegmentationEvaluator(class_map, output_uri,
                                                  vector_output_uri)
        evaluator.process(scenes, self.tmp_dir.name)
        vector_eval_json = json.loads(file_to_str(vector_output_uri))
        exp_vector_eval_json = json.loads(
            file_to_str(data_file_path('expected-vector-eval-with-aoi.json')))

        # NOTE:  The precision  and recall  values found  in the  file
        # `expected-vector-eval.json`  are equal to fractions of  the
        # form (n-1)/n for  n <= 7 which  can be seen to  be (and have
        # been manually verified to be) correct.
        self.assertDictEqual(vector_eval_json, exp_vector_eval_json)


</source>
<source file="systems/raster-vision-0.10.0/tests/evaluation/test_semantic_segmentation_evaluator.py" startline="100" endline="119" pcid="1909">
    def test_vector_evaluator(self):
        class_map = ClassMap([
            ClassItem(id=1, name='one'),
            ClassItem(id=2, name='two'),
        ])
        output_uri = join(self.tmp_dir.name, 'raster-out.json')
        vector_output_uri = join(self.tmp_dir.name, 'vector-out.json')
        scenes = [self.get_vector_scene(1), self.get_vector_scene(2)]
        evaluator = SemanticSegmentationEvaluator(class_map, output_uri,
                                                  vector_output_uri)
        evaluator.process(scenes, self.tmp_dir.name)
        vector_eval_json = json.loads(file_to_str(vector_output_uri))
        exp_vector_eval_json = json.loads(
            file_to_str(data_file_path('expected-vector-eval.json')))
        # NOTE:  The precision  and recall  values found  in the  file
        # `expected-vector-eval.json`  are equal to fractions of  the
        # form (n-1)/n for  n <= 7 which  can be seen to  be (and have
        # been manually verified to be) correct.
        self.assertDictEqual(vector_eval_json, exp_vector_eval_json)

</source>
</class>

<class classid="50" nclones="3" nlines="20" similarity="85">
<source file="systems/raster-vision-0.10.0/tests/task/test_semantic_segmentation_config.py" startline="22" endline="48" pcid="1915">
        self.assertListEqual(t.class_map.get_items(), expected)
        self.assertListEqual(t.chip_options.target_classes, [1, 2])

    def test_build_task_from_proto(self):
        task_config = {
            'task_type': rv.SEMANTIC_SEGMENTATION,
            'semantic_segmentation_config': {
                'chip_options': {
                    'debug_chip_probability': 0.75
                },
                'chip_size':
                500,
                'class_items': [{
                    'id': 1,
                    'name': 'car',
                    'color': 'red'
                }, {
                    'id': 2,
                    'name': 'building',
                    'color': 'blue'
                }]
            }
        }
        msg = json_format.Parse(json.dumps(task_config), TaskConfigMsg())
        task = rv.TaskConfig.from_proto(msg)

        self.assertEqual(task.class_map.get_by_name('building').id, 2)
</source>
<source file="systems/raster-vision-0.10.0/tests/task/test_object_detection_config.py" startline="21" endline="47" pcid="1924">
        self.assertListEqual(t.class_map.get_items(), expected)

    def test_build_task_from_proto(self):
        task_config = {
            'task_type': rv.OBJECT_DETECTION,
            'object_detection_config': {
                'chip_size':
                500,
                'class_items': [{
                    'id': 1,
                    'name': 'car',
                    'color': 'red'
                }, {
                    'id': 2,
                    'name': 'building',
                    'color': 'blue'
                }, {
                    'id': 3,
                    'name': 'background',
                    'color': 'black'
                }]
            }
        }
        msg = json_format.Parse(json.dumps(task_config), TaskConfigMsg())
        task = rv.TaskConfig.from_proto(msg)

        self.assertEqual(task.class_map.get_by_name('building').id, 2)
</source>
<source file="systems/raster-vision-0.10.0/tests/task/test_chip_classification_config.py" startline="21" endline="48" pcid="1919">
        self.assertListEqual(t.class_map.get_items(), expected)

    def test_build_task_from_proto(self):
        task_config = {
            'task_type': rv.CHIP_CLASSIFICATION,
            'chip_classification_config': {
                'chip_size':
                500,
                'class_items': [{
                    'id': 1,
                    'name': 'car',
                    'color': 'red'
                }, {
                    'id': 2,
                    'name': 'building',
                    'color': 'blue'
                }, {
                    'id': 3,
                    'name': 'background',
                    'color': 'black'
                }]
            }
        }
        msg = json_format.Parse(json.dumps(task_config), TaskConfigMsg())

        task = rv.TaskConfig.from_proto(msg)

        self.assertEqual(task.class_map.get_by_name('building').id, 2)
</source>
</class>

<class classid="51" nclones="3" nlines="12" similarity="100">
<source file="systems/raster-vision-0.10.0/tests/task/test_semantic_segmentation_config.py" startline="49" endline="68" pcid="1916">
        self.assertEqual(task.chip_size, 500)
        self.assertEqual(task.chip_options.debug_chip_probability, 0.75)

    def test_create_proto_from_task(self):
        t = rv.TaskConfig.builder(rv.SEMANTIC_SEGMENTATION) \
                         .with_classes(['car', 'boat']) \
                         .with_chip_size(500) \
                         .build()

        msg = t.to_proto()

        expected_classes = [
            ClassItemMsg(name='car', id=1),
            ClassItemMsg(name='boat', id=2)
        ]

        self.assertEqual(msg.task_type, rv.SEMANTIC_SEGMENTATION)
        self.assertEqual(msg.semantic_segmentation_config.chip_size, 500)

        actual_class_items = dict(
</source>
<source file="systems/raster-vision-0.10.0/tests/task/test_object_detection_config.py" startline="48" endline="66" pcid="1925">
        self.assertEqual(task.chip_size, 500)

    def test_create_proto_from_task(self):
        t = rv.TaskConfig.builder(rv.OBJECT_DETECTION) \
                         .with_classes(['car', 'boat']) \
                         .with_chip_size(500) \
                         .build()

        msg = t.to_proto()

        expected_classes = [
            ClassItemMsg(name='car', id=1),
            ClassItemMsg(name='boat', id=2)
        ]

        self.assertEqual(msg.task_type, rv.OBJECT_DETECTION)
        self.assertEqual(msg.object_detection_config.chip_size, 500)

        actual_class_items = dict(
</source>
<source file="systems/raster-vision-0.10.0/tests/task/test_chip_classification_config.py" startline="49" endline="67" pcid="1920">
        self.assertEqual(task.chip_size, 500)

    def test_create_proto_from_task(self):
        t = rv.TaskConfig.builder(rv.CHIP_CLASSIFICATION) \
                         .with_classes(['car', 'boat']) \
                         .with_chip_size(500) \
                         .build()

        msg = t.to_proto()

        expected_classes = [
            ClassItemMsg(name='car', id=1),
            ClassItemMsg(name='boat', id=2)
        ]

        self.assertEqual(msg.task_type, rv.CHIP_CLASSIFICATION)
        self.assertEqual(msg.chip_classification_config.chip_size, 500)

        actual_class_items = dict(
</source>
</class>

<class classid="52" nclones="2" nlines="10" similarity="90">
<source file="systems/raster-vision-0.10.0/tests/core/test_class_map.py" startline="57" endline="68" pcid="1935">

    def test_construct_from_protos(self):
        source = [
            ClassItemMsg(id=1, name='one', color='red'),
            ClassItemMsg(id=2, name='two', color='green'),
            ClassItemMsg(id=3, name='three', color='blue')
        ]
        cm = ClassMap.construct_from(source)
        for i, msg in enumerate(source):
            expected = ClassItem.from_proto(msg)
            actual = cm.get_by_id(i + 1)
            self.assertEqual(actual, expected)
</source>
<source file="systems/raster-vision-0.10.0/tests/core/test_class_map.py" startline="69" endline="80" pcid="1936">

    def test_construct_from_class_items(self):
        source = [
            ClassItem(id=1, name='one', color='red'),
            ClassItem(id=2, name='two', color='green'),
            ClassItem(id=3, name='three', color='blue')
        ]
        cm = ClassMap.construct_from(source)
        for i, item in enumerate(source):
            expected = item
            actual = cm.get_by_id(i + 1)
            self.assertEqual(actual, expected)
</source>
</class>

<class classid="53" nclones="2" nlines="45" similarity="76">
<source file="systems/raster-vision-0.10.0/integration_tests/chip_classification_tests/experiment.py" startline="8" endline="73" pcid="1997">
    def exp_main(self, root_uri, data_uri=None, full_train=False,
                 use_tf=False):
        full_train = str_to_bool(full_train)
        use_tf = str_to_bool(use_tf)

        def get_path(part):
            if full_train:
                return os.path.join(data_uri, part)
            else:
                return os.path.join(os.path.dirname(__file__), part)

        img_path = get_path('scene/image.tif')
        label_path = get_path('scene/labels.json')

        img2_path = get_path('scene/image2.tif')
        label2_path = get_path('scene/labels2.json')

        backend_conf_path = get_path('configs/backend.config')

        task = rv.TaskConfig.builder(rv.CHIP_CLASSIFICATION) \
                            .with_chip_size(200) \
                            .with_classes({
                                'car': (1, 'red'),
                                'building': (2, 'blue'),
                                'background': (3, 'black')
                            }) \
                            .with_debug(True) \
                            .build()

        if use_tf:
            pretrained_model = (
                'https://github.com/azavea/raster-vision-data/'
                'releases/download/v0.0.7/chip-classification-test-weights.hdf5'
            )

            backend = rv.BackendConfig.builder(rv.KERAS_CLASSIFICATION) \
                .with_task(task) \
                .with_debug(True) \
                .with_template(backend_conf_path) \
                .with_num_epochs(8) \
                .with_pretrained_model(pretrained_model) \
                .with_train_options(sync_interval=None,
                                    do_monitoring=False,
                                    replace_model=True) \
                .build()
        else:
            if full_train:
                backend = rv.BackendConfig.builder(rv.PYTORCH_CHIP_CLASSIFICATION) \
                    .with_task(task) \
                    .with_train_options(
                        batch_size=16,
                        num_epochs=10,
                        sync_interval=200) \
                    .build()
            else:
                pretrained_uri = (
                    'https://github.com/azavea/raster-vision-data/releases/download/'
                    'v0.9.0/pytorch_chip_classification_test.pth')
                backend = rv.BackendConfig.builder(rv.PYTORCH_CHIP_CLASSIFICATION) \
                    .with_task(task) \
                    .with_train_options(
                        batch_size=2,
                        num_epochs=1,
                        lr=1e-9) \
                    .with_pretrained_uri(pretrained_uri) \
                    .build()
</source>
<source file="systems/raster-vision-0.10.0/integration_tests/object_detection_tests/experiment.py" startline="8" endline="67" pcid="2002">
    def exp_main(self, root_uri, data_uri=None, full_train=False,
                 use_tf=False):
        full_train = str_to_bool(full_train)
        use_tf = str_to_bool(use_tf)

        def get_path(part):
            if full_train:
                return os.path.join(data_uri, part)
            else:
                return os.path.join(os.path.dirname(__file__), part)

        img_path = get_path('scene/image.tif')
        label_path = get_path('scene/labels.json')
        img2_path = get_path('scene/image2.tif')
        label2_path = get_path('scene/labels2.json')
        backend_conf_path = get_path('configs/backend.config')

        task = rv.TaskConfig.builder(rv.OBJECT_DETECTION) \
                            .with_chip_size(300) \
                            .with_classes({
                                'car': (1, 'blue'),
                                'building': (2, 'red')
                            }) \
                            .with_chip_options(neg_ratio=1.0,
                                               ioa_thresh=1.0,
                                               window_method='sliding') \
                            .with_predict_options(merge_thresh=0.1,
                                                  score_thresh=0.5) \
                            .build()

        if use_tf:
            pretrained_model = (
                'https://github.com/azavea/raster-vision-data/'
                'releases/download/v0.0.7/object-detection-test.tar.gz')

            backend = rv.BackendConfig.builder(rv.TF_OBJECT_DETECTION) \
                                    .with_task(task) \
                                    .with_num_steps(200) \
                                    .with_template(backend_conf_path) \
                                    .with_pretrained_model(pretrained_model) \
                                    .with_train_options(sync_interval=None,
                                                        do_monitoring=False,
                                                        replace_model=True) \
                                    .with_debug(True) \
                                    .build()
        else:
            if full_train:
                backend = rv.BackendConfig.builder(rv.PYTORCH_OBJECT_DETECTION) \
                    .with_task(task) \
                    .with_train_options(
                        batch_size=8,
                        num_epochs=200,
                        sync_interval=200) \
                    .build()
            else:
                pretrained_uri = (
                    'https://github.com/azavea/raster-vision-data/releases/download/'
                    'v0.9.0/pytorch_object_detection_test.pth')

                backend = rv.BackendConfig.builder(rv.PYTORCH_OBJECT_DETECTION) \
</source>
</class>

</clones>
