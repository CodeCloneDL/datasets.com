<html>
<head>
    <title>NiCad6 Clone Report</title>
    <style type="text/css">
        body {font-family:sans-serif;}
        table {background-color:white; border:0px; padding:0px; border-spacing:4px; width:auto; margin-left:30px; margin-right:auto;}
        td {background-color:rgba(192,212,238,0.8); border:0px; padding:8px; width:auto; vertical-align:top; border-radius:8px}
        pre {background-color:white; padding:4px;}
        a {color:darkblue;}
    </style>
</head>
<body>
<h2>NiCad6 Clone Report</h2>
<table>
<tr style="font-size:14pt">
<td><b>System:</b> &nbsp; pytorch-lightning-1.5.9</td>
<td><b>Clone pairs:</b> &nbsp; 89</td>
<td><b>Clone classes:</b> &nbsp; 24</td>
</tr>
<tr style="font-size:12pt">
<td style="background-color:white">Clone type: &nbsp; 3-2</td>
<td style="background-color:white">Granularity: &nbsp; functions-blind</td>
<td style="background-color:white">Max diff threshold: &nbsp; 30%</td>
<td style="background-color:white">Clone size: &nbsp; 10 - 2500 lines</td>
<td style="background-color:white">Total functions-blind: &nbsp; 1718</td>
</tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 1:</b> &nbsp; 3 fragments, nominal size 11 lines, similarity 71%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag14')" href="javascript:;">
pytorch-lightning-1.5.9/legacy/simple_classif_training.py: 108-118
</a>
<div class="mid" id="frag14" style="display:none"><pre>
    def forward(self, x):
        x = self.layer_0(x)
        x = self.layer_0a(x)
        x = self.layer_1(x)
        x = self.layer_1a(x)
        x = self.layer_2(x)
        x = self.layer_2a(x)
        x = self.layer_end(x)
        logits = F.softmax(x, dim=1)
        return logits

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1671')" href="javascript:;">
pytorch-lightning-1.5.9/pl_examples/basic_examples/mnist_examples/image_classifier_1_pytorch.py: 39-54
</a>
<div class="mid" id="frag1671" style="display:none"><pre>
    def forward(self, x):
        x = self.conv1(x)
        x = F.relu(x)
        x = self.conv2(x)
        x = F.relu(x)
        x = F.max_pool2d(x, 2)
        x = self.dropout1(x)
        x = torch.flatten(x, 1)
        x = self.fc1(x)
        x = F.relu(x)
        x = self.dropout2(x)
        x = self.fc2(x)
        output = F.log_softmax(x, dim=1)
        return output


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag688')" href="javascript:;">
pytorch-lightning-1.5.9/tests/helpers/simple_models.py: 36-46
</a>
<div class="mid" id="frag688" style="display:none"><pre>
    def forward(self, x):
        x = self.layer_0(x)
        x = self.layer_0a(x)
        x = self.layer_1(x)
        x = self.layer_1a(x)
        x = self.layer_2(x)
        x = self.layer_2a(x)
        x = self.layer_end(x)
        logits = F.softmax(x, dim=1)
        return logits

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 2:</b> &nbsp; 19 fragments, nominal size 14 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag22')" href="javascript:;">
pytorch-lightning-1.5.9/tests/accelerators/test_ddp_spawn.py: 26-43
</a>
<div class="mid" id="frag22" style="display:none"><pre>
def test_multi_gpu_early_stop_ddp_spawn(tmpdir):
    tutils.set_random_main_port()

    trainer_options = dict(
        default_root_dir=tmpdir,
        callbacks=[EarlyStopping(monitor="train_acc")],
        max_epochs=50,
        limit_train_batches=10,
        limit_val_batches=10,
        gpus=[0, 1],
        strategy="ddp_spawn",
    )

    dm = ClassifDataModule()
    model = ClassificationModel()
    tpipes.run_model_test(trainer_options, model, dm)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag334')" href="javascript:;">
pytorch-lightning-1.5.9/tests/models/test_gpu.py: 41-57
</a>
<div class="mid" id="frag334" style="display:none"><pre>
def test_multi_gpu_none_backend(tmpdir):
    """Make sure when using multiple GPUs the user can't use `accelerator = None`."""
    tutils.set_random_main_port()
    trainer_options = dict(
        default_root_dir=tmpdir,
        enable_progress_bar=False,
        max_epochs=1,
        limit_train_batches=0.2,
        limit_val_batches=0.2,
        gpus=2,
    )

    dm = ClassifDataModule()
    model = ClassificationModel()
    tpipes.run_model_test(trainer_options, model, dm)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag395')" href="javascript:;">
pytorch-lightning-1.5.9/tests/models/test_tpu.py: 217-234
</a>
<div class="mid" id="frag395" style="display:none"><pre>
def test_tpu_clip_grad_by_value(tmpdir):
    """Test if clip_gradients by value works on TPU."""
    tutils.reset_seed()
    trainer_options = dict(
        default_root_dir=tmpdir,
        enable_progress_bar=False,
        max_epochs=4,
        tpu_cores=1,
        limit_train_batches=10,
        limit_val_batches=10,
        gradient_clip_val=0.5,
        gradient_clip_algorithm="value",
    )

    model = BoringModel()
    tpipes.run_model_test(trainer_options, model, on_gpu=False, with_hpc=False)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag43')" href="javascript:;">
pytorch-lightning-1.5.9/tests/accelerators/test_dp.py: 57-79
</a>
<div class="mid" id="frag43" style="display:none"><pre>
def test_multi_gpu_early_stop_dp(tmpdir):
    """Make sure DDP works.

    with early stopping
    """
    tutils.set_random_main_port()

    dm = ClassifDataModule()
    model = CustomClassificationModelDP()

    trainer_options = dict(
        default_root_dir=tmpdir,
        callbacks=[EarlyStopping(monitor="val_acc")],
        max_epochs=50,
        limit_train_batches=10,
        limit_val_batches=10,
        gpus=[0, 1],
        strategy="dp",
    )

    tpipes.run_model_test(trainer_options, model, dm)


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag44')" href="javascript:;">
pytorch-lightning-1.5.9/tests/accelerators/test_dp.py: 81-101
</a>
<div class="mid" id="frag44" style="display:none"><pre>
def test_multi_gpu_model_dp(tmpdir):
    tutils.set_random_main_port()

    trainer_options = dict(
        default_root_dir=tmpdir,
        max_epochs=1,
        limit_train_batches=10,
        limit_val_batches=10,
        gpus=[0, 1],
        strategy="dp",
        enable_progress_bar=False,
    )

    model = BoringModel()

    tpipes.run_model_test(trainer_options, model)

    # test memory helper functions
    memory.get_memory_profile("min_max")


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag23')" href="javascript:;">
pytorch-lightning-1.5.9/tests/accelerators/test_ddp_spawn.py: 45-65
</a>
<div class="mid" id="frag23" style="display:none"><pre>
def test_multi_gpu_model_ddp_spawn(tmpdir):
    tutils.set_random_main_port()

    trainer_options = dict(
        default_root_dir=tmpdir,
        max_epochs=1,
        limit_train_batches=10,
        limit_val_batches=10,
        gpus=[0, 1],
        strategy="ddp_spawn",
        enable_progress_bar=False,
    )

    model = BoringModel()

    tpipes.run_model_test(trainer_options, model)

    # test memory helper functions
    memory.get_memory_profile("min_max")


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag394')" href="javascript:;">
pytorch-lightning-1.5.9/tests/models/test_tpu.py: 198-214
</a>
<div class="mid" id="frag394" style="display:none"><pre>
def test_tpu_grad_norm(tmpdir):
    """Test if grad_norm works on TPU."""
    tutils.reset_seed()
    trainer_options = dict(
        default_root_dir=tmpdir,
        enable_progress_bar=False,
        max_epochs=4,
        tpu_cores=1,
        limit_train_batches=0.4,
        limit_val_batches=0.4,
        gradient_clip_val=0.5,
    )

    model = BoringModel()
    tpipes.run_model_test(trainer_options, model, on_gpu=False, with_hpc=False)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag362')" href="javascript:;">
pytorch-lightning-1.5.9/tests/models/test_cpu.py: 126-145
</a>
<div class="mid" id="frag362" style="display:none"><pre>
def test_multi_cpu_model_ddp(tmpdir):
    """Make sure DDP works."""
    tutils.set_random_main_port()

    trainer_options = dict(
        default_root_dir=tmpdir,
        enable_progress_bar=False,
        max_epochs=1,
        limit_train_batches=0.4,
        limit_val_batches=0.2,
        gpus=None,
        num_processes=2,
        strategy="ddp_spawn",
    )

    dm = ClassifDataModule()
    model = ClassificationModel()
    tpipes.run_model_test(trainer_options, model, data=dm, on_gpu=False)


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag389')" href="javascript:;">
pytorch-lightning-1.5.9/tests/models/test_tpu.py: 110-127
</a>
<div class="mid" id="frag389" style="display:none"><pre>
def test_model_16bit_tpu_cores_1(tmpdir):
    """Make sure model trains on TPU."""
    tutils.reset_seed()
    trainer_options = dict(
        default_root_dir=tmpdir,
        precision=16,
        enable_progress_bar=False,
        max_epochs=2,
        tpu_cores=1,
        limit_train_batches=8,
        limit_val_batches=2,
    )

    model = BoringModel()
    tpipes.run_model_test(trainer_options, model, on_gpu=False)
    assert os.environ.get("XLA_USE_BF16") == str(1), "XLA_USE_BF16 was not set in environment variables"


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag391')" href="javascript:;">
pytorch-lightning-1.5.9/tests/models/test_tpu.py: 152-169
</a>
<div class="mid" id="frag391" style="display:none"><pre>
def test_model_16bit_tpu_cores_8(tmpdir):
    """Make sure model trains on TPU."""
    tutils.reset_seed()
    trainer_options = dict(
        default_root_dir=tmpdir,
        precision=16,
        enable_progress_bar=False,
        max_epochs=1,
        tpu_cores=8,
        limit_train_batches=4,
        limit_val_batches=4,
    )

    # 8 cores needs a big dataset
    model = SerialLoaderBoringModel()
    tpipes.run_model_test(trainer_options, model, on_gpu=False, with_hpc=False, min_acc=0.05)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag388')" href="javascript:;">
pytorch-lightning-1.5.9/tests/models/test_tpu.py: 91-107
</a>
<div class="mid" id="frag388" style="display:none"><pre>
def test_model_tpu_cores_8(tmpdir):
    """Make sure model trains on TPU."""
    tutils.reset_seed()
    trainer_options = dict(
        default_root_dir=tmpdir,
        enable_progress_bar=False,
        max_epochs=1,
        tpu_cores=8,
        limit_train_batches=4,
        limit_val_batches=4,
    )

    # 8 cores needs a big dataset
    model = SerialLoaderBoringModel()
    tpipes.run_model_test(trainer_options, model, on_gpu=False, with_hpc=False, min_acc=0.05)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag386')" href="javascript:;">
pytorch-lightning-1.5.9/tests/models/test_tpu.py: 53-68
</a>
<div class="mid" id="frag386" style="display:none"><pre>
def test_model_tpu_cores_1(tmpdir):
    """Make sure model trains on TPU."""
    tutils.reset_seed()
    trainer_options = dict(
        default_root_dir=tmpdir,
        enable_progress_bar=False,
        max_epochs=2,
        tpu_cores=1,
        limit_train_batches=4,
        limit_val_batches=4,
    )

    model = BoringModel()
    tpipes.run_model_test(trainer_options, model, on_gpu=False, with_hpc=False)


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag387')" href="javascript:;">
pytorch-lightning-1.5.9/tests/models/test_tpu.py: 72-88
</a>
<div class="mid" id="frag387" style="display:none"><pre>
def test_model_tpu_index(tmpdir, tpu_core):
    """Make sure model trains on TPU."""
    tutils.reset_seed()
    trainer_options = dict(
        default_root_dir=tmpdir,
        enable_progress_bar=False,
        max_epochs=2,
        tpu_cores=[tpu_core],
        limit_train_batches=4,
        limit_val_batches=4,
    )

    model = BoringModel()
    tpipes.run_model_test(trainer_options, model, on_gpu=False, with_hpc=False)
    assert torch_xla._XLAC._xla_get_default_device() == f"xla:{tpu_core}"


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag379')" href="javascript:;">
pytorch-lightning-1.5.9/tests/models/test_onnx.py: 90-113
</a>
<div class="mid" id="frag379" style="display:none"><pre>
def test_model_saves_on_multi_gpu(tmpdir):
    """Test that ONNX model saves on a distributed backend."""
    tutils.set_random_main_port()

    trainer_options = dict(
        default_root_dir=tmpdir,
        max_epochs=1,
        limit_train_batches=10,
        limit_val_batches=10,
        gpus=[0, 1],
        strategy="ddp_spawn",
        enable_progress_bar=False,
    )

    model = BoringModel()
    model.example_input_array = torch.randn(5, 32)

    tpipes.run_model_test(trainer_options, model, min_acc=0.08)

    file_path = os.path.join(tmpdir, "model.onnx")
    model.to_onnx(file_path)
    assert os.path.exists(file_path) is True


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag374')" href="javascript:;">
pytorch-lightning-1.5.9/tests/models/test_cpu.py: 300-316
</a>
<div class="mid" id="frag374" style="display:none"><pre>
def test_all_features_cpu_model(tmpdir):
    """Test each of the trainer options."""
    trainer_options = dict(
        default_root_dir=tmpdir,
        gradient_clip_val=1.0,
        overfit_batches=0.20,
        track_grad_norm=2,
        enable_progress_bar=False,
        accumulate_grad_batches=2,
        max_epochs=1,
        limit_train_batches=0.4,
        limit_val_batches=0.4,
    )

    model = BoringModel()

    tpipes.run_model_test(trainer_options, model, on_gpu=False, min_acc=0.01)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag414')" href="javascript:;">
pytorch-lightning-1.5.9/tests/models/test_tpu.py: 447-470
</a>
<div class="mid" id="frag414" style="display:none"><pre>
def test_tpu_host_world_size(tmpdir):
    """Test Host World size env setup on TPU."""

    class DebugModel(BoringModel):
        def on_train_start(self):
            assert os.environ.get("XRT_HOST_WORLD_SIZE") == str(1)

        def teardown(self, stage):
            assert "XRT_HOST_WORLD_SIZE" not in os.environ

    tutils.reset_seed()
    trainer_options = dict(
        default_root_dir=tmpdir,
        enable_progress_bar=False,
        max_epochs=4,
        tpu_cores=8,
        limit_train_batches=0.4,
        limit_val_batches=0.4,
    )

    model = DebugModel()
    tpipes.run_model_test(trainer_options, model, on_gpu=False, with_hpc=False)


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag390')" href="javascript:;">
pytorch-lightning-1.5.9/tests/models/test_tpu.py: 131-149
</a>
<div class="mid" id="frag390" style="display:none"><pre>
def test_model_16bit_tpu_index(tmpdir, tpu_core):
    """Make sure model trains on TPU."""
    tutils.reset_seed()
    trainer_options = dict(
        default_root_dir=tmpdir,
        precision=16,
        enable_progress_bar=False,
        max_epochs=2,
        tpu_cores=[tpu_core],
        limit_train_batches=4,
        limit_val_batches=2,
    )

    model = BoringModel()
    tpipes.run_model_test(trainer_options, model, on_gpu=False)
    assert torch_xla._XLAC._xla_get_default_device() == f"xla:{tpu_core}"
    assert os.environ.get("XLA_USE_BF16") == str(1), "XLA_USE_BF16 was not set in environment variables"


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag365')" href="javascript:;">
pytorch-lightning-1.5.9/tests/models/test_cpu.py: 171-190
</a>
<div class="mid" id="frag365" style="display:none"><pre>
def test_default_logger_callbacks_cpu_model(tmpdir):
    """Test each of the trainer options."""
    trainer_options = dict(
        default_root_dir=tmpdir,
        max_epochs=1,
        gradient_clip_val=1.0,
        overfit_batches=0.20,
        enable_progress_bar=False,
        limit_train_batches=0.01,
        limit_val_batches=0.01,
    )

    model = BoringModel()
    tpipes.run_model_test_without_loggers(trainer_options, model, min_acc=0.01)

    # test freeze on cpu
    model.freeze()
    model.unfreeze()


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag411')" href="javascript:;">
pytorch-lightning-1.5.9/tests/models/test_tpu.py: 420-444
</a>
<div class="mid" id="frag411" style="display:none"><pre>
def test_tpu_debug_mode(tmpdir):
    """Test if debug mode works on TPU."""

    class DebugModel(BoringModel):
        def on_train_start(self):
            assert os.environ.get("PT_XLA_DEBUG") == str(1), "PT_XLA_DEBUG was not set in environment variables"

        def teardown(self, stage):
            assert "PT_XLA_DEBUG" not in os.environ

    tutils.reset_seed()
    trainer_options = dict(
        default_root_dir=tmpdir,
        enable_progress_bar=False,
        max_epochs=4,
        tpu_cores=8,
        limit_train_batches=0.4,
        limit_val_batches=0.4,
        strategy=TPUSpawnPlugin(debug=True),
    )

    model = DebugModel()
    tpipes.run_model_test(trainer_options, model, on_gpu=False, with_hpc=False)


</pre></div>
</td>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 3:</b> &nbsp; 2 fragments, nominal size 24 lines, similarity 80%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag138')" href="javascript:;">
pytorch-lightning-1.5.9/tests/accelerators/test_tpu.py: 259-289
</a>
<div class="mid" id="frag138" style="display:none"><pre>
def test_auto_parameters_tying_tpus_nested_module(tmpdir):
    class SubModule(nn.Module):
        def __init__(self, layer):
            super().__init__()
            self.layer = layer

        def forward(self, x):
            return self.layer(x)

    class NestedModule(BoringModel):
        def __init__(self):
            super().__init__()
            self.layer = nn.Linear(32, 10, bias=False)
            self.net_a = SubModule(self.layer)
            self.layer_2 = nn.Linear(10, 32, bias=False)
            self.net_b = SubModule(self.layer)

        def forward(self, x):
            x = self.net_a(x)
            x = self.layer_2(x)
            x = self.net_b(x)
            return x

    model = NestedModule()

    trainer = Trainer(default_root_dir=tmpdir, limit_train_batches=5, tpu_cores=8, max_epochs=1)
    trainer.fit(model)

    assert torch.all(torch.eq(model.net_a.layer.weight, model.net_b.layer.weight))


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag863')" href="javascript:;">
pytorch-lightning-1.5.9/tests/utilities/test_parameter_tying.py: 46-77
</a>
<div class="mid" id="frag863" style="display:none"><pre>
def test_set_shared_parameters():
    model = ParameterSharingModule()
    set_shared_parameters(model, [["layer_1.weight", "layer_3.weight"]])

    assert torch.all(torch.eq(model.layer_1.weight, model.layer_3.weight))

    class SubModule(nn.Module):
        def __init__(self, layer):
            super().__init__()
            self.layer = layer

        def forward(self, x):
            return self.layer(x)

    class NestedModule(BoringModel):
        def __init__(self):
            super().__init__()
            self.layer = nn.Linear(32, 10, bias=False)
            self.net_a = SubModule(self.layer)
            self.layer_2 = nn.Linear(10, 32, bias=False)
            self.net_b = SubModule(self.layer)

        def forward(self, x):
            x = self.net_a(x)
            x = self.layer_2(x)
            x = self.net_b(x)
            return x

    model = NestedModule()
    set_shared_parameters(model, [["layer.weight", "net_a.layer.weight", "net_b.layer.weight"]])

    assert torch.all(torch.eq(model.net_a.layer.weight, model.net_b.layer.weight))
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 4:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 80%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag153')" href="javascript:;">
pytorch-lightning-1.5.9/tests/tuner/test_auto_gpu_select.py: 30-43
</a>
<div class="mid" id="frag153" style="display:none"><pre>
def test_trainer_with_gpus_options_combination_at_available_gpus_env(auto_select_gpus, gpus, expected_error):
    if expected_error:
        with pytest.raises(
            expected_error,
            match=re.escape(
                "auto_select_gpus=True, gpus=0 is not a valid configuration."
                " Please select a valid number of GPU resources when using auto_select_gpus."
            ),
        ):
            Trainer(auto_select_gpus=auto_select_gpus, gpus=gpus)
    else:
        Trainer(auto_select_gpus=auto_select_gpus, gpus=gpus)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag154')" href="javascript:;">
pytorch-lightning-1.5.9/tests/tuner/test_auto_gpu_select.py: 49-60
</a>
<div class="mid" id="frag154" style="display:none"><pre>
def test_pick_multiple_gpus(nb, expected_gpu_idxs, expected_error):
    if expected_error:
        with pytest.raises(
            expected_error,
            match=re.escape(
                "auto_select_gpus=True, gpus=0 is not a valid configuration."
                " Please select a valid number of GPU resources when using auto_select_gpus."
            ),
        ):
            pick_multiple_gpus(nb)
    else:
        assert expected_gpu_idxs == pick_multiple_gpus(nb)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 5:</b> &nbsp; 6 fragments, nominal size 43 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag155')" href="javascript:;">
pytorch-lightning-1.5.9/tests/loops/test_evaluation_loop_flow.py: 24-81
</a>
<div class="mid" id="frag155" style="display:none"><pre>
def test__eval_step__flow(tmpdir):
    """Tests that only training_step can be used."""

    class TestModel(DeterministicModel):
        def training_step(self, batch, batch_idx):
            acc = self.step(batch, batch_idx)
            acc = acc + batch_idx
            self.training_step_called = True
            return acc

        def validation_step(self, batch, batch_idx):
            self.validation_step_called = True
            if batch_idx == 0:
                out = ["1", 2, torch.tensor(2)]
            if batch_idx &gt; 0:
                out = {"something": "random"}
            return out

        def backward(self, loss, optimizer, optimizer_idx):
            return LightningModule.backward(self, loss, optimizer, optimizer_idx)

    model = TestModel()
    model.validation_step_end = None
    model.validation_epoch_end = None

    trainer = Trainer(
        default_root_dir=tmpdir,
        limit_train_batches=2,
        limit_val_batches=2,
        max_epochs=2,
        log_every_n_steps=1,
        enable_model_summary=False,
    )
    trainer.fit(model)

    # make sure correct steps were called
    assert model.validation_step_called
    assert not model.validation_step_end_called
    assert not model.validation_epoch_end_called

    # simulate training manually
    trainer.state.stage = RunningStage.TRAINING
    batch_idx, batch = 0, next(iter(model.train_dataloader()))
    train_step_out = trainer.fit_loop.epoch_loop.batch_loop.run(batch, batch_idx)

    assert len(train_step_out) == 1
    train_step_out = train_step_out[0][0]
    assert isinstance(train_step_out["loss"], torch.Tensor)
    assert train_step_out["loss"].item() == 171

    # make sure the optimizer closure returns the correct things
    opt_closure = trainer.fit_loop.epoch_loop.batch_loop.optimizer_loop._make_closure(
        batch, batch_idx, 0, trainer.optimizers[0]
    )
    opt_closure_result = opt_closure()
    assert opt_closure_result.item() == 171


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag159')" href="javascript:;">
pytorch-lightning-1.5.9/tests/loops/test_evaluation_loop_flow.py: 82-144
</a>
<div class="mid" id="frag159" style="display:none"><pre>
def test__eval_step__eval_step_end__flow(tmpdir):
    """Tests that only training_step can be used."""

    class TestModel(DeterministicModel):
        def training_step(self, batch, batch_idx):
            acc = self.step(batch, batch_idx)
            acc = acc + batch_idx
            self.training_step_called = True
            return acc

        def validation_step(self, batch, batch_idx):
            self.validation_step_called = True
            if batch_idx == 0:
                out = ["1", 2, torch.tensor(2)]
            if batch_idx &gt; 0:
                out = {"something": "random"}
            self.last_out = out
            return out

        def validation_step_end(self, out):
            self.validation_step_end_called = True
            assert self.last_out == out
            return out

        def backward(self, loss, optimizer, optimizer_idx):
            return LightningModule.backward(self, loss, optimizer, optimizer_idx)

    model = TestModel()
    model.validation_epoch_end = None

    trainer = Trainer(
        default_root_dir=tmpdir,
        limit_train_batches=2,
        limit_val_batches=2,
        max_epochs=2,
        log_every_n_steps=1,
        enable_model_summary=False,
    )
    trainer.fit(model)

    # make sure correct steps were called
    assert model.validation_step_called
    assert model.validation_step_end_called
    assert not model.validation_epoch_end_called

    trainer.state.stage = RunningStage.TRAINING
    # make sure training outputs what is expected
    batch_idx, batch = 0, next(iter(model.train_dataloader()))
    train_step_out = trainer.fit_loop.epoch_loop.batch_loop.run(batch, batch_idx)

    assert len(train_step_out) == 1
    train_step_out = train_step_out[0][0]
    assert isinstance(train_step_out["loss"], torch.Tensor)
    assert train_step_out["loss"].item() == 171

    # make sure the optimizer closure returns the correct things
    opt_closure = trainer.fit_loop.epoch_loop.batch_loop.optimizer_loop._make_closure(
        batch, batch_idx, 0, trainer.optimizers[0]
    )
    opt_closure_result = opt_closure()
    assert opt_closure_result.item() == 171


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag246')" href="javascript:;">
pytorch-lightning-1.5.9/tests/loops/test_training_loop_flow_scalar.py: 99-164
</a>
<div class="mid" id="frag246" style="display:none"><pre>
def test__training_step__epoch_end__flow_scalar(tmpdir):
    """Tests that only training_step can be used."""

    class TestModel(DeterministicModel):
        def training_step(self, batch, batch_idx):
            acc = self.step(batch, batch_idx)
            acc = acc + batch_idx

            self.training_step_called = True
            return acc

        def training_epoch_end(self, outputs):
            self.training_epoch_end_called = True

            # verify we saw the current num of batches
            assert len(outputs) == 2

            for b in outputs:
                # time = 1
                assert len(b) == 1
                assert "loss" in b
                assert isinstance(b, dict)

        def backward(self, loss, optimizer, optimizer_idx):
            return LightningModule.backward(self, loss, optimizer, optimizer_idx)

    model = TestModel()
    model.val_dataloader = None

    trainer = Trainer(
        default_root_dir=tmpdir,
        limit_train_batches=2,
        limit_val_batches=2,
        max_epochs=2,
        log_every_n_steps=1,
        enable_model_summary=False,
    )
    trainer.fit(model)

    # make sure correct steps were called
    assert model.training_step_called
    assert not model.training_step_end_called
    assert model.training_epoch_end_called

    # assert epoch end metrics were added
    assert len(trainer.callback_metrics) == 0
    assert len(trainer.progress_bar_metrics) == 0

    trainer.state.stage = RunningStage.TRAINING
    # make sure training outputs what is expected
    batch_idx, batch = 0, next(iter(model.train_dataloader()))
    train_step_out = trainer.fit_loop.epoch_loop.batch_loop.run(batch, batch_idx)

    assert len(train_step_out) == 1
    train_step_out = train_step_out[0][0]
    assert isinstance(train_step_out["loss"], torch.Tensor)
    assert train_step_out["loss"].item() == 171

    # make sure the optimizer closure returns the correct things
    opt_closure = trainer.fit_loop.epoch_loop.batch_loop.optimizer_loop._make_closure(
        batch, batch_idx, 0, trainer.optimizers[0]
    )
    opt_closure_result = opt_closure()
    assert opt_closure_result.item() == 171


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag250')" href="javascript:;">
pytorch-lightning-1.5.9/tests/loops/test_training_loop_flow_scalar.py: 165-236
</a>
<div class="mid" id="frag250" style="display:none"><pre>
def test__training_step__step_end__epoch_end__flow_scalar(tmpdir):
    """Checks train_step + training_step_end + training_epoch_end (all with scalar return from train_step)."""

    class TestModel(DeterministicModel):
        def training_step(self, batch, batch_idx):
            acc = self.step(batch, batch_idx)
            acc = acc + batch_idx

            self.training_step_called = True
            return acc

        def training_step_end(self, tr_step_output):
            assert isinstance(tr_step_output, torch.Tensor)
            assert self.count_num_graphs({"loss": tr_step_output}) == 1
            self.training_step_end_called = True
            return tr_step_output

        def training_epoch_end(self, outputs):
            self.training_epoch_end_called = True

            # verify we saw the current num of batches
            assert len(outputs) == 2

            for b in outputs:
                # time = 1
                assert len(b) == 1
                assert "loss" in b
                assert isinstance(b, dict)

        def backward(self, loss, optimizer, optimizer_idx):
            return LightningModule.backward(self, loss, optimizer, optimizer_idx)

    model = TestModel()
    model.val_dataloader = None

    trainer = Trainer(
        default_root_dir=tmpdir,
        limit_train_batches=2,
        limit_val_batches=2,
        max_epochs=2,
        log_every_n_steps=1,
        enable_model_summary=False,
    )
    trainer.fit(model)

    # make sure correct steps were called
    assert model.training_step_called
    assert model.training_step_end_called
    assert model.training_epoch_end_called

    # assert epoch end metrics were added
    assert len(trainer.callback_metrics) == 0
    assert len(trainer.progress_bar_metrics) == 0

    trainer.state.stage = RunningStage.TRAINING
    # make sure training outputs what is expected
    batch_idx, batch = 0, next(iter(model.train_dataloader()))
    train_step_out = trainer.fit_loop.epoch_loop.batch_loop.run(batch, batch_idx)

    assert len(train_step_out) == 1
    train_step_out = train_step_out[0][0]
    assert isinstance(train_step_out["loss"], torch.Tensor)
    assert train_step_out["loss"].item() == 171

    # make sure the optimizer closure returns the correct things
    opt_closure = trainer.fit_loop.epoch_loop.batch_loop.optimizer_loop._make_closure(
        batch, batch_idx, 0, trainer.optimizers[0]
    )
    opt_closure_result = opt_closure()
    assert opt_closure_result.item() == 171


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag169')" href="javascript:;">
pytorch-lightning-1.5.9/tests/loops/test_evaluation_loop_flow.py: 198-253
</a>
<div class="mid" id="frag169" style="display:none"><pre>
def test__validation_step__step_end__epoch_end__flow(tmpdir):
    """Tests that only training_step can be used."""

    class TestModel(DeterministicModel):
        def training_step(self, batch, batch_idx):
            acc = self.step(batch, batch_idx)
            acc = acc + batch_idx
            self.training_step_called = True
            return acc

        def validation_step(self, batch, batch_idx):
            self.validation_step_called = True
            if batch_idx == 0:
                out = ["1", 2, torch.tensor(2)]
                self.out_a = out
            if batch_idx &gt; 0:
                out = {"something": "random"}
                self.out_b = out
            self.last_out = out
            return out

        def validation_step_end(self, out):
            self.validation_step_end_called = True
            assert self.last_out == out
            return out

        def validation_epoch_end(self, outputs):
            self.validation_epoch_end_called = True
            assert len(outputs) == 2

            out_a = outputs[0]
            out_b = outputs[1]

            assert out_a == self.out_a
            assert out_b == self.out_b

        def backward(self, loss, optimizer, optimizer_idx):
            return LightningModule.backward(self, loss, optimizer, optimizer_idx)

    model = TestModel()

    trainer = Trainer(
        default_root_dir=tmpdir,
        limit_train_batches=2,
        limit_val_batches=2,
        max_epochs=2,
        log_every_n_steps=1,
        enable_model_summary=False,
    )

    trainer.fit(model)

    # make sure correct steps were called
    assert model.validation_step_called
    assert model.validation_step_end_called
    assert model.validation_epoch_end_called
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag164')" href="javascript:;">
pytorch-lightning-1.5.9/tests/loops/test_evaluation_loop_flow.py: 145-197
</a>
<div class="mid" id="frag164" style="display:none"><pre>
def test__eval_step__epoch_end__flow(tmpdir):
    """Tests that only training_step can be used."""

    class TestModel(DeterministicModel):
        def training_step(self, batch, batch_idx):
            acc = self.step(batch, batch_idx)
            acc = acc + batch_idx
            self.training_step_called = True
            return acc

        def validation_step(self, batch, batch_idx):
            self.validation_step_called = True
            if batch_idx == 0:
                out = ["1", 2, torch.tensor(2)]
                self.out_a = out
            if batch_idx &gt; 0:
                out = {"something": "random"}
                self.out_b = out
            return out

        def validation_epoch_end(self, outputs):
            self.validation_epoch_end_called = True
            assert len(outputs) == 2

            out_a = outputs[0]
            out_b = outputs[1]

            assert out_a == self.out_a
            assert out_b == self.out_b

        def backward(self, loss, optimizer, optimizer_idx):
            return LightningModule.backward(self, loss, optimizer, optimizer_idx)

    model = TestModel()
    model.validation_step_end = None

    trainer = Trainer(
        default_root_dir=tmpdir,
        limit_train_batches=2,
        limit_val_batches=2,
        max_epochs=2,
        log_every_n_steps=1,
        enable_model_summary=False,
    )

    trainer.fit(model)

    # make sure correct steps were called
    assert model.validation_step_called
    assert not model.validation_step_end_called
    assert model.validation_epoch_end_called


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 6:</b> &nbsp; 5 fragments, nominal size 14 lines, similarity 73%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag234')" href="javascript:;">
pytorch-lightning-1.5.9/tests/loops/test_flow_warnings.py: 26-45
</a>
<div class="mid" id="frag234" style="display:none"><pre>
def test_no_depre_without_epoch_end(tmpdir):
    """Tests that only training_step can be used."""

    model = TestModel()
    model.validation_epoch_end = None

    trainer = Trainer(
        default_root_dir=tmpdir,
        limit_train_batches=2,
        limit_val_batches=2,
        max_epochs=2,
        log_every_n_steps=1,
        enable_model_summary=False,
    )

    with warnings.catch_warnings(record=True) as w:
        trainer.fit(model)

        for msg in w:
            assert "should not return anything " not in str(msg)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1188')" href="javascript:;">
pytorch-lightning-1.5.9/tests/trainer/logging_/test_distributed_logging.py: 82-99
</a>
<div class="mid" id="frag1188" style="display:none"><pre>
def test_all_rank_logging_ddp_spawn(tmpdir):
    """Check that all ranks can be logged from."""
    model = TestModel()
    all_rank_logger = AllRankLogger()
    model.training_epoch_end = None
    trainer = Trainer(
        strategy="ddp_spawn",
        gpus=2,
        default_root_dir=tmpdir,
        limit_train_batches=1,
        limit_val_batches=1,
        max_epochs=1,
        logger=all_rank_logger,
        enable_model_summary=False,
    )
    trainer.fit(model)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1187')" href="javascript:;">
pytorch-lightning-1.5.9/tests/trainer/logging_/test_distributed_logging.py: 63-80
</a>
<div class="mid" id="frag1187" style="display:none"><pre>
def test_all_rank_logging_ddp_cpu(tmpdir):
    """Check that all ranks can be logged from."""
    model = TestModel()
    all_rank_logger = AllRankLogger()
    trainer = Trainer(
        strategy="ddp_spawn",
        num_processes=2,
        default_root_dir=tmpdir,
        limit_train_batches=1,
        limit_val_batches=1,
        max_epochs=1,
        enable_model_summary=False,
        logger=all_rank_logger,
        log_every_n_steps=1,
    )
    trainer.fit(model)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag831')" href="javascript:;">
pytorch-lightning-1.5.9/tests/plugins/test_double_plugin.py: 156-170
</a>
<div class="mid" id="frag831" style="display:none"><pre>
def test_double_precision_ddp(tmpdir):
    model = DoublePrecisionBoringModel()

    trainer = Trainer(
        max_epochs=1,
        default_root_dir=tmpdir,
        strategy="ddp_spawn",
        gpus=2,
        fast_dev_run=2,
        precision=64,
        log_every_n_steps=1,
    )
    trainer.fit(model)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1207')" href="javascript:;">
pytorch-lightning-1.5.9/tests/trainer/properties/test_get_model.py: 41-57
</a>
<div class="mid" id="frag1207" style="display:none"><pre>
def test_get_model_ddp_cpu(tmpdir):
    """Tests that `trainer.lightning_module` extracts the model correctly when using ddp on cpu."""

    model = TrainerGetModel()

    limit_train_batches = 2
    trainer = Trainer(
        default_root_dir=tmpdir,
        limit_train_batches=limit_train_batches,
        limit_val_batches=2,
        max_epochs=1,
        strategy="ddp_spawn",
        num_processes=2,
    )
    trainer.fit(model)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 7:</b> &nbsp; 2 fragments, nominal size 26 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag239')" href="javascript:;">
pytorch-lightning-1.5.9/tests/loops/test_training_loop_flow_scalar.py: 28-59
</a>
<div class="mid" id="frag239" style="display:none"><pre>
def test__training_step__flow_scalar(tmpdir):
    """Tests that only training_step can be used."""

    class TestModel(DeterministicModel):
        def training_step(self, batch, batch_idx):
            acc = self.step(batch, batch_idx)
            acc = acc + batch_idx
            self.training_step_called = True
            return acc

        def backward(self, loss, optimizer, optimizer_idx):
            return LightningModule.backward(self, loss, optimizer, optimizer_idx)

    model = TestModel()
    model.val_dataloader = None

    trainer = Trainer(
        default_root_dir=tmpdir,
        limit_train_batches=2,
        limit_val_batches=2,
        max_epochs=2,
        log_every_n_steps=1,
        enable_model_summary=False,
    )
    trainer.fit(model)

    # make sure correct steps were called
    assert model.training_step_called
    assert not model.training_step_end_called
    assert not model.training_epoch_end_called


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag242')" href="javascript:;">
pytorch-lightning-1.5.9/tests/loops/test_training_loop_flow_scalar.py: 60-98
</a>
<div class="mid" id="frag242" style="display:none"><pre>
def test__training_step__tr_step_end__flow_scalar(tmpdir):
    """Tests that only training_step can be used."""

    class TestModel(DeterministicModel):
        def training_step(self, batch, batch_idx):
            acc = self.step(batch, batch_idx)
            acc = acc + batch_idx
            self.training_step_called = True
            self.out = acc
            return acc

        def training_step_end(self, tr_step_output):
            assert self.out == tr_step_output
            assert self.count_num_graphs({"loss": tr_step_output}) == 1
            self.training_step_end_called = True
            return tr_step_output

        def backward(self, loss, optimizer, optimizer_idx):
            return LightningModule.backward(self, loss, optimizer, optimizer_idx)

    model = TestModel()
    model.val_dataloader = None

    trainer = Trainer(
        default_root_dir=tmpdir,
        limit_train_batches=2,
        limit_val_batches=2,
        max_epochs=2,
        log_every_n_steps=1,
        enable_model_summary=False,
    )
    trainer.fit(model)

    # make sure correct steps were called
    assert model.training_step_called
    assert model.training_step_end_called
    assert not model.training_epoch_end_called


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 8:</b> &nbsp; 3 fragments, nominal size 29 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag304')" href="javascript:;">
pytorch-lightning-1.5.9/tests/models/test_restore.py: 309-355
</a>
<div class="mid" id="frag304" style="display:none"><pre>
def test_running_test_pretrained_model_distrib_dp(tmpdir):
    """Verify `test()` on pretrained model."""

    tutils.set_random_main_port()

    dm = ClassifDataModule()
    model = CustomClassificationModelDP(lr=0.1)

    # exp file to get meta
    logger = tutils.get_default_logger(tmpdir)

    # exp file to get weights
    checkpoint = tutils.init_checkpoint_callback(logger)

    trainer_options = dict(
        enable_progress_bar=False,
        max_epochs=2,
        limit_train_batches=5,
        limit_val_batches=5,
        callbacks=[checkpoint],
        logger=logger,
        gpus=[0, 1],
        strategy="dp",
        default_root_dir=tmpdir,
    )

    # fit model
    trainer = Trainer(**trainer_options)
    trainer.fit(model, datamodule=dm)

    # correct result and ok accuracy
    assert trainer.state.finished, f"Training failed with {trainer.state}"
    pretrained_model = CustomClassificationModelDP.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)

    # run test set
    new_trainer = Trainer(**trainer_options)
    new_trainer.test(pretrained_model, datamodule=dm)
    pretrained_model.cpu()

    dataloaders = dm.test_dataloader()
    if not isinstance(dataloaders, list):
        dataloaders = [dataloaders]

    for dataloader in dataloaders:
        tpipes.run_prediction_eval_model_template(pretrained_model, dataloader)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag305')" href="javascript:;">
pytorch-lightning-1.5.9/tests/models/test_restore.py: 357-403
</a>
<div class="mid" id="frag305" style="display:none"><pre>
def test_running_test_pretrained_model_distrib_ddp_spawn(tmpdir):
    """Verify `test()` on pretrained model."""
    tutils.set_random_main_port()
    dm = ClassifDataModule()
    model = ClassificationModel()

    # exp file to get meta
    logger = tutils.get_default_logger(tmpdir)

    # exp file to get weights
    checkpoint = tutils.init_checkpoint_callback(logger)

    trainer_options = dict(
        enable_progress_bar=False,
        max_epochs=2,
        limit_train_batches=2,
        limit_val_batches=2,
        callbacks=[checkpoint],
        logger=logger,
        gpus=[0, 1],
        strategy="ddp_spawn",
        default_root_dir=tmpdir,
    )

    # fit model
    trainer = Trainer(**trainer_options)
    trainer.fit(model, datamodule=dm)

    log.info(os.listdir(tutils.get_data_path(logger, path_dir=tmpdir)))

    # correct result and ok accuracy
    assert trainer.state.finished, f"Training failed with {trainer.state}"
    pretrained_model = ClassificationModel.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)

    # run test set
    new_trainer = Trainer(**trainer_options)
    new_trainer.test(pretrained_model, datamodule=dm)
    pretrained_model.cpu()

    dataloaders = dm.test_dataloader()
    if not isinstance(dataloaders, list):
        dataloaders = [dataloaders]

    for dataloader in dataloaders:
        tpipes.run_prediction_eval_model_template(pretrained_model, dataloader, min_acc=0.1)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag306')" href="javascript:;">
pytorch-lightning-1.5.9/tests/models/test_restore.py: 404-441
</a>
<div class="mid" id="frag306" style="display:none"><pre>
def test_running_test_pretrained_model_cpu(tmpdir):
    """Verify test() on pretrained model."""
    tutils.reset_seed()
    dm = ClassifDataModule()
    model = ClassificationModel()

    # logger file to get meta
    logger = tutils.get_default_logger(tmpdir)

    # logger file to get weights
    checkpoint = tutils.init_checkpoint_callback(logger)

    trainer_options = dict(
        enable_progress_bar=False,
        max_epochs=2,
        limit_train_batches=2,
        limit_val_batches=2,
        limit_test_batches=2,
        callbacks=[checkpoint],
        logger=logger,
        default_root_dir=tmpdir,
    )

    # fit model
    trainer = Trainer(**trainer_options)
    trainer.fit(model, datamodule=dm)

    # correct result and ok accuracy
    assert trainer.state.finished, f"Training failed with {trainer.state}"
    pretrained_model = ClassificationModel.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)

    new_trainer = Trainer(**trainer_options)
    new_trainer.test(pretrained_model, datamodule=dm)

    # test we have good test accuracy
    tutils.assert_ok_model_acc(new_trainer, key="test_acc", thr=0.45)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 9:</b> &nbsp; 2 fragments, nominal size 25 lines, similarity 84%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag312')" href="javascript:;">
pytorch-lightning-1.5.9/tests/models/test_restore.py: 612-652
</a>
<div class="mid" id="frag312" style="display:none"><pre>
def test_strict_model_load_more_params(monkeypatch, tmpdir, tmpdir_server, url_ckpt):
    """Tests use case where trainer saves the model, and user loads it from tags independently."""
    # set $TORCH_HOME, which determines torch hub's cache path, to tmpdir
    monkeypatch.setenv("TORCH_HOME", tmpdir)

    model = BoringModel()
    # Extra layer
    model.c_d3 = torch.nn.Linear(32, 32)

    # logger file to get meta
    logger = tutils.get_default_logger(tmpdir)

    # fit model
    trainer = Trainer(
        default_root_dir=tmpdir,
        max_epochs=1,
        limit_train_batches=2,
        limit_val_batches=2,
        logger=logger,
        callbacks=[ModelCheckpoint(dirpath=tmpdir)],
    )
    trainer.fit(model)

    # traning complete
    assert trainer.state.finished, f"Training failed with {trainer.state}"

    # save model
    new_weights_path = os.path.join(tmpdir, "save_test.ckpt")
    trainer.save_checkpoint(new_weights_path)

    # load new model
    hparams_path = os.path.join(tutils.get_data_path(logger, path_dir=tmpdir), "hparams.yaml")
    hparams_url = f"http://{tmpdir_server[0]}:{tmpdir_server[1]}/{os.path.basename(new_weights_path)}"
    ckpt_path = hparams_url if url_ckpt else new_weights_path

    BoringModel.load_from_checkpoint(checkpoint_path=ckpt_path, hparams_file=hparams_path, strict=False)

    with pytest.raises(RuntimeError, match=r'Unexpected key\(s\) in state_dict: "c_d3.weight", "c_d3.bias"'):
        BoringModel.load_from_checkpoint(checkpoint_path=ckpt_path, hparams_file=hparams_path, strict=True)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag313')" href="javascript:;">
pytorch-lightning-1.5.9/tests/models/test_restore.py: 654-697
</a>
<div class="mid" id="frag313" style="display:none"><pre>
def test_strict_model_load_less_params(monkeypatch, tmpdir, tmpdir_server, url_ckpt):
    """Tests use case where trainer saves the model, and user loads it from tags independently."""
    # set $TORCH_HOME, which determines torch hub's cache path, to tmpdir
    monkeypatch.setenv("TORCH_HOME", tmpdir)

    model = BoringModel()

    # logger file to get meta
    logger = tutils.get_default_logger(tmpdir)

    # fit model
    trainer = Trainer(
        default_root_dir=tmpdir,
        max_epochs=1,
        limit_train_batches=2,
        limit_val_batches=2,
        logger=logger,
        callbacks=[ModelCheckpoint(dirpath=tmpdir)],
    )
    trainer.fit(model)

    # traning complete
    assert trainer.state.finished, f"Training failed with {trainer.state}"

    # save model
    new_weights_path = os.path.join(tmpdir, "save_test.ckpt")
    trainer.save_checkpoint(new_weights_path)

    # load new model
    hparams_path = os.path.join(tutils.get_data_path(logger, path_dir=tmpdir), "hparams.yaml")
    ckpt_url = f"http://{tmpdir_server[0]}:{tmpdir_server[1]}/{os.path.basename(new_weights_path)}"
    ckpt_path = ckpt_url if url_ckpt else new_weights_path

    class CurrentModel(BoringModel):
        def __init__(self):
            super().__init__()
            self.c_d3 = torch.nn.Linear(7, 7)

    CurrentModel.load_from_checkpoint(checkpoint_path=ckpt_path, hparams_file=hparams_path, strict=False)

    with pytest.raises(RuntimeError, match=r'Missing key\(s\) in state_dict: "c_d3.weight", "c_d3.bias"'):
        CurrentModel.load_from_checkpoint(checkpoint_path=ckpt_path, hparams_file=hparams_path, strict=True)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 10:</b> &nbsp; 2 fragments, nominal size 26 lines, similarity 81%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag366')" href="javascript:;">
pytorch-lightning-1.5.9/tests/models/test_cpu.py: 191-233
</a>
<div class="mid" id="frag366" style="display:none"><pre>
def test_running_test_after_fitting(tmpdir):
    """Verify test() on fitted model."""

    class ModelTrainValTest(BoringModel):
        def validation_step(self, *args, **kwargs):
            output = super().validation_step(*args, **kwargs)
            self.log("val_loss", output["x"])
            return output

        def test_step(self, *args, **kwargs):
            output = super().test_step(*args, **kwargs)
            self.log("test_loss", output["y"])
            return output

    model = ModelTrainValTest()

    # logger file to get meta
    logger = tutils.get_default_logger(tmpdir)

    # logger file to get weights
    checkpoint = tutils.init_checkpoint_callback(logger)

    # fit model
    trainer = Trainer(
        default_root_dir=tmpdir,
        enable_progress_bar=False,
        max_epochs=2,
        limit_train_batches=0.4,
        limit_val_batches=0.2,
        limit_test_batches=0.2,
        callbacks=[checkpoint],
        logger=logger,
    )
    trainer.fit(model)

    assert trainer.state.finished, f"Training failed with {trainer.state}"

    trainer.test()

    # test we have good test accuracy
    tutils.assert_ok_model_acc(trainer, key="test_loss", thr=0.5)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag369')" href="javascript:;">
pytorch-lightning-1.5.9/tests/models/test_cpu.py: 234-277
</a>
<div class="mid" id="frag369" style="display:none"><pre>
def test_running_test_no_val(tmpdir):
    """Verify `test()` works on a model with no `val_dataloader`.

    It performs train and test only
    """

    class ModelTrainTest(BoringModel):
        def val_dataloader(self):
            pass

        def test_step(self, *args, **kwargs):
            output = super().test_step(*args, **kwargs)
            self.log("test_loss", output["y"])
            return output

    model = ModelTrainTest()

    # logger file to get meta
    logger = tutils.get_default_logger(tmpdir)

    # logger file to get weights
    checkpoint = tutils.init_checkpoint_callback(logger)

    # fit model
    trainer = Trainer(
        default_root_dir=tmpdir,
        enable_progress_bar=False,
        max_epochs=1,
        limit_train_batches=0.4,
        limit_val_batches=0.2,
        limit_test_batches=0.2,
        callbacks=[checkpoint],
        logger=logger,
    )
    trainer.fit(model)

    assert trainer.state.finished, f"Training failed with {trainer.state}"

    trainer.test()

    # test we have good test accuracy
    tutils.assert_ok_model_acc(trainer, key="test_loss")


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 11:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 90%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag544')" href="javascript:;">
pytorch-lightning-1.5.9/tests/callbacks/test_finetuning_callback.py: 175-185
</a>
<div class="mid" id="frag544" style="display:none"><pre>
        def __init__(self):
            super().__init__()
            self.backbone = nn.Sequential(
                nn.Linear(32, 32, bias=False),
                nn.Linear(32, 32, bias=False),
                nn.Linear(32, 32, bias=False),
                nn.Linear(32, 32, bias=False),
                nn.Linear(32, 32, bias=False),
                nn.BatchNorm1d(32),
            )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag548')" href="javascript:;">
pytorch-lightning-1.5.9/tests/callbacks/test_finetuning_callback.py: 229-239
</a>
<div class="mid" id="frag548" style="display:none"><pre>
        def __init__(self):
            super().__init__()
            self.layer = nn.Sequential(
                nn.Linear(32, 32, bias=False),
                nn.Linear(32, 32, bias=True),
                nn.Linear(32, 32, bias=False),
                nn.Linear(32, 32, bias=True),
                nn.Linear(32, 32, bias=False),
                nn.Linear(32, 2, bias=True),
            )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 12:</b> &nbsp; 6 fragments, nominal size 14 lines, similarity 71%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag614')" href="javascript:;">
pytorch-lightning-1.5.9/tests/callbacks/test_gradient_accumulation_scheduler.py: 26-43
</a>
<div class="mid" id="frag614" style="display:none"><pre>
def test_trainer_accumulate_grad_batches_zero_grad(tmpdir, accumulate_grad_batches):
    with patch("torch.optim.SGD.zero_grad") as sgd_zero_grad:
        model = BoringModel()
        trainer = Trainer(
            default_root_dir=tmpdir,
            limit_train_batches=20,
            limit_val_batches=1,
            max_epochs=1,
            enable_model_summary=False,
            accumulate_grad_batches=accumulate_grad_batches,
        )
        assert trainer.accumulate_grad_batches == accumulate_grad_batches
        trainer.fit(model)

        assert sum(isinstance(cb, GradientAccumulationScheduler) for cb in trainer.callbacks) == 1
        assert sgd_zero_grad.call_count == math.ceil(trainer.limit_train_batches / accumulate_grad_batches)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag616')" href="javascript:;">
pytorch-lightning-1.5.9/tests/callbacks/test_gradient_accumulation_scheduler.py: 69-86
</a>
<div class="mid" id="frag616" style="display:none"><pre>
def test_trainer_accumulate_grad_batches_with_callback(tmpdir):
    with patch("torch.optim.SGD.zero_grad") as sgd_zero_grad:
        model = BoringModel()
        trainer = Trainer(
            default_root_dir=tmpdir,
            limit_train_batches=10,
            limit_val_batches=1,
            max_epochs=4,
            enable_model_summary=False,
            callbacks=[GradientAccumulationScheduler({1: 2, 3: 4})],
        )
        assert trainer.accumulate_grad_batches == 1
        trainer.fit(model)

        assert sum(isinstance(cb, GradientAccumulationScheduler) for cb in trainer.callbacks) == 1
        assert sgd_zero_grad.call_count == 10 + 5 + 5 + 3


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag615')" href="javascript:;">
pytorch-lightning-1.5.9/tests/callbacks/test_gradient_accumulation_scheduler.py: 51-68
</a>
<div class="mid" id="frag615" style="display:none"><pre>
def test_trainer_accumulate_grad_batches_dict_zero_grad(tmpdir, accumulate_grad_batches, expected_call_count):
    with patch("torch.optim.SGD.zero_grad") as sgd_zero_grad:
        model = BoringModel()
        trainer = Trainer(
            default_root_dir=tmpdir,
            limit_train_batches=10,
            limit_val_batches=1,
            max_epochs=4,
            enable_model_summary=False,
            accumulate_grad_batches=accumulate_grad_batches,
        )
        assert trainer.accumulate_grad_batches == accumulate_grad_batches.get(0, 1)
        trainer.fit(model)

        assert sum(isinstance(cb, GradientAccumulationScheduler) for cb in trainer.callbacks) == 1
        assert sgd_zero_grad.call_count == expected_call_count


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag649')" href="javascript:;">
pytorch-lightning-1.5.9/tests/callbacks/test_rich_progress_bar.py: 166-184
</a>
<div class="mid" id="frag649" style="display:none"><pre>
def test_rich_progress_bar_leave(tmpdir, leave, reset_call_count):
    # Calling `reset` means continuing on the same progress bar.
    model = BoringModel()

    with mock.patch(
        "pytorch_lightning.callbacks.progress.rich_progress.Progress.reset", autospec=True
    ) as mock_progress_reset:
        progress_bar = RichProgressBar(leave=leave)
        trainer = Trainer(
            default_root_dir=tmpdir,
            num_sanity_val_steps=0,
            limit_train_batches=1,
            max_epochs=6,
            callbacks=progress_bar,
        )
        trainer.fit(model)
    assert mock_progress_reset.call_count == reset_call_count


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1144')" href="javascript:;">
pytorch-lightning-1.5.9/tests/trainer/optimization/test_optimizers.py: 561-576
</a>
<div class="mid" id="frag1144" style="display:none"><pre>
def test_lr_scheduler_epoch_step_frequency(mocked_sched, check_val_every_n_epoch, tmpdir):
    epochs = 4
    expected_steps = epochs + 1  # every LRScheduler gets called once at init

    model = BoringModel()
    trainer = Trainer(
        default_root_dir=tmpdir,
        limit_train_batches=2,
        limit_val_batches=2,
        check_val_every_n_epoch=check_val_every_n_epoch,
        max_epochs=epochs,
    )
    trainer.fit(model)
    assert mocked_sched.call_count == expected_steps


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag627')" href="javascript:;">
pytorch-lightning-1.5.9/tests/callbacks/test_callback_hook_outputs.py: 64-80
</a>
<div class="mid" id="frag627" style="display:none"><pre>
def test_free_memory_on_eval_outputs(tmpdir):
    class CB(Callback):
        def on_epoch_end(self, trainer, pl_module):
            assert len(trainer._evaluation_loop.outputs) == 0

    model = BoringModel()

    trainer = Trainer(
        callbacks=CB(),
        default_root_dir=tmpdir,
        limit_train_batches=2,
        limit_val_batches=2,
        max_epochs=1,
        enable_model_summary=False,
    )

    trainer.fit(model)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 13:</b> &nbsp; 3 fragments, nominal size 21 lines, similarity 95%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag629')" href="javascript:;">
pytorch-lightning-1.5.9/tests/callbacks/test_device_stats_monitor.py: 29-55
</a>
<div class="mid" id="frag629" style="display:none"><pre>
def test_device_stats_gpu_from_torch(tmpdir):
    """Test GPU stats are logged using a logger with Pytorch &gt;= 1.8.0."""
    model = BoringModel()
    device_stats = DeviceStatsMonitor()

    class DebugLogger(CSVLogger):
        @rank_zero_only
        def log_metrics(self, metrics: Dict[str, float], step: Optional[int] = None) -&gt; None:
            fields = ["allocated_bytes.all.freed", "inactive_split.all.peak", "reserved_bytes.large_pool.peak"]
            for f in fields:
                assert any(f in h for h in metrics.keys())

    trainer = Trainer(
        default_root_dir=tmpdir,
        max_epochs=2,
        limit_train_batches=7,
        log_every_n_steps=1,
        gpus=1,
        callbacks=[device_stats],
        logger=DebugLogger(tmpdir),
        enable_checkpointing=False,
        enable_progress_bar=False,
    )

    trainer.fit(model)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag633')" href="javascript:;">
pytorch-lightning-1.5.9/tests/callbacks/test_device_stats_monitor.py: 86-113
</a>
<div class="mid" id="frag633" style="display:none"><pre>
def test_device_stats_monitor_tpu(tmpdir):
    """Test TPU stats are logged using a logger."""

    model = BoringModel()
    device_stats = DeviceStatsMonitor()

    class DebugLogger(CSVLogger):
        @rank_zero_only
        def log_metrics(self, metrics: Dict[str, float], step: Optional[int] = None) -&gt; None:
            fields = ["avg. free memory (MB)", "avg. peak memory (MB)"]
            for f in fields:
                assert any(f in h for h in metrics.keys())

    trainer = Trainer(
        default_root_dir=tmpdir,
        max_epochs=1,
        limit_train_batches=1,
        tpu_cores=8,
        log_every_n_steps=1,
        callbacks=[device_stats],
        logger=DebugLogger(tmpdir),
        enable_checkpointing=False,
        enable_progress_bar=False,
    )

    trainer.fit(model)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag631')" href="javascript:;">
pytorch-lightning-1.5.9/tests/callbacks/test_device_stats_monitor.py: 58-84
</a>
<div class="mid" id="frag631" style="display:none"><pre>
def test_device_stats_gpu_from_nvidia(tmpdir):
    """Test GPU stats are logged using a logger with Pytorch &lt; 1.8.0."""
    model = BoringModel()
    device_stats = DeviceStatsMonitor()

    class DebugLogger(CSVLogger):
        @rank_zero_only
        def log_metrics(self, metrics: Dict[str, float], step: Optional[int] = None) -&gt; None:
            fields = ["utilization.gpu", "memory.used", "memory.free", "utilization.memory"]
            for f in fields:
                assert any(f in h for h in metrics.keys())

    trainer = Trainer(
        default_root_dir=tmpdir,
        max_epochs=2,
        limit_train_batches=7,
        log_every_n_steps=1,
        gpus=1,
        callbacks=[device_stats],
        logger=DebugLogger(tmpdir),
        enable_checkpointing=False,
        enable_progress_bar=False,
    )

    trainer.fit(model)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 14:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag749')" href="javascript:;">
pytorch-lightning-1.5.9/tests/plugins/environments/test_slurm_environment.py: 24-40
</a>
<div class="mid" id="frag749" style="display:none"><pre>
def test_default_attributes():
    """Test the default attributes when no environment variables are set."""
    env = SLURMEnvironment()
    assert env.creates_processes_externally
    assert env.master_address() == "127.0.0.1"
    assert env.master_port() == 12910
    with pytest.raises(KeyError):
        # world size is required to be passed as env variable
        env.world_size()
    with pytest.raises(KeyError):
        # local rank is required to be passed as env variable
        env.local_rank()
    with pytest.raises(KeyError):
        # node_rank is required to be passed as env variable
        env.node_rank()


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag752')" href="javascript:;">
pytorch-lightning-1.5.9/tests/plugins/environments/test_kubeflow_environment.py: 24-43
</a>
<div class="mid" id="frag752" style="display:none"><pre>
def test_default_attributes():
    """Test the default attributes when no environment variables are set."""
    env = KubeflowEnvironment()
    assert env.creates_processes_externally

    with pytest.raises(KeyError):
        # MASTER_ADDR is required
        env.master_address()
    with pytest.raises(KeyError):
        # MASTER_PORT is required
        env.master_port()
    with pytest.raises(KeyError):
        # WORLD_SIZE is required
        env.world_size()
    with pytest.raises(KeyError):
        # RANK is required
        env.global_rank()
    assert env.local_rank() == 0


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 15:</b> &nbsp; 3 fragments, nominal size 17 lines, similarity 94%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag750')" href="javascript:;">
pytorch-lightning-1.5.9/tests/plugins/environments/test_slurm_environment.py: 52-74
</a>
<div class="mid" id="frag750" style="display:none"><pre>
def test_attributes_from_environment_variables(caplog):
    """Test that the SLURM cluster environment takes the attributes from the environment variables."""
    env = SLURMEnvironment()
    assert env.master_address() == "1.1.1.1"
    assert env.master_port() == 15000 + 1234
    assert env.world_size() == 20
    assert env.global_rank() == 1
    assert env.local_rank() == 2
    assert env.node_rank() == 3
    # setter should be no-op
    with caplog.at_level(logging.DEBUG, logger="pytorch_lightning.plugins.environments"):
        env.set_global_rank(100)
    assert env.global_rank() == 1
    assert "setting global rank is not allowed" in caplog.text

    caplog.clear()

    with caplog.at_level(logging.DEBUG, logger="pytorch_lightning.plugins.environments"):
        env.set_world_size(100)
    assert env.world_size() == 20
    assert "setting world size is not allowed" in caplog.text


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag764')" href="javascript:;">
pytorch-lightning-1.5.9/tests/plugins/environments/test_torchelastic_environment.py: 48-68
</a>
<div class="mid" id="frag764" style="display:none"><pre>
def test_attributes_from_environment_variables(caplog):
    """Test that the torchelastic cluster environment takes the attributes from the environment variables."""
    env = TorchElasticEnvironment()
    assert env.master_address() == "1.2.3.4"
    assert env.master_port() == 500
    assert env.world_size() == 20
    assert env.global_rank() == 1
    assert env.local_rank() == 2
    assert env.node_rank() == 3
    # setter should be no-op
    with caplog.at_level(logging.DEBUG, logger="pytorch_lightning.plugins.environments"):
        env.set_global_rank(100)
    assert env.global_rank() == 1
    assert "setting global rank is not allowed" in caplog.text

    caplog.clear()

    with caplog.at_level(logging.DEBUG, logger="pytorch_lightning.plugins.environments"):
        env.set_world_size(100)
    assert env.world_size() == 20
    assert "setting world size is not allowed" in caplog.text
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag753')" href="javascript:;">
pytorch-lightning-1.5.9/tests/plugins/environments/test_kubeflow_environment.py: 54-76
</a>
<div class="mid" id="frag753" style="display:none"><pre>
def test_attributes_from_environment_variables(caplog):
    """Test that the torchelastic cluster environment takes the attributes from the environment variables."""
    env = KubeflowEnvironment()
    assert env.master_address() == "1.2.3.4"
    assert env.master_port() == 500
    assert env.world_size() == 20
    assert env.global_rank() == 1
    assert env.local_rank() == 0
    assert env.node_rank() == 1
    # setter should be no-op
    with caplog.at_level(logging.DEBUG, logger="pytorch_lightning.plugins.environments"):
        env.set_global_rank(100)
    assert env.global_rank() == 1
    assert "setting global rank is not allowed" in caplog.text

    caplog.clear()

    with caplog.at_level(logging.DEBUG, logger="pytorch_lightning.plugins.environments"):
        env.set_world_size(100)
    assert env.world_size() == 20
    assert "setting world size is not allowed" in caplog.text


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 16:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 83%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag793')" href="javascript:;">
pytorch-lightning-1.5.9/tests/plugins/test_ddp_plugin.py: 37-56
</a>
<div class="mid" id="frag793" style="display:none"><pre>
def test_ddp_with_2_gpus():
    """Tests if device is set correctely when training and after teardown for DDPPlugin."""
    trainer = Trainer(gpus=2, strategy="ddp", fast_dev_run=True)
    # assert training type plugin attributes for device setting
    assert isinstance(trainer.training_type_plugin, DDPPlugin)
    assert trainer.training_type_plugin.on_gpu
    assert not trainer.training_type_plugin.on_tpu
    local_rank = trainer.training_type_plugin.local_rank
    assert trainer.training_type_plugin.root_device == torch.device(f"cuda:{local_rank}")

    model = BoringModelGPU()

    trainer.fit(model)

    # assert after training, model is moved to CPU and memory is deallocated
    assert model.device == torch.device("cpu")
    cuda_memory = torch.cuda.memory_allocated()
    assert cuda_memory &lt; model.start_cuda_memory


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag802')" href="javascript:;">
pytorch-lightning-1.5.9/tests/plugins/test_single_device_plugin.py: 39-55
</a>
<div class="mid" id="frag802" style="display:none"><pre>
def test_single_gpu():
    """Tests if device is set correctly when training and after teardown for single GPU plugin."""
    trainer = Trainer(gpus=1, fast_dev_run=True)
    # assert training type plugin attributes for device setting
    assert isinstance(trainer.training_type_plugin, SingleDevicePlugin)
    assert trainer.training_type_plugin.on_gpu
    assert not trainer.training_type_plugin.on_tpu
    assert trainer.training_type_plugin.root_device == torch.device("cuda:0")

    model = BoringModelGPU()

    trainer.fit(model)

    # assert after training, model is moved to CPU and memory is deallocated
    assert model.device == torch.device("cpu")
    cuda_memory = torch.cuda.memory_allocated()
    assert cuda_memory &lt; model.start_cuda_memory
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 17:</b> &nbsp; 5 fragments, nominal size 18 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag803')" href="javascript:;">
pytorch-lightning-1.5.9/tests/plugins/test_ddp_plugin_with_comm_hook.py: 30-48
</a>
<div class="mid" id="frag803" style="display:none"><pre>
def test_ddp_fp16_compress_comm_hook(tmpdir):
    """Test for DDP FP16 compress hook."""
    model = BoringModel()
    training_type_plugin = DDPPlugin(ddp_comm_hook=default.fp16_compress_hook, sync_batchnorm=True)
    trainer = Trainer(
        max_epochs=1,
        gpus=2,
        strategy=training_type_plugin,
        default_root_dir=tmpdir,
        sync_batchnorm=True,
        fast_dev_run=True,
    )
    trainer.fit(model)
    trainer_comm_hook = trainer.accelerator.training_type_plugin._model.get_ddp_logging_data().comm_hook
    expected_comm_hook = default.fp16_compress_hook.__qualname__
    assert trainer_comm_hook == expected_comm_hook
    assert trainer.state.finished, f"Training failed with {trainer.state}"


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag806')" href="javascript:;">
pytorch-lightning-1.5.9/tests/plugins/test_ddp_plugin_with_comm_hook.py: 99-114
</a>
<div class="mid" id="frag806" style="display:none"><pre>
def test_ddp_spawn_fp16_compress_comm_hook(tmpdir):
    """Test for DDP Spawn FP16 compress hook."""
    model = BoringModel()
    training_type_plugin = DDPSpawnPlugin(ddp_comm_hook=default.fp16_compress_hook, sync_batchnorm=True)
    trainer = Trainer(
        max_epochs=1,
        gpus=2,
        strategy=training_type_plugin,
        default_root_dir=tmpdir,
        sync_batchnorm=True,
        fast_dev_run=True,
    )
    trainer.fit(model)
    assert trainer.state.finished, f"Training failed with {trainer.state}"


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag804')" href="javascript:;">
pytorch-lightning-1.5.9/tests/plugins/test_ddp_plugin_with_comm_hook.py: 50-72
</a>
<div class="mid" id="frag804" style="display:none"><pre>
def test_ddp_sgd_comm_hook(tmpdir):
    """Test for DDP FP16 compress hook."""
    model = BoringModel()
    training_type_plugin = DDPPlugin(
        ddp_comm_state=powerSGD.PowerSGDState(process_group=None),
        ddp_comm_hook=powerSGD.powerSGD_hook,
        sync_batchnorm=True,
    )
    trainer = Trainer(
        max_epochs=1,
        gpus=2,
        strategy=training_type_plugin,
        default_root_dir=tmpdir,
        sync_batchnorm=True,
        fast_dev_run=True,
    )
    trainer.fit(model)
    trainer_comm_hook = trainer.accelerator.training_type_plugin._model.get_ddp_logging_data().comm_hook
    expected_comm_hook = powerSGD.powerSGD_hook.__qualname__
    assert trainer_comm_hook == expected_comm_hook
    assert trainer.state.finished, f"Training failed with {trainer.state}"


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag807')" href="javascript:;">
pytorch-lightning-1.5.9/tests/plugins/test_ddp_plugin_with_comm_hook.py: 116-141
</a>
<div class="mid" id="frag807" style="display:none"><pre>
def test_ddp_post_local_sgd_comm_hook(tmpdir):
    """Test for DDP post-localSGD hook."""
    model = BoringModel()

    training_type_plugin = DDPPlugin(
        ddp_comm_state=post_localSGD.PostLocalSGDState(
            process_group=None,
            subgroup=None,
            start_localSGD_iter=8,
        ),
        ddp_comm_hook=post_localSGD.post_localSGD_hook,
        model_averaging_period=4,
        sync_batchnorm=True,
    )
    trainer = Trainer(
        fast_dev_run=True,
        gpus=2,
        strategy=training_type_plugin,
        default_root_dir=tmpdir,
        sync_batchnorm=True,
    )
    trainer.fit(model)
    trainer_comm_hook = trainer.accelerator.training_type_plugin._model.get_ddp_logging_data().comm_hook
    expected_comm_hook = post_localSGD.post_localSGD_hook.__qualname__
    assert trainer_comm_hook == expected_comm_hook
    assert trainer.state.finished, f"Training failed with {trainer.state}"
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag805')" href="javascript:;">
pytorch-lightning-1.5.9/tests/plugins/test_ddp_plugin_with_comm_hook.py: 74-97
</a>
<div class="mid" id="frag805" style="display:none"><pre>
def test_ddp_fp16_compress_wrap_sgd_comm_hook(tmpdir):
    """Test for DDP FP16 compress wrapper for SGD hook."""
    model = BoringModel()
    training_type_plugin = DDPPlugin(
        ddp_comm_state=powerSGD.PowerSGDState(process_group=None),
        ddp_comm_hook=powerSGD.powerSGD_hook,
        ddp_comm_wrapper=default.fp16_compress_wrapper,
        sync_batchnorm=True,
    )
    trainer = Trainer(
        max_epochs=1,
        gpus=2,
        strategy=training_type_plugin,
        default_root_dir=tmpdir,
        sync_batchnorm=True,
        fast_dev_run=True,
    )
    trainer.fit(model)
    trainer_comm_hook = trainer.accelerator.training_type_plugin._model.get_ddp_logging_data().comm_hook
    expected_comm_hook = default.fp16_compress_wrapper(powerSGD.powerSGD_hook).__qualname__
    assert trainer_comm_hook == expected_comm_hook
    assert trainer.state.finished, f"Training failed with {trainer.state}"


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 18:</b> &nbsp; 4 fragments, nominal size 15 lines, similarity 73%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag995')" href="javascript:;">
pytorch-lightning-1.5.9/tests/loggers/test_csv.py: 89-108
</a>
<div class="mid" id="frag995" style="display:none"><pre>
def test_file_logger_log_hyperparams(tmpdir):
    logger = CSVLogger(tmpdir)
    hparams = {
        "float": 0.3,
        "int": 1,
        "string": "abc",
        "bool": True,
        "dict": {"a": {"b": "c"}},
        "list": [1, 2, 3],
        "namespace": Namespace(foo=Namespace(bar="buzz")),
        "layer": torch.nn.BatchNorm1d,
    }
    logger.log_hyperparams(hparams)
    logger.save()

    path_yaml = os.path.join(logger.log_dir, ExperimentWriter.NAME_HPARAMS_FILE)
    params = load_hparams_from_yaml(path_yaml)
    assert all(n in params for n in hparams)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1007')" href="javascript:;">
pytorch-lightning-1.5.9/tests/loggers/test_tensorboard.py: 172-188
</a>
<div class="mid" id="frag1007" style="display:none"><pre>
def test_tensorboard_log_hyperparams(tmpdir):
    logger = TensorBoardLogger(tmpdir)
    hparams = {
        "float": 0.3,
        "int": 1,
        "string": "abc",
        "bool": True,
        "dict": {"a": {"b": "c"}},
        "list": [1, 2, 3],
        "namespace": Namespace(foo=Namespace(bar="buzz")),
        "layer": torch.nn.BatchNorm1d,
        "tensor": torch.empty(2, 2, 2),
        "array": np.empty([2, 2, 2]),
    }
    logger.log_hyperparams(hparams)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1008')" href="javascript:;">
pytorch-lightning-1.5.9/tests/loggers/test_tensorboard.py: 189-206
</a>
<div class="mid" id="frag1008" style="display:none"><pre>
def test_tensorboard_log_hparams_and_metrics(tmpdir):
    logger = TensorBoardLogger(tmpdir, default_hp_metric=False)
    hparams = {
        "float": 0.3,
        "int": 1,
        "string": "abc",
        "bool": True,
        "dict": {"a": {"b": "c"}},
        "list": [1, 2, 3],
        "namespace": Namespace(foo=Namespace(bar="buzz")),
        "layer": torch.nn.BatchNorm1d,
        "tensor": torch.empty(2, 2, 2),
        "array": np.empty([2, 2, 2]),
    }
    metrics = {"abc": torch.tensor([0.54])}
    logger.log_hyperparams(hparams, metrics)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1009')" href="javascript:;">
pytorch-lightning-1.5.9/tests/loggers/test_tensorboard.py: 207-224
</a>
<div class="mid" id="frag1009" style="display:none"><pre>
def test_tensorboard_log_omegaconf_hparams_and_metrics(tmpdir):
    logger = TensorBoardLogger(tmpdir, default_hp_metric=False)
    hparams = {
        "float": 0.3,
        "int": 1,
        "string": "abc",
        "bool": True,
        "dict": {"a": {"b": "c"}},
        "list": [1, 2, 3],
        # "namespace": Namespace(foo=Namespace(bar="buzz")),
        # "layer": torch.nn.BatchNorm1d,
    }
    hparams = OmegaConf.create(hparams)

    metrics = {"abc": torch.tensor([0.54])}
    logger.log_hyperparams(hparams, metrics)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 19:</b> &nbsp; 2 fragments, nominal size 25 lines, similarity 88%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1047')" href="javascript:;">
pytorch-lightning-1.5.9/tests/trainer/dynamic_args/test_multiple_eval_dataloaders.py: 45-78
</a>
<div class="mid" id="frag1047" style="display:none"><pre>
def test_multiple_eval_dataloaders_tuple(tmpdir):
    class TestModel(BoringModel):
        def validation_step(self, batch, batch_idx, dataloader_idx):
            if dataloader_idx == 0:
                assert batch.sum() == 0
            elif dataloader_idx == 1:
                assert batch.sum() == 11
            else:
                raise Exception("should only have two dataloaders")

        def training_epoch_end(self, outputs) -&gt; None:
            # outputs should be an array with an entry per optimizer
            assert len(outputs) == 2

        def val_dataloader(self):
            dl1 = torch.utils.data.DataLoader(RandomDatasetA(32, 64), batch_size=11)
            dl2 = torch.utils.data.DataLoader(RandomDatasetB(32, 64), batch_size=11)
            return [dl1, dl2]

    model = TestModel()
    model.validation_epoch_end = None

    trainer = Trainer(
        default_root_dir=tmpdir,
        limit_train_batches=2,
        limit_val_batches=2,
        max_epochs=1,
        log_every_n_steps=1,
        enable_model_summary=False,
    )

    trainer.fit(model)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1051')" href="javascript:;">
pytorch-lightning-1.5.9/tests/trainer/dynamic_args/test_multiple_eval_dataloaders.py: 79-108
</a>
<div class="mid" id="frag1051" style="display:none"><pre>
def test_multiple_eval_dataloaders_list(tmpdir):
    class TestModel(BoringModel):
        def validation_step(self, batch, batch_idx, dataloader_idx):
            if dataloader_idx == 0:
                assert batch.sum() == 0
            elif dataloader_idx == 1:
                assert batch.sum() == 11
            else:
                raise Exception("should only have two dataloaders")

        def val_dataloader(self):
            dl1 = torch.utils.data.DataLoader(RandomDatasetA(32, 64), batch_size=11)
            dl2 = torch.utils.data.DataLoader(RandomDatasetB(32, 64), batch_size=11)
            return dl1, dl2

    model = TestModel()
    model.validation_epoch_end = None

    trainer = Trainer(
        default_root_dir=tmpdir,
        limit_train_batches=2,
        limit_val_batches=2,
        max_epochs=1,
        log_every_n_steps=1,
        enable_model_summary=False,
    )

    trainer.fit(model)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 20:</b> &nbsp; 3 fragments, nominal size 10 lines, similarity 88%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1106')" href="javascript:;">
pytorch-lightning-1.5.9/tests/trainer/optimization/test_optimizers.py: 90-102
</a>
<div class="mid" id="frag1106" style="display:none"><pre>
def test_reducelronplateau_with_no_monitor_in_lr_scheduler_dict_raises(tmpdir):
    """Test exception when lr_scheduler dict has a ReduceLROnPlateau with no monitor."""
    model = BoringModel()
    optimizer = optim.Adam(model.parameters())
    model.configure_optimizers = lambda: {
        "optimizer": optimizer,
        "lr_scheduler": {"scheduler": optim.lr_scheduler.ReduceLROnPlateau(optimizer)},
    }
    trainer = Trainer(default_root_dir=tmpdir, fast_dev_run=True)
    with pytest.raises(MisconfigurationException, match="must include a monitor when a `ReduceLROnPlateau`"):
        trainer.fit(model)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1131')" href="javascript:;">
pytorch-lightning-1.5.9/tests/trainer/optimization/test_optimizers.py: 457-469
</a>
<div class="mid" id="frag1131" style="display:none"><pre>
def test_lr_scheduler_with_unknown_interval_raises(tmpdir):
    """Test exception when lr_scheduler dict has unknown interval param value."""
    model = BoringModel()
    optimizer = optim.Adam(model.parameters())
    model.configure_optimizers = lambda: {
        "optimizer": optimizer,
        "lr_scheduler": {"scheduler": optim.lr_scheduler.StepLR(optimizer, 1), "interval": "incorrect_unknown_value"},
    }
    trainer = Trainer(default_root_dir=tmpdir, fast_dev_run=True)
    with pytest.raises(MisconfigurationException, match=r'The "interval" key in lr scheduler dict must be'):
        trainer.fit(model)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1132')" href="javascript:;">
pytorch-lightning-1.5.9/tests/trainer/optimization/test_optimizers.py: 470-482
</a>
<div class="mid" id="frag1132" style="display:none"><pre>
def test_lr_scheduler_with_extra_keys_warns(tmpdir):
    """Test warning when lr_scheduler dict has extra keys."""
    model = BoringModel()
    optimizer = optim.Adam(model.parameters())
    model.configure_optimizers = lambda: {
        "optimizer": optimizer,
        "lr_scheduler": {"scheduler": optim.lr_scheduler.StepLR(optimizer, 1), "foo": 1, "bar": 2},
    }
    trainer = Trainer(default_root_dir=tmpdir, fast_dev_run=True)
    with pytest.warns(RuntimeWarning, match=r"Found unsupported keys in the lr scheduler dict: \[.+\]"):
        trainer.fit(model)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 21:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1166')" href="javascript:;">
pytorch-lightning-1.5.9/tests/trainer/test_config_validator.py: 22-39
</a>
<div class="mid" id="frag1166" style="display:none"><pre>
def test_wrong_train_setting(tmpdir):
    """
    * Test that an error is thrown when no `train_dataloader()` is defined
    * Test that an error is thrown when no `training_step()` is defined
    """
    trainer = Trainer(default_root_dir=tmpdir, max_epochs=1)

    with pytest.raises(MisconfigurationException, match=r"No `train_dataloader\(\)` method defined."):
        model = BoringModel()
        model.train_dataloader = None
        trainer.fit(model)

    with pytest.raises(MisconfigurationException, match=r"No `training_step\(\)` method defined."):
        model = BoringModel()
        model.training_step = None
        trainer.fit(model)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1168')" href="javascript:;">
pytorch-lightning-1.5.9/tests/trainer/test_config_validator.py: 50-66
</a>
<div class="mid" id="frag1168" style="display:none"><pre>
def test_fit_val_loop_config(tmpdir):
    """When either val loop or val data are missing raise warning."""
    trainer = Trainer(default_root_dir=tmpdir, max_epochs=1)

    # no val data has val loop
    with pytest.warns(UserWarning, match=r"You passed in a `val_dataloader` but have no `validation_step`"):
        model = BoringModel()
        model.validation_step = None
        trainer.fit(model)

    # has val loop but no val data
    with pytest.warns(UserWarning, match=r"You defined a `validation_step` but have no `val_dataloader`"):
        model = BoringModel()
        model.val_dataloader = None
        trainer.fit(model)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 22:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1272')" href="javascript:;">
pytorch-lightning-1.5.9/tests/base/model_valid_steps.py: 23-43
</a>
<div class="mid" id="frag1272" style="display:none"><pre>
    def validation_step(self, batch, batch_idx, *args, **kwargs):
        """Lightning calls this inside the validation loop.

        :param batch:
        :return:
        """
        self.validation_step_called = True
        x, y = batch
        x = x.view(x.size(0), -1)
        y_hat = self(x)

        loss_val = self.loss(y, y_hat)

        # acc
        labels_hat = torch.argmax(y_hat, dim=1)
        val_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)
        val_acc = torch.tensor(val_acc).type_as(x)

        output = OrderedDict({"val_loss": loss_val, "val_acc": val_acc, "test_dic": dict(val_loss_a=loss_val)})
        return output

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1274')" href="javascript:;">
pytorch-lightning-1.5.9/tests/base/model_valid_steps.py: 62-80
</a>
<div class="mid" id="frag1274" style="display:none"><pre>
    def validation_step__multiple_dataloaders(self, batch, batch_idx, dataloader_idx, **kwargs):
        """Lightning calls this inside the validation loop.

        :param batch:
        :return:
        """
        x, y = batch
        x = x.view(x.size(0), -1)
        y_hat = self(x)

        loss_val = self.loss(y, y_hat)

        # acc
        labels_hat = torch.argmax(y_hat, dim=1)
        val_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)
        val_acc = torch.tensor(val_acc).type_as(x)

        output = OrderedDict({f"val_loss_{dataloader_idx}": loss_val, f"val_acc_{dataloader_idx}": val_acc})
        return output
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 23:</b> &nbsp; 2 fragments, nominal size 20 lines, similarity 80%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1294')" href="javascript:;">
pytorch-lightning-1.5.9/tests/base/model_test_steps.py: 23-56
</a>
<div class="mid" id="frag1294" style="display:none"><pre>
    def test_step(self, batch, batch_idx, *args, **kwargs):
        """Default, baseline test_step.

        :param batch:
        :return:
        """
        self.test_step_called = True

        x, y = batch
        x = x.view(x.size(0), -1)
        y_hat = self(x)

        loss_test = self.loss(y, y_hat)

        # acc
        labels_hat = torch.argmax(y_hat, dim=1)
        test_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)
        test_acc = torch.tensor(test_acc)

        test_acc = test_acc.type_as(x)

        # alternate possible outputs to test
        if batch_idx % 1 == 0:
            output = OrderedDict({"test_loss": loss_test, "test_acc": test_acc})
            return output
        if batch_idx % 2 == 0:
            return test_acc

        if batch_idx % 3 == 0:
            output = OrderedDict(
                {"test_loss": loss_test, "test_acc": test_acc, "test_dic": dict(test_loss_a=loss_test)}
            )
            return output

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1295')" href="javascript:;">
pytorch-lightning-1.5.9/tests/base/model_test_steps.py: 57-90
</a>
<div class="mid" id="frag1295" style="display:none"><pre>
    def test_step__multiple_dataloaders(self, batch, batch_idx, dataloader_idx, **kwargs):
        """Default, baseline test_step.

        :param batch:
        :return:
        """
        x, y = batch
        x = x.view(x.size(0), -1)
        y_hat = self(x)

        loss_test = self.loss(y, y_hat)

        # acc
        labels_hat = torch.argmax(y_hat, dim=1)
        test_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)
        test_acc = torch.tensor(test_acc)

        test_acc = test_acc.type_as(x)

        # alternate possible outputs to test
        if batch_idx % 1 == 0:
            output = OrderedDict({"test_loss": loss_test, "test_acc": test_acc})
            return output
        if batch_idx % 2 == 0:
            return test_acc

        if batch_idx % 3 == 0:
            output = OrderedDict(
                {"test_loss": loss_test, "test_acc": test_acc, "test_dic": dict(test_loss_a=loss_test)}
            )
            return output
        if batch_idx % 5 == 0:
            output = OrderedDict({f"test_loss_{dataloader_idx}": loss_test, f"test_acc_{dataloader_idx}": test_acc})
            return output
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 24:</b> &nbsp; 2 fragments, nominal size 56 lines, similarity 71%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1669')" href="javascript:;">
pytorch-lightning-1.5.9/pl_examples/basic_examples/mnist_examples/image_classifier_2_lite.py: 47-140
</a>
<div class="mid" id="frag1669" style="display:none"><pre>
    def run(self, hparams):
        self.hparams = hparams
        seed_everything(hparams.seed)  # instead of torch.manual_seed(...)

        transform = T.Compose([T.ToTensor(), T.Normalize((0.1307,), (0.3081,))])
        # This is meant to ensure the data are download only by 1 process.
        if self.is_global_zero:
            MNIST("./data", download=True)
        self.barrier()
        train_dataset = MNIST("./data", train=True, transform=transform)
        test_dataset = MNIST("./data", train=False, transform=transform)
        train_loader = torch.utils.data.DataLoader(
            train_dataset,
            batch_size=hparams.batch_size,
        )
        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=hparams.batch_size)

        # don't forget to call `setup_dataloaders` to prepare for dataloaders for distributed training.
        train_loader, test_loader = self.setup_dataloaders(train_loader, test_loader)

        model = Net()  # remove call to .to(device)
        optimizer = optim.Adadelta(model.parameters(), lr=hparams.lr)

        # don't forget to call `setup` to prepare for model / optimizer for distributed training.
        # the model is moved automatically to the right device.
        model, optimizer = self.setup(model, optimizer)

        scheduler = StepLR(optimizer, step_size=1, gamma=hparams.gamma)

        # use torchmetrics instead of manually computing the accuracy
        test_acc = Accuracy().to(self.device)

        # EPOCH LOOP
        for epoch in range(1, hparams.epochs + 1):

            # TRAINING LOOP
            model.train()
            for batch_idx, (data, target) in enumerate(train_loader):
                # NOTE: no need to call `.to(device)` on the data, target
                optimizer.zero_grad()
                output = model(data)
                loss = F.nll_loss(output, target)
                self.backward(loss)  # instead of loss.backward()

                optimizer.step()
                if (batch_idx == 0) or ((batch_idx + 1) % hparams.log_interval == 0):
                    print(
                        "Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}".format(
                            epoch,
                            batch_idx * len(data),
                            len(train_loader.dataset),
                            100.0 * batch_idx / len(train_loader),
                            loss.item(),
                        )
                    )
                    if hparams.dry_run:
                        break

            scheduler.step()

            # TESTING LOOP
            model.eval()
            test_loss = 0
            with torch.no_grad():
                for data, target in test_loader:
                    # NOTE: no need to call `.to(device)` on the data, target
                    output = model(data)
                    test_loss += F.nll_loss(output, target, reduction="sum").item()

                    # WITHOUT TorchMetrics
                    # pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability
                    # correct += pred.eq(target.view_as(pred)).sum().item()

                    # WITH TorchMetrics
                    test_acc(output, target)

                    if hparams.dry_run:
                        break

            # all_gather is used to aggregated the value across processes
            test_loss = self.all_gather(test_loss).sum() / len(test_loader.dataset)

            print(f"\nTest set: Average loss: {test_loss:.4f}, Accuracy: ({test_acc.compute():.0f}%)\n")
            test_acc.reset()

            if hparams.dry_run:
                break

        # When using distributed training, use `self.save`
        # to ensure the current process is allowed to save a checkpoint
        if hparams.save_model:
            self.save(model.state_dict(), "mnist_cnn.pt")


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1672')" href="javascript:;">
pytorch-lightning-1.5.9/pl_examples/basic_examples/mnist_examples/image_classifier_1_pytorch.py: 55-130
</a>
<div class="mid" id="frag1672" style="display:none"><pre>
def run(hparams):

    torch.manual_seed(hparams.seed)

    use_cuda = torch.cuda.is_available()
    device = torch.device("cuda" if use_cuda else "cpu")

    transform = T.Compose([T.ToTensor(), T.Normalize((0.1307,), (0.3081,))])
    train_dataset = MNIST("./data", train=True, download=True, transform=transform)
    test_dataset = MNIST("./data", train=False, transform=transform)
    train_loader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=hparams.batch_size,
    )
    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=hparams.batch_size)

    model = Net().to(device)
    optimizer = optim.Adadelta(model.parameters(), lr=hparams.lr)

    scheduler = StepLR(optimizer, step_size=1, gamma=hparams.gamma)

    # EPOCH LOOP
    for epoch in range(1, hparams.epochs + 1):

        # TRAINING LOOP
        model.train()
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(device), target.to(device)
            optimizer.zero_grad()
            output = model(data)
            loss = F.nll_loss(output, target)
            loss.backward()
            optimizer.step()
            if (batch_idx == 0) or ((batch_idx + 1) % hparams.log_interval == 0):
                print(
                    "Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}".format(
                        epoch,
                        batch_idx * len(data),
                        len(train_loader.dataset),
                        100.0 * batch_idx / len(train_loader),
                        loss.item(),
                    )
                )
                if hparams.dry_run:
                    break
        scheduler.step()

        # TESTING LOOP
        model.eval()
        test_loss = 0
        correct = 0
        with torch.no_grad():
            for data, target in test_loader:
                data, target = data.to(device), target.to(device)
                output = model(data)
                test_loss += F.nll_loss(output, target, reduction="sum").item()  # sum up batch loss
                pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability
                correct += pred.eq(target.view_as(pred)).sum().item()
                if hparams.dry_run:
                    break

        test_loss /= len(test_loader.dataset)

        print(
            "\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n".format(
                test_loss, correct, len(test_loader.dataset), 100.0 * correct / len(test_loader.dataset)
            )
        )

        if hparams.dry_run:
            break

    if hparams.save_model:
        torch.save(model.state_dict(), "mnist_cnn.pt")


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<script language="JavaScript">
function ShowHide(divId) { 
    if(document.getElementById(divId).style.display == 'none') {
        document.getElementById(divId).style.display='block';
    } else { 
        document.getElementById(divId).style.display = 'none';
    } 
}
</script>
</body>
</html>
