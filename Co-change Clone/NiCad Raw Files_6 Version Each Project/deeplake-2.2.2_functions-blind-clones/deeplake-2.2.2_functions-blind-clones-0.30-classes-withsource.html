<html>
<head>
    <title>NiCad6 Clone Report</title>
    <style type="text/css">
        body {font-family:sans-serif;}
        table {background-color:white; border:0px; padding:0px; border-spacing:4px; width:auto; margin-left:30px; margin-right:auto;}
        td {background-color:rgba(192,212,238,0.8); border:0px; padding:8px; width:auto; vertical-align:top; border-radius:8px}
        pre {background-color:white; padding:4px;}
        a {color:darkblue;}
    </style>
</head>
<body>
<h2>NiCad6 Clone Report</h2>
<table>
<tr style="font-size:14pt">
<td><b>System:</b> &nbsp; deeplake-2.2.2</td>
<td><b>Clone pairs:</b> &nbsp; 33</td>
<td><b>Clone classes:</b> &nbsp; 16</td>
</tr>
<tr style="font-size:12pt">
<td style="background-color:white">Clone type: &nbsp; 3-2</td>
<td style="background-color:white">Granularity: &nbsp; functions-blind</td>
<td style="background-color:white">Max diff threshold: &nbsp; 30%</td>
<td style="background-color:white">Clone size: &nbsp; 10 - 2500 lines</td>
<td style="background-color:white">Total functions-blind: &nbsp; 541</td>
</tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 1:</b> &nbsp; 2 fragments, nominal size 25 lines, similarity 73%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag4')" href="javascript:;">
deeplake-2.2.2/hub/auto/tests/test_ingestion.py: 52-79
</a>
<div class="mid" id="frag4" style="display:none"><pre>
def test_image_classification_sets(memory_ds: Dataset):
    path = get_dummy_data_path("tests_auto/image_classification_with_sets")
    ds = hub.ingest(
        src=path,
        dest=memory_ds.path,
        images_compression="auto",
        progress_bar=False,
        summary=False,
        overwrite=False,
    )

    assert list(ds.tensors) == [
        "test/images",
        "test/labels",
        "train/images",
        "train/labels",
    ]

    assert ds["train/images"].meta.sample_compression == "jpeg"
    assert ds["test/images"].numpy().shape == (3, 200, 200, 3)
    assert ds["test/labels"].numpy().shape == (3, 1)
    assert ds["test/labels"].info.class_names == ("class0", "class1", "class2")

    assert ds["train/images"].numpy().shape == (3, 200, 200, 3)
    assert ds["train/labels"].numpy().shape == (3, 1)
    assert ds["train/labels"].info.class_names == ("class0", "class1", "class2")


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag8')" href="javascript:;">
deeplake-2.2.2/hub/auto/tests/test_kaggle.py: 35-65
</a>
<div class="mid" id="frag8" style="display:none"><pre>
def test_ingestion_sets(local_ds: Dataset, hub_kaggle_credentials):
    with CliRunner().isolated_filesystem():
        kaggle_path = os.path.join(local_ds.path, "unstructured_kaggle_data_sets")
        username, key = hub_kaggle_credentials

        ds = hub.ingest_kaggle(
            tag="thisiseshan/bird-classes",
            src=kaggle_path,
            dest=local_ds.path,
            images_compression="jpeg",
            kaggle_credentials={"username": username, "key": key},
            progress_bar=False,
            summary=False,
            overwrite=False,
        )

        assert list(ds.tensors.keys()) == [
            "test/images",
            "test/labels",
            "train/images",
            "train/labels",
        ]
        assert ds["test/images"].numpy().shape == (3, 200, 200, 3)
        assert ds["test/labels"].numpy().shape == (3, 1)
        assert ds["test/labels"].info.class_names == ("class0", "class1", "class2")

        assert ds["train/images"].numpy().shape == (3, 200, 200, 3)
        assert ds["train/labels"].numpy().shape == (3, 1)
        assert ds["train/labels"].info.class_names == ("class0", "class1", "class2")


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 2:</b> &nbsp; 2 fragments, nominal size 20 lines, similarity 85%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag5')" href="javascript:;">
deeplake-2.2.2/hub/auto/tests/test_ingestion.py: 80-102
</a>
<div class="mid" id="frag5" style="display:none"><pre>
def test_ingestion_exception(memory_ds: Dataset):
    path = get_dummy_data_path("tests_auto/image_classification_with_sets")
    with pytest.raises(InvalidPathException):
        hub.ingest(
            src="tests_auto/invalid_path",
            dest=memory_ds.path,
            images_compression="auto",
            progress_bar=False,
            summary=False,
            overwrite=False,
        )

    with pytest.raises(SamePathException):
        hub.ingest(
            src=path,
            dest=path,
            images_compression="auto",
            progress_bar=False,
            summary=False,
            overwrite=False,
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag6')" href="javascript:;">
deeplake-2.2.2/hub/auto/tests/test_ingestion.py: 103-123
</a>
<div class="mid" id="frag6" style="display:none"><pre>
def test_overwrite(local_ds: Dataset):
    path = get_dummy_data_path("tests_auto/image_classification")

    hub.ingest(
        src=path,
        dest=local_ds.path,
        images_compression="auto",
        progress_bar=False,
        summary=False,
        overwrite=False,
    )

    with pytest.raises(TensorAlreadyExistsError):
        hub.ingest(
            src=path,
            dest=local_ds.path,
            images_compression="auto",
            progress_bar=False,
            summary=False,
            overwrite=False,
        )
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 3:</b> &nbsp; 4 fragments, nominal size 20 lines, similarity 85%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag76')" href="javascript:;">
deeplake-2.2.2/hub/util/encoder.py: 22-43
</a>
<div class="mid" id="frag76" style="display:none"><pre>
def merge_all_tensor_metas(
    all_workers_tensor_metas: List[Dict[str, TensorMeta]],
    target_ds: hub.Dataset,
    storage: StorageProvider,
    overwrite: bool,
    tensors: List[str],
) -&gt; None:
    """Merges tensor metas from all workers into a single one and stores it in target_ds."""
    commit_id = target_ds.version_state["commit_id"]
    for tensor in tensors:
        rel_path = posixpath.relpath(tensor, target_ds.group_index)
        tensor_meta = None if overwrite else target_ds[rel_path].meta
        for current_worker_metas in all_workers_tensor_metas:
            current_meta = current_worker_metas[tensor]
            if tensor_meta is None:
                tensor_meta = current_meta
            else:
                combine_metas(tensor_meta, current_meta)
        meta_key = get_tensor_meta_key(tensor, commit_id)
        storage[meta_key] = tensor_meta.tobytes()  # type: ignore


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag78')" href="javascript:;">
deeplake-2.2.2/hub/util/encoder.py: 64-88
</a>
<div class="mid" id="frag78" style="display:none"><pre>
def merge_all_chunk_id_encoders(
    all_workers_chunk_id_encoders: List[Dict[str, ChunkIdEncoder]],
    target_ds: hub.Dataset,
    storage: StorageProvider,
    overwrite: bool,
    tensors: List[str],
) -&gt; None:
    """Merges chunk_id_encoders from all workers into a single one and stores it in target_ds."""
    commit_id = target_ds.version_state["commit_id"]
    for tensor in tensors:
        rel_path = posixpath.relpath(tensor, target_ds.group_index)
        chunk_id_encoder = (
            None if overwrite else target_ds[rel_path].chunk_engine.chunk_id_encoder
        )
        for current_worker_chunk_id_encoders in all_workers_chunk_id_encoders:
            current_chunk_id_encoder = current_worker_chunk_id_encoders[tensor]
            if chunk_id_encoder is None:
                chunk_id_encoder = current_worker_chunk_id_encoders[tensor]
            else:
                combine_chunk_id_encoders(chunk_id_encoder, current_chunk_id_encoder)

        chunk_id_key = get_chunk_id_encoder_key(tensor, commit_id)
        storage[chunk_id_key] = chunk_id_encoder.tobytes()  # type: ignore


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag82')" href="javascript:;">
deeplake-2.2.2/hub/util/encoder.py: 154-178
</a>
<div class="mid" id="frag82" style="display:none"><pre>
def merge_all_commit_chunk_sets(
    all_workers_commit_chunk_sets: List[Dict[str, CommitChunkSet]],
    target_ds: hub.Dataset,
    storage: StorageProvider,
    overwrite: bool,
    tensors: List[str],
) -&gt; None:
    """Merges commit_chunk_sets from all workers into a single one and stores it in target_ds."""
    commit_id = target_ds.version_state["commit_id"]
    for tensor in tensors:
        rel_path = posixpath.relpath(tensor, target_ds.group_index)
        commit_chunk_set = (
            None if overwrite else target_ds[rel_path].chunk_engine.commit_chunk_set
        )
        for current_worker_commit_chunk_set in all_workers_commit_chunk_sets:
            current_commit_chunk_set = current_worker_commit_chunk_set[tensor]
            if commit_chunk_set is None:
                commit_chunk_set = current_commit_chunk_set
            else:
                combine_commit_chunk_sets(commit_chunk_set, current_commit_chunk_set)

        commit_chunk_key = get_tensor_commit_chunk_set_key(tensor, commit_id)
        storage[commit_chunk_key] = commit_chunk_set.tobytes()  # type: ignore


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag84')" href="javascript:;">
deeplake-2.2.2/hub/util/encoder.py: 187-210
</a>
<div class="mid" id="frag84" style="display:none"><pre>
def merge_all_commit_diffs(
    all_workers_commit_diffs: List[Dict[str, CommitDiff]],
    target_ds: hub.Dataset,
    storage: StorageProvider,
    overwrite: bool,
    tensors: List[str],
) -&gt; None:
    """Merges commit_diffs from all workers into a single one and stores it in target_ds."""
    commit_id = target_ds.version_state["commit_id"]
    for tensor in tensors:
        rel_path = posixpath.relpath(tensor, target_ds.group_index)  # type: ignore
        commit_diff = None if overwrite else target_ds[rel_path].chunk_engine.commit_diff  # type: ignore
        for current_worker_commit_diffs in all_workers_commit_diffs:
            current_commit_diff = current_worker_commit_diffs[tensor]
            if commit_diff is None:
                commit_diff = current_commit_diff
                commit_diff.transform_data()
            else:
                combine_commit_diffs(commit_diff, current_commit_diff)

        commit_chunk_key = get_tensor_commit_diff_key(tensor, commit_id)
        storage[commit_chunk_key] = commit_diff.tobytes()  # type: ignore


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 4:</b> &nbsp; 2 fragments, nominal size 30 lines, similarity 93%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag198')" href="javascript:;">
deeplake-2.2.2/hub/integrations/pytorch/pytorch.py: 11-46
</a>
<div class="mid" id="frag198" style="display:none"><pre>
def create_dataloader_nesteddataloader(
    dataset,
    tensors,
    use_local_cache,
    transform,
    num_workers,
    buffer_size,
    batch_size,
    collate_fn,
    pin_memory,
    drop_last,
):
    import torch
    import torch.utils.data
    from hub.integrations.pytorch.dataset import SubIterableDataset

    return torch.utils.data.DataLoader(
        # this data set is more efficient also shuffles
        # using threads race conditions as source of entropy
        SubIterableDataset(
            dataset,
            tensors=tensors,
            use_local_cache=use_local_cache,
            transform=transform,
            num_workers=num_workers,
            buffer_size=buffer_size,
            batch_size=batch_size,
            collate_fn=collate_fn,
        ),
        batch_size=batch_size,
        collate_fn=collate_fn,
        pin_memory=pin_memory,
        drop_last=drop_last,
    )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag199')" href="javascript:;">
deeplake-2.2.2/hub/integrations/pytorch/pytorch.py: 47-80
</a>
<div class="mid" id="frag199" style="display:none"><pre>
def create_dataloader_shufflingdataloader(
    dataset,
    tensors,
    use_local_cache,
    transform,
    num_workers,
    buffer_size,
    batch_size,
    collate_fn,
    pin_memory,
    drop_last,
):
    import torch
    import torch.utils.data
    from hub.integrations.pytorch.dataset import ShufflingIterableDataset

    return torch.utils.data.DataLoader(
        # this data set is more efficient also shuffles
        # using threads race conditions as source of entropy
        ShufflingIterableDataset(
            dataset,
            tensors=tensors,
            use_local_cache=use_local_cache,
            transform=transform,
            num_workers=num_workers,
            buffer_size=buffer_size,
        ),
        batch_size=batch_size,
        collate_fn=collate_fn,
        pin_memory=pin_memory,
        drop_last=drop_last,
    )


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 5:</b> &nbsp; 2 fragments, nominal size 16 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag202')" href="javascript:;">
deeplake-2.2.2/hub/core/chunk/test_chunk_compressed.py: 31-49
</a>
<div class="mid" id="frag202" style="display:none"><pre>
def test_read_write_sequence(compression):
    tensor_meta = create_tensor_meta()
    common_args["tensor_meta"] = tensor_meta
    common_args["compression"] = compression
    dtype = tensor_meta.dtype
    data_in = [
        np.random.randint(0, 255, size=(1000, 500)).astype(dtype) for _ in range(10)
    ]
    data_in2 = data_in.copy()
    while data_in:
        chunk = ChunkCompressedChunk(**common_args)
        num_samples = int(chunk.extend_if_has_space(data_in))
        chunk._decompressed_samples = None
        data_out = [chunk.read_sample(i) for i in range(num_samples)]
        np.testing.assert_array_equal(data_out, data_in2[:num_samples])
        data_in = data_in[num_samples:]
        data_in2 = data_in2[num_samples:]


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag206')" href="javascript:;">
deeplake-2.2.2/hub/core/chunk/test_sample_compressed.py: 32-47
</a>
<div class="mid" id="frag206" style="display:none"><pre>
def test_read_write_sequence(compression):
    tensor_meta = create_tensor_meta()
    common_args["tensor_meta"] = tensor_meta
    common_args["compression"] = compression
    dtype = tensor_meta.dtype
    data_in = [np.random.rand(1000, 500, 3).astype(dtype) for _ in range(10)]
    data_in2 = data_in.copy()
    while data_in:
        chunk = SampleCompressedChunk(**common_args)
        num_samples = int(chunk.extend_if_has_space(data_in))
        data_out = [chunk.read_sample(i) for i in range(num_samples)]
        np.testing.assert_array_equal(data_out, data_in2[:num_samples])
        data_in = data_in[num_samples:]
        data_in2 = data_in2[num_samples:]


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 6:</b> &nbsp; 3 fragments, nominal size 46 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag203')" href="javascript:;">
deeplake-2.2.2/hub/core/chunk/test_chunk_compressed.py: 52-107
</a>
<div class="mid" id="frag203" style="display:none"><pre>
def test_read_write_sequence_big(cat_path, compression, random):
    tensor_meta = create_tensor_meta()
    common_args["tensor_meta"] = tensor_meta
    common_args["compression"] = compression
    dtype = tensor_meta.dtype
    data_in = []
    for i in range(50):
        if i % 10 == 0:
            data_in.append(
                np.random.randint(0, 255, size=(6001, 3000, 3)).astype(dtype) * random
            )
        elif i % 3 == 0:
            data_in.append(
                hub.read(cat_path) if random else np.zeros((900, 900, 3), dtype=dtype)
            )
        else:
            data_in.append(
                np.random.randint(0, 255, size=(1000, 500, 3)).astype(dtype) * random
            )
    data_in2 = data_in.copy()
    tiles = []
    original_length = len(data_in)
    tiled = False
    while data_in:
        chunk = ChunkCompressedChunk(**common_args)
        chunk._compression_ratio = 10  # start with a bad compression ratio to hit exponential back off code path
        num_samples = chunk.extend_if_has_space(data_in)
        if num_samples == PARTIAL_NUM_SAMPLES:
            tiled = True
            tiles.append(chunk.read_sample(0))
            sample = data_in[0]
            assert isinstance(sample, SampleTiles)
            if sample.is_last_write:
                current_length = len(data_in)
                index = original_length - current_length
                full_data_out = np_list_to_sample(
                    tiles,
                    sample.sample_shape,
                    sample.tile_shape,
                    sample.layout_shape,
                    dtype,
                )
                np.testing.assert_array_equal(full_data_out, data_in2[index])
                data_in = data_in[1:]
                tiles = []

        elif num_samples &gt; 0:
            data_out = [chunk.read_sample(i) for i in range(num_samples)]
            for i, item in enumerate(data_out):
                if isinstance(item, Sample):
                    item = item.array
                np.testing.assert_array_equal(item, data_in[i])
            data_in = data_in[num_samples:]
    assert tiled


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag207')" href="javascript:;">
deeplake-2.2.2/hub/core/chunk/test_sample_compressed.py: 49-95
</a>
<div class="mid" id="frag207" style="display:none"><pre>
def test_read_write_sequence_big(cat_path, compression):
    tensor_meta = create_tensor_meta()
    common_args["tensor_meta"] = tensor_meta
    common_args["compression"] = compression
    dtype = tensor_meta.dtype
    data_in = []
    for i in range(50):
        if i % 10 == 0:
            data_in.append(np.random.rand(6001, 3000, 3).astype(dtype))
        elif i % 3 == 0:
            data_in.append(hub.read(cat_path))
        else:
            data_in.append(np.random.rand(1000, 500, 3).astype(dtype))
    data_in2 = data_in.copy()
    tiles = []
    original_length = len(data_in)

    while data_in:
        chunk = SampleCompressedChunk(**common_args)
        num_samples = chunk.extend_if_has_space(data_in)
        if num_samples == PARTIAL_NUM_SAMPLES:
            tiles.append(chunk.read_sample(0))
            sample = data_in[0]
            assert isinstance(sample, SampleTiles)
            if sample.is_last_write:
                current_length = len(data_in)
                index = original_length - current_length
                full_data_out = np_list_to_sample(
                    tiles,
                    sample.sample_shape,
                    sample.tile_shape,
                    sample.layout_shape,
                    dtype,
                )
                np.testing.assert_array_equal(full_data_out, data_in2[index])
                data_in = data_in[1:]
                tiles = []

        elif num_samples &gt; 0:
            data_out = [chunk.read_sample(i) for i in range(num_samples)]
            for i, item in enumerate(data_out):
                if isinstance(item, Sample):
                    item = item.array
                np.testing.assert_array_equal(item, data_in[i])
            data_in = data_in[num_samples:]


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag227')" href="javascript:;">
deeplake-2.2.2/hub/core/chunk/test_uncompressed.py: 43-87
</a>
<div class="mid" id="frag227" style="display:none"><pre>
def test_read_write_sequence_big(cat_path):
    tensor_meta = create_tensor_meta()
    common_args["tensor_meta"] = tensor_meta
    dtype = tensor_meta.dtype
    data_in = []
    for i in range(50):
        if i % 10 == 0:
            data_in.append(np.random.rand(3001, 3000, 3).astype(dtype))
        elif i % 3 == 0:
            data_in.append(hub.read(cat_path))
        else:
            data_in.append(np.random.rand(500, 500, 3).astype(dtype))
    data_in2 = data_in.copy()
    tiles = []
    original_length = len(data_in)

    while data_in:
        chunk = UncompressedChunk(**common_args)
        num_samples = chunk.extend_if_has_space(data_in)
        if num_samples == PARTIAL_NUM_SAMPLES:
            tiles.append(chunk.read_sample(0))
            sample = data_in[0]
            assert isinstance(sample, SampleTiles)
            if sample.is_last_write:
                current_length = len(data_in)
                index = original_length - current_length
                full_data_out = np_list_to_sample(
                    tiles,
                    sample.sample_shape,
                    sample.tile_shape,
                    sample.layout_shape,
                    dtype,
                )
                np.testing.assert_array_equal(full_data_out, data_in2[index])
                data_in = data_in[1:]
                tiles = []
        elif num_samples &gt; 0:
            data_out = [chunk.read_sample(i) for i in range(num_samples)]
            for i, item in enumerate(data_out):
                if isinstance(item, Sample):
                    item = item.array
                np.testing.assert_array_equal(item, data_in[i])
            data_in = data_in[num_samples:]


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 7:</b> &nbsp; 3 fragments, nominal size 21 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag204')" href="javascript:;">
deeplake-2.2.2/hub/core/chunk/test_chunk_compressed.py: 109-133
</a>
<div class="mid" id="frag204" style="display:none"><pre>
def test_update(compression):
    tensor_meta = create_tensor_meta()
    common_args["tensor_meta"] = tensor_meta
    common_args["compression"] = compression
    dtype = tensor_meta.dtype
    arr = np.random.randint(0, 255, size=(7, 300, 200, 3)).astype(dtype)
    data_in = list(arr)
    chunk = ChunkCompressedChunk(**common_args)
    chunk.extend_if_has_space(data_in)

    data_out = np.array([chunk.read_sample(i) for i in range(7)])
    np.testing.assert_array_equal(data_out, data_in)

    data_3 = np.random.randint(0, 255, size=(1400, 700, 3)).astype(dtype)
    data_5 = np.random.randint(0, 255, size=(2000, 3000, 3)).astype(dtype)

    chunk.update_sample(3, data_3)
    chunk.update_sample(5, data_5)
    for i in range(7):
        if i == 3:
            np.testing.assert_array_equal(chunk.read_sample(i), data_3)
        elif i == 5:
            np.testing.assert_array_equal(chunk.read_sample(i), data_5)
        else:
            np.testing.assert_array_equal(chunk.read_sample(i), data_in[i])
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag230')" href="javascript:;">
deeplake-2.2.2/hub/core/chunk/test_uncompressed.py: 123-145
</a>
<div class="mid" id="frag230" style="display:none"><pre>
def test_update():
    tensor_meta = create_tensor_meta()
    common_args["tensor_meta"] = tensor_meta
    dtype = tensor_meta.dtype
    data_in = np.random.rand(7, 500, 500).astype(dtype)
    chunk = UncompressedChunk(**common_args)
    chunk.extend_if_has_space(data_in)

    data_out = np.array([chunk.read_sample(i) for i in range(7)])
    np.testing.assert_array_equal(data_out, data_in)

    data_3 = np.random.rand(700, 700).astype(dtype)
    data_5 = np.random.rand(3000, 3000).astype(dtype)

    chunk.update_sample(3, data_3)
    chunk.update_sample(5, data_5)
    for i in range(7):
        if i == 3:
            np.testing.assert_array_equal(chunk.read_sample(i), data_3)
        elif i == 5:
            np.testing.assert_array_equal(chunk.read_sample(i), data_5)
        else:
            np.testing.assert_array_equal(chunk.read_sample(i), data_in[i])
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag208')" href="javascript:;">
deeplake-2.2.2/hub/core/chunk/test_sample_compressed.py: 97-120
</a>
<div class="mid" id="frag208" style="display:none"><pre>
def test_update(compression):
    tensor_meta = create_tensor_meta()
    common_args["tensor_meta"] = tensor_meta
    common_args["compression"] = compression
    dtype = tensor_meta.dtype
    arr = np.random.rand(7, 100, 500, 3).astype(dtype)
    data_in = list(arr)
    chunk = SampleCompressedChunk(**common_args)
    chunk.extend_if_has_space(data_in)
    data_out = np.array([chunk.read_sample(i) for i in range(7)])
    np.testing.assert_array_equal(data_out, data_in)

    data_3 = np.random.rand(1400, 700, 3).astype(dtype)
    data_5 = np.random.rand(6000, 3000, 3).astype(dtype)

    chunk.update_sample(3, data_3)
    chunk.update_sample(5, data_5)
    for i in range(7):
        if i == 3:
            np.testing.assert_array_equal(chunk.read_sample(i), data_3)
        elif i == 5:
            np.testing.assert_array_equal(chunk.read_sample(i), data_5)
        else:
            np.testing.assert_array_equal(chunk.read_sample(i), arr[i])
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 8:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 73%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag232')" href="javascript:;">
deeplake-2.2.2/hub/core/test_serialize.py: 49-75
</a>
<div class="mid" id="frag232" style="display:none"><pre>
def test_sample_img_compression(cat_path, compression="png"):
    sample = hub.read(cat_path)
    arr = sample.array

    # reloaded to get rid of cached array in sample
    sample = hub.read(cat_path)
    out, shape = serialize_sample_object(
        sample, compression, None, "uint16", "generic", 16 * MB
    )
    arr_deserialized = decompress_array(out, compression=compression).reshape(shape)
    np.testing.assert_array_equal(arr, arr_deserialized)

    # reloaded to get rid of cached array in sample
    sample = hub.read(cat_path)
    out, shape = serialize_sample_object(
        sample, compression, None, "uint16", "generic", 100 * KB
    )
    assert isinstance(out, SampleTiles)
    out_list = [out.yield_tile() for _ in range(out.num_tiles)]
    np_list = [
        decompress_array(b[0], compression=compression).reshape(b[1]) for b in out_list
    ]
    tile_shape, layout_shape = out.tile_shape, out.layout_shape
    out = np_list_to_sample(np_list, shape, tile_shape, layout_shape, "uint16")
    np.testing.assert_array_equal(arr, out)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag234')" href="javascript:;">
deeplake-2.2.2/hub/core/test_serialize.py: 102-124
</a>
<div class="mid" id="frag234" style="display:none"><pre>
def test_sample_no_compression(cat_path):
    sample = hub.read(cat_path)
    arr = sample.array

    # reloaded to get rid of cached array in sample
    sample = hub.read(cat_path)
    out, shape = serialize_sample_object(
        sample, None, None, "uint16", "generic", 16 * MB
    )
    arr_deserialized = np.frombuffer(out, dtype="uint16").reshape(shape)
    np.testing.assert_array_equal(arr, arr_deserialized)

    # reloaded to get rid of cached array in sample
    sample = hub.read(cat_path)
    out, shape = serialize_sample_object(
        sample, None, None, "uint16", "generic", 100 * KB
    )
    assert isinstance(out, SampleTiles)
    out_list = [out.yield_tile() for _ in range(out.num_tiles)]
    np_list = [np.frombuffer(b[0], dtype="uint16").reshape(b[1]) for b in out_list]
    tile_shape, layout_shape = out.tile_shape, out.layout_shape
    out = np_list_to_sample(np_list, shape, tile_shape, layout_shape, "uint16")
    np.testing.assert_array_equal(arr, out)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 9:</b> &nbsp; 3 fragments, nominal size 18 lines, similarity 83%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag271')" href="javascript:;">
deeplake-2.2.2/hub/core/dataset/hub_cloud_dataset.py: 105-124
</a>
<div class="mid" id="frag271" style="display:none"><pre>
    def _send_query_progress(
        self,
        query_id: str = "",
        query_text: str = "",
        start: bool = False,
        end: bool = False,
        progress: int = 0,
        status="",
    ):
        hub_meta = {
            "query_id": query_id,
            "query_text": query_text,
            "progress": progress,
            "start": start,
            "end": end,
            "status": status,
        }
        event_id = f"{self.org_id}/{self.ds_name}.query"
        self._send_event(event_id=event_id, event_group="query", hub_meta=hub_meta)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag272')" href="javascript:;">
deeplake-2.2.2/hub/core/dataset/hub_cloud_dataset.py: 125-144
</a>
<div class="mid" id="frag272" style="display:none"><pre>
    def _send_compute_progress(
        self,
        compute_id: str = "",
        start: bool = False,
        end: bool = False,
        progress: int = 0,
        status="",
    ):
        hub_meta = {
            "compute_id": compute_id,
            "progress": progress,
            "start": start,
            "end": end,
            "status": status,
        }
        event_id = f"{self.org_id}/{self.ds_name}.compute"
        self._send_event(
            event_id=event_id, event_group="hub_compute", hub_meta=hub_meta
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag273')" href="javascript:;">
deeplake-2.2.2/hub/core/dataset/hub_cloud_dataset.py: 145-162
</a>
<div class="mid" id="frag273" style="display:none"><pre>
    def _send_pytorch_progress(
        self,
        pytorch_id: str = "",
        start: bool = False,
        end: bool = False,
        progress: int = 0,
        status="",
    ):
        hub_meta = {
            "pytorch_id": pytorch_id,
            "progress": progress,
            "start": start,
            "end": end,
            "status": status,
        }
        event_id = f"{self.org_id}/{self.ds_name}.pytorch"
        self._send_event(event_id=event_id, event_group="pytorch", hub_meta=hub_meta)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 10:</b> &nbsp; 2 fragments, nominal size 17 lines, similarity 83%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag305')" href="javascript:;">
deeplake-2.2.2/hub/core/meta/encode/tests/test_shape_encoder.py: 15-34
</a>
<div class="mid" id="frag305" style="display:none"><pre>
def test_fixed():
    enc = ShapeEncoder()

    enc.register_samples((28, 28, 3), 1000)
    enc.register_samples((28, 28, 3), 1000)
    enc.register_samples((28, 28, 3), 3)
    enc.register_samples((28, 28, 3), 1000)
    enc.register_samples((28, 28, 3), 1000)

    assert enc.num_samples == 4003
    assert len(enc._encoded) == 1
    assert enc.num_samples_at(0) == 4003

    assert enc[0] == (28, 28, 3)
    assert enc[1999] == (28, 28, 3)
    assert enc[2000] == (28, 28, 3)
    assert enc[3000] == (28, 28, 3)
    assert enc[-1] == (28, 28, 3)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag306')" href="javascript:;">
deeplake-2.2.2/hub/core/meta/encode/tests/test_shape_encoder.py: 35-57
</a>
<div class="mid" id="frag306" style="display:none"><pre>
def test_dynamic():
    enc = ShapeEncoder()

    enc.register_samples((28, 28, 3), 1000)
    enc.register_samples((28, 28, 3), 1000)
    enc.register_samples((30, 28, 3), 1000)
    enc.register_samples((28, 28, 4), 1000)
    enc.register_samples((28, 28, 3), 1)

    assert enc.num_samples == 4001
    assert len(enc._encoded) == 4
    assert enc.num_samples_at(0) == 2000
    assert enc.num_samples_at(1) == 1000
    assert enc.num_samples_at(2) == 1000
    assert enc.num_samples_at(3) == 1

    assert enc[0] == (28, 28, 3)
    assert enc[1999] == (28, 28, 3)
    assert enc[2000] == (30, 28, 3)
    assert enc[3000] == (28, 28, 4)
    assert enc[-1] == (28, 28, 3)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 11:</b> &nbsp; 4 fragments, nominal size 38 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag346')" href="javascript:;">
deeplake-2.2.2/hub/core/transform/test_transform.py: 107-154
</a>
<div class="mid" id="frag346" style="display:none"><pre>
def test_single_transform_hub_dataset(ds, scheduler):
    data_in = hub.dataset("./test/single_transform_hub_dataset", overwrite=True)
    with data_in:
        data_in.create_tensor("image")
        data_in.create_tensor("label")
        for i in range(1, 100):
            data_in.image.append(i * np.ones((i, i)))
            data_in.label.append(i * np.ones((1,)))
    ds_out = ds
    ds_out.create_tensor("image")
    ds_out.create_tensor("label")
    if (
        isinstance(remove_memory_cache(ds.storage), MemoryProvider)
        and scheduler != "threaded"
    ):
        # any scheduler other than `threaded` will not work with a dataset stored in memory
        with pytest.raises(InvalidOutputDatasetError):
            fn2(copy=1, mul=2).eval(
                data_in,
                ds_out,
                num_workers=TRANSFORM_TEST_NUM_WORKERS,
                progressbar=False,
                scheduler=scheduler,
            )
        data_in.delete()
        return

    fn2(copy=1, mul=2).eval(
        data_in,
        ds_out,
        num_workers=TRANSFORM_TEST_NUM_WORKERS,
        scheduler=scheduler,
        progressbar=False,
    )
    assert len(ds_out) == 99
    for index in range(1, 100):
        np.testing.assert_array_equal(
            ds_out[index - 1].image.numpy(), 2 * index * np.ones((index, index))
        )
        np.testing.assert_array_equal(
            ds_out[index - 1].label.numpy(), 2 * index * np.ones((1,))
        )

    assert ds_out.image.shape_interval.lower == (99, 1, 1)
    assert ds_out.image.shape_interval.upper == (99, 99, 99)
    data_in.delete()


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag355')" href="javascript:;">
deeplake-2.2.2/hub/core/transform/test_transform.py: 468-511
</a>
<div class="mid" id="frag355" style="display:none"><pre>
def test_hub_like(ds, scheduler="threaded"):
    with CliRunner().isolated_filesystem():
        data_in = ds
        with data_in:
            data_in.create_tensor("image", htype="image", sample_compression="png")
            data_in.create_tensor("label", htype="class_label")
            for i in range(1, 100):
                data_in.image.append(i * np.ones((i, i), dtype="uint8"))
                data_in.label.append(i * np.ones((1,), dtype="uint32"))
        ds_out = hub.like("./transform_hub_like", data_in)
        if (
            isinstance(remove_memory_cache(ds.storage), MemoryProvider)
            and scheduler != "threaded"
        ):
            # any scheduler other than `threaded` will not work with a dataset stored in memory
            with pytest.raises(InvalidOutputDatasetError):
                fn2(copy=1, mul=2).eval(
                    data_in,
                    ds_out,
                    num_workers=TRANSFORM_TEST_NUM_WORKERS,
                    progressbar=False,
                    scheduler=scheduler,
                )
            return
        fn2(copy=1, mul=2).eval(
            data_in,
            ds_out,
            num_workers=TRANSFORM_TEST_NUM_WORKERS,
            progressbar=False,
            scheduler=scheduler,
        )
        assert len(ds_out) == 99
        for index in range(1, 100):
            np.testing.assert_array_equal(
                ds_out[index - 1].image.numpy(), 2 * index * np.ones((index, index))
            )
            np.testing.assert_array_equal(
                ds_out[index - 1].label.numpy(), 2 * index * np.ones((1,))
            )

        assert ds_out.image.shape_interval.lower == (99, 1, 1)
        assert ds_out.image.shape_interval.upper == (99, 99, 99)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag349')" href="javascript:;">
deeplake-2.2.2/hub/core/transform/test_transform.py: 225-269
</a>
<div class="mid" id="frag349" style="display:none"><pre>
def test_single_transform_hub_dataset_htypes(ds, num_workers, scheduler):
    data_in = hub.dataset("./test/single_transform_hub_dataset_htypes", overwrite=True)
    with data_in:
        data_in.create_tensor("image", htype="image", sample_compression="png")
        data_in.create_tensor("label", htype="class_label")
        for i in range(1, 100):
            data_in.image.append(i * np.ones((i, i), dtype="uint8"))
            data_in.label.append(i * np.ones((1,), dtype="uint32"))
    ds_out = ds
    ds_out.create_tensor("image")
    ds_out.create_tensor("label")
    if (
        isinstance(remove_memory_cache(ds.storage), MemoryProvider)
        and scheduler != "threaded"
        and num_workers &gt; 0
    ):
        # any scheduler other than `threaded` will not work with a dataset stored in memory
        # num_workers = 0 automatically does single threaded irrespective of the scheduler
        with pytest.raises(InvalidOutputDatasetError):
            fn2(copy=1, mul=2).eval(
                data_in,
                ds_out,
                num_workers=num_workers,
                progressbar=False,
                scheduler=scheduler,
            )
        data_in.delete()
        return
    fn2(copy=1, mul=2).eval(
        data_in, ds_out, num_workers=num_workers, progressbar=False, scheduler=scheduler
    )
    assert len(ds_out) == 99
    for index in range(1, 100):
        np.testing.assert_array_equal(
            ds_out[index - 1].image.numpy(), 2 * index * np.ones((index, index))
        )
        np.testing.assert_array_equal(
            ds_out[index - 1].label.numpy(), 2 * index * np.ones((1,))
        )

    assert ds_out.image.shape_interval.lower == (99, 1, 1)
    assert ds_out.image.shape_interval.upper == (99, 99, 99)
    data_in.delete()


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag360')" href="javascript:;">
deeplake-2.2.2/hub/core/transform/test_transform.py: 554-605
</a>
<div class="mid" id="frag360" style="display:none"><pre>
def test_transform_persistance(local_ds_generator, num_workers=2, scheduler="threaded"):
    data_in = hub.dataset("./test/single_transform_hub_dataset_htypes", overwrite=True)
    with data_in:
        data_in.create_tensor("image", htype="image", sample_compression="png")
        data_in.create_tensor("label", htype="class_label")
        for i in range(1, 100):
            data_in.image.append(i * np.ones((i, i), dtype="uint8"))
            data_in.label.append(i * np.ones((1,), dtype="uint32"))
    ds_out = local_ds_generator()
    ds_out.create_tensor("image")
    ds_out.create_tensor("label")
    if (
        isinstance(remove_memory_cache(ds_out.storage), MemoryProvider)
        and scheduler != "threaded"
        and num_workers &gt; 0
    ):
        # any scheduler other than `threaded` will not work with a dataset stored in memory
        # num_workers = 0 automatically does single threaded irrespective of the scheduler
        with pytest.raises(InvalidOutputDatasetError):
            fn2(copy=1, mul=2).eval(
                data_in,
                ds_out,
                num_workers=num_workers,
                scheduler=scheduler,
                progressbar=False,
            )
        data_in.delete()
        return
    fn2(copy=1, mul=2).eval(
        data_in, ds_out, num_workers=num_workers, scheduler=scheduler, progressbar=False
    )

    def test_ds_out():
        assert len(ds_out) == 99
        for index in range(1, 100):
            np.testing.assert_array_equal(
                ds_out[index - 1].image.numpy(), 2 * index * np.ones((index, index))
            )
            np.testing.assert_array_equal(
                ds_out[index - 1].label.numpy(), 2 * index * np.ones((1,))
            )

        assert ds_out.image.shape_interval.lower == (99, 1, 1)
        assert ds_out.image.shape_interval.upper == (99, 99, 99)

    test_ds_out()
    ds_out = local_ds_generator()
    test_ds_out()

    data_in.delete()


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 12:</b> &nbsp; 2 fragments, nominal size 28 lines, similarity 89%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag353')" href="javascript:;">
deeplake-2.2.2/hub/core/transform/test_transform.py: 399-431
</a>
<div class="mid" id="frag353" style="display:none"><pre>
def test_transform_hub_read(ds, cat_path, sample_compression, scheduler):
    data_in = [cat_path] * 10
    ds_out = ds
    ds_out.create_tensor("image", htype="image", sample_compression=sample_compression)

    if (
        isinstance(remove_memory_cache(ds.storage), MemoryProvider)
        and scheduler != "threaded"
    ):
        # any scheduler other than `threaded` will not work with a dataset stored in memory
        with pytest.raises(InvalidOutputDatasetError):
            read_image().eval(
                data_in,
                ds_out,
                num_workers=TRANSFORM_TEST_NUM_WORKERS,
                progressbar=False,
                scheduler=scheduler,
            )
        return

    read_image().eval(
        data_in,
        ds_out,
        num_workers=TRANSFORM_TEST_NUM_WORKERS,
        progressbar=False,
        scheduler=scheduler,
    )
    assert len(ds_out) == 10
    for i in range(10):
        assert ds_out.image[i].numpy().shape == (900, 900, 3)
        np.testing.assert_array_equal(ds_out.image[i].numpy(), ds_out.image[0].numpy())


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag354')" href="javascript:;">
deeplake-2.2.2/hub/core/transform/test_transform.py: 435-466
</a>
<div class="mid" id="frag354" style="display:none"><pre>
def test_transform_hub_read_pipeline(ds, cat_path, sample_compression, scheduler):
    data_in = [cat_path] * 10
    ds_out = ds
    ds_out.create_tensor("image", htype="image", sample_compression=sample_compression)
    pipeline = hub.compose([read_image(), crop_image(copy=2)])
    if (
        isinstance(remove_memory_cache(ds.storage), MemoryProvider)
        and scheduler != "threaded"
    ):
        # any scheduler other than `threaded` will not work with a dataset stored in memory
        with pytest.raises(InvalidOutputDatasetError):
            pipeline.eval(
                data_in,
                ds_out,
                num_workers=TRANSFORM_TEST_NUM_WORKERS,
                progressbar=False,
                scheduler=scheduler,
            )
        return
    pipeline.eval(
        data_in,
        ds_out,
        num_workers=TRANSFORM_TEST_NUM_WORKERS,
        progressbar=False,
        scheduler=scheduler,
    )
    assert len(ds_out) == 20
    for i in range(20):
        assert ds_out.image[i].numpy().shape == (100, 100, 3)
        np.testing.assert_array_equal(ds_out.image[i].numpy(), ds_out.image[0].numpy())


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 13:</b> &nbsp; 2 fragments, nominal size 15 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag412')" href="javascript:;">
deeplake-2.2.2/hub/core/tiling/test_serialize.py: 26-45
</a>
<div class="mid" id="frag412" style="display:none"><pre>
def test_serialize_tiles():
    sample = _get_arange_sample((2, 5))
    tile_shape = (3, 3)

    tiles = break_into_tiles(sample, tile_shape)
    shapes = [t.shape for _, t in np.ndenumerate(tiles)]
    serialized_tiles = serialize_tiles(tiles, lambda x: memoryview(x.tobytes()))
    assert serialized_tiles.shape == tiles.shape

    flattened_tiles = serialized_tiles.reshape((serialized_tiles.size,))
    tiled_arrays = [
        np.frombuffer(x, dtype=sample.dtype).reshape(sh)
        for x, sh in zip(flattened_tiles, shapes)
    ]
    coalesced_sample = np_list_to_sample(
        tiled_arrays, sample.shape, tile_shape, tiles.shape, sample.dtype
    )
    np.testing.assert_array_equal(sample, coalesced_sample)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag413')" href="javascript:;">
deeplake-2.2.2/hub/core/tiling/test_serialize.py: 46-65
</a>
<div class="mid" id="frag413" style="display:none"><pre>
def test_serialize_tiles_gzip():
    sample = _get_arange_sample((2, 5))
    tile_shape = (3, 3)

    tiles = break_into_tiles(sample, tile_shape)
    shapes = [t.shape for _, t in np.ndenumerate(tiles)]
    gzip_compress = lambda x: memoryview(gzip.compress(x.tobytes()))
    serialized_tiles = serialize_tiles(tiles, gzip_compress)
    assert serialized_tiles.shape == tiles.shape

    flattened_tiles = serialized_tiles.reshape((serialized_tiles.size,))
    gzip_decompress = lambda x: np.frombuffer(gzip.decompress(x), dtype=sample.dtype)
    tiled_arrays = [
        gzip_decompress(x).reshape(sh) for x, sh in zip(flattened_tiles, shapes)
    ]

    coalesced_sample = np_list_to_sample(
        tiled_arrays, sample.shape, tile_shape, tiles.shape, sample.dtype
    )
    np.testing.assert_array_equal(sample, coalesced_sample)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 14:</b> &nbsp; 3 fragments, nominal size 13 lines, similarity 81%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag500')" href="javascript:;">
deeplake-2.2.2/hub/api/tests/test_chunk_sizes.py: 33-54
</a>
<div class="mid" id="frag500" style="display:none"><pre>
def test_append(memory_ds):
    ds = memory_ds
    images, labels = _create_tensors(ds)

    _append_tensors(images, labels)

    _assert_num_chunks(labels, 1)
    _assert_num_chunks(images, 5)

    _append_tensors(images, labels)

    _assert_num_chunks(labels, 1)
    _assert_num_chunks(images, 10)

    _append_tensors(images, labels)

    _assert_num_chunks(labels, 1)
    _assert_num_chunks(images, 15)

    assert len(ds) == 300


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag501')" href="javascript:;">
deeplake-2.2.2/hub/api/tests/test_chunk_sizes.py: 55-76
</a>
<div class="mid" id="frag501" style="display:none"><pre>
def test_extend(memory_ds):
    ds = memory_ds
    images, labels = _create_tensors(ds)

    _extend_tensors(images, labels)

    _assert_num_chunks(labels, 1)
    _assert_num_chunks(images, 5)

    _extend_tensors(images, labels)

    _assert_num_chunks(labels, 1)
    _assert_num_chunks(images, 10)

    _extend_tensors(images, labels)

    _assert_num_chunks(labels, 1)
    _assert_num_chunks(images, 15)

    assert len(ds) == 300


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag502')" href="javascript:;">
deeplake-2.2.2/hub/api/tests/test_chunk_sizes.py: 77-101
</a>
<div class="mid" id="frag502" style="display:none"><pre>
def test_extend_and_append(memory_ds):
    ds = memory_ds
    images, labels = _create_tensors(ds)

    _extend_tensors(images, labels)

    _assert_num_chunks(labels, 1)
    _assert_num_chunks(images, 5)

    _append_tensors(images, labels)

    _assert_num_chunks(labels, 1)
    _assert_num_chunks(images, 10)

    _extend_tensors(images, labels)

    _assert_num_chunks(labels, 1)
    _assert_num_chunks(images, 15)

    _append_tensors(images, labels)

    _assert_num_chunks(labels, 1)
    _assert_num_chunks(images, 20)

    assert len(ds) == 400
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 15:</b> &nbsp; 2 fragments, nominal size 21 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag504')" href="javascript:;">
deeplake-2.2.2/hub/api/tests/test_api_with_compression.py: 37-67
</a>
<div class="mid" id="frag504" style="display:none"><pre>
def test_populate_compressed_samples(ds: Dataset, cat_path, flower_path):
    images = ds.create_tensor(
        TENSOR_KEY, htype="image", sample_compression="png", max_chunk_size=2 * MB
    )

    assert images.meta.dtype == "uint8"
    assert images.meta.sample_compression == "png"

    _populate_compressed_samples(images, cat_path, flower_path)

    expected_shapes = [
        (900, 900, 3),
        (513, 464, 4),
        (100, 100, 4),
        (100, 100, 4),
        (513, 464, 4),
        (900, 900, 3),
    ]

    assert len(images) == 6

    for img, exp_shape in zip(images, expected_shapes):
        arr = img.numpy()
        assert arr.shape == exp_shape
        assert arr.dtype == "uint8"

    assert images.shape == (6, None, None, None)
    assert images.shape_interval.lower == (6, 100, 100, 3)
    assert images.shape_interval.upper == (6, 900, 900, 4)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag505')" href="javascript:;">
deeplake-2.2.2/hub/api/tests/test_api_with_compression.py: 69-96
</a>
<div class="mid" id="frag505" style="display:none"><pre>
def test_iterate_compressed_samples(ds: Dataset, cat_path, flower_path):
    images = ds.create_tensor(TENSOR_KEY, htype="image", sample_compression="png")

    assert images.meta.dtype == "uint8"
    assert images.meta.sample_compression == "png"

    _populate_compressed_samples(images, cat_path, flower_path)

    expected_shapes = [
        (900, 900, 3),
        (513, 464, 4),
        (100, 100, 4),
        (100, 100, 4),
        (513, 464, 4),
        (900, 900, 3),
    ]

    assert len(images) == len(expected_shapes)
    for image, expected_shape in zip(images, expected_shapes):
        x = image.numpy()

        assert (
            type(x) == np.ndarray
        ), "Check is necessary in case a `PIL` object is returned instead of an array."
        assert x.shape == expected_shape
        assert x.dtype == "uint8"


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 16:</b> &nbsp; 3 fragments, nominal size 14 lines, similarity 71%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag530')" href="javascript:;">
deeplake-2.2.2/hub/api/tests/test_json.py: 9-24
</a>
<div class="mid" id="frag530" style="display:none"><pre>
def test_json_basic(memory_ds):
    ds = memory_ds
    ds.create_tensor("json", htype="json")
    items = [
        {"x": [1, 2, 3], "y": [4, [5, 6]]},
        {"x": [1, 2, 3], "y": [4, {"z": [0.1, 0.2, []]}]},
    ]
    with ds:
        for x in items:
            ds.json.append(x)
        ds.json.extend(items)
    assert ds.json.shape == (4, 1)
    for i in range(4):
        assert ds.json[i].data() == items[i % 2]


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag531')" href="javascript:;">
deeplake-2.2.2/hub/api/tests/test_json.py: 25-40
</a>
<div class="mid" id="frag531" style="display:none"><pre>
def test_json_with_numpy(memory_ds):
    ds = memory_ds
    ds.create_tensor("json", htype="json")
    items = [
        {"x": np.array([1, 2, 3], dtype=np.float32), "y": [4, [5, 6]]},
        {"x": np.array([1, 2, 3], dtype=np.uint8), "y": [4, {"z": [0.1, 0.2, []]}]},
    ]
    with ds:
        for x in items:
            ds.json.append(x)
        ds.json.extend(items)
    for i in range(4):
        assert ds.json[i].data()["y"] == items[i % 2]["y"]
        np.testing.assert_array_equal(ds.json[i].data()["x"], items[i % 2]["x"])


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag533')" href="javascript:;">
deeplake-2.2.2/hub/api/tests/test_json.py: 65-82
</a>
<div class="mid" id="frag533" style="display:none"><pre>
def test_json_list_basic(memory_ds):
    ds = memory_ds
    ds.create_tensor("list", htype="list")
    items = [
        [{"x": [1, 2, 3], "y": [4, [5, 6]]}, [[]], [None, 0.1]],
        [[], [[[]]], {"a": [0.1, 1, "a", []]}],
    ]
    with ds:
        for x in items:
            ds.list.append(x)
        ds.list.extend(items)
    assert ds.list.shape == (4, 3)
    for i in range(4):
        assert ds.list[i].data() == items[i % 2]
    for i, x in enumerate(ds.list.data()):
        assert x == items[i % 2]


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<script language="JavaScript">
function ShowHide(divId) { 
    if(document.getElementById(divId).style.display == 'none') {
        document.getElementById(divId).style.display='block';
    } else { 
        document.getElementById(divId).style.display = 'none';
    } 
}
</script>
</body>
</html>
