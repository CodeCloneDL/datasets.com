<clones>
<systeminfo processor="nicad6" system="raster-vision-0.12.0" granularity="functions-blind" threshold="30%" minlines="10" maxlines="2500"/>
<cloneinfo npcs="939" npairs="50"/>
<runinfo ncompares="17131" cputime="59702"/>
<classinfo nclasses="19"/>

<class classid="1" nclones="2" nlines="56" similarity="70">
<source file="systems/raster-vision-0.12.0/rastervision_pytorch_backend/rastervision/pytorch_backend/examples/object_detection/xview.py" startline="15" endline="76" pcid="28">
def get_config(runner, raw_uri, processed_uri, root_uri, test=False):
    train_scene_info = get_scene_info(join(processed_uri, 'train-scenes.csv'))
    val_scene_info = get_scene_info(join(processed_uri, 'val-scenes.csv'))
    if test:
        train_scene_info = train_scene_info[0:1]
        val_scene_info = val_scene_info[0:1]

    def make_scene(scene_info):
        (raster_uri, label_uri) = scene_info
        raster_uri = join(raw_uri, raster_uri)
        label_uri = join(processed_uri, label_uri)

        if test:
            crop_uri = join(processed_uri, 'crops',
                            os.path.basename(raster_uri))
            save_image_crop(raster_uri, crop_uri, size=600, min_features=5)
            raster_uri = crop_uri

        id = os.path.splitext(os.path.basename(raster_uri))[0]

        raster_source = RasterioSourceConfig(
            uris=[raster_uri], channel_order=[0, 1, 2])

        label_source = ObjectDetectionLabelSourceConfig(
            vector_source=GeoJSONVectorSourceConfig(
                uri=label_uri, default_class_id=0, ignore_crs_field=True))

        return SceneConfig(
            id=id, raster_source=raster_source, label_source=label_source)

    train_scenes = [make_scene(info) for info in train_scene_info]
    val_scenes = [make_scene(info) for info in val_scene_info]
    class_config = ClassConfig(names=['vehicle'], colors=['red'])
    chip_sz = 300
    dataset = DatasetConfig(
        class_config=class_config,
        train_scenes=train_scenes,
        validation_scenes=val_scenes)
    chip_options = ObjectDetectionChipOptions(neg_ratio=1.0, ioa_thresh=0.8)
    predict_options = ObjectDetectionPredictOptions(
        merge_thresh=0.1, score_thresh=0.5)

    backend = PyTorchObjectDetectionConfig(
        model=ObjectDetectionModelConfig(backbone=Backbone.resnet50),
        solver=SolverConfig(
            lr=1e-4,
            num_epochs=10,
            test_num_epochs=2,
            batch_sz=16,
            one_cycle=True),
        log_tensorboard=True,
        run_tensorboard=False,
        test_mode=test)

    return ObjectDetectionConfig(
        root_uri=root_uri,
        dataset=dataset,
        backend=backend,
        train_chip_sz=chip_sz,
        predict_chip_sz=chip_sz,
        chip_options=chip_options,
        predict_options=predict_options)
</source>
<source file="systems/raster-vision-0.12.0/rastervision_pytorch_backend/rastervision/pytorch_backend/examples/object_detection/cowc_potsdam.py" startline="15" endline="82" pcid="34">
def get_config(runner, raw_uri, processed_uri, root_uri, test=False):
    train_ids = [
        '2_10', '2_11', '2_12', '2_14', '3_11', '3_13', '4_10', '5_10', '6_7',
        '6_9'
    ]
    val_ids = ['2_13', '6_8', '3_10']

    if test:
        train_ids = train_ids[0:1]
        val_ids = val_ids[0:1]

    def make_scene(id):
        raster_uri = join(raw_uri,
                          '4_Ortho_RGBIR/top_potsdam_{}_RGBIR.tif'.format(id))
        label_uri = join(processed_uri, 'labels', 'all',
                         'top_potsdam_{}_RGBIR.json'.format(id))

        if test:
            crop_uri = join(processed_uri, 'crops',
                            os.path.basename(raster_uri))
            save_image_crop(
                raster_uri,
                crop_uri,
                label_uri=label_uri,
                size=1000,
                min_features=5)
            raster_uri = crop_uri

        raster_source = RasterioSourceConfig(
            uris=[raster_uri], channel_order=[0, 1, 2])

        label_source = ObjectDetectionLabelSourceConfig(
            vector_source=GeoJSONVectorSourceConfig(
                uri=label_uri, default_class_id=0, ignore_crs_field=True))

        return SceneConfig(
            id=id, raster_source=raster_source, label_source=label_source)

    class_config = ClassConfig(names=['vehicle'])
    chip_sz = 300
    dataset = DatasetConfig(
        class_config=class_config,
        train_scenes=[make_scene(id) for id in train_ids],
        validation_scenes=[make_scene(id) for id in val_ids])
    chip_options = ObjectDetectionChipOptions(neg_ratio=5.0, ioa_thresh=0.9)
    predict_options = ObjectDetectionPredictOptions(
        merge_thresh=0.5, score_thresh=0.9)

    backend = PyTorchObjectDetectionConfig(
        model=ObjectDetectionModelConfig(backbone=Backbone.resnet18),
        solver=SolverConfig(
            lr=1e-4,
            num_epochs=10,
            test_num_epochs=2,
            batch_sz=16,
            one_cycle=True),
        log_tensorboard=True,
        run_tensorboard=False,
        test_mode=test)

    return ObjectDetectionConfig(
        root_uri=root_uri,
        dataset=dataset,
        backend=backend,
        train_chip_sz=chip_sz,
        predict_chip_sz=chip_sz,
        chip_options=chip_options,
        predict_options=predict_options)
</source>
</class>

<class classid="2" nclones="2" nlines="16" similarity="93">
<source file="systems/raster-vision-0.12.0/rastervision_pytorch_learner/rastervision/pytorch_learner/examples/classification.py" startline="11" endline="27" pcid="135">
def get_config(runner, test=False):
    base_uri = ('s3://raster-vision-lf-dev/learner/classification'
                if runner == AWS_BATCH else '/opt/data/learner/classification')
    root_uri = join(base_uri, 'output')
    data_uri = join(base_uri, 'tiny-buildings.zip')

    model = ModelConfig(backbone='resnet50')
    solver = SolverConfig(lr=2e-4, num_epochs=3, batch_sz=8, one_cycle=True)
    data = ClassificationDataConfig(
        data_format='image_folder',
        uri=data_uri,
        img_sz=200,
        labels=['building', 'no_building'])
    learner = ClassificationLearnerConfig(
        model=model, solver=solver, data=data, test_mode=test)
    pipeline = LearnerPipelineConfig(root_uri=root_uri, learner=learner)
    return pipeline
</source>
<source file="systems/raster-vision-0.12.0/rastervision_pytorch_learner/rastervision/pytorch_learner/examples/regression.py" startline="10" endline="27" pcid="136">
def get_config(runner, test=False):
    base_uri = ('s3://raster-vision-lf-dev/learner/regression'
                if runner == AWS_BATCH else '/opt/data/learner/regression')
    root_uri = join(base_uri, 'output')
    data_uri = join(base_uri, 'tiny-buildings.zip')

    model = RegressionModelConfig(backbone='resnet50')
    solver = SolverConfig(lr=1e-4, num_epochs=10, batch_sz=8, one_cycle=True)
    data = RegressionDataConfig(
        data_format='image_csv',
        uri=data_uri,
        img_sz=200,
        labels=['has_buildings'])
    learner = RegressionLearnerConfig(
        model=model, solver=solver, data=data, test_mode=test)

    pipeline = LearnerPipelineConfig(root_uri=root_uri, learner=learner)
    return pipeline
</source>
</class>

<class classid="3" nclones="2" nlines="33" similarity="76">
<source file="systems/raster-vision-0.12.0/rastervision_pytorch_learner/rastervision/pytorch_learner/classification_learner.py" startline="32" endline="71" pcid="138">
    def _get_datasets(self, uri):
        cfg = self.cfg
        class_names = cfg.data.class_names

        if cfg.data.data_format == ClassificationDataFormat.image_folder:
            data_dirs = self.unzip_data(uri)

        transform, aug_transform = self.get_data_transforms()

        train_ds, valid_ds, test_ds = [], [], []
        for data_dir in data_dirs:
            train_dir = join(data_dir, 'train')
            valid_dir = join(data_dir, 'valid')

            if isdir(train_dir):
                if cfg.overfit_mode:
                    train_ds.append(
                        AlbumentationsDataset(
                            ImageFolder(train_dir, classes=class_names),
                            transform=transform))
                else:
                    train_ds.append(
                        AlbumentationsDataset(
                            ImageFolder(train_dir, classes=class_names),
                            transform=aug_transform))

            if isdir(valid_dir):
                valid_ds.append(
                    AlbumentationsDataset(
                        ImageFolder(valid_dir, classes=class_names),
                        transform=transform))
                test_ds.append(
                    AlbumentationsDataset(
                        ImageFolder(valid_dir, classes=class_names),
                        transform=transform))

        train_ds, valid_ds, test_ds = \
            ConcatDataset(train_ds), ConcatDataset(valid_ds), ConcatDataset(test_ds)

        return train_ds, valid_ds, test_ds
</source>
<source file="systems/raster-vision-0.12.0/rastervision_pytorch_learner/rastervision/pytorch_learner/regression_learner.py" startline="86" endline="125" pcid="183">
    def _get_datasets(self, uri):
        cfg = self.cfg
        data_dirs = self.unzip_data(uri)
        transform, aug_transform = self.get_data_transforms()

        train_ds, valid_ds, test_ds = [], [], []
        for data_dir in data_dirs:
            train_dir = join(data_dir, 'train')
            valid_dir = join(data_dir, 'valid')

            if isdir(train_dir):
                if cfg.overfit_mode:
                    train_ds.append(
                        AlbumentationsDataset(
                            ImageRegressionDataset(train_dir,
                                                   cfg.data.class_names),
                            transform=transform))
                else:
                    train_ds.append(
                        AlbumentationsDataset(
                            ImageRegressionDataset(train_dir,
                                                   cfg.data.class_names),
                            transform=aug_transform))

            if isdir(valid_dir):
                valid_ds.append(
                    AlbumentationsDataset(
                        ImageRegressionDataset(valid_dir,
                                               cfg.data.class_names),
                        transform=transform))
                test_ds.append(
                    AlbumentationsDataset(
                        ImageRegressionDataset(valid_dir,
                                               cfg.data.class_names),
                        transform=transform))

        train_ds, valid_ds, test_ds = \
            ConcatDataset(train_ds), ConcatDataset(valid_ds), ConcatDataset(test_ds)

        return train_ds, valid_ds, test_ds
</source>
</class>

<class classid="4" nclones="2" nlines="15" similarity="93">
<source file="systems/raster-vision-0.12.0/tests/pytorch_learner/test_utils.py" startline="28" endline="44" pcid="206">
    def test1(self):
        label_names = ['a', 'b']
        conf_mat = torch.tensor([[2., 0], [0, 2]])
        metrics = compute_conf_mat_metrics(conf_mat, label_names)
        exp_metrics = {
            'avg_precision': 1.0,
            'avg_recall': 1.0,
            'avg_f1': 1.0,
            'a_precision': 1.0,
            'a_recall': 1.0,
            'a_f1': 1.0,
            'b_precision': 1.0,
            'b_recall': 1.0,
            'b_f1': 1.0
        }
        self.assertDictEqual(metrics, exp_metrics)

</source>
<source file="systems/raster-vision-0.12.0/tests/pytorch_learner/test_utils.py" startline="45" endline="61" pcid="207">
    def test2(self):
        label_names = ['a', 'b']
        conf_mat = torch.tensor([[0, 2.], [2, 0]])
        metrics = compute_conf_mat_metrics(conf_mat, label_names)
        exp_metrics = {
            'avg_precision': 0.0,
            'avg_recall': 0.0,
            'avg_f1': 0.0,
            'a_precision': 0.0,
            'a_recall': 0.0,
            'a_f1': 0.0,
            'b_precision': 0.0,
            'b_recall': 0.0,
            'b_f1': 0.0
        }
        self.assertDictEqual(metrics, exp_metrics)

</source>
</class>

<class classid="5" nclones="3" nlines="11" similarity="81">
<source file="systems/raster-vision-0.12.0/tests/pipeline/test_file_system.py" startline="136" endline="150" pcid="226">
    def setUp(self):
        # Setup mock S3 bucket.
        self.mock_s3 = mock_s3()
        self.mock_s3.start()
        self.s3 = boto3.client('s3')
        self.bucket_name = 'mock_bucket'
        self.s3.create_bucket(Bucket=self.bucket_name)

        self.content_str = 'hello'
        self.file_name = 'hello.txt'
        self.s3_path = 's3://{}/{}'.format(self.bucket_name, self.file_name)

        self.tmp_dir = rv_config.get_tmp_dir()
        self.local_path = os.path.join(self.tmp_dir.name, self.file_name)

</source>
<source file="systems/raster-vision-0.12.0/tests/pipeline/test_file_system.py" startline="459" endline="471" pcid="260">
    def setUp(self):
        # Setup mock S3 bucket.
        self.mock_s3 = mock_s3()
        self.mock_s3.start()
        self.s3 = boto3.client('s3')
        self.bucket_name = 'mock_bucket'
        self.s3.create_bucket(Bucket=self.bucket_name)

        self.content_str = 'hello'
        self.file_name = 'hello.txt'
        self.tmp_dir = rv_config.get_tmp_dir()
        self.cache_dir = os.path.join(self.tmp_dir.name, 'cache')

</source>
<source file="systems/raster-vision-0.12.0/tests/pipeline/test_file_system.py" startline="181" endline="195" pcid="230">
    def setUp(self):
        # Setup mock S3 bucket.
        self.mock_s3 = mock_s3()
        self.mock_s3.start()
        self.s3 = boto3.client('s3')
        self.bucket_name = 'mock_bucket'
        self.s3.create_bucket(Bucket=self.bucket_name)

        self.content_str = 'hello'
        self.file_name = 'hello.txt'
        self.s3_path = 's3://{}/{}'.format(self.bucket_name, self.file_name)

        self.tmp_dir = rv_config.get_tmp_dir()
        self.local_path = os.path.join(self.tmp_dir.name, self.file_name)

</source>
</class>

<class classid="6" nclones="3" nlines="10" similarity="70">
<source file="systems/raster-vision-0.12.0/tests/pipeline/test_file_system.py" startline="242" endline="255" pcid="236">
    def test_last_modified_s3(self):
        path = os.path.join(self.tmp_dir.name, 'lorem', 'ipsum1.txt')
        s3_path = 's3://{}/lorem1.txt'.format(self.bucket_name)
        directory = os.path.dirname(path)
        make_dir(directory, check_empty=False)

        fs = FileSystem.get_file_system(s3_path, 'r')

        str_to_file(self.lorem, path)
        upload_or_copy(path, s3_path)
        stamp = fs.last_modified(s3_path)

        self.assertTrue(isinstance(stamp, datetime.datetime))

</source>
<source file="systems/raster-vision-0.12.0/tests/pipeline/test_file_system.py" startline="256" endline="268" pcid="237">
    def test_list_paths_s3(self):
        path = os.path.join(self.tmp_dir.name, 'lorem', 'ipsum.txt')
        s3_path = 's3://{}/xxx/lorem.txt'.format(self.bucket_name)
        s3_directory = 's3://{}/xxx/'.format(self.bucket_name)
        directory = os.path.dirname(path)
        make_dir(directory, check_empty=False)

        str_to_file(self.lorem, path)
        upload_or_copy(path, s3_path)

        list_paths(s3_directory)
        self.assertEqual(len(list_paths(s3_directory)), 1)

</source>
<source file="systems/raster-vision-0.12.0/tests/pipeline/test_file_system.py" startline="350" endline="362" pcid="246">
    def test_copy_to_local(self):
        path1 = os.path.join(self.tmp_dir.name, 'lorem', 'ipsum.txt')
        path2 = os.path.join(self.tmp_dir.name, 'yyy', 'ipsum.txt')
        dir1 = os.path.dirname(path1)
        dir2 = os.path.dirname(path2)
        make_dir(dir1, check_empty=False)
        make_dir(dir2, check_empty=False)

        str_to_file(self.lorem, path1)

        upload_or_copy(path1, path2)
        self.assertEqual(len(list_paths(dir2)), 1)

</source>
</class>

<class classid="7" nclones="2" nlines="10" similarity="100">
<source file="systems/raster-vision-0.12.0/tests/pipeline/test_file_system.py" startline="313" endline="325" pcid="243">
    def test_sync_from_dir_local(self):
        path = os.path.join(self.tmp_dir.name, 'lorem', 'ipsum.txt')
        src = os.path.dirname(path)
        dst = os.path.join(self.tmp_dir.name, 'xxx')
        make_dir(src, check_empty=False)
        make_dir(dst, check_empty=False)

        fs = FileSystem.get_file_system(path, 'r')
        fs.write_bytes(path, bytes([0x00, 0x01]))
        sync_from_dir(src, dst, delete=True)

        self.assertEqual(len(list_paths(dst)), 1)

</source>
<source file="systems/raster-vision-0.12.0/tests/pipeline/test_file_system.py" startline="337" endline="349" pcid="245">
    def test_sync_to_dir_local(self):
        path = os.path.join(self.tmp_dir.name, 'lorem', 'ipsum.txt')
        src = os.path.dirname(path)
        dst = os.path.join(self.tmp_dir.name, 'xxx')
        make_dir(src, check_empty=False)
        make_dir(dst, check_empty=False)

        fs = FileSystem.get_file_system(path, 'r')
        fs.write_bytes(path, bytes([0x00, 0x01]))
        sync_to_dir(src, dst, delete=True)

        self.assertEqual(len(list_paths(dst)), 1)

</source>
</class>

<class classid="8" nclones="2" nlines="12" similarity="83">
<source file="systems/raster-vision-0.12.0/tests/core/data/label_source/test_semantic_segmentation_label_source.py" startline="11" endline="22" pcid="265">
    def test_enough_target_pixels_true(self):
        data = np.zeros((10, 10, 1), dtype=np.uint8)
        data[4:, 4:, :] = 1
        null_class_id = 2
        raster_source = MockRasterSource([0], 1)
        raster_source.set_raster(data)
        label_source = SemanticSegmentationLabelSource(raster_source,
                                                       null_class_id)
        with label_source.activate():
            extent = Box(0, 0, 10, 10)
            self.assertTrue(label_source.enough_target_pixels(extent, 30, [1]))

</source>
<source file="systems/raster-vision-0.12.0/tests/core/data/label_source/test_semantic_segmentation_label_source.py" startline="23" endline="35" pcid="266">
    def test_enough_target_pixels_false(self):
        data = np.zeros((10, 10, 1), dtype=np.uint8)
        data[7:, 7:, :] = 1
        null_class_id = 2
        raster_source = MockRasterSource([0], 1)
        raster_source.set_raster(data)
        label_source = SemanticSegmentationLabelSource(raster_source,
                                                       null_class_id)
        with label_source.activate():
            extent = Box(0, 0, 10, 10)
            self.assertFalse(
                label_source.enough_target_pixels(extent, 30, [1]))

</source>
</class>

<class classid="9" nclones="2" nlines="15" similarity="86">
<source file="systems/raster-vision-0.12.0/tests/core/data/label_source/test_semantic_segmentation_label_source.py" startline="36" endline="50" pcid="267">
    def test_get_labels(self):
        data = np.zeros((10, 10, 1), dtype=np.uint8)
        data[7:, 7:, 0] = 1
        null_class_id = 2
        raster_source = MockRasterSource([0], 1)
        raster_source.set_raster(data)
        label_source = SemanticSegmentationLabelSource(raster_source,
                                                       null_class_id)
        with label_source.activate():
            window = Box.make_square(7, 7, 3)
            labels = label_source.get_labels(window=window)
            label_arr = labels.get_label_arr(window)
            expected_label_arr = np.ones((3, 3))
            np.testing.assert_array_equal(label_arr, expected_label_arr)

</source>
<source file="systems/raster-vision-0.12.0/tests/core/data/label_source/test_semantic_segmentation_label_source.py" startline="51" endline="66" pcid="268">
    def test_get_labels_off_edge(self):
        data = np.zeros((10, 10, 1), dtype=np.uint8)
        data[7:, 7:, 0] = 1
        null_class_id = 2
        raster_source = MockRasterSource([0], 1)
        raster_source.set_raster(data)
        label_source = SemanticSegmentationLabelSource(raster_source,
                                                       null_class_id)
        with label_source.activate():
            window = Box.make_square(7, 7, 6)
            labels = label_source.get_labels(window=window)
            label_arr = labels.get_label_arr(window)
            expected_label_arr = np.full((6, 6), 2)
            expected_label_arr[0:3, 0:3] = 1
            np.testing.assert_array_equal(label_arr, expected_label_arr)

</source>
</class>

<class classid="10" nclones="8" nlines="10" similarity="90">
<source file="systems/raster-vision-0.12.0/tests/core/data/label_source/test_chip_classification_label_source.py" startline="75" endline="87" pcid="272">
    def test_infer_cell1(self):
        # More of box 1 is in cell.
        cell = Box.make_square(0, 0, 3)
        ioa_thresh = 0.5
        use_intersection_over_cell = False
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.class_id1)

</source>
<source file="systems/raster-vision-0.12.0/tests/core/data/label_source/test_chip_classification_label_source.py" startline="128" endline="141" pcid="276">
    def test_infer_cell5(self):
        # More of box1 in cell, using intersection_over_cell with the
        # IOA high enough.
        cell = Box.make_square(0, 0, 3)
        ioa_thresh = 0.4
        use_intersection_over_cell = True
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.class_id1)

</source>
<source file="systems/raster-vision-0.12.0/tests/core/data/label_source/test_chip_classification_label_source.py" startline="114" endline="127" pcid="275">
    def test_infer_cell4(self):
        # Both boxes inside cell, but using intersection_over_cell,
        # the IOA isn't high enough.
        cell = Box.make_square(0, 0, 10)
        ioa_thresh = 0.5
        use_intersection_over_cell = True
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, None)

</source>
<source file="systems/raster-vision-0.12.0/tests/core/data/label_source/test_chip_classification_label_source.py" startline="142" endline="154" pcid="277">
    def test_infer_cell6(self):
        # No boxes overlap enough, use background_class_id
        cell = Box.make_square(0, 0, 10)
        ioa_thresh = 0.5
        use_intersection_over_cell = True
        background_class_id = self.background_class_id
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.background_class_id)

</source>
<source file="systems/raster-vision-0.12.0/tests/core/data/label_source/test_chip_classification_label_source.py" startline="101" endline="113" pcid="274">
    def test_infer_cell3(self):
        # Only box 2 is in cell, but IOA isn't high enough.
        cell = Box.make_square(3, 3, 3)
        ioa_thresh = 0.5
        use_intersection_over_cell = False
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, None)

</source>
<source file="systems/raster-vision-0.12.0/tests/core/data/label_source/test_chip_classification_label_source.py" startline="88" endline="100" pcid="273">
    def test_infer_cell2(self):
        # More of box 2 is in cell.
        cell = Box.make_square(1, 1, 3)
        ioa_thresh = 0.5
        use_intersection_over_cell = False
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.class_id2)

</source>
<source file="systems/raster-vision-0.12.0/tests/core/data/label_source/test_chip_classification_label_source.py" startline="155" endline="167" pcid="278">
    def test_infer_cell7(self):
        # Cell doesn't overlap with any boxes.
        cell = Box.make_square(10, 10, 1)
        ioa_thresh = 0.5
        use_intersection_over_cell = True
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, None)

</source>
<source file="systems/raster-vision-0.12.0/tests/core/data/label_source/test_chip_classification_label_source.py" startline="168" endline="181" pcid="279">
    def test_infer_cell8(self):
        # box2 overlaps more than box1, but using pick_min_class_id, so
        # picks box1.
        cell = Box.make_square(1, 1, 3)
        ioa_thresh = 0.5
        use_intersection_over_cell = False
        background_class_id = None
        pick_min_class_id = True

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.class_id2)

</source>
</class>

<class classid="11" nclones="2" nlines="14" similarity="92">
<source file="systems/raster-vision-0.12.0/tests/core/data/label_source/test_chip_classification_label_source.py" startline="209" endline="226" pcid="281">
    def test_get_labels_small_extent(self):
        # Extent only has enough of first box in it.
        extent = Box.make_square(0, 0, 2)

        config = ChipClassificationLabelSourceConfig(
            vector_source=GeoJSONVectorSourceConfig(
                uri=self.uri, default_class_id=None))
        source = config.build(self.class_config, self.crs_transformer, extent,
                              self.tmp_dir.name)
        labels = source.get_labels()

        cells = labels.get_cells()
        self.assertEqual(len(cells), 1)
        class_id = labels.get_cell_class_id(self.box1)
        self.assertEqual(class_id, self.class_id1)
        class_id = labels.get_cell_class_id(self.box2)
        self.assertEqual(class_id, None)

</source>
<source file="systems/raster-vision-0.12.0/tests/core/data/label_source/test_chip_classification_label_source.py" startline="227" endline="245" pcid="282">
    def test_get_labels(self):
        # Extent contains both boxes.
        extent = Box.make_square(0, 0, 8)

        config = ChipClassificationLabelSourceConfig(
            vector_source=GeoJSONVectorSourceConfig(
                uri=self.uri, default_class_id=None))
        source = config.build(self.class_config, self.crs_transformer, extent,
                              self.tmp_dir.name)
        labels = source.get_labels()

        cells = labels.get_cells()
        self.assertEqual(len(cells), 2)
        class_id = labels.get_cell_class_id(self.box1)
        self.assertEqual(class_id, self.class_id1)
        class_id = labels.get_cell_class_id(self.box2)
        self.assertEqual(class_id, self.class_id2)


</source>
</class>

<class classid="12" nclones="2" nlines="24" similarity="91">
<source file="systems/raster-vision-0.12.0/tests/core/data/raster_source/test_rasterio_source.py" startline="25" endline="51" pcid="293">
    def test_nodata_val(self):
        # make geotiff filled with ones and zeros with nodata == 1
        img_path = join(self.tmp_dir, 'tmp.tif')
        height = 100
        width = 100
        nb_channels = 3
        with rasterio.open(
                img_path,
                'w',
                driver='GTiff',
                height=height,
                width=width,
                count=nb_channels,
                dtype=np.uint8,
                nodata=1) as img_dataset:
            im = np.random.randint(0, 2, (height, width, nb_channels)).astype(
                np.uint8)
            for channel in range(nb_channels):
                img_dataset.write(im[:, :, channel], channel + 1)

        config = RasterioSourceConfig(uris=[img_path])
        source = config.build(tmp_dir=self.tmp_dir)
        with source.activate():
            out_chip = source.get_image_array()
            expected_out_chip = np.zeros((height, width, nb_channels))
            np.testing.assert_equal(out_chip, expected_out_chip)

</source>
<source file="systems/raster-vision-0.12.0/tests/core/data/raster_source/test_rasterio_source.py" startline="52" endline="78" pcid="294">
    def test_mask(self):
        # make geotiff filled with ones and zeros and mask the whole image
        img_path = join(self.tmp_dir, 'tmp.tif')
        height = 100
        width = 100
        nb_channels = 3
        with rasterio.open(
                img_path,
                'w',
                driver='GTiff',
                height=height,
                width=width,
                count=nb_channels,
                dtype=np.uint8) as img_dataset:
            im = np.random.randint(0, 2, (height, width, nb_channels)).astype(
                np.uint8)
            for channel in range(nb_channels):
                img_dataset.write(im[:, :, channel], channel + 1)
            img_dataset.write_mask(np.zeros(im.shape[0:2]).astype(np.bool))

        config = RasterioSourceConfig(uris=[img_path])
        source = config.build(tmp_dir=self.tmp_dir)
        with source.activate():
            out_chip = source.get_image_array()
            expected_out_chip = np.zeros((height, width, nb_channels))
            np.testing.assert_equal(out_chip, expected_out_chip)

</source>
</class>

<class classid="13" nclones="2" nlines="15" similarity="93">
<source file="systems/raster-vision-0.12.0/tests/core/data/raster_source/test_rasterio_source.py" startline="96" endline="115" pcid="297">
    def test_shift_x(self):
        # Specially-engineered image w/ one meter per pixel resolution
        # in the x direction.
        img_path = data_file_path('ones.tif')
        channel_order = [0]

        config = RasterioSourceConfig(
            uris=[img_path],
            channel_order=channel_order,
            x_shift=1.0,
            y_shift=0.0)
        source = config.build(tmp_dir=self.tmp_dir)

        with source.activate():
            extent = source.get_extent()
            data = source.get_chip(extent)
            self.assertEqual(data.sum(), 2**16 - 256)
            column = data[:, 255, 0]
            self.assertEqual(column.sum(), 0)

</source>
<source file="systems/raster-vision-0.12.0/tests/core/data/raster_source/test_rasterio_source.py" startline="116" endline="135" pcid="298">
    def test_shift_y(self):
        # Specially-engineered image w/ one meter per pixel resolution
        # in the y direction.
        img_path = data_file_path('ones.tif')
        channel_order = [0]

        config = RasterioSourceConfig(
            uris=[img_path],
            channel_order=channel_order,
            x_shift=0.0,
            y_shift=1.0)
        source = config.build(tmp_dir=self.tmp_dir)

        with source.activate():
            extent = source.get_extent()
            data = source.get_chip(extent)
            self.assertEqual(data.sum(), 2**16 - 256)
            row = data[0, :, 0]
            self.assertEqual(row.sum(), 0)

</source>
</class>

<class classid="14" nclones="2" nlines="12" similarity="91">
<source file="systems/raster-vision-0.12.0/tests/core/data/vector_source/test_geojson_vector_source.py" startline="124" endline="139" pcid="335">
    def test_transform_geojson_line_buf(self):
        geom = {'type': 'LineString', 'coordinates': [[10, 10], [10, 20]]}
        geojson = self.geom_to_geojson(geom)

        trans_geojson = self.transform_geojson(geojson, line_bufs={0: 5.0})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).buffer(5.0).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(geojson, line_bufs={1: 5.0})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).buffer(1.0).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(geojson, line_bufs={0: None})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).equals(shape(trans_geom)))

</source>
<source file="systems/raster-vision-0.12.0/tests/core/data/vector_source/test_geojson_vector_source.py" startline="140" endline="155" pcid="336">
    def test_transform_point_buf(self):
        geom = {'type': 'Point', 'coordinates': [10, 10]}
        geojson = self.geom_to_geojson(geom)

        trans_geojson = self.transform_geojson(geojson, point_bufs={0: 5.0})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).buffer(5.0).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(geojson, point_bufs={1: 5.0})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).buffer(1.0).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(geojson, point_bufs={0: None})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).equals(shape(trans_geom)))

</source>
</class>

<class classid="15" nclones="2" nlines="10" similarity="90">
<source file="systems/raster-vision-0.12.0/tests/core/evaluation/test_class_evaluation_item.py" startline="20" endline="30" pcid="401">
    def test_merge_first_empty(self):
        a = ClassEvaluationItem()
        b = ClassEvaluationItem(
            precision=1, recall=1, f1=1, count_error=0, gt_count=1)
        a.merge(b)
        self.assertEqual(a.precision, 1)
        self.assertEqual(a.recall, 1)
        self.assertEqual(a.f1, 1)
        self.assertEqual(a.count_error, 0)
        self.assertEqual(a.gt_count, 1)

</source>
<source file="systems/raster-vision-0.12.0/tests/core/evaluation/test_class_evaluation_item.py" startline="31" endline="41" pcid="402">
    def test_merge_second_empty(self):
        a = ClassEvaluationItem(
            precision=1, recall=1, f1=1, count_error=0, gt_count=1)
        b = ClassEvaluationItem()
        a.merge(b)
        self.assertEqual(a.precision, 1)
        self.assertEqual(a.recall, 1)
        self.assertEqual(a.f1, 1)
        self.assertEqual(a.count_error, 0)
        self.assertEqual(a.gt_count, 1)

</source>
</class>

<class classid="16" nclones="3" nlines="21" similarity="76">
<source file="systems/raster-vision-0.12.0/tests/core/evaluation/test_object_detection_evaluation.py" startline="36" endline="60" pcid="408">
    def test_compute(self):
        class_config = self.make_class_config()
        eval = ObjectDetectionEvaluation(class_config)
        gt_labels = self.make_ground_truth_labels()
        pred_labels = self.make_predicted_labels()

        eval.compute(gt_labels, pred_labels)
        eval_item1 = eval.class_to_eval_item[0]
        self.assertEqual(eval_item1.gt_count, 2)
        self.assertEqual(eval_item1.precision, 1.0)
        self.assertEqual(eval_item1.recall, 1.0)
        self.assertEqual(eval_item1.f1, 1.0)

        eval_item2 = eval.class_to_eval_item[1]
        self.assertEqual(eval_item2.gt_count, 2)
        self.assertEqual(eval_item2.precision, 1.0)
        self.assertEqual(eval_item2.recall, 0.5)
        self.assertEqual(eval_item2.f1, 2 / 3)

        avg_item = eval.avg_item
        self.assertEqual(avg_item.gt_count, 4)
        self.assertAlmostEqual(avg_item.precision, 1.0)
        self.assertEqual(avg_item.recall, 0.75)
        self.assertAlmostEqual(avg_item.f1, 0.83, places=2)

</source>
<source file="systems/raster-vision-0.12.0/tests/core/evaluation/test_object_detection_evaluation.py" startline="61" endline="85" pcid="409">
    def test_compute_no_preds(self):
        class_config = self.make_class_config()
        eval = ObjectDetectionEvaluation(class_config)
        gt_labels = self.make_ground_truth_labels()
        pred_labels = ObjectDetectionLabels.make_empty()

        eval.compute(gt_labels, pred_labels)
        eval_item1 = eval.class_to_eval_item[0]
        self.assertEqual(eval_item1.gt_count, 2)
        self.assertEqual(eval_item1.precision, None)
        self.assertEqual(eval_item1.recall, 0.0)
        self.assertEqual(eval_item1.f1, None)

        eval_item2 = eval.class_to_eval_item[1]
        self.assertEqual(eval_item2.gt_count, 2)
        self.assertEqual(eval_item2.precision, None)
        self.assertEqual(eval_item2.recall, 0.0)
        self.assertEqual(eval_item2.f1, None)

        avg_item = eval.avg_item
        self.assertEqual(avg_item.gt_count, 4)
        self.assertEqual(avg_item.precision, 0.0)
        self.assertEqual(avg_item.recall, 0.0)
        self.assertEqual(avg_item.f1, 0.0)

</source>
<source file="systems/raster-vision-0.12.0/tests/core/evaluation/test_object_detection_evaluation.py" startline="86" endline="111" pcid="410">
    def test_compute_no_ground_truth(self):
        class_config = self.make_class_config()
        eval = ObjectDetectionEvaluation(class_config)
        gt_labels = ObjectDetectionLabels.make_empty()
        pred_labels = self.make_predicted_labels()

        eval.compute(gt_labels, pred_labels)
        eval_item1 = eval.class_to_eval_item[0]
        self.assertEqual(eval_item1.gt_count, 0)
        self.assertEqual(eval_item1.precision, None)
        self.assertEqual(eval_item1.recall, None)
        self.assertEqual(eval_item1.f1, None)

        eval_item2 = eval.class_to_eval_item[1]
        self.assertEqual(eval_item2.gt_count, 0)
        self.assertEqual(eval_item2.precision, None)
        self.assertEqual(eval_item2.recall, None)
        self.assertEqual(eval_item2.f1, None)

        avg_item = eval.avg_item
        self.assertEqual(avg_item.gt_count, 0)
        self.assertEqual(avg_item.precision, None)
        self.assertEqual(avg_item.recall, None)
        self.assertEqual(avg_item.f1, None)


</source>
</class>

<class classid="17" nclones="2" nlines="11" similarity="90">
<source file="systems/raster-vision-0.12.0/tests/core/evaluation/test_semantic_segmentation_evaluator.py" startline="100" endline="116" pcid="416">
    def test_vector_evaluator(self):
        output_uri = join(self.tmp_dir.name, 'raster-out.json')
        vector_output_uri = join(self.tmp_dir.name, 'vector-out.json')
        scenes = [self.get_vector_scene(0), self.get_vector_scene(1)]
        evaluator = SemanticSegmentationEvaluator(
            self.class_config, output_uri, vector_output_uri)
        evaluator.process(scenes, self.tmp_dir.name)
        vector_eval_json = file_to_json(vector_output_uri)
        exp_vector_eval_json = file_to_json(
            data_file_path('expected-vector-eval.json'))

        # NOTE:  The precision  and recall  values found  in the  file
        # `expected-vector-eval.json`  are equal to fractions of  the
        # form (n-1)/n for  n <= 7 which  can be seen to  be (and have
        # been manually verified to be) correct.
        self.assertDictEqual(vector_eval_json, exp_vector_eval_json)

</source>
<source file="systems/raster-vision-0.12.0/tests/core/evaluation/test_semantic_segmentation_evaluator.py" startline="117" endline="134" pcid="417">
    def test_vector_evaluator_with_aoi(self):
        output_uri = join(self.tmp_dir.name, 'raster-out.json')
        vector_output_uri = join(self.tmp_dir.name, 'vector-out.json')
        scenes = [self.get_vector_scene(0, use_aoi=True)]
        evaluator = SemanticSegmentationEvaluator(
            self.class_config, output_uri, vector_output_uri)
        evaluator.process(scenes, self.tmp_dir.name)
        vector_eval_json = file_to_json(vector_output_uri)
        exp_vector_eval_json = file_to_json(
            data_file_path('expected-vector-eval-with-aoi.json'))

        # NOTE:  The precision  and recall  values found  in the  file
        # `expected-vector-eval.json`  are equal to fractions of  the
        # form (n-1)/n for  n <= 7 which  can be seen to  be (and have
        # been manually verified to be) correct.
        self.assertDictEqual(vector_eval_json, exp_vector_eval_json)


</source>
</class>

<class classid="18" nclones="2" nlines="11" similarity="81">
<source file="systems/raster-vision-0.12.0/rastervision_core/rastervision/core/data/label_store/chip_classification_geojson_store.py" startline="26" endline="42" pcid="645">
    def save(self, labels):
        """Save labels to URI if writable.

        Note that if the grid is inferred from polygons, only the grid will be
        written, not the original polygons.
        """
        boxes = labels.get_cells()
        class_ids = labels.get_class_ids()
        scores = list(labels.get_scores())
        geojson = boxes_to_geojson(
            boxes,
            class_ids,
            self.crs_transformer,
            self.class_config,
            scores=scores)
        json_to_file(geojson, self.uri)

</source>
<source file="systems/raster-vision-0.12.0/rastervision_core/rastervision/core/data/label_store/object_detection_geojson_store.py" startline="25" endline="37" pcid="656">
    def save(self, labels):
        """Save labels to URI."""
        boxes = labels.get_boxes()
        class_ids = labels.get_class_ids().tolist()
        scores = labels.get_scores().tolist()
        geojson = boxes_to_geojson(
            boxes,
            class_ids,
            self.crs_transformer,
            self.class_config,
            scores=scores)
        json_to_file(geojson, self.uri)

</source>
</class>

<class classid="19" nclones="2" nlines="65" similarity="86">
<source file="systems/raster-vision-0.12.0/integration_tests/semantic_segmentation/config.py" startline="15" endline="90" pcid="796">
def get_config(runner, root_uri, data_uri=None, full_train=False):
    def get_path(part):
        if full_train:
            return join(data_uri, part)
        else:
            return join(dirname(__file__), part)

    class_config = ClassConfig(names=['red', 'green'], colors=['red', 'green'])

    def make_scene(id, img_path, label_path):
        raster_source = RasterioSourceConfig(
            channel_order=[0, 1, 2], uris=[img_path])
        label_source = SemanticSegmentationLabelSourceConfig(
            rgb_class_config=class_config,
            raster_source=RasterioSourceConfig(uris=[label_path]))
        label_store = SemanticSegmentationLabelStoreConfig(
            rgb=True,
            vector_output=[
                PolygonVectorOutputConfig(class_id=0),
                BuildingVectorOutputConfig(class_id=1)
            ])

        return SceneConfig(
            id=id,
            raster_source=raster_source,
            label_source=label_source,
            label_store=label_store)

    if full_train:
        model = SemanticSegmentationModelConfig(backbone=Backbone.resnet50)
        solver = SolverConfig(
            lr=1e-4,
            num_epochs=300,
            batch_sz=8,
            one_cycle=True,
            sync_interval=300)
    else:
        pretrained_uri = (
            'https://github.com/azavea/raster-vision-data/releases/download/v0.12/'
            'semantic-segmentation.pth')
        model = SemanticSegmentationModelConfig(
            backbone=Backbone.resnet50, init_weights=pretrained_uri)
        solver = SolverConfig(
            lr=1e-9,
            num_epochs=1,
            batch_sz=2,
            one_cycle=True,
            sync_interval=200)
    backend = PyTorchSemanticSegmentationConfig(
        model=model,
        solver=solver,
        log_tensorboard=False,
        run_tensorboard=False,
        augmentors=[])

    scenes = [
        make_scene('test-scene', get_path('scene/image.tif'),
                   get_path('scene/labels.tif')),
        make_scene('test-scene2', get_path('scene/image2.tif'),
                   get_path('scene/labels2.tif'))
    ]
    dataset = DatasetConfig(
        class_config=class_config,
        train_scenes=scenes,
        validation_scenes=scenes)

    chip_options = SemanticSegmentationChipOptions(
        window_method=SemanticSegmentationWindowMethod.sliding, stride=300)

    return SemanticSegmentationConfig(
        root_uri=root_uri,
        dataset=dataset,
        backend=backend,
        train_chip_sz=300,
        predict_chip_sz=300,
        chip_options=chip_options)
</source>
<source file="systems/raster-vision-0.12.0/integration_tests/object_detection/config.py" startline="14" endline="84" pcid="814">
def get_config(runner, root_uri, data_uri=None, full_train=False):
    def get_path(part):
        if full_train:
            return join(data_uri, part)
        else:
            return join(dirname(__file__), part)

    class_config = ClassConfig(
        names=['car', 'building'], colors=['blue', 'red'])

    def make_scene(scene_id, img_path, label_path):
        raster_source = RasterioSourceConfig(
            channel_order=[0, 1, 2], uris=[img_path])
        label_source = ObjectDetectionLabelSourceConfig(
            vector_source=GeoJSONVectorSourceConfig(
                uri=label_path, default_class_id=None))
        return SceneConfig(
            id=scene_id,
            raster_source=raster_source,
            label_source=label_source)

    if full_train:
        model = ObjectDetectionModelConfig(backbone=Backbone.resnet18)
        solver = SolverConfig(
            lr=1e-4,
            num_epochs=300,
            batch_sz=8,
            one_cycle=True,
            sync_interval=300)
    else:
        pretrained_uri = (
            'https://github.com/azavea/raster-vision-data/releases/download/v0.12/'
            'object-detection.pth')
        model = ObjectDetectionModelConfig(
            backbone=Backbone.resnet18, init_weights=pretrained_uri)
        solver = SolverConfig(
            lr=1e-9,
            num_epochs=1,
            batch_sz=2,
            one_cycle=True,
            sync_interval=200)
    backend = PyTorchObjectDetectionConfig(
        model=model,
        solver=solver,
        log_tensorboard=False,
        run_tensorboard=False,
        augmentors=[])

    scenes = [
        make_scene('od_test', get_path('scene/image.tif'),
                   get_path('scene/labels.json')),
        make_scene('od_test-2', get_path('scene/image2.tif'),
                   get_path('scene/labels2.json'))
    ]
    dataset = DatasetConfig(
        class_config=class_config,
        train_scenes=scenes,
        validation_scenes=scenes)

    chip_options = ObjectDetectionChipOptions(neg_ratio=1.0, ioa_thresh=1.0)
    predict_options = ObjectDetectionPredictOptions(
        merge_thresh=0.1, score_thresh=0.5)

    return ObjectDetectionConfig(
        root_uri=root_uri,
        dataset=dataset,
        backend=backend,
        train_chip_sz=300,
        predict_chip_sz=300,
        chip_options=chip_options,
        predict_options=predict_options)
</source>
</class>

</clones>
