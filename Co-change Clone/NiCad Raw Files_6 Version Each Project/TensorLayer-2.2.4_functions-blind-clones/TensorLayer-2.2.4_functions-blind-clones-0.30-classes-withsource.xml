<clones>
<systeminfo processor="nicad6" system="TensorLayer-2.2.4" granularity="functions-blind" threshold="30%" minlines="10" maxlines="2500"/>
<cloneinfo npcs="1842" npairs="625"/>
<runinfo ncompares="97114" cputime="80198"/>
<classinfo nclasses="72"/>

<class classid="1" nclones="4" nlines="11" similarity="75">
<source file="systems/TensorLayer-2.2.4/tests/files/test_utils_saveload.py" startline="18" endline="32" pcid="1">
def basic_static_model():
    ni = Input((None, 24, 24, 3))
    nn = Conv2d(16, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, name="conv1")(ni)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool1')(nn)

    nn = Conv2d(16, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, name="conv2")(nn)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool2')(nn)

    nn = Flatten(name='flatten')(nn)
    nn = Dense(100, act=None, name="dense1")(nn)
    nn = Dense(10, act=None, name="dense2")(nn)
    M = Model(inputs=ni, outputs=nn, name='basic_static')
    return M


</source>
<source file="systems/TensorLayer-2.2.4/tests/models/test_model_save.py" startline="17" endline="32" pcid="56">
def basic_static_model(include_top=True):
    ni = Input((None, 24, 24, 3))
    nn = Conv2d(16, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, name="conv1")(ni)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool1')(nn)

    nn = Conv2d(16, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, name="conv2")(nn)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool2')(nn)

    nn = Flatten(name='flatten')(nn)
    nn = Dense(100, act=None, name="dense1")(nn)
    if include_top is True:
        nn = Dense(10, act=None, name="dense2")(nn)
    M = Model(inputs=ni, outputs=nn)
    return M


</source>
<source file="systems/TensorLayer-2.2.4/tests/models/test_model_save_graph.py" startline="23" endline="36" pcid="73">
def basic_static_model():
    ni = Input((None, 24, 24, 3))
    nn = Conv2d(16, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, name="conv1")(ni)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool1')(nn)

    nn = Conv2d(16, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, name="conv2")(nn)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool2')(nn)

    nn = Flatten(name='flatten')(nn)
    nn = Dense(100, act=None, name="dense1")(nn)
    M = Model(inputs=ni, outputs=nn)
    return M


</source>
<source file="systems/TensorLayer-2.2.4/tests/models/test_model_core.py" startline="17" endline="31" pcid="33">
def basic_static_model():
    ni = Input((None, 24, 24, 3))
    nn = Conv2d(16, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, name="conv1")(ni)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool1')(nn)

    nn = Conv2d(16, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, name="conv2")(nn)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool2')(nn)

    nn = Flatten(name='flatten')(nn)
    nn = Dense(100, act=None, name="dense1")(nn)
    nn = Dense(10, act=None, name="dense2")(nn)
    M = Model(inputs=ni, outputs=nn)
    return M


</source>
</class>

<class classid="2" nclones="2" nlines="15" similarity="75">
<source file="systems/TensorLayer-2.2.4/tests/files/test_utils_saveload.py" startline="69" endline="88" pcid="6">
    def test_hdf5(self):
        modify_val = np.zeros_like(self.static_model.all_weights[-2].numpy())
        ori_val = self.static_model.all_weights[-2].numpy()
        tl.files.save_weights_to_hdf5("./model_basic.h5", self.static_model)

        self.static_model.all_weights[-2].assign(modify_val)
        tl.files.load_hdf5_to_weights_in_order("./model_basic.h5", self.static_model)
        self.assertLess(np.max(np.abs(ori_val - self.static_model.all_weights[-2].numpy())), 1e-7)

        self.static_model.all_weights[-2].assign(modify_val)
        tl.files.load_hdf5_to_weights("./model_basic.h5", self.static_model)
        self.assertLess(np.max(np.abs(ori_val - self.static_model.all_weights[-2].numpy())), 1e-7)

        ori_weights = self.static_model._all_weights
        self.static_model._all_weights = self.static_model._all_weights[1:]
        self.static_model.all_weights[-2].assign(modify_val)
        tl.files.load_hdf5_to_weights("./model_basic.h5", self.static_model, skip=True)
        self.assertLess(np.max(np.abs(ori_val - self.static_model.all_weights[-2].numpy())), 1e-7)
        self.static_model._all_weights = ori_weights

</source>
<source file="systems/TensorLayer-2.2.4/tests/files/test_utils_saveload.py" startline="98" endline="114" pcid="8">
    def test_npz_dict(self):
        modify_val = np.zeros_like(self.dynamic_model.all_weights[-2].numpy())
        ori_val = self.dynamic_model.all_weights[-2].numpy()
        tl.files.save_npz_dict(self.dynamic_model.all_weights, "./model_basic.npz")

        self.dynamic_model.all_weights[-2].assign(modify_val)
        tl.files.load_and_assign_npz_dict("./model_basic.npz", self.dynamic_model)
        self.assertLess(np.max(np.abs(ori_val - self.dynamic_model.all_weights[-2].numpy())), 1e-7)

        ori_weights = self.dynamic_model._all_weights
        self.dynamic_model._all_weights = self.static_model._all_weights[1:]
        self.dynamic_model.all_weights[-2].assign(modify_val)
        tl.files.load_and_assign_npz_dict("./model_basic.npz", self.dynamic_model, skip=True)
        self.assertLess(np.max(np.abs(ori_val - self.dynamic_model.all_weights[-2].numpy())), 1e-7)
        self.dynamic_model._all_weights = ori_weights


</source>
</class>

<class classid="3" nclones="2" nlines="32" similarity="70">
<source file="systems/TensorLayer-2.2.4/tests/models/test_seq2seq_model.py" startline="47" endline="95" pcid="11">
    def test_basic_simpleSeq2Seq(self):
        model_ = Seq2seq(
            decoder_seq_length=5,
            cell_enc=tf.keras.layers.GRUCell,
            cell_dec=tf.keras.layers.GRUCell,
            n_layer=3,
            n_units=128,
            embedding_layer=tl.layers.Embedding(vocabulary_size=self.vocab_size, embedding_size=self.embedding_size),
        )

        optimizer = tf.optimizers.Adam(learning_rate=0.001)

        for epoch in range(self.num_epochs):
            model_.train()
            trainX, trainY = shuffle(self.trainX, self.trainY)
            total_loss, n_iter = 0, 0
            for X, Y in tqdm(tl.iterate.minibatches(inputs=trainX, targets=trainY, batch_size=self.batch_size,
                                                    shuffle=False), total=self.n_step,
                             desc='Epoch[{}/{}]'.format(epoch + 1, self.num_epochs), leave=False):

                dec_seq = Y[:, :-1]
                target_seq = Y[:, 1:]

                with tf.GradientTape() as tape:
                    ## compute outputs
                    output = model_(inputs=[X, dec_seq])

                    output = tf.reshape(output, [-1, self.vocab_size])

                    loss = cross_entropy_seq(logits=output, target_seqs=target_seq)

                    grad = tape.gradient(loss, model_.all_weights)
                    optimizer.apply_gradients(zip(grad, model_.all_weights))

                total_loss += loss
                n_iter += 1

            model_.eval()
            test_sample = trainX[0:2, :].tolist()

            top_n = 1
            for i in range(top_n):
                prediction = model_([test_sample], seq_length=self.dec_seq_length, start_token=0, top_n=1)
                print("Prediction: >>>>>  ", prediction, "\n Target: >>>>>  ", trainY[0:2, 1:], "\n\n")

            # printing average loss after every epoch
            print('Epoch [{}/{}]: loss {:.4f}'.format(epoch + 1, self.num_epochs, total_loss / n_iter))


</source>
<source file="systems/TensorLayer-2.2.4/tests/models/test_seq2seq_with_attention.py" startline="59" endline="101" pcid="55">
    def test_basic_simpleSeq2Seq(self):

        model_ = Seq2seqLuongAttention(
            hidden_size=128, cell=tf.keras.layers.SimpleRNNCell,
            embedding_layer=tl.layers.Embedding(vocabulary_size=self.vocab_size,
                                                embedding_size=self.embedding_size), method='dot'
        )
        optimizer = tf.optimizers.Adam(learning_rate=0.001)

        for epoch in range(self.num_epochs):
            model_.train()
            trainX, trainY = shuffle(self.trainX, self.trainY)
            total_loss, n_iter = 0, 0
            for X, Y in tqdm(tl.iterate.minibatches(inputs=trainX, targets=trainY, batch_size=self.batch_size,
                                                    shuffle=False), total=self.n_step,
                             desc='Epoch[{}/{}]'.format(epoch + 1, self.num_epochs), leave=False):
                dec_seq = Y[:, :-1]
                target_seq = Y[:, 1:]

                with tf.GradientTape() as tape:
                    ## compute outputs
                    output = model_(inputs=[X, dec_seq])
                    # print(output)
                    output = tf.reshape(output, [-1, self.vocab_size])

                    loss = cross_entropy_seq(logits=output, target_seqs=target_seq)
                    grad = tape.gradient(loss, model_.trainable_weights)
                    optimizer.apply_gradients(zip(grad, model_.trainable_weights))

                total_loss += loss
                n_iter += 1

            model_.eval()
            test_sample = self.testX[:5, :].tolist()  # Can't capture the sequence.
            top_n = 1
            for i in range(top_n):
                prediction = model_([test_sample], seq_length=self.dec_seq_length, sos=0)
                print("Prediction: >>>>>  ", prediction, "\n Target: >>>>>  ", self.testY[:5, 1:], "\n\n")

            # printing average loss after every epoch
            print('Epoch [{}/{}]: loss {:.4f}'.format(epoch + 1, self.num_epochs, total_loss / n_iter))


</source>
</class>

<class classid="4" nclones="2" nlines="48" similarity="83">
<source file="systems/TensorLayer-2.2.4/tests/models/test_model_core.py" startline="67" endline="135" pcid="38">
    def test_dynamic_basic(self):
        print('-' * 20, 'test_dynamic_basic', '-' * 20)
        model_basic = basic_dynamic_model()

        # test empty model before calling
        self.assertEqual(model_basic.is_train, None)
        self.assertEqual(model_basic._all_weights, None)
        self.assertEqual(model_basic._inputs, None)
        self.assertEqual(model_basic._outputs, None)
        self.assertEqual(model_basic._model_layer, None)
        self.assertEqual(model_basic._all_layers, None)
        self.assertEqual(model_basic._nodes_fixed, False)

        # test layer and weights access
        all_layers = model_basic.all_layers
        self.assertEqual(len(model_basic.all_layers), 7)
        self.assertEqual(model_basic._all_weights, None)

        self.assertIsNotNone(model_basic.all_weights)
        print([w.name for w in model_basic.all_weights])

        # test model mode
        model_basic.train()
        self.assertEqual(model_basic.is_train, True)
        model_basic.eval()
        self.assertEqual(model_basic.is_train, False)
        model_basic.test()
        self.assertEqual(model_basic.is_train, False)
        model_basic.infer()
        self.assertEqual(model_basic.is_train, False)

        # test as_layer
        try:
            model_basic.as_layer()
        except Exception as e:
            print(e)
        self.assertIsNone(model_basic._model_layer)

        # test print
        try:
            print(model_basic)
        except Exception as e:
            print(e)

        # test forwarding
        inputs = np.random.normal(size=[2, 24, 24, 3]).astype(np.float32)
        outputs1 = model_basic(inputs)
        self.assertEqual(model_basic._nodes_fixed, True)
        self.assertEqual(model_basic.is_train, False)

        try:
            outputs2 = model_basic(inputs, is_train=True)
        except Exception as e:
            print(e)
        outputs2 = model_basic(inputs, is_train=False)
        self.assertEqual(model_basic.is_train, False)

        self.assertLess(np.max(np.abs(outputs1.numpy() - outputs2.numpy())), 1e-7)

        # test layer node
        self.assertEqual(len(model_basic.all_layers[-1]._nodes), 0)
        self.assertEqual(model_basic.all_layers[-2]._nodes_fixed, True)

        # test release_memory
        try:
            model_basic.release_memory()
        except Exception as e:
            print(e)

</source>
<source file="systems/TensorLayer-2.2.4/tests/models/test_model_core.py" startline="136" endline="201" pcid="39">
    def test_static_basic(self):
        print('-' * 20, 'test_static_basic', '-' * 20)
        model_basic = basic_static_model()

        # test empty model before calling
        self.assertEqual(model_basic.is_train, None)
        self.assertEqual(model_basic._all_weights, None)
        self.assertIsNotNone(model_basic._inputs)
        self.assertIsNotNone(model_basic._outputs)
        self.assertEqual(model_basic._model_layer, None)
        self.assertIsNotNone(model_basic._all_layers)
        self.assertIsNotNone(model_basic._nodes_fixed)

        # test layer and weights access
        all_layers = model_basic.all_layers
        self.assertEqual(len(model_basic.all_layers), 8)
        self.assertEqual(model_basic._all_weights, None)

        self.assertIsNotNone(model_basic.all_weights)
        print([w.name for w in model_basic.all_weights])

        # test model mode
        model_basic.train()
        self.assertEqual(model_basic.is_train, True)
        model_basic.eval()
        self.assertEqual(model_basic.is_train, False)
        model_basic.test()
        self.assertEqual(model_basic.is_train, False)
        model_basic.infer()
        self.assertEqual(model_basic.is_train, False)

        # test as_layer
        self.assertIsInstance(model_basic.as_layer(), tl.layers.Layer)
        self.assertIsNotNone(model_basic._model_layer)

        # test print
        try:
            print(model_basic)
        except Exception as e:
            print(e)

        # test forwarding
        inputs = np.random.normal(size=[2, 24, 24, 3]).astype(np.float32)
        outputs1 = model_basic(inputs)
        self.assertEqual(model_basic._nodes_fixed, True)
        self.assertEqual(model_basic.is_train, False)

        try:
            outputs2 = model_basic(inputs, is_train=True)
        except Exception as e:
            print(e)
        outputs2 = model_basic(inputs, is_train=False)
        self.assertEqual(model_basic.is_train, False)

        self.assertLess(np.max(np.abs(outputs1.numpy() - outputs2.numpy())), 1e-7)

        # test layer node
        self.assertEqual(len(model_basic.all_layers[-1]._nodes), 1)
        self.assertEqual(model_basic.all_layers[-2]._nodes_fixed, True)

        # test release_memory
        try:
            model_basic.release_memory()
        except Exception as e:
            print(e)

</source>
</class>

<class classid="5" nclones="2" nlines="10" similarity="70">
<source file="systems/TensorLayer-2.2.4/tests/models/test_model_save.py" startline="49" endline="60" pcid="58">
    def forward(self, x):
        x = self.conv1(x)
        x = self.pool1(x)
        x = self.conv2(x)
        x = self.pool2(x)
        x = self.flatten(x)
        x = self.dense1(x)
        if self.include_top:
            x = self.dense2(x)
        return x


</source>
<source file="systems/TensorLayer-2.2.4/examples/basic_tutorials/tutorial_mnist_mlp_dynamic.py" startline="29" endline="40" pcid="667">
    def forward(self, x, foo=None):
        z = self.dropout1(x)
        z = self.dense1(z)
        z = self.dropout2(z)
        z = self.dense2(z)
        z = self.dropout3(z)
        out = self.dense3(z)
        if foo is not None:
            out = tf.nn.relu(out)
        return out


</source>
</class>

<class classid="6" nclones="2" nlines="10" similarity="100">
<source file="systems/TensorLayer-2.2.4/tests/models/test_model_save_graph.py" startline="160" endline="172" pcid="81">
def create_base_network(input_shape):
    '''Base network to be shared (eq. to feature extraction).
    '''
    input = Input(shape=input_shape)
    x = Flatten()(input)
    x = Dense(128, act=tf.nn.relu)(x)
    x = Dropout(0.9)(x)
    x = Dense(128, act=tf.nn.relu)(x)
    x = Dropout(0.9)(x)
    x = Dense(128, act=tf.nn.relu)(x)
    return Model(input, x)


</source>
<source file="systems/TensorLayer-2.2.4/examples/basic_tutorials/tutorial_mnist_siamese.py" startline="41" endline="53" pcid="662">
def create_base_network(input_shape):
    '''Base network to be shared (eq. to feature extraction).
    '''
    input = Input(shape=input_shape)
    x = Flatten()(input)
    x = Dense(128, act=tf.nn.relu)(x)
    x = Dropout(0.9)(x)
    x = Dense(128, act=tf.nn.relu)(x)
    x = Dropout(0.9)(x)
    x = Dense(128, act=tf.nn.relu)(x)
    return Model(input, x)


</source>
</class>

<class classid="7" nclones="2" nlines="19" similarity="80">
<source file="systems/TensorLayer-2.2.4/tests/models/test_model_save_graph.py" startline="257" endline="276" pcid="90">
    def test_lambda_layer_no_para_no_args(self):
        x = tl.layers.Input([8, 3], name='input')
        y = tl.layers.Lambda(lambda x: 2 * x, name='lambda')(x)
        M1 = tl.models.Model(x, y)
        M1.save("lambda_no_para_no_args.hdf5")
        M2 = tl.models.Model.load("lambda_no_para_no_args.hdf5")
        print(M1)
        print(M2)
        M1.eval()
        M2.eval()
        npInput = np.zeros((8, 3)) + 3
        output1 = M1(npInput).numpy()
        output2 = M1(npInput).numpy()

        M1_config = RemoveDateInConfig(M1.config)
        M2_config = RemoveDateInConfig(M2.config)

        self.assertEqual((output1 == output2).all(), True)
        self.assertEqual(M1_config, M2_config)

</source>
<source file="systems/TensorLayer-2.2.4/tests/models/test_model_save_graph.py" startline="277" endline="301" pcid="91">
    def test_lambda_layer_no_para_with_args(self):

        def customize_func(x, foo=42):  # x is the inputs, foo is an argument
            return foo * x

        x = tl.layers.Input([8, 3], name='input')
        y = tl.layers.Lambda(customize_func, fn_args={'foo': 3}, name='lambda')(x)
        M1 = tl.models.Model(x, y)
        M1.save("lambda_no_para_with_args.hdf5")
        M2 = tl.models.Model.load("lambda_no_para_with_args.hdf5")
        print(M1)
        print(M2)
        M1.eval()
        M2.eval()
        npInput = np.zeros((8, 3)) + 3
        output1 = M1(npInput).numpy()
        output2 = M2(npInput).numpy()

        M1_config = RemoveDateInConfig(M1.config)
        M2_config = RemoveDateInConfig(M2.config)

        self.assertEqual((output1 == output2).all(), True)
        self.assertEqual((output1 == (np.zeros((8, 3)) + 9)).all(), True)
        self.assertEqual(M1_config, M2_config)

</source>
</class>

<class classid="8" nclones="2" nlines="26" similarity="82">
<source file="systems/TensorLayer-2.2.4/tests/models/test_model_save_graph.py" startline="302" endline="338" pcid="93">
    def test_lambda_layer_keras_model(self):
        input_shape = [100, 5]
        in_2 = tl.layers.Input(input_shape, name='input')
        layers = [
            tf.keras.layers.Dense(10, activation=tf.nn.relu),
            tf.keras.layers.Dense(5, activation=tf.nn.sigmoid),
            tf.keras.layers.Dense(1, activation=tf.nn.relu)
        ]
        perceptron = tf.keras.Sequential(layers)
        # in order to compile keras model and get trainable_variables of the keras model
        _ = perceptron(np.random.random(input_shape).astype(np.float32))
        plambdalayer = tl.layers.Lambda(perceptron, perceptron.trainable_variables)(in_2)
        M2 = tl.models.Model(inputs=in_2, outputs=plambdalayer)

        M2.save('M2_keras.hdf5')
        M4 = Model.load('M2_keras.hdf5')

        M2.eval()
        M4.eval()
        npInput = np.zeros(input_shape) + 3
        output2 = M2(npInput).numpy()
        output4 = M4(npInput).numpy()

        M2_config = RemoveDateInConfig(M2.config)
        M4_config = RemoveDateInConfig(M4.config)

        self.assertEqual((output2 == output4).all(), True)
        self.assertEqual(M2_config, M4_config)

        ori_weights = M4.all_weights
        ori_val = ori_weights[1].numpy()
        modify_val = np.zeros_like(ori_val) + 10
        M4.all_weights[1].assign(modify_val)
        M4 = Model.load('M2_keras.hdf5')

        self.assertLess(np.max(np.abs(ori_val - M4.all_weights[1].numpy())), 1e-7)

</source>
<source file="systems/TensorLayer-2.2.4/tests/models/test_model_save_graph.py" startline="339" endline="371" pcid="94">
    def test_lambda_layer_keras_layer(self):
        input_shape = [100, 5]
        in_1 = tl.layers.Input(input_shape, name='input')
        denselayer = tf.keras.layers.Dense(10, activation=tf.nn.relu)
        # in order to compile keras model and get trainable_variables of the keras model
        _ = denselayer(np.random.random(input_shape).astype(np.float32))
        dlambdalayer = tl.layers.Lambda(denselayer, denselayer.trainable_variables)(in_1)
        M1 = tl.models.Model(inputs=in_1, outputs=dlambdalayer)

        M1.save('M1_keras.hdf5')
        M3 = Model.load('M1_keras.hdf5')

        M1.eval()
        M3.eval()
        npInput = np.zeros(input_shape) + 3
        output1 = M1(npInput).numpy()
        output3 = M3(npInput).numpy()

        M1_config = RemoveDateInConfig(M1.config)
        M3_config = RemoveDateInConfig(M3.config)

        self.assertEqual((output1 == output3).all(), True)
        self.assertEqual(M1_config, M3_config)

        ori_weights = M3.all_weights
        ori_val = ori_weights[1].numpy()
        modify_val = np.zeros_like(ori_val) + 10
        M3.all_weights[1].assign(modify_val)
        M3 = Model.load('M1_keras.hdf5')

        self.assertLess(np.max(np.abs(ori_val - M3.all_weights[1].numpy())), 1e-7)


</source>
</class>

<class classid="9" nclones="3" nlines="19" similarity="75">
<source file="systems/TensorLayer-2.2.4/tests/models/test_model_save_graph.py" startline="378" endline="402" pcid="96">
    def test_elementwise_no_para_with_args(self):
        # z = mean + noise * tf.exp(std * 0.5) + foo
        def func(noise, mean, std, foo=42):
            return mean + noise * tf.exp(std * 0.5) + foo

        noise = tl.layers.Input([100, 1])
        mean = tl.layers.Input([100, 1])
        std = tl.layers.Input([100, 1])
        out = tl.layers.ElementwiseLambda(fn=func, fn_args={'foo': 84}, name='elementwiselambda')([noise, mean, std])
        M1 = Model(inputs=[noise, mean, std], outputs=out)
        M1.save("elementwise_npwa.hdf5")
        M2 = Model.load("elementwise_npwa.hdf5")

        M1.eval()
        M2.eval()
        ipt = [np.zeros((100, 1)) + 11, np.zeros((100, 1)) + 21, np.zeros((100, 1)) + 31]
        output1 = M1(ipt).numpy()
        output2 = M2(ipt).numpy()

        M1_config = RemoveDateInConfig(M1.config)
        M2_config = RemoveDateInConfig(M2.config)

        self.assertEqual((output1 == output2).all(), True)
        self.assertEqual(M1_config, M2_config)

</source>
<source file="systems/TensorLayer-2.2.4/tests/models/test_model_save_graph.py" startline="428" endline="481" pcid="100">
    def test_elementwise_lambda_func(self):
        # z = mean + noise * tf.exp(std * 0.5)
        noise = tl.layers.Input([100, 1])
        mean = tl.layers.Input([100, 1])
        std = tl.layers.Input([100, 1])
        out = tl.layers.ElementwiseLambda(fn=lambda x, y, z: x + y * tf.exp(z * 0.5),
                                          name='elementwiselambda')([noise, mean, std])
        M1 = Model(inputs=[noise, mean, std], outputs=out)
        M1.save("elementwise_lambda.hdf5")
        M2 = Model.load("elementwise_lambda.hdf5")

        M1.eval()
        M2.eval()
        ipt = [
            (np.zeros((100, 1)) + 11).astype(np.float32), (np.zeros((100, 1)) + 21).astype(np.float32),
            (np.zeros((100, 1)) + 31).astype(np.float32)
        ]
        output1 = M1(ipt).numpy()
        output2 = M2(ipt).numpy()

        M1_config = RemoveDateInConfig(M1.config)
        M2_config = RemoveDateInConfig(M2.config)

        self.assertEqual((output1 == output2).all(), True)
        self.assertEqual(M1_config, M2_config)

    # # ElementwiseLambda does not support keras layer/model func yet
    # def test_elementwise_keras_model(self):
    #     kerasinput1 = tf.keras.layers.Input(shape=(100, ))
    #     kerasinput2 = tf.keras.layers.Input(shape=(100, ))
    #     kerasconcate = tf.keras.layers.concatenate(inputs=[kerasinput1, kerasinput2])
    #     kerasmodel = tf.keras.models.Model(inputs=[kerasinput1, kerasinput2], outputs=kerasconcate)
    #     _ = kerasmodel([np.random.random([100,]).astype(np.float32), np.random.random([100,]).astype(np.float32)])
    #
    #     input1 = tl.layers.Input([100, 1])
    #     input2 = tl.layers.Input([100, 1])
    #     out = tl.layers.ElementwiseLambda(fn=kerasmodel, name='elementwiselambda')([input1, input2])
    #     M1 = Model(inputs=[input1, input2], outputs=out)
    #     M1.save("elementwise_keras_model.hdf5")
    #     M2 = Model.load("elementwise_keras_model.hdf5")
    #
    #     M1.eval()
    #     M2.eval()
    #     ipt = [np.zeros((100, 1)) + 11, np.zeros((100, 1)) + 21, np.zeros((100, 1)) + 31]
    #     output1 = M1(ipt).numpy()
    #     output2 = M2(ipt).numpy()
    #
    #     M1_config = RemoveDateInConfig(M1.config)
    #     M2_config = RemoveDateInConfig(M2.config)
    #
    #     self.assertEqual((output1 == output2).all(), True)
    #     self.assertEqual(M1_config, M2_config)


</source>
<source file="systems/TensorLayer-2.2.4/tests/models/test_model_save_graph.py" startline="403" endline="427" pcid="98">
    def test_elementwise_no_para_no_args(self):
        # z = mean + noise * tf.exp(std * 0.5) + foo
        def func(noise, mean, std, foo=42):
            return mean + noise * tf.exp(std * 0.5) + foo

        noise = tl.layers.Input([100, 1])
        mean = tl.layers.Input([100, 1])
        std = tl.layers.Input([100, 1])
        out = tl.layers.ElementwiseLambda(fn=func, name='elementwiselambda')([noise, mean, std])
        M1 = Model(inputs=[noise, mean, std], outputs=out)
        M1.save("elementwise_npna.hdf5")
        M2 = Model.load("elementwise_npna.hdf5")

        M1.eval()
        M2.eval()
        ipt = [np.zeros((100, 1)) + 11, np.zeros((100, 1)) + 21, np.zeros((100, 1)) + 31]
        output1 = M1(ipt).numpy()
        output2 = M2(ipt).numpy()

        M1_config = RemoveDateInConfig(M1.config)
        M2_config = RemoveDateInConfig(M2.config)

        self.assertEqual((output1 == output2).all(), True)
        self.assertEqual(M1_config, M2_config)

</source>
</class>

<class classid="10" nclones="5" nlines="29" similarity="70">
<source file="systems/TensorLayer-2.2.4/tests/utils/custom_layers/inception_blocks.py" startline="19" endline="69" pcid="133">
def block_inception_a(inputs, scope=None, is_train=False):
    """Builds Inception-A block for Inception v4 network."""
    # By default use stride=1 and SAME padding

    with tf.variable_scope(name_or_scope=scope, default_name='BlockInceptionA', values=[inputs]):
        with tf.variable_scope('Branch_0'):
            branch_0, _ = conv_module(
                inputs, n_out_channel=96, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

        with tf.variable_scope('Branch_1'):
            branch_1, _ = conv_module(
                inputs, n_out_channel=64, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_1, _ = conv_module(
                branch_1, n_out_channel=96, filter_size=(3, 3), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_3x3'
            )

        with tf.variable_scope('Branch_2'):
            branch_2, _ = conv_module(
                inputs, n_out_channel=64, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_2, _ = conv_module(
                branch_2, n_out_channel=96, filter_size=(3, 3), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_3x3'
            )

            branch_2, _ = conv_module(
                branch_2, n_out_channel=96, filter_size=(3, 3), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0c_3x3'
            )

        with tf.variable_scope('Branch_3'):
            branch_3 = tl.layers.MeanPool2d(
                inputs, filter_size=(3, 3), strides=(1, 1), padding='SAME', name='AvgPool_0a_3x3'
            )

            branch_3, _ = conv_module(
                branch_3, n_out_channel=96, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_1x1'
            )

        return tl.layers.ConcatLayer([branch_0, branch_1, branch_2, branch_3], concat_dim=3, name='concat_layer')


</source>
<source file="systems/TensorLayer-2.2.4/tests/utils/custom_layers/inception_blocks.py" startline="169" endline="211" pcid="136">
def block_reduction_b(inputs, scope=None, is_train=False):
    """Builds Reduction-B block for Inception v4 network."""
    # By default use stride=1 and SAME padding

    with tf.variable_scope(scope, 'BlockReductionB', [inputs]):
        with tf.variable_scope('Branch_0'):
            branch_0, _ = conv_module(
                inputs, n_out_channel=192, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_0, _ = conv_module(
                branch_0, n_out_channel=192, filter_size=(3, 3), strides=(2, 2), padding='VALID', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_1a_3x3'
            )

        with tf.variable_scope('Branch_1'):
            branch_1, _ = conv_module(
                inputs, n_out_channel=256, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_1, _ = conv_module(
                branch_1, n_out_channel=256, filter_size=(1, 7), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_1x7'
            )

            branch_1, _ = conv_module(
                branch_1, n_out_channel=320, filter_size=(7, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0c_7x1'
            )

            branch_1, _ = conv_module(
                branch_1, n_out_channel=320, filter_size=(3, 3), strides=(2, 2), padding='VALID', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_1a_3x3'
            )

        with tf.variable_scope('Branch_2'):
            branch_2 = tl.layers.MaxPool2d(inputs, (3, 3), strides=(2, 2), padding='VALID', name='MaxPool_1a_3x3')

        return tl.layers.ConcatLayer([branch_0, branch_1, branch_2], concat_dim=3, name='concat_layer')


</source>
<source file="systems/TensorLayer-2.2.4/tests/utils/custom_layers/inception_blocks.py" startline="212" endline="279" pcid="137">
def block_inception_c(inputs, scope=None, is_train=False):
    """Builds Inception-C block for Inception v4 network."""
    # By default use stride=1 and SAME padding

    with tf.variable_scope(scope, 'BlockInceptionC', [inputs]):
        with tf.variable_scope('Branch_0'):
            branch_0, _ = conv_module(
                inputs, n_out_channel=256, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

        with tf.variable_scope('Branch_1'):
            branch_1, _ = conv_module(
                inputs, n_out_channel=384, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_1a, _ = conv_module(
                branch_1, n_out_channel=256, filter_size=(1, 3), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_1x3'
            )

            branch_1b, _ = conv_module(
                branch_1, n_out_channel=256, filter_size=(3, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0c_3x1'
            )

            branch_1 = tl.layers.ConcatLayer([branch_1a, branch_1b], concat_dim=3, name='concat_layer')

        with tf.variable_scope('Branch_2'):
            branch_2, _ = conv_module(
                inputs, n_out_channel=384, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_2, _ = conv_module(
                branch_2, n_out_channel=448, filter_size=(3, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_3x1'
            )

            branch_2, _ = conv_module(
                branch_2, n_out_channel=512, filter_size=(1, 3), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0c_1x3'
            )

            branch_2a, _ = conv_module(
                branch_2, n_out_channel=256, filter_size=(1, 3), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0d_1x3'
            )

            branch_2b, _ = conv_module(
                branch_2, n_out_channel=256, filter_size=(3, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0e_3x1'
            )

            branch_2 = tl.layers.ConcatLayer([branch_2a, branch_2b], concat_dim=3, name='concat_layer')

        with tf.variable_scope('Branch_3'):
            branch_3 = tl.layers.MeanPool2d(
                inputs, filter_size=(3, 3), strides=(1, 1), padding='SAME', name='AvgPool_0a_3x3'
            )

            branch_3, _ = conv_module(
                branch_3, n_out_channel=256, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_1x1'
            )

        return tl.layers.ConcatLayer([branch_0, branch_1, branch_2, branch_3], concat_dim=3, name='concat_layer')
</source>
<source file="systems/TensorLayer-2.2.4/tests/utils/custom_layers/inception_blocks.py" startline="103" endline="168" pcid="135">
def block_inception_b(inputs, scope=None, is_train=False):
    """Builds Inception-B block for Inception v4 network."""
    # By default use stride=1 and SAME padding

    with tf.variable_scope(scope, 'BlockInceptionB', [inputs]):
        with tf.variable_scope('Branch_0'):
            branch_0, _ = conv_module(
                inputs, n_out_channel=384, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

        with tf.variable_scope('Branch_1'):
            branch_1, _ = conv_module(
                inputs, n_out_channel=192, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_1, _ = conv_module(
                branch_1, n_out_channel=224, filter_size=(1, 7), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_1x7'
            )

            branch_1, _ = conv_module(
                branch_1, n_out_channel=256, filter_size=(7, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0c_7x1'
            )

        with tf.variable_scope('Branch_2'):
            branch_2, _ = conv_module(
                inputs, n_out_channel=192, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_2, _ = conv_module(
                branch_2, n_out_channel=192, filter_size=(7, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_7x1'
            )

            branch_2, _ = conv_module(
                branch_2, n_out_channel=224, filter_size=(1, 7), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0c_1x7'
            )

            branch_2, _ = conv_module(
                branch_2, n_out_channel=224, filter_size=(7, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0d_7x1'
            )

            branch_2, _ = conv_module(
                branch_2, n_out_channel=256, filter_size=(1, 7), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0e_1x7'
            )

        with tf.variable_scope('Branch_3'):
            branch_3 = tl.layers.MeanPool2d(
                inputs, filter_size=(3, 3), strides=(1, 1), padding='SAME', name='AvgPool_0a_3x3'
            )

            branch_3, _ = conv_module(
                branch_3, n_out_channel=128, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_1x1'
            )

        return tl.layers.ConcatLayer([branch_0, branch_1, branch_2, branch_3], concat_dim=3, name='concat_layer')


</source>
<source file="systems/TensorLayer-2.2.4/tests/utils/custom_layers/inception_blocks.py" startline="70" endline="102" pcid="134">
def block_reduction_a(inputs, scope=None, is_train=False):
    """Builds Reduction-A block for Inception v4 network."""
    # By default use stride=1 and SAME padding

    with tf.variable_scope(scope, 'BlockReductionA', [inputs]):
        with tf.variable_scope('Branch_0'):
            branch_0, _ = conv_module(
                inputs, n_out_channel=384, filter_size=(3, 3), strides=(2, 2), padding='VALID', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_1a_3x3'
            )

        with tf.variable_scope('Branch_1'):
            branch_1, _ = conv_module(
                inputs, n_out_channel=192, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_1, _ = conv_module(
                branch_1, n_out_channel=224, filter_size=(3, 3), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_3x3'
            )

            branch_1, _ = conv_module(
                branch_1, n_out_channel=256, filter_size=(3, 3), strides=(2, 2), padding='VALID', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_1a_3x3'
            )

        with tf.variable_scope('Branch_2'):
            branch_2 = tl.layers.MaxPool2d(inputs, (3, 3), strides=(2, 2), padding='VALID', name='MaxPool_1a_3x3')

        return tl.layers.ConcatLayer([branch_0, branch_1, branch_2], concat_dim=3, name='concat_layer')


</source>
</class>

<class classid="11" nclones="2" nlines="10" similarity="100">
<source file="systems/TensorLayer-2.2.4/tests/pending/test_documentation.py" startline="24" endline="35" pcid="167">
    def test_html_documentation(self):
        app = Sphinx(
            self.source_dir,
            self.config_dir,
            self.output_dir,
            self.doctree_dir,
            buildername='html',
            warningiserror=True,
        )
        app.build(force_all=self.all_files)
        # TODO: additional checks here if needed

</source>
<source file="systems/TensorLayer-2.2.4/tests/pending/test_documentation.py" startline="36" endline="48" pcid="168">
    def test_text_documentation(self):
        # The same, but with different buildername
        app = Sphinx(
            self.source_dir,
            self.config_dir,
            self.output_dir,
            self.doctree_dir,
            buildername='text',
            warningiserror=False,
        )
        app.build(force_all=self.all_files)
        # TODO:  additional checks if needed

</source>
</class>

<class classid="12" nclones="4" nlines="12" similarity="75">
<source file="systems/TensorLayer-2.2.4/tests/pending/test_logging_hyperdash.py" startline="35" endline="57" pcid="275">
    def test_monitor(self):

        with self.assertNotRaises(Exception):

            hd.HyperDashHandler.set_apikey(self.apikey)

            @hd.monitor("TRAVIS 1 - dogs vs. cats")
            def train_dogs_vs_cats(exp=None):

                # Record the value of hyperparameter gamma for this experiment
                lr = exp.param("learning rate", 0.005)
                tl.logging.debug("Learning Rate: %f" % lr)

                for epoch, accuracy in enumerate([10, 30, 50, 70, 80, 90, 95, 100]):
                    tl.logging.debug("Epoch %d - Accuracy %d%%" % (epoch + 1, accuracy))

                    # Record a numerical performance metric
                    exp.metric(name="accuracy", value=accuracy)

                    time.sleep(0.1)

            train_dogs_vs_cats()

</source>
<source file="systems/TensorLayer-2.2.4/tests/pending/test_logging_hyperdash.py" startline="107" endline="133" pcid="281">
    def test_Experiment_variant(self):

        with self.assertNotRaises(Exception):

            def train_dogs_vs_cats():

                # Create an experiment with a model name, then autostart
                exp = hd.Experiment("TRAVIS 4 - dogs vs. cats", api_key=self.apikey)

                # Record the value of hyperparameter gamma for this experiment
                lr = exp.param("learning rate", 0.005)
                tl.logging.debug("Learning Rate: %f" % lr)

                for epoch, accuracy in enumerate([10, 30, 50, 70, 80, 90, 95, 100]):
                    tl.logging.debug("Epoch %d - Accuracy %d%%" % (epoch + 1, accuracy))

                    # Record a numerical performance metric
                    exp.metric(name="accuracy", value=accuracy)

                    time.sleep(0.1)

                # Cleanup and mark that the experiment successfully completed
                exp.end()

            train_dogs_vs_cats()


</source>
<source file="systems/TensorLayer-2.2.4/tests/pending/test_logging_hyperdash.py" startline="58" endline="78" pcid="277">
    def test_monitor_variant(self):

        with self.assertNotRaises(Exception):

            @hd.monitor("TRAVIS 2 - dogs vs. cats", api_key=self.apikey)
            def train_dogs_vs_cats(exp=None):

                # Record the value of hyperparameter gamma for this experiment
                lr = exp.param("learning rate", 0.005)
                tl.logging.debug("Learning Rate: %f" % lr)

                for epoch, accuracy in enumerate([10, 30, 50, 70, 80, 90, 95, 100]):
                    tl.logging.debug("Epoch %d - Accuracy %d%%" % (epoch + 1, accuracy))

                    # Record a numerical performance metric
                    exp.metric(name="accuracy", value=accuracy)

                    time.sleep(0.1)

            train_dogs_vs_cats()

</source>
<source file="systems/TensorLayer-2.2.4/tests/pending/test_logging_hyperdash.py" startline="79" endline="106" pcid="279">
    def test_Experiment(self):

        hd.HyperDashHandler.set_apikey(self.apikey)

        with self.assertNotRaises(Exception):

            def train_dogs_vs_cats():

                # Create an experiment with a model name, then autostart
                exp = hd.Experiment("TRAVIS 3 - dogs vs. cats")

                # Record the value of hyperparameter gamma for this experiment
                lr = exp.param("learning rate", 0.005)
                tl.logging.debug("Learning Rate: %f" % lr)

                for epoch, accuracy in enumerate([10, 30, 50, 70, 80, 90, 95, 100]):
                    tl.logging.debug("Epoch %d - Accuracy %d%%" % (epoch + 1, accuracy))

                    # Record a numerical performance metric
                    exp.metric(name="accuracy", value=accuracy)

                    time.sleep(0.1)

                # Cleanup and mark that the experiment successfully completed
                exp.end()

            train_dogs_vs_cats()

</source>
</class>

<class classid="13" nclones="2" nlines="11" similarity="72">
<source file="systems/TensorLayer-2.2.4/tests/test_activations.py" startline="28" endline="43" pcid="314">
    def test_lrelu(self):
        for i in range(-5, 15):

            if i > 0:
                good_output = i
            else:
                good_output = self.alpha * i

            computed_output = tl.act.leaky_relu(float(i), alpha=self.alpha)

            self.assertAlmostEqual(computed_output.numpy(), good_output, places=5)

        net = tl.layers.Input([10, 2])
        net = tl.layers.Dense(n_units=100, act=lambda x: tl.act.lrelu(x, 0.2), name='dense')(net)
        print(net)

</source>
<source file="systems/TensorLayer-2.2.4/tests/test_activations.py" startline="44" endline="59" pcid="315">
    def test_lrelu6(self):
        for i in range(-5, 15):

            if i < 0:
                good_output = self.alpha * i
            else:
                good_output = min(6, i)

            computed_output = tl.act.leaky_relu6(float(i), alpha=self.alpha)

            self.assertAlmostEqual(computed_output.numpy(), good_output, places=5)

        net = tl.layers.Input([10, 2])
        net = tl.layers.Dense(n_units=100, act=lambda x: tl.act.leaky_relu6(x, 0.2), name='dense')(net)
        print(net)

</source>
</class>

<class classid="14" nclones="2" nlines="15" similarity="100">
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layernode.py" startline="198" endline="223" pcid="335">
        def get_model(inputs_shape):
            ni = Input(inputs_shape)

            ## 1. Localisation network
            # use MLP as the localisation net
            nn = Flatten()(ni)
            nn = Dense(n_units=20, act=tf.nn.tanh)(nn)
            nn = Dropout(keep=0.8)(nn)
            # you can also use CNN instead for MLP as the localisation net

            ## 2. Spatial transformer module (sampler)
            stn = SpatialTransformer2dAffine(out_size=(40, 40), in_channels=20)
            # s = stn((nn, ni))
            nn = stn((nn, ni))
            s = nn

            ## 3. Classifier
            nn = Conv2d(16, (3, 3), (2, 2), act=tf.nn.relu, padding='SAME')(nn)
            nn = Conv2d(16, (3, 3), (2, 2), act=tf.nn.relu, padding='SAME')(nn)
            nn = Flatten()(nn)
            nn = Dense(n_units=1024, act=tf.nn.relu)(nn)
            nn = Dense(n_units=10, act=tf.identity)(nn)

            M = Model(inputs=ni, outputs=[nn, s])
            return M

</source>
<source file="systems/TensorLayer-2.2.4/examples/spatial_transformer_network/tutorial_spatial_transformer_network_static.py" startline="56" endline="81" pcid="624">
##================== DEFINE MODEL ============================================##
def get_model(inputs_shape):
    ni = Input(inputs_shape)

    ## 1. Localisation network
    # use MLP as the localisation net
    nn = Flatten()(ni)
    nn = Dense(n_units=20, act=tf.nn.tanh)(nn)
    nn = Dropout(keep=0.8)(nn)
    # you can also use CNN instead for MLP as the localisation net

    ## 2. Spatial transformer module (sampler)
    stn = SpatialTransformer2dAffine(out_size=(40, 40), in_channels=20)
    nn = stn((nn, ni))
    s = nn

    ## 3. Classifier
    nn = Conv2d(16, (3, 3), (2, 2), act=tf.nn.relu, padding='SAME')(nn)
    nn = Conv2d(16, (3, 3), (2, 2), act=tf.nn.relu, padding='SAME')(nn)
    nn = Flatten()(nn)
    nn = Dense(n_units=1024, act=tf.nn.relu)(nn)
    nn = Dense(n_units=10, act=tf.identity)(nn)

    M = Model(inputs=ni, outputs=[nn, s])
    return M

</source>
</class>

<class classid="15" nclones="2" nlines="13" similarity="84">
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_stack.py" startline="19" endline="35" pcid="412">
    def setUpClass(cls):
        print("-" * 20, "Layer_Stack_Test", "-" * 20)
        cls.batch_size = 4
        cls.inputs_shape = [cls.batch_size, 10]

        cls.ni = Input(cls.inputs_shape, name='input_layer')
        a = Dense(n_units=5)(cls.ni)
        b = Dense(n_units=5)(cls.ni)
        cls.layer1 = Stack(axis=1)
        cls.n1 = cls.layer1([a, b])
        cls.M = Model(inputs=cls.ni, outputs=cls.n1)

        cls.inputs = tf.random.uniform(cls.inputs_shape)
        cls.n2 = cls.M(cls.inputs, is_train=True)

        print(cls.layer1)

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_stack.py" startline="50" endline="65" pcid="416">
    def setUpClass(cls):
        print("-" * 20, "Layer_UnStack_Test", "-" * 20)
        cls.batch_size = 4
        cls.inputs_shape = [cls.batch_size, 10]

        cls.ni = Input(cls.inputs_shape, name='input_layer')
        a = Dense(n_units=5)(cls.ni)
        cls.layer1 = UnStack(axis=1)  # unstack in channel axis
        cls.n1 = cls.layer1(a)
        cls.M = Model(inputs=cls.ni, outputs=cls.n1)

        cls.inputs = tf.random.uniform(cls.inputs_shape)
        cls.n2 = cls.M(cls.inputs, is_train=True)

        print(cls.layer1)

</source>
</class>

<class classid="16" nclones="2" nlines="19" similarity="75">
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_merge.py" startline="26" endline="49" pcid="422">
    def test_concat(self):

        class CustomModel(tl.models.Model):

            def __init__(self):
                super(CustomModel, self).__init__()
                self.dense1 = tl.layers.Dense(in_channels=20, n_units=10, act=tf.nn.relu, name='relu1_1')
                self.dense2 = tl.layers.Dense(in_channels=20, n_units=10, act=tf.nn.relu, name='relu2_1')
                self.concat = tl.layers.Concat(concat_dim=1, name='concat_layer')

            def forward(self, inputs):
                d1 = self.dense1(inputs)
                d2 = self.dense2(inputs)
                outputs = self.concat([d1, d2])
                return outputs

        model = CustomModel()
        model.train()
        inputs = tf.convert_to_tensor(np.random.random([4, 20]).astype(np.float32))
        outputs = model(inputs)
        print(model)

        self.assertEqual(outputs.get_shape().as_list(), [4, 20])

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_merge.py" startline="50" endline="76" pcid="425">
    def test_elementwise(self):

        class CustomModel(tl.models.Model):

            def __init__(self):
                super(CustomModel, self).__init__()
                self.dense1 = tl.layers.Dense(in_channels=20, n_units=10, act=tf.nn.relu, name='relu1_1')
                self.dense2 = tl.layers.Dense(in_channels=20, n_units=10, act=tf.nn.relu, name='relu2_1')
                self.element = tl.layers.Elementwise(combine_fn=tf.minimum, name='minimum', act=tf.identity)

            def forward(self, inputs):
                d1 = self.dense1(inputs)
                d2 = self.dense2(inputs)
                outputs = self.element([d1, d2])
                return outputs, d1, d2

        model = CustomModel()
        model.train()
        inputs = tf.convert_to_tensor(np.random.random([4, 20]).astype(np.float32))
        outputs, d1, d2 = model(inputs)
        print(model)

        min = tf.minimum(d1, d2)
        self.assertEqual(outputs.get_shape().as_list(), [4, 10])
        self.assertTrue(np.array_equal(min.numpy(), outputs.numpy()))


</source>
</class>

<class classid="17" nclones="2" nlines="36" similarity="97">
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_core_nested.py" startline="26" endline="71" pcid="434">
    def test_nested_layer_with_inchannels(cls):

        class MyLayer(tl.layers.Layer):

            def __init__(self, name=None):
                super(MyLayer, self).__init__(name=name)
                self.input_layer = tl.layers.Dense(in_channels=50, n_units=20)
                self.build(None)
                self._built = True

            def build(self, inputs_shape=None):
                self.W = self._get_weights('weights', shape=(20, 10))

            def forward(self, inputs):
                inputs = self.input_layer(inputs)
                output = tf.matmul(inputs, self.W)
                return output

        class model(tl.models.Model):

            def __init__(self, name=None):
                super(model, self).__init__(name=name)
                self.layer = MyLayer()

            def forward(self, inputs):
                return self.layer(inputs)

        input = tf.random.normal(shape=(100, 50))
        model_dynamic = model()
        model_dynamic.train()
        cls.assertEqual(model_dynamic(input).shape, (100, 10))
        cls.assertEqual(len(model_dynamic.all_weights), 3)
        cls.assertEqual(len(model_dynamic.trainable_weights), 3)
        model_dynamic.layer.input_layer.b.assign_add(tf.ones((20, )))
        cls.assertEqual(np.sum(model_dynamic.all_weights[-1].numpy() - tf.ones(20, ).numpy()), 0)

        ni = tl.layers.Input(shape=(100, 50))
        nn = MyLayer(name='mylayer1')(ni)
        model_static = tl.models.Model(inputs=ni, outputs=nn)
        model_static.eval()
        cls.assertEqual(model_static(input).shape, (100, 10))
        cls.assertEqual(len(model_static.all_weights), 3)
        cls.assertEqual(len(model_static.trainable_weights), 3)
        model_static.get_layer('mylayer1').input_layer.b.assign_add(tf.ones((20, )))
        cls.assertEqual(np.sum(model_static.all_weights[-1].numpy() - tf.ones(20, ).numpy()), 0)

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_core_nested.py" startline="72" endline="118" pcid="440">
    def test_nested_layer_without_inchannels(cls):

        class MyLayer(tl.layers.Layer):

            def __init__(self, name=None):
                super(MyLayer, self).__init__(name=name)
                self.input_layer = tl.layers.Dense(n_units=20)  # no need for in_channels here
                self.build(None)
                self._built = True

            def build(self, inputs_shape=None):
                self.W = self._get_weights('weights', shape=(20, 10))

            def forward(self, inputs):
                inputs = self.input_layer(inputs)
                output = tf.matmul(inputs, self.W)
                return output

        class model(tl.models.Model):

            def __init__(self, name=None):
                super(model, self).__init__(name=name)
                self.layer = MyLayer()

            def forward(self, inputs):
                return self.layer(inputs)

        input = tf.random.normal(shape=(100, 50))
        model_dynamic = model()
        model_dynamic.train()
        cls.assertEqual(model_dynamic(input).shape, (100, 10))
        cls.assertEqual(len(model_dynamic.all_weights), 3)
        cls.assertEqual(len(model_dynamic.trainable_weights), 3)
        model_dynamic.layer.input_layer.b.assign_add(tf.ones((20, )))
        cls.assertEqual(np.sum(model_dynamic.all_weights[-1].numpy() - tf.ones(20, ).numpy()), 0)

        ni = tl.layers.Input(shape=(100, 50))
        nn = MyLayer(name='mylayer2')(ni)
        model_static = tl.models.Model(inputs=ni, outputs=nn)
        model_static.eval()
        cls.assertEqual(model_static(input).shape, (100, 10))
        cls.assertEqual(len(model_static.all_weights), 3)
        cls.assertEqual(len(model_static.trainable_weights), 3)
        model_static.get_layer('mylayer2').input_layer.b.assign_add(tf.ones((20, )))
        cls.assertEqual(np.sum(model_static.all_weights[-1].numpy() - tf.ones(20, ).numpy()), 0)


</source>
</class>

<class classid="18" nclones="6" nlines="19" similarity="75">
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_recurrent.py" startline="49" endline="76" pcid="471">
    def test_basic_simplernn(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.RNN(
            cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, dropout=0.1), return_last_output=True,
            return_seq_2d=False, return_last_state=True
        )
        rnn, rnn_state = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn_state[0]])
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()
        assert rnnlayer.is_train

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y, final_state = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_recurrent.py" startline="280" endline="306" pcid="487">
    def test_basic_lstmrnn(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.RNN(
            cell=tf.keras.layers.LSTMCell(units=self.hidden_size, dropout=0.1), return_last_output=True,
            return_seq_2d=False, return_last_state=True
        )
        rnn, rnn_state = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn_state[0], rnn_state[1]])
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y, final_h, final_c = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_recurrent.py" startline="307" endline="332" pcid="488">
    def test_basic_lstmrnn_class(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.LSTMRNN(
            units=self.hidden_size, dropout=0.1, return_last_output=True, return_seq_2d=False, return_last_state=True
        )
        rnn, rnn_state = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn_state[0], rnn_state[1]])
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y, final_h, final_c = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_recurrent.py" startline="360" endline="385" pcid="490">
    def test_basic_grurnn_class(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.GRURNN(
            units=self.hidden_size, dropout=0.1, return_last_output=True, return_seq_2d=False, return_last_state=True
        )
        rnn, rnn_state = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn_state[0]])
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y, final_h = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_recurrent.py" startline="333" endline="359" pcid="489">
    def test_basic_grurnn(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.RNN(
            cell=tf.keras.layers.GRUCell(units=self.hidden_size, dropout=0.1), return_last_output=True,
            return_seq_2d=False, return_last_state=True
        )
        rnn, rnn_state = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn_state[0]])
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y, final_h = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_recurrent.py" startline="77" endline="103" pcid="472">
    def test_basic_simplernn_class(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.SimpleRNN(
            units=self.hidden_size, dropout=0.1, return_last_output=True, return_seq_2d=False, return_last_state=True
        )
        rnn, rnn_state = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn_state[0]])
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()
        assert rnnlayer.is_train

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y, final_state = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</source>
</class>

<class classid="19" nclones="5" nlines="25" similarity="73">
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_recurrent.py" startline="140" endline="172" pcid="475">
    def test_basic_simplernn_dynamic(self):

        class CustomisedModel(tl.models.Model):

            def __init__(self):
                super(CustomisedModel, self).__init__()
                self.rnnlayer = tl.layers.RNN(
                    cell=tf.keras.layers.SimpleRNNCell(units=8, dropout=0.1), in_channels=4, return_last_output=False,
                    return_seq_2d=False, return_last_state=False
                )
                self.dense = tl.layers.Dense(in_channels=8, n_units=1)

            def forward(self, x):
                z = self.rnnlayer(x)
                z = self.dense(z[:, -1, :])
                return z

        rnn_model = CustomisedModel()
        print(rnn_model)
        optimizer = tf.optimizers.Adam(learning_rate=0.01)
        rnn_model.train()

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_recurrent.py" startline="173" endline="205" pcid="478">
    def test_basic_simplernn_dynamic_class(self):

        class CustomisedModel(tl.models.Model):

            def __init__(self):
                super(CustomisedModel, self).__init__()
                self.rnnlayer = tl.layers.SimpleRNN(
                    units=8, dropout=0.1, in_channels=4, return_last_output=False, return_seq_2d=False,
                    return_last_state=False
                )
                self.dense = tl.layers.Dense(in_channels=8, n_units=1)

            def forward(self, x):
                z = self.rnnlayer(x)
                z = self.dense(z[:, -1, :])
                return z

        rnn_model = CustomisedModel()
        print(rnn_model)
        optimizer = tf.optimizers.Adam(learning_rate=0.01)
        rnn_model.train()

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_recurrent.py" startline="206" endline="239" pcid="481">
    def test_basic_simplernn_dynamic_2(self):

        class CustomisedModel(tl.models.Model):

            def __init__(self):
                super(CustomisedModel, self).__init__()
                self.rnnlayer = tl.layers.RNN(
                    cell=tf.keras.layers.SimpleRNNCell(units=8, dropout=0.1), in_channels=4, return_last_output=False,
                    return_seq_2d=False, return_last_state=False
                )
                self.dense = tl.layers.Dense(in_channels=8, n_units=1)

            def forward(self, x):
                z = self.rnnlayer(x, return_seq_2d=True)
                z = self.dense(z[-2:, :])
                return z

        rnn_model = CustomisedModel()
        print(rnn_model)
        optimizer = tf.optimizers.Adam(learning_rate=0.01)
        rnn_model.train()
        assert rnn_model.rnnlayer.is_train

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_recurrent.py" startline="240" endline="279" pcid="484">
    def test_basic_simplernn_dynamic_3(self):

        class CustomisedModel(tl.models.Model):

            def __init__(self):
                super(CustomisedModel, self).__init__()
                self.rnnlayer1 = tl.layers.RNN(
                    cell=tf.keras.layers.SimpleRNNCell(units=8, dropout=0.1), in_channels=4, return_last_output=True,
                    return_last_state=True
                )
                self.rnnlayer2 = tl.layers.RNN(
                    cell=tf.keras.layers.SimpleRNNCell(units=8, dropout=0.1), in_channels=4, return_last_output=True,
                    return_last_state=False
                )
                self.dense = tl.layers.Dense(in_channels=8, n_units=1)

            def forward(self, x):
                _, state = self.rnnlayer1(x[:, :2, :])
                z = self.rnnlayer2(x[:, 2:, :], initial_state=state)
                z = self.dense(z)
                return z

        rnn_model = CustomisedModel()
        print(rnn_model)
        optimizer = tf.optimizers.Adam(learning_rate=0.01)
        rnn_model.train()
        assert rnn_model.rnnlayer1.is_train
        assert rnn_model.rnnlayer2.is_train

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_recurrent.py" startline="453" endline="488" pcid="493">
    def test_basic_birnn_grucell(self):

        class CustomisedModel(tl.models.Model):

            def __init__(self):
                super(CustomisedModel, self).__init__()
                self.rnnlayer = tl.layers.BiRNN(
                    fw_cell=tf.keras.layers.GRUCell(units=8,
                                                    dropout=0.1), bw_cell=tf.keras.layers.GRUCell(units=8, dropout=0.1),
                    in_channels=4, return_seq_2d=False, return_last_state=False
                )
                self.dense = tl.layers.Dense(in_channels=16, n_units=1)
                self.reshape = tl.layers.Reshape([-1, 6])

            def forward(self, x):
                z = self.rnnlayer(x, return_seq_2d=True)
                z = self.dense(z)
                z = self.reshape(z)
                return z

        rnn_model = CustomisedModel()
        print(rnn_model)
        optimizer = tf.optimizers.Adam(learning_rate=0.01)
        rnn_model.train()

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</source>
</class>

<class classid="20" nclones="2" nlines="25" similarity="92">
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_recurrent.py" startline="386" endline="418" pcid="491">
    def test_basic_birnn_simplernncell(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.BiRNN(
            fw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, dropout=0.1),
            bw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size + 1,
                                                  dropout=0.1), return_seq_2d=True, return_last_state=True
        )
        rnn, rnn_fw_state, rnn_bw_state = rnnlayer(inputs)
        dense = tl.layers.Dense(n_units=1)(rnn)
        outputs = tl.layers.Reshape([-1, self.num_steps])(dense)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn, rnn_fw_state[0], rnn_bw_state[0]])
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()
        assert rnnlayer.is_train

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y, r, rfw, rbw = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y2)

            self.assertEqual(
                r.get_shape().as_list(), [self.batch_size * self.num_steps, self.hidden_size + self.hidden_size + 1]
            )
            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_recurrent.py" startline="419" endline="452" pcid="492">
    def test_basic_birnn_lstmcell(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.BiRNN(
            fw_cell=tf.keras.layers.LSTMCell(units=self.hidden_size, dropout=0.1),
            bw_cell=tf.keras.layers.LSTMCell(units=self.hidden_size + 1,
                                             dropout=0.1), return_seq_2d=False, return_last_state=True
        )
        rnn, rnn_fw_state, rnn_bw_state = rnnlayer(inputs)
        din = tl.layers.Reshape([-1, self.hidden_size + self.hidden_size + 1])(rnn)
        dense = tl.layers.Dense(n_units=1)(din)
        outputs = tl.layers.Reshape([-1, self.num_steps])(dense)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn, rnn_fw_state[0], rnn_bw_state[0]])
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()
        assert rnnlayer.is_train

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y, r, rfw, rbw = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y2)

            self.assertEqual(
                r.get_shape().as_list(), [self.batch_size, self.num_steps, self.hidden_size + self.hidden_size + 1]
            )
            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</source>
</class>

<class classid="21" nclones="2" nlines="27" similarity="75">
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_recurrent.py" startline="489" endline="522" pcid="496">
    def test_stack_simplernn(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer1 = tl.layers.RNN(
            cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, dropout=0.1), return_last_output=False,
            return_seq_2d=False, return_last_state=False
        )
        rnn1 = rnnlayer1(inputs)
        rnnlayer2 = tl.layers.RNN(
            cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, dropout=0.1), return_last_output=True,
            return_seq_2d=False, return_last_state=False
        )
        rnn2 = rnnlayer2(rnn1)
        outputs = tl.layers.Dense(n_units=1)(rnn2)
        rnn_model = tl.models.Model(inputs=inputs, outputs=outputs)
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()
        assert rnnlayer1.is_train
        assert rnnlayer2.is_train

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_recurrent.py" startline="523" endline="559" pcid="497">
    def test_stack_birnn_simplernncell(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.BiRNN(
            fw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, dropout=0.1),
            bw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size + 1,
                                                  dropout=0.1), return_seq_2d=False, return_last_state=False
        )
        rnn = rnnlayer(inputs)
        rnnlayer2 = tl.layers.BiRNN(
            fw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, dropout=0.1),
            bw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size + 1,
                                                  dropout=0.1), return_seq_2d=True, return_last_state=False
        )
        rnn2 = rnnlayer2(rnn)
        dense = tl.layers.Dense(n_units=1)(rnn2)
        outputs = tl.layers.Reshape([-1, self.num_steps])(dense)
        rnn_model = tl.models.Model(inputs=inputs, outputs=outputs)
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()
        assert rnnlayer.is_train
        assert rnnlayer2.is_train

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y2)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</source>
</class>

<class classid="22" nclones="4" nlines="19" similarity="85">
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_recurrent.py" startline="560" endline="585" pcid="498">
    def test_basic_simplernn_dropout_1(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.RNN(
            cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, dropout=0.5), return_last_output=True,
            return_seq_2d=False, return_last_state=False
        )
        rnn = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn])
        print(rnn_model)

        rnn_model.train()
        assert rnnlayer.is_train

        pred_y, rnn_1 = rnn_model(self.data_x)
        pred_y, rnn_2 = rnn_model(self.data_x)
        self.assertFalse(np.allclose(rnn_1, rnn_2))

        rnn_model.eval()
        assert not rnnlayer.is_train

        pred_y_1, rnn_1 = rnn_model(self.data_x)
        pred_y_2, rnn_2 = rnn_model(self.data_x)
        self.assertTrue(np.allclose(rnn_1, rnn_2))

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_recurrent.py" startline="639" endline="665" pcid="501">
    def test_basic_birnn_simplernn_dropout_2(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.BiRNN(
            fw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, recurrent_dropout=0.5),
            bw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size,
                                                  recurrent_dropout=0.5), return_seq_2d=True, return_last_state=False
        )
        rnn = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn])
        print(rnn_model)

        rnn_model.train()
        assert rnnlayer.is_train

        pred_y, rnn_1 = rnn_model(self.data_x)
        pred_y, rnn_2 = rnn_model(self.data_x)
        self.assertFalse(np.allclose(rnn_1, rnn_2))

        rnn_model.eval()
        assert not rnnlayer.is_train

        pred_y_1, rnn_1 = rnn_model(self.data_x)
        pred_y_2, rnn_2 = rnn_model(self.data_x)
        self.assertTrue(np.allclose(rnn_1, rnn_2))

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_recurrent.py" startline="612" endline="638" pcid="500">
    def test_basic_birnn_simplernn_dropout_1(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.BiRNN(
            fw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, dropout=0.5),
            bw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size,
                                                  dropout=0.5), return_seq_2d=True, return_last_state=False
        )
        rnn = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn])
        print(rnn_model)

        rnn_model.train()
        assert rnnlayer.is_train

        pred_y, rnn_1 = rnn_model(self.data_x)
        pred_y, rnn_2 = rnn_model(self.data_x)
        self.assertFalse(np.allclose(rnn_1, rnn_2))

        rnn_model.eval()
        assert not rnnlayer.is_train

        pred_y_1, rnn_1 = rnn_model(self.data_x)
        pred_y_2, rnn_2 = rnn_model(self.data_x)
        self.assertTrue(np.allclose(rnn_1, rnn_2))

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_recurrent.py" startline="586" endline="611" pcid="499">
    def test_basic_simplernn_dropout_2(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.RNN(
            cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, recurrent_dropout=0.5), return_last_output=True,
            return_seq_2d=False, return_last_state=False
        )
        rnn = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn])
        print(rnn_model)

        rnn_model.train()
        assert rnnlayer.is_train

        pred_y, rnn_1 = rnn_model(self.data_x)
        pred_y, rnn_2 = rnn_model(self.data_x)
        self.assertFalse(np.allclose(rnn_1, rnn_2))

        rnn_model.eval()
        assert not rnnlayer.is_train

        pred_y_1, rnn_1 = rnn_model(self.data_x)
        pred_y_2, rnn_2 = rnn_model(self.data_x)
        self.assertTrue(np.allclose(rnn_1, rnn_2))

</source>
</class>

<class classid="23" nclones="6" nlines="15" similarity="70">
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_activation.py" startline="27" endline="45" pcid="524">
    def test_prelu_1(self):
        inputs = tl.layers.Input([10, 5])
        prelulayer = tl.layers.PRelu(channel_shared=True)
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data.shape)
        for i in range(len(gt)):
            for j in range(len(gt[i])):
                if self.data[i][j] >= 0:
                    gt[i][j] = self.data[i][j]
                else:
                    gt[i][j] = prelulayer.alpha_var_constrained.numpy() * self.data[i][j]

        self.assertTrue(np.array_equal(out.numpy(), gt))

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_activation.py" startline="85" endline="105" pcid="527">
    def test_prelu6_1(self):
        inputs = tl.layers.Input([10, 5])
        prelulayer = tl.layers.PRelu6(channel_shared=True)
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data.shape)
        for i in range(len(gt)):
            for j in range(len(gt[i])):
                if self.data[i][j] >= 0 and self.data[i][j] <= 6:
                    gt[i][j] = self.data[i][j]
                elif self.data[i][j] > 6:
                    gt[i][j] = 6
                else:
                    gt[i][j] = prelulayer.alpha_var_constrained.numpy() * self.data[i][j]

        self.assertTrue(np.array_equal(out.numpy(), gt))

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_activation.py" startline="106" endline="126" pcid="528">
    def test_prelu6_2(self):
        inputs = tl.layers.Input([10, 5])
        prelulayer = tl.layers.PRelu6(in_channels=5)
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data.shape)
        for i in range(len(gt)):
            for j in range(len(gt[i])):
                if self.data[i][j] >= 0 and self.data[i][j] <= 6:
                    gt[i][j] = self.data[i][j]
                elif self.data[i][j] > 6:
                    gt[i][j] = 6
                else:
                    gt[i][j] = prelulayer.alpha_var_constrained.numpy()[j] * self.data[i][j]

        self.assertTrue(np.array_equal(out.numpy(), gt))

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_activation.py" startline="46" endline="64" pcid="525">
    def test_prelu_2(self):
        inputs = tl.layers.Input([10, 5])
        prelulayer = tl.layers.PRelu(in_channels=5)
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data.shape)
        for i in range(len(gt)):
            for j in range(len(gt[i])):
                if self.data[i][j] >= 0:
                    gt[i][j] = self.data[i][j]
                else:
                    gt[i][j] = prelulayer.alpha_var_constrained.numpy()[j] * self.data[i][j]

        self.assertTrue(np.array_equal(out.numpy(), gt))

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_activation.py" startline="149" endline="170" pcid="530">
    def test_ptrelu6_1(self):
        inputs = tl.layers.Input([10, 5])
        prelulayer = tl.layers.PTRelu6(channel_shared=True)
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data.shape)
        for i in range(len(gt)):
            for j in range(len(gt[i])):
                if self.data[i][j] >= 0 and self.data[i][j] <= 6:
                    gt[i][j] = self.data[i][j]
                elif self.data[i][j] > 6:
                    gt[i][j] = 6 + prelulayer.alpha_high_constrained.numpy() * (self.data[i][j] - 6)
                else:
                    gt[i][j] = prelulayer.alpha_low_constrained.numpy() * self.data[i][j]

        # FIXME: Figure out why this assert randomly fail in CI.
        # self.assertTrue(np.array_equal(out.numpy(), gt))

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_activation.py" startline="171" endline="191" pcid="531">
    def test_ptrelu6_2(self):
        inputs = tl.layers.Input([10, 5])
        prelulayer = tl.layers.PTRelu6(in_channels=5)
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data.shape)
        for i in range(len(gt)):
            for j in range(len(gt[i])):
                if self.data[i][j] >= 0 and self.data[i][j] <= 6:
                    gt[i][j] = self.data[i][j]
                elif self.data[i][j] > 6:
                    gt[i][j] = 6 + prelulayer.alpha_high_constrained.numpy()[j] * (self.data[i][j] - 6)
                else:
                    gt[i][j] = prelulayer.alpha_low_constrained.numpy()[j] * self.data[i][j]

        self.assertTrue(np.allclose(out.numpy(), gt))

</source>
</class>

<class classid="24" nclones="3" nlines="17" similarity="77">
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_activation.py" startline="65" endline="84" pcid="526">
    def test_prelu_3(self):
        inputs = tl.layers.Input([10, 10, 5])
        prelulayer = tl.layers.PRelu(in_channels=5)
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data2, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data2.shape)
        for i in range(len(gt)):
            for k in range(len(gt[i])):
                for j in range(len(gt[i][k])):
                    if self.data2[i][k][j] >= 0:
                        gt[i][k][j] = self.data2[i][k][j]
                    else:
                        gt[i][k][j] = prelulayer.alpha_var_constrained.numpy()[j] * self.data2[i][k][j]

        self.assertTrue(np.array_equal(out.numpy(), gt))

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_activation.py" startline="192" endline="214" pcid="532">
    def test_ptrelu6_3(self):
        inputs = tl.layers.Input([3, 2, 5])
        prelulayer = tl.layers.PTRelu6()
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data2, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data2.shape)
        for i in range(len(gt)):
            for k in range(len(gt[i])):
                for j in range(len(gt[i][k])):
                    if self.data2[i][k][j] >= 0 and self.data2[i][k][j] <= 6:
                        gt[i][k][j] = self.data2[i][k][j]
                    elif self.data2[i][k][j] > 6:
                        gt[i][k][j] = 6 + prelulayer.alpha_high_constrained.numpy()[j] * (self.data2[i][k][j] - 6)
                    else:
                        gt[i][k][j] = prelulayer.alpha_low_constrained.numpy()[j] * self.data2[i][k][j]

        self.assertTrue(np.allclose(out.numpy(), gt))


</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_activation.py" startline="127" endline="148" pcid="529">
    def test_prelu6_3(self):
        inputs = tl.layers.Input([10, 10, 5])
        prelulayer = tl.layers.PRelu6(in_channels=5)
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data2, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data2.shape)
        for i in range(len(gt)):
            for k in range(len(gt[i])):
                for j in range(len(gt[i][k])):
                    if self.data2[i][k][j] >= 0 and self.data2[i][k][j] <= 6:
                        gt[i][k][j] = self.data2[i][k][j]
                    elif self.data2[i][k][j] > 6:
                        gt[i][k][j] = 6
                    else:
                        gt[i][k][j] = prelulayer.alpha_var_constrained.numpy()[j] * self.data2[i][k][j]

        self.assertTrue(np.array_equal(out.numpy(), gt))

</source>
</class>

<class classid="25" nclones="6" nlines="17" similarity="88">
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_dense.py" startline="20" endline="41" pcid="557">
    def setUpClass(cls):
        print("-" * 20, "Layer_BinaryDense_Test", "-" * 20)
        cls.batch_size = 4
        cls.inputs_shape = [cls.batch_size, 10]

        cls.ni = Input(cls.inputs_shape, name='input_layer')
        cls.layer1 = BinaryDense(n_units=5)
        nn = cls.layer1(cls.ni)
        cls.layer1._nodes_fixed = True
        cls.M = Model(inputs=cls.ni, outputs=nn)

        cls.layer2 = BinaryDense(n_units=5, in_channels=10)
        cls.layer2._nodes_fixed = True

        cls.inputs = tf.ones((cls.inputs_shape))
        cls.n1 = cls.layer1(cls.inputs)
        cls.n2 = cls.layer2(cls.inputs)
        cls.n3 = cls.M(cls.inputs, is_train=True)

        print(cls.layer1)
        print(cls.layer2)

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_dense.py" startline="304" endline="325" pcid="587">
    def setUpClass(cls):
        print("-" * 20, "Layer_BinaryDense_Test", "-" * 20)
        cls.batch_size = 4
        cls.inputs_shape = [cls.batch_size, 10]

        cls.ni = Input(cls.inputs_shape, name='input_layer')
        cls.layer1 = TernaryDense(n_units=5)
        nn = cls.layer1(cls.ni)
        cls.layer1._nodes_fixed = True
        cls.M = Model(inputs=cls.ni, outputs=nn)

        cls.layer2 = TernaryDense(n_units=5, in_channels=10)
        cls.layer2._nodes_fixed = True

        cls.inputs = tf.ones((cls.inputs_shape))
        cls.n1 = cls.layer1(cls.inputs)
        cls.n2 = cls.layer2(cls.inputs)
        cls.n3 = cls.M(cls.inputs, is_train=True)

        print(cls.layer1)
        print(cls.layer2)

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_dense.py" startline="136" endline="157" pcid="569">
    def setUpClass(cls):
        print("-" * 20, "Layer_DropconnectDense_Test", "-" * 20)
        cls.batch_size = 4
        cls.inputs_shape = [cls.batch_size, 10]

        cls.ni = Input(cls.inputs_shape, name='input_layer')
        cls.layer1 = DropconnectDense(n_units=5, keep=1.0)
        nn = cls.layer1(cls.ni)
        cls.layer1._nodes_fixed = True
        cls.M = Model(inputs=cls.ni, outputs=nn)

        cls.layer2 = DropconnectDense(n_units=5, in_channels=10, keep=0.01)
        cls.layer2._nodes_fixed = True

        cls.inputs = tf.ones((cls.inputs_shape))
        cls.n1 = cls.layer1(cls.inputs)
        cls.n2 = cls.layer2(cls.inputs)
        cls.n3 = cls.M(cls.inputs, is_train=True)

        print(cls.layer1)
        print(cls.layer2)

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_dense.py" startline="194" endline="215" pcid="575">
    def setUpClass(cls):
        print("-" * 20, "Layer_QuanDense_Test", "-" * 20)
        cls.batch_size = 4
        cls.inputs_shape = [cls.batch_size, 10]

        cls.ni = Input(cls.inputs_shape, name='input_layer')
        cls.layer1 = QuanDense(n_units=5)
        nn = cls.layer1(cls.ni)
        cls.layer1._nodes_fixed = True
        cls.M = Model(inputs=cls.ni, outputs=nn)

        cls.layer2 = QuanDense(n_units=5, in_channels=10)
        cls.layer2._nodes_fixed = True

        cls.inputs = tf.random.uniform((cls.inputs_shape))
        cls.n1 = cls.layer1(cls.inputs)
        cls.n2 = cls.layer2(cls.inputs)
        cls.n3 = cls.M(cls.inputs, is_train=True)

        print(cls.layer1)
        print(cls.layer2)

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_dense.py" startline="78" endline="99" pcid="563">
    def setUpClass(cls):
        print("-" * 20, "Layer_DorefaDense_Test", "-" * 20)
        cls.batch_size = 4
        cls.inputs_shape = [cls.batch_size, 10]

        cls.ni = Input(cls.inputs_shape, name='input_layer')
        cls.layer1 = DorefaDense(n_units=5)
        nn = cls.layer1(cls.ni)
        cls.layer1._nodes_fixed = True
        cls.M = Model(inputs=cls.ni, outputs=nn)

        cls.layer2 = DorefaDense(n_units=5, in_channels=10)
        cls.layer2._nodes_fixed = True

        cls.inputs = tf.ones((cls.inputs_shape))
        cls.n1 = cls.layer1(cls.inputs)
        cls.n2 = cls.layer2(cls.inputs)
        cls.n3 = cls.M(cls.inputs, is_train=True)

        print(cls.layer1)
        print(cls.layer2)

</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_dense.py" startline="249" endline="270" pcid="581">
    def setUpClass(cls):
        print("-" * 20, "Layer_QuanDenseWithBN_Test", "-" * 20)
        cls.batch_size = 4
        cls.inputs_shape = [cls.batch_size, 10]

        cls.ni = Input(cls.inputs_shape, name='input_layer')
        cls.layer1 = QuanDenseWithBN(n_units=5)
        nn = cls.layer1(cls.ni)
        cls.layer1._nodes_fixed = True
        cls.M = Model(inputs=cls.ni, outputs=nn)

        cls.layer2 = QuanDenseWithBN(n_units=5, in_channels=10)
        cls.layer2._nodes_fixed = True

        cls.inputs = tf.random.uniform((cls.inputs_shape))
        cls.n1 = cls.layer1(cls.inputs)
        cls.n2 = cls.layer2(cls.inputs)
        cls.n3 = cls.M(cls.inputs, is_train=True)

        print(cls.layer1)
        print(cls.layer2)

</source>
</class>

<class classid="26" nclones="6" nlines="14" similarity="85">
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_dense.py" startline="58" endline="74" pcid="562">
    def test_exception(self):
        try:
            layer = BinaryDense(n_units=5)
            inputs = Input([4, 10, 5], name='ill_inputs')
            out = layer(inputs)
            self.fail('ill inputs')
        except Exception as e:
            print(e)

        try:
            layer = BinaryDense(n_units=5, use_gemm=True)
            out = layer(self.ni)
            self.fail('use gemm')
        except Exception as e:
            print(e)


</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_dense.py" startline="229" endline="245" pcid="580">
    def test_exception(self):
        try:
            layer = QuanDense(n_units=5)
            inputs = Input([4, 10, 5], name='ill_inputs')
            out = layer(inputs)
            self.fail('ill inputs')
        except Exception as e:
            print(e)

        try:
            layer = QuanDense(n_units=5, use_gemm=True)
            out = layer(self.ni)
            self.fail('use gemm')
        except Exception as e:
            print(e)


</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_dense.py" startline="342" endline="358" pcid="592">
    def test_exception(self):
        try:
            layer = TernaryDense(n_units=5)
            inputs = Input([4, 10, 5], name='ill_inputs')
            out = layer(inputs)
            self.fail('ill inputs')
        except Exception as e:
            print(e)

        try:
            layer = TernaryDense(n_units=5, use_gemm=True)
            out = layer(self.ni)
            self.fail('use gemm')
        except Exception as e:
            print(e)


</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_dense.py" startline="174" endline="190" pcid="574">
    def test_exception(self):
        try:
            layer = DropconnectDense(n_units=5)
            inputs = Input([4, 10, 5], name='ill_inputs')
            out = layer(inputs)
            self.fail('ill inputs')
        except Exception as e:
            print(e)

        try:
            layer = DropconnectDense(n_units=5, keep=0.0)
            self.fail('keep no elements')
        except Exception as e:
            self.assertIsInstance(e, ValueError)
            print(e)


</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_dense.py" startline="116" endline="132" pcid="568">
    def test_exception(self):
        try:
            layer = DorefaDense(n_units=5)
            inputs = Input([4, 10, 5], name='ill_inputs')
            out = layer(inputs)
            self.fail('ill inputs')
        except Exception as e:
            print(e)

        try:
            layer = DorefaDense(n_units=5, use_gemm=True)
            out = layer(self.ni)
            self.fail('use gemm')
        except Exception as e:
            print(e)


</source>
<source file="systems/TensorLayer-2.2.4/tests/layers/test_layers_dense.py" startline="284" endline="300" pcid="586">
    def test_exception(self):
        try:
            layer = QuanDenseWithBN(n_units=5)
            inputs = Input([4, 10, 5], name='ill_inputs')
            out = layer(inputs)
            self.fail('ill inputs')
        except Exception as e:
            print(e)

        try:
            layer = QuanDenseWithBN(n_units=5, use_gemm=True)
            out = layer(self.ni)
            self.fail('use gemm')
        except Exception as e:
            print(e)


</source>
</class>

<class classid="27" nclones="2" nlines="10" similarity="100">
<source file="systems/TensorLayer-2.2.4/examples/spatial_transformer_network/tutorial_spatial_transformer_network_dynamic.py" startline="16" endline="36" pcid="618">

def pad_distort_im_fn(x):
    """ Zero pads an image to 40x40, and distort it.

    Examples
    ---------
    x = pad_distort_im_fn(X_train[0])
    print(x, x.shape, x.max())
    tl.vis.save_image(x, '_xd.png')
    tl.vis.save_image(X_train[0], '_x.png')
    """
    b = np.zeros((40, 40, 1), dtype=np.float32)
    o = int((40 - 28) / 2)
    b[o:o + 28, o:o + 28] = x
    x = b
    x = tl.prepro.rotation(x, rg=30, is_random=True, fill_mode='constant')
    x = tl.prepro.shear(x, 0.05, is_random=True, fill_mode='constant')
    x = tl.prepro.shift(x, wrg=0.25, hrg=0.25, is_random=True, fill_mode='constant')
    x = tl.prepro.zoom(x, zoom_range=(0.95, 1.05))
    return x

</source>
<source file="systems/TensorLayer-2.2.4/examples/spatial_transformer_network/tutorial_spatial_transformer_network_static.py" startline="16" endline="36" pcid="622">

def pad_distort_im_fn(x):
    """ Zero pads an image to 40x40, and distort it.

    Examples
    ---------
    x = pad_distort_im_fn(X_train[0])
    print(x, x.shape, x.max())
    tl.vis.save_image(x, '_xd.png')
    tl.vis.save_image(X_train[0], '_x.png')
    """
    b = np.zeros((40, 40, 1), dtype=np.float32)
    o = int((40 - 28) / 2)
    b[o:o + 28, o:o + 28] = x
    x = b
    x = tl.prepro.rotation(x, rg=30, is_random=True, fill_mode='constant')
    x = tl.prepro.shear(x, 0.05, is_random=True, fill_mode='constant')
    x = tl.prepro.shift(x, wrg=0.25, hrg=0.25, is_random=True, fill_mode='constant')
    x = tl.prepro.zoom(x, zoom_range=(0.95, 1.05))
    return x

</source>
</class>

<class classid="28" nclones="2" nlines="39" similarity="100">
<source file="systems/TensorLayer-2.2.4/examples/text_generation/tutorial_generate_text.py" startline="42" endline="83" pcid="641">
def basic_clean_str(string):
    """Tokenization/string cleaning for a datasets."""
    string = re.sub(r"\n", " ", string)  # '\n'      --> ' '
    string = re.sub(r"\'s", " \'s", string)  # it's      --> it 's
    string = re.sub(r"\’s", " \'s", string)
    string = re.sub(r"\'ve", " have", string)  # they've   --> they have
    string = re.sub(r"\’ve", " have", string)
    string = re.sub(r"\'t", " not", string)  # can't     --> can not
    string = re.sub(r"\’t", " not", string)
    string = re.sub(r"\'re", " are", string)  # they're   --> they are
    string = re.sub(r"\’re", " are", string)
    string = re.sub(r"\'d", "", string)  # I'd (I had, I would) --> I
    string = re.sub(r"\’d", "", string)
    string = re.sub(r"\'ll", " will", string)  # I'll      --> I will
    string = re.sub(r"\’ll", " will", string)
    string = re.sub(r"\“", "  ", string)  # “a”       --> “ a ”
    string = re.sub(r"\”", "  ", string)
    string = re.sub(r"\"", "  ", string)  # "a"       --> " a "
    string = re.sub(r"\'", "  ", string)  # they'     --> they '
    string = re.sub(r"\’", "  ", string)  # they’     --> they ’
    string = re.sub(r"\.", " . ", string)  # they.     --> they .
    string = re.sub(r"\,", " , ", string)  # they,     --> they ,
    string = re.sub(r"\!", " ! ", string)
    string = re.sub(r"\-", "  ", string)  # "low-cost"--> lost cost
    string = re.sub(r"\(", "  ", string)  # (they)    --> ( they)
    string = re.sub(r"\)", "  ", string)  # ( they)   --> ( they )
    string = re.sub(r"\]", "  ", string)  # they]     --> they ]
    string = re.sub(r"\[", "  ", string)  # they[     --> they [
    string = re.sub(r"\?", "  ", string)  # they?     --> they ?
    string = re.sub(r"\>", "  ", string)  # they>     --> they >
    string = re.sub(r"\<", "  ", string)  # they<     --> they <
    string = re.sub(r"\=", "  ", string)  # easier=   --> easier =
    string = re.sub(r"\;", "  ", string)  # easier;   --> easier ;
    string = re.sub(r"\;", "  ", string)
    string = re.sub(r"\:", "  ", string)  # easier:   --> easier :
    string = re.sub(r"\"", "  ", string)  # easier"   --> easier "
    string = re.sub(r"\$", "  ", string)  # $380      --> $ 380
    string = re.sub(r"\_", "  ", string)  # _100     --> _ 100
    string = re.sub(r"\s{2,}", " ", string)  # Akara is    handsome --> Akara is handsome
    return string.strip().lower()  # lowercase


</source>
<source file="systems/TensorLayer-2.2.4/examples/text_generation/tutorial_generate_text.py" startline="84" endline="125" pcid="642">
def customized_clean_str(string):
    """Tokenization/string cleaning for a datasets."""
    string = re.sub(r"\n", " ", string)  # '\n'      --> ' '
    string = re.sub(r"\'s", " \'s", string)  # it's      --> it 's
    string = re.sub(r"\’s", " \'s", string)
    string = re.sub(r"\'ve", " have", string)  # they've   --> they have
    string = re.sub(r"\’ve", " have", string)
    string = re.sub(r"\'t", " not", string)  # can't     --> can not
    string = re.sub(r"\’t", " not", string)
    string = re.sub(r"\'re", " are", string)  # they're   --> they are
    string = re.sub(r"\’re", " are", string)
    string = re.sub(r"\'d", "", string)  # I'd (I had, I would) --> I
    string = re.sub(r"\’d", "", string)
    string = re.sub(r"\'ll", " will", string)  # I'll      --> I will
    string = re.sub(r"\’ll", " will", string)
    string = re.sub(r"\“", " “ ", string)  # “a”       --> “ a ”
    string = re.sub(r"\”", " ” ", string)
    string = re.sub(r"\"", " “ ", string)  # "a"       --> " a "
    string = re.sub(r"\'", " ' ", string)  # they'     --> they '
    string = re.sub(r"\’", " ' ", string)  # they’     --> they '
    string = re.sub(r"\.", " . ", string)  # they.     --> they .
    string = re.sub(r"\,", " , ", string)  # they,     --> they ,
    string = re.sub(r"\-", " ", string)  # "low-cost"--> lost cost
    string = re.sub(r"\(", " ( ", string)  # (they)    --> ( they)
    string = re.sub(r"\)", " ) ", string)  # ( they)   --> ( they )
    string = re.sub(r"\!", " ! ", string)  # they!     --> they !
    string = re.sub(r"\]", " ] ", string)  # they]     --> they ]
    string = re.sub(r"\[", " [ ", string)  # they[     --> they [
    string = re.sub(r"\?", " ? ", string)  # they?     --> they ?
    string = re.sub(r"\>", " > ", string)  # they>     --> they >
    string = re.sub(r"\<", " < ", string)  # they<     --> they <
    string = re.sub(r"\=", " = ", string)  # easier=   --> easier =
    string = re.sub(r"\;", " ; ", string)  # easier;   --> easier ;
    string = re.sub(r"\;", " ; ", string)
    string = re.sub(r"\:", " : ", string)  # easier:   --> easier :
    string = re.sub(r"\"", " \" ", string)  # easier"   --> easier "
    string = re.sub(r"\$", " $ ", string)  # $380      --> $ 380
    string = re.sub(r"\_", " _ ", string)  # _100     --> _ 100
    string = re.sub(r"\s{2,}", " ", string)  # Akara is    handsome --> Akara is handsome
    return string.strip().lower()  # lowercase


</source>
</class>

<class classid="29" nclones="2" nlines="17" similarity="76">
<source file="systems/TensorLayer-2.2.4/examples/basic_tutorials/tutorial_cifar10_cnn_static.py" startline="23" endline="47" pcid="650">
def get_model(inputs_shape):
    # self defined initialization
    W_init = tl.initializers.truncated_normal(stddev=5e-2)
    W_init2 = tl.initializers.truncated_normal(stddev=0.04)
    b_init2 = tl.initializers.constant(value=0.1)

    # build network
    ni = Input(inputs_shape)
    nn = Conv2d(64, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, W_init=W_init, b_init=None, name='conv1')(ni)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool1')(nn)
    nn = LocalResponseNorm(depth_radius=4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name="norm1")(nn)

    nn = Conv2d(64, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, W_init=W_init, b_init=None, name='conv2')(nn)
    nn = LocalResponseNorm(depth_radius=4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name="norm2")(nn)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool2')(nn)

    nn = Flatten(name='flatten')(nn)
    nn = Dense(384, act=tf.nn.relu, W_init=W_init2, b_init=b_init2, name='dense1relu')(nn)
    nn = Dense(192, act=tf.nn.relu, W_init=W_init2, b_init=b_init2, name='dense2relu')(nn)
    nn = Dense(10, act=None, W_init=W_init2, name='output')(nn)

    M = Model(inputs=ni, outputs=nn, name='cnn')
    return M


</source>
<source file="systems/TensorLayer-2.2.4/examples/basic_tutorials/tutorial_cifar10_cnn_static.py" startline="48" endline="73" pcid="651">
def get_model_batchnorm(inputs_shape):
    # self defined initialization
    W_init = tl.initializers.truncated_normal(stddev=5e-2)
    W_init2 = tl.initializers.truncated_normal(stddev=0.04)
    b_init2 = tl.initializers.constant(value=0.1)

    # build network
    ni = Input(inputs_shape)
    nn = Conv2d(64, (5, 5), (1, 1), padding='SAME', W_init=W_init, b_init=None, name='conv1')(ni)
    nn = BatchNorm(decay=0.99, act=tf.nn.relu, name='batch1')(nn)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool1')(nn)

    nn = Conv2d(64, (5, 5), (1, 1), padding='SAME', W_init=W_init, b_init=None, name='conv2')(nn)
    nn = BatchNorm(decay=0.99, act=tf.nn.relu, name='batch2')(nn)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool2')(nn)

    nn = Flatten(name='flatten')(nn)
    nn = Dense(384, act=tf.nn.relu, W_init=W_init2, b_init=b_init2, name='dense1relu')(nn)
    nn = Dense(192, act=tf.nn.relu, W_init=W_init2, b_init=b_init2, name='dense2relu')(nn)
    nn = Dense(10, act=None, W_init=W_init2, name='output')(nn)

    M = Model(inputs=ni, outputs=nn, name='cnn')
    return M


# get the network
</source>
</class>

<class classid="30" nclones="2" nlines="11" similarity="90">
<source file="systems/TensorLayer-2.2.4/examples/reinforcement_learning/tutorial_SAC.py" startline="335" endline="346" pcid="687">
    def save(self):  # save trained weights
        path = os.path.join('model', '_'.join([ALG_NAME, ENV_ID]))
        if not os.path.exists(path):
            os.makedirs(path)
        extend_path = lambda s: os.path.join(path, s)
        tl.files.save_npz(self.soft_q_net1.trainable_weights, extend_path('model_q_net1.npz'))
        tl.files.save_npz(self.soft_q_net2.trainable_weights, extend_path('model_q_net2.npz'))
        tl.files.save_npz(self.target_soft_q_net1.trainable_weights, extend_path('model_target_q_net1.npz'))
        tl.files.save_npz(self.target_soft_q_net2.trainable_weights, extend_path('model_target_q_net2.npz'))
        tl.files.save_npz(self.policy_net.trainable_weights, extend_path('model_policy_net.npz'))
        np.save(extend_path('log_alpha.npy'), self.log_alpha.numpy())  # save log_alpha variable

</source>
<source file="systems/TensorLayer-2.2.4/examples/reinforcement_learning/tutorial_TD3.py" startline="316" endline="327" pcid="830">
    def save(self):  # save trained weights
        path = os.path.join('model', '_'.join([ALG_NAME, ENV_ID]))
        if not os.path.exists(path):
            os.makedirs(path)
        extend_path = lambda s: os.path.join(path, s)
        tl.files.save_npz(self.q_net1.trainable_weights, extend_path('model_q_net1.npz'))
        tl.files.save_npz(self.q_net2.trainable_weights, extend_path('model_q_net2.npz'))
        tl.files.save_npz(self.target_q_net1.trainable_weights, extend_path('model_target_q_net1.npz'))
        tl.files.save_npz(self.target_q_net2.trainable_weights, extend_path('model_target_q_net2.npz'))
        tl.files.save_npz(self.policy_net.trainable_weights, extend_path('model_policy_net.npz'))
        tl.files.save_npz(self.target_policy_net.trainable_weights, extend_path('model_target_policy_net.npz'))

</source>
</class>

<class classid="31" nclones="2" nlines="31" similarity="96">
<source file="systems/TensorLayer-2.2.4/examples/reinforcement_learning/tutorial_DPPO.py" startline="85" endline="123" pcid="746">
    def __init__(self, state_dim, action_dim, action_bound, method='clip'):

        # critic
        with tf.name_scope('critic'):
            inputs = tl.layers.Input([None, state_dim], tf.float32, 'state')
            layer = tl.layers.Dense(64, tf.nn.relu)(inputs)
            layer = tl.layers.Dense(64, tf.nn.relu)(layer)
            v = tl.layers.Dense(1)(layer)
        self.critic = tl.models.Model(inputs, v)
        self.critic.train()
        self.method = method

        # actor
        with tf.name_scope('actor'):
            inputs = tl.layers.Input([None, state_dim], tf.float32, 'state')
            layer = tl.layers.Dense(64, tf.nn.relu)(inputs)
            layer = tl.layers.Dense(64, tf.nn.relu)(layer)
            a = tl.layers.Dense(action_dim, tf.nn.tanh)(layer)
            mean = tl.layers.Lambda(lambda x: x * action_bound, name='lambda')(a)
            logstd = tf.Variable(np.zeros(action_dim, dtype=np.float32))
        self.actor = tl.models.Model(inputs, mean)
        self.actor.trainable_weights.append(logstd)
        self.actor.logstd = logstd
        self.actor.train()

        self.actor_opt = tf.optimizers.Adam(LR_A)
        self.critic_opt = tf.optimizers.Adam(LR_C)

        self.method = method
        if method == 'penalty':
            self.kl_target = KL_TARGET
            self.lam = LAM
        elif method == 'clip':
            self.epsilon = EPSILON

        self.state_buffer, self.action_buffer = [], []
        self.reward_buffer, self.cumulative_reward_buffer = [], []
        self.action_bound = action_bound

</source>
<source file="systems/TensorLayer-2.2.4/examples/reinforcement_learning/tutorial_PPO.py" startline="74" endline="110" pcid="832">
    def __init__(self, state_dim, action_dim, action_bound, method='clip'):
        # critic
        with tf.name_scope('critic'):
            inputs = tl.layers.Input([None, state_dim], tf.float32, 'state')
            layer = tl.layers.Dense(64, tf.nn.relu)(inputs)
            layer = tl.layers.Dense(64, tf.nn.relu)(layer)
            v = tl.layers.Dense(1)(layer)
        self.critic = tl.models.Model(inputs, v)
        self.critic.train()

        # actor
        with tf.name_scope('actor'):
            inputs = tl.layers.Input([None, state_dim], tf.float32, 'state')
            layer = tl.layers.Dense(64, tf.nn.relu)(inputs)
            layer = tl.layers.Dense(64, tf.nn.relu)(layer)
            a = tl.layers.Dense(action_dim, tf.nn.tanh)(layer)
            mean = tl.layers.Lambda(lambda x: x * action_bound, name='lambda')(a)
            logstd = tf.Variable(np.zeros(action_dim, dtype=np.float32))
        self.actor = tl.models.Model(inputs, mean)
        self.actor.trainable_weights.append(logstd)
        self.actor.logstd = logstd
        self.actor.train()

        self.actor_opt = tf.optimizers.Adam(LR_A)
        self.critic_opt = tf.optimizers.Adam(LR_C)

        self.method = method
        if method == 'penalty':
            self.kl_target = KL_TARGET
            self.lam = LAM
        elif method == 'clip':
            self.epsilon = EPSILON

        self.state_buffer, self.action_buffer = [], []
        self.reward_buffer, self.cumulative_reward_buffer = [], []
        self.action_bound = action_bound

</source>
</class>

<class classid="32" nclones="2" nlines="18" similarity="100">
<source file="systems/TensorLayer-2.2.4/examples/reinforcement_learning/tutorial_DPPO.py" startline="124" endline="153" pcid="747">
    def train_actor(self, state, action, adv, old_pi):
        """
        Update policy network
        :param state: state batch
        :param action: action batch
        :param adv: advantage batch
        :param old_pi: old pi distribution
        :return: kl_mean or None
        """
        with tf.GradientTape() as tape:
            mean, std = self.actor(state), tf.exp(self.actor.logstd)
            pi = tfp.distributions.Normal(mean, std)

            ratio = tf.exp(pi.log_prob(action) - old_pi.log_prob(action))
            surr = ratio * adv
            if self.method == 'penalty':  # ppo penalty
                kl = tfp.distributions.kl_divergence(old_pi, pi)
                kl_mean = tf.reduce_mean(kl)
                loss = -(tf.reduce_mean(surr - self.lam * kl))
            else:  # ppo clip
                loss = -tf.reduce_mean(
                    tf.minimum(surr,
                               tf.clip_by_value(ratio, 1. - self.epsilon, 1. + self.epsilon) * adv)
                )
        a_gard = tape.gradient(loss, self.actor.trainable_weights)
        self.actor_opt.apply_gradients(zip(a_gard, self.actor.trainable_weights))

        if self.method == 'kl_pen':
            return kl_mean

</source>
<source file="systems/TensorLayer-2.2.4/examples/reinforcement_learning/tutorial_PPO.py" startline="111" endline="140" pcid="833">
    def train_actor(self, state, action, adv, old_pi):
        """
        Update policy network
        :param state: state batch
        :param action: action batch
        :param adv: advantage batch
        :param old_pi: old pi distribution
        :return: kl_mean or None
        """
        with tf.GradientTape() as tape:
            mean, std = self.actor(state), tf.exp(self.actor.logstd)
            pi = tfp.distributions.Normal(mean, std)

            ratio = tf.exp(pi.log_prob(action) - old_pi.log_prob(action))
            surr = ratio * adv
            if self.method == 'penalty':  # ppo penalty
                kl = tfp.distributions.kl_divergence(old_pi, pi)
                kl_mean = tf.reduce_mean(kl)
                loss = -(tf.reduce_mean(surr - self.lam * kl))
            else:  # ppo clip
                loss = -tf.reduce_mean(
                    tf.minimum(surr,
                               tf.clip_by_value(ratio, 1. - self.epsilon, 1. + self.epsilon) * adv)
                )
        a_gard = tape.gradient(loss, self.actor.trainable_weights)
        self.actor_opt.apply_gradients(zip(a_gard, self.actor.trainable_weights))

        if self.method == 'kl_pen':
            return kl_mean

</source>
</class>

<class classid="33" nclones="2" nlines="20" similarity="80">
<source file="systems/TensorLayer-2.2.4/examples/reinforcement_learning/tutorial_C51.py" startline="110" endline="134" pcid="767">
    def __init__(self, name):
        super(CNN, self).__init__(name=name)
        h, w, in_channels = in_dim
        dense_in_channels = 64 * ((h - 28) // 8) * ((w - 28) // 8)
        self.conv1 = tl.layers.Conv2d(
            32, (8, 8), (4, 4), tf.nn.relu, 'VALID', in_channels=in_channels, name='conv2d_1',
            W_init=tf.initializers.GlorotUniform()
        )
        self.conv2 = tl.layers.Conv2d(
            64, (4, 4), (2, 2), tf.nn.relu, 'VALID', in_channels=32, name='conv2d_2',
            W_init=tf.initializers.GlorotUniform()
        )
        self.conv3 = tl.layers.Conv2d(
            64, (3, 3), (1, 1), tf.nn.relu, 'VALID', in_channels=64, name='conv2d_3',
            W_init=tf.initializers.GlorotUniform()
        )
        self.flatten = tl.layers.Flatten(name='flatten')
        self.preq = tl.layers.Dense(
            256, tf.nn.relu, in_channels=dense_in_channels, name='pre_q', W_init=tf.initializers.GlorotUniform()
        )
        self.qvalue = tl.layers.Dense(
            out_dim * atom_num, in_channels=256, name='q', W_init=tf.initializers.GlorotUniform()
        )
        self.reshape = tl.layers.Reshape((-1, out_dim, atom_num))

</source>
<source file="systems/TensorLayer-2.2.4/examples/reinforcement_learning/tutorial_DQN_variants.py" startline="153" endline="179" pcid="843">
    def __init__(self, name):
        super(CNN, self).__init__(name=name)
        h, w, in_channels = in_dim
        dense_in_channels = 64 * ((h - 28) // 8) * ((w - 28) // 8)
        self.conv1 = tl.layers.Conv2d(
            32, (8, 8), (4, 4), tf.nn.relu, 'VALID', in_channels=in_channels, name='conv2d_1',
            W_init=tf.initializers.GlorotUniform()
        )
        self.conv2 = tl.layers.Conv2d(
            64, (4, 4), (2, 2), tf.nn.relu, 'VALID', in_channels=32, name='conv2d_2',
            W_init=tf.initializers.GlorotUniform()
        )
        self.conv3 = tl.layers.Conv2d(
            64, (3, 3), (1, 1), tf.nn.relu, 'VALID', in_channels=64, name='conv2d_3',
            W_init=tf.initializers.GlorotUniform()
        )
        self.flatten = tl.layers.Flatten(name='flatten')
        self.preq = tl.layers.Dense(
            256, tf.nn.relu, in_channels=dense_in_channels, name='pre_q', W_init=tf.initializers.GlorotUniform()
        )
        self.qvalue = tl.layers.Dense(out_dim, in_channels=256, name='q', W_init=tf.initializers.GlorotUniform())
        self.pres = tl.layers.Dense(
            256, tf.nn.relu, in_channels=dense_in_channels, name='pre_s', W_init=tf.initializers.GlorotUniform()
        )
        self.svalue = tl.layers.Dense(1, in_channels=256, name='state', W_init=tf.initializers.GlorotUniform())
        self.noise_scale = 0

</source>
</class>

<class classid="34" nclones="2" nlines="16" similarity="100">
<source file="systems/TensorLayer-2.2.4/examples/reinforcement_learning/tutorial_C51.py" startline="159" endline="175" pcid="772">
    def _encode_sample(self, idxes):
        b_o, b_a, b_r, b_o_, b_d = [], [], [], [], []
        for i in idxes:
            o, a, r, o_, d = self._storage[i]
            b_o.append(o)
            b_a.append(a)
            b_r.append(r)
            b_o_.append(o_)
            b_d.append(d)
        return (
            np.stack(b_o).astype('float32') * ob_scale,
            np.stack(b_a).astype('int32'),
            np.stack(b_r).astype('float32'),
            np.stack(b_o_).astype('float32') * ob_scale,
            np.stack(b_d).astype('float32'),
        )

</source>
<source file="systems/TensorLayer-2.2.4/examples/reinforcement_learning/tutorial_DQN_variants.py" startline="227" endline="243" pcid="848">
    def _encode_sample(self, idxes):
        b_o, b_a, b_r, b_o_, b_d = [], [], [], [], []
        for i in idxes:
            o, a, r, o_, d = self._storage[i]
            b_o.append(o)
            b_a.append(a)
            b_r.append(r)
            b_o_.append(o_)
            b_d.append(d)
        return (
            np.stack(b_o).astype('float32') * ob_scale,
            np.stack(b_a).astype('int32'),
            np.stack(b_r).astype('float32'),
            np.stack(b_o_).astype('float32') * ob_scale,
            np.stack(b_d).astype('float32'),
        )

</source>
</class>

<class classid="35" nclones="2" nlines="17" similarity="94">
<source file="systems/TensorLayer-2.2.4/examples/reinforcement_learning/tutorial_C51.py" startline="197" endline="213" pcid="776">
    def __init__(self):
        model = MLP if qnet_type == 'MLP' else CNN
        self.qnet = model('q')
        if args.train:
            self.qnet.train()
            self.targetqnet = model('targetq')
            self.targetqnet.infer()
            sync(self.qnet, self.targetqnet)
        else:
            self.qnet.infer()
            self.load(args.save_path)
        self.niter = 0
        if clipnorm is not None:
            self.optimizer = tf.optimizers.Adam(learning_rate=lr, clipnorm=clipnorm)
        else:
            self.optimizer = tf.optimizers.Adam(learning_rate=lr)

</source>
<source file="systems/TensorLayer-2.2.4/examples/reinforcement_learning/tutorial_DQN_variants.py" startline="275" endline="292" pcid="854">
    def __init__(self):
        model = MLP if qnet_type == 'MLP' else CNN
        self.qnet = model('q')
        if args.train:
            self.qnet.train()
            self.targetqnet = model('targetq')
            self.targetqnet.infer()
            sync(self.qnet, self.targetqnet)
        else:
            self.qnet.infer()
            self.load(args.save_path)
        self.niter = 0
        if clipnorm is not None:
            self.optimizer = tf.optimizers.Adam(learning_rate=lr, clipnorm=clipnorm)
        else:
            self.optimizer = tf.optimizers.Adam(learning_rate=lr)
        self.noise_scale = noise_scale

</source>
</class>

<class classid="36" nclones="2" nlines="21" similarity="76">
<source file="systems/TensorLayer-2.2.4/examples/reinforcement_learning/tutorial_DQN_variants.py" startline="122" endline="150" pcid="842">
    def forward(self, ni):
        feature = self.h1(ni)

        # apply noise to all linear layer
        if self.noise_scale != 0:
            noises = []
            for layer in [self.qvalue, self.svalue]:
                for var in layer.trainable_weights:
                    noise = tf.random.normal(tf.shape(var), 0, self.noise_scale)
                    noises.append(noise)
                    var.assign_add(noise)

        qvalue = self.qvalue(feature)
        svalue = self.svalue(feature)

        if self.noise_scale != 0:
            idx = 0
            for layer in [self.qvalue, self.svalue]:
                for var in layer.trainable_weights:
                    var.assign_sub(noises[idx])
                    idx += 1

        if dueling:
            # dueling network
            return svalue + qvalue - tf.reduce_mean(qvalue, 1, keepdims=True)
        else:
            return qvalue


</source>
<source file="systems/TensorLayer-2.2.4/examples/reinforcement_learning/tutorial_DQN_variants.py" startline="180" endline="209" pcid="844">
    def forward(self, ni):
        feature = self.flatten(self.conv3(self.conv2(self.conv1(ni))))

        # apply noise to all linear layer
        if self.noise_scale != 0:
            noises = []
            for layer in [self.preq, self.qvalue, self.pres, self.svalue]:
                for var in layer.trainable_weights:
                    noise = tf.random.normal(tf.shape(var), 0, self.noise_scale)
                    noises.append(noise)
                    var.assign_add(noise)

        qvalue = self.qvalue(self.preq(feature))
        svalue = self.svalue(self.pres(feature))

        if self.noise_scale != 0:
            idx = 0
            for layer in [self.preq, self.qvalue, self.pres, self.svalue]:
                for var in layer.trainable_weights:
                    var.assign_sub(noises[idx])
                    idx += 1

        if dueling:
            # dueling network
            return svalue + qvalue - tf.reduce_mean(qvalue, 1, keepdims=True)
        else:
            return qvalue


# ##############################  Replay  ####################################
</source>
</class>

<class classid="37" nclones="2" nlines="13" similarity="76">
<source file="systems/TensorLayer-2.2.4/examples/data_process/tutorial_tfrecord.py" startline="77" endline="94" pcid="862">
def read_and_decode(filename):
    # generate a queue with a given file name
    raw_dataset = tf.data.TFRecordDataset([filename]).shuffle(1000).batch(4)
    for serialized_example in raw_dataset:
        features = tf.io.parse_example(
            serialized_example, features={
                'label': tf.io.FixedLenFeature([], tf.int64),
                'img_raw': tf.io.FixedLenFeature([], tf.string),
            }
        )
        # You can do more image distortion here for training data
        img_batch = tf.io.decode_raw(features['img_raw'], tf.uint8)
        img_batch = tf.reshape(img_batch, [4, 224, 224, 3])
        # img = tf.cast(img, tf.float32) * (1. / 255) - 0.5
        label_batch = tf.cast(features['label'], tf.int32)
        yield img_batch, label_batch


</source>
<source file="systems/TensorLayer-2.2.4/examples/data_process/tutorial_tfrecord2.py" startline="63" endline="80" pcid="870">
def read_and_decode(filename):
    batchsize = 4
    raw_dataset = tf.data.TFRecordDataset([filename]).shuffle(1000).batch(batchsize)
    for serialized_example in raw_dataset:
        features = tf.io.parse_example(
            serialized_example, features={
                'label': tf.io.FixedLenFeature([], tf.int64),
                'img_raw': tf.io.FixedLenFeature([], tf.string),
            }
        )
        # You can do more image distortion here for training data
        img_batch = tf.io.decode_raw(features['img_raw'], tf.uint8)
        img_batch = tf.reshape(img_batch, [-1, 32, 32, 3])
        # img = tf.cast(img, tf.float32) #* (1. / 255) - 0.5    # don't need to cast here, as it is float32 already
        label_batch = tf.cast(features['label'], tf.int32)
        yield img_batch, label_batch


</source>
</class>

<class classid="38" nclones="8" nlines="11" similarity="100">
<source file="systems/TensorLayer-2.2.4/examples/quantized_net/tutorial_quanconv_cifar10.py" startline="133" endline="145" pcid="916">
def _train_step(network, X_batch, y_batch, cost, train_op=tf.optimizers.Adam(learning_rate=0.0001), acc=None):
    with tf.GradientTape() as tape:
        y_pred = network(X_batch)
        _loss = cost(y_pred, y_batch)
    grad = tape.gradient(_loss, network.trainable_weights)
    train_op.apply_gradients(zip(grad, network.trainable_weights))
    if acc is not None:
        _acc = acc(y_pred, y_batch)
        return _loss, _acc
    else:
        return _loss, None


</source>
<source file="systems/TensorLayer-2.2.4/examples/quantized_net/tutorial_ternaryweight_mnist_cnn.py" startline="41" endline="53" pcid="926">
def _train_step(network, X_batch, y_batch, cost, train_op=tf.optimizers.Adam(learning_rate=0.0001), acc=None):
    with tf.GradientTape() as tape:
        y_pred = network(X_batch)
        _loss = cost(y_pred, y_batch)
    grad = tape.gradient(_loss, network.trainable_weights)
    train_op.apply_gradients(zip(grad, network.trainable_weights))
    if acc is not None:
        _acc = acc(y_pred, y_batch)
        return _loss, _acc
    else:
        return _loss, None


</source>
<source file="systems/TensorLayer-2.2.4/examples/quantized_net/tutorial_dorefanet_mnist_cnn.py" startline="40" endline="52" pcid="929">
def _train_step(network, X_batch, y_batch, cost, train_op=tf.optimizers.Adam(learning_rate=0.0001), acc=None):
    with tf.GradientTape() as tape:
        y_pred = network(X_batch)
        _loss = cost(y_pred, y_batch)
    grad = tape.gradient(_loss, network.trainable_weights)
    train_op.apply_gradients(zip(grad, network.trainable_weights))
    if acc is not None:
        _acc = acc(y_pred, y_batch)
        return _loss, _acc
    else:
        return _loss, None


</source>
<source file="systems/TensorLayer-2.2.4/examples/quantized_net/tutorial_dorefanet_cifar10_tfrecord.py" startline="136" endline="148" pcid="936">
def _train_step(network, X_batch, y_batch, cost, train_op=tf.optimizers.Adam(learning_rate=0.0001), acc=None):
    with tf.GradientTape() as tape:
        y_pred = network(X_batch)
        _loss = cost(y_pred, y_batch)
    grad = tape.gradient(_loss, network.trainable_weights)
    train_op.apply_gradients(zip(grad, network.trainable_weights))
    if acc is not None:
        _acc = acc(y_pred, y_batch)
        return _loss, _acc
    else:
        return _loss, None


</source>
<source file="systems/TensorLayer-2.2.4/examples/quantized_net/tutorial_binarynet_mnist_cnn.py" startline="45" endline="57" pcid="942">
def _train_step(network, X_batch, y_batch, cost, train_op=tf.optimizers.Adam(learning_rate=0.0001), acc=None):
    with tf.GradientTape() as tape:
        y_pred = network(X_batch)
        _loss = cost(y_pred, y_batch)
    grad = tape.gradient(_loss, network.trainable_weights)
    train_op.apply_gradients(zip(grad, network.trainable_weights))
    if acc is not None:
        _acc = acc(y_pred, y_batch)
        return _loss, _acc
    else:
        return _loss, None


</source>
<source file="systems/TensorLayer-2.2.4/examples/quantized_net/tutorial_quanconv_mnist.py" startline="51" endline="63" pcid="939">
def _train_step(network, X_batch, y_batch, cost, train_op=tf.optimizers.Adam(learning_rate=0.0001), acc=None):
    with tf.GradientTape() as tape:
        y_pred = network(X_batch)
        _loss = cost(y_pred, y_batch)
    grad = tape.gradient(_loss, network.trainable_weights)
    train_op.apply_gradients(zip(grad, network.trainable_weights))
    if acc is not None:
        _acc = acc(y_pred, y_batch)
        return _loss, _acc
    else:
        return _loss, None


</source>
<source file="systems/TensorLayer-2.2.4/examples/quantized_net/tutorial_ternaryweight_cifar10_tfrecord.py" startline="142" endline="154" pcid="923">
def _train_step(network, X_batch, y_batch, cost, train_op=tf.optimizers.Adam(learning_rate=0.0001), acc=None):
    with tf.GradientTape() as tape:
        y_pred = network(X_batch)
        _loss = cost(y_pred, y_batch)
    grad = tape.gradient(_loss, network.trainable_weights)
    train_op.apply_gradients(zip(grad, network.trainable_weights))
    if acc is not None:
        _acc = acc(y_pred, y_batch)
        return _loss, _acc
    else:
        return _loss, None


</source>
<source file="systems/TensorLayer-2.2.4/examples/quantized_net/tutorial_binarynet_cifar10_tfrecord.py" startline="143" endline="155" pcid="949">
def _train_step(network, X_batch, y_batch, cost, train_op=tf.optimizers.Adam(learning_rate=0.0001), acc=None):
    with tf.GradientTape() as tape:
        y_pred = network(X_batch)
        _loss = cost(y_pred, y_batch)
    grad = tape.gradient(_loss, network.trainable_weights)
    train_op.apply_gradients(zip(grad, network.trainable_weights))
    if acc is not None:
        _acc = acc(y_pred, y_batch)
        return _loss, _acc
    else:
        return _loss, None


</source>
</class>

<class classid="39" nclones="3" nlines="15" similarity="77">
<source file="systems/TensorLayer-2.2.4/examples/quantized_net/tutorial_ternaryweight_mnist_cnn.py" startline="20" endline="40" pcid="925">
def model(inputs_shape, n_class=10):
    in_net = Input(inputs_shape, name='input')
    net = TernaryConv2d(32, (5, 5), (1, 1), padding='SAME', b_init=None, name='bcnn1')(in_net)
    net = MaxPool2d((2, 2), (2, 2), padding='SAME', name='pool1')(net)
    net = BatchNorm(act=tl.act.htanh, name='bn1')(net)

    net = TernaryConv2d(64, (5, 5), (1, 1), padding='SAME', b_init=None, name='bcnn2')(net)
    net = MaxPool2d((2, 2), (2, 2), padding='SAME', name='pool2')(net)
    net = BatchNorm(act=tl.act.htanh, name='bn2')(net)

    net = Flatten('flatten')(net)
    net = Dense(256, b_init=None, name='dense')(net)
    net = BatchNorm(act=tl.act.htanh, name='bn3')(net)

    net = TernaryDense(n_class, b_init=None, name='bout')(net)
    net = BatchNorm(name='bno')(net)

    net = Model(inputs=in_net, outputs=net, name='dorefanet')
    return net


</source>
<source file="systems/TensorLayer-2.2.4/examples/quantized_net/tutorial_dorefanet_mnist_cnn.py" startline="20" endline="39" pcid="928">
def model(inputs_shape, n_class=10):
    in_net = Input(inputs_shape, name='input')
    net = DorefaConv2d(1, 3, 32, (5, 5), (1, 1), padding='SAME', b_init=None, name='bcnn1')(in_net)
    net = MaxPool2d((2, 2), (2, 2), padding='SAME', name='pool1')(net)
    net = BatchNorm(act=tl.act.htanh, name='bn1')(net)

    net = DorefaConv2d(1, 3, 64, (5, 5), (1, 1), padding='SAME', b_init=None, name='bcnn2')(net)
    net = MaxPool2d((2, 2), (2, 2), padding='SAME', name='pool2')(net)
    net = BatchNorm(act=tl.act.htanh, name='bn2')(net)

    net = Flatten('flatten')(net)
    net = DorefaDense(1, 3, 256, b_init=None, name='dense')(net)
    net = BatchNorm(act=tl.act.htanh, name='bn3')(net)

    net = Dense(n_class, b_init=None, name='bout')(net)
    net = BatchNorm(name='bno')(net)
    net = Model(inputs=in_net, outputs=net, name='dorefanet')
    return net


</source>
<source file="systems/TensorLayer-2.2.4/examples/quantized_net/tutorial_binarynet_mnist_cnn.py" startline="20" endline="44" pcid="941">
def model(inputs_shape, n_class=10):
    # In BNN, all the layers inputs are binary, with the exception of the first layer.
    # ref: https://github.com/itayhubara/BinaryNet.tf/blob/master/models/BNN_cifar10.py
    net_in = Input(inputs_shape, name='input')
    net = BinaryConv2d(32, (5, 5), (1, 1), padding='SAME', b_init=None, name='bcnn1')(net_in)
    net = MaxPool2d((2, 2), (2, 2), padding='SAME', name='pool1')(net)
    net = BatchNorm(act=tl.act.htanh, name='bn1')(net)

    net = Sign("sign1")(net)
    net = BinaryConv2d(64, (5, 5), (1, 1), padding='SAME', b_init=None, name='bcnn2')(net)
    net = MaxPool2d((2, 2), (2, 2), padding='SAME', name='pool2')(net)
    net = BatchNorm(act=tl.act.htanh, name='bn2')(net)

    net = Flatten('ft')(net)
    net = Sign("sign2")(net)
    net = BinaryDense(256, b_init=None, name='dense')(net)
    net = BatchNorm(act=tl.act.htanh, name='bn3')(net)

    net = Sign("sign3")(net)
    net = BinaryDense(10, b_init=None, name='bout')(net)
    net = BatchNorm(name='bno')(net)
    net = Model(inputs=net_in, outputs=net, name='binarynet')
    return net


</source>
</class>

<class classid="40" nclones="4" nlines="19" similarity="78">
<source file="systems/TensorLayer-2.2.4/tensorlayer/cost.py" startline="548" endline="595" pcid="1054">
# Regularization Functions
def li_regularizer(scale, scope=None):
    """Li regularization removes the neurons of previous layer. The `i` represents `inputs`.
    Returns a function that can be used to apply group li regularization to weights.
    The implementation follows `TensorFlow contrib <https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/regularizers.py>`__.

    Parameters
    ----------
    scale : float
        A scalar multiplier `Tensor`. 0.0 disables the regularizer.
    scope: str
        An optional scope name for this function.

    Returns
    --------
    A function with signature `li(weights, name=None)` that apply Li regularization.

    Raises
    ------
    ValueError : if scale is outside of the range [0.0, 1.0] or if scale is not a float.

    """
    if isinstance(scale, numbers.Integral):
        raise ValueError('scale cannot be an integer: %s' % scale)
    if isinstance(scale, numbers.Real):
        if scale < 0.:
            raise ValueError('Setting a scale less than 0 on a regularizer: %g' % scale)
        if scale >= 1.:
            raise ValueError('Setting a scale greater than 1 on a regularizer: %g' % scale)
        if scale == 0.:
            logging.info('Scale of 0 disables regularizer.')
            return lambda _, name=None: None

    def li(weights):
        """Applies li regularization to weights."""
        with tf.name_scope('li_regularizer') as scope:
            my_scale = ops.convert_to_tensor(scale, dtype=weights.dtype.base_dtype, name='scale')
            # if tf.__version__ <= '0.12':
            #     standard_ops_fn = standard_ops.mul
            # else:
            standard_ops_fn = standard_ops.multiply
            return standard_ops_fn(
                my_scale, standard_ops.reduce_sum(standard_ops.sqrt(standard_ops.reduce_sum(tf.square(weights), 1))),
                name=scope
            )

    return li

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/cost.py" startline="596" endline="642" pcid="1056">

def lo_regularizer(scale):
    """Lo regularization removes the neurons of current layer. The `o` represents `outputs`
    Returns a function that can be used to apply group lo regularization to weights.
    The implementation follows `TensorFlow contrib <https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/regularizers.py>`__.

    Parameters
    ----------
    scale : float
        A scalar multiplier `Tensor`. 0.0 disables the regularizer.

    Returns
    -------
    A function with signature `lo(weights, name=None)` that apply Lo regularization.

    Raises
    ------
    ValueError : If scale is outside of the range [0.0, 1.0] or if scale is not a float.

    """
    if isinstance(scale, numbers.Integral):
        raise ValueError('scale cannot be an integer: %s' % scale)

    if isinstance(scale, numbers.Real):
        if scale < 0.:
            raise ValueError('Setting a scale less than 0 on a regularizer: %g' % scale)
        if scale >= 1.:
            raise ValueError('Setting a scale greater than 1 on a regularizer: %g' % scale)
        if scale == 0.:
            logging.info('Scale of 0 disables regularizer.')
            return lambda _, name=None: None

    def lo(weights, name='lo_regularizer'):
        """Applies group column regularization to weights."""
        with tf.name_scope(name) as scope:
            my_scale = ops.convert_to_tensor(scale, dtype=weights.dtype.base_dtype, name='scale')
            # if tf.__version__ <= '0.12':
            #     standard_ops_fn = standard_ops.mul
            # else:
            standard_ops_fn = standard_ops.multiply
            return standard_ops_fn(
                my_scale, standard_ops.reduce_sum(standard_ops.sqrt(standard_ops.reduce_sum(tf.square(weights), 0))),
                name=scope
            )

    return lo

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/cost.py" startline="736" endline="782" pcid="1062">

def maxnorm_i_regularizer(scale):
    """Max-norm input regularization removes the neurons of previous layer.
    Returns a function that can be used to apply max-norm regularization to each row of weight matrix.
    The implementation follows `TensorFlow contrib <https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/regularizers.py>`__.

    Parameters
    ----------
    scale : float
        A scalar multiplier `Tensor`. 0.0 disables the regularizer.

    Returns
    ---------
    A function with signature `mn_i(weights, name=None)` that apply Lo regularization.

    Raises
    ---------
    ValueError : If scale is outside of the range [0.0, 1.0] or if scale is not a float.

    """
    if isinstance(scale, numbers.Integral):
        raise ValueError('scale cannot be an integer: %s' % scale)

    if isinstance(scale, numbers.Real):
        if scale < 0.:
            raise ValueError('Setting a scale less than 0 on a regularizer: %g' % scale)
        # if scale >= 1.:
        #   raise ValueError('Setting a scale greater than 1 on a regularizer: %g' %
        #                    scale)
        if scale == 0.:
            logging.info('Scale of 0 disables regularizer.')
            return lambda _, name=None: None

    def mn_i(weights, name='maxnorm_i_regularizer'):
        """Applies max-norm regularization to weights."""
        with tf.name_scope(name) as scope:
            my_scale = ops.convert_to_tensor(scale, dtype=weights.dtype.base_dtype, name='scale')
            if tf.__version__ <= '0.12':
                standard_ops_fn = standard_ops.mul
            else:
                standard_ops_fn = standard_ops.multiply
            return standard_ops_fn(
                my_scale, standard_ops.reduce_sum(standard_ops.reduce_max(standard_ops.abs(weights), 1)), name=scope
            )

    return mn_i

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/cost.py" startline="689" endline="735" pcid="1060">

def maxnorm_o_regularizer(scale):
    """Max-norm output regularization removes the neurons of current layer.
    Returns a function that can be used to apply max-norm regularization to each column of weight matrix.
    The implementation follows `TensorFlow contrib <https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/regularizers.py>`__.

    Parameters
    ----------
    scale : float
        A scalar multiplier `Tensor`. 0.0 disables the regularizer.

    Returns
    ---------
    A function with signature `mn_o(weights, name=None)` that apply Lo regularization.

    Raises
    ---------
    ValueError : If scale is outside of the range [0.0, 1.0] or if scale is not a float.

    """
    if isinstance(scale, numbers.Integral):
        raise ValueError('scale cannot be an integer: %s' % scale)

    if isinstance(scale, numbers.Real):
        if scale < 0.:
            raise ValueError('Setting a scale less than 0 on a regularizer: %g' % scale)
        # if scale >= 1.:
        #   raise ValueError('Setting a scale greater than 1 on a regularizer: %g' %
        #                    scale)
        if scale == 0.:
            logging.info('Scale of 0 disables regularizer.')
            return lambda _, name=None: None

    def mn_o(weights, name='maxnorm_o_regularizer'):
        """Applies max-norm regularization to weights."""
        with tf.name_scope(name) as scope:
            my_scale = ops.convert_to_tensor(scale, dtype=weights.dtype.base_dtype, name='scale')
            if tf.__version__ <= '0.12':
                standard_ops_fn = standard_ops.mul
            else:
                standard_ops_fn = standard_ops.multiply
            return standard_ops_fn(
                my_scale, standard_ops.reduce_sum(standard_ops.reduce_max(standard_ops.abs(weights), 0)), name=scope
            )

    return mn_o

</source>
</class>

<class classid="41" nclones="2" nlines="10" similarity="100">
<source file="systems/TensorLayer-2.2.4/tensorlayer/models/vgg.py" startline="199" endline="260" pcid="1106">
def vgg16(pretrained=False, end_with='outputs', mode='dynamic', name=None):
    """Pre-trained VGG16 model.

    Parameters
    ------------
    pretrained : boolean
        Whether to load pretrained weights. Default False.
    end_with : str
        The end point of the model. Default ``fc3_relu`` i.e. the whole model.
    mode : str.
        Model building mode, 'dynamic' or 'static'. Default 'dynamic'.
    name : None or str
        A unique layer name.

    Examples
    ---------
    Classify ImageNet classes with VGG16, see `tutorial_models_vgg.py <https://github.com/tensorlayer/tensorlayer/blob/master/example/tutorial_models_vgg.py>`__
    With TensorLayer

    >>> # get the whole model, without pre-trained VGG parameters
    >>> vgg = tl.models.vgg16()
    >>> # get the whole model, restore pre-trained VGG parameters
    >>> vgg = tl.models.vgg16(pretrained=True)
    >>> # use for inferencing
    >>> output = vgg(img, is_train=False)
    >>> probs = tf.nn.softmax(output)[0].numpy()

    Extract features with VGG16 and Train a classifier with 100 classes

    >>> # get VGG without the last layer
    >>> cnn = tl.models.vgg16(end_with='fc2_relu', mode='static').as_layer()
    >>> # add one more layer and build a new model
    >>> ni = Input([None, 224, 224, 3], name="inputs")
    >>> nn = cnn(ni)
    >>> nn = tl.layers.Dense(n_units=100, name='out')(nn)
    >>> model = tl.models.Model(inputs=ni, outputs=nn)
    >>> # train your own classifier (only update the last layer)
    >>> train_params = model.get_layer('out').trainable_weights

    Reuse model

    >>> # in dynamic model, we can directly use the same model
    >>> # in static model
    >>> vgg_layer = tl.models.vgg16().as_layer()
    >>> ni_1 = tl.layers.Input([None, 224, 244, 3])
    >>> ni_2 = tl.layers.Input([None, 224, 244, 3])
    >>> a_1 = vgg_layer(ni_1)
    >>> a_2 = vgg_layer(ni_2)
    >>> M = Model(inputs=[ni_1, ni_2], outputs=[a_1, a_2])

    """
    if mode == 'dynamic':
        model = VGG(layer_type='vgg16', batch_norm=False, end_with=end_with, name=name)
    elif mode == 'static':
        model = VGG_static(layer_type='vgg16', batch_norm=False, end_with=end_with, name=name)
    else:
        raise Exception("No such mode %s" % mode)
    if pretrained:
        restore_model(model, layer_type='vgg16')
    return model


</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/models/vgg.py" startline="261" endline="322" pcid="1107">
def vgg19(pretrained=False, end_with='outputs', mode='dynamic', name=None):
    """Pre-trained VGG19 model.

    Parameters
    ------------
    pretrained : boolean
        Whether to load pretrained weights. Default False.
    end_with : str
        The end point of the model. Default ``fc3_relu`` i.e. the whole model.
    mode : str.
        Model building mode, 'dynamic' or 'static'. Default 'dynamic'.
    name : None or str
        A unique layer name.

    Examples
    ---------
    Classify ImageNet classes with VGG19, see `tutorial_models_vgg.py <https://github.com/tensorlayer/tensorlayer/blob/master/example/tutorial_models_vgg.py>`__
    With TensorLayer

    >>> # get the whole model, without pre-trained VGG parameters
    >>> vgg = tl.models.vgg19()
    >>> # get the whole model, restore pre-trained VGG parameters
    >>> vgg = tl.models.vgg19(pretrained=True)
    >>> # use for inferencing
    >>> output = vgg(img, is_train=False)
    >>> probs = tf.nn.softmax(output)[0].numpy()

    Extract features with VGG19 and Train a classifier with 100 classes

    >>> # get VGG without the last layer
    >>> cnn = tl.models.vgg19(end_with='fc2_relu', mode='static').as_layer()
    >>> # add one more layer and build a new model
    >>> ni = Input([None, 224, 224, 3], name="inputs")
    >>> nn = cnn(ni)
    >>> nn = tl.layers.Dense(n_units=100, name='out')(nn)
    >>> model = tl.models.Model(inputs=ni, outputs=nn)
    >>> # train your own classifier (only update the last layer)
    >>> train_params = model.get_layer('out').trainable_weights

    Reuse model

    >>> # in dynamic model, we can directly use the same model
    >>> # in static model
    >>> vgg_layer = tl.models.vgg19().as_layer()
    >>> ni_1 = tl.layers.Input([None, 224, 244, 3])
    >>> ni_2 = tl.layers.Input([None, 224, 244, 3])
    >>> a_1 = vgg_layer(ni_1)
    >>> a_2 = vgg_layer(ni_2)
    >>> M = Model(inputs=[ni_1, ni_2], outputs=[a_1, a_2])

    """
    if mode == 'dynamic':
        model = VGG(layer_type='vgg19', batch_norm=False, end_with=end_with, name=name)
    elif mode == 'static':
        model = VGG_static(layer_type='vgg19', batch_norm=False, end_with=end_with, name=name)
    else:
        raise Exception("No such mode %s" % mode)
    if pretrained:
        restore_model(model, layer_type='vgg19')
    return model


</source>
</class>

<class classid="42" nclones="2" nlines="20" similarity="80">
<source file="systems/TensorLayer-2.2.4/tensorlayer/optimizers/amsgrad.py" startline="79" endline="106" pcid="1160">
    def _apply_dense(self, grad, var):
        beta1_power = math_ops.cast(self._beta1_power, var.dtype.base_dtype)
        beta2_power = math_ops.cast(self._beta2_power, var.dtype.base_dtype)
        lr_t = math_ops.cast(self._lr_t, var.dtype.base_dtype)
        beta1_t = math_ops.cast(self._beta1_t, var.dtype.base_dtype)
        beta2_t = math_ops.cast(self._beta2_t, var.dtype.base_dtype)
        epsilon_t = math_ops.cast(self._epsilon_t, var.dtype.base_dtype)

        lr = (lr_t * math_ops.sqrt(1 - beta2_power) / (1 - beta1_power))

        # m_t = beta1 * m + (1 - beta1) * g_t
        m = self.get_slot(var, "m")
        m_scaled_g_values = grad * (1 - beta1_t)
        m_t = state_ops.assign(m, beta1_t * m + m_scaled_g_values, use_locking=self._use_locking)

        # v_t = beta2 * v + (1 - beta2) * (g_t * g_t)
        v = self.get_slot(var, "v")
        v_scaled_g_values = (grad * grad) * (1 - beta2_t)
        v_t = state_ops.assign(v, beta2_t * v + v_scaled_g_values, use_locking=self._use_locking)

        # amsgrad
        vhat = self.get_slot(var, "vhat")
        vhat_t = state_ops.assign(vhat, math_ops.maximum(v_t, vhat))
        v_sqrt = math_ops.sqrt(vhat_t)

        var_update = state_ops.assign_sub(var, lr * m_t / (v_sqrt + epsilon_t), use_locking=self._use_locking)
        return control_flow_ops.group(*[var_update, m_t, v_t, vhat_t])

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/optimizers/amsgrad.py" startline="107" endline="135" pcid="1161">
    def _resource_apply_dense(self, grad, var):
        var = var.handle
        beta1_power = math_ops.cast(self._beta1_power, grad.dtype.base_dtype)
        beta2_power = math_ops.cast(self._beta2_power, grad.dtype.base_dtype)
        lr_t = math_ops.cast(self._lr_t, grad.dtype.base_dtype)
        beta1_t = math_ops.cast(self._beta1_t, grad.dtype.base_dtype)
        beta2_t = math_ops.cast(self._beta2_t, grad.dtype.base_dtype)
        epsilon_t = math_ops.cast(self._epsilon_t, grad.dtype.base_dtype)

        lr = (lr_t * math_ops.sqrt(1 - beta2_power) / (1 - beta1_power))

        # m_t = beta1 * m + (1 - beta1) * g_t
        m = self.get_slot(var, "m").handle
        m_scaled_g_values = grad * (1 - beta1_t)
        m_t = state_ops.assign(m, beta1_t * m + m_scaled_g_values, use_locking=self._use_locking)

        # v_t = beta2 * v + (1 - beta2) * (g_t * g_t)
        v = self.get_slot(var, "v").handle
        v_scaled_g_values = (grad * grad) * (1 - beta2_t)
        v_t = state_ops.assign(v, beta2_t * v + v_scaled_g_values, use_locking=self._use_locking)

        # amsgrad
        vhat = self.get_slot(var, "vhat").handle
        vhat_t = state_ops.assign(vhat, math_ops.maximum(v_t, vhat))
        v_sqrt = math_ops.sqrt(vhat_t)

        var_update = state_ops.assign_sub(var, lr * m_t / (v_sqrt + epsilon_t), use_locking=self._use_locking)
        return control_flow_ops.group(*[var_update, m_t, v_t, vhat_t])

</source>
</class>

<class classid="43" nclones="2" nlines="32" similarity="84">
<source file="systems/TensorLayer-2.2.4/tensorlayer/visualize.py" startline="403" endline="463" pcid="1194">
def CNN2d(CNN=None, second=10, saveable=True, name='cnn', fig_idx=3119362):
    """Display a group of RGB or Greyscale CNN masks.

    Parameters
    ----------
    CNN : numpy.array
        The image. e.g: 64 5x5 RGB images can be (5, 5, 3, 64).
    second : int
        The display second(s) for the image(s), if saveable is False.
    saveable : boolean
        Save or plot the figure.
    name : str
        A name to save the image, if saveable is True.
    fig_idx : int
        The matplotlib figure index.

    Examples
    --------
    >>> tl.visualize.CNN2d(network.all_params[0].eval(), second=10, saveable=True, name='cnn1_mnist', fig_idx=2012)

    """
    import matplotlib.pyplot as plt
    # tl.logging.info(CNN.shape)    # (5, 5, 3, 64)
    # exit()
    n_mask = CNN.shape[3]
    n_row = CNN.shape[0]
    n_col = CNN.shape[1]
    n_color = CNN.shape[2]
    row = int(np.sqrt(n_mask))
    col = int(np.ceil(n_mask / row))
    plt.ion()  # active mode
    fig = plt.figure(fig_idx)
    count = 1
    for _ir in range(1, row + 1):
        for _ic in range(1, col + 1):
            if count > n_mask:
                break
            fig.add_subplot(col, row, count)
            # tl.logging.info(CNN[:,:,:,count-1].shape, n_row, n_col)   # (5, 1, 32) 5 5
            # exit()
            # plt.imshow(
            #         np.reshape(CNN[count-1,:,:,:], (n_row, n_col)),
            #         cmap='gray', interpolation="nearest")     # theano
            if n_color == 1:
                plt.imshow(np.reshape(CNN[:, :, :, count - 1], (n_row, n_col)), cmap='gray', interpolation="nearest")
            elif n_color == 3:
                plt.imshow(
                    np.reshape(CNN[:, :, :, count - 1], (n_row, n_col, n_color)), cmap='gray', interpolation="nearest"
                )
            else:
                raise Exception("Unknown n_color")
            plt.gca().xaxis.set_major_locator(plt.NullLocator())  # distable tick
            plt.gca().yaxis.set_major_locator(plt.NullLocator())
            count = count + 1
    if saveable:
        plt.savefig(name + '.pdf', format='pdf')
    else:
        plt.draw()
        plt.pause(second)


</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/visualize.py" startline="464" endline="528" pcid="1195">
def images2d(images=None, second=10, saveable=True, name='images', dtype=None, fig_idx=3119362):
    """Display a group of RGB or Greyscale images.

    Parameters
    ----------
    images : numpy.array
        The images.
    second : int
        The display second(s) for the image(s), if saveable is False.
    saveable : boolean
        Save or plot the figure.
    name : str
        A name to save the image, if saveable is True.
    dtype : None or numpy data type
        The data type for displaying the images.
    fig_idx : int
        matplotlib figure index.

    Examples
    --------
    >>> X_train, y_train, X_test, y_test = tl.files.load_cifar10_dataset(shape=(-1, 32, 32, 3), plotable=False)
    >>> tl.visualize.images2d(X_train[0:100,:,:,:], second=10, saveable=False, name='cifar10', dtype=np.uint8, fig_idx=20212)

    """
    import matplotlib.pyplot as plt
    # tl.logging.info(images.shape)    # (50000, 32, 32, 3)
    # exit()
    if dtype:
        images = np.asarray(images, dtype=dtype)
    n_mask = images.shape[0]
    n_row = images.shape[1]
    n_col = images.shape[2]
    n_color = images.shape[3]
    row = int(np.sqrt(n_mask))
    col = int(np.ceil(n_mask / row))
    plt.ion()  # active mode
    fig = plt.figure(fig_idx)
    count = 1
    for _ir in range(1, row + 1):
        for _ic in range(1, col + 1):
            if count > n_mask:
                break
            fig.add_subplot(col, row, count)
            # tl.logging.info(images[:,:,:,count-1].shape, n_row, n_col)   # (5, 1, 32) 5 5
            # plt.imshow(
            #         np.reshape(images[count-1,:,:,:], (n_row, n_col)),
            #         cmap='gray', interpolation="nearest")     # theano
            if n_color == 1:
                plt.imshow(np.reshape(images[count - 1, :, :], (n_row, n_col)), cmap='gray', interpolation="nearest")
                # plt.title(name)
            elif n_color == 3:
                plt.imshow(images[count - 1, :, :], cmap='gray', interpolation="nearest")
                # plt.title(name)
            else:
                raise Exception("Unknown n_color")
            plt.gca().xaxis.set_major_locator(plt.NullLocator())  # distable tick
            plt.gca().yaxis.set_major_locator(plt.NullLocator())
            count = count + 1
    if saveable:
        plt.savefig(name + '.pdf', format='pdf')
    else:
        plt.draw()
        plt.pause(second)


</source>
</class>

<class classid="44" nclones="2" nlines="18" similarity="77">
<source file="systems/TensorLayer-2.2.4/tensorlayer/db.py" startline="111" endline="170" pcid="1237">
    def save_model(self, network=None, model_name='model', **kwargs):
        """Save model architecture and parameters into database, timestamp will be added automatically.

        Parameters
        ----------
        network : TensorLayer Model
            TensorLayer Model instance.
        model_name : str
            The name/key of model.
        kwargs : other events
            Other events, such as name, accuracy, loss, step number and etc (optinal).

        Examples
        ---------
        Save model architecture and parameters into database.
        >>> db.save_model(net, accuracy=0.8, loss=2.3, name='second_model')

        Load one model with parameters from database (run this in other script)
        >>> net = db.find_top_model(accuracy=0.8, loss=2.3)

        Find and load the latest model.
        >>> net = db.find_top_model(sort=[("time", pymongo.DESCENDING)])
        >>> net = db.find_top_model(sort=[("time", -1)])

        Find and load the oldest model.
        >>> net = db.find_top_model(sort=[("time", pymongo.ASCENDING)])
        >>> net = db.find_top_model(sort=[("time", 1)])

        Get model information
        >>> net._accuracy
        ... 0.8

        Returns
        ---------
        boolean : True for success, False for fail.
        """
        kwargs.update({'model_name': model_name})
        self._fill_project_info(kwargs)  # put project_name into kwargs

        # params = network.get_all_params()
        params = network.all_weights

        s = time.time()

        # kwargs.update({'architecture': network.all_graphs, 'time': datetime.utcnow()})
        kwargs.update({'architecture': network.config, 'time': datetime.utcnow()})

        try:
            params_id = self.model_fs.put(self._serialization(params))
            kwargs.update({'params_id': params_id, 'time': datetime.utcnow()})
            self.db.Model.insert_one(kwargs)
            print("[Database] Save model: SUCCESS, took: {}s".format(round(time.time() - s, 2)))
            return True
        except Exception as e:
            exc_type, exc_obj, exc_tb = sys.exc_info()
            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]
            logging.info("{}  {}  {}  {}  {}".format(exc_type, exc_obj, fname, exc_tb.tb_lineno, e))
            print("[Database] Save model: FAIL")
            return False

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/db.py" startline="258" endline="301" pcid="1240">
    def save_dataset(self, dataset=None, dataset_name=None, **kwargs):
        """Saves one dataset into database, timestamp will be added automatically.

        Parameters
        ----------
        dataset : any type
            The dataset you want to store.
        dataset_name : str
            The name of dataset.
        kwargs : other events
            Other events, such as description, author and etc (optinal).

        Examples
        ----------
        Save dataset
        >>> db.save_dataset([X_train, y_train, X_test, y_test], 'mnist', description='this is a tutorial')

        Get dataset
        >>> dataset = db.find_top_dataset('mnist')

        Returns
        ---------
        boolean : Return True if save success, otherwise, return False.
        """
        self._fill_project_info(kwargs)
        if dataset_name is None:
            raise Exception("dataset_name is None, please give a dataset name")
        kwargs.update({'dataset_name': dataset_name})

        s = time.time()
        try:
            dataset_id = self.dataset_fs.put(self._serialization(dataset))
            kwargs.update({'dataset_id': dataset_id, 'time': datetime.utcnow()})
            self.db.Dataset.insert_one(kwargs)
            # print("[Database] Save params: {} SUCCESS, took: {}s".format(file_name, round(time.time()-s, 2)))
            print("[Database] Save dataset: SUCCESS, took: {}s".format(round(time.time() - s, 2)))
            return True
        except Exception as e:
            exc_type, exc_obj, exc_tb = sys.exc_info()
            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]
            logging.info("{}  {}  {}  {}  {}".format(exc_type, exc_obj, fname, exc_tb.tb_lineno, e))
            print("[Database] Save dataset: FAIL")
            return False

</source>
</class>

<class classid="45" nclones="2" nlines="28" similarity="70">
<source file="systems/TensorLayer-2.2.4/tensorlayer/db.py" startline="171" endline="244" pcid="1238">
    def find_top_model(self, sort=None, model_name='model', **kwargs):
        """Finds and returns a model architecture and its parameters from the database which matches the requirement.

        Parameters
        ----------
        sort : List of tuple
            PyMongo sort comment, search "PyMongo find one sorting" and `collection level operations <http://api.mongodb.com/python/current/api/pymongo/collection.html>`__ for more details.
        model_name : str or None
            The name/key of model.
        kwargs : other events
            Other events, such as name, accuracy, loss, step number and etc (optinal).

        Examples
        ---------
        - see ``save_model``.

        Returns
        ---------
        network : TensorLayer Model
            Note that, the returned network contains all information of the document (record), e.g. if you saved accuracy in the document, you can get the accuracy by using ``net._accuracy``.
        """
        # print(kwargs)   # {}
        kwargs.update({'model_name': model_name})
        self._fill_project_info(kwargs)

        s = time.time()

        d = self.db.Model.find_one(filter=kwargs, sort=sort)

        # _temp_file_name = '_find_one_model_ztemp_file'
        if d is not None:
            params_id = d['params_id']
            graphs = d['architecture']
            _datetime = d['time']
            # exists_or_mkdir(_temp_file_name, False)
            # with open(os.path.join(_temp_file_name, 'graph.pkl'), 'wb') as file:
            #     pickle.dump(graphs, file, protocol=pickle.HIGHEST_PROTOCOL)
        else:
            print("[Database] FAIL! Cannot find model: {}".format(kwargs))
            return False
        try:
            params = self._deserialization(self.model_fs.get(params_id).read())
            # TODO : restore model and load weights
            network = static_graph2net(graphs)
            assign_weights(weights=params, network=network)
            # np.savez(os.path.join(_temp_file_name, 'params.npz'), params=params)
            #
            # network = load_graph_and_params(name=_temp_file_name, sess=sess)
            # del_folder(_temp_file_name)

            pc = self.db.Model.find(kwargs)
            print(
                "[Database] Find one model SUCCESS. kwargs:{} sort:{} save time:{} took: {}s".format(
                    kwargs, sort, _datetime, round(time.time() - s, 2)
                )
            )

            # FIXME : not sure what's this for
            # put all informations of model into the TL layer
            # for key in d:
            #     network.__dict__.update({"_%s" % key: d[key]})

            # check whether more parameters match the requirement
            params_id_list = pc.distinct('params_id')
            n_params = len(params_id_list)
            if n_params != 1:
                print("     Note that there are {} models match the kwargs".format(n_params))
            return network
        except Exception as e:
            exc_type, exc_obj, exc_tb = sys.exc_info()
            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]
            logging.info("{}  {}  {}  {}  {}".format(exc_type, exc_obj, fname, exc_tb.tb_lineno, e))
            return False

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/db.py" startline="302" endline="360" pcid="1241">
    def find_top_dataset(self, dataset_name=None, sort=None, **kwargs):
        """Finds and returns a dataset from the database which matches the requirement.

        Parameters
        ----------
        dataset_name : str
            The name of dataset.
        sort : List of tuple
            PyMongo sort comment, search "PyMongo find one sorting" and `collection level operations <http://api.mongodb.com/python/current/api/pymongo/collection.html>`__ for more details.
        kwargs : other events
            Other events, such as description, author and etc (optinal).

        Examples
        ---------
        Save dataset
        >>> db.save_dataset([X_train, y_train, X_test, y_test], 'mnist', description='this is a tutorial')

        Get dataset
        >>> dataset = db.find_top_dataset('mnist')
        >>> datasets = db.find_datasets('mnist')

        Returns
        --------
        dataset : the dataset or False
            Return False if nothing found.

        """

        self._fill_project_info(kwargs)
        if dataset_name is None:
            raise Exception("dataset_name is None, please give a dataset name")
        kwargs.update({'dataset_name': dataset_name})

        s = time.time()

        d = self.db.Dataset.find_one(filter=kwargs, sort=sort)

        if d is not None:
            dataset_id = d['dataset_id']
        else:
            print("[Database] FAIL! Cannot find dataset: {}".format(kwargs))
            return False
        try:
            dataset = self._deserialization(self.dataset_fs.get(dataset_id).read())
            pc = self.db.Dataset.find(kwargs)
            print("[Database] Find one dataset SUCCESS, {} took: {}s".format(kwargs, round(time.time() - s, 2)))

            # check whether more datasets match the requirement
            dataset_id_list = pc.distinct('dataset_id')
            n_dataset = len(dataset_id_list)
            if n_dataset != 1:
                print("     Note that there are {} datasets match the requirement".format(n_dataset))
            return dataset
        except Exception as e:
            exc_type, exc_obj, exc_tb = sys.exc_info()
            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]
            logging.info("{}  {}  {}  {}  {}".format(exc_type, exc_obj, fname, exc_tb.tb_lineno, e))
            return False

</source>
</class>

<class classid="46" nclones="2" nlines="14" similarity="71">
<source file="systems/TensorLayer-2.2.4/tensorlayer/prepro.py" startline="728" endline="766" pcid="1270">
    Examples
    ---------
    >>> x --> [row, col, 1]
    >>> x = tl.prepro.rotation(x, rg=40, is_random=False)
    >>> tl.vis.save_image(x, 'im.png')

    """
    if is_random:
        theta = np.pi / 180 * np.random.uniform(-rg, rg)
    else:
        theta = np.pi / 180 * rg
    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0], [np.sin(theta), np.cos(theta), 0], [0, 0, 1]])

    h, w = x.shape[row_index], x.shape[col_index]
    transform_matrix = transform_matrix_offset_center(rotation_matrix, h, w)
    x = affine_transform(x, transform_matrix, channel_index, fill_mode, cval, order)
    return x


def rotation_multi(
    x, rg=20, is_random=False, row_index=0, col_index=1, channel_index=2, fill_mode='nearest', cval=0., order=1
):
    """Rotate multiple images with the same arguments, randomly or non-randomly.
    Usually be used for image segmentation which x=[X, Y], X and Y should be matched.

    Parameters
    -----------
    x : list of numpy.array
        List of images with dimension of [n_images, row, col, channel] (default).
    others : args
        See ``tl.prepro.rotation``.

    Returns
    -------
    numpy.array
        A list of processed images.

    Examples
    --------
</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/prepro.py" startline="1063" endline="1095" pcid="1278">
        A processed image.

    References
    -----------
    - `Affine transformation <https://uk.mathworks.com/discovery/affine-transformation.html>`__

    """
    if is_random:
        shear = np.random.uniform(-intensity, intensity)
    else:
        shear = intensity
    shear_matrix = np.array([[1, -np.sin(shear), 0], [0, np.cos(shear), 0], [0, 0, 1]])

    h, w = x.shape[row_index], x.shape[col_index]
    transform_matrix = transform_matrix_offset_center(shear_matrix, h, w)
    x = affine_transform(x, transform_matrix, channel_index, fill_mode, cval, order)
    return x


def shear_multi(
    x, intensity=0.1, is_random=False, row_index=0, col_index=1, channel_index=2, fill_mode='nearest', cval=0., order=1
):
    """Shear images with the same arguments, randomly or non-randomly.
    Usually be used for image segmentation which x=[X, Y], X and Y should be matched.

    Parameters
    -----------
    x : list of numpy.array
        List of images with dimension of [n_images, row, col, channel] (default).
    others : args
        See ``tl.prepro.shear``.

    Returns
</source>
</class>

<class classid="47" nclones="2" nlines="18" similarity="73">
<source file="systems/TensorLayer-2.2.4/tensorlayer/prepro.py" startline="1096" endline="1146" pcid="1279">
    -------
    numpy.array
        A list of processed images.

    """
    if is_random:
        shear = np.random.uniform(-intensity, intensity)
    else:
        shear = intensity
    shear_matrix = np.array([[1, -np.sin(shear), 0], [0, np.cos(shear), 0], [0, 0, 1]])

    h, w = x[0].shape[row_index], x[0].shape[col_index]
    transform_matrix = transform_matrix_offset_center(shear_matrix, h, w)
    results = []
    for data in x:
        results.append(affine_transform(data, transform_matrix, channel_index, fill_mode, cval, order))
    return np.asarray(results)


def shear2(
    x, shear=(0.1, 0.1), is_random=False, row_index=0, col_index=1, channel_index=2, fill_mode='nearest', cval=0.,
    order=1
):
    """Shear an image randomly or non-randomly.

    Parameters
    -----------
    x : numpy.array
        An image with dimension of [row, col, channel] (default).
    shear : tuple of two floats
        Percentage of shear for height and width direction (0, 1).
    is_random : boolean
        If True, randomly shear. Default is False.
    row_index col_index and channel_index : int
        Index of row, col and channel, default (0, 1, 2), for theano (1, 2, 0).
    fill_mode : str
        Method to fill missing pixel, default `nearest`, more options `constant`, `reflect` or `wrap`, see `scipy ndimage affine_transform <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.affine_transform.html>`__
    cval : float
        Value used for points outside the boundaries of the input if mode='constant'. Default is 0.0.
    order : int
        The order of interpolation. The order has to be in the range 0-5. See ``tl.prepro.affine_transform`` and `scipy ndimage affine_transform <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.affine_transform.html>`__

    Returns
    -------
    numpy.array
        A processed image.

    References
    -----------
    - `Affine transformation <https://uk.mathworks.com/discovery/affine-transformation.html>`__

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/prepro.py" startline="1147" endline="1187" pcid="1280">
    """
    if len(shear) != 2:
        raise AssertionError(
            "shear should be tuple of 2 floats, or you want to use tl.prepro.shear rather than tl.prepro.shear2 ?"
        )
    if isinstance(shear, tuple):
        shear = list(shear)
    if is_random:
        shear[0] = np.random.uniform(-shear[0], shear[0])
        shear[1] = np.random.uniform(-shear[1], shear[1])

    shear_matrix = np.array([[1, shear[0], 0], \
                            [shear[1], 1, 0], \
                            [0, 0, 1]])

    h, w = x.shape[row_index], x.shape[col_index]
    transform_matrix = transform_matrix_offset_center(shear_matrix, h, w)
    x = affine_transform(x, transform_matrix, channel_index, fill_mode, cval, order)
    return x


def shear_multi2(
    x, shear=(0.1, 0.1), is_random=False, row_index=0, col_index=1, channel_index=2, fill_mode='nearest', cval=0.,
    order=1
):
    """Shear images with the same arguments, randomly or non-randomly.
    Usually be used for image segmentation which x=[X, Y], X and Y should be matched.

    Parameters
    -----------
    x : list of numpy.array
        List of images with dimension of [n_images, row, col, channel] (default).
    others : args
        See ``tl.prepro.shear2``.

    Returns
    -------
    numpy.array
        A list of processed images.

    """
</source>
</class>

<class classid="48" nclones="2" nlines="13" similarity="71">
<source file="systems/TensorLayer-2.2.4/tensorlayer/prepro.py" startline="2029" endline="2067" pcid="1300">
    # flatx = np.reshape(x, (x.shape))
    # flatx = np.reshape(x, (x.shape[0], ))
    # tl.logging.info(flatx.shape)  # (160, 176, 1)
    whitex = np.dot(flatx, principal_components)
    x = np.reshape(whitex, (x.shape[0], x.shape[1], x.shape[2]))
    return x


# developing
# def barrel_transform(x, intensity):
#     # https://github.com/fchollet/keras/blob/master/keras/preprocessing/image.py
#     # TODO
#     pass
#
# def barrel_transform_multi(x, intensity):
#     # https://github.com/fchollet/keras/blob/master/keras/preprocessing/image.py
#     # TODO
#     pass


# channel shift
def channel_shift(x, intensity, is_random=False, channel_index=2):
    """Shift the channels of an image, randomly or non-randomly, see `numpy.rollaxis <https://docs.scipy.org/doc/numpy/reference/generated/numpy.rollaxis.html>`__.

    Parameters
    -----------
    x : numpy.array
        An image with dimension of [row, col, channel] (default).
    intensity : float
        Intensity of shifting.
    is_random : boolean
        If True, randomly shift. Default is False.
    channel_index : int
        Index of channel. Default is 2.

    Returns
    -------
    numpy.array
        A processed image.
</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/prepro.py" startline="2068" endline="2101" pcid="1301">

    """
    if is_random:
        factor = np.random.uniform(-intensity, intensity)
    else:
        factor = intensity
    x = np.rollaxis(x, channel_index, 0)
    min_x, max_x = np.min(x), np.max(x)
    channel_images = [np.clip(x_channel + factor, min_x, max_x) for x_channel in x]
    x = np.stack(channel_images, axis=0)
    x = np.rollaxis(x, 0, channel_index + 1)
    return x
    # x = np.rollaxis(x, channel_index, 0)
    # min_x, max_x = np.min(x), np.max(x)
    # channel_images = [np.clip(x_channel + np.random.uniform(-intensity, intensity), min_x, max_x)
    #                   for x_channel in x]
    # x = np.stack(channel_images, axis=0)
    # x = np.rollaxis(x, 0, channel_index+1)
    # return x


def channel_shift_multi(x, intensity, is_random=False, channel_index=2):
    """Shift the channels of images with the same arguments, randomly or non-randomly, see `numpy.rollaxis <https://docs.scipy.org/doc/numpy/reference/generated/numpy.rollaxis.html>`__.
    Usually be used for image segmentation which x=[X, Y], X and Y should be matched.

    Parameters
    -----------
    x : list of numpy.array
        List of images with dimension of [n_images, row, col, channel] (default).
    others : args
        See ``tl.prepro.channel_shift``.

    Returns
    -------
</source>
</class>

<class classid="49" nclones="3" nlines="74" similarity="76">
<source file="systems/TensorLayer-2.2.4/tensorlayer/prepro.py" startline="2828" endline="2980" pcid="1322">
        return im, coords_new
    else:
        return im, coords


# im = np.zeros([80, 100, 3])    # as an image with shape width=100, height=80
# _, coords = obj_box_imresize(im, coords=[[20, 40, 30, 30], [10, 20, 20, 20]], size=[160, 200], is_rescale=False)
# tl.logging.info(coords)
# #   [[40, 80, 60, 60], [20, 40, 40, 40]]
# _, coords = obj_box_imresize(im, coords=[[20, 40, 30, 30]], size=[40, 100], is_rescale=False)
# tl.logging.info(coords)
# #   [20, 20, 30, 15]
# _, coords = obj_box_imresize(im, coords=[[20, 40, 30, 30]], size=[60, 150], is_rescale=False)
# tl.logging.info(coords)
# #   [30, 30, 45, 22]
# im2, coords = obj_box_imresize(im, coords=[[0.2, 0.4, 0.3, 0.3]], size=[160, 200], is_rescale=True)
# tl.logging.info(coords, im2.shape)
# # [0.2, 0.4, 0.3, 0.3] (160, 200, 3)
# exit()


def obj_box_crop(
    im, classes=None, coords=None, wrg=100, hrg=100, is_rescale=False, is_center=False, is_random=False, thresh_wh=0.02,
    thresh_wh2=12.
):
    """Randomly or centrally crop an image, and compute the new bounding box coordinates.
    Objects outside the cropped image will be removed.

    Parameters
    -----------
    im : numpy.array
        An image with dimension of [row, col, channel] (default).
    classes : list of int or None
        Class IDs.
    coords : list of list of 4 int/float or None
        Coordinates [[x, y, w, h], [x, y, w, h], ...]
    wrg hrg and is_random : args
        See ``tl.prepro.crop``.
    is_rescale : boolean
        Set to True, if the input coordinates are rescaled to [0, 1]. Default is False.
    is_center : boolean, default False
        Set to True, if the x and y of coordinates are the centroid (i.e. darknet format). Default is False.
    thresh_wh : float
        Threshold, remove the box if its ratio of width(height) to image size less than the threshold.
    thresh_wh2 : float
        Threshold, remove the box if its ratio of width to height or vice verse higher than the threshold.

    Returns
    -------
    numpy.array
        A processed image
    list of int
        A list of classes
    list of list of 4 numbers
        A list of new bounding boxes.

    """
    if classes is None:
        classes = []
    if coords is None:
        coords = []

    h, w = im.shape[0], im.shape[1]

    if (h <= hrg) or (w <= wrg):
        raise AssertionError("The size of cropping should smaller than the original image")

    if is_random:
        h_offset = int(np.random.uniform(0, h - hrg) - 1)
        w_offset = int(np.random.uniform(0, w - wrg) - 1)
        h_end = hrg + h_offset
        w_end = wrg + w_offset
        im_new = im[h_offset:h_end, w_offset:w_end]
    else:  # central crop
        h_offset = int(np.floor((h - hrg) / 2.))
        w_offset = int(np.floor((w - wrg) / 2.))
        h_end = h_offset + hrg
        w_end = w_offset + wrg
        im_new = im[h_offset:h_end, w_offset:w_end]

    #              w
    #   _____________________________
    #   |  h/w offset               |
    #   |       -------             |
    # h |       |     |             |
    #   |       |     |             |
    #   |       -------             |
    #   |            h/w end        |
    #   |___________________________|

    def _get_coord(coord):
        """Input pixel-unit [x, y, w, h] format, then make sure [x, y] it is the up-left coordinates,
        before getting the new coordinates.
        Boxes outsides the cropped image will be removed.

        """
        if is_center:
            coord = obj_box_coord_centroid_to_upleft(coord)

        ##======= pixel unit format and upleft, w, h ==========##

        # x = np.clip( coord[0] - w_offset, 0, w_end - w_offset)
        # y = np.clip( coord[1] - h_offset, 0, h_end - h_offset)
        # w = np.clip( coord[2]           , 0, w_end - w_offset)
        # h = np.clip( coord[3]           , 0, h_end - h_offset)

        x = coord[0] - w_offset
        y = coord[1] - h_offset
        w = coord[2]
        h = coord[3]

        if x < 0:
            if x + w <= 0:
                return None
            w = w + x
            x = 0
        elif x > im_new.shape[1]:  # object outside the cropped image
            return None

        if y < 0:
            if y + h <= 0:
                return None
            h = h + y
            y = 0
        elif y > im_new.shape[0]:  # object outside the cropped image
            return None

        if (x is not None) and (x + w > im_new.shape[1]):  # box outside the cropped image
            w = im_new.shape[1] - x

        if (y is not None) and (y + h > im_new.shape[0]):  # box outside the cropped image
            h = im_new.shape[0] - y

        if (w / (h + 1.) > thresh_wh2) or (h / (w + 1.) > thresh_wh2):  # object shape strange: too narrow
            # tl.logging.info('xx', w, h)
            return None

        if (w / (im_new.shape[1] * 1.) < thresh_wh) or (h / (im_new.shape[0] * 1.) <
                                                        thresh_wh):  # object shape strange: too narrow
            # tl.logging.info('yy', w, im_new.shape[1], h, im_new.shape[0])
            return None

        coord = [x, y, w, h]

        ## convert back if input format is center.
        if is_center:
            coord = obj_box_coord_upleft_to_centroid(coord)

        return coord

    coords_new = list()
    classes_new = list()
    for i, _ in enumerate(coords):
</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/prepro.py" startline="2981" endline="3115" pcid="1324">
        coord = coords[i]

        if len(coord) != 4:
            raise AssertionError("coordinate should be 4 values : [x, y, w, h]")

        if is_rescale:
            # for scaled coord, upscaled before process and scale back in the end.
            coord = obj_box_coord_scale_to_pixelunit(coord, im.shape)
            coord = _get_coord(coord)
            if coord is not None:
                coord = obj_box_coord_rescale(coord, im_new.shape)
                coords_new.append(coord)
                classes_new.append(classes[i])
        else:
            coord = _get_coord(coord)
            if coord is not None:
                coords_new.append(coord)
                classes_new.append(classes[i])
    return im_new, classes_new, coords_new


def obj_box_shift(
    im, classes=None, coords=None, wrg=0.1, hrg=0.1, row_index=0, col_index=1, channel_index=2, fill_mode='nearest',
    cval=0., order=1, is_rescale=False, is_center=False, is_random=False, thresh_wh=0.02, thresh_wh2=12.
):
    """Shift an image randomly or non-randomly, and compute the new bounding box coordinates.
    Objects outside the cropped image will be removed.

    Parameters
    -----------
    im : numpy.array
        An image with dimension of [row, col, channel] (default).
    classes : list of int or None
        Class IDs.
    coords : list of list of 4 int/float or None
        Coordinates [[x, y, w, h], [x, y, w, h], ...]
    wrg, hrg row_index col_index channel_index is_random fill_mode cval and order : see ``tl.prepro.shift``.
    is_rescale : boolean
        Set to True, if the input coordinates are rescaled to [0, 1]. Default is False.
    is_center : boolean
        Set to True, if the x and y of coordinates are the centroid (i.e. darknet format). Default is False.
    thresh_wh : float
        Threshold, remove the box if its ratio of width(height) to image size less than the threshold.
    thresh_wh2 : float
        Threshold, remove the box if its ratio of width to height or vice verse higher than the threshold.


    Returns
    -------
    numpy.array
        A processed image
    list of int
        A list of classes
    list of list of 4 numbers
        A list of new bounding boxes.

    """
    if classes is None:
        classes = []
    if coords is None:
        coords = []

    imh, imw = im.shape[row_index], im.shape[col_index]

    if (hrg >= 1.0) and (hrg <= 0.) and (wrg >= 1.0) and (wrg <= 0.):
        raise AssertionError("shift range should be (0, 1)")

    if is_random:
        tx = np.random.uniform(-hrg, hrg) * imh
        ty = np.random.uniform(-wrg, wrg) * imw
    else:
        tx, ty = hrg * imh, wrg * imw
    translation_matrix = np.array([[1, 0, tx], [0, 1, ty], [0, 0, 1]])

    transform_matrix = translation_matrix  # no need to do offset
    im_new = affine_transform(im, transform_matrix, channel_index, fill_mode, cval, order)

    # modified from obj_box_crop
    def _get_coord(coord):
        """Input pixel-unit [x, y, w, h] format, then make sure [x, y] it is the up-left coordinates,
        before getting the new coordinates.
        Boxes outsides the cropped image will be removed.

        """
        if is_center:
            coord = obj_box_coord_centroid_to_upleft(coord)

        ##======= pixel unit format and upleft, w, h ==========##
        x = coord[0] - ty  # only change this
        y = coord[1] - tx  # only change this
        w = coord[2]
        h = coord[3]

        if x < 0:
            if x + w <= 0:
                return None
            w = w + x
            x = 0
        elif x > im_new.shape[1]:  # object outside the cropped image
            return None

        if y < 0:
            if y + h <= 0:
                return None
            h = h + y
            y = 0
        elif y > im_new.shape[0]:  # object outside the cropped image
            return None

        if (x is not None) and (x + w > im_new.shape[1]):  # box outside the cropped image
            w = im_new.shape[1] - x

        if (y is not None) and (y + h > im_new.shape[0]):  # box outside the cropped image
            h = im_new.shape[0] - y

        if (w / (h + 1.) > thresh_wh2) or (h / (w + 1.) > thresh_wh2):  # object shape strange: too narrow
            # tl.logging.info('xx', w, h)
            return None

        if (w / (im_new.shape[1] * 1.) < thresh_wh) or (h / (im_new.shape[0] * 1.) <
                                                        thresh_wh):  # object shape strange: too narrow
            # tl.logging.info('yy', w, im_new.shape[1], h, im_new.shape[0])
            return None

        coord = [x, y, w, h]

        ## convert back if input format is center.
        if is_center:
            coord = obj_box_coord_upleft_to_centroid(coord)

        return coord

    coords_new = list()
    classes_new = list()
    for i, _ in enumerate(coords):
</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/prepro.py" startline="3116" endline="3252" pcid="1326">
        coord = coords[i]

        if len(coord) != 4:
            raise AssertionError("coordinate should be 4 values : [x, y, w, h]")

        if is_rescale:
            # for scaled coord, upscaled before process and scale back in the end.
            coord = obj_box_coord_scale_to_pixelunit(coord, im.shape)
            coord = _get_coord(coord)
            if coord is not None:
                coord = obj_box_coord_rescale(coord, im_new.shape)
                coords_new.append(coord)
                classes_new.append(classes[i])
        else:
            coord = _get_coord(coord)
            if coord is not None:
                coords_new.append(coord)
                classes_new.append(classes[i])
    return im_new, classes_new, coords_new


def obj_box_zoom(
    im, classes=None, coords=None, zoom_range=(0.9, 1.1), row_index=0, col_index=1, channel_index=2,
    fill_mode='nearest', cval=0., order=1, is_rescale=False, is_center=False, is_random=False, thresh_wh=0.02,
    thresh_wh2=12.
):
    """Zoom in and out of a single image, randomly or non-randomly, and compute the new bounding box coordinates.
    Objects outside the cropped image will be removed.

    Parameters
    -----------
    im : numpy.array
        An image with dimension of [row, col, channel] (default).
    classes : list of int or None
        Class IDs.
    coords : list of list of 4 int/float or None
        Coordinates [[x, y, w, h], [x, y, w, h], ...].
    zoom_range row_index col_index channel_index is_random fill_mode cval and order : see ``tl.prepro.zoom``.
    is_rescale : boolean
        Set to True, if the input coordinates are rescaled to [0, 1]. Default is False.
    is_center : boolean
        Set to True, if the x and y of coordinates are the centroid. (i.e. darknet format). Default is False.
    thresh_wh : float
        Threshold, remove the box if its ratio of width(height) to image size less than the threshold.
    thresh_wh2 : float
        Threshold, remove the box if its ratio of width to height or vice verse higher than the threshold.

    Returns
    -------
    numpy.array
        A processed image
    list of int
        A list of classes
    list of list of 4 numbers
        A list of new bounding boxes.

    """
    if classes is None:
        classes = []
    if coords is None:
        coords = []

    if len(zoom_range) != 2:
        raise Exception('zoom_range should be a tuple or list of two floats. ' 'Received arg: ', zoom_range)
    if is_random:
        if zoom_range[0] == 1 and zoom_range[1] == 1:
            zx, zy = 1, 1
            tl.logging.info(" random_zoom : not zoom in/out")
        else:
            zx, zy = np.random.uniform(zoom_range[0], zoom_range[1], 2)
    else:
        zx, zy = zoom_range
    # tl.logging.info(zx, zy)
    zoom_matrix = np.array([[zx, 0, 0], [0, zy, 0], [0, 0, 1]])

    h, w = im.shape[row_index], im.shape[col_index]
    transform_matrix = transform_matrix_offset_center(zoom_matrix, h, w)
    im_new = affine_transform(im, transform_matrix, channel_index, fill_mode, cval, order)

    # modified from obj_box_crop
    def _get_coord(coord):
        """Input pixel-unit [x, y, w, h] format, then make sure [x, y] it is the up-left coordinates,
        before getting the new coordinates.
        Boxes outsides the cropped image will be removed.

        """
        if is_center:
            coord = obj_box_coord_centroid_to_upleft(coord)

        # ======= pixel unit format and upleft, w, h ==========
        x = (coord[0] - im.shape[1] / 2) / zy + im.shape[1] / 2  # only change this
        y = (coord[1] - im.shape[0] / 2) / zx + im.shape[0] / 2  # only change this
        w = coord[2] / zy  # only change this
        h = coord[3] / zx  # only change thisS

        if x < 0:
            if x + w <= 0:
                return None
            w = w + x
            x = 0
        elif x > im_new.shape[1]:  # object outside the cropped image
            return None

        if y < 0:
            if y + h <= 0:
                return None
            h = h + y
            y = 0
        elif y > im_new.shape[0]:  # object outside the cropped image
            return None

        if (x is not None) and (x + w > im_new.shape[1]):  # box outside the cropped image
            w = im_new.shape[1] - x

        if (y is not None) and (y + h > im_new.shape[0]):  # box outside the cropped image
            h = im_new.shape[0] - y

        if (w / (h + 1.) > thresh_wh2) or (h / (w + 1.) > thresh_wh2):  # object shape strange: too narrow
            # tl.logging.info('xx', w, h)
            return None

        if (w / (im_new.shape[1] * 1.) < thresh_wh) or (h / (im_new.shape[0] * 1.) <
                                                        thresh_wh):  # object shape strange: too narrow
            # tl.logging.info('yy', w, im_new.shape[1], h, im_new.shape[0])
            return None

        coord = [x, y, w, h]

        # convert back if input format is center.
        if is_center:
            coord = obj_box_coord_upleft_to_centroid(coord)

        return coord

    coords_new = list()
    classes_new = list()
    for i, _ in enumerate(coords):
</source>
</class>

<class classid="50" nclones="2" nlines="16" similarity="88">
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/embedding.py" startline="352" endline="369" pcid="1360">
    def __init__(
        self,
        vocabulary_size,
        embedding_size,
        E_init=tl.initializers.random_uniform(-0.1, 0.1),
        name=None,  #'embedding',
    ):
        super(Embedding, self).__init__(name)
        self.vocabulary_size = vocabulary_size
        self.embedding_size = embedding_size
        self.E_init = E_init

        if not self._built:
            self.build(tuple())
            self._built = True

        logging.info("Embedding %s: (%d, %d)" % (self.name, self.vocabulary_size, self.embedding_size))

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/embedding.py" startline="446" endline="466" pcid="1364">
    def __init__(
        self,
        vocabulary_size,
        embedding_size,
        pad_value=0,
        E_init=tl.initializers.random_uniform(-0.1, 0.1),
        name=None,  # 'average_embedding',
    ):

        super(AverageEmbedding, self).__init__(name)
        self.vocabulary_size = vocabulary_size
        self.embedding_size = embedding_size
        self.pad_value = pad_value
        self.E_init = E_init

        if not self._built:
            self.build(tuple())
            self._built = True

        logging.info("AverageEmbedding %s: (%d, %d)" % (self.name, self.vocabulary_size, self.embedding_size))

</source>
</class>

<class classid="51" nclones="18" nlines="33" similarity="70">
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/ternary_conv.py" startline="63" endline="106" pcid="1368">
    def __init__(
        self,
        n_filter=32,
        filter_size=(3, 3),
        strides=(1, 1),
        act=None,
        padding='SAME',
        use_gemm=False,
        data_format="channels_last",
        dilation_rate=(1, 1),
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None  # 'ternary_cnn2d',
    ):
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.use_gemm = use_gemm
        self.data_format = data_format
        self.dilation_rate = self._dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "TernaryConv2d %s: n_filter: %d filter_size: %s strides: %s pad: %s act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

        if use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        if len(self.strides) != 2:
            raise ValueError("len(strides) should be 2.")

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/dorefa_conv.py" startline="67" endline="114" pcid="1395">
    def __init__(
        self,
        bitW=1,
        bitA=3,
        n_filter=32,
        filter_size=(3, 3),
        strides=(1, 1),
        act=None,
        padding='SAME',
        use_gemm=False,
        data_format="channels_last",
        dilation_rate=(1, 1),
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None  # 'dorefa_cnn2d',
    ):
        super().__init__(name, act=act)
        self.bitW = bitW
        self.bitA = bitA
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.use_gemm = use_gemm
        self.data_format = data_format
        self.dilation_rate = self._dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "DorefaConv2d %s: n_filter: %d filter_size: %s strides: %s pad: %s act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

        if self.use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        if len(self.strides) != 2:
            raise ValueError("len(strides) should be 2.")

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/simplified_conv.py" startline="59" endline="94" pcid="1460">
    def __init__(
        self,
        n_filter=32,
        filter_size=5,
        stride=1,
        act=None,
        padding='SAME',
        data_format="channels_last",
        dilation_rate=1,
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None  # 'conv1d'
    ):
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.stride = stride
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "Conv1d %s: n_filter: %d filter_size: %s stride: %d pad: %s act: %s" % (
                self.name, n_filter, filter_size, stride, padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/group_conv.py" startline="61" endline="98" pcid="1420">
    def __init__(
        self,
        n_filter=32,
        filter_size=(3, 3),
        strides=(2, 2),
        n_group=2,
        act=None,
        padding='SAME',
        data_format='channels_last',
        dilation_rate=(1, 1),
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None  # 'groupconv',
    ):  # Windaway
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.strides = self._strides = strides
        self.n_group = n_group
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = self._dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "GroupConv2d %s: n_filter: %d size: %s strides: %s n_group: %d pad: %s act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), n_group, padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/separable_conv.py" startline="210" endline="253" pcid="1456">
    def __init__(
        self,
        n_filter=100,
        filter_size=(3, 3),
        strides=(1, 1),
        act=None,
        padding='valid',
        data_format='channels_last',
        dilation_rate=(1, 1),
        depth_multiplier=1,
        depthwise_init=None,
        pointwise_init=None,
        b_init=tl.initializers.constant(value=0.0),
        # depthwise_regularizer=None,
        # pointwise_regularizer=None,
        # bias_regularizer=None,
        # activity_regularizer=None,
        # depthwise_constraint=None,
        # pointwise_constraint=None,
        # W_init=tf.truncated_normal_initializer(stddev=0.1),
        # b_init=tf.constant_initializer(value=0.0),
        in_channels=None,
        name=None  # 'seperable2d',
    ):
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = dilation_rate
        self.depth_multiplier = depth_multiplier
        self.depthwise_init = depthwise_init
        self.pointwise_init = pointwise_init
        self.b_init = b_init
        self.in_channels = in_channels

        logging.info(
            "SeparableConv2d  %s: n_filter: %d filter_size: %s filter_size: %s depth_multiplier: %d act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), depth_multiplier,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/binary_conv.py" startline="63" endline="106" pcid="1372">
    def __init__(
        self,
        n_filter=32,
        filter_size=(3, 3),
        strides=(1, 1),
        act=None,
        padding='SAME',
        use_gemm=False,
        data_format="channels_last",
        dilation_rate=(1, 1),
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None  # 'binary_cnn2d',
    ):
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.use_gemm = use_gemm
        self.data_format = data_format
        self._dilation_rate = self.dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "BinaryConv2d %s: n_filter: %d filter_size: %s strides: %s pad: %s act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

        if use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        if len(self.strides) != 2:
            raise ValueError("len(strides) should be 2.")

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/simplified_conv.py" startline="189" endline="224" pcid="1464">
    def __init__(
        self,
        n_filter=32,
        filter_size=(3, 3),
        strides=(1, 1),
        act=None,
        padding='SAME',
        data_format='channels_last',
        dilation_rate=(1, 1),
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None  # 'conv2d',
    ):
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self._strides = self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self._dilation_rate = self.dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "Conv2d %s: n_filter: %d filter_size: %s strides: %s pad: %s act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/depthwise_conv.py" startline="71" endline="106" pcid="1424">
    def __init__(
        self,
        filter_size=(3, 3),
        strides=(1, 1),
        act=None,
        padding='SAME',
        data_format='channels_last',
        dilation_rate=(1, 1),
        depth_multiplier=1,
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None  # 'depthwise_conv2d'
    ):
        super().__init__(name, act=act)
        self.filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.dilation_rate = self._dilation_rate = dilation_rate
        self.data_format = data_format
        self.depth_multiplier = depth_multiplier
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "DepthwiseConv2d %s: filter_size: %s strides: %s pad: %s act: %s" % (
                self.name, str(filter_size), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/quan_conv.py" startline="68" endline="115" pcid="1448">
    def __init__(
        self,
        bitW=8,
        bitA=8,
        n_filter=32,
        filter_size=(3, 3),
        strides=(1, 1),
        act=None,
        padding='SAME',
        use_gemm=False,
        data_format="channels_last",
        dilation_rate=(1, 1),
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None  # 'quan_cnn2d',
    ):
        super().__init__(name, act=act)
        self.bitW = bitW
        self.bitA = bitA
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.use_gemm = use_gemm
        self.data_format = data_format
        self.dilation_rate = self._dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "QuanConv2d %s: n_filter: %d filter_size: %s strides: %s pad: %s act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

        if self.use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        if len(self.strides) != 2:
            raise ValueError("len(strides) should be 2.")

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/simplified_conv.py" startline="322" endline="357" pcid="1468">
    def __init__(
        self,
        n_filter=32,
        filter_size=(3, 3, 3),
        strides=(1, 1, 1),
        act=None,
        padding='SAME',
        data_format='channels_last',
        dilation_rate=(1, 1, 1),
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None  # 'conv3d',
    ):
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self._strides = self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self._dilation_rate = self.dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "Conv3d %s: n_filter: %d filter_size: %s strides: %s pad: %s act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/simplified_deconv.py" startline="191" endline="228" pcid="1444">
    def __init__(
        self,
        n_filter=32,
        filter_size=(3, 3, 3),
        strides=(2, 2, 2),
        padding='SAME',
        act=None,
        data_format='channels_last',
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None  # 'decnn3d'
    ):
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        # Attention: To build, we need not only the in_channels! Solved.
        if self.in_channels is not None:
            self.build(None)
            self._built = True

        logging.info(
            "DeConv3d %s: n_filters: %s strides: %s pad: %s act: %s" % (
                self.name, str(n_filter), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

        if len(strides) != 3:
            raise ValueError("len(strides) should be 3, DeConv3d and DeConv3dLayer are different.")

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/expert_deconv.py" startline="204" endline="237" pcid="1432">
    def __init__(
        self,
        act=None,
        shape=(3, 3, 128, 256),
        outputs_shape=(1, 256, 256, 128),
        strides=(1, 2, 2, 1),
        padding='SAME',
        data_format='NHWC',
        dilation_rate=(1, 1, 1, 1),
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        name=None  # 'decnn2d_layer',
    ):
        super().__init__(name, act=act)
        self.shape = shape
        self.outputs_shape = outputs_shape
        self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = self.shape[-1]

        self.build(None)
        self._built = True

        logging.info(
            "DeConv2dLayer %s: shape: %s out_shape: %s strides: %s pad: %s act: %s" % (
                self.name, str(shape), str(outputs_shape), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/separable_conv.py" startline="63" endline="106" pcid="1452">
    def __init__(
        self,
        n_filter=100,
        filter_size=3,
        strides=1,
        act=None,
        padding='valid',
        data_format='channels_last',
        dilation_rate=1,
        depth_multiplier=1,
        depthwise_init=None,
        pointwise_init=None,
        b_init=tl.initializers.constant(value=0.0),
        # depthwise_regularizer=None,
        # pointwise_regularizer=None,
        # bias_regularizer=None,
        # activity_regularizer=None,
        # depthwise_constraint=None,
        # pointwise_constraint=None,
        # W_init=tf.truncated_normal_initializer(stddev=0.1),
        # b_init=tf.constant_initializer(value=0.0),
        in_channels=None,
        name=None  # 'seperable1d',
    ):
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = dilation_rate
        self.depth_multiplier = depth_multiplier
        self.depthwise_init = depthwise_init
        self.pointwise_init = pointwise_init
        self.b_init = b_init
        self.in_channels = in_channels

        logging.info(
            "SeparableConv1d  %s: n_filter: %d filter_size: %s strides: %s depth_multiplier: %d act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), depth_multiplier,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/expert_deconv.py" startline="330" endline="363" pcid="1436">
    def __init__(
        self,
        act=None,
        shape=(2, 2, 2, 128, 256),
        outputs_shape=(1, 12, 32, 32, 128),
        strides=(1, 2, 2, 2, 1),
        padding='SAME',
        data_format='NDHWC',
        dilation_rate=(1, 1, 1, 1, 1),
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        name=None  # 'decnn3d_layer',
    ):
        super().__init__(name, act=act)
        self.shape = shape
        self.outputs_shape = outputs_shape
        self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = self.shape[-1]

        self.build(None)
        self._built = True

        logging.info(
            "DeConv3dLayer %s: shape: %s out_shape: %s strides: %s pad: %s act: %s" % (
                self.name, str(shape), str(outputs_shape), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/expert_deconv.py" startline="70" endline="103" pcid="1428">
    def __init__(
        self,
        act=None,
        shape=(3, 128, 256),
        outputs_shape=(1, 256, 128),
        strides=(1, 2, 1),
        padding='SAME',
        data_format='NWC',
        dilation_rate=(1, 1, 1),
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        name=None  # 'decnn1d_layer',
    ):
        super().__init__(name, act=act)
        self.shape = shape
        self.outputs_shape = outputs_shape
        self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = self.shape[-1]

        self.build(None)
        self._built = True

        logging.info(
            "DeConv1dLayer %s: shape: %s out_shape: %s strides: %s pad: %s act: %s" % (
                self.name, str(shape), str(outputs_shape), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/expert_conv.py" startline="62" endline="95" pcid="1376">
    def __init__(
        self,
        act=None,
        shape=(5, 1, 5),
        stride=1,
        padding='SAME',
        data_format='NWC',
        dilation_rate=1,
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        name=None  # 'cnn1d_layer',
    ):
        super().__init__(name, act=act)
        self.n_filter = shape[-1]
        self.filter_size = shape[0]
        self.shape = shape
        self.stride = stride
        self.dilation_rate = dilation_rate
        self.padding = padding
        self.data_format = data_format
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = shape[-2]

        self.build(None)
        self._built = True

        logging.info(
            "Conv1dLayer %s: shape: %s stride: %s pad: %s act: %s" % (
                self.name, str(shape), str(stride), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/expert_conv.py" startline="299" endline="332" pcid="1384">
    def __init__(
        self,
        act=None,
        shape=(2, 2, 2, 3, 32),
        strides=(1, 2, 2, 2, 1),
        padding='SAME',
        data_format='NDHWC',
        dilation_rate=(1, 1, 1, 1, 1),
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        name=None  # 'cnn3d_layer'
    ):
        super().__init__(name, act=act)
        self.n_filter = shape[-1]
        self.filter_size = (shape[0], shape[1], shape[2])
        self.shape = shape
        self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = shape[-2]

        self.build(None)
        self._built = True

        logging.info(
            "Conv3dLayer %s: shape: %s strides: %s pad: %s act: %s" % (
                self.name, str(shape), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/expert_conv.py" startline="181" endline="214" pcid="1380">
    def __init__(
        self,
        act=None,
        shape=(5, 5, 1, 100),
        strides=(1, 1, 1, 1),
        padding='SAME',
        data_format='NHWC',
        dilation_rate=(1, 1, 1, 1),
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        name=None  # 'cnn2d_layer',
    ):
        super().__init__(name, act=act)
        self.n_filter = shape[-1]
        self.filter_size = (shape[0], shape[1])
        self.shape = shape
        self.strides = strides
        self.dilation_rate = dilation_rate
        self.padding = padding
        self.data_format = data_format
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = shape[-2]

        self.build(None)
        self._built = True

        logging.info(
            "Conv2dLayer %s: shape: %s strides: %s pad: %s act: %s" % (
                self.name, str(shape), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</source>
</class>

<class classid="52" nclones="25" nlines="12" similarity="70">
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/ternary_conv.py" startline="107" endline="122" pcid="1369">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/depthwise_conv.py" startline="107" endline="124" pcid="1425">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(
            classname=self.__class__.__name__, n_filter=self.in_channels * self.depth_multiplier, **self.__dict__
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/simplified_deconv.py" startline="229" endline="244" pcid="1445">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        # if self.dilation_rate != (1,) * len(self.dilation_rate):
        #     s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/binary_conv.py" startline="107" endline="122" pcid="1373">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/expert_deconv.py" startline="104" endline="121" pcid="1429">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(
            classname=self.__class__.__name__, n_filter=self.shape[-2], filter_size=self.shape[0], **self.__dict__
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/dorefa_conv.py" startline="115" endline="130" pcid="1396">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/expert_conv.py" startline="333" endline="350" pcid="1385">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != [
                1,
        ] * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/simplified_conv.py" startline="358" endline="373" pcid="1469">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/quan_conv.py" startline="116" endline="131" pcid="1449">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/expert_deconv.py" startline="364" endline="382" pcid="1437">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(
            classname=self.__class__.__name__, n_filter=self.shape[-2],
            filter_size=(self.shape[0], self.shape[1], self.shape[2]), **self.__dict__
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/expert_deconv.py" startline="238" endline="256" pcid="1433">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(
            classname=self.__class__.__name__, n_filter=self.shape[-2], filter_size=(self.shape[0], self.shape[1]),
            **self.__dict__
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/expert_conv.py" startline="96" endline="111" pcid="1377">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', stride={stride}, padding={padding}'
        )
        if self.dilation_rate != 1:
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/simplified_conv.py" startline="225" endline="240" pcid="1465">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/separable_conv.py" startline="107" endline="122" pcid="1453">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', stride={strides}, padding={padding}'
        )
        if self.dilation_rate != 1:
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/expert_conv.py" startline="215" endline="232" pcid="1381">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != [
                1,
        ] * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/group_conv.py" startline="99" endline="114" pcid="1421">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/simplified_deconv.py" startline="104" endline="119" pcid="1441">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/separable_conv.py" startline="254" endline="269" pcid="1457">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', stride={strides}, padding={padding}'
        )
        if self.dilation_rate != 1:
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/deformable_conv.py" startline="173" endline="186" pcid="1410">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', padding={padding}'
        )
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/simplified_conv.py" startline="95" endline="110" pcid="1461">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', stride={stride}, padding={padding}'
        )
        if self.dilation_rate != 1:
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/quan_conv_bn.py" startline="135" endline="147" pcid="1389">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}' + actstr
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/dense/dropconnect.py" startline="89" endline="99" pcid="1579">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = ('{classname}(n_units={n_units}, ' + actstr)
        s += ', keep={keep}'
        if self.in_channels is not None:
            s += ', in_channels=\'{in_channels}\''
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/dense/quan_dense.py" startline="75" endline="85" pcid="1583">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = ('{classname}(n_units={n_units}, ' + actstr)
        s += ', bitW={bitW}, bitA={bitA}'
        if self.in_channels is not None:
            s += ', in_channels=\'{in_channels}\''
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/dense/quan_dense_bn.py" startline="106" endline="116" pcid="1595">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = ('{classname}(n_units={n_units}, ' + actstr)
        s += ', bitW={bitW}, bitA={bitA}'
        if self.in_channels is not None:
            s += ', in_channels=\'{in_channels}\''
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/dense/dorefa_dense.py" startline="77" endline="87" pcid="1571">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = ('{classname}(n_units={n_units}, ' + actstr)
        s += ', bitW={bitW}, bitA={bitA}'
        if self.in_channels is not None:
            s += ', in_channels=\'{in_channels}\''
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
</class>

<class classid="53" nclones="8" nlines="19" similarity="70">
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/ternary_conv.py" startline="123" endline="144" pcid="1370">
    def build(self, inputs_shape):
        if self.data_format == 'channels_last':
            self.data_format = 'NHWC'
            if self.in_channels is None:
                self.in_channels = inputs_shape[-1]
            self._strides = [1, self._strides[0], self._strides[1], 1]
            self._dilation_rate = [1, self._dilation_rate[0], self._dilation_rate[1], 1]
        elif self.data_format == 'channels_first':
            self.data_format = 'NCHW'
            if self.in_channels is None:
                self.in_channels = inputs_shape[1]
            self._strides = [1, 1, self._strides[0], self._strides[1]]
            self._dilation_rate = [1, 1, self._dilation_rate[0], self._dilation_rate[1]]
        else:
            raise Exception("data_format should be either channels_last or channels_first")

        self.filter_shape = (self.filter_size[0], self.filter_size[1], self.in_channels, self.n_filter)

        self.W = self._get_weights("filters", shape=self.filter_shape, init=self.W_init)
        if self.b_init:
            self.b = self._get_weights("biases", shape=(self.n_filter, ), init=self.b_init)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/quan_conv.py" startline="132" endline="153" pcid="1450">
    def build(self, inputs_shape):
        if self.data_format == 'channels_last':
            self.data_format = 'NHWC'
            if self.in_channels is None:
                self.in_channels = inputs_shape[-1]
            self._strides = [1, self._strides[0], self._strides[1], 1]
            self._dilation_rate = [1, self._dilation_rate[0], self._dilation_rate[1], 1]
        elif self.data_format == 'channels_first':
            self.data_format = 'NCHW'
            if self.in_channels is None:
                self.in_channels = inputs_shape[1]
            self._strides = [1, 1, self._strides[0], self._strides[1]]
            self._dilation_rate = [1, 1, self._dilation_rate[0], self._dilation_rate[1]]
        else:
            raise Exception("data_format should be either channels_last or channels_first")

        self.filter_shape = (self.filter_size[0], self.filter_size[1], self.in_channels, self.n_filter)

        self.W = self._get_weights("filters", shape=self.filter_shape, init=self.W_init)
        if self.b_init:
            self.b = self._get_weights("biases", shape=(self.n_filter, ), init=self.b_init)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/group_conv.py" startline="115" endline="144" pcid="1422">
    def build(self, inputs_shape):

        if self.data_format == 'channels_last':
            self.data_format = 'NHWC'
            if self.in_channels is None:
                self.in_channels = inputs_shape[-1]
            self._strides = [1, self._strides[0], self._strides[1], 1]
            self._dilation_rate = [1, self._dilation_rate[0], self._dilation_rate[1], 1]
        elif self.data_format == 'channels_first':
            self.data_format = 'NCHW'
            if self.in_channels is None:
                self.in_channels = inputs_shape[1]
            self._strides = [1, 1, self._strides[0], self._strides[1]]
            self._dilation_rate = [1, 1, self._dilation_rate[0], self._dilation_rate[1]]
        else:
            raise Exception("data_format should be either channels_last or channels_first")

        self.groupConv = lambda i, k: tf.nn.conv2d(
            i, k, strides=self._strides, padding=self.padding, data_format=self.data_format, dilations=self.
            _dilation_rate, name=self.name
        )

        self.filter_shape = (
            self.filter_size[0], self.filter_size[1], int(self.in_channels / self.n_group), self.n_filter
        )

        self.We = self._get_weights("filters", shape=self.filter_shape, init=self.W_init)
        if self.b_init:
            self.b = self._get_weights("biases", shape=self.n_filter, init=self.b_init)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/simplified_conv.py" startline="374" endline="398" pcid="1470">
    def build(self, inputs_shape):
        if self.data_format == 'channels_last':
            self.data_format = 'NDHWC'
            if self.in_channels is None:
                self.in_channels = inputs_shape[-1]
            self._strides = [1, self._strides[0], self._strides[1], self._strides[2], 1]
            self._dilation_rate = [1, self.dilation_rate[0], self.dilation_rate[1], self.dilation_rate[2], 1]
        elif self.data_format == 'channels_first':
            self.data_format = 'NCDHW'
            if self.in_channels is None:
                self.in_channels = inputs_shape[1]
            self._strides = [1, 1, self._strides[0], self._strides[1], self._strides[2]]
            self._dilation_rate = [1, 1, self._dilation_rate[0], self._dilation_rate[1], self._dilation_rate[2]]
        else:
            raise Exception("data_format should be either channels_last or channels_first")

        self.filter_shape = (
            self.filter_size[0], self.filter_size[1], self.filter_size[2], self.in_channels, self.n_filter
        )

        self.W = self._get_weights("filters", shape=self.filter_shape, init=self.W_init)

        if self.b_init:
            self.b = self._get_weights("biases", shape=(self.n_filter, ), init=self.b_init)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/binary_conv.py" startline="123" endline="144" pcid="1374">
    def build(self, inputs_shape):
        if self.data_format == 'channels_last':
            self.data_format = 'NHWC'
            if self.in_channels is None:
                self.in_channels = inputs_shape[-1]
            self._strides = [1, self._strides[0], self._strides[1], 1]
            self._dilation_rate = [1, self._dilation_rate[0], self._dilation_rate[1], 1]
        elif self.data_format == 'channels_first':
            self.data_format = 'NCHW'
            if self.in_channels is None:
                self.in_channels = inputs_shape[1]
            self._strides = [1, 1, self._strides[0], self._strides[1]]
            self._dilation_rate = [1, 1, self._dilation_rate[0], self._dilation_rate[1]]
        else:
            raise Exception("data_format should be either channels_last or channels_first")

        self.filter_shape = (self.filter_size[0], self.filter_size[1], self.in_channels, self.n_filter)

        self.W = self._get_weights("filters", shape=self.filter_shape, init=self.W_init)
        if self.b_init:
            self.b = self._get_weights("biases", shape=(self.n_filter, ), init=self.b_init)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/dorefa_conv.py" startline="131" endline="152" pcid="1397">
    def build(self, inputs_shape):
        if self.data_format == 'channels_last':
            self.data_format = 'NHWC'
            if self.in_channels is None:
                self.in_channels = inputs_shape[-1]
            self._strides = [1, self._strides[0], self._strides[1], 1]
            self._dilation_rate = [1, self._dilation_rate[0], self._dilation_rate[1], 1]
        elif self.data_format == 'channels_first':
            self.data_format = 'NCHW'
            if self.in_channels is None:
                self.in_channels = inputs_shape[1]
            self._strides = [1, 1, self._strides[0], self._strides[1]]
            self._dilation_rate = [1, 1, self._dilation_rate[0], self._dilation_rate[1]]
        else:
            raise Exception("data_format should be either channels_last or channels_first")

        self.filter_shape = (self.filter_size[0], self.filter_size[1], self.in_channels, self.n_filter)

        self.W = self._get_weights("filters", shape=self.filter_shape, init=self.W_init)
        if self.b_init:
            self.b = self._get_weights("biases", shape=(self.n_filter, ), init=self.b_init)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/depthwise_conv.py" startline="125" endline="147" pcid="1426">
    def build(self, inputs_shape):
        if self.data_format == 'channels_last':
            self.data_format = 'NHWC'
            if self.in_channels is None:
                self.in_channels = inputs_shape[-1]
            self._strides = [1, self._strides[0], self._strides[1], 1]
            self._dilation_rate = [1, self._dilation_rate[0], self._dilation_rate[1], 1]
        elif self.data_format == 'channels_first':
            self.data_format = 'NCHW'
            if self.in_channels is None:
                self.in_channels = inputs_shape[1]
            self._strides = [1, 1, self._strides[0], self._strides[1]]
            self._dilation_rate = [1, 1, self._dilation_rate[0], self._dilation_rate[1]]
        else:
            raise Exception("data_format should be either channels_last or channels_first")

        self.filter_shape = (self.filter_size[0], self.filter_size[1], self.in_channels, self.depth_multiplier)

        self.W = self._get_weights("filters", shape=self.filter_shape, init=self.W_init)

        if self.b_init:
            self.b = self._get_weights("biases", shape=(self.in_channels * self.depth_multiplier), init=self.b_init)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/simplified_conv.py" startline="241" endline="263" pcid="1466">
    def build(self, inputs_shape):
        if self.data_format == 'channels_last':
            self.data_format = 'NHWC'
            if self.in_channels is None:
                self.in_channels = inputs_shape[-1]
            self._strides = [1, self._strides[0], self._strides[1], 1]
            self._dilation_rate = [1, self._dilation_rate[0], self._dilation_rate[1], 1]
        elif self.data_format == 'channels_first':
            self.data_format = 'NCHW'
            if self.in_channels is None:
                self.in_channels = inputs_shape[1]
            self._strides = [1, 1, self._strides[0], self._strides[1]]
            self._dilation_rate = [1, 1, self._dilation_rate[0], self._dilation_rate[1]]
        else:
            raise Exception("data_format should be either channels_last or channels_first")

        self.filter_shape = (self.filter_size[0], self.filter_size[1], self.in_channels, self.n_filter)

        self.W = self._get_weights("filters", shape=self.filter_shape, init=self.W_init)

        if self.b_init:
            self.b = self._get_weights("biases", shape=(self.n_filter, ), init=self.b_init)

</source>
</class>

<class classid="54" nclones="4" nlines="11" similarity="75">
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/ternary_conv.py" startline="145" endline="162" pcid="1371">
    def forward(self, inputs):

        alpha = compute_alpha(self.W)

        W_ = ternary_operation(self.W)
        W_ = tf.multiply(alpha, W_)

        outputs = tf.nn.conv2d(
            input=inputs, filters=W_, strides=self._strides, padding=self.padding, data_format=self.data_format,
            dilations=self._dilation_rate, name=self.name
        )

        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)

        return outputs
</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/quan_conv.py" startline="154" endline="170" pcid="1451">
    def forward(self, inputs):

        inputs = quantize_active_overflow(inputs, self.bitA)  # Do not remove

        W_ = quantize_weight_overflow(self.W, self.bitW)

        outputs = tf.nn.conv2d(
            input=inputs, filters=W_, strides=self.strides, padding=self.padding, data_format=self.data_format,
            dilations=self._dilation_rate, name=self.name
        )

        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)

        return outputs
</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/binary_conv.py" startline="145" endline="159" pcid="1375">
    def forward(self, inputs):

        _W = quantize(self.W)

        outputs = tf.nn.conv2d(
            input=inputs, filters=_W, strides=self._strides, padding=self.padding, data_format=self.data_format,
            dilations=self._dilation_rate, name=self.name
        )

        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)

        return outputs
</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/dorefa_conv.py" startline="153" endline="169" pcid="1398">
    def forward(self, inputs):

        inputs = quantize_active(cabs(inputs), self.bitA)  # Do not remove

        W_ = quantize_weight(self.W, self.bitW)

        outputs = tf.nn.conv2d(
            input=inputs, filters=W_, strides=self._strides, padding=self.padding, data_format=self.data_format,
            dilations=self._dilation_rate, name=self.name
        )

        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)

        return outputs
</source>
</class>

<class classid="55" nclones="13" nlines="14" similarity="73">
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/expert_conv.py" startline="117" endline="137" pcid="1379">
    def forward(self, inputs):

        outputs = tf.nn.conv1d(
            input=inputs,
            filters=self.W,
            stride=self.stride,
            padding=self.padding,
            dilations=[
                self.dilation_rate,
            ],
            data_format=self.data_format,
            name=self.name,
        )

        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs


</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/expert_conv.py" startline="357" endline="372" pcid="1387">
    def forward(self, inputs):
        outputs = tf.nn.conv3d(
            input=inputs,
            filters=self.W,
            strides=self.strides,
            padding=self.padding,
            data_format=self.data_format,  #'NDHWC',
            dilations=list(self.dilation_rate),  #[1, 1, 1, 1, 1],
            name=self.name,
        )

        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs
</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/expert_conv.py" startline="238" endline="255" pcid="1383">
    def forward(self, inputs):
        outputs = tf.nn.conv2d(
            input=inputs,
            filters=self.W,
            strides=self.strides,
            padding=self.padding,
            data_format=self.data_format,
            dilations=list(self.dilation_rate),
            name=self.name,
        )

        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs


</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/depthwise_conv.py" startline="148" endline="162" pcid="1427">
    def forward(self, inputs):
        outputs = tf.nn.depthwise_conv2d(
            input=inputs,
            filter=self.W,
            strides=self._strides,
            padding=self.padding,
            data_format=self.data_format,
            dilations=self.dilation_rate,
            name=self.name,
        )
        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs
</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/simplified_conv.py" startline="131" endline="147" pcid="1463">
    def forward(self, inputs):
        outputs = tf.nn.conv1d(
            input=inputs,
            filters=self.W,
            stride=self.stride,
            padding=self.padding,
            data_format=self.data_format,
            dilations=self.dilation_rate,
            name=self.name,
        )
        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs


</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/simplified_conv.py" startline="264" endline="280" pcid="1467">
    def forward(self, inputs):
        outputs = tf.nn.conv2d(
            input=inputs,
            filters=self.W,
            strides=self._strides,
            padding=self.padding,
            data_format=self.data_format,  #'NHWC',
            dilations=self._dilation_rate,  #[1, 1, 1, 1],
            name=self.name,
        )
        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs


</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/expert_deconv.py" startline="262" endline="279" pcid="1435">
    def forward(self, inputs):
        outputs = tf.nn.conv2d_transpose(
            input=inputs,
            filters=self.W,
            output_shape=self.outputs_shape,
            strides=self.strides,
            padding=self.padding,
            data_format=self.data_format,
            dilations=list(self.dilation_rate),
            name=self.name,
        )
        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs


</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/simplified_conv.py" startline="399" endline="413" pcid="1471">
    def forward(self, inputs):
        outputs = tf.nn.conv3d(
            input=inputs,
            filters=self.W,
            strides=self._strides,
            padding=self.padding,
            data_format=self.data_format,  #'NDHWC',
            dilations=self._dilation_rate,  #[1, 1, 1, 1, 1],
            name=self.name,
        )
        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs
</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/expert_deconv.py" startline="127" endline="144" pcid="1431">
    def forward(self, inputs):
        outputs = tf.nn.conv1d_transpose(
            input=inputs,
            filters=self.W,
            output_shape=self.outputs_shape,
            strides=list(self.strides),
            padding=self.padding,
            data_format=self.data_format,
            dilations=list(self.dilation_rate),
            name=self.name,
        )
        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs


</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/pooling.py" startline="169" endline="182" pcid="1658">
    def forward(self, inputs):
        outputs = tf.nn.pool(
            input=inputs,
            window_shape=self._filter_size,
            pooling_type="MAX",
            strides=self._strides,
            padding=self.padding,
            data_format=self.data_format,
            dilations=self._dilation_rate,
            name=self.name,
        )
        return outputs


</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/pooling.py" startline="489" endline="500" pcid="1674">
    def forward(self, inputs):
        outputs = tf.nn.max_pool3d(
            input=inputs,
            ksize=self.filter_size,
            strides=self._strides,
            padding=self.padding,
            data_format=self.data_format,
            name=self.name,
        )
        return outputs


</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/pooling.py" startline="255" endline="268" pcid="1662">
    def forward(self, inputs):
        outputs = tf.nn.pool(
            input=inputs,
            window_shape=self._filter_size,
            pooling_type="AVG",
            padding=self.padding,
            dilations=None,  # TODO: support dilations
            strides=self._strides,
            name=self.name,
            data_format=self.data_format
        )
        return outputs


</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/pooling.py" startline="571" endline="582" pcid="1678">
    def forward(self, inputs):
        outputs = tf.nn.avg_pool3d(
            input=inputs,
            ksize=self.filter_size,
            strides=self._strides,
            padding=self.padding,
            data_format=self.data_format,
            name=self.name,
        )
        return outputs


</source>
</class>

<class classid="56" nclones="2" nlines="25" similarity="73">
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/quan_conv_bn.py" startline="189" endline="225" pcid="1391">
    def forward(self, inputs):
        x = inputs
        inputs = quantize_active_overflow(inputs, self.bitA)  # Do not remove
        outputs = tf.nn.conv2d(
            input=x, filters=self.W, strides=self._strides, padding=self.padding, data_format=self.data_format,
            dilations=self._dilation_rate, name=self.name
        )

        mean, variance = tf.nn.moments(outputs, axes=list(range(len(outputs.get_shape()) - 1)))

        update_moving_mean = moving_averages.assign_moving_average(
            self.moving_mean, mean, self.decay, zero_debias=False
        )  # if zero_debias=True, has bias
        update_moving_variance = moving_averages.assign_moving_average(
            self.moving_variance, mean, self.decay, zero_debias=False
        )  # if zero_debias=True, has bias

        if self.is_train:
            mean, var = self.mean_var_with_update(update_moving_mean, update_moving_variance, mean, variance)
        else:
            mean, var = self.moving_mean, self.moving_variance

        w_fold = self._w_fold(self.W, self.scale_para, var, self.epsilon)

        W_ = quantize_weight_overflow(w_fold, self.bitW)

        conv_fold = tf.nn.conv2d(inputs, W_, strides=self.strides, padding=self.padding, data_format=self.data_format)

        if self.beta_init:
            bias_fold = self._bias_fold(self.offset_para, self.scale_para, mean, var, self.epsilon)
            conv_fold = tf.nn.bias_add(conv_fold, bias_fold, name='bn_bias_add')

        if self.act:
            conv_fold = self.act(conv_fold)

        return conv_fold

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/dense/quan_dense_bn.py" startline="148" endline="185" pcid="1597">
    def forward(self, inputs):
        x = inputs
        inputs = quantize_active_overflow(inputs, self.bitA)
        mid_out = tf.matmul(x, self.W)

        mean, variance = tf.nn.moments(x=mid_out, axes=list(range(len(mid_out.get_shape()) - 1)))

        update_moving_mean = moving_averages.assign_moving_average(
            self.moving_mean, mean, self.decay, zero_debias=False
        )  # if zero_debias=True, has bias

        update_moving_variance = moving_averages.assign_moving_average(
            self.moving_variance, variance, self.decay, zero_debias=False
        )  # if zero_debias=True, has bias

        if self.is_train:
            mean, var = self.mean_var_with_update(update_moving_mean, update_moving_variance, mean, variance)
        else:
            mean, var = self.moving_mean, self.moving_variance

        w_fold = self._w_fold(self.W, self.scale_para, var, self.epsilon)

        W = quantize_weight_overflow(w_fold, self.bitW)

        outputs = tf.matmul(inputs, W)

        if self.beta_init:
            bias_fold = self._bias_fold(self.offset_para, self.scale_para, mean, var, self.epsilon)
            outputs = tf.nn.bias_add(outputs, bias_fold, name='bias_add')
        else:
            outputs = outputs

        if self.act:
            outputs = self.act(outputs)
        else:
            outputs = outputs
        return outputs

</source>
</class>

<class classid="57" nclones="8" nlines="21" similarity="72">
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/super_resolution.py" startline="49" endline="69" pcid="1399">
    def __init__(
        self,
        scale=2,
        act=None,
        in_channels=None,
        name=None  # 'subpixel_conv1d'
    ):
        super().__init__(name, act=act)
        self.scale = scale
        self.in_channels = in_channels
        self.out_channels = int(self.in_channels / self.scale)

        if self.in_channels is not None:
            self.build(None)
            self._built = True

        logging.info(
            "SubpixelConv1d  %s: scale: %d act: %s" %
            (self.name, scale, self.act.__name__ if self.act is not None else 'No Activation')
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/super_resolution.py" startline="143" endline="163" pcid="1404">
    def __init__(
        self,
        scale=2,
        n_out_channels=None,
        act=None,
        in_channels=None,
        name=None  # 'subpixel_conv2d'
    ):
        super().__init__(name, act=act)
        self.scale = scale
        self.n_out_channels = n_out_channels
        self.in_channels = in_channels

        if self.in_channels is not None:
            self.build(None)
            self._built = True
        logging.info(
            "SubpixelConv2d  %s: scale: %d act: %s" %
            (self.name, scale, self.act.__name__ if self.act is not None else 'No Activation')
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/dense/binary_dense.py" startline="42" endline="67" pcid="1590">
    def __init__(
        self,
        n_units=100,
        act=None,
        use_gemm=False,
        W_init=tl.initializers.truncated_normal(stddev=0.05),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None,  #'binary_dense',
    ):
        super().__init__(name, act=act)
        self.n_units = n_units
        self.use_gemm = use_gemm
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels is not None:
            self.build((None, self.in_channels))
            self._built = True

        logging.info(
            "BinaryDense  %s: %d %s" %
            (self.name, n_units, self.act.__name__ if self.act is not None else 'No Activation')
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/dense/ternary_dense.py" startline="42" endline="67" pcid="1574">
    def __init__(
        self,
        n_units=100,
        act=None,
        use_gemm=False,
        W_init=tl.initializers.truncated_normal(stddev=0.05),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None,  #'ternary_dense',
    ):
        super().__init__(name, act=act)
        self.n_units = n_units
        self.use_gemm = use_gemm
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels is not None:
            self.build((None, self.in_channels))
            self._built = True

        logging.info(
            "TernaryDense  %s: %d %s" %
            (self.name, n_units, self.act.__name__ if self.act is not None else 'No Activation')
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/dense/dropconnect.py" startline="59" endline="88" pcid="1578">
    def __init__(
        self,
        keep=0.5,
        n_units=100,
        act=None,
        W_init=tl.initializers.truncated_normal(stddev=0.05),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None,  # 'dropconnect',
    ):
        super().__init__(name, act=act)

        if isinstance(keep, numbers.Real) and not (keep > 0 and keep <= 1):
            raise ValueError("keep must be a scalar tensor or a float in the " "range (0, 1], got %g" % keep)

        self.keep = keep
        self.n_units = n_units
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels is not None:
            self.build((None, self.in_channels))
            self._built = True

        logging.info(
            "DropconnectDense %s: %d %s" %
            (self.name, n_units, self.act.__name__ if self.act is not None else 'No Activation')
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/dense/dorefa_dense.py" startline="47" endline="76" pcid="1570">
    def __init__(
        self,
        bitW=1,
        bitA=3,
        n_units=100,
        act=None,
        use_gemm=False,
        W_init=tl.initializers.truncated_normal(stddev=0.05),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None,  #'dorefa_dense',
    ):
        super().__init__(name, act=act)
        self.bitW = bitW
        self.bitA = bitA
        self.n_units = n_units
        self.use_gemm = use_gemm
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels is not None:
            self.build((None, self.in_channels))
            self._built = True

        logging.info(
            "DorefaDense  %s: %d %s" %
            (self.name, n_units, self.act.__name__ if self.act is not None else 'No Activation')
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/dense/quan_dense.py" startline="45" endline="74" pcid="1582">
    def __init__(
        self,
        n_units=100,
        act=None,
        bitW=8,
        bitA=8,
        use_gemm=False,
        W_init=tl.initializers.truncated_normal(stddev=0.05),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None,  #'quan_dense',
    ):
        super().__init__(name, act=act)
        self.n_units = n_units
        self.bitW = bitW
        self.bitA = bitA
        self.use_gemm = use_gemm
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels is not None:
            self.build((None, self.in_channels))
            self._built = True

        logging.info(
            "QuanDense  %s: %d %s" %
            (self.name, n_units, self.act.__name__ if self.act is not None else 'No Activation')
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/dense/base_dense.py" startline="56" endline="81" pcid="1586">
    def __init__(
        self,
        n_units,
        act=None,
        W_init=tl.initializers.truncated_normal(stddev=0.05),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None,  # 'dense',
    ):

        super(Dense, self).__init__(name, act=act)

        self.n_units = n_units
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels is not None:
            self.build(self.in_channels)
            self._built = True

        logging.info(
            "Dense  %s: %d %s" %
            (self.name, self.n_units, self.act.__name__ if self.act is not None else 'No Activation')
        )

</source>
</class>

<class classid="58" nclones="4" nlines="24" similarity="70">
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/simplified_deconv.py" startline="120" endline="147" pcid="1442">
    def build(self, inputs_shape):
        self.layer = tf.keras.layers.Conv2DTranspose(
            filters=self.n_filter,
            kernel_size=self.filter_size,
            strides=self.strides,
            padding=self.padding,
            data_format=self.data_format,
            dilation_rate=self.dilation_rate,
            activation=self.act,
            use_bias=(True if self.b_init is not None else False),
            kernel_initializer=self.W_init,
            bias_initializer=self.b_init,
            # dtype=tf.float32,
            name=self.name,
        )
        if inputs_shape is not None:
            self.in_channels = inputs_shape[1 if self.data_format == "channels_first" else -1]
        elif self.in_channels is not None:
            inputs_shape = [1, self.in_channels, 1, 1
                           ] if self.data_format == "channels_first" else [1, 1, 1, self.in_channels]
        else:
            raise ValueError("Either inputs_shape or in_channels must be specified for build.")
        _out = self.layer(
            tf.convert_to_tensor(np.random.uniform(size=inputs_shape), dtype=np.float32)
        )  #np.random.uniform([1] + list(inputs_shape)))  # initialize weights
        outputs_shape = _out.shape
        self._trainable_weights = self.layer.weights

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/separable_conv.py" startline="123" endline="159" pcid="1454">
    def build(self, inputs_shape):
        self.layer = tf.keras.layers.SeparableConv1D(
            filters=self.n_filter,
            kernel_size=self.filter_size,
            strides=self.strides,
            padding=self.padding,
            data_format=self.data_format,
            dilation_rate=self.dilation_rate,
            depth_multiplier=self.depth_multiplier,
            activation=self.act,
            use_bias=(True if self.b_init is not None else False),
            depthwise_initializer=self.depthwise_init,
            pointwise_initializer=self.pointwise_init,
            bias_initializer=self.b_init,
            # depthwise_regularizer=None,
            # pointwise_regularizer=None,
            # bias_regularizer=None,
            # activity_regularizer=None,
            # depthwise_constraint=None,
            # pointwise_constraint=None,
            # bias_constraint=None,
            trainable=True,
            name=self.name
        )
        if self.data_format == "channels_first":
            self.in_channels = inputs_shape[1]
        else:
            self.in_channels = inputs_shape[-1]

        # _out = self.layer(np.random.uniform([1] + list(inputs_shape)))  # initialize weights
        _out = self.layer(
            tf.convert_to_tensor(np.random.uniform(size=list(inputs_shape)), dtype=np.float)
        )  # initialize weights
        outputs_shape = _out.shape
        # self._add_weights(self.layer.weights)
        self._trainable_weights = self.layer.weights

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/separable_conv.py" startline="270" endline="304" pcid="1458">
    def build(self, inputs_shape):
        self.layer = tf.keras.layers.SeparableConv2D(
            filters=self.n_filter,
            kernel_size=self.filter_size,
            strides=self.strides,
            padding=self.padding,
            data_format=self.data_format,
            dilation_rate=self.dilation_rate,
            depth_multiplier=self.depth_multiplier,
            activation=self.act,
            use_bias=(True if self.b_init is not None else False),
            depthwise_initializer=self.depthwise_init,
            pointwise_initializer=self.pointwise_init,
            bias_initializer=self.b_init,
            # depthwise_regularizer=None,
            # pointwise_regularizer=None,
            # bias_regularizer=None,
            # activity_regularizer=None,
            # depthwise_constraint=None,
            # pointwise_constraint=None,
            # bias_constraint=None,
            trainable=True,
            name=self.name
        )
        if self.data_format == "channels_first":
            self.in_channels = inputs_shape[1]
        else:
            self.in_channels = inputs_shape[-1]
        # _out = self.layer(np.random.uniform([1] + list(inputs_shape)))  # initialize weights
        _out = self.layer(
            tf.convert_to_tensor(np.random.uniform(size=list(inputs_shape)), dtype=np.float)
        )  # initialize weights
        outputs_shape = _out.shape
        self._trainable_weights = self.layer.weights

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/convolution/simplified_deconv.py" startline="245" endline="270" pcid="1446">
    def build(self, inputs_shape):
        self.layer = tf.keras.layers.Conv3DTranspose(
            filters=self.n_filter,
            kernel_size=self.filter_size,
            strides=self.strides,
            padding=self.padding,
            data_format=self.data_format,
            activation=self.act,
            use_bias=(True if self.b_init is not None else False),
            kernel_initializer=self.W_init,
            bias_initializer=self.b_init,
            name=self.name,
        )
        if inputs_shape is not None:
            self.in_channels = inputs_shape[1 if self.data_format == "channels_first" else -1]
        elif self.in_channels is not None:
            inputs_shape = [1, self.in_channels, 1, 1, 1
                           ] if self.data_format == "channels_first" else [1, 1, 1, 1, self.in_channels]
        else:
            raise ValueError("Either inputs_shape or in_channels must be specified for build.")
        _out = self.layer(
            tf.convert_to_tensor(np.random.uniform(size=inputs_shape), dtype=np.float32)
        )  #self.layer(np.random.uniform([1] + list(inputs_shape)))  # initialize weights
        outputs_shape = _out.shape
        self._trainable_weights = self.layer.weights

</source>
</class>

<class classid="59" nclones="3" nlines="15" similarity="100">
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/normalization.py" startline="511" endline="529" pcid="1504">
    def _get_param_shape(self, inputs_shape):
        if self.data_format == 'channels_last':
            axis = 2
        elif self.data_format == 'channels_first':
            axis = 1
        else:
            raise ValueError('data_format should be either %s or %s' % ('channels_last', 'channels_first'))

        if self.num_features is None:
            channels = inputs_shape[axis]
        else:
            channels = self.num_features
        params_shape = [1] * 3
        params_shape[axis] = channels

        axes = [i for i in range(3) if i != 0 and i != axis]
        return params_shape, axes


</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/normalization.py" startline="548" endline="566" pcid="1505">
    def _get_param_shape(self, inputs_shape):
        if self.data_format == 'channels_last':
            axis = 3
        elif self.data_format == 'channels_first':
            axis = 1
        else:
            raise ValueError('data_format should be either %s or %s' % ('channels_last', 'channels_first'))

        if self.num_features is None:
            channels = inputs_shape[axis]
        else:
            channels = self.num_features
        params_shape = [1] * 4
        params_shape[axis] = channels

        axes = [i for i in range(4) if i != 0 and i != axis]
        return params_shape, axes


</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/normalization.py" startline="585" endline="604" pcid="1506">
    def _get_param_shape(self, inputs_shape):
        if self.data_format == 'channels_last':
            axis = 4
        elif self.data_format == 'channels_first':
            axis = 1
        else:
            raise ValueError('data_format should be either %s or %s' % ('channels_last', 'channels_first'))

        if self.num_features is None:
            channels = inputs_shape[axis]
        else:
            channels = self.num_features
        params_shape = [1] * 5
        params_shape[axis] = channels

        axes = [i for i in range(5) if i != 0 and i != axis]
        return params_shape, axes


# FIXME : not sure about the correctness, need testing
</source>
</class>

<class classid="60" nclones="2" nlines="10" similarity="70">
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/stack.py" startline="40" endline="51" pcid="1562">
    def __init__(
        self,
        axis=1,
        name=None,  #'stack',
    ):
        super().__init__(name)
        self.axis = axis

        self.build(None)
        self._built = True
        logging.info("Stack %s: axis: %d" % (self.name, self.axis))

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/merge.py" startline="42" endline="55" pcid="1601">
    def __init__(
        self,
        concat_dim=-1,
        name=None,  #'concat',
    ):

        super(Concat, self).__init__(name)
        self.concat_dim = concat_dim

        self.build(None)
        self._built = True

        logging.info("Concat %s: concat_dim: %d" % (self.name, concat_dim))

</source>
</class>

<class classid="61" nclones="4" nlines="11" similarity="81">
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/dense/dorefa_dense.py" startline="88" endline="102" pcid="1572">
    def build(self, inputs_shape):
        if len(inputs_shape) != 2:
            raise Exception("The input dimension must be rank 2, please reshape or flatten it")

        if self.in_channels is None:
            self.in_channels = inputs_shape[1]

        if self.use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        n_in = inputs_shape[-1]
        self.W = self._get_weights("weights", shape=(n_in, self.n_units), init=self.W_init)
        if self.b_init is not None:
            self.b = self._get_weights("biases", shape=(self.n_units), init=self.b_init)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/dense/ternary_dense.py" startline="78" endline="93" pcid="1576">
    def build(self, inputs_shape):
        if len(inputs_shape) != 2:
            raise Exception("The input dimension must be rank 2, please reshape or flatten it")

        if self.in_channels is None:
            self.in_channels = inputs_shape[1]

        if self.use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        n_in = inputs_shape[-1]

        self.W = self._get_weights(var_name="weights", shape=(n_in, self.n_units), init=self.W_init)
        if self.b_init is not None:
            self.b = self._get_weights(var_name="biases", shape=(self.n_units), init=self.b_init)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/dense/binary_dense.py" startline="78" endline="92" pcid="1592">
    def build(self, inputs_shape):
        if len(inputs_shape) != 2:
            raise Exception("The input dimension must be rank 2, please reshape or flatten it")

        if self.in_channels is None:
            self.in_channels = inputs_shape[1]

        if self.use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        n_in = inputs_shape[-1]
        self.W = self._get_weights("weights", shape=(n_in, self.n_units), init=self.W_init)
        if self.b_init is not None:
            self.b = self._get_weights("biases", shape=(self.n_units), init=self.b_init)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/dense/quan_dense.py" startline="86" endline="100" pcid="1584">
    def build(self, inputs_shape):
        if len(inputs_shape) != 2:
            raise Exception("The input dimension must be rank 2, please reshape or flatten it")

        if self.in_channels is None:
            self.in_channels = inputs_shape[1]

        if self.use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        n_in = inputs_shape[-1]
        self.W = self._get_weights("weights", shape=(n_in, self.n_units), init=self.W_init)
        if self.b_init is not None:
            self.b = self._get_weights("biases", shape=int(self.n_units), init=self.b_init)

</source>
</class>

<class classid="62" nclones="2" nlines="20" similarity="71">
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/recurrent.py" startline="140" endline="162" pcid="1636">
    def __init__(
        self,
        cell,
        return_last_output=False,
        return_seq_2d=False,
        return_last_state=True,
        in_channels=None,
        name=None,  # 'rnn'
    ):

        super(RNN, self).__init__(name=name)

        self.cell = cell
        self.return_last_output = return_last_output
        self.return_seq_2d = return_seq_2d
        self.return_last_state = return_last_state

        if in_channels is not None:
            self.build((None, None, in_channels))
            self._built = True

        logging.info("RNN %s: cell: %s, n_units: %s" % (self.name, self.cell.__class__.__name__, self.cell.units))

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/recurrent.py" startline="636" endline="662" pcid="1643">
    def __init__(
        self,
        fw_cell,
        bw_cell,
        return_seq_2d=False,
        return_last_state=False,
        in_channels=None,
        name=None,  # 'birnn'
    ):
        super(BiRNN, self).__init__(name)

        self.fw_cell = fw_cell
        self.bw_cell = bw_cell
        self.return_seq_2d = return_seq_2d
        self.return_last_state = return_last_state

        if in_channels is not None:
            self.build((None, None, in_channels))
            self._built = True

        logging.info(
            "BiRNN %s: fw_cell: %s, fw_n_units: %s, bw_cell: %s, bw_n_units： %s" % (
                self.name, self.fw_cell.__class__.__name__, self.fw_cell.units, self.bw_cell.__class__.__name__,
                self.bw_cell.units
            )
        )

</source>
</class>

<class classid="63" nclones="3" nlines="13" similarity="100">
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/recurrent.py" startline="392" endline="407" pcid="1640">
    def __init__(
        self,
        units,
        return_last_output=False,
        return_seq_2d=False,
        return_last_state=True,
        in_channels=None,
        name=None,  # 'simplernn'
        **kwargs
    ):
        super(SimpleRNN, self).__init__(
            cell=tf.keras.layers.SimpleRNNCell(units=units, **kwargs), return_last_output=return_last_output,
            return_seq_2d=return_seq_2d, return_last_state=return_last_state, in_channels=in_channels, name=name
        )


</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/recurrent.py" startline="548" endline="563" pcid="1642">
    def __init__(
        self,
        units,
        return_last_output=False,
        return_seq_2d=False,
        return_last_state=True,
        in_channels=None,
        name=None,  # 'lstmrnn'
        **kwargs
    ):
        super(LSTMRNN, self).__init__(
            cell=tf.keras.layers.LSTMCell(units=units, **kwargs), return_last_output=return_last_output,
            return_seq_2d=return_seq_2d, return_last_state=return_last_state, in_channels=in_channels, name=name
        )


</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/recurrent.py" startline="470" endline="485" pcid="1641">
    def __init__(
        self,
        units,
        return_last_output=False,
        return_seq_2d=False,
        return_last_state=True,
        in_channels=None,
        name=None,  # 'grurnn'
        **kwargs
    ):
        super(GRURNN, self).__init__(
            cell=tf.keras.layers.GRUCell(units=units, **kwargs), return_last_output=return_last_output,
            return_seq_2d=return_seq_2d, return_last_state=return_last_state, in_channels=in_channels, name=name
        )


</source>
</class>

<class classid="64" nclones="7" nlines="18" similarity="72">
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/pooling.py" startline="61" endline="82" pcid="1651">
    def __init__(
        self,
        filter_size=(1, 2, 2, 1),
        strides=(1, 2, 2, 1),
        padding='SAME',
        pool=tf.nn.max_pool,
        name=None  # 'pool_pro',
    ):
        super().__init__(name)
        self.filter_size = filter_size
        self.strides = strides
        self.padding = padding
        self.pool = pool

        self.build()
        self._built = True

        logging.info(
            "PoolLayer %s: filter_size: %s strides: %s padding: %s pool: %s" %
            (self.name, str(self.filter_size), str(self.strides), self.padding, pool.__name__)
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/pooling.py" startline="450" endline="471" pcid="1671">
    def __init__(
        self,
        filter_size=(3, 3, 3),
        strides=(2, 2, 2),
        padding='VALID',
        data_format='channels_last',
        name=None  # 'maxpool3d'
    ):
        super().__init__(name)
        self.filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.data_format = data_format

        self.build()
        self._built = True

        logging.info(
            "MaxPool3d %s: filter_size: %s strides: %s padding: %s" %
            (self.name, str(filter_size), str(strides), str(padding))
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/pooling.py" startline="532" endline="553" pcid="1675">
    def __init__(
        self,
        filter_size=(3, 3, 3),
        strides=(2, 2, 2),
        padding='VALID',
        data_format='channels_last',
        name=None  # 'meanpool3d'
    ):
        super().__init__(name)
        self.filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.data_format = data_format

        self.build()
        self._built = True

        logging.info(
            "MeanPool3d %s: filter_size: %s strides: %s padding: %s" %
            (self.name, str(filter_size), str(strides), str(padding))
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/pooling.py" startline="295" endline="318" pcid="1663">
    def __init__(
        self,
        filter_size=(3, 3),
        strides=(2, 2),
        padding='SAME',
        data_format='channels_last',
        name=None  # 'maxpool2d'
    ):
        super().__init__(name)
        self.filter_size = filter_size
        if strides is None:
            strides = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.data_format = data_format

        self.build()
        self._built = True

        logging.info(
            "MaxPool2d %s: filter_size: %s strides: %s padding: %s" %
            (self.name, str(filter_size), str(strides), str(padding))
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/pooling.py" startline="370" endline="393" pcid="1667">
    def __init__(
        self,
        filter_size=(3, 3),
        strides=(2, 2),
        padding='SAME',
        data_format='channels_last',
        name=None  # 'meanpool2d'
    ):
        super().__init__(name)
        self.filter_size = filter_size
        if strides is None:
            strides = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.data_format = data_format

        self.build()
        self._built = True

        logging.info(
            "MeanPool2d %s: filter_size: %s strides: %s padding: %s" %
            (self.name, str(filter_size), str(strides), str(padding))
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/pooling.py" startline="209" endline="232" pcid="1659">
    def __init__(
        self,
        filter_size=3,
        strides=2,
        padding='SAME',
        data_format='channels_last',
        dilation_rate=1,
        name=None  # 'meanpool1d'
    ):
        super().__init__(name)
        self.filter_size = self._filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = self._dilation_rate = dilation_rate

        self.build()
        self._built = True

        logging.info(
            "MeanPool1d %s: filter_size: %s strides: %s padding: %s" %
            (self.name, str(filter_size), str(strides), str(padding))
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/pooling.py" startline="124" endline="147" pcid="1655">
    def __init__(
        self,
        filter_size=3,
        strides=2,
        padding='SAME',
        data_format='channels_last',
        dilation_rate=1,
        name=None  # 'maxpool1d'
    ):
        super().__init__(name)
        self.filter_size = self._filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = self._dilation_rate = dilation_rate

        self.build()
        self._built = True

        logging.info(
            "MaxPool1d %s: filter_size: %s strides: %s padding: %s" %
            (self.name, str(filter_size), str(strides), str(padding))
        )

</source>
</class>

<class classid="65" nclones="2" nlines="10" similarity="100">
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/pooling.py" startline="157" endline="168" pcid="1657">
    def build(self, inputs_shape=None):
        # https://tensorflow.google.cn/versions/r2.0/api_docs/python/tf/nn/pool
        if self.data_format == 'channels_last':
            self.data_format = 'NWC'
        elif self.data_format == 'channels_first':
            self.data_format = 'NCW'
        else:
            raise Exception("unsupported data format")
        self._filter_size = [self.filter_size]
        self._strides = [self.strides]
        self._dilation_rate = [self.dilation_rate]

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/pooling.py" startline="242" endline="254" pcid="1661">
    def build(self, inputs_shape=None):
        # pass
        # https://tensorflow.google.cn/versions/r2.0/api_docs/python/tf/nn/pool
        if self.data_format == 'channels_last':
            self.data_format = 'NWC'
        elif self.data_format == 'channels_first':
            self.data_format = 'NCW'
        else:
            raise Exception("unsupported data format")
        self._filter_size = [self.filter_size]
        self._strides = [self.strides]
        self._dilation_rate = [self.dilation_rate]

</source>
</class>

<class classid="66" nclones="7" nlines="10" similarity="90">
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/pooling.py" startline="603" endline="616" pcid="1679">
    def __init__(
        self,
        data_format="channels_last",
        name=None  # 'globalmaxpool1d'
    ):
        super().__init__(name)

        self.data_format = data_format

        self.build()
        self._built = True

        logging.info("GlobalMaxPool1d %s" % self.name)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/pooling.py" startline="659" endline="671" pcid="1683">
    def __init__(
        self,
        data_format='channels_last',
        name=None  # 'globalmeanpool1d'
    ):
        super().__init__(name)
        self.data_format = data_format

        self.build()
        self._built = True

        logging.info("GlobalMeanPool1d %s" % self.name)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/pooling.py" startline="937" endline="948" pcid="1703">
    def __init__(
        self,
        mode='TopLeft',
        name=None  # 'cornerpool2d'
    ):
        super().__init__(name)
        self.mode = mode
        self.build()
        self._built = True

        logging.info("CornerPool2d %s : mode: %s" % (self.name, str(mode)))

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/pooling.py" startline="825" endline="838" pcid="1695">
    def __init__(
        self,
        data_format='channels_last',
        name=None  # 'globalmaxpool3d'
    ):
        super().__init__(name)

        self.data_format = data_format

        self.build()
        self._built = True

        logging.info("GlobalMaxPool3d %s" % self.name)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/pooling.py" startline="769" endline="782" pcid="1691">
    def __init__(
        self,
        data_format='channels_last',
        name=None  # 'globalmeanpool2d'
    ):
        super().__init__(name)

        self.data_format = data_format

        self.build()
        self._built = True

        logging.info("GlobalMeanPool2d %s" % self.name)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/pooling.py" startline="881" endline="893" pcid="1699">
    def __init__(
        self,
        data_format='channels_last',
        name=None  # 'globalmeanpool3d'
    ):
        super().__init__(name)
        self.data_format = data_format

        self.build()
        self._built = True

        logging.info("GlobalMeanPool3d %s" % self.name)

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/pooling.py" startline="714" endline="726" pcid="1687">
    def __init__(
        self,
        data_format='channels_last',
        name=None  # 'globalmaxpool2d'
    ):
        super().__init__(name)
        self.data_format = data_format

        self.build()
        self._built = True

        logging.info("GlobalMaxPool2d %s" % self.name)

</source>
</class>

<class classid="67" nclones="3" nlines="12" similarity="75">
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/padding.py" startline="101" endline="115" pcid="1711">
    def __init__(
        self,
        padding,
        name=None,  # 'zeropad1d',
    ):
        super().__init__(name)
        self.padding = padding
        logging.info("ZeroPad1d   %s: padding: %s" % (self.name, str(padding)))

        if not isinstance(self.padding, (int, tuple, dict)):
            raise AssertionError()

        self.build()
        self._built = True

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/padding.py" startline="210" endline="225" pcid="1719">
    def __init__(
        self,
        padding,
        name=None,  # 'zeropad3d',
    ):
        super().__init__(name)
        self.padding = padding

        logging.info("ZeroPad3d   %s: padding: %s" % (self.name, str(self.padding)))

        if not isinstance(self.padding, (int, tuple)):
            raise AssertionError()

        self.build()
        self._built = True

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/padding.py" startline="155" endline="170" pcid="1715">
    def __init__(
        self,
        padding,
        name=None,  # 'zeropad2d',
    ):
        super().__init__(name)

        self.padding = padding
        logging.info("ZeroPad2d   %s: padding: %s" % (self.name, str(self.padding)))

        if not isinstance(self.padding, (int, tuple)):
            raise AssertionError("Padding should be of type `int` or `tuple`")

        self.build()
        self._built = True

</source>
</class>

<class classid="68" nclones="2" nlines="19" similarity="100">
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/image_resampling.py" startline="48" endline="72" pcid="1723">
    def __init__(
        self,
        scale,
        method='bilinear',
        antialias=False,
        data_format='channel_last',
        name=None,
    ):
        super(UpSampling2d, self).__init__(name)
        self.method = method
        self.antialias = antialias
        self.data_format = data_format

        logging.info(
            "UpSampling2d %s: scale: %s method: %s antialias: %s" % (self.name, scale, self.method, self.antialias)
        )

        self.build(None)
        self._built = True

        if isinstance(scale, (list, tuple)) and len(scale) != 2:
            raise ValueError("scale must be int or tuple/list of length 2")

        self.scale = (scale, scale) if isinstance(scale, int) else scale

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/image_resampling.py" startline="129" endline="153" pcid="1727">
    def __init__(
        self,
        scale,
        method='bilinear',
        antialias=False,
        data_format='channel_last',
        name=None,
    ):
        super(DownSampling2d, self).__init__(name)
        self.method = method
        self.antialias = antialias
        self.data_format = data_format

        logging.info(
            "DownSampling2d %s: scale: %s method: %s antialias: %s" % (self.name, scale, self.method, self.antialias)
        )

        self.build(None)
        self._built = True

        if isinstance(scale, (list, tuple)) and len(scale) != 2:
            raise ValueError("scale must be int or tuple/list of length 2")

        self.scale = (scale, scale) if isinstance(scale, int) else scale

</source>
</class>

<class classid="69" nclones="2" nlines="10" similarity="80">
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/extend.py" startline="35" endline="47" pcid="1731">
    def __init__(
        self,
        axis,
        name=None  # 'expand_dims',
    ):
        super(ExpandDims, self).__init__(name)
        self.axis = axis

        self.build((None, ))
        self._built = True

        logging.info("ExpandDims  %s: axis: %d" % (self.name, self.axis))

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/scale.py" startline="35" endline="47" pcid="1755">
    def __init__(
        self,
        init_scale=0.05,
        name='scale',
    ):
        super(Scale, self).__init__(name)
        self.init_scale = init_scale

        self.build((None, ))
        self._built = True

        logging.info("Scale  %s: init_scale: %f" % (self.name, self.init_scale))

</source>
</class>

<class classid="70" nclones="3" nlines="18" similarity="94">
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/activation.py" startline="56" endline="77" pcid="1739">
    def __init__(
        self,
        channel_shared=False,
        in_channels=None,
        a_init=truncated_normal(mean=0.0, stddev=0.05),
        name=None  # "prelu"
    ):

        super(PRelu, self).__init__(name)
        self.channel_shared = channel_shared
        self.in_channels = in_channels
        self.a_init = a_init

        if self.channel_shared:
            self.build((None, ))
            self._built = True
        elif self.in_channels is not None:
            self.build((None, self.in_channels))
            self._built = True

        logging.info("PRelu %s: channel_shared: %s" % (self.name, self.channel_shared))

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/activation.py" startline="231" endline="252" pcid="1747">
    def __init__(
        self,
        channel_shared=False,
        in_channels=None,
        a_init=truncated_normal(mean=0.0, stddev=0.05),
        name=None  # "ptrelu6"
    ):

        super(PTRelu6, self).__init__(name)
        self.channel_shared = channel_shared
        self.in_channels = in_channels
        self.a_init = a_init

        if self.channel_shared:
            self.build((None, ))
            self._built = True
        elif self.in_channels:
            self.build((None, self.in_channels))
            self._built = True

        logging.info("PTRelu6 %s: channel_shared: %s" % (self.name, self.channel_shared))

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/activation.py" startline="143" endline="164" pcid="1743">
    def __init__(
        self,
        channel_shared=False,
        in_channels=None,
        a_init=truncated_normal(mean=0.0, stddev=0.05),
        name=None  # "prelu6"
    ):

        super(PRelu6, self).__init__(name)
        self.channel_shared = channel_shared
        self.in_channels = in_channels
        self.a_init = a_init

        if self.channel_shared:
            self.build((None, ))
            self._built = True
        elif self.in_channels is not None:
            self.build((None, self.in_channels))
            self._built = True

        logging.info("PRelu6 %s: channel_shared: %s" % (self.name, self.channel_shared))

</source>
</class>

<class classid="71" nclones="2" nlines="19" similarity="89">
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/lambda_layers.py" startline="104" endline="125" pcid="1834">
    def __init__(
        self,
        fn,
        fn_weights=None,
        fn_args=None,
        name=None,
    ):

        super(Lambda, self).__init__(name=name)
        self.fn = fn
        self._trainable_weights = fn_weights if fn_weights is not None else []
        self.fn_args = fn_args if fn_args is not None else {}

        try:
            fn_name = repr(self.fn)
        except:
            fn_name = 'name not available'
        logging.info("Lambda  %s: func: %s, len_weights: %s" % (self.name, fn_name, len(self._trainable_weights)))

        self.build()
        self._built = True

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/lambda_layers.py" startline="226" endline="249" pcid="1839">
    def __init__(
        self,
        fn,
        fn_weights=None,
        fn_args=None,
        name=None,  #'elementwiselambda',
    ):

        super(ElementwiseLambda, self).__init__(name=name)
        self.fn = fn
        self._trainable_weights = fn_weights if fn_weights is not None else []
        self.fn_args = fn_args if fn_args is not None else {}

        try:
            fn_name = repr(self.fn)
        except:
            fn_name = 'name not available'
        logging.info(
            "ElementwiseLambda  %s: func: %s, len_weights: %s" % (self.name, fn_name, len(self._trainable_weights))
        )

        self.build()
        self._built = True

</source>
</class>

<class classid="72" nclones="2" nlines="13" similarity="100">
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/lambda_layers.py" startline="126" endline="140" pcid="1835">
    def __repr__(self):
        s = '{classname}('
        s += 'fn={fn_name},'
        s += 'len_weights={len_weights},'
        s += 'name=\'{name}\''
        s += ')'
        try:
            fn_name = repr(self.fn)
        except:
            fn_name = 'name not available'
        return s.format(
            classname=self.__class__.__name__, fn_name=fn_name, len_weights=len(self._trainable_weights),
            **self.__dict__
        )

</source>
<source file="systems/TensorLayer-2.2.4/tensorlayer/layers/lambda_layers.py" startline="250" endline="264" pcid="1840">
    def __repr__(self):
        s = '{classname}('
        s += 'fn={fn_name},'
        s += 'len_weights={len_weights},'
        s += 'name=\'{name}\''
        s += ')'
        try:
            fn_name = repr(self.fn)
        except:
            fn_name = 'name not available'
        return s.format(
            classname=self.__class__.__name__, fn_name=fn_name, len_weights=len(self._trainable_weights),
            **self.__dict__
        )

</source>
</class>

</clones>
