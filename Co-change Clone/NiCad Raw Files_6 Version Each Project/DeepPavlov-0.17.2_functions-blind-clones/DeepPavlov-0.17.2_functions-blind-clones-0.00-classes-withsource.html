<html>
<head>
    <title>NiCad6 Clone Report</title>
    <style type="text/css">
        body {font-family:sans-serif;}
        table {background-color:white; border:0px; padding:0px; border-spacing:4px; width:auto; margin-left:30px; margin-right:auto;}
        td {background-color:rgba(192,212,238,0.8); border:0px; padding:8px; width:auto; vertical-align:top; border-radius:8px}
        pre {background-color:white; padding:4px;}
        a {color:darkblue;}
    </style>
</head>
<body>
<h2>NiCad6 Clone Report</h2>
<table>
<tr style="font-size:14pt">
<td><b>System:</b> &nbsp; DeepPavlov-0.17.2</td>
<td><b>Clone pairs:</b> &nbsp; 12</td>
<td><b>Clone classes:</b> &nbsp; 7</td>
</tr>
<tr style="font-size:12pt">
<td style="background-color:white">Clone type: &nbsp; 2</td>
<td style="background-color:white">Granularity: &nbsp; functions-blind</td>
<td style="background-color:white">Max diff threshold: &nbsp; 0%</td>
<td style="background-color:white">Clone size: &nbsp; 10 - 2500 lines</td>
<td style="background-color:white">Total functions-blind: &nbsp; 788</td>
</tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 1:</b> &nbsp; 2 fragments, nominal size 17 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag89')" href="javascript:;">
DeepPavlov-0.17.2/deeppavlov/models/bert/bert_classifier.py: 164-185
</a>
<div class="mid" id="frag89" style="display:none"><pre>

    def _init_optimizer(self):
        with tf.variable_scope('Optimizer'):
            self.global_step = tf.get_variable('global_step', shape=[], dtype=tf.int32,
                                               initializer=tf.constant_initializer(0), trainable=False)
            # default optimizer for Bert is Adam with fixed L2 regularization
            if self.optimizer is None:

                self.train_op = self.get_train_op(self.loss, learning_rate=self.learning_rate_ph,
                                                  optimizer=AdamWeightDecayOptimizer,
                                                  weight_decay_rate=self.weight_decay_rate,
                                                  beta_1=0.9,
                                                  beta_2=0.999,
                                                  epsilon=1e-6,
                                                  exclude_from_weight_decay=["LayerNorm", "layer_norm", "bias"]
                                                  )
            else:
                self.train_op = self.get_train_op(self.loss, learning_rate=self.learning_rate_ph)

            if self.optimizer is None:
                new_global_step = self.global_step + 1
                self.train_op = tf.group(self.train_op, [self.global_step.assign(new_global_step)])
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag96')" href="javascript:;">
DeepPavlov-0.17.2/deeppavlov/models/bert/bert_squad.py: 181-202
</a>
<div class="mid" id="frag96" style="display:none"><pre>

    def _init_optimizer(self):
        with tf.variable_scope('Optimizer'):
            self.global_step = tf.get_variable('global_step', shape=[], dtype=tf.int32,
                                               initializer=tf.constant_initializer(0), trainable=False)
            # default optimizer for Bert is Adam with fixed L2 regularization
            if self.optimizer is None:

                self.train_op = self.get_train_op(self.loss, learning_rate=self.learning_rate_ph,
                                                  optimizer=AdamWeightDecayOptimizer,
                                                  weight_decay_rate=self.weight_decay_rate,
                                                  beta_1=0.9,
                                                  beta_2=0.999,
                                                  epsilon=1e-6,
                                                  exclude_from_weight_decay=["LayerNorm", "layer_norm", "bias"]
                                                  )
            else:
                self.train_op = self.get_train_op(self.loss, learning_rate=self.learning_rate_ph)

            if self.optimizer is None:
                new_global_step = self.global_step + 1
                self.train_op = tf.group(self.train_op, [self.global_step.assign(new_global_step)])
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 2:</b> &nbsp; 2 fragments, nominal size 46 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag171')" href="javascript:;">
DeepPavlov-0.17.2/deeppavlov/models/ranking/matching_models/dam_utils/layers.py: 313-381
</a>
<div class="mid" id="frag171" style="display:none"><pre>
def CNN_3d(x, out_channels_0, out_channels_1, add_relu=True):
    '''Add a 3d convlution layer with relu and max pooling layer.

    Args:
        x: a tensor with shape [batch, in_depth, in_height, in_width, in_channels]
        out_channels: a number
        filter_size: a number
        pooling_size: a number

    Returns:
        a flattened tensor with shape [batch, num_features]

    Raises:
    '''
    in_channels = x.shape[-1]
    weights_0 = tf.get_variable(
        name='filter_0',
        shape=[3, 3, 3, in_channels, out_channels_0],
        dtype=tf.float32,
        initializer=tf.random_uniform_initializer(-0.001, 0.001))
    bias_0 = tf.get_variable(
        name='bias_0',
        shape=[out_channels_0],
        dtype=tf.float32,
        initializer=tf.zeros_initializer())

    conv_0 = tf.nn.conv3d(x, weights_0, strides=[1, 1, 1, 1, 1], padding="SAME")
    log.info('conv_0 shape: %s' % conv_0.shape)
    conv_0 = conv_0 + bias_0

    if add_relu:
        conv_0 = tf.nn.elu(conv_0)

    pooling_0 = tf.nn.max_pool3d(
        conv_0,
        ksize=[1, 3, 3, 3, 1],
        strides=[1, 3, 3, 3, 1],
        padding="SAME")
    log.info('pooling_0 shape: %s' % pooling_0.shape)

    # layer_1
    weights_1 = tf.get_variable(
        name='filter_1',
        shape=[3, 3, 3, out_channels_0, out_channels_1],
        dtype=tf.float32,
        initializer=tf.random_uniform_initializer(-0.001, 0.001))
    bias_1 = tf.get_variable(
        name='bias_1',
        shape=[out_channels_1],
        dtype=tf.float32,
        initializer=tf.zeros_initializer())

    conv_1 = tf.nn.conv3d(pooling_0, weights_1, strides=[1, 1, 1, 1, 1], padding="SAME")
    log.info('conv_1 shape: %s' % conv_1.shape)
    conv_1 = conv_1 + bias_1

    if add_relu:
        conv_1 = tf.nn.elu(conv_1)

    pooling_1 = tf.nn.max_pool3d(
        conv_1,
        ksize=[1, 3, 3, 3, 1],
        strides=[1, 3, 3, 3, 1],
        padding="SAME")
    log.info('pooling_1 shape: %s' % pooling_1.shape)

    return tf.contrib.layers.flatten(pooling_1)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag172')" href="javascript:;">
DeepPavlov-0.17.2/deeppavlov/models/ranking/matching_models/dam_utils/layers.py: 382-450
</a>
<div class="mid" id="frag172" style="display:none"><pre>
def CNN_3d_2d(x, out_channels_0, out_channels_1, add_relu=True):
    '''Add a 3d convlution layer with relu and max pooling layer.

    Args:
        x: a tensor with shape [batch, in_depth, in_height, in_width, in_channels]
        out_channels: a number
        filter_size: a number
        pooling_size: a number

    Returns:
        a flattened tensor with shape [batch, num_features]

    Raises:
    '''
    in_channels = x.shape[-1]
    weights_0 = tf.get_variable(
        name='filter_0',
        shape=[1, 3, 3, in_channels, out_channels_0],
        dtype=tf.float32,
        initializer=tf.random_uniform_initializer(-0.01, 0.01))
    bias_0 = tf.get_variable(
        name='bias_0',
        shape=[out_channels_0],
        dtype=tf.float32,
        initializer=tf.zeros_initializer())

    conv_0 = tf.nn.conv3d(x, weights_0, strides=[1, 1, 1, 1, 1], padding="SAME")
    log.info('conv_0 shape: %s' % conv_0.shape)
    conv_0 = conv_0 + bias_0

    if add_relu:
        conv_0 = tf.nn.elu(conv_0)

    pooling_0 = tf.nn.max_pool3d(
        conv_0,
        ksize=[1, 1, 3, 3, 1],
        strides=[1, 1, 3, 3, 1],
        padding="SAME")
    log.info('pooling_0 shape: %s' % pooling_0.shape)

    # layer_1
    weights_1 = tf.get_variable(
        name='filter_1',
        shape=[1, 3, 3, out_channels_0, out_channels_1],
        dtype=tf.float32,
        initializer=tf.random_uniform_initializer(-0.01, 0.01))
    bias_1 = tf.get_variable(
        name='bias_1',
        shape=[out_channels_1],
        dtype=tf.float32,
        initializer=tf.zeros_initializer())

    conv_1 = tf.nn.conv3d(pooling_0, weights_1, strides=[1, 1, 1, 1, 1], padding="SAME")
    log.info('conv_1 shape: %s' % conv_1.shape)
    conv_1 = conv_1 + bias_1

    if add_relu:
        conv_1 = tf.nn.elu(conv_1)

    pooling_1 = tf.nn.max_pool3d(
        conv_1,
        ksize=[1, 1, 3, 3, 1],
        strides=[1, 1, 3, 3, 1],
        padding="SAME")
    log.info('pooling_1 shape: %s' % pooling_1.shape)

    return tf.contrib.layers.flatten(pooling_1)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 3:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag486')" href="javascript:;">
DeepPavlov-0.17.2/deeppavlov/dataset_readers/paraphraser_reader.py: 31-49
</a>
<div class="mid" id="frag486" style="display:none"><pre>
    def read(self,
             data_path: str,
             do_lower_case: bool = True,
             *args, **kwargs) -&gt; Dict[str, List[Tuple[Tuple[str, str], int]]]:
        """Read the paraphraser.ru dataset from files.

        Args:
            data_path: A path to a folder with dataset files.
            do_lower_case: Do you want to lowercase all texts
        """

        data_path = expand_path(data_path)
        train_fname = data_path / 'paraphrases.xml'
        test_fname = data_path / 'paraphrases_gold.xml'

        train_data = self._build_data(train_fname, do_lower_case)
        test_data = self._build_data(test_fname, do_lower_case)
        return {"train": train_data, "valid": [], "test": test_data}

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag506')" href="javascript:;">
DeepPavlov-0.17.2/deeppavlov/dataset_readers/rel_ranking_reader.py: 31-49
</a>
<div class="mid" id="frag506" style="display:none"><pre>
    def read(self,
             data_path: str,
             do_lower_case: bool = True,
             *args, **kwargs) -&gt; Dict[str, List[Tuple[Tuple[str, str], int]]]:
        """Read the paraphraser.ru dataset from files.
​
        Args:
            data_path: A path to a folder with dataset files.
            do_lower_case: Do you want to lowercase all texts
        """

        data_path = expand_path(data_path)
        train_fname = data_path / 'paraphrases.xml'
        test_fname = data_path / 'paraphrases_gold.xml'

        train_data = self._build_data(train_fname, do_lower_case)
        test_data = self._build_data(test_fname, do_lower_case)
        return {"train": train_data, "valid": [], "test": test_data}

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 4:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag751')" href="javascript:;">
DeepPavlov-0.17.2/deeppavlov/metrics/record_metrics.py: 13-32
</a>
<div class="mid" id="frag751" style="display:none"><pre>
def record_f1_score(record_examples: List[RecordNestedExample]):
    """Calculate F1 score for given nested ReCoRD examples

    Args:
        record_examples: processed ReCoRD examples

    Returns:
        float: F1 score
    """
    if not record_examples:
        return 0.
    f1_scores = []
    for example in record_examples:
        example_f1s = []
        for answer in example.answers:
            example_f1s.append(exact_match_score(example.prediction, answer))
        f1_scores.append(max(example_f1s))
    return np.mean(f1_scores)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag752')" href="javascript:;">
DeepPavlov-0.17.2/deeppavlov/metrics/record_metrics.py: 34-53
</a>
<div class="mid" id="frag752" style="display:none"><pre>
def record_em_score(record_examples: List[RecordNestedExample]):
    """Calculate Exact Match score for given nested ReCoRD examples

    Args:
        record_examples: processed ReCoRD examples

    Returns:
        float: Exact Match score
    """
    if not record_examples:
        return 0.
    em_scores = []
    for example in record_examples:
        example_ems = []
        for answer in example.answers:
            example_ems.append(string_f1_score(example.prediction, answer))
        em_scores.append(max(example_ems))
    return np.mean(em_scores)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 5:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag766')" href="javascript:;">
DeepPavlov-0.17.2/tests/test_tf_layers.py: 25-38
</a>
<div class="mid" id="frag766" style="display:none"><pre>
    def __init__(self, num_layers, num_units):
        sess_config = tf.ConfigProto(allow_soft_placement=True)
        sess_config.gpu_options.allow_growth = True
        self.sess = tf.Session(config=sess_config)

        self.x = tf.placeholder(shape=(None, None, 50), dtype=tf.float32)
        with tf.variable_scope('cudnn_model'):
            h, (h_last, c_last) = cudnn_lstm(self.x, num_units, num_layers, trainable_initial_states=True)

            self.h = h
            self.h_last = h_last

        self.sess.run(tf.global_variables_initializer())

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag770')" href="javascript:;">
DeepPavlov-0.17.2/tests/test_tf_layers.py: 56-69
</a>
<div class="mid" id="frag770" style="display:none"><pre>
    def __init__(self, num_layers, num_units):
        sess_config = tf.ConfigProto(allow_soft_placement=True)
        sess_config.gpu_options.allow_growth = True
        self.sess = tf.Session(config=sess_config)

        self.x = tf.placeholder(shape=(None, None, 50), dtype=tf.float32)
        with tf.variable_scope('cudnn_model'):
            h, (h_last, c_last) = cudnn_compatible_lstm(self.x, num_units, num_layers, trainable_initial_states=True)

            self.h = h
            self.h_last = h_last

        self.sess.run(tf.global_variables_initializer())

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 6:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag774')" href="javascript:;">
DeepPavlov-0.17.2/tests/test_tf_layers.py: 87-100
</a>
<div class="mid" id="frag774" style="display:none"><pre>
    def __init__(self, num_layers, num_units):
        sess_config = tf.ConfigProto(allow_soft_placement=True)
        sess_config.gpu_options.allow_growth = True
        self.sess = tf.Session(config=sess_config)

        self.x = tf.placeholder(shape=(None, None, 50), dtype=tf.float32)
        with tf.variable_scope('cudnn_model'):
            h, h_last = cudnn_gru(self.x, num_units, num_layers, trainable_initial_states=True)

            self.h = h
            self.h_last = h_last

        self.sess.run(tf.global_variables_initializer())

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag778')" href="javascript:;">
DeepPavlov-0.17.2/tests/test_tf_layers.py: 118-131
</a>
<div class="mid" id="frag778" style="display:none"><pre>
    def __init__(self, num_layers, num_units):
        sess_config = tf.ConfigProto(allow_soft_placement=True)
        sess_config.gpu_options.allow_growth = True
        self.sess = tf.Session(config=sess_config)

        self.x = tf.placeholder(shape=(None, None, 50), dtype=tf.float32)
        with tf.variable_scope('cudnn_model'):
            h, h_last = cudnn_compatible_gru(self.x, num_units, num_layers, trainable_initial_states=True)

            self.h = h
            self.h_last = h_last

        self.sess.run(tf.global_variables_initializer())

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 7:</b> &nbsp; 4 fragments, nominal size 14 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag783')" href="javascript:;">
DeepPavlov-0.17.2/tests/test_tf_layers.py: 157-174
</a>
<div class="mid" id="frag783" style="display:none"><pre>
    def test_cudnn_lstm_save_load(self, num_layers):
        x = np.random.normal(size=(10, 10, 50))
        tf.reset_default_graph()
        cdnnlstmmodel = DPCudnnLSTMModel(num_layers=num_layers, num_units=100)
        before_load_hidden, before_load_state = cdnnlstmmodel(x)[0], cdnnlstmmodel(x)[1]
        cdnnlstmmodel.save(str(tf_layers_data_path / 'dpcudnnlstmmodel' / 'model'))

        tf.reset_default_graph()
        cdnnlstmmodel = DPCudnnLSTMModel(num_layers=num_layers, num_units=100)
        cdnnlstmmodel.load(str(tf_layers_data_path / 'dpcudnnlstmmodel' / 'model'))
        after_load_hidden, after_load_state = cdnnlstmmodel(x)[0], cdnnlstmmodel(x)[1]

        equal_hidden = self.equal_values(after_load_hidden, before_load_hidden)
        equal_state = self.equal_values(after_load_state, before_load_state)

        assert equal_hidden &gt; 1 - self.allowed_error_lvl
        assert equal_state &gt; 1 - self.allowed_error_lvl

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag785')" href="javascript:;">
DeepPavlov-0.17.2/tests/test_tf_layers.py: 195-212
</a>
<div class="mid" id="frag785" style="display:none"><pre>
    def test_cudnn_gru_save_load(self, num_layers):
        x = np.random.normal(size=(10, 10, 50))
        tf.reset_default_graph()
        cdnngrumodel = DPCudnnGRUModel(num_layers=num_layers, num_units=100)
        before_load_hidden, before_load_state = cdnngrumodel(x)[0], cdnngrumodel(x)[1]
        cdnngrumodel.save(str(tf_layers_data_path / 'cdnngrumodel' / 'model'))

        tf.reset_default_graph()
        cdnngrumodel = DPCudnnGRUModel(num_layers=num_layers, num_units=100)
        cdnngrumodel.load(str(tf_layers_data_path / 'cdnngrumodel' / 'model'))
        after_load_hidden, after_load_state = cdnngrumodel(x)[0], cdnngrumodel(x)[1]

        equal_hidden = self.equal_values(after_load_hidden, before_load_hidden)
        equal_state = self.equal_values(after_load_state, before_load_state)

        assert equal_hidden &gt; 1 - self.allowed_error_lvl
        assert equal_state &gt; 1 - self.allowed_error_lvl

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag786')" href="javascript:;">
DeepPavlov-0.17.2/tests/test_tf_layers.py: 214-230
</a>
<div class="mid" id="frag786" style="display:none"><pre>
    def test_cudnn_gru_save_and_cudnn_compatible_load(self, num_layers):
        x = np.random.normal(size=(10, 10, 50))
        tf.reset_default_graph()
        cdnngrumodel = DPCudnnGRUModel(num_layers=num_layers, num_units=100)
        before_load_hidden, before_load_state = cdnngrumodel(x)[0], cdnngrumodel(x)[1]
        cdnngrumodel.save(str(tf_layers_data_path / 'cdnngrumodel' / 'model'))

        tf.reset_default_graph()
        cdnngrumodel = DPGRUModel(num_layers=num_layers, num_units=100)
        cdnngrumodel.load(str(tf_layers_data_path / 'cdnngrumodel' / 'model'))
        after_load_hidden, after_load_state = cdnngrumodel(x)[0], cdnngrumodel(x)[1]

        equal_hidden = self.equal_values(after_load_hidden, before_load_hidden)
        equal_state = self.equal_values(after_load_state, before_load_state)

        assert equal_hidden &gt; 1 - self.allowed_error_lvl
        assert equal_state &gt; 1 - self.allowed_error_lvl
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag784')" href="javascript:;">
DeepPavlov-0.17.2/tests/test_tf_layers.py: 176-193
</a>
<div class="mid" id="frag784" style="display:none"><pre>
    def test_cudnn_lstm_save_and_cudnn_compatible_load(self, num_layers):
        x = np.random.normal(size=(10, 10, 50))
        tf.reset_default_graph()
        cdnnlstmmodel = DPCudnnLSTMModel(num_layers=num_layers, num_units=100)
        before_load_hidden, before_load_state = cdnnlstmmodel(x)[0], cdnnlstmmodel(x)[1]
        cdnnlstmmodel.save(str(tf_layers_data_path / 'dpcudnnlstmmodel' / 'model'))

        tf.reset_default_graph()
        cdnnlstmmodel = DPLSTMModel(num_layers=num_layers, num_units=100)
        cdnnlstmmodel.load(str(tf_layers_data_path / 'dpcudnnlstmmodel' / 'model'))
        after_load_hidden, after_load_state = cdnnlstmmodel(x)[0], cdnnlstmmodel(x)[1]

        equal_hidden = self.equal_values(after_load_hidden, before_load_hidden)
        equal_state = self.equal_values(after_load_state, before_load_state)

        assert equal_hidden &gt; 1 - self.allowed_error_lvl
        assert equal_state &gt; 1 - self.allowed_error_lvl

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<script language="JavaScript">
function ShowHide(divId) { 
    if(document.getElementById(divId).style.display == 'none') {
        document.getElementById(divId).style.display='block';
    } else { 
        document.getElementById(divId).style.display = 'none';
    } 
}
</script>
</body>
</html>
