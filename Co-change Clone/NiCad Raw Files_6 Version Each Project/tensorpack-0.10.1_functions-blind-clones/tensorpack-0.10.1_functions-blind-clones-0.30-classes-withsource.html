<html>
<head>
    <title>NiCad6 Clone Report</title>
    <style type="text/css">
        body {font-family:sans-serif;}
        table {background-color:white; border:0px; padding:0px; border-spacing:4px; width:auto; margin-left:30px; margin-right:auto;}
        td {background-color:rgba(192,212,238,0.8); border:0px; padding:8px; width:auto; vertical-align:top; border-radius:8px}
        pre {background-color:white; padding:4px;}
        a {color:darkblue;}
    </style>
</head>
<body>
<h2>NiCad6 Clone Report</h2>
<table>
<tr style="font-size:14pt">
<td><b>System:</b> &nbsp; tensorpack-0.10.1</td>
<td><b>Clone pairs:</b> &nbsp; 9</td>
<td><b>Clone classes:</b> &nbsp; 9</td>
</tr>
<tr style="font-size:12pt">
<td style="background-color:white">Clone type: &nbsp; 3-2</td>
<td style="background-color:white">Granularity: &nbsp; functions-blind</td>
<td style="background-color:white">Max diff threshold: &nbsp; 30%</td>
<td style="background-color:white">Clone size: &nbsp; 10 - 2500 lines</td>
<td style="background-color:white">Total functions-blind: &nbsp; 1422</td>
</tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 1:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 81%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag92')" href="javascript:;">
tensorpack-0.10.1/tensorpack/dataflow/imgaug/imgproc.py: 152-164
</a>
<div class="mid" id="frag92" style="display:none"><pre>
    def _augment(self, img, _):
        img = img.astype('float32')
        if self.all_channel:
            mean = np.mean(img)
            std = np.std(img)
        else:
            mean = np.mean(img, axis=(0, 1), keepdims=True)
            std = np.std(img, axis=(0, 1), keepdims=True)
        std = np.maximum(std, 1.0 / np.sqrt(np.prod(img.shape)))
        img = (img - mean) / std
        return img


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag108')" href="javascript:;">
tensorpack-0.10.1/tensorpack/dataflow/imgaug/imgproc.py: 322-331
</a>
<div class="mid" id="frag108" style="display:none"><pre>
    def _augment(self, img, _):
        img = img.astype('float32')
        if self.all_channel:
            minimum = np.min(img)
            maximum = np.max(img)
        else:
            minimum = np.min(img, axis=(0, 1), keepdims=True)
            maximum = np.max(img, axis=(0, 1), keepdims=True)
        img = (self.max - self.min) * (img - minimum) / (maximum - minimum) + self.min
        return img
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 2:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 78%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag180')" href="javascript:;">
tensorpack-0.10.1/tensorpack/dataflow/imgaug/imgaug_test.py: 94-114
</a>
<div class="mid" id="frag180" style="display:none"><pre>
    def test_augmentors(self):
        augmentors = self._get_augs()

        img = _rand_image()
        orig = img.copy()
        tfms = augmentors.get_transform(img)

        # test printing
        print(augmentors)
        print(tfms)

        newimg = tfms.apply_image(img)
        print(tfms)  # lazy ones will instantiate after the first apply

        newimg2 = tfms.apply_image(orig)
        self.assertTrue(np.allclose(newimg, newimg2))
        self.assertEqual(newimg2.shape[0], 30)

        coords = np.asarray([[0, 0], [10, 12]], dtype="float32")
        tfms.apply_coords(coords)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag182')" href="javascript:;">
tensorpack-0.10.1/tensorpack/dataflow/imgaug/imgaug_test.py: 128-141
</a>
<div class="mid" id="frag182" style="display:none"><pre>
    def test_legacy_augs_new_usage(self):
        augmentors = self._get_augs_with_legacy()

        img = _rand_image()
        orig = img.copy()
        tfms = augmentors.get_transform(img)
        newimg = tfms.apply_image(img)
        newimg2 = tfms.apply_image(orig)
        self.assertTrue(np.allclose(newimg, newimg2))
        self.assertEqual(newimg2.shape[0], 30)

        coords = np.asarray([[0, 0], [10, 12]], dtype="float32")
        tfms.apply_coords(coords)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 3:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag181')" href="javascript:;">
tensorpack-0.10.1/tensorpack/dataflow/imgaug/imgaug_test.py: 115-127
</a>
<div class="mid" id="frag181" style="display:none"><pre>
    def test_legacy_usage(self):
        augmentors = self._get_augs()

        img = _rand_image()
        orig = img.copy()
        newimg, tfms = augmentors.augment_return_params(img)
        newimg2 = augmentors.augment_with_params(orig, tfms)
        self.assertTrue(np.allclose(newimg, newimg2))
        self.assertEqual(newimg2.shape[0], 30)

        coords = np.asarray([[0, 0], [10, 12]], dtype="float32")
        augmentors.augment_coords(coords, tfms)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag183')" href="javascript:;">
tensorpack-0.10.1/tensorpack/dataflow/imgaug/imgaug_test.py: 142-155
</a>
<div class="mid" id="frag183" style="display:none"><pre>
    def test_legacy_augs_legacy_usage(self):
        augmentors = self._get_augs_with_legacy()

        img = _rand_image()
        orig = img.copy()
        newimg, tfms = augmentors.augment_return_params(img)
        newimg2 = augmentors.augment_with_params(orig, tfms)
        self.assertTrue(np.allclose(newimg, newimg2))
        self.assertEqual(newimg2.shape[0], 30)

        coords = np.asarray([[0, 0], [10, 12]], dtype="float32")
        augmentors.augment_coords(coords, tfms)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 4:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag286')" href="javascript:;">
tensorpack-0.10.1/tensorpack/dataflow/image.py: 130-151
</a>
<div class="mid" id="frag286" style="display:none"><pre>

    def __init__(self, ds, augmentors, img_index=0, coords_index=1, copy=True, catch_exceptions=False):

        """
        Args:
            ds (DataFlow): input DataFlow.
            augmentors (AugmentorList): a list of :class:`imgaug.ImageAugmentor` to be applied in order.
            img_index (int or str): the index/key of the image component to be augmented.
            coords_index (int or str): the index/key of the coordinate component to be augmented.
            copy, catch_exceptions: same as in :class:`AugmentImageComponent`
        """
        if isinstance(augmentors, AugmentorList):
            self.augs = augmentors
        else:
            self.augs = AugmentorList(augmentors)

        self._img_index = img_index
        self._coords_index = coords_index
        self._copy = copy
        self._exception_handler = ExceptionHandler(catch_exceptions)

        super(AugmentImageCoordinates, self).__init__(ds, self._aug_mapper)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag289')" href="javascript:;">
tensorpack-0.10.1/tensorpack/dataflow/image.py: 184-204
</a>
<div class="mid" id="frag289" style="display:none"><pre>

    def __init__(self, ds, augmentors, index=(0, 1), coords_index=(), copy=True, catch_exceptions=False):
        """
        Args:
            ds (DataFlow): input DataFlow.
            augmentors (AugmentorList): a list of :class:`imgaug.ImageAugmentor` instance to be applied in order.
            index: tuple of indices of the image components.
            coords_index: tuple of indices of the coordinates components.
            copy, catch_exceptions: same as in :class:`AugmentImageComponent`
        """
        if isinstance(augmentors, AugmentorList):
            self.augs = augmentors
        else:
            self.augs = AugmentorList(augmentors)
        self.ds = ds
        self._exception_handler = ExceptionHandler(catch_exceptions)
        self._copy = copy
        self._index = index
        self._coords_index = coords_index

        super(AugmentImageComponents, self).__init__(ds, self._aug_mapper)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 5:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag346')" href="javascript:;">
tensorpack-0.10.1/tensorpack/models/pool.py: 19-34
</a>
<div class="mid" id="frag346" style="display:none"><pre>
def MaxPooling(
        inputs,
        pool_size,
        strides=None,
        padding='valid',
        data_format='channels_last'):
    """
    Same as `tf.layers.MaxPooling2D`. Default strides is equal to pool_size.
    """
    if strides is None:
        strides = pool_size
    layer = tf.layers.MaxPooling2D(pool_size, strides, padding=padding, data_format=data_format)
    ret = layer.apply(inputs, scope=tf.get_variable_scope())
    return tf.identity(ret, name='output')


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag347')" href="javascript:;">
tensorpack-0.10.1/tensorpack/models/pool.py: 39-54
</a>
<div class="mid" id="frag347" style="display:none"><pre>
def AvgPooling(
        inputs,
        pool_size,
        strides=None,
        padding='valid',
        data_format='channels_last'):
    """
    Same as `tf.layers.AveragePooling2D`. Default strides is equal to pool_size.
    """
    if strides is None:
        strides = pool_size
    layer = tf.layers.AveragePooling2D(pool_size, strides, padding=padding, data_format=data_format)
    ret = layer.apply(inputs, scope=tf.get_variable_scope())
    return tf.identity(ret, name='output')


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 6:</b> &nbsp; 2 fragments, nominal size 16 lines, similarity 81%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag982')" href="javascript:;">
tensorpack-0.10.1/examples/GAN/Improved-WGAN.py: 28-44
</a>
<div class="mid" id="frag982" style="display:none"><pre>
    def discriminator(self, imgs):
        nf = 64
        with argscope(Conv2D, activation=tf.identity, kernel_size=4, strides=2):
            l = (LinearWrap(imgs)
                 .Conv2D('conv0', nf, activation=tf.nn.leaky_relu)
                 .Conv2D('conv1', nf * 2)
                 .LayerNorm('ln1')
                 .tf.nn.leaky_relu()
                 .Conv2D('conv2', nf * 4)
                 .LayerNorm('ln2')
                 .tf.nn.leaky_relu()
                 .Conv2D('conv3', nf * 8)
                 .LayerNorm('ln3')
                 .tf.nn.leaky_relu()
                 .FullyConnected('fct', 1, activation=tf.identity)())
        return tf.reshape(l, [-1])

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag988')" href="javascript:;">
tensorpack-0.10.1/examples/GAN/DCGAN.py: 61-78
</a>
<div class="mid" id="frag988" style="display:none"><pre>
    def discriminator(self, imgs):
        """ return a (b, 1) logits"""
        nf = 64
        with argscope(Conv2D, kernel_size=4, strides=2):
            l = (LinearWrap(imgs)
                 .Conv2D('conv0', nf, activation=tf.nn.leaky_relu)
                 .Conv2D('conv1', nf * 2)
                 .BatchNorm('bn1')
                 .tf.nn.leaky_relu()
                 .Conv2D('conv2', nf * 4)
                 .BatchNorm('bn2')
                 .tf.nn.leaky_relu()
                 .Conv2D('conv3', nf * 8)
                 .BatchNorm('bn3')
                 .tf.nn.leaky_relu()
                 .FullyConnected('fct', 1)())
        return l

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 7:</b> &nbsp; 2 fragments, nominal size 15 lines, similarity 73%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1047')" href="javascript:;">
tensorpack-0.10.1/examples/keras/mnist-keras.py: 43-58
</a>
<div class="mid" id="frag1047" style="display:none"><pre>
def get_keras_model():
    with clear_tower0_name_scope():
        M = keras.models.Sequential()
        M.add(KL.Conv2D(32, 3, activation='relu', padding='same'))
        M.add(KL.MaxPooling2D())
        M.add(KL.Conv2D(32, 3, activation='relu', padding='same'))
        M.add(KL.Conv2D(32, 3, activation='relu', padding='same'))
        M.add(KL.MaxPooling2D())
        M.add(KL.Conv2D(32, 3, padding='same', activation='relu'))
        M.add(KL.Flatten())
        M.add(KL.Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(1e-5)))
        M.add(KL.Dropout(rate=0.5))
        M.add(KL.Dense(10, activation=None, kernel_regularizer=keras.regularizers.l2(1e-5)))
    return M


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1054')" href="javascript:;">
tensorpack-0.10.1/examples/keras/mnist-keras-v2.py: 34-55
</a>
<div class="mid" id="frag1054" style="display:none"><pre>
    def model_func(image):
        """
        Keras model has to be created inside this function to be used with tensorpack.
        """
        M = keras.models.Sequential()
        # input_tensor have to be used here for tensorpack trainer to function properly.
        # Just use inputs[1], inputs[2] if you have multiple inputs.
        M.add(KL.InputLayer(input_tensor=image))
        M.add(KL.Conv2D(32, 3, activation='relu', padding='same'))
        M.add(KL.MaxPooling2D())
        M.add(KL.Conv2D(32, 3, activation='relu', padding='same'))
        M.add(KL.Conv2D(32, 3, activation='relu', padding='same'))
        M.add(KL.MaxPooling2D())
        M.add(KL.Conv2D(32, 3, padding='same', activation='relu'))

        M.add(KL.Flatten())
        M.add(KL.Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(1e-5)))
        M.add(KL.Dropout(0.5))
        M.add(KL.Dense(10, activation=None, kernel_regularizer=keras.regularizers.l2(1e-5)))
        M.add(KL.Activation('softmax'))
        return M

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 8:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 88%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1279')" href="javascript:;">
tensorpack-0.10.1/examples/basics/svhn-digit-convnet.py: 68-88
</a>
<div class="mid" id="frag1279" style="display:none"><pre>
def get_data():
    d1 = dataset.SVHNDigit('train')
    d2 = dataset.SVHNDigit('extra')
    data_train = RandomMixData([d1, d2])
    data_test = dataset.SVHNDigit('test', shuffle=False)

    augmentors = [
        imgaug.Resize((40, 40)),
        imgaug.Brightness(30),
        imgaug.Contrast((0.5, 1.5)),
    ]
    data_train = AugmentImageComponent(data_train, augmentors)
    data_train = BatchData(data_train, 128)
    data_train = MultiProcessRunner(data_train, 5, 5)

    augmentors = [imgaug.Resize((40, 40))]
    data_test = AugmentImageComponent(data_test, augmentors)
    data_test = BatchData(data_test, 128, remainder=True)
    return data_train, data_test


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1417')" href="javascript:;">
tensorpack-0.10.1/examples/DisturbLabel/svhn-disturb.py: 21-42
</a>
<div class="mid" id="frag1417" style="display:none"><pre>
def get_data():
    d1 = dataset.SVHNDigit('train')
    d2 = dataset.SVHNDigit('extra')
    data_train = RandomMixData([d1, d2])
    data_train = DisturbLabel(data_train, args.prob)
    data_test = dataset.SVHNDigit('test')

    augmentors = [
        imgaug.Resize((40, 40)),
        imgaug.Brightness(30),
        imgaug.Contrast((0.5, 1.5)),
    ]
    data_train = AugmentImageComponent(data_train, augmentors)
    data_train = BatchData(data_train, 128)
    data_train = MultiProcessRunner(data_train, 5, 5)

    augmentors = [imgaug.Resize((40, 40))]
    data_test = AugmentImageComponent(data_test, augmentors)
    data_test = BatchData(data_test, 128, remainder=True)
    return data_train, data_test


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 9:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1289')" href="javascript:;">
tensorpack-0.10.1/examples/basics/export-model.py: 127-140
</a>
<div class="mid" id="frag1289" style="display:none"><pre>
def apply(model_path):
    """Run inference from a training model checkpoint. """
    pred_config = PredictConfig(
        session_init=SmartInit(model_path),
        model=Model(),
        input_names=['input_img'],
        output_names=['prediction_img'])

    pred = OfflinePredictor(pred_config)
    img = cv2.imread('lena.png')
    prediction = pred([img])[0]
    cv2.imwrite('applied_default.jpg', prediction[0])


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1290')" href="javascript:;">
tensorpack-0.10.1/examples/basics/export-model.py: 141-155
</a>
<div class="mid" id="frag1290" style="display:none"><pre>
def apply_inference_graph(model_path):
    """Run inference from a different graph, which receives encoded images buffers. """
    pred_config = PredictConfig(
        session_init=SmartInit(model_path),
        model=InferenceOnlyModel(),
        input_names=['input_img_bytes'],
        output_names=['prediction_img_bytes'])

    pred = OfflinePredictor(pred_config)
    buf = open('lena.png', 'rb').read()
    prediction = pred([buf])[0]
    with open('applied_inference_graph.png', 'wb') as f:
        f.write(prediction[0])


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<script language="JavaScript">
function ShowHide(divId) { 
    if(document.getElementById(divId).style.display == 'none') {
        document.getElementById(divId).style.display='block';
    } else { 
        document.getElementById(divId).style.display = 'none';
    } 
}
</script>
</body>
</html>
