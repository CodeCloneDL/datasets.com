<clonepair1>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/cmc_score.py" startline="183" endline="208" pcid="410"></source>
    def __init__(
        self,
        embeddings_key: str,
        pids_key: str,
        cids_key: str,
        is_query_key: str,
        topk_args: Iterable[int] = None,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=ReidCMCMetric(
                embeddings_key=embeddings_key,
                pids_key=pids_key,
                cids_key=cids_key,
                is_query_key=is_query_key,
                topk_args=topk_args,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=[embeddings_key, is_query_key],
            target_key=[pids_key, cids_key],
        )


</clonepair1>

<clonepair1>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/segmentation.py" startline="91" endline="120" pcid="418"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        class_dim: int = 1,
        weights: Optional[List[float]] = None,
        class_names: Optional[List[str]] = None,
        threshold: Optional[float] = None,
        log_on_batch: bool = True,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=IOUMetric(
                class_dim=class_dim,
                weights=weights,
                class_names=class_names,
                threshold=threshold,
                compute_per_class_metrics=compute_per_class_metrics,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair1>
<clonepair2>
<source file="systems/catalyst-21.12/catalyst/contrib/utils/thresholds.py" startline="373" endline="409" pcid="82"></source>
def get_best_multilabel_thresholds(
    scores: np.ndarray, labels: np.ndarray, objective: METRIC_FN
) -> Tuple[float, List[float]]:
    """Finds best thresholds for multilabel classification task.

    Args:
        scores: estimated per-class scores/probabilities predicted by the model
        labels: ground truth labels
        objective: callable function, metric which we want to maximize

    Returns:
        tuple with best found objective score and per-class thresholds
    """
    num_classes = scores.shape[1]
    best_metric, best_thresholds = 0.0, []

    for baseline_thresholds_fn in [
        get_baseline_thresholds,
        get_multiclass_thresholds,
        get_binary_threshold,
        get_multilabel_thresholds,
    ]:
        _, baseline_thresholds = baseline_thresholds_fn(
            labels=labels, scores=scores, objective=objective
        )
        if isinstance(baseline_thresholds, (int, float)):
            baseline_thresholds = [baseline_thresholds] * num_classes
        metric_value, thresholds_value = get_multilabel_thresholds_greedy(
            labels=labels, scores=scores, objective=objective, thresholds=baseline_thresholds
        )
        if metric_value > best_metric:
            best_metric = metric_value
            best_thresholds = thresholds_value

    return best_metric, best_thresholds


</clonepair2>

<clonepair2>
<source file="systems/catalyst-21.12/catalyst/contrib/utils/thresholds.py" startline="410" endline="448" pcid="83"></source>
def get_best_multiclass_thresholds(
    scores: np.ndarray, labels: np.ndarray, objective: METRIC_FN
) -> Tuple[float, List[float]]:
    """Finds best thresholds for multiclass classification task.

    Args:
        scores: estimated per-class scores/probabilities predicted by the model
        labels: ground truth labels
        objective: callable function, metric which we want to maximize

    Returns:
        tuple with best found objective score and per-class thresholds
    """
    num_classes = scores.shape[1]
    best_metric, best_thresholds = 0.0, []
    labels_onehot = np.zeros((labels.size, labels.max() + 1))
    labels_onehot[np.arange(labels.size), labels] = 1

    for baseline_thresholds_fn in [
        get_baseline_thresholds,
        get_multiclass_thresholds,
        get_binary_threshold,
        get_multilabel_thresholds,
    ]:
        _, baseline_thresholds = baseline_thresholds_fn(
            labels=labels_onehot, scores=scores, objective=objective
        )
        if isinstance(baseline_thresholds, (int, float)):
            baseline_thresholds = [baseline_thresholds] * num_classes
        metric_value, thresholds_value = get_multiclass_thresholds_greedy(
            labels=labels, scores=scores, objective=objective, thresholds=baseline_thresholds
        )
        if metric_value > best_metric:
            best_metric = metric_value
            best_thresholds = thresholds_value

    return best_metric, best_thresholds


</clonepair2>
<clonepair3>
<source file="systems/catalyst-21.12/tests/catalyst/callbacks/test_soft_update.py" startline="20" endline="44" pcid="883"></source>
def test_soft_update():

    model = nn.ModuleDict(
        {"target": nn.Linear(10, 10, bias=False), "source": nn.Linear(10, 10, bias=False)}
    )
    set_requires_grad(model, False)
    model["target"].weight.data.fill_(0)

    runner = DummyRunner(model=model)
    runner.is_train_loader = True

    soft_update = dl.SoftUpdateCallaback(
        target_model_key="target", source_model_key="source", tau=0.1, scope="on_batch_end"
    )
    soft_update.on_batch_end(runner)

    checks = (
        ((0.1 * runner.model["source"].weight.data) == runner.model["target"].weight.data)
        .flatten()
        .tolist()
    )

    assert all(checks)


</clonepair3>

<clonepair3>
<source file="systems/catalyst-21.12/tests/catalyst/callbacks/test_soft_update.py" startline="45" endline="63" pcid="884"></source>
def test_soft_update_not_work():

    model = nn.ModuleDict(
        {"target": nn.Linear(10, 10, bias=False), "source": nn.Linear(10, 10, bias=False)}
    )
    set_requires_grad(model, False)
    model["target"].weight.data.fill_(0)

    runner = DummyRunner(model=model)
    runner.is_train_loader = True

    soft_update = dl.SoftUpdateCallaback(
        target_model_key="target", source_model_key="source", tau=0.1, scope="on_batch_start"
    )
    soft_update.on_batch_end(runner)

    checks = (runner.model["target"].weight.data == 0).flatten().tolist()

    assert all(checks)
</clonepair3>
<clonepair4>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/cmc_score.py" startline="183" endline="208" pcid="410"></source>
    def __init__(
        self,
        embeddings_key: str,
        pids_key: str,
        cids_key: str,
        is_query_key: str,
        topk_args: Iterable[int] = None,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=ReidCMCMetric(
                embeddings_key=embeddings_key,
                pids_key=pids_key,
                cids_key=cids_key,
                is_query_key=is_query_key,
                topk_args=topk_args,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=[embeddings_key, is_query_key],
            target_key=[pids_key, cids_key],
        )


</clonepair4>

<clonepair4>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/classification.py" startline="187" endline="212" pcid="408"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        num_classes: Optional[int] = None,
        zero_division: int = 0,
        log_on_batch: bool = True,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MultilabelPrecisionRecallF1SupportMetric(
                zero_division=zero_division,
                prefix=prefix,
                suffix=suffix,
                compute_per_class_metrics=compute_per_class_metrics,
                num_classes=num_classes,
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair4>
<clonepair5>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/cmc_score.py" startline="141" endline="164" pcid="409"></source>
    def __init__(
        self,
        embeddings_key: str,
        labels_key: str,
        is_query_key: str,
        topk_args: Iterable[int] = None,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=CMCMetric(
                embeddings_key=embeddings_key,
                labels_key=labels_key,
                is_query_key=is_query_key,
                topk_args=topk_args,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=[embeddings_key, is_query_key],
            target_key=[labels_key],
        )


</clonepair5>

<clonepair5>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/classification.py" startline="187" endline="212" pcid="408"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        num_classes: Optional[int] = None,
        zero_division: int = 0,
        log_on_batch: bool = True,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MultilabelPrecisionRecallF1SupportMetric(
                zero_division=zero_division,
                prefix=prefix,
                suffix=suffix,
                compute_per_class_metrics=compute_per_class_metrics,
                num_classes=num_classes,
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair5>
<clonepair6>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/cmc_score.py" startline="141" endline="164" pcid="409"></source>
    def __init__(
        self,
        embeddings_key: str,
        labels_key: str,
        is_query_key: str,
        topk_args: Iterable[int] = None,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=CMCMetric(
                embeddings_key=embeddings_key,
                labels_key=labels_key,
                is_query_key=is_query_key,
                topk_args=topk_args,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=[embeddings_key, is_query_key],
            target_key=[labels_key],
        )


</clonepair6>

<clonepair6>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/cmc_score.py" startline="183" endline="208" pcid="410"></source>
    def __init__(
        self,
        embeddings_key: str,
        pids_key: str,
        cids_key: str,
        is_query_key: str,
        topk_args: Iterable[int] = None,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=ReidCMCMetric(
                embeddings_key=embeddings_key,
                pids_key=pids_key,
                cids_key=cids_key,
                is_query_key=is_query_key,
                topk_args=topk_args,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=[embeddings_key, is_query_key],
            target_key=[pids_key, cids_key],
        )


</clonepair6>
<clonepair7>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/auc.py" startline="74" endline="91" pcid="417"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=AUCMetric(
                compute_per_class_metrics=compute_per_class_metrics, prefix=prefix, suffix=suffix
            ),
            input_key=input_key,
            target_key=target_key,
        )


</clonepair7>

<clonepair7>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/accuracy.py" startline="177" endline="194" pcid="412"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        threshold: Union[float, torch.Tensor] = 0.5,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MultilabelAccuracyMetric(threshold=threshold, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair7>
<clonepair8>
<source file="systems/catalyst-21.12/catalyst/contrib/utils/thresholds.py" startline="288" endline="326" pcid="79"></source>
def get_multilabel_thresholds_greedy(
    scores: np.ndarray,
    labels: np.ndarray,
    objective: METRIC_FN,
    num_iterations: int = 100,
    num_thresholds: int = 100,
    thresholds: np.ndarray = None,
    patience: int = 3,
    atol: float = 0.01,
) -> Tuple[float, List[float]]:
    """Finds best thresholds for multilabel classification task with brute-force algorithm.

    Args:
        scores: estimated per-class scores/probabilities predicted by the model
        labels: ground truth labels
        objective: callable function, metric which we want to maximize
        num_iterations: number of iteration for brute-force algorithm
        num_thresholds: number of thresholds ot try for each class
        thresholds: baseline thresholds, which we want to optimize
        patience: maximum number of iteration before early stop exit
        atol: minimum required improvement per iteration for early stop exit

    Returns:
        tuple with best found objective score and per-class thresholds
    """
    best_metric, thresholds = get_thresholds_greedy(
        scores=scores,
        labels=labels,
        score_fn=partial(_multilabel_score_fn, objective=objective),
        num_iterations=num_iterations,
        num_thresholds=num_thresholds,
        thresholds=thresholds,
        patience=patience,
        atol=atol,
    )

    return best_metric, thresholds


</clonepair8>

<clonepair8>
<source file="systems/catalyst-21.12/catalyst/contrib/utils/thresholds.py" startline="334" endline="372" pcid="81"></source>
def get_multiclass_thresholds_greedy(
    scores: np.ndarray,
    labels: np.ndarray,
    objective: METRIC_FN,
    num_iterations: int = 100,
    num_thresholds: int = 100,
    thresholds: np.ndarray = None,
    patience: int = 3,
    atol: float = 0.01,
) -> Tuple[float, List[float]]:
    """Finds best thresholds for multiclass classification task with brute-force algorithm.

    Args:
        scores: estimated per-class scores/probabilities predicted by the model
        labels: ground truth labels
        objective: callable function, metric which we want to maximize
        num_iterations: number of iteration for brute-force algorithm
        num_thresholds: number of thresholds ot try for each class
        thresholds: baseline thresholds, which we want to optimize
        patience: maximum number of iteration before early stop exit
        atol: minimum required improvement per iteration for early stop exit

    Returns:
        tuple with best found objective score and per-class thresholds
    """
    best_metric, thresholds = get_thresholds_greedy(
        scores=scores,
        labels=labels,
        score_fn=partial(_multiclass_score_fn, objective=objective),
        num_iterations=num_iterations,
        num_thresholds=num_thresholds,
        thresholds=thresholds,
        patience=patience,
        atol=atol,
    )

    return best_metric, thresholds


</clonepair8>
<clonepair9>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/auc.py" startline="74" endline="91" pcid="417"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=AUCMetric(
                compute_per_class_metrics=compute_per_class_metrics, prefix=prefix, suffix=suffix
            ),
            input_key=input_key,
            target_key=target_key,
        )


</clonepair9>

<clonepair9>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/accuracy.py" startline="177" endline="194" pcid="412"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        threshold: Union[float, torch.Tensor] = 0.5,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MultilabelAccuracyMetric(threshold=threshold, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair9>
<clonepair10>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/auc.py" startline="74" endline="91" pcid="417"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=AUCMetric(
                compute_per_class_metrics=compute_per_class_metrics, prefix=prefix, suffix=suffix
            ),
            input_key=input_key,
            target_key=target_key,
        )


</clonepair10>

<clonepair10>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair10>
<clonepair11>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/auc.py" startline="74" endline="91" pcid="417"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=AUCMetric(
                compute_per_class_metrics=compute_per_class_metrics, prefix=prefix, suffix=suffix
            ),
            input_key=input_key,
            target_key=target_key,
        )


</clonepair11>

<clonepair11>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair11>
<clonepair12>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/auc.py" startline="74" endline="91" pcid="417"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=AUCMetric(
                compute_per_class_metrics=compute_per_class_metrics, prefix=prefix, suffix=suffix
            ),
            input_key=input_key,
            target_key=target_key,
        )


</clonepair12>

<clonepair12>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair12>
<clonepair13>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/auc.py" startline="74" endline="91" pcid="417"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=AUCMetric(
                compute_per_class_metrics=compute_per_class_metrics, prefix=prefix, suffix=suffix
            ),
            input_key=input_key,
            target_key=target_key,
        )


</clonepair13>

<clonepair13>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair13>
<clonepair14>
<source file="systems/catalyst-21.12/catalyst/metrics/_map.py" startline="143" endline="160" pcid="561"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MAPMetric"""
        super().__init__(
            metric_name="map",
            metric_function=mean_average_precision,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair14>

<clonepair14>
<source file="systems/catalyst-21.12/catalyst/metrics/_accuracy.py" startline="133" endline="152" pcid="619"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        num_classes: int = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init AccuracyMetric"""
        self.topk_args = topk_args or get_default_topk_args(num_classes)
        super().__init__(
            metric_name="accuracy",
            metric_function=accuracy,
            topk_args=self.topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair14>
<clonepair15>
<source file="systems/catalyst-21.12/catalyst/metrics/_accuracy.py" startline="133" endline="152" pcid="619"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        num_classes: int = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init AccuracyMetric"""
        self.topk_args = topk_args or get_default_topk_args(num_classes)
        super().__init__(
            metric_name="accuracy",
            metric_function=accuracy,
            topk_args=self.topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair15>

<clonepair15>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair15>
<clonepair16>
<source file="systems/catalyst-21.12/catalyst/metrics/_accuracy.py" startline="133" endline="152" pcid="619"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        num_classes: int = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init AccuracyMetric"""
        self.topk_args = topk_args or get_default_topk_args(num_classes)
        super().__init__(
            metric_name="accuracy",
            metric_function=accuracy,
            topk_args=self.topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair16>

<clonepair16>
<source file="systems/catalyst-21.12/catalyst/metrics/_mrr.py" startline="129" endline="146" pcid="548"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MRRMetric"""
        super().__init__(
            metric_name="mrr",
            metric_function=mrr,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair16>
<clonepair17>
<source file="systems/catalyst-21.12/catalyst/metrics/_accuracy.py" startline="133" endline="152" pcid="619"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        num_classes: int = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init AccuracyMetric"""
        self.topk_args = topk_args or get_default_topk_args(num_classes)
        super().__init__(
            metric_name="accuracy",
            metric_function=accuracy,
            topk_args=self.topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair17>

<clonepair17>
<source file="systems/catalyst-21.12/catalyst/metrics/_hitrate.py" startline="131" endline="148" pcid="547"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init HitrateMetric"""
        super().__init__(
            metric_name="hitrate",
            metric_function=hitrate,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair17>
<clonepair18>
<source file="systems/catalyst-21.12/catalyst/metrics/_accuracy.py" startline="133" endline="152" pcid="619"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        num_classes: int = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init AccuracyMetric"""
        self.topk_args = topk_args or get_default_topk_args(num_classes)
        super().__init__(
            metric_name="accuracy",
            metric_function=accuracy,
            topk_args=self.topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair18>

<clonepair18>
<source file="systems/catalyst-21.12/catalyst/metrics/_ndcg.py" startline="136" endline="153" pcid="562"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init NDCGMetric"""
        super().__init__(
            metric_name="ndcg",
            metric_function=ndcg,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair18>
<clonepair19>
<source file="systems/catalyst-21.12/catalyst/metrics/_accuracy.py" startline="133" endline="152" pcid="619"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        num_classes: int = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init AccuracyMetric"""
        self.topk_args = topk_args or get_default_topk_args(num_classes)
        super().__init__(
            metric_name="accuracy",
            metric_function=accuracy,
            topk_args=self.topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair19>

<clonepair19>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair19>
<clonepair20>
<source file="systems/catalyst-21.12/catalyst/metrics/_accuracy.py" startline="133" endline="152" pcid="619"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        num_classes: int = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init AccuracyMetric"""
        self.topk_args = topk_args or get_default_topk_args(num_classes)
        super().__init__(
            metric_name="accuracy",
            metric_function=accuracy,
            topk_args=self.topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair20>

<clonepair20>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair20>
<clonepair21>
<source file="systems/catalyst-21.12/catalyst/metrics/_accuracy.py" startline="133" endline="152" pcid="619"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        num_classes: int = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init AccuracyMetric"""
        self.topk_args = topk_args or get_default_topk_args(num_classes)
        super().__init__(
            metric_name="accuracy",
            metric_function=accuracy,
            topk_args=self.topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair21>

<clonepair21>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair21>
<clonepair22>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/accuracy.py" startline="177" endline="194" pcid="412"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        threshold: Union[float, torch.Tensor] = 0.5,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MultilabelAccuracyMetric(threshold=threshold, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair22>

<clonepair22>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair22>
<clonepair23>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/accuracy.py" startline="177" endline="194" pcid="412"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        threshold: Union[float, torch.Tensor] = 0.5,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MultilabelAccuracyMetric(threshold=threshold, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair23>

<clonepair23>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair23>
<clonepair24>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/accuracy.py" startline="177" endline="194" pcid="412"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        threshold: Union[float, torch.Tensor] = 0.5,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MultilabelAccuracyMetric(threshold=threshold, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair24>

<clonepair24>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair24>
<clonepair25>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/accuracy.py" startline="177" endline="194" pcid="412"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        threshold: Union[float, torch.Tensor] = 0.5,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MultilabelAccuracyMetric(threshold=threshold, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair25>

<clonepair25>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair25>
<clonepair26>
<source file="systems/catalyst-21.12/catalyst/metrics/_map.py" startline="143" endline="160" pcid="561"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MAPMetric"""
        super().__init__(
            metric_name="map",
            metric_function=mean_average_precision,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair26>

<clonepair26>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair26>
<clonepair27>
<source file="systems/catalyst-21.12/catalyst/metrics/_map.py" startline="143" endline="160" pcid="561"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MAPMetric"""
        super().__init__(
            metric_name="map",
            metric_function=mean_average_precision,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair27>

<clonepair27>
<source file="systems/catalyst-21.12/catalyst/metrics/_mrr.py" startline="129" endline="146" pcid="548"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MRRMetric"""
        super().__init__(
            metric_name="mrr",
            metric_function=mrr,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair27>
<clonepair28>
<source file="systems/catalyst-21.12/catalyst/metrics/_map.py" startline="143" endline="160" pcid="561"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MAPMetric"""
        super().__init__(
            metric_name="map",
            metric_function=mean_average_precision,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair28>

<clonepair28>
<source file="systems/catalyst-21.12/catalyst/metrics/_hitrate.py" startline="131" endline="148" pcid="547"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init HitrateMetric"""
        super().__init__(
            metric_name="hitrate",
            metric_function=hitrate,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair28>
<clonepair29>
<source file="systems/catalyst-21.12/catalyst/metrics/_map.py" startline="143" endline="160" pcid="561"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MAPMetric"""
        super().__init__(
            metric_name="map",
            metric_function=mean_average_precision,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair29>

<clonepair29>
<source file="systems/catalyst-21.12/catalyst/metrics/_ndcg.py" startline="136" endline="153" pcid="562"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init NDCGMetric"""
        super().__init__(
            metric_name="ndcg",
            metric_function=ndcg,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair29>
<clonepair30>
<source file="systems/catalyst-21.12/catalyst/metrics/_map.py" startline="143" endline="160" pcid="561"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MAPMetric"""
        super().__init__(
            metric_name="map",
            metric_function=mean_average_precision,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair30>

<clonepair30>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair30>
<clonepair31>
<source file="systems/catalyst-21.12/catalyst/metrics/_map.py" startline="143" endline="160" pcid="561"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MAPMetric"""
        super().__init__(
            metric_name="map",
            metric_function=mean_average_precision,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair31>

<clonepair31>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair31>
<clonepair32>
<source file="systems/catalyst-21.12/catalyst/metrics/_map.py" startline="143" endline="160" pcid="561"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MAPMetric"""
        super().__init__(
            metric_name="map",
            metric_function=mean_average_precision,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair32>

<clonepair32>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair32>
<clonepair33>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair33>

<clonepair33>
<source file="systems/catalyst-21.12/catalyst/metrics/_mrr.py" startline="129" endline="146" pcid="548"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MRRMetric"""
        super().__init__(
            metric_name="mrr",
            metric_function=mrr,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair33>
<clonepair34>
<source file="systems/catalyst-21.12/catalyst/metrics/_hitrate.py" startline="131" endline="148" pcid="547"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init HitrateMetric"""
        super().__init__(
            metric_name="hitrate",
            metric_function=hitrate,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair34>

<clonepair34>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair34>
<clonepair35>
<source file="systems/catalyst-21.12/catalyst/metrics/_ndcg.py" startline="136" endline="153" pcid="562"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init NDCGMetric"""
        super().__init__(
            metric_name="ndcg",
            metric_function=ndcg,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair35>

<clonepair35>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair35>
<clonepair36>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="99" endline="116" pcid="413"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=HitrateMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair36>

<clonepair36>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="207" endline="224" pcid="414"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MAPMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair36>
<clonepair37>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="99" endline="116" pcid="413"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=HitrateMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair37>

<clonepair37>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair37>
<clonepair38>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="99" endline="116" pcid="413"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=HitrateMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair38>

<clonepair38>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair38>
<clonepair39>
<source file="systems/catalyst-21.12/catalyst/metrics/_hitrate.py" startline="131" endline="148" pcid="547"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init HitrateMetric"""
        super().__init__(
            metric_name="hitrate",
            metric_function=hitrate,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair39>

<clonepair39>
<source file="systems/catalyst-21.12/catalyst/metrics/_mrr.py" startline="129" endline="146" pcid="548"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MRRMetric"""
        super().__init__(
            metric_name="mrr",
            metric_function=mrr,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair39>
<clonepair40>
<source file="systems/catalyst-21.12/catalyst/metrics/_ndcg.py" startline="136" endline="153" pcid="562"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init NDCGMetric"""
        super().__init__(
            metric_name="ndcg",
            metric_function=ndcg,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair40>

<clonepair40>
<source file="systems/catalyst-21.12/catalyst/metrics/_mrr.py" startline="129" endline="146" pcid="548"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MRRMetric"""
        super().__init__(
            metric_name="mrr",
            metric_function=mrr,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair40>
<clonepair41>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair41>

<clonepair41>
<source file="systems/catalyst-21.12/catalyst/metrics/_mrr.py" startline="129" endline="146" pcid="548"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MRRMetric"""
        super().__init__(
            metric_name="mrr",
            metric_function=mrr,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair41>
<clonepair42>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair42>

<clonepair42>
<source file="systems/catalyst-21.12/catalyst/metrics/_mrr.py" startline="129" endline="146" pcid="548"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MRRMetric"""
        super().__init__(
            metric_name="mrr",
            metric_function=mrr,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair42>
<clonepair43>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair43>

<clonepair43>
<source file="systems/catalyst-21.12/catalyst/metrics/_mrr.py" startline="129" endline="146" pcid="548"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MRRMetric"""
        super().__init__(
            metric_name="mrr",
            metric_function=mrr,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair43>
<clonepair44>
<source file="systems/catalyst-21.12/catalyst/metrics/_ndcg.py" startline="136" endline="153" pcid="562"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init NDCGMetric"""
        super().__init__(
            metric_name="ndcg",
            metric_function=ndcg,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair44>

<clonepair44>
<source file="systems/catalyst-21.12/catalyst/metrics/_hitrate.py" startline="131" endline="148" pcid="547"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init HitrateMetric"""
        super().__init__(
            metric_name="hitrate",
            metric_function=hitrate,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair44>
<clonepair45>
<source file="systems/catalyst-21.12/catalyst/metrics/_hitrate.py" startline="131" endline="148" pcid="547"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init HitrateMetric"""
        super().__init__(
            metric_name="hitrate",
            metric_function=hitrate,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair45>

<clonepair45>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair45>
<clonepair46>
<source file="systems/catalyst-21.12/catalyst/metrics/_hitrate.py" startline="131" endline="148" pcid="547"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init HitrateMetric"""
        super().__init__(
            metric_name="hitrate",
            metric_function=hitrate,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair46>

<clonepair46>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair46>
<clonepair47>
<source file="systems/catalyst-21.12/catalyst/metrics/_hitrate.py" startline="131" endline="148" pcid="547"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init HitrateMetric"""
        super().__init__(
            metric_name="hitrate",
            metric_function=hitrate,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair47>

<clonepair47>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair47>
<clonepair48>
<source file="systems/catalyst-21.12/catalyst/metrics/_ndcg.py" startline="136" endline="153" pcid="562"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init NDCGMetric"""
        super().__init__(
            metric_name="ndcg",
            metric_function=ndcg,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair48>

<clonepair48>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair48>
<clonepair49>
<source file="systems/catalyst-21.12/catalyst/metrics/_ndcg.py" startline="136" endline="153" pcid="562"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init NDCGMetric"""
        super().__init__(
            metric_name="ndcg",
            metric_function=ndcg,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair49>

<clonepair49>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair49>
<clonepair50>
<source file="systems/catalyst-21.12/catalyst/metrics/_ndcg.py" startline="136" endline="153" pcid="562"></source>
    def __init__(
        self,
        topk_args: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init NDCGMetric"""
        super().__init__(
            metric_name="ndcg",
            metric_function=ndcg,
            topk_args=topk_args,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair50>

<clonepair50>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair50>
<clonepair51>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="315" endline="332" pcid="415"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MRRMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair51>

<clonepair51>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair51>
<clonepair52>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="315" endline="332" pcid="415"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MRRMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair52>

<clonepair52>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair52>
<clonepair53>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="315" endline="332" pcid="415"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MRRMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair53>

<clonepair53>
<source file="systems/catalyst-21.12/catalyst/callbacks/metrics/recsys.py" startline="423" endline="440" pcid="416"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk_args: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk_args=topk_args, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair53>
<clonepair54>
<source file="systems/catalyst-21.12/catalyst/metrics/functional/_precision.py" startline="8" endline="63" pcid="597"></source>
def precision(
    outputs: torch.Tensor,
    targets: torch.Tensor,
    argmax_dim: int = -1,
    eps: float = 1e-7,
    num_classes: Optional[int] = None,
) -> Union[float, torch.Tensor]:
    """
    Multiclass precision score.

    Args:
        outputs: estimated targets as predicted by a model
            with shape [bs; ..., (num_classes or 1)]
        targets: ground truth (correct) target values
            with shape [bs; ..., 1]
        argmax_dim: int, that specifies dimension for argmax transformation
            in case of scores/probabilities in ``outputs``
        eps: float. Epsilon to avoid zero division.
        num_classes: int, that specifies number of classes if it known

    Returns:
        Tensor: precision for every class

    Examples:

    .. code-block:: python

        import torch
        from catalyst import metrics
        metrics.precision(
            outputs=torch.tensor([
                [1, 0, 0],
                [0, 1, 0],
                [0, 0, 1],
            ]),
            targets=torch.tensor([0, 1, 2]),
        )
        # tensor([1., 1., 1.])


    .. code-block:: python

        import torch
        from catalyst import metrics
        metrics.precision(
            outputs=torch.tensor([[0, 0, 1, 1, 0, 1, 0, 1]]),
            targets=torch.tensor([[0, 1, 0, 1, 0, 0, 1, 1]]),
        )
        # tensor([0.5000, 0.5000]
    """
    precision_score, _, _, _, = precision_recall_fbeta_support(
        outputs=outputs, targets=targets, argmax_dim=argmax_dim, eps=eps, num_classes=num_classes
    )
    return precision_score


</clonepair54>

<clonepair54>
<source file="systems/catalyst-21.12/catalyst/metrics/functional/_recall.py" startline="8" endline="64" pcid="613"></source>
def recall(
    outputs: torch.Tensor,
    targets: torch.Tensor,
    argmax_dim: int = -1,
    eps: float = 1e-7,
    num_classes: Optional[int] = None,
) -> Union[float, torch.Tensor]:
    """
    Multiclass recall score.

    Args:
        outputs: estimated targets as predicted by a model
            with shape [bs; ..., (num_classes or 1)]
        targets: ground truth (correct) target values
            with shape [bs; ..., 1]
        argmax_dim: int, that specifies dimension for argmax transformation
            in case of scores/probabilities in ``outputs``
        eps: float. Epsilon to avoid zero division.
        num_classes: int, that specifies number of classes if it known

    Returns:
        Tensor: recall for every class

    Examples:

    .. code-block:: python

        import torch
        from catalyst import metrics
        metrics.recall(
            outputs=torch.tensor([
                [1, 0, 0],
                [0, 1, 0],
                [0, 0, 1],
            ]),
            targets=torch.tensor([0, 1, 2]),
        )
        # tensor([1., 1., 1.])


    .. code-block:: python

        import torch
        from catalyst import metrics
        metrics.recall(
            outputs=torch.tensor([[0, 0, 1, 1, 0, 1, 0, 1]]),
            targets=torch.tensor([[0, 1, 0, 1, 0, 0, 1, 1]]),
        )
        # tensor([0.5000, 0.5000]
    """
    _, recall_score, _, _ = precision_recall_fbeta_support(
        outputs=outputs, targets=targets, argmax_dim=argmax_dim, eps=eps, num_classes=num_classes
    )

    return recall_score


</clonepair54>
<clonepair55>
<source file="systems/catalyst-21.12/tests/catalyst/metrics/test_additive.py" startline="56" endline="75" pcid="942"></source>
def test_additive_std(
    values_list: Iterable[float],
    num_samples_list: Iterable[int],
    true_values_list: Iterable[float],
):
    """
    Test additive metric std computation

    Args:
        values_list: list of values to update metric
        num_samples_list: list of num_samples
        true_values_list: list of metric intermediate value
    """
    metric = AdditiveMetric()
    for value, num_samples, true_value in zip(values_list, num_samples_list, true_values_list):
        metric.update(value=value, num_samples=num_samples)
        _, std = metric.compute()
        assert np.isclose(std, true_value)


</clonepair55>

<clonepair55>
<source file="systems/catalyst-21.12/tests/catalyst/metrics/test_additive.py" startline="93" endline="112" pcid="943"></source>
def test_additive_mode(
    values_list: Union[Iterable[float], Iterable[torch.Tensor]],
    num_samples_list: Iterable[int],
    true_values_list: Iterable[float],
    mode: Iterable[str],
):
    """
    Test additive metric std computation

    Args:
        values_list: list of values to update metric
        num_samples_list: list of num_samples
        true_values_list: list of metric intermediate value
        mode: `AdditiveMetric` mode
    """
    metric = AdditiveMetric(mode=mode)
    for value, num_samples, true_value in zip(values_list, num_samples_list, true_values_list):
        metric.update(value=value, num_samples=num_samples)
        mean, _ = metric.compute()
        assert np.isclose(mean, true_value)
</clonepair55>
<clonepair56>
<source file="systems/catalyst-21.12/tests/catalyst/metrics/test_additive.py" startline="24" endline="43" pcid="941"></source>
def test_additive_mean(
    values_list: Iterable[float],
    num_samples_list: Iterable[int],
    true_values_list: Iterable[float],
) -> None:
    """
    Test additive metric mean computation

    Args:
        values_list: list of values to update metric
        num_samples_list: list of num_samples
        true_values_list: list of metric intermediate value
    """
    metric = AdditiveMetric()
    for value, num_samples, true_value in zip(values_list, num_samples_list, true_values_list):
        metric.update(value=value, num_samples=num_samples)
        mean, _ = metric.compute()
        assert np.isclose(mean, true_value)


</clonepair56>

<clonepair56>
<source file="systems/catalyst-21.12/tests/catalyst/metrics/test_additive.py" startline="93" endline="112" pcid="943"></source>
def test_additive_mode(
    values_list: Union[Iterable[float], Iterable[torch.Tensor]],
    num_samples_list: Iterable[int],
    true_values_list: Iterable[float],
    mode: Iterable[str],
):
    """
    Test additive metric std computation

    Args:
        values_list: list of values to update metric
        num_samples_list: list of num_samples
        true_values_list: list of metric intermediate value
        mode: `AdditiveMetric` mode
    """
    metric = AdditiveMetric(mode=mode)
    for value, num_samples, true_value in zip(values_list, num_samples_list, true_values_list):
        metric.update(value=value, num_samples=num_samples)
        mean, _ = metric.compute()
        assert np.isclose(mean, true_value)
</clonepair56>
<clonepair57>
<source file="systems/catalyst-21.12/tests/catalyst/metrics/test_additive.py" startline="24" endline="43" pcid="941"></source>
def test_additive_mean(
    values_list: Iterable[float],
    num_samples_list: Iterable[int],
    true_values_list: Iterable[float],
) -> None:
    """
    Test additive metric mean computation

    Args:
        values_list: list of values to update metric
        num_samples_list: list of num_samples
        true_values_list: list of metric intermediate value
    """
    metric = AdditiveMetric()
    for value, num_samples, true_value in zip(values_list, num_samples_list, true_values_list):
        metric.update(value=value, num_samples=num_samples)
        mean, _ = metric.compute()
        assert np.isclose(mean, true_value)


</clonepair57>

<clonepair57>
<source file="systems/catalyst-21.12/tests/catalyst/metrics/test_additive.py" startline="56" endline="75" pcid="942"></source>
def test_additive_std(
    values_list: Iterable[float],
    num_samples_list: Iterable[int],
    true_values_list: Iterable[float],
):
    """
    Test additive metric std computation

    Args:
        values_list: list of values to update metric
        num_samples_list: list of num_samples
        true_values_list: list of metric intermediate value
    """
    metric = AdditiveMetric()
    for value, num_samples, true_value in zip(values_list, num_samples_list, true_values_list):
        metric.update(value=value, num_samples=num_samples)
        _, std = metric.compute()
        assert np.isclose(std, true_value)


</clonepair57>
