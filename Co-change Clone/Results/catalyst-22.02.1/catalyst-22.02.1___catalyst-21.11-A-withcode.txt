<clonepair1>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/segmentation.py" startline="334" endline="367" pcid="410"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        alpha: float,
        beta: Optional[float] = None,
        class_dim: int = 1,
        weights: Optional[List[float]] = None,
        class_names: Optional[List[str]] = None,
        threshold: Optional[float] = None,
        log_on_batch: bool = True,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=TrevskyMetric(
                alpha=alpha,
                beta=beta,
                class_dim=class_dim,
                weights=weights,
                class_names=class_names,
                threshold=threshold,
                compute_per_class_metrics=compute_per_class_metrics,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair1>

<clonepair1>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/classification.py" startline="86" endline="111" pcid="394"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        num_classes: Optional[int] = None,
        zero_division: int = 0,
        log_on_batch: bool = True,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MulticlassPrecisionRecallF1SupportMetric(
                zero_division=zero_division,
                prefix=prefix,
                suffix=suffix,
                compute_per_class_metrics=compute_per_class_metrics,
                num_classes=num_classes,
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair1>
<clonepair2>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/segmentation.py" startline="334" endline="367" pcid="410"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        alpha: float,
        beta: Optional[float] = None,
        class_dim: int = 1,
        weights: Optional[List[float]] = None,
        class_names: Optional[List[str]] = None,
        threshold: Optional[float] = None,
        log_on_batch: bool = True,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=TrevskyMetric(
                alpha=alpha,
                beta=beta,
                class_dim=class_dim,
                weights=weights,
                class_names=class_names,
                threshold=threshold,
                compute_per_class_metrics=compute_per_class_metrics,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair2>

<clonepair2>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/classification.py" startline="193" endline="218" pcid="395"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        num_classes: Optional[int] = None,
        zero_division: int = 0,
        log_on_batch: bool = True,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MultilabelPrecisionRecallF1SupportMetric(
                zero_division=zero_division,
                prefix=prefix,
                suffix=suffix,
                compute_per_class_metrics=compute_per_class_metrics,
                num_classes=num_classes,
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair2>
<clonepair3>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/segmentation.py" startline="214" endline="243" pcid="409"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        class_dim: int = 1,
        weights: Optional[List[float]] = None,
        class_names: Optional[List[str]] = None,
        threshold: Optional[float] = None,
        log_on_batch: bool = True,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=DiceMetric(
                class_dim=class_dim,
                weights=weights,
                class_names=class_names,
                threshold=threshold,
                compute_per_class_metrics=compute_per_class_metrics,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair3>

<clonepair3>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/classification.py" startline="86" endline="111" pcid="394"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        num_classes: Optional[int] = None,
        zero_division: int = 0,
        log_on_batch: bool = True,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MulticlassPrecisionRecallF1SupportMetric(
                zero_division=zero_division,
                prefix=prefix,
                suffix=suffix,
                compute_per_class_metrics=compute_per_class_metrics,
                num_classes=num_classes,
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair3>
<clonepair4>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/segmentation.py" startline="214" endline="243" pcid="409"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        class_dim: int = 1,
        weights: Optional[List[float]] = None,
        class_names: Optional[List[str]] = None,
        threshold: Optional[float] = None,
        log_on_batch: bool = True,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=DiceMetric(
                class_dim=class_dim,
                weights=weights,
                class_names=class_names,
                threshold=threshold,
                compute_per_class_metrics=compute_per_class_metrics,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair4>

<clonepair4>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/classification.py" startline="193" endline="218" pcid="395"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        num_classes: Optional[int] = None,
        zero_division: int = 0,
        log_on_batch: bool = True,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MultilabelPrecisionRecallF1SupportMetric(
                zero_division=zero_division,
                prefix=prefix,
                suffix=suffix,
                compute_per_class_metrics=compute_per_class_metrics,
                num_classes=num_classes,
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair4>
<clonepair5>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/cmc_score.py" startline="201" endline="225" pcid="398"></source>
    def __init__(
        self,
        embeddings_key: str,
        pids_key: str,
        cids_key: str,
        is_query_key: str,
        topk: Iterable[int] = None,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=ReidCMCMetric(
                embeddings_key=embeddings_key,
                pids_key=pids_key,
                cids_key=cids_key,
                is_query_key=is_query_key,
                topk=topk,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=[embeddings_key, is_query_key],
            target_key=[pids_key, cids_key],
        )

</clonepair5>

<clonepair5>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/segmentation.py" startline="214" endline="243" pcid="409"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        class_dim: int = 1,
        weights: Optional[List[float]] = None,
        class_names: Optional[List[str]] = None,
        threshold: Optional[float] = None,
        log_on_batch: bool = True,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=DiceMetric(
                class_dim=class_dim,
                weights=weights,
                class_names=class_names,
                threshold=threshold,
                compute_per_class_metrics=compute_per_class_metrics,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair5>
<clonepair6>
<source file="systems/catalyst-22.02.1/catalyst/contrib/utils/thresholds.py" startline="387" endline="426" pcid="72"></source>
def get_best_multilabel_thresholds(
    scores: np.ndarray, labels: np.ndarray, objective: METRIC_FN
) -> Tuple[float, List[float]]:
    """Finds best thresholds for multilabel classification task.

    Args:
        scores: estimated per-class scores/probabilities predicted by the model
        labels: ground truth labels
        objective: callable function, metric which we want to maximize

    Returns:
        tuple with best found objective score and per-class thresholds
    """
    num_classes = scores.shape[1]
    best_metric, best_thresholds = 0.0, []

    for baseline_thresholds_fn in [
        get_baseline_thresholds,
        get_multiclass_thresholds,
        get_binary_threshold,
        get_multilabel_thresholds,
    ]:
        _, baseline_thresholds = baseline_thresholds_fn(
            labels=labels, scores=scores, objective=objective
        )
        if isinstance(baseline_thresholds, (int, float)):
            baseline_thresholds = [baseline_thresholds] * num_classes
        metric_value, thresholds_value = get_multilabel_thresholds_greedy(
            labels=labels,
            scores=scores,
            objective=objective,
            thresholds=baseline_thresholds,
        )
        if metric_value > best_metric:
            best_metric = metric_value
            best_thresholds = thresholds_value

    return best_metric, best_thresholds


</clonepair6>

<clonepair6>
<source file="systems/catalyst-22.02.1/catalyst/contrib/utils/thresholds.py" startline="427" endline="468" pcid="73"></source>
def get_best_multiclass_thresholds(
    scores: np.ndarray, labels: np.ndarray, objective: METRIC_FN
) -> Tuple[float, List[float]]:
    """Finds best thresholds for multiclass classification task.

    Args:
        scores: estimated per-class scores/probabilities predicted by the model
        labels: ground truth labels
        objective: callable function, metric which we want to maximize

    Returns:
        tuple with best found objective score and per-class thresholds
    """
    num_classes = scores.shape[1]
    best_metric, best_thresholds = 0.0, []
    labels_onehot = np.zeros((labels.size, labels.max() + 1))
    labels_onehot[np.arange(labels.size), labels] = 1

    for baseline_thresholds_fn in [
        get_baseline_thresholds,
        get_multiclass_thresholds,
        get_binary_threshold,
        get_multilabel_thresholds,
    ]:
        _, baseline_thresholds = baseline_thresholds_fn(
            labels=labels_onehot, scores=scores, objective=objective
        )
        if isinstance(baseline_thresholds, (int, float)):
            baseline_thresholds = [baseline_thresholds] * num_classes
        metric_value, thresholds_value = get_multiclass_thresholds_greedy(
            labels=labels,
            scores=scores,
            objective=objective,
            thresholds=baseline_thresholds,
        )
        if metric_value > best_metric:
            best_metric = metric_value
            best_thresholds = thresholds_value

    return best_metric, best_thresholds


</clonepair6>
<clonepair7>
<source file="systems/catalyst-22.02.1/tests/catalyst/callbacks/test_soft_update.py" startline="20" endline="53" pcid="688"></source>
def test_soft_update():

    model = nn.ModuleDict(
        {
            "target": nn.Linear(10, 10, bias=False),
            "source": nn.Linear(10, 10, bias=False),
        }
    )
    set_requires_grad(model, False)
    model["target"].weight.data.fill_(0)

    runner = DummyRunner(model=model)
    runner.is_train_loader = True

    soft_update = dl.SoftUpdateCallaback(
        target_model="target",
        source_model="source",
        tau=0.1,
        scope="on_batch_end",
    )
    soft_update.on_batch_end(runner)

    checks = (
        (
            (0.1 * runner.model["source"].weight.data)
            == runner.model["target"].weight.data
        )
        .flatten()
        .tolist()
    )

    assert all(checks)


</clonepair7>

<clonepair7>
<source file="systems/catalyst-22.02.1/tests/catalyst/callbacks/test_soft_update.py" startline="54" endline="78" pcid="689"></source>
def test_soft_update_not_work():

    model = nn.ModuleDict(
        {
            "target": nn.Linear(10, 10, bias=False),
            "source": nn.Linear(10, 10, bias=False),
        }
    )
    set_requires_grad(model, False)
    model["target"].weight.data.fill_(0)

    runner = DummyRunner(model=model)
    runner.is_train_loader = True

    soft_update = dl.SoftUpdateCallaback(
        target_model="target",
        source_model="source",
        tau=0.1,
        scope="on_batch_start",
    )
    soft_update.on_batch_end(runner)

    checks = (runner.model["target"].weight.data == 0).flatten().tolist()

    assert all(checks)
</clonepair7>
<clonepair8>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/classification.py" startline="86" endline="111" pcid="394"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        num_classes: Optional[int] = None,
        zero_division: int = 0,
        log_on_batch: bool = True,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MulticlassPrecisionRecallF1SupportMetric(
                zero_division=zero_division,
                prefix=prefix,
                suffix=suffix,
                compute_per_class_metrics=compute_per_class_metrics,
                num_classes=num_classes,
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair8>

<clonepair8>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/classification.py" startline="193" endline="218" pcid="395"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        num_classes: Optional[int] = None,
        zero_division: int = 0,
        log_on_batch: bool = True,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MultilabelPrecisionRecallF1SupportMetric(
                zero_division=zero_division,
                prefix=prefix,
                suffix=suffix,
                compute_per_class_metrics=compute_per_class_metrics,
                num_classes=num_classes,
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair8>
<clonepair9>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/cmc_score.py" startline="201" endline="225" pcid="398"></source>
    def __init__(
        self,
        embeddings_key: str,
        pids_key: str,
        cids_key: str,
        is_query_key: str,
        topk: Iterable[int] = None,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=ReidCMCMetric(
                embeddings_key=embeddings_key,
                pids_key=pids_key,
                cids_key=cids_key,
                is_query_key=is_query_key,
                topk=topk,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=[embeddings_key, is_query_key],
            target_key=[pids_key, cids_key],
        )

</clonepair9>

<clonepair9>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/classification.py" startline="86" endline="111" pcid="394"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        num_classes: Optional[int] = None,
        zero_division: int = 0,
        log_on_batch: bool = True,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MulticlassPrecisionRecallF1SupportMetric(
                zero_division=zero_division,
                prefix=prefix,
                suffix=suffix,
                compute_per_class_metrics=compute_per_class_metrics,
                num_classes=num_classes,
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair9>
<clonepair10>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/cmc_score.py" startline="151" endline="173" pcid="396"></source>
    def __init__(
        self,
        embeddings_key: str,
        labels_key: str,
        is_query_key: str,
        topk: Iterable[int] = None,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=CMCMetric(
                embeddings_key=embeddings_key,
                labels_key=labels_key,
                is_query_key=is_query_key,
                topk=topk,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=[embeddings_key, is_query_key],
            target_key=[labels_key],
        )

</clonepair10>

<clonepair10>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/classification.py" startline="86" endline="111" pcid="394"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        num_classes: Optional[int] = None,
        zero_division: int = 0,
        log_on_batch: bool = True,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MulticlassPrecisionRecallF1SupportMetric(
                zero_division=zero_division,
                prefix=prefix,
                suffix=suffix,
                compute_per_class_metrics=compute_per_class_metrics,
                num_classes=num_classes,
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair10>
<clonepair11>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/cmc_score.py" startline="201" endline="225" pcid="398"></source>
    def __init__(
        self,
        embeddings_key: str,
        pids_key: str,
        cids_key: str,
        is_query_key: str,
        topk: Iterable[int] = None,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=ReidCMCMetric(
                embeddings_key=embeddings_key,
                pids_key=pids_key,
                cids_key=cids_key,
                is_query_key=is_query_key,
                topk=topk,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=[embeddings_key, is_query_key],
            target_key=[pids_key, cids_key],
        )

</clonepair11>

<clonepair11>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/classification.py" startline="193" endline="218" pcid="395"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        num_classes: Optional[int] = None,
        zero_division: int = 0,
        log_on_batch: bool = True,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MultilabelPrecisionRecallF1SupportMetric(
                zero_division=zero_division,
                prefix=prefix,
                suffix=suffix,
                compute_per_class_metrics=compute_per_class_metrics,
                num_classes=num_classes,
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair11>
<clonepair12>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/cmc_score.py" startline="151" endline="173" pcid="396"></source>
    def __init__(
        self,
        embeddings_key: str,
        labels_key: str,
        is_query_key: str,
        topk: Iterable[int] = None,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=CMCMetric(
                embeddings_key=embeddings_key,
                labels_key=labels_key,
                is_query_key=is_query_key,
                topk=topk,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=[embeddings_key, is_query_key],
            target_key=[labels_key],
        )

</clonepair12>

<clonepair12>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/classification.py" startline="193" endline="218" pcid="395"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        num_classes: Optional[int] = None,
        zero_division: int = 0,
        log_on_batch: bool = True,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MultilabelPrecisionRecallF1SupportMetric(
                zero_division=zero_division,
                prefix=prefix,
                suffix=suffix,
                compute_per_class_metrics=compute_per_class_metrics,
                num_classes=num_classes,
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair12>
<clonepair13>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/cmc_score.py" startline="151" endline="173" pcid="396"></source>
    def __init__(
        self,
        embeddings_key: str,
        labels_key: str,
        is_query_key: str,
        topk: Iterable[int] = None,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=CMCMetric(
                embeddings_key=embeddings_key,
                labels_key=labels_key,
                is_query_key=is_query_key,
                topk=topk,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=[embeddings_key, is_query_key],
            target_key=[labels_key],
        )

</clonepair13>

<clonepair13>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/cmc_score.py" startline="201" endline="225" pcid="398"></source>
    def __init__(
        self,
        embeddings_key: str,
        pids_key: str,
        cids_key: str,
        is_query_key: str,
        topk: Iterable[int] = None,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=ReidCMCMetric(
                embeddings_key=embeddings_key,
                pids_key=pids_key,
                cids_key=cids_key,
                is_query_key=is_query_key,
                topk=topk,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=[embeddings_key, is_query_key],
            target_key=[pids_key, cids_key],
        )

</clonepair13>
<clonepair14>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/auc.py" startline="82" endline="100" pcid="406"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=AUCMetric(
                compute_per_class_metrics=compute_per_class_metrics,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=input_key,
            target_key=target_key,
        )

</clonepair14>

<clonepair14>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/accuracy.py" startline="94" endline="117" pcid="400"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        num_classes: int = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=AccuracyMetric(
                topk=topk,
                num_classes=num_classes,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair14>
<clonepair15>
<source file="systems/catalyst-22.02.1/catalyst/contrib/utils/thresholds.py" startline="300" endline="339" pcid="69"></source>
def get_multilabel_thresholds_greedy(
    scores: np.ndarray,
    labels: np.ndarray,
    objective: METRIC_FN,
    num_iterations: int = 100,
    num_thresholds: int = 100,
    thresholds: np.ndarray = None,
    patience: int = 3,
    atol: float = 0.01,
) -> Tuple[float, List[float]]:
    """Finds best thresholds
    for multilabel classification task with brute-force algorithm.

    Args:
        scores: estimated per-class scores/probabilities predicted by the model
        labels: ground truth labels
        objective: callable function, metric which we want to maximize
        num_iterations: number of iteration for brute-force algorithm
        num_thresholds: number of thresholds ot try for each class
        thresholds: baseline thresholds, which we want to optimize
        patience: maximum number of iteration before early stop exit
        atol: minimum required improvement per iteration for early stop exit

    Returns:
        tuple with best found objective score and per-class thresholds
    """
    best_metric, thresholds = get_thresholds_greedy(
        scores=scores,
        labels=labels,
        score_fn=partial(_multilabel_score_fn, objective=objective),
        num_iterations=num_iterations,
        num_thresholds=num_thresholds,
        thresholds=thresholds,
        patience=patience,
        atol=atol,
    )

    return best_metric, thresholds


</clonepair15>

<clonepair15>
<source file="systems/catalyst-22.02.1/catalyst/contrib/utils/thresholds.py" startline="347" endline="386" pcid="71"></source>
def get_multiclass_thresholds_greedy(
    scores: np.ndarray,
    labels: np.ndarray,
    objective: METRIC_FN,
    num_iterations: int = 100,
    num_thresholds: int = 100,
    thresholds: np.ndarray = None,
    patience: int = 3,
    atol: float = 0.01,
) -> Tuple[float, List[float]]:
    """Finds best thresholds
    for multiclass classification task with brute-force algorithm.

    Args:
        scores: estimated per-class scores/probabilities predicted by the model
        labels: ground truth labels
        objective: callable function, metric which we want to maximize
        num_iterations: number of iteration for brute-force algorithm
        num_thresholds: number of thresholds ot try for each class
        thresholds: baseline thresholds, which we want to optimize
        patience: maximum number of iteration before early stop exit
        atol: minimum required improvement per iteration for early stop exit

    Returns:
        tuple with best found objective score and per-class thresholds
    """
    best_metric, thresholds = get_thresholds_greedy(
        scores=scores,
        labels=labels,
        score_fn=partial(_multiclass_score_fn, objective=objective),
        num_iterations=num_iterations,
        num_thresholds=num_thresholds,
        thresholds=thresholds,
        patience=patience,
        atol=atol,
    )

    return best_metric, thresholds


</clonepair15>
<clonepair16>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/auc.py" startline="82" endline="100" pcid="406"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=AUCMetric(
                compute_per_class_metrics=compute_per_class_metrics,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=input_key,
            target_key=target_key,
        )

</clonepair16>

<clonepair16>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/accuracy.py" startline="186" endline="205" pcid="401"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        threshold: Union[float, torch.Tensor] = 0.5,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MultilabelAccuracyMetric(
                threshold=threshold, prefix=prefix, suffix=suffix
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair16>
<clonepair17>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/auc.py" startline="82" endline="100" pcid="406"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=AUCMetric(
                compute_per_class_metrics=compute_per_class_metrics,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=input_key,
            target_key=target_key,
        )

</clonepair17>

<clonepair17>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="102" endline="119" pcid="402"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=HitrateMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair17>
<clonepair18>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/auc.py" startline="82" endline="100" pcid="406"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=AUCMetric(
                compute_per_class_metrics=compute_per_class_metrics,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=input_key,
            target_key=target_key,
        )

</clonepair18>

<clonepair18>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="213" endline="230" pcid="403"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MAPMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair18>
<clonepair19>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/auc.py" startline="82" endline="100" pcid="406"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=AUCMetric(
                compute_per_class_metrics=compute_per_class_metrics,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=input_key,
            target_key=target_key,
        )

</clonepair19>

<clonepair19>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="324" endline="341" pcid="404"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MRRMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair19>
<clonepair20>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/auc.py" startline="82" endline="100" pcid="406"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        compute_per_class_metrics: bool = SETTINGS.compute_per_class_metrics,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=AUCMetric(
                compute_per_class_metrics=compute_per_class_metrics,
                prefix=prefix,
                suffix=suffix,
            ),
            input_key=input_key,
            target_key=target_key,
        )

</clonepair20>

<clonepair20>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="435" endline="452" pcid="405"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair20>
<clonepair21>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_map.py" startline="146" endline="163" pcid="540"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MAPMetric"""
        super().__init__(
            metric_name="map",
            metric_function=mean_average_precision,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair21>

<clonepair21>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_accuracy.py" startline="136" endline="155" pcid="598"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        num_classes: int = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init AccuracyMetric"""
        self.topk = topk or get_default_topk(num_classes)
        super().__init__(
            metric_name="accuracy",
            metric_function=accuracy,
            topk=self.topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair21>
<clonepair22>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_accuracy.py" startline="136" endline="155" pcid="598"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        num_classes: int = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init AccuracyMetric"""
        self.topk = topk or get_default_topk(num_classes)
        super().__init__(
            metric_name="accuracy",
            metric_function=accuracy,
            topk=self.topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair22>

<clonepair22>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="102" endline="119" pcid="402"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=HitrateMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair22>
<clonepair23>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_accuracy.py" startline="136" endline="155" pcid="598"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        num_classes: int = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init AccuracyMetric"""
        self.topk = topk or get_default_topk(num_classes)
        super().__init__(
            metric_name="accuracy",
            metric_function=accuracy,
            topk=self.topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair23>

<clonepair23>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_mrr.py" startline="132" endline="149" pcid="527"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MRRMetric"""
        super().__init__(
            metric_name="mrr",
            metric_function=mrr,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair23>
<clonepair24>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_accuracy.py" startline="136" endline="155" pcid="598"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        num_classes: int = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init AccuracyMetric"""
        self.topk = topk or get_default_topk(num_classes)
        super().__init__(
            metric_name="accuracy",
            metric_function=accuracy,
            topk=self.topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair24>

<clonepair24>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_hitrate.py" startline="134" endline="151" pcid="526"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init HitrateMetric"""
        super().__init__(
            metric_name="hitrate",
            metric_function=hitrate,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair24>
<clonepair25>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_accuracy.py" startline="136" endline="155" pcid="598"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        num_classes: int = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init AccuracyMetric"""
        self.topk = topk or get_default_topk(num_classes)
        super().__init__(
            metric_name="accuracy",
            metric_function=accuracy,
            topk=self.topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair25>

<clonepair25>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_ndcg.py" startline="138" endline="155" pcid="541"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init NDCGMetric"""
        super().__init__(
            metric_name="ndcg",
            metric_function=ndcg,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair25>
<clonepair26>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_accuracy.py" startline="136" endline="155" pcid="598"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        num_classes: int = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init AccuracyMetric"""
        self.topk = topk or get_default_topk(num_classes)
        super().__init__(
            metric_name="accuracy",
            metric_function=accuracy,
            topk=self.topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair26>

<clonepair26>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="213" endline="230" pcid="403"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MAPMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair26>
<clonepair27>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_accuracy.py" startline="136" endline="155" pcid="598"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        num_classes: int = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init AccuracyMetric"""
        self.topk = topk or get_default_topk(num_classes)
        super().__init__(
            metric_name="accuracy",
            metric_function=accuracy,
            topk=self.topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair27>

<clonepair27>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="324" endline="341" pcid="404"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MRRMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair27>
<clonepair28>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_accuracy.py" startline="136" endline="155" pcid="598"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        num_classes: int = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init AccuracyMetric"""
        self.topk = topk or get_default_topk(num_classes)
        super().__init__(
            metric_name="accuracy",
            metric_function=accuracy,
            topk=self.topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair28>

<clonepair28>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="435" endline="452" pcid="405"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair28>
<clonepair29>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/accuracy.py" startline="186" endline="205" pcid="401"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        threshold: Union[float, torch.Tensor] = 0.5,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MultilabelAccuracyMetric(
                threshold=threshold, prefix=prefix, suffix=suffix
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair29>

<clonepair29>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="102" endline="119" pcid="402"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=HitrateMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair29>
<clonepair30>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/accuracy.py" startline="186" endline="205" pcid="401"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        threshold: Union[float, torch.Tensor] = 0.5,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MultilabelAccuracyMetric(
                threshold=threshold, prefix=prefix, suffix=suffix
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair30>

<clonepair30>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="213" endline="230" pcid="403"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MAPMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair30>
<clonepair31>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/accuracy.py" startline="186" endline="205" pcid="401"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        threshold: Union[float, torch.Tensor] = 0.5,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MultilabelAccuracyMetric(
                threshold=threshold, prefix=prefix, suffix=suffix
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair31>

<clonepair31>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="324" endline="341" pcid="404"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MRRMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair31>
<clonepair32>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/accuracy.py" startline="186" endline="205" pcid="401"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        threshold: Union[float, torch.Tensor] = 0.5,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MultilabelAccuracyMetric(
                threshold=threshold, prefix=prefix, suffix=suffix
            ),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair32>

<clonepair32>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="435" endline="452" pcid="405"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair32>
<clonepair33>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_map.py" startline="146" endline="163" pcid="540"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MAPMetric"""
        super().__init__(
            metric_name="map",
            metric_function=mean_average_precision,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair33>

<clonepair33>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="102" endline="119" pcid="402"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=HitrateMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair33>
<clonepair34>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_map.py" startline="146" endline="163" pcid="540"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MAPMetric"""
        super().__init__(
            metric_name="map",
            metric_function=mean_average_precision,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair34>

<clonepair34>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_mrr.py" startline="132" endline="149" pcid="527"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MRRMetric"""
        super().__init__(
            metric_name="mrr",
            metric_function=mrr,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair34>
<clonepair35>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_map.py" startline="146" endline="163" pcid="540"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MAPMetric"""
        super().__init__(
            metric_name="map",
            metric_function=mean_average_precision,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair35>

<clonepair35>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_hitrate.py" startline="134" endline="151" pcid="526"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init HitrateMetric"""
        super().__init__(
            metric_name="hitrate",
            metric_function=hitrate,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair35>
<clonepair36>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_map.py" startline="146" endline="163" pcid="540"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MAPMetric"""
        super().__init__(
            metric_name="map",
            metric_function=mean_average_precision,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair36>

<clonepair36>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_ndcg.py" startline="138" endline="155" pcid="541"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init NDCGMetric"""
        super().__init__(
            metric_name="ndcg",
            metric_function=ndcg,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair36>
<clonepair37>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_map.py" startline="146" endline="163" pcid="540"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MAPMetric"""
        super().__init__(
            metric_name="map",
            metric_function=mean_average_precision,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair37>

<clonepair37>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="213" endline="230" pcid="403"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MAPMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair37>
<clonepair38>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_map.py" startline="146" endline="163" pcid="540"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MAPMetric"""
        super().__init__(
            metric_name="map",
            metric_function=mean_average_precision,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair38>

<clonepair38>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="324" endline="341" pcid="404"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MRRMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair38>
<clonepair39>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_map.py" startline="146" endline="163" pcid="540"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MAPMetric"""
        super().__init__(
            metric_name="map",
            metric_function=mean_average_precision,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair39>

<clonepair39>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="435" endline="452" pcid="405"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair39>
<clonepair40>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="102" endline="119" pcid="402"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=HitrateMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair40>

<clonepair40>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_mrr.py" startline="132" endline="149" pcid="527"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MRRMetric"""
        super().__init__(
            metric_name="mrr",
            metric_function=mrr,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair40>
<clonepair41>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_hitrate.py" startline="134" endline="151" pcid="526"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init HitrateMetric"""
        super().__init__(
            metric_name="hitrate",
            metric_function=hitrate,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair41>

<clonepair41>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="102" endline="119" pcid="402"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=HitrateMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair41>
<clonepair42>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_ndcg.py" startline="138" endline="155" pcid="541"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init NDCGMetric"""
        super().__init__(
            metric_name="ndcg",
            metric_function=ndcg,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair42>

<clonepair42>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="102" endline="119" pcid="402"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=HitrateMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair42>
<clonepair43>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="102" endline="119" pcid="402"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=HitrateMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair43>

<clonepair43>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="213" endline="230" pcid="403"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MAPMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair43>
<clonepair44>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="102" endline="119" pcid="402"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=HitrateMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair44>

<clonepair44>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="324" endline="341" pcid="404"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MRRMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair44>
<clonepair45>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="102" endline="119" pcid="402"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=HitrateMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair45>

<clonepair45>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="435" endline="452" pcid="405"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair45>
<clonepair46>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_hitrate.py" startline="134" endline="151" pcid="526"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init HitrateMetric"""
        super().__init__(
            metric_name="hitrate",
            metric_function=hitrate,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair46>

<clonepair46>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_mrr.py" startline="132" endline="149" pcid="527"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MRRMetric"""
        super().__init__(
            metric_name="mrr",
            metric_function=mrr,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair46>
<clonepair47>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_ndcg.py" startline="138" endline="155" pcid="541"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init NDCGMetric"""
        super().__init__(
            metric_name="ndcg",
            metric_function=ndcg,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair47>

<clonepair47>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_mrr.py" startline="132" endline="149" pcid="527"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MRRMetric"""
        super().__init__(
            metric_name="mrr",
            metric_function=mrr,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair47>
<clonepair48>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="213" endline="230" pcid="403"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MAPMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair48>

<clonepair48>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_mrr.py" startline="132" endline="149" pcid="527"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MRRMetric"""
        super().__init__(
            metric_name="mrr",
            metric_function=mrr,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair48>
<clonepair49>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="324" endline="341" pcid="404"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MRRMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair49>

<clonepair49>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_mrr.py" startline="132" endline="149" pcid="527"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MRRMetric"""
        super().__init__(
            metric_name="mrr",
            metric_function=mrr,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair49>
<clonepair50>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="435" endline="452" pcid="405"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair50>

<clonepair50>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_mrr.py" startline="132" endline="149" pcid="527"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init MRRMetric"""
        super().__init__(
            metric_name="mrr",
            metric_function=mrr,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair50>
<clonepair51>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_ndcg.py" startline="138" endline="155" pcid="541"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init NDCGMetric"""
        super().__init__(
            metric_name="ndcg",
            metric_function=ndcg,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair51>

<clonepair51>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_hitrate.py" startline="134" endline="151" pcid="526"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init HitrateMetric"""
        super().__init__(
            metric_name="hitrate",
            metric_function=hitrate,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair51>
<clonepair52>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_hitrate.py" startline="134" endline="151" pcid="526"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init HitrateMetric"""
        super().__init__(
            metric_name="hitrate",
            metric_function=hitrate,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair52>

<clonepair52>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="213" endline="230" pcid="403"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MAPMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair52>
<clonepair53>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_hitrate.py" startline="134" endline="151" pcid="526"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init HitrateMetric"""
        super().__init__(
            metric_name="hitrate",
            metric_function=hitrate,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair53>

<clonepair53>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="324" endline="341" pcid="404"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MRRMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair53>
<clonepair54>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_hitrate.py" startline="134" endline="151" pcid="526"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init HitrateMetric"""
        super().__init__(
            metric_name="hitrate",
            metric_function=hitrate,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair54>

<clonepair54>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="435" endline="452" pcid="405"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair54>
<clonepair55>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_ndcg.py" startline="138" endline="155" pcid="541"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init NDCGMetric"""
        super().__init__(
            metric_name="ndcg",
            metric_function=ndcg,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair55>

<clonepair55>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="213" endline="230" pcid="403"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MAPMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair55>
<clonepair56>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_ndcg.py" startline="138" endline="155" pcid="541"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init NDCGMetric"""
        super().__init__(
            metric_name="ndcg",
            metric_function=ndcg,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair56>

<clonepair56>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="324" endline="341" pcid="404"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MRRMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair56>
<clonepair57>
<source file="systems/catalyst-22.02.1/catalyst/metrics/_ndcg.py" startline="138" endline="155" pcid="541"></source>
    def __init__(
        self,
        topk: Iterable[int] = None,
        compute_on_call: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init NDCGMetric"""
        super().__init__(
            metric_name="ndcg",
            metric_function=ndcg,
            topk=topk,
            compute_on_call=compute_on_call,
            prefix=prefix,
            suffix=suffix,
        )


</clonepair57>

<clonepair57>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="435" endline="452" pcid="405"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair57>
<clonepair58>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="213" endline="230" pcid="403"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MAPMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair58>

<clonepair58>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="324" endline="341" pcid="404"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MRRMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair58>
<clonepair59>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="213" endline="230" pcid="403"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MAPMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair59>

<clonepair59>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="435" endline="452" pcid="405"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair59>
<clonepair60>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="324" endline="341" pcid="404"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=MRRMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair60>

<clonepair60>
<source file="systems/catalyst-22.02.1/catalyst/callbacks/metrics/recsys.py" startline="435" endline="452" pcid="405"></source>
    def __init__(
        self,
        input_key: str,
        target_key: str,
        topk: Iterable[int] = None,
        log_on_batch: bool = True,
        prefix: str = None,
        suffix: str = None,
    ):
        """Init."""
        super().__init__(
            metric=NDCGMetric(topk=topk, prefix=prefix, suffix=suffix),
            input_key=input_key,
            target_key=target_key,
            log_on_batch=log_on_batch,
        )


</clonepair60>
<clonepair61>
<source file="systems/catalyst-22.02.1/catalyst/metrics/functional/_precision.py" startline="8" endline="67" pcid="576"></source>
def precision(
    outputs: torch.Tensor,
    targets: torch.Tensor,
    argmax_dim: int = -1,
    eps: float = 1e-7,
    num_classes: Optional[int] = None,
) -> Union[float, torch.Tensor]:
    """
    Multiclass precision score.

    Args:
        outputs: estimated targets as predicted by a model
            with shape [bs; ..., (num_classes or 1)]
        targets: ground truth (correct) target values
            with shape [bs; ..., 1]
        argmax_dim: int, that specifies dimension for argmax transformation
            in case of scores/probabilities in ``outputs``
        eps: float. Epsilon to avoid zero division.
        num_classes: int, that specifies number of classes if it known

    Returns:
        Tensor: precision for every class

    Examples:

    .. code-block:: python

        import torch
        from catalyst import metrics
        metrics.precision(
            outputs=torch.tensor([
                [1, 0, 0],
                [0, 1, 0],
                [0, 0, 1],
            ]),
            targets=torch.tensor([0, 1, 2]),
        )
        # tensor([1., 1., 1.])


    .. code-block:: python

        import torch
        from catalyst import metrics
        metrics.precision(
            outputs=torch.tensor([[0, 0, 1, 1, 0, 1, 0, 1]]),
            targets=torch.tensor([[0, 1, 0, 1, 0, 0, 1, 1]]),
        )
        # tensor([0.5000, 0.5000]
    """
    precision_score, _, _, _, = precision_recall_fbeta_support(
        outputs=outputs,
        targets=targets,
        argmax_dim=argmax_dim,
        eps=eps,
        num_classes=num_classes,
    )
    return precision_score


</clonepair61>

<clonepair61>
<source file="systems/catalyst-22.02.1/catalyst/metrics/functional/_recall.py" startline="8" endline="68" pcid="592"></source>
def recall(
    outputs: torch.Tensor,
    targets: torch.Tensor,
    argmax_dim: int = -1,
    eps: float = 1e-7,
    num_classes: Optional[int] = None,
) -> Union[float, torch.Tensor]:
    """
    Multiclass recall score.

    Args:
        outputs: estimated targets as predicted by a model
            with shape [bs; ..., (num_classes or 1)]
        targets: ground truth (correct) target values
            with shape [bs; ..., 1]
        argmax_dim: int, that specifies dimension for argmax transformation
            in case of scores/probabilities in ``outputs``
        eps: float. Epsilon to avoid zero division.
        num_classes: int, that specifies number of classes if it known

    Returns:
        Tensor: recall for every class

    Examples:

    .. code-block:: python

        import torch
        from catalyst import metrics
        metrics.recall(
            outputs=torch.tensor([
                [1, 0, 0],
                [0, 1, 0],
                [0, 0, 1],
            ]),
            targets=torch.tensor([0, 1, 2]),
        )
        # tensor([1., 1., 1.])


    .. code-block:: python

        import torch
        from catalyst import metrics
        metrics.recall(
            outputs=torch.tensor([[0, 0, 1, 1, 0, 1, 0, 1]]),
            targets=torch.tensor([[0, 1, 0, 1, 0, 0, 1, 1]]),
        )
        # tensor([0.5000, 0.5000]
    """
    _, recall_score, _, _ = precision_recall_fbeta_support(
        outputs=outputs,
        targets=targets,
        argmax_dim=argmax_dim,
        eps=eps,
        num_classes=num_classes,
    )

    return recall_score


</clonepair61>
<clonepair62>
<source file="systems/catalyst-22.02.1/tests/catalyst/metrics/test_additive.py" startline="66" endline="87" pcid="731"></source>
def test_additive_std(
    values_list: Iterable[float],
    num_samples_list: Iterable[int],
    true_values_list: Iterable[float],
):
    """
    Test additive metric std computation

    Args:
        values_list: list of values to update metric
        num_samples_list: list of num_samples
        true_values_list: list of metric intermediate value
    """
    metric = AdditiveMetric()
    for value, num_samples, true_value in zip(
        values_list, num_samples_list, true_values_list
    ):
        metric.update(value=value, num_samples=num_samples)
        _, std = metric.compute()
        assert np.isclose(std, true_value)


</clonepair62>

<clonepair62>
<source file="systems/catalyst-22.02.1/tests/catalyst/metrics/test_additive.py" startline="105" endline="126" pcid="732"></source>
def test_additive_mode(
    values_list: Union[Iterable[float], Iterable[torch.Tensor]],
    num_samples_list: Iterable[int],
    true_values_list: Iterable[float],
    mode: Iterable[str],
):
    """
    Test additive metric std computation

    Args:
        values_list: list of values to update metric
        num_samples_list: list of num_samples
        true_values_list: list of metric intermediate value
        mode: `AdditiveMetric` mode
    """
    metric = AdditiveMetric(mode=mode)
    for value, num_samples, true_value in zip(
        values_list, num_samples_list, true_values_list
    ):
        metric.update(value=value, num_samples=num_samples)
        mean, _ = metric.compute()
        assert np.isclose(mean, true_value)
</clonepair62>
<clonepair63>
<source file="systems/catalyst-22.02.1/tests/catalyst/metrics/test_additive.py" startline="28" endline="49" pcid="730"></source>
def test_additive_mean(
    values_list: Iterable[float],
    num_samples_list: Iterable[int],
    true_values_list: Iterable[float],
) -> None:
    """
    Test additive metric mean computation

    Args:
        values_list: list of values to update metric
        num_samples_list: list of num_samples
        true_values_list: list of metric intermediate value
    """
    metric = AdditiveMetric()
    for value, num_samples, true_value in zip(
        values_list, num_samples_list, true_values_list
    ):
        metric.update(value=value, num_samples=num_samples)
        mean, _ = metric.compute()
        assert np.isclose(mean, true_value)


</clonepair63>

<clonepair63>
<source file="systems/catalyst-22.02.1/tests/catalyst/metrics/test_additive.py" startline="105" endline="126" pcid="732"></source>
def test_additive_mode(
    values_list: Union[Iterable[float], Iterable[torch.Tensor]],
    num_samples_list: Iterable[int],
    true_values_list: Iterable[float],
    mode: Iterable[str],
):
    """
    Test additive metric std computation

    Args:
        values_list: list of values to update metric
        num_samples_list: list of num_samples
        true_values_list: list of metric intermediate value
        mode: `AdditiveMetric` mode
    """
    metric = AdditiveMetric(mode=mode)
    for value, num_samples, true_value in zip(
        values_list, num_samples_list, true_values_list
    ):
        metric.update(value=value, num_samples=num_samples)
        mean, _ = metric.compute()
        assert np.isclose(mean, true_value)
</clonepair63>
<clonepair64>
<source file="systems/catalyst-22.02.1/tests/catalyst/metrics/test_additive.py" startline="28" endline="49" pcid="730"></source>
def test_additive_mean(
    values_list: Iterable[float],
    num_samples_list: Iterable[int],
    true_values_list: Iterable[float],
) -> None:
    """
    Test additive metric mean computation

    Args:
        values_list: list of values to update metric
        num_samples_list: list of num_samples
        true_values_list: list of metric intermediate value
    """
    metric = AdditiveMetric()
    for value, num_samples, true_value in zip(
        values_list, num_samples_list, true_values_list
    ):
        metric.update(value=value, num_samples=num_samples)
        mean, _ = metric.compute()
        assert np.isclose(mean, true_value)


</clonepair64>

<clonepair64>
<source file="systems/catalyst-22.02.1/tests/catalyst/metrics/test_additive.py" startline="66" endline="87" pcid="731"></source>
def test_additive_std(
    values_list: Iterable[float],
    num_samples_list: Iterable[int],
    true_values_list: Iterable[float],
):
    """
    Test additive metric std computation

    Args:
        values_list: list of values to update metric
        num_samples_list: list of num_samples
        true_values_list: list of metric intermediate value
    """
    metric = AdditiveMetric()
    for value, num_samples, true_value in zip(
        values_list, num_samples_list, true_values_list
    ):
        metric.update(value=value, num_samples=num_samples)
        _, std = metric.compute()
        assert np.isclose(std, true_value)


</clonepair64>
