<clones>
<systeminfo processor="nicad6" system="TensorLayer-2.0.2" granularity="functions-blind" threshold="30%" minlines="10" maxlines="2500"/>
<cloneinfo npcs="1564" npairs="564"/>
<runinfo ncompares="75893" cputime="69711"/>
<classinfo nclasses="64"/>

<class classid="1" nclones="4" nlines="11" similarity="75">
<source file="systems/TensorLayer-2.0.2/tests/files/test_utils_saveload.py" startline="18" endline="32" pcid="1">
def basic_static_model():
    ni = Input((None, 24, 24, 3))
    nn = Conv2d(16, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, name="conv1")(ni)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool1')(nn)

    nn = Conv2d(16, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, name="conv2")(nn)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool2')(nn)

    nn = Flatten(name='flatten')(nn)
    nn = Dense(100, act=None, name="dense1")(nn)
    nn = Dense(10, act=None, name="dense2")(nn)
    M = Model(inputs=ni, outputs=nn, name='basic_static')
    return M


</source>
<source file="systems/TensorLayer-2.0.2/tests/models/test_model_save_graph.py" startline="18" endline="31" pcid="65">
def basic_static_model():
    ni = Input((None, 24, 24, 3))
    nn = Conv2d(16, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, name="conv1")(ni)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool1')(nn)

    nn = Conv2d(16, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, name="conv2")(nn)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool2')(nn)

    nn = Flatten(name='flatten')(nn)
    nn = Dense(100, act=None, name="dense1")(nn)
    M = Model(inputs=ni, outputs=nn)
    return M


</source>
<source file="systems/TensorLayer-2.0.2/tests/models/test_model_save.py" startline="17" endline="32" pcid="49">
def basic_static_model(include_top=True):
    ni = Input((None, 24, 24, 3))
    nn = Conv2d(16, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, name="conv1")(ni)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool1')(nn)

    nn = Conv2d(16, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, name="conv2")(nn)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool2')(nn)

    nn = Flatten(name='flatten')(nn)
    nn = Dense(100, act=None, name="dense1")(nn)
    if include_top is True:
        nn = Dense(10, act=None, name="dense2")(nn)
    M = Model(inputs=ni, outputs=nn)
    return M


</source>
<source file="systems/TensorLayer-2.0.2/tests/models/test_model_core.py" startline="17" endline="31" pcid="33">
def basic_static_model():
    ni = Input((None, 24, 24, 3))
    nn = Conv2d(16, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, name="conv1")(ni)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool1')(nn)

    nn = Conv2d(16, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, name="conv2")(nn)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool2')(nn)

    nn = Flatten(name='flatten')(nn)
    nn = Dense(100, act=None, name="dense1")(nn)
    nn = Dense(10, act=None, name="dense2")(nn)
    M = Model(inputs=ni, outputs=nn)
    return M


</source>
</class>

<class classid="2" nclones="2" nlines="15" similarity="75">
<source file="systems/TensorLayer-2.0.2/tests/files/test_utils_saveload.py" startline="69" endline="88" pcid="6">
    def test_hdf5(self):
        modify_val = np.zeros_like(self.static_model.all_weights[-2].numpy())
        ori_val = self.static_model.all_weights[-2].numpy()
        tl.files.save_weights_to_hdf5("./model_basic.h5", self.static_model)

        self.static_model.all_weights[-2].assign(modify_val)
        tl.files.load_hdf5_to_weights_in_order("./model_basic.h5", self.static_model)
        self.assertLess(np.max(np.abs(ori_val - self.static_model.all_weights[-2].numpy())), 1e-7)

        self.static_model.all_weights[-2].assign(modify_val)
        tl.files.load_hdf5_to_weights("./model_basic.h5", self.static_model)
        self.assertLess(np.max(np.abs(ori_val - self.static_model.all_weights[-2].numpy())), 1e-7)

        ori_weights = self.static_model._all_weights
        self.static_model._all_weights = self.static_model._all_weights[1:]
        self.static_model.all_weights[-2].assign(modify_val)
        tl.files.load_hdf5_to_weights("./model_basic.h5", self.static_model, skip=True)
        self.assertLess(np.max(np.abs(ori_val - self.static_model.all_weights[-2].numpy())), 1e-7)
        self.static_model._all_weights = ori_weights

</source>
<source file="systems/TensorLayer-2.0.2/tests/files/test_utils_saveload.py" startline="98" endline="114" pcid="8">
    def test_npz_dict(self):
        modify_val = np.zeros_like(self.dynamic_model.all_weights[-2].numpy())
        ori_val = self.dynamic_model.all_weights[-2].numpy()
        tl.files.save_npz_dict(self.dynamic_model.all_weights, "./model_basic.npz")

        self.dynamic_model.all_weights[-2].assign(modify_val)
        tl.files.load_and_assign_npz_dict("./model_basic.npz", self.dynamic_model)
        self.assertLess(np.max(np.abs(ori_val - self.dynamic_model.all_weights[-2].numpy())), 1e-7)

        ori_weights = self.dynamic_model._all_weights
        self.dynamic_model._all_weights = self.static_model._all_weights[1:]
        self.dynamic_model.all_weights[-2].assign(modify_val)
        tl.files.load_and_assign_npz_dict("./model_basic.npz", self.dynamic_model, skip=True)
        self.assertLess(np.max(np.abs(ori_val - self.dynamic_model.all_weights[-2].numpy())), 1e-7)
        self.dynamic_model._all_weights = ori_weights


</source>
</class>

<class classid="3" nclones="2" nlines="48" similarity="83">
<source file="systems/TensorLayer-2.0.2/tests/models/test_model_core.py" startline="67" endline="135" pcid="38">
    def test_dynamic_basic(self):
        print('-' * 20, 'test_dynamic_basic', '-' * 20)
        model_basic = basic_dynamic_model()

        # test empty model before calling
        self.assertEqual(model_basic.is_train, None)
        self.assertEqual(model_basic._all_weights, None)
        self.assertEqual(model_basic._inputs, None)
        self.assertEqual(model_basic._outputs, None)
        self.assertEqual(model_basic._model_layer, None)
        self.assertEqual(model_basic._all_layers, None)
        self.assertEqual(model_basic._nodes_fixed, False)

        # test layer and weights access
        all_layers = model_basic.all_layers
        self.assertEqual(len(model_basic.all_layers), 7)
        self.assertEqual(model_basic._all_weights, None)

        self.assertIsNotNone(model_basic.all_weights)
        print([w.name for w in model_basic.all_weights])

        # test model mode
        model_basic.train()
        self.assertEqual(model_basic.is_train, True)
        model_basic.eval()
        self.assertEqual(model_basic.is_train, False)
        model_basic.test()
        self.assertEqual(model_basic.is_train, False)
        model_basic.infer()
        self.assertEqual(model_basic.is_train, False)

        # test as_layer
        try:
            model_basic.as_layer()
        except Exception as e:
            print(e)
        self.assertIsNone(model_basic._model_layer)

        # test print
        try:
            print(model_basic)
        except Exception as e:
            print(e)

        # test forwarding
        inputs = np.random.normal(size=[2, 24, 24, 3]).astype(np.float32)
        outputs1 = model_basic(inputs)
        self.assertEqual(model_basic._nodes_fixed, True)
        self.assertEqual(model_basic.is_train, False)

        try:
            outputs2 = model_basic(inputs, is_train=True)
        except Exception as e:
            print(e)
        outputs2 = model_basic(inputs, is_train=False)
        self.assertEqual(model_basic.is_train, False)

        self.assertLess(np.max(np.abs(outputs1.numpy() - outputs2.numpy())), 1e-7)

        # test layer node
        self.assertEqual(len(model_basic.all_layers[-1]._nodes), 0)
        self.assertEqual(model_basic.all_layers[-2]._nodes_fixed, True)

        # test release_memory
        try:
            model_basic.release_memory()
        except Exception as e:
            print(e)

</source>
<source file="systems/TensorLayer-2.0.2/tests/models/test_model_core.py" startline="136" endline="201" pcid="39">
    def test_static_basic(self):
        print('-' * 20, 'test_static_basic', '-' * 20)
        model_basic = basic_static_model()

        # test empty model before calling
        self.assertEqual(model_basic.is_train, None)
        self.assertEqual(model_basic._all_weights, None)
        self.assertIsNotNone(model_basic._inputs)
        self.assertIsNotNone(model_basic._outputs)
        self.assertEqual(model_basic._model_layer, None)
        self.assertIsNotNone(model_basic._all_layers)
        self.assertIsNotNone(model_basic._nodes_fixed)

        # test layer and weights access
        all_layers = model_basic.all_layers
        self.assertEqual(len(model_basic.all_layers), 8)
        self.assertEqual(model_basic._all_weights, None)

        self.assertIsNotNone(model_basic.all_weights)
        print([w.name for w in model_basic.all_weights])

        # test model mode
        model_basic.train()
        self.assertEqual(model_basic.is_train, True)
        model_basic.eval()
        self.assertEqual(model_basic.is_train, False)
        model_basic.test()
        self.assertEqual(model_basic.is_train, False)
        model_basic.infer()
        self.assertEqual(model_basic.is_train, False)

        # test as_layer
        self.assertIsInstance(model_basic.as_layer(), tl.layers.Layer)
        self.assertIsNotNone(model_basic._model_layer)

        # test print
        try:
            print(model_basic)
        except Exception as e:
            print(e)

        # test forwarding
        inputs = np.random.normal(size=[2, 24, 24, 3]).astype(np.float32)
        outputs1 = model_basic(inputs)
        self.assertEqual(model_basic._nodes_fixed, True)
        self.assertEqual(model_basic.is_train, False)

        try:
            outputs2 = model_basic(inputs, is_train=True)
        except Exception as e:
            print(e)
        outputs2 = model_basic(inputs, is_train=False)
        self.assertEqual(model_basic.is_train, False)

        self.assertLess(np.max(np.abs(outputs1.numpy() - outputs2.numpy())), 1e-7)

        # test layer node
        self.assertEqual(len(model_basic.all_layers[-1]._nodes), 1)
        self.assertEqual(model_basic.all_layers[-2]._nodes_fixed, True)

        # test release_memory
        try:
            model_basic.release_memory()
        except Exception as e:
            print(e)

</source>
</class>

<class classid="4" nclones="2" nlines="10" similarity="70">
<source file="systems/TensorLayer-2.0.2/tests/models/test_model_save.py" startline="49" endline="60" pcid="51">
    def forward(self, x):
        x = self.conv1(x)
        x = self.pool1(x)
        x = self.conv2(x)
        x = self.pool2(x)
        x = self.flatten(x)
        x = self.dense1(x)
        if self.include_top:
            x = self.dense2(x)
        return x


</source>
<source file="systems/TensorLayer-2.0.2/examples/basic_tutorials/tutorial_mnist_mlp_dynamic.py" startline="29" endline="39" pcid="608">
    def forward(self, x, foo=None):
        z = self.dropout1(x)
        z = self.dense1(z)
        z = self.dropout2(z)
        z = self.dense2(z)
        z = self.dropout3(z)
        out = self.dense3(z)
        if foo is not None:
            out = tf.nn.relu(out)
        return out

</source>
</class>

<class classid="5" nclones="2" nlines="10" similarity="100">
<source file="systems/TensorLayer-2.0.2/tests/models/test_model_save_graph.py" startline="152" endline="164" pcid="73">
def create_base_network(input_shape):
    '''Base network to be shared (eq. to feature extraction).
    '''
    input = Input(shape=input_shape)
    x = Flatten()(input)
    x = Dense(128, act=tf.nn.relu)(x)
    x = Dropout(0.9)(x)
    x = Dense(128, act=tf.nn.relu)(x)
    x = Dropout(0.9)(x)
    x = Dense(128, act=tf.nn.relu)(x)
    return Model(input, x)


</source>
<source file="systems/TensorLayer-2.0.2/examples/basic_tutorials/tutorial_mnist_siamese.py" startline="41" endline="53" pcid="603">
def create_base_network(input_shape):
    '''Base network to be shared (eq. to feature extraction).
    '''
    input = Input(shape=input_shape)
    x = Flatten()(input)
    x = Dense(128, act=tf.nn.relu)(x)
    x = Dropout(0.9)(x)
    x = Dense(128, act=tf.nn.relu)(x)
    x = Dropout(0.9)(x)
    x = Dense(128, act=tf.nn.relu)(x)
    return Model(input, x)


</source>
</class>

<class classid="6" nclones="2" nlines="17" similarity="77">
<source file="systems/TensorLayer-2.0.2/tests/models/test_model_save_graph.py" startline="240" endline="256" pcid="82">
    def test_lambda_layer_no_para_no_args(self):
        x = tl.layers.Input([8, 3], name='input')
        y = tl.layers.Lambda(lambda x: 2 * x, name='lambda')(x)
        M1 = tl.models.Model(x, y)
        M1.save("lambda_no_para_no_args.hdf5")
        M2 = tl.models.Model.load("lambda_no_para_no_args.hdf5")
        print(M1)
        print(M2)
        M1.eval()
        M2.eval()
        npInput = np.zeros((8, 3)) + 3
        output1 = M1(npInput).numpy()
        output2 = M1(npInput).numpy()

        self.assertEqual((output1 == output2).all(), True)
        self.assertEqual(M1.config, M2.config)

</source>
<source file="systems/TensorLayer-2.0.2/tests/models/test_model_save_graph.py" startline="257" endline="278" pcid="83">
    def test_lambda_layer_no_para_with_args(self):

        def customize_func(x, foo=42):  # x is the inputs, foo is an argument
            return foo * x

        x = tl.layers.Input([8, 3], name='input')
        y = tl.layers.Lambda(customize_func, fn_args={'foo': 3}, name='lambda')(x)
        M1 = tl.models.Model(x, y)
        M1.save("lambda_no_para_with_args.hdf5")
        M2 = tl.models.Model.load("lambda_no_para_with_args.hdf5")
        print(M1)
        print(M2)
        M1.eval()
        M2.eval()
        npInput = np.zeros((8, 3)) + 3
        output1 = M1(npInput).numpy()
        output2 = M2(npInput).numpy()

        self.assertEqual((output1 == output2).all(), True)
        self.assertEqual((output1 == (np.zeros((8, 3)) + 9)).all(), True)
        self.assertEqual(M1.config, M2.config)

</source>
</class>

<class classid="7" nclones="2" nlines="24" similarity="80">
<source file="systems/TensorLayer-2.0.2/tests/models/test_model_save_graph.py" startline="279" endline="312" pcid="85">
    def test_lambda_layer_keras_model(self):
        input_shape = [100, 5]
        in_2 = tl.layers.Input(input_shape, name='input')
        layers = [
            tf.keras.layers.Dense(10, activation=tf.nn.relu),
            tf.keras.layers.Dense(5, activation=tf.nn.sigmoid),
            tf.keras.layers.Dense(1, activation=tf.nn.relu)
        ]
        perceptron = tf.keras.Sequential(layers)
        # in order to compile keras model and get trainable_variables of the keras model
        _ = perceptron(np.random.random(input_shape).astype(np.float32))
        plambdalayer = tl.layers.Lambda(perceptron, perceptron.trainable_variables)(in_2)
        M2 = tl.models.Model(inputs=in_2, outputs=plambdalayer)

        M2.save('M2_keras.hdf5')
        M4 = Model.load('M2_keras.hdf5')

        M2.eval()
        M4.eval()
        npInput = np.zeros(input_shape) + 3
        output2 = M2(npInput).numpy()
        output4 = M4(npInput).numpy()

        self.assertEqual((output2 == output4).all(), True)
        self.assertEqual(M2.config, M4.config)

        ori_weights = M4.all_weights
        ori_val = ori_weights[1].numpy()
        modify_val = np.zeros_like(ori_val) + 10
        M4.all_weights[1].assign(modify_val)
        M4 = Model.load('M2_keras.hdf5')

        self.assertLess(np.max(np.abs(ori_val - M4.all_weights[1].numpy())), 1e-7)

</source>
<source file="systems/TensorLayer-2.0.2/tests/models/test_model_save_graph.py" startline="313" endline="342" pcid="86">
    def test_lambda_layer_keras_layer(self):
        input_shape = [100, 5]
        in_1 = tl.layers.Input(input_shape, name='input')
        denselayer = tf.keras.layers.Dense(10, activation=tf.nn.relu)
        # in order to compile keras model and get trainable_variables of the keras model
        _ = denselayer(np.random.random(input_shape).astype(np.float32))
        dlambdalayer = tl.layers.Lambda(denselayer, denselayer.trainable_variables)(in_1)
        M1 = tl.models.Model(inputs=in_1, outputs=dlambdalayer)

        M1.save('M1_keras.hdf5')
        M3 = Model.load('M1_keras.hdf5')

        M1.eval()
        M3.eval()
        npInput = np.zeros(input_shape) + 3
        output1 = M1(npInput).numpy()
        output3 = M3(npInput).numpy()

        self.assertEqual((output1 == output3).all(), True)
        self.assertEqual(M1.config, M3.config)

        ori_weights = M3.all_weights
        ori_val = ori_weights[1].numpy()
        modify_val = np.zeros_like(ori_val) + 10
        M3.all_weights[1].assign(modify_val)
        M3 = Model.load('M1_keras.hdf5')

        self.assertLess(np.max(np.abs(ori_val - M3.all_weights[1].numpy())), 1e-7)


</source>
</class>

<class classid="8" nclones="3" nlines="17" similarity="72">
<source file="systems/TensorLayer-2.0.2/tests/models/test_model_save_graph.py" startline="349" endline="370" pcid="88">
    def test_elementwise_no_para_with_args(self):
        # z = mean + noise * tf.exp(std * 0.5) + foo
        def func(noise, mean, std, foo=42):
            return mean + noise * tf.exp(std * 0.5) + foo

        noise = tl.layers.Input([100, 1])
        mean = tl.layers.Input([100, 1])
        std = tl.layers.Input([100, 1])
        out = tl.layers.ElementwiseLambda(fn=func, fn_args={'foo': 84}, name='elementwiselambda')([noise, mean, std])
        M1 = Model(inputs=[noise, mean, std], outputs=out)
        M1.save("elementwise_npwa.hdf5")
        M2 = Model.load("elementwise_npwa.hdf5")

        M1.eval()
        M2.eval()
        ipt = [np.zeros((100, 1)) + 11, np.zeros((100, 1)) + 21, np.zeros((100, 1)) + 31]
        output1 = M1(ipt).numpy()
        output2 = M2(ipt).numpy()

        self.assertEqual((output1 == output2).all(), True)
        self.assertEqual(M1.config, M2.config)

</source>
<source file="systems/TensorLayer-2.0.2/tests/models/test_model_save_graph.py" startline="393" endline="440" pcid="92">
    def test_elementwise_lambda_func(self):
        # z = mean + noise * tf.exp(std * 0.5)
        noise = tl.layers.Input([100, 1])
        mean = tl.layers.Input([100, 1])
        std = tl.layers.Input([100, 1])
        out = tl.layers.ElementwiseLambda(fn=lambda x, y, z: x + y * tf.exp(z * 0.5),
                                          name='elementwiselambda')([noise, mean, std])
        M1 = Model(inputs=[noise, mean, std], outputs=out)
        M1.save("elementwise_lambda.hdf5")
        M2 = Model.load("elementwise_lambda.hdf5")

        M1.eval()
        M2.eval()
        ipt = [
            (np.zeros((100, 1)) + 11).astype(np.float32), (np.zeros((100, 1)) + 21).astype(np.float32),
            (np.zeros((100, 1)) + 31).astype(np.float32)
        ]
        output1 = M1(ipt).numpy()
        output2 = M2(ipt).numpy()

        self.assertEqual((output1 == output2).all(), True)
        self.assertEqual(M1.config, M2.config)

    # # ElementwiseLambda does not support keras layer/model func yet
    # def test_elementwise_keras_model(self):
    #     kerasinput1 = tf.keras.layers.Input(shape=(100, ))
    #     kerasinput2 = tf.keras.layers.Input(shape=(100, ))
    #     kerasconcate = tf.keras.layers.concatenate(inputs=[kerasinput1, kerasinput2])
    #     kerasmodel = tf.keras.models.Model(inputs=[kerasinput1, kerasinput2], outputs=kerasconcate)
    #     _ = kerasmodel([np.random.random([100,]).astype(np.float32), np.random.random([100,]).astype(np.float32)])
    #
    #     input1 = tl.layers.Input([100, 1])
    #     input2 = tl.layers.Input([100, 1])
    #     out = tl.layers.ElementwiseLambda(fn=kerasmodel, name='elementwiselambda')([input1, input2])
    #     M1 = Model(inputs=[input1, input2], outputs=out)
    #     M1.save("elementwise_keras_model.hdf5")
    #     M2 = Model.load("elementwise_keras_model.hdf5")
    #
    #     M1.eval()
    #     M2.eval()
    #     ipt = [np.zeros((100, 1)) + 11, np.zeros((100, 1)) + 21, np.zeros((100, 1)) + 31]
    #     output1 = M1(ipt).numpy()
    #     output2 = M2(ipt).numpy()
    #
    #     self.assertEqual((output1 == output2).all(), True)
    #     self.assertEqual(M1.config, M2.config)


</source>
<source file="systems/TensorLayer-2.0.2/tests/models/test_model_save_graph.py" startline="371" endline="392" pcid="90">
    def test_elementwise_no_para_no_args(self):
        # z = mean + noise * tf.exp(std * 0.5) + foo
        def func(noise, mean, std, foo=42):
            return mean + noise * tf.exp(std * 0.5) + foo

        noise = tl.layers.Input([100, 1])
        mean = tl.layers.Input([100, 1])
        std = tl.layers.Input([100, 1])
        out = tl.layers.ElementwiseLambda(fn=func, name='elementwiselambda')([noise, mean, std])
        M1 = Model(inputs=[noise, mean, std], outputs=out)
        M1.save("elementwise_npna.hdf5")
        M2 = Model.load("elementwise_npna.hdf5")

        M1.eval()
        M2.eval()
        ipt = [np.zeros((100, 1)) + 11, np.zeros((100, 1)) + 21, np.zeros((100, 1)) + 31]
        output1 = M1(ipt).numpy()
        output2 = M2(ipt).numpy()

        self.assertEqual((output1 == output2).all(), True)
        self.assertEqual(M1.config, M2.config)

</source>
</class>

<class classid="9" nclones="5" nlines="31" similarity="70">
<source file="systems/TensorLayer-2.0.2/tests/utils/custom_layers/inception_blocks.py" startline="19" endline="69" pcid="123">
def block_inception_a(inputs, scope=None, is_train=False):
    """Builds Inception-A block for Inception v4 network."""
    # By default use stride=1 and SAME padding

    with tf.variable_scope(name_or_scope=scope, default_name='BlockInceptionA', values=[inputs]):
        with tf.variable_scope('Branch_0'):
            branch_0, _ = conv_module(
                inputs, n_out_channel=96, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

        with tf.variable_scope('Branch_1'):
            branch_1, _ = conv_module(
                inputs, n_out_channel=64, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_1, _ = conv_module(
                branch_1, n_out_channel=96, filter_size=(3, 3), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_3x3'
            )

        with tf.variable_scope('Branch_2'):
            branch_2, _ = conv_module(
                inputs, n_out_channel=64, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_2, _ = conv_module(
                branch_2, n_out_channel=96, filter_size=(3, 3), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_3x3'
            )

            branch_2, _ = conv_module(
                branch_2, n_out_channel=96, filter_size=(3, 3), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0c_3x3'
            )

        with tf.variable_scope('Branch_3'):
            branch_3 = tl.layers.MeanPool2d(
                inputs, filter_size=(3, 3), strides=(1, 1), padding='SAME', name='AvgPool_0a_3x3'
            )

            branch_3, _ = conv_module(
                branch_3, n_out_channel=96, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_1x1'
            )

        return tl.layers.ConcatLayer([branch_0, branch_1, branch_2, branch_3], concat_dim=3, name='concat_layer')


</source>
<source file="systems/TensorLayer-2.0.2/tests/utils/custom_layers/inception_blocks.py" startline="103" endline="168" pcid="125">
def block_inception_b(inputs, scope=None, is_train=False):
    """Builds Inception-B block for Inception v4 network."""
    # By default use stride=1 and SAME padding

    with tf.variable_scope(scope, 'BlockInceptionB', [inputs]):
        with tf.variable_scope('Branch_0'):
            branch_0, _ = conv_module(
                inputs, n_out_channel=384, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

        with tf.variable_scope('Branch_1'):
            branch_1, _ = conv_module(
                inputs, n_out_channel=192, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_1, _ = conv_module(
                branch_1, n_out_channel=224, filter_size=(1, 7), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_1x7'
            )

            branch_1, _ = conv_module(
                branch_1, n_out_channel=256, filter_size=(7, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0c_7x1'
            )

        with tf.variable_scope('Branch_2'):
            branch_2, _ = conv_module(
                inputs, n_out_channel=192, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_2, _ = conv_module(
                branch_2, n_out_channel=192, filter_size=(7, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_7x1'
            )

            branch_2, _ = conv_module(
                branch_2, n_out_channel=224, filter_size=(1, 7), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0c_1x7'
            )

            branch_2, _ = conv_module(
                branch_2, n_out_channel=224, filter_size=(7, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0d_7x1'
            )

            branch_2, _ = conv_module(
                branch_2, n_out_channel=256, filter_size=(1, 7), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0e_1x7'
            )

        with tf.variable_scope('Branch_3'):
            branch_3 = tl.layers.MeanPool2d(
                inputs, filter_size=(3, 3), strides=(1, 1), padding='SAME', name='AvgPool_0a_3x3'
            )

            branch_3, _ = conv_module(
                branch_3, n_out_channel=128, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_1x1'
            )

        return tl.layers.ConcatLayer([branch_0, branch_1, branch_2, branch_3], concat_dim=3, name='concat_layer')


</source>
<source file="systems/TensorLayer-2.0.2/tests/utils/custom_layers/inception_blocks.py" startline="169" endline="211" pcid="126">
def block_reduction_b(inputs, scope=None, is_train=False):
    """Builds Reduction-B block for Inception v4 network."""
    # By default use stride=1 and SAME padding

    with tf.variable_scope(scope, 'BlockReductionB', [inputs]):
        with tf.variable_scope('Branch_0'):
            branch_0, _ = conv_module(
                inputs, n_out_channel=192, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_0, _ = conv_module(
                branch_0, n_out_channel=192, filter_size=(3, 3), strides=(2, 2), padding='VALID', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_1a_3x3'
            )

        with tf.variable_scope('Branch_1'):
            branch_1, _ = conv_module(
                inputs, n_out_channel=256, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_1, _ = conv_module(
                branch_1, n_out_channel=256, filter_size=(1, 7), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_1x7'
            )

            branch_1, _ = conv_module(
                branch_1, n_out_channel=320, filter_size=(7, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0c_7x1'
            )

            branch_1, _ = conv_module(
                branch_1, n_out_channel=320, filter_size=(3, 3), strides=(2, 2), padding='VALID', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_1a_3x3'
            )

        with tf.variable_scope('Branch_2'):
            branch_2 = tl.layers.MaxPool2d(inputs, (3, 3), strides=(2, 2), padding='VALID', name='MaxPool_1a_3x3')

        return tl.layers.ConcatLayer([branch_0, branch_1, branch_2], concat_dim=3, name='concat_layer')


</source>
<source file="systems/TensorLayer-2.0.2/tests/utils/custom_layers/inception_blocks.py" startline="212" endline="279" pcid="127">
def block_inception_c(inputs, scope=None, is_train=False):
    """Builds Inception-C block for Inception v4 network."""
    # By default use stride=1 and SAME padding

    with tf.variable_scope(scope, 'BlockInceptionC', [inputs]):
        with tf.variable_scope('Branch_0'):
            branch_0, _ = conv_module(
                inputs, n_out_channel=256, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

        with tf.variable_scope('Branch_1'):
            branch_1, _ = conv_module(
                inputs, n_out_channel=384, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_1a, _ = conv_module(
                branch_1, n_out_channel=256, filter_size=(1, 3), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_1x3'
            )

            branch_1b, _ = conv_module(
                branch_1, n_out_channel=256, filter_size=(3, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0c_3x1'
            )

            branch_1 = tl.layers.ConcatLayer([branch_1a, branch_1b], concat_dim=3, name='concat_layer')

        with tf.variable_scope('Branch_2'):
            branch_2, _ = conv_module(
                inputs, n_out_channel=384, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_2, _ = conv_module(
                branch_2, n_out_channel=448, filter_size=(3, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_3x1'
            )

            branch_2, _ = conv_module(
                branch_2, n_out_channel=512, filter_size=(1, 3), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0c_1x3'
            )

            branch_2a, _ = conv_module(
                branch_2, n_out_channel=256, filter_size=(1, 3), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0d_1x3'
            )

            branch_2b, _ = conv_module(
                branch_2, n_out_channel=256, filter_size=(3, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0e_3x1'
            )

            branch_2 = tl.layers.ConcatLayer([branch_2a, branch_2b], concat_dim=3, name='concat_layer')

        with tf.variable_scope('Branch_3'):
            branch_3 = tl.layers.MeanPool2d(
                inputs, filter_size=(3, 3), strides=(1, 1), padding='SAME', name='AvgPool_0a_3x3'
            )

            branch_3, _ = conv_module(
                branch_3, n_out_channel=256, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_1x1'
            )

        return tl.layers.ConcatLayer([branch_0, branch_1, branch_2, branch_3], concat_dim=3, name='concat_layer')
</source>
<source file="systems/TensorLayer-2.0.2/tests/utils/custom_layers/inception_blocks.py" startline="70" endline="102" pcid="124">
def block_reduction_a(inputs, scope=None, is_train=False):
    """Builds Reduction-A block for Inception v4 network."""
    # By default use stride=1 and SAME padding

    with tf.variable_scope(scope, 'BlockReductionA', [inputs]):
        with tf.variable_scope('Branch_0'):
            branch_0, _ = conv_module(
                inputs, n_out_channel=384, filter_size=(3, 3), strides=(2, 2), padding='VALID', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_1a_3x3'
            )

        with tf.variable_scope('Branch_1'):
            branch_1, _ = conv_module(
                inputs, n_out_channel=192, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_1, _ = conv_module(
                branch_1, n_out_channel=224, filter_size=(3, 3), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_3x3'
            )

            branch_1, _ = conv_module(
                branch_1, n_out_channel=256, filter_size=(3, 3), strides=(2, 2), padding='VALID', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_1a_3x3'
            )

        with tf.variable_scope('Branch_2'):
            branch_2 = tl.layers.MaxPool2d(inputs, (3, 3), strides=(2, 2), padding='VALID', name='MaxPool_1a_3x3')

        return tl.layers.ConcatLayer([branch_0, branch_1, branch_2], concat_dim=3, name='concat_layer')


</source>
</class>

<class classid="10" nclones="2" nlines="10" similarity="100">
<source file="systems/TensorLayer-2.0.2/tests/pending/test_documentation.py" startline="24" endline="35" pcid="157">
    def test_html_documentation(self):
        app = Sphinx(
            self.source_dir,
            self.config_dir,
            self.output_dir,
            self.doctree_dir,
            buildername='html',
            warningiserror=True,
        )
        app.build(force_all=self.all_files)
        # TODO: additional checks here if needed

</source>
<source file="systems/TensorLayer-2.0.2/tests/pending/test_documentation.py" startline="36" endline="48" pcid="158">
    def test_text_documentation(self):
        # The same, but with different buildername
        app = Sphinx(
            self.source_dir,
            self.config_dir,
            self.output_dir,
            self.doctree_dir,
            buildername='text',
            warningiserror=False,
        )
        app.build(force_all=self.all_files)
        # TODO:  additional checks if needed

</source>
</class>

<class classid="11" nclones="4" nlines="12" similarity="75">
<source file="systems/TensorLayer-2.0.2/tests/pending/test_logging_hyperdash.py" startline="37" endline="59" pcid="265">
    def test_monitor(self):

        with self.assertNotRaises(Exception):

            hd.HyperDashHandler.set_apikey(self.apikey)

            @hd.monitor("TRAVIS 1 - dogs vs. cats")
            def train_dogs_vs_cats(exp=None):

                # Record the value of hyperparameter gamma for this experiment
                lr = exp.param("learning rate", 0.005)
                tl.logging.debug("Learning Rate: %f" % lr)

                for epoch, accuracy in enumerate([10, 30, 50, 70, 80, 90, 95, 100]):
                    tl.logging.debug("Epoch %d - Accuracy %d%%" % (epoch + 1, accuracy))

                    # Record a numerical performance metric
                    exp.metric(name="accuracy", value=accuracy)

                    time.sleep(0.1)

            train_dogs_vs_cats()

</source>
<source file="systems/TensorLayer-2.0.2/tests/pending/test_logging_hyperdash.py" startline="60" endline="80" pcid="267">
    def test_monitor_variant(self):

        with self.assertNotRaises(Exception):

            @hd.monitor("TRAVIS 2 - dogs vs. cats", api_key=self.apikey)
            def train_dogs_vs_cats(exp=None):

                # Record the value of hyperparameter gamma for this experiment
                lr = exp.param("learning rate", 0.005)
                tl.logging.debug("Learning Rate: %f" % lr)

                for epoch, accuracy in enumerate([10, 30, 50, 70, 80, 90, 95, 100]):
                    tl.logging.debug("Epoch %d - Accuracy %d%%" % (epoch + 1, accuracy))

                    # Record a numerical performance metric
                    exp.metric(name="accuracy", value=accuracy)

                    time.sleep(0.1)

            train_dogs_vs_cats()

</source>
<source file="systems/TensorLayer-2.0.2/tests/pending/test_logging_hyperdash.py" startline="109" endline="135" pcid="271">
    def test_Experiment_variant(self):

        with self.assertNotRaises(Exception):

            def train_dogs_vs_cats():

                # Create an experiment with a model name, then autostart
                exp = hd.Experiment("TRAVIS 4 - dogs vs. cats", api_key=self.apikey)

                # Record the value of hyperparameter gamma for this experiment
                lr = exp.param("learning rate", 0.005)
                tl.logging.debug("Learning Rate: %f" % lr)

                for epoch, accuracy in enumerate([10, 30, 50, 70, 80, 90, 95, 100]):
                    tl.logging.debug("Epoch %d - Accuracy %d%%" % (epoch + 1, accuracy))

                    # Record a numerical performance metric
                    exp.metric(name="accuracy", value=accuracy)

                    time.sleep(0.1)

                # Cleanup and mark that the experiment successfully completed
                exp.end()

            train_dogs_vs_cats()


</source>
<source file="systems/TensorLayer-2.0.2/tests/pending/test_logging_hyperdash.py" startline="81" endline="108" pcid="269">
    def test_Experiment(self):

        hd.HyperDashHandler.set_apikey(self.apikey)

        with self.assertNotRaises(Exception):

            def train_dogs_vs_cats():

                # Create an experiment with a model name, then autostart
                exp = hd.Experiment("TRAVIS 3 - dogs vs. cats")

                # Record the value of hyperparameter gamma for this experiment
                lr = exp.param("learning rate", 0.005)
                tl.logging.debug("Learning Rate: %f" % lr)

                for epoch, accuracy in enumerate([10, 30, 50, 70, 80, 90, 95, 100]):
                    tl.logging.debug("Epoch %d - Accuracy %d%%" % (epoch + 1, accuracy))

                    # Record a numerical performance metric
                    exp.metric(name="accuracy", value=accuracy)

                    time.sleep(0.1)

                # Cleanup and mark that the experiment successfully completed
                exp.end()

            train_dogs_vs_cats()

</source>
</class>

<class classid="12" nclones="2" nlines="11" similarity="72">
<source file="systems/TensorLayer-2.0.2/tests/test_activations.py" startline="28" endline="43" pcid="304">
    def test_lrelu(self):
        for i in range(-5, 15):

            if i > 0:
                good_output = i
            else:
                good_output = self.alpha * i

            computed_output = tl.act.leaky_relu(float(i), alpha=self.alpha)

            self.assertAlmostEqual(computed_output.numpy(), good_output, places=5)

        net = tl.layers.Input([10, 2])
        net = tl.layers.Dense(n_units=100, act=lambda x: tl.act.lrelu(x, 0.2), name='dense')(net)
        print(net)

</source>
<source file="systems/TensorLayer-2.0.2/tests/test_activations.py" startline="44" endline="59" pcid="305">
    def test_lrelu6(self):
        for i in range(-5, 15):

            if i < 0:
                good_output = self.alpha * i
            else:
                good_output = min(6, i)

            computed_output = tl.act.leaky_relu6(float(i), alpha=self.alpha)

            self.assertAlmostEqual(computed_output.numpy(), good_output, places=5)

        net = tl.layers.Input([10, 2])
        net = tl.layers.Dense(n_units=100, act=lambda x: tl.act.leaky_relu6(x, 0.2), name='dense')(net)
        print(net)

</source>
</class>

<class classid="13" nclones="2" nlines="13" similarity="84">
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_stack.py" startline="19" endline="35" pcid="398">
    def setUpClass(cls):
        print("-" * 20, "Layer_Stack_Test", "-" * 20)
        cls.batch_size = 4
        cls.inputs_shape = [cls.batch_size, 10]

        cls.ni = Input(cls.inputs_shape, name='input_layer')
        a = Dense(n_units=5)(cls.ni)
        b = Dense(n_units=5)(cls.ni)
        cls.layer1 = Stack(axis=1)
        cls.n1 = cls.layer1([a, b])
        cls.M = Model(inputs=cls.ni, outputs=cls.n1)

        cls.inputs = tf.random.uniform(cls.inputs_shape)
        cls.n2 = cls.M(cls.inputs, is_train=True)

        print(cls.layer1)

</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_stack.py" startline="50" endline="65" pcid="402">
    def setUpClass(cls):
        print("-" * 20, "Layer_UnStack_Test", "-" * 20)
        cls.batch_size = 4
        cls.inputs_shape = [cls.batch_size, 10]

        cls.ni = Input(cls.inputs_shape, name='input_layer')
        a = Dense(n_units=5)(cls.ni)
        cls.layer1 = UnStack(axis=1)  # unstack in channel axis
        cls.n1 = cls.layer1(a)
        cls.M = Model(inputs=cls.ni, outputs=cls.n1)

        cls.inputs = tf.random.uniform(cls.inputs_shape)
        cls.n2 = cls.M(cls.inputs, is_train=True)

        print(cls.layer1)

</source>
</class>

<class classid="14" nclones="2" nlines="19" similarity="75">
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_merge.py" startline="26" endline="49" pcid="408">
    def test_concat(self):

        class CustomModel(tl.models.Model):

            def __init__(self):
                super(CustomModel, self).__init__()
                self.dense1 = tl.layers.Dense(in_channels=20, n_units=10, act=tf.nn.relu, name='relu1_1')
                self.dense2 = tl.layers.Dense(in_channels=20, n_units=10, act=tf.nn.relu, name='relu2_1')
                self.concat = tl.layers.Concat(concat_dim=1, name='concat_layer')

            def forward(self, inputs):
                d1 = self.dense1(inputs)
                d2 = self.dense2(inputs)
                outputs = self.concat([d1, d2])
                return outputs

        model = CustomModel()
        model.train()
        inputs = tf.convert_to_tensor(np.random.random([4, 20]).astype(np.float32))
        outputs = model(inputs)
        print(model)

        self.assertEqual(outputs.get_shape().as_list(), [4, 20])

</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_merge.py" startline="50" endline="76" pcid="411">
    def test_elementwise(self):

        class CustomModel(tl.models.Model):

            def __init__(self):
                super(CustomModel, self).__init__()
                self.dense1 = tl.layers.Dense(in_channels=20, n_units=10, act=tf.nn.relu, name='relu1_1')
                self.dense2 = tl.layers.Dense(in_channels=20, n_units=10, act=tf.nn.relu, name='relu2_1')
                self.element = tl.layers.Elementwise(combine_fn=tf.minimum, name='minimum', act=tf.identity)

            def forward(self, inputs):
                d1 = self.dense1(inputs)
                d2 = self.dense2(inputs)
                outputs = self.element([d1, d2])
                return outputs, d1, d2

        model = CustomModel()
        model.train()
        inputs = tf.convert_to_tensor(np.random.random([4, 20]).astype(np.float32))
        outputs, d1, d2 = model(inputs)
        print(model)

        min = tf.minimum(d1, d2)
        self.assertEqual(outputs.get_shape().as_list(), [4, 10])
        self.assertTrue(np.array_equal(min.numpy(), outputs.numpy()))


</source>
</class>

<class classid="15" nclones="3" nlines="20" similarity="85">
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_recurrent.py" startline="43" endline="70" pcid="437">
    def test_basic_simplernn(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.RNN(
            cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, dropout=0.1), return_last_output=True,
            return_seq_2d=False, return_last_state=True
        )
        rnn, rnn_state = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn_state[0]])
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()
        assert rnnlayer.is_train

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y, final_state = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_recurrent.py" startline="214" endline="240" pcid="449">
    def test_basic_lstmrnn(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.RNN(
            cell=tf.keras.layers.LSTMCell(units=self.hidden_size, dropout=0.1), return_last_output=True,
            return_seq_2d=False, return_last_state=True
        )
        rnn, rnn_state = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn_state[0], rnn_state[1]])
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y, final_h, final_c = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_recurrent.py" startline="241" endline="267" pcid="450">
    def test_basic_grurnn(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.RNN(
            cell=tf.keras.layers.GRUCell(units=self.hidden_size, dropout=0.1), return_last_output=True,
            return_seq_2d=False, return_last_state=True
        )
        rnn, rnn_state = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn_state[0]])
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y, final_h = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</source>
</class>

<class classid="16" nclones="4" nlines="26" similarity="73">
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_recurrent.py" startline="107" endline="139" pcid="440">
    def test_basic_simplernn_dynamic(self):

        class CustomisedModel(tl.models.Model):

            def __init__(self):
                super(CustomisedModel, self).__init__()
                self.rnnlayer = tl.layers.RNN(
                    cell=tf.keras.layers.SimpleRNNCell(units=8, dropout=0.1), in_channels=4, return_last_output=False,
                    return_seq_2d=False, return_last_state=False
                )
                self.dense = tl.layers.Dense(in_channels=8, n_units=1)

            def forward(self, x):
                z = self.rnnlayer(x)
                z = self.dense(z[:, -1, :])
                return z

        rnn_model = CustomisedModel()
        print(rnn_model)
        optimizer = tf.optimizers.Adam(learning_rate=0.01)
        rnn_model.train()

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_recurrent.py" startline="335" endline="370" pcid="453">
    def test_basic_birnn_grucell(self):

        class CustomisedModel(tl.models.Model):

            def __init__(self):
                super(CustomisedModel, self).__init__()
                self.rnnlayer = tl.layers.BiRNN(
                    fw_cell=tf.keras.layers.GRUCell(units=8,
                                                    dropout=0.1), bw_cell=tf.keras.layers.GRUCell(units=8, dropout=0.1),
                    in_channels=4, return_seq_2d=False, return_last_state=False
                )
                self.dense = tl.layers.Dense(in_channels=16, n_units=1)
                self.reshape = tl.layers.Reshape([-1, 6])

            def forward(self, x):
                z = self.rnnlayer(x, return_seq_2d=True)
                z = self.dense(z)
                z = self.reshape(z)
                return z

        rnn_model = CustomisedModel()
        print(rnn_model)
        optimizer = tf.optimizers.Adam(learning_rate=0.01)
        rnn_model.train()

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_recurrent.py" startline="174" endline="213" pcid="446">
    def test_basic_simplernn_dynamic_3(self):

        class CustomisedModel(tl.models.Model):

            def __init__(self):
                super(CustomisedModel, self).__init__()
                self.rnnlayer1 = tl.layers.RNN(
                    cell=tf.keras.layers.SimpleRNNCell(units=8, dropout=0.1), in_channels=4, return_last_output=True,
                    return_last_state=True
                )
                self.rnnlayer2 = tl.layers.RNN(
                    cell=tf.keras.layers.SimpleRNNCell(units=8, dropout=0.1), in_channels=4, return_last_output=True,
                    return_last_state=False
                )
                self.dense = tl.layers.Dense(in_channels=8, n_units=1)

            def forward(self, x):
                _, state = self.rnnlayer1(x[:, :2, :])
                z = self.rnnlayer2(x[:, 2:, :], initial_state=state)
                z = self.dense(z)
                return z

        rnn_model = CustomisedModel()
        print(rnn_model)
        optimizer = tf.optimizers.Adam(learning_rate=0.01)
        rnn_model.train()
        assert rnn_model.rnnlayer1.is_train
        assert rnn_model.rnnlayer2.is_train

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_recurrent.py" startline="140" endline="173" pcid="443">
    def test_basic_simplernn_dynamic_2(self):

        class CustomisedModel(tl.models.Model):

            def __init__(self):
                super(CustomisedModel, self).__init__()
                self.rnnlayer = tl.layers.RNN(
                    cell=tf.keras.layers.SimpleRNNCell(units=8, dropout=0.1), in_channels=4, return_last_output=False,
                    return_seq_2d=False, return_last_state=False
                )
                self.dense = tl.layers.Dense(in_channels=8, n_units=1)

            def forward(self, x):
                z = self.rnnlayer(x, return_seq_2d=True)
                z = self.dense(z[-2:, :])
                return z

        rnn_model = CustomisedModel()
        print(rnn_model)
        optimizer = tf.optimizers.Adam(learning_rate=0.01)
        rnn_model.train()
        assert rnn_model.rnnlayer.is_train

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</source>
</class>

<class classid="17" nclones="2" nlines="25" similarity="92">
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_recurrent.py" startline="268" endline="300" pcid="451">
    def test_basic_birnn_simplernncell(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.BiRNN(
            fw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, dropout=0.1),
            bw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size + 1,
                                                  dropout=0.1), return_seq_2d=True, return_last_state=True
        )
        rnn, rnn_fw_state, rnn_bw_state = rnnlayer(inputs)
        dense = tl.layers.Dense(n_units=1)(rnn)
        outputs = tl.layers.Reshape([-1, self.num_steps])(dense)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn, rnn_fw_state[0], rnn_bw_state[0]])
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()
        assert rnnlayer.is_train

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y, r, rfw, rbw = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y2)

            self.assertEqual(
                r.get_shape().as_list(), [self.batch_size * self.num_steps, self.hidden_size + self.hidden_size + 1]
            )
            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_recurrent.py" startline="301" endline="334" pcid="452">
    def test_basic_birnn_lstmcell(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.BiRNN(
            fw_cell=tf.keras.layers.LSTMCell(units=self.hidden_size, dropout=0.1),
            bw_cell=tf.keras.layers.LSTMCell(units=self.hidden_size + 1,
                                             dropout=0.1), return_seq_2d=False, return_last_state=True
        )
        rnn, rnn_fw_state, rnn_bw_state = rnnlayer(inputs)
        din = tl.layers.Reshape([-1, self.hidden_size + self.hidden_size + 1])(rnn)
        dense = tl.layers.Dense(n_units=1)(din)
        outputs = tl.layers.Reshape([-1, self.num_steps])(dense)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn, rnn_fw_state[0], rnn_bw_state[0]])
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()
        assert rnnlayer.is_train

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y, r, rfw, rbw = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y2)

            self.assertEqual(
                r.get_shape().as_list(), [self.batch_size, self.num_steps, self.hidden_size + self.hidden_size + 1]
            )
            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</source>
</class>

<class classid="18" nclones="2" nlines="27" similarity="75">
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_recurrent.py" startline="371" endline="404" pcid="456">
    def test_stack_simplernn(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer1 = tl.layers.RNN(
            cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, dropout=0.1), return_last_output=False,
            return_seq_2d=False, return_last_state=False
        )
        rnn1 = rnnlayer1(inputs)
        rnnlayer2 = tl.layers.RNN(
            cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, dropout=0.1), return_last_output=True,
            return_seq_2d=False, return_last_state=False
        )
        rnn2 = rnnlayer2(rnn1)
        outputs = tl.layers.Dense(n_units=1)(rnn2)
        rnn_model = tl.models.Model(inputs=inputs, outputs=outputs)
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()
        assert rnnlayer1.is_train
        assert rnnlayer2.is_train

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_recurrent.py" startline="405" endline="441" pcid="457">
    def test_stack_birnn_simplernncell(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.BiRNN(
            fw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, dropout=0.1),
            bw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size + 1,
                                                  dropout=0.1), return_seq_2d=False, return_last_state=False
        )
        rnn = rnnlayer(inputs)
        rnnlayer2 = tl.layers.BiRNN(
            fw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, dropout=0.1),
            bw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size + 1,
                                                  dropout=0.1), return_seq_2d=True, return_last_state=False
        )
        rnn2 = rnnlayer2(rnn)
        dense = tl.layers.Dense(n_units=1)(rnn2)
        outputs = tl.layers.Reshape([-1, self.num_steps])(dense)
        rnn_model = tl.models.Model(inputs=inputs, outputs=outputs)
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()
        assert rnnlayer.is_train
        assert rnnlayer2.is_train

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y2)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</source>
</class>

<class classid="19" nclones="4" nlines="19" similarity="85">
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_recurrent.py" startline="442" endline="467" pcid="458">
    def test_basic_simplernn_dropout_1(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.RNN(
            cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, dropout=0.5), return_last_output=True,
            return_seq_2d=False, return_last_state=False
        )
        rnn = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn])
        print(rnn_model)

        rnn_model.train()
        assert rnnlayer.is_train

        pred_y, rnn_1 = rnn_model(self.data_x)
        pred_y, rnn_2 = rnn_model(self.data_x)
        self.assertFalse(np.allclose(rnn_1, rnn_2))

        rnn_model.eval()
        assert not rnnlayer.is_train

        pred_y_1, rnn_1 = rnn_model(self.data_x)
        pred_y_2, rnn_2 = rnn_model(self.data_x)
        self.assertTrue(np.allclose(rnn_1, rnn_2))

</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_recurrent.py" startline="468" endline="493" pcid="459">
    def test_basic_simplernn_dropout_2(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.RNN(
            cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, recurrent_dropout=0.5), return_last_output=True,
            return_seq_2d=False, return_last_state=False
        )
        rnn = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn])
        print(rnn_model)

        rnn_model.train()
        assert rnnlayer.is_train

        pred_y, rnn_1 = rnn_model(self.data_x)
        pred_y, rnn_2 = rnn_model(self.data_x)
        self.assertFalse(np.allclose(rnn_1, rnn_2))

        rnn_model.eval()
        assert not rnnlayer.is_train

        pred_y_1, rnn_1 = rnn_model(self.data_x)
        pred_y_2, rnn_2 = rnn_model(self.data_x)
        self.assertTrue(np.allclose(rnn_1, rnn_2))

</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_recurrent.py" startline="521" endline="547" pcid="461">
    def test_basic_birnn_simplernn_dropout_2(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.BiRNN(
            fw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, recurrent_dropout=0.5),
            bw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size,
                                                  recurrent_dropout=0.5), return_seq_2d=True, return_last_state=False
        )
        rnn = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn])
        print(rnn_model)

        rnn_model.train()
        assert rnnlayer.is_train

        pred_y, rnn_1 = rnn_model(self.data_x)
        pred_y, rnn_2 = rnn_model(self.data_x)
        self.assertFalse(np.allclose(rnn_1, rnn_2))

        rnn_model.eval()
        assert not rnnlayer.is_train

        pred_y_1, rnn_1 = rnn_model(self.data_x)
        pred_y_2, rnn_2 = rnn_model(self.data_x)
        self.assertTrue(np.allclose(rnn_1, rnn_2))

</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_recurrent.py" startline="494" endline="520" pcid="460">
    def test_basic_birnn_simplernn_dropout_1(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.BiRNN(
            fw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, dropout=0.5),
            bw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size,
                                                  dropout=0.5), return_seq_2d=True, return_last_state=False
        )
        rnn = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn])
        print(rnn_model)

        rnn_model.train()
        assert rnnlayer.is_train

        pred_y, rnn_1 = rnn_model(self.data_x)
        pred_y, rnn_2 = rnn_model(self.data_x)
        self.assertFalse(np.allclose(rnn_1, rnn_2))

        rnn_model.eval()
        assert not rnnlayer.is_train

        pred_y_1, rnn_1 = rnn_model(self.data_x)
        pred_y_2, rnn_2 = rnn_model(self.data_x)
        self.assertTrue(np.allclose(rnn_1, rnn_2))

</source>
</class>

<class classid="20" nclones="6" nlines="15" similarity="70">
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_activation.py" startline="27" endline="45" pcid="476">
    def test_prelu_1(self):
        inputs = tl.layers.Input([10, 5])
        prelulayer = tl.layers.PRelu(channel_shared=True)
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data.shape)
        for i in range(len(gt)):
            for j in range(len(gt[i])):
                if self.data[i][j] >= 0:
                    gt[i][j] = self.data[i][j]
                else:
                    gt[i][j] = prelulayer.alpha_var_constrained.numpy() * self.data[i][j]

        self.assertTrue(np.array_equal(out.numpy(), gt))

</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_activation.py" startline="106" endline="126" pcid="480">
    def test_prelu6_2(self):
        inputs = tl.layers.Input([10, 5])
        prelulayer = tl.layers.PRelu6(in_channels=5)
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data.shape)
        for i in range(len(gt)):
            for j in range(len(gt[i])):
                if self.data[i][j] >= 0 and self.data[i][j] <= 6:
                    gt[i][j] = self.data[i][j]
                elif self.data[i][j] > 6:
                    gt[i][j] = 6
                else:
                    gt[i][j] = prelulayer.alpha_var_constrained.numpy()[j] * self.data[i][j]

        self.assertTrue(np.array_equal(out.numpy(), gt))

</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_activation.py" startline="170" endline="190" pcid="483">
    def test_ptrelu6_2(self):
        inputs = tl.layers.Input([10, 5])
        prelulayer = tl.layers.PTRelu6(in_channels=5)
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data.shape)
        for i in range(len(gt)):
            for j in range(len(gt[i])):
                if self.data[i][j] >= 0 and self.data[i][j] <= 6:
                    gt[i][j] = self.data[i][j]
                elif self.data[i][j] > 6:
                    gt[i][j] = 6 + prelulayer.alpha_high_constrained.numpy()[j] * (self.data[i][j] - 6)
                else:
                    gt[i][j] = prelulayer.alpha_low_constrained.numpy()[j] * self.data[i][j]

        self.assertTrue(np.allclose(out.numpy(), gt))

</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_activation.py" startline="149" endline="169" pcid="482">
    def test_ptrelu6_1(self):
        inputs = tl.layers.Input([10, 5])
        prelulayer = tl.layers.PTRelu6(channel_shared=True)
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data.shape)
        for i in range(len(gt)):
            for j in range(len(gt[i])):
                if self.data[i][j] >= 0 and self.data[i][j] <= 6:
                    gt[i][j] = self.data[i][j]
                elif self.data[i][j] > 6:
                    gt[i][j] = 6 + prelulayer.alpha_high_constrained.numpy() * (self.data[i][j] - 6)
                else:
                    gt[i][j] = prelulayer.alpha_low_constrained.numpy() * self.data[i][j]

        self.assertTrue(np.array_equal(out.numpy(), gt))

</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_activation.py" startline="46" endline="64" pcid="477">
    def test_prelu_2(self):
        inputs = tl.layers.Input([10, 5])
        prelulayer = tl.layers.PRelu(in_channels=5)
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data.shape)
        for i in range(len(gt)):
            for j in range(len(gt[i])):
                if self.data[i][j] >= 0:
                    gt[i][j] = self.data[i][j]
                else:
                    gt[i][j] = prelulayer.alpha_var_constrained.numpy()[j] * self.data[i][j]

        self.assertTrue(np.array_equal(out.numpy(), gt))

</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_activation.py" startline="85" endline="105" pcid="479">
    def test_prelu6_1(self):
        inputs = tl.layers.Input([10, 5])
        prelulayer = tl.layers.PRelu6(channel_shared=True)
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data.shape)
        for i in range(len(gt)):
            for j in range(len(gt[i])):
                if self.data[i][j] >= 0 and self.data[i][j] <= 6:
                    gt[i][j] = self.data[i][j]
                elif self.data[i][j] > 6:
                    gt[i][j] = 6
                else:
                    gt[i][j] = prelulayer.alpha_var_constrained.numpy() * self.data[i][j]

        self.assertTrue(np.array_equal(out.numpy(), gt))

</source>
</class>

<class classid="21" nclones="3" nlines="17" similarity="77">
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_activation.py" startline="65" endline="84" pcid="478">
    def test_prelu_3(self):
        inputs = tl.layers.Input([10, 10, 5])
        prelulayer = tl.layers.PRelu(in_channels=5)
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data2, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data2.shape)
        for i in range(len(gt)):
            for k in range(len(gt[i])):
                for j in range(len(gt[i][k])):
                    if self.data2[i][k][j] >= 0:
                        gt[i][k][j] = self.data2[i][k][j]
                    else:
                        gt[i][k][j] = prelulayer.alpha_var_constrained.numpy()[j] * self.data2[i][k][j]

        self.assertTrue(np.array_equal(out.numpy(), gt))

</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_activation.py" startline="127" endline="148" pcid="481">
    def test_prelu6_3(self):
        inputs = tl.layers.Input([10, 10, 5])
        prelulayer = tl.layers.PRelu6(in_channels=5)
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data2, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data2.shape)
        for i in range(len(gt)):
            for k in range(len(gt[i])):
                for j in range(len(gt[i][k])):
                    if self.data2[i][k][j] >= 0 and self.data2[i][k][j] <= 6:
                        gt[i][k][j] = self.data2[i][k][j]
                    elif self.data2[i][k][j] > 6:
                        gt[i][k][j] = 6
                    else:
                        gt[i][k][j] = prelulayer.alpha_var_constrained.numpy()[j] * self.data2[i][k][j]

        self.assertTrue(np.array_equal(out.numpy(), gt))

</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_activation.py" startline="191" endline="213" pcid="484">
    def test_ptrelu6_3(self):
        inputs = tl.layers.Input([3, 2, 5])
        prelulayer = tl.layers.PTRelu6()
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data2, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data2.shape)
        for i in range(len(gt)):
            for k in range(len(gt[i])):
                for j in range(len(gt[i][k])):
                    if self.data2[i][k][j] >= 0 and self.data2[i][k][j] <= 6:
                        gt[i][k][j] = self.data2[i][k][j]
                    elif self.data2[i][k][j] > 6:
                        gt[i][k][j] = 6 + prelulayer.alpha_high_constrained.numpy()[j] * (self.data2[i][k][j] - 6)
                    else:
                        gt[i][k][j] = prelulayer.alpha_low_constrained.numpy()[j] * self.data2[i][k][j]

        self.assertTrue(np.allclose(out.numpy(), gt))


</source>
</class>

<class classid="22" nclones="5" nlines="17" similarity="88">
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_dense.py" startline="20" endline="41" pcid="509">
    def setUpClass(cls):
        print("-" * 20, "Layer_BinaryDense_Test", "-" * 20)
        cls.batch_size = 4
        cls.inputs_shape = [cls.batch_size, 10]

        cls.ni = Input(cls.inputs_shape, name='input_layer')
        cls.layer1 = BinaryDense(n_units=5)
        nn = cls.layer1(cls.ni)
        cls.layer1._nodes_fixed = True
        cls.M = Model(inputs=cls.ni, outputs=nn)

        cls.layer2 = BinaryDense(n_units=5, in_channels=10)
        cls.layer2._nodes_fixed = True

        cls.inputs = tf.ones((cls.inputs_shape))
        cls.n1 = cls.layer1(cls.inputs)
        cls.n2 = cls.layer2(cls.inputs)
        cls.n3 = cls.M(cls.inputs, is_train=True)

        print(cls.layer1)
        print(cls.layer2)

</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_dense.py" startline="78" endline="99" pcid="515">
    def setUpClass(cls):
        print("-" * 20, "Layer_DorefaDense_Test", "-" * 20)
        cls.batch_size = 4
        cls.inputs_shape = [cls.batch_size, 10]

        cls.ni = Input(cls.inputs_shape, name='input_layer')
        cls.layer1 = DorefaDense(n_units=5)
        nn = cls.layer1(cls.ni)
        cls.layer1._nodes_fixed = True
        cls.M = Model(inputs=cls.ni, outputs=nn)

        cls.layer2 = DorefaDense(n_units=5, in_channels=10)
        cls.layer2._nodes_fixed = True

        cls.inputs = tf.ones((cls.inputs_shape))
        cls.n1 = cls.layer1(cls.inputs)
        cls.n2 = cls.layer2(cls.inputs)
        cls.n3 = cls.M(cls.inputs, is_train=True)

        print(cls.layer1)
        print(cls.layer2)

</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_dense.py" startline="136" endline="157" pcid="521">
    def setUpClass(cls):
        print("-" * 20, "Layer_DropconnectDense_Test", "-" * 20)
        cls.batch_size = 4
        cls.inputs_shape = [cls.batch_size, 10]

        cls.ni = Input(cls.inputs_shape, name='input_layer')
        cls.layer1 = DropconnectDense(n_units=5, keep=1.0)
        nn = cls.layer1(cls.ni)
        cls.layer1._nodes_fixed = True
        cls.M = Model(inputs=cls.ni, outputs=nn)

        cls.layer2 = DropconnectDense(n_units=5, in_channels=10, keep=0.01)
        cls.layer2._nodes_fixed = True

        cls.inputs = tf.ones((cls.inputs_shape))
        cls.n1 = cls.layer1(cls.inputs)
        cls.n2 = cls.layer2(cls.inputs)
        cls.n3 = cls.M(cls.inputs, is_train=True)

        print(cls.layer1)
        print(cls.layer2)

</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_dense.py" startline="249" endline="270" pcid="533">
    def setUpClass(cls):
        print("-" * 20, "Layer_BinaryDense_Test", "-" * 20)
        cls.batch_size = 4
        cls.inputs_shape = [cls.batch_size, 10]

        cls.ni = Input(cls.inputs_shape, name='input_layer')
        cls.layer1 = TernaryDense(n_units=5)
        nn = cls.layer1(cls.ni)
        cls.layer1._nodes_fixed = True
        cls.M = Model(inputs=cls.ni, outputs=nn)

        cls.layer2 = TernaryDense(n_units=5, in_channels=10)
        cls.layer2._nodes_fixed = True

        cls.inputs = tf.ones((cls.inputs_shape))
        cls.n1 = cls.layer1(cls.inputs)
        cls.n2 = cls.layer2(cls.inputs)
        cls.n3 = cls.M(cls.inputs, is_train=True)

        print(cls.layer1)
        print(cls.layer2)

</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_dense.py" startline="194" endline="215" pcid="527">
    def setUpClass(cls):
        print("-" * 20, "Layer_QuanDense_Test", "-" * 20)
        cls.batch_size = 4
        cls.inputs_shape = [cls.batch_size, 10]

        cls.ni = Input(cls.inputs_shape, name='input_layer')
        cls.layer1 = QuanDense(n_units=5)
        nn = cls.layer1(cls.ni)
        cls.layer1._nodes_fixed = True
        cls.M = Model(inputs=cls.ni, outputs=nn)

        cls.layer2 = QuanDense(n_units=5, in_channels=10)
        cls.layer2._nodes_fixed = True

        cls.inputs = tf.random.uniform((cls.inputs_shape))
        cls.n1 = cls.layer1(cls.inputs)
        cls.n2 = cls.layer2(cls.inputs)
        cls.n3 = cls.M(cls.inputs, is_train=True)

        print(cls.layer1)
        print(cls.layer2)

</source>
</class>

<class classid="23" nclones="5" nlines="14" similarity="85">
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_dense.py" startline="58" endline="74" pcid="514">
    def test_exception(self):
        try:
            layer = BinaryDense(n_units=5)
            inputs = Input([4, 10, 5], name='ill_inputs')
            out = layer(inputs)
            self.fail('ill inputs')
        except Exception as e:
            print(e)

        try:
            layer = BinaryDense(n_units=5, use_gemm=True)
            out = layer(self.ni)
            self.fail('use gemm')
        except Exception as e:
            print(e)


</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_dense.py" startline="287" endline="303" pcid="538">
    def test_exception(self):
        try:
            layer = TernaryDense(n_units=5)
            inputs = Input([4, 10, 5], name='ill_inputs')
            out = layer(inputs)
            self.fail('ill inputs')
        except Exception as e:
            print(e)

        try:
            layer = TernaryDense(n_units=5, use_gemm=True)
            out = layer(self.ni)
            self.fail('use gemm')
        except Exception as e:
            print(e)


</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_dense.py" startline="174" endline="190" pcid="526">
    def test_exception(self):
        try:
            layer = DropconnectDense(n_units=5)
            inputs = Input([4, 10, 5], name='ill_inputs')
            out = layer(inputs)
            self.fail('ill inputs')
        except Exception as e:
            print(e)

        try:
            layer = DropconnectDense(n_units=5, keep=0.0)
            self.fail('keep no elements')
        except Exception as e:
            self.assertIsInstance(e, ValueError)
            print(e)


</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_dense.py" startline="229" endline="245" pcid="532">
    def test_exception(self):
        try:
            layer = QuanDense(n_units=5)
            inputs = Input([4, 10, 5], name='ill_inputs')
            out = layer(inputs)
            self.fail('ill inputs')
        except Exception as e:
            print(e)

        try:
            layer = QuanDense(n_units=5, use_gemm=True)
            out = layer(self.ni)
            self.fail('use gemm')
        except Exception as e:
            print(e)


</source>
<source file="systems/TensorLayer-2.0.2/tests/layers/test_layers_dense.py" startline="116" endline="132" pcid="520">
    def test_exception(self):
        try:
            layer = DorefaDense(n_units=5)
            inputs = Input([4, 10, 5], name='ill_inputs')
            out = layer(inputs)
            self.fail('ill inputs')
        except Exception as e:
            print(e)

        try:
            layer = DorefaDense(n_units=5, use_gemm=True)
            out = layer(self.ni)
            self.fail('use gemm')
        except Exception as e:
            print(e)


</source>
</class>

<class classid="24" nclones="2" nlines="10" similarity="100">
<source file="systems/TensorLayer-2.0.2/examples/spatial_transformer_network/tutorial_spatial_transformer_network_dynamic.py" startline="14" endline="34" pcid="559">

def pad_distort_im_fn(x):
    """ Zero pads an image to 40x40, and distort it.

    Examples
    ---------
    x = pad_distort_im_fn(X_train[0])
    print(x, x.shape, x.max())
    tl.vis.save_image(x, '_xd.png')
    tl.vis.save_image(X_train[0], '_x.png')
    """
    b = np.zeros((40, 40, 1), dtype=np.float32)
    o = int((40 - 28) / 2)
    b[o:o + 28, o:o + 28] = x
    x = b
    x = tl.prepro.rotation(x, rg=30, is_random=True, fill_mode='constant')
    x = tl.prepro.shear(x, 0.05, is_random=True, fill_mode='constant')
    x = tl.prepro.shift(x, wrg=0.25, hrg=0.25, is_random=True, fill_mode='constant')
    x = tl.prepro.zoom(x, zoom_range=(0.95, 1.05))
    return x

</source>
<source file="systems/TensorLayer-2.0.2/examples/spatial_transformer_network/tutorial_spatial_transformer_network_static.py" startline="13" endline="33" pcid="563">

def pad_distort_im_fn(x):
    """ Zero pads an image to 40x40, and distort it.

    Examples
    ---------
    x = pad_distort_im_fn(X_train[0])
    print(x, x.shape, x.max())
    tl.vis.save_image(x, '_xd.png')
    tl.vis.save_image(X_train[0], '_x.png')
    """
    b = np.zeros((40, 40, 1), dtype=np.float32)
    o = int((40 - 28) / 2)
    b[o:o + 28, o:o + 28] = x
    x = b
    x = tl.prepro.rotation(x, rg=30, is_random=True, fill_mode='constant')
    x = tl.prepro.shear(x, 0.05, is_random=True, fill_mode='constant')
    x = tl.prepro.shift(x, wrg=0.25, hrg=0.25, is_random=True, fill_mode='constant')
    x = tl.prepro.zoom(x, zoom_range=(0.95, 1.05))
    return x

</source>
</class>

<class classid="25" nclones="2" nlines="39" similarity="100">
<source file="systems/TensorLayer-2.0.2/examples/text_generation/tutorial_generate_text.py" startline="42" endline="83" pcid="582">
def basic_clean_str(string):
    """Tokenization/string cleaning for a datasets."""
    string = re.sub(r"\n", " ", string)  # '\n'      --> ' '
    string = re.sub(r"\'s", " \'s", string)  # it's      --> it 's
    string = re.sub(r"\’s", " \'s", string)
    string = re.sub(r"\'ve", " have", string)  # they've   --> they have
    string = re.sub(r"\’ve", " have", string)
    string = re.sub(r"\'t", " not", string)  # can't     --> can not
    string = re.sub(r"\’t", " not", string)
    string = re.sub(r"\'re", " are", string)  # they're   --> they are
    string = re.sub(r"\’re", " are", string)
    string = re.sub(r"\'d", "", string)  # I'd (I had, I would) --> I
    string = re.sub(r"\’d", "", string)
    string = re.sub(r"\'ll", " will", string)  # I'll      --> I will
    string = re.sub(r"\’ll", " will", string)
    string = re.sub(r"\“", "  ", string)  # “a”       --> “ a ”
    string = re.sub(r"\”", "  ", string)
    string = re.sub(r"\"", "  ", string)  # "a"       --> " a "
    string = re.sub(r"\'", "  ", string)  # they'     --> they '
    string = re.sub(r"\’", "  ", string)  # they’     --> they ’
    string = re.sub(r"\.", " . ", string)  # they.     --> they .
    string = re.sub(r"\,", " , ", string)  # they,     --> they ,
    string = re.sub(r"\!", " ! ", string)
    string = re.sub(r"\-", "  ", string)  # "low-cost"--> lost cost
    string = re.sub(r"\(", "  ", string)  # (they)    --> ( they)
    string = re.sub(r"\)", "  ", string)  # ( they)   --> ( they )
    string = re.sub(r"\]", "  ", string)  # they]     --> they ]
    string = re.sub(r"\[", "  ", string)  # they[     --> they [
    string = re.sub(r"\?", "  ", string)  # they?     --> they ?
    string = re.sub(r"\>", "  ", string)  # they>     --> they >
    string = re.sub(r"\<", "  ", string)  # they<     --> they <
    string = re.sub(r"\=", "  ", string)  # easier=   --> easier =
    string = re.sub(r"\;", "  ", string)  # easier;   --> easier ;
    string = re.sub(r"\;", "  ", string)
    string = re.sub(r"\:", "  ", string)  # easier:   --> easier :
    string = re.sub(r"\"", "  ", string)  # easier"   --> easier "
    string = re.sub(r"\$", "  ", string)  # $380      --> $ 380
    string = re.sub(r"\_", "  ", string)  # _100     --> _ 100
    string = re.sub(r"\s{2,}", " ", string)  # Akara is    handsome --> Akara is handsome
    return string.strip().lower()  # lowercase


</source>
<source file="systems/TensorLayer-2.0.2/examples/text_generation/tutorial_generate_text.py" startline="84" endline="125" pcid="583">
def customized_clean_str(string):
    """Tokenization/string cleaning for a datasets."""
    string = re.sub(r"\n", " ", string)  # '\n'      --> ' '
    string = re.sub(r"\'s", " \'s", string)  # it's      --> it 's
    string = re.sub(r"\’s", " \'s", string)
    string = re.sub(r"\'ve", " have", string)  # they've   --> they have
    string = re.sub(r"\’ve", " have", string)
    string = re.sub(r"\'t", " not", string)  # can't     --> can not
    string = re.sub(r"\’t", " not", string)
    string = re.sub(r"\'re", " are", string)  # they're   --> they are
    string = re.sub(r"\’re", " are", string)
    string = re.sub(r"\'d", "", string)  # I'd (I had, I would) --> I
    string = re.sub(r"\’d", "", string)
    string = re.sub(r"\'ll", " will", string)  # I'll      --> I will
    string = re.sub(r"\’ll", " will", string)
    string = re.sub(r"\“", " “ ", string)  # “a”       --> “ a ”
    string = re.sub(r"\”", " ” ", string)
    string = re.sub(r"\"", " “ ", string)  # "a"       --> " a "
    string = re.sub(r"\'", " ' ", string)  # they'     --> they '
    string = re.sub(r"\’", " ' ", string)  # they’     --> they '
    string = re.sub(r"\.", " . ", string)  # they.     --> they .
    string = re.sub(r"\,", " , ", string)  # they,     --> they ,
    string = re.sub(r"\-", " ", string)  # "low-cost"--> lost cost
    string = re.sub(r"\(", " ( ", string)  # (they)    --> ( they)
    string = re.sub(r"\)", " ) ", string)  # ( they)   --> ( they )
    string = re.sub(r"\!", " ! ", string)  # they!     --> they !
    string = re.sub(r"\]", " ] ", string)  # they]     --> they ]
    string = re.sub(r"\[", " [ ", string)  # they[     --> they [
    string = re.sub(r"\?", " ? ", string)  # they?     --> they ?
    string = re.sub(r"\>", " > ", string)  # they>     --> they >
    string = re.sub(r"\<", " < ", string)  # they<     --> they <
    string = re.sub(r"\=", " = ", string)  # easier=   --> easier =
    string = re.sub(r"\;", " ; ", string)  # easier;   --> easier ;
    string = re.sub(r"\;", " ; ", string)
    string = re.sub(r"\:", " : ", string)  # easier:   --> easier :
    string = re.sub(r"\"", " \" ", string)  # easier"   --> easier "
    string = re.sub(r"\$", " $ ", string)  # $380      --> $ 380
    string = re.sub(r"\_", " _ ", string)  # _100     --> _ 100
    string = re.sub(r"\s{2,}", " ", string)  # Akara is    handsome --> Akara is handsome
    return string.strip().lower()  # lowercase


</source>
</class>

<class classid="26" nclones="2" nlines="17" similarity="76">
<source file="systems/TensorLayer-2.0.2/examples/basic_tutorials/tutorial_cifar10_cnn_static.py" startline="24" endline="48" pcid="591">
def get_model(inputs_shape):
    # self defined initialization
    W_init = tl.initializers.truncated_normal(stddev=5e-2)
    W_init2 = tl.initializers.truncated_normal(stddev=0.04)
    b_init2 = tl.initializers.constant(value=0.1)

    # build network
    ni = Input(inputs_shape)
    nn = Conv2d(64, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, W_init=W_init, b_init=None, name='conv1')(ni)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool1')(nn)
    nn = LocalResponseNorm(depth_radius=4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name="norm1")(nn)

    nn = Conv2d(64, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, W_init=W_init, b_init=None, name='conv2')(nn)
    nn = LocalResponseNorm(depth_radius=4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name="norm2")(nn)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool2')(nn)

    nn = Flatten(name='flatten')(nn)
    nn = Dense(384, act=tf.nn.relu, W_init=W_init2, b_init=b_init2, name='dense1relu')(nn)
    nn = Dense(192, act=tf.nn.relu, W_init=W_init2, b_init=b_init2, name='dense2relu')(nn)
    nn = Dense(10, act=None, W_init=W_init2, name='output')(nn)

    M = Model(inputs=ni, outputs=nn, name='cnn')
    return M


</source>
<source file="systems/TensorLayer-2.0.2/examples/basic_tutorials/tutorial_cifar10_cnn_static.py" startline="49" endline="74" pcid="592">
def get_model_batchnorm(inputs_shape):
    # self defined initialization
    W_init = tl.initializers.truncated_normal(stddev=5e-2)
    W_init2 = tl.initializers.truncated_normal(stddev=0.04)
    b_init2 = tl.initializers.constant(value=0.1)

    # build network
    ni = Input(inputs_shape)
    nn = Conv2d(64, (5, 5), (1, 1), padding='SAME', W_init=W_init, b_init=None, name='conv1')(ni)
    nn = BatchNorm(decay=0.99, act=tf.nn.relu, name='batch1')(nn)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool1')(nn)

    nn = Conv2d(64, (5, 5), (1, 1), padding='SAME', W_init=W_init, b_init=None, name='conv2')(nn)
    nn = BatchNorm(decay=0.99, act=tf.nn.relu, name='batch2')(nn)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool2')(nn)

    nn = Flatten(name='flatten')(nn)
    nn = Dense(384, act=tf.nn.relu, W_init=W_init2, b_init=b_init2, name='dense1relu')(nn)
    nn = Dense(192, act=tf.nn.relu, W_init=W_init2, b_init=b_init2, name='dense2relu')(nn)
    nn = Dense(10, act=None, W_init=W_init2, name='output')(nn)

    M = Model(inputs=ni, outputs=nn, name='cnn')
    return M


# get the network
</source>
</class>

<class classid="27" nclones="2" nlines="10" similarity="80">
<source file="systems/TensorLayer-2.0.2/examples/reinforcement_learning/tutorial_cartpole_ac.py" startline="78" endline="118" pcid="615">
    def __init__(self, n_features, n_actions, lr=0.001):
            # self.sess = sess
            # self.s = tf.placeholder(tf.float32, [1, n_features], "state")
            # self.a = tf.placeholder(tf.int32, [None], "act")
            # self.td_error = tf.placeholder(tf.float32, [None], "td_error")  # TD_error

            # with tf.variable_scope('Actor'):  # Policy network
            #     n = InputLayer(self.s, name='in')
            #     n = DenseLayer(n, n_units=30, act=tf.nn.relu6, W_init=tf.random_uniform_initializer(0, 0.01), name='hidden')
            #     # n = DenseLayer(n, n_units=10, act=tf.nn.relu6, W_init=tf.random_uniform_initializer(0, 0.01), name='hidden2')
            #     n = DenseLayer(n, n_units=n_actions, name='Pi')

        def get_model(inputs_shape):
            ni = tl.layers.Input(inputs_shape, name='state')
            nn = tl.layers.Dense(n_units=30, act=tf.nn.relu6, W_init=tf.random_uniform_initializer(0, 0.01), name='hidden')(ni)
            nn = tl.layers.Dense(n_units=10, act=tf.nn.relu6, W_init=tf.random_uniform_initializer(0, 0.01), name='hidden2')(nn)
            nn = tl.layers.Dense(n_units=n_actions, name='actions')(nn)
            return tl.models.Model(inputs=ni, outputs=nn, name="Actor")
        self.model = get_model([1, n_features])
        self.model.train()
            # self.acts_logits = n.outputs
            # self.acts_prob = tf.nn.softmax(self.acts_logits)

            # Hao Dong
            # with tf.variable_scope('loss'):
            #     self.exp_v = tl.rein.cross_entropy_reward_loss(
            #         logits=self.acts_logits, actions=self.a, rewards=self.td_error, name='actor_weighted_loss'
            #     )

            # with tf.variable_scope('train'):
            #     self.train_op = tf.train.AdamOptimizer(lr).minimize(self.exp_v)
        self.optimizer = tf.train.AdamOptimizer(lr)
        # Morvan Zhou (the same)
        # with tf.variable_scope('exp_v'):
        #     # log_prob = tf.log(self.acts_prob[0, self.a[0]])
        #     # self.exp_v = tf.reduce_mean(log_prob * self.td_error[0])  # advantage (TD_error) guided loss
        #     self.exp_v = tl.rein.log_weight(probs=self.acts_prob[0, self.a[0]], weights=self.td_error)
        #
        # with tf.variable_scope('train'):
        #     self.train_op = tf.train.AdamOptimizer(lr).minimize(-self.exp_v)  # minimize(-exp_v) = maximize(exp_v)

</source>
<source file="systems/TensorLayer-2.0.2/examples/reinforcement_learning/tutorial_cartpole_ac.py" startline="144" endline="171" pcid="620">
    def __init__(self, n_features, lr=0.01):
            # self.sess = sess
            # self.s = tf.placeholder(tf.float32, [1, n_features], "state")
            # self.v_ = tf.placeholder(tf.float32, [1, 1], "v_next")
            # self.r = tf.placeholder(tf.float32, None, 'r')

            # with tf.variable_scope('Critic'):  # we use Value-function here, not Action-Value-function
            #     n = InputLayer(self.s, name='in')
            #     n = DenseLayer(n, n_units=30, act=tf.nn.relu6, W_init=tf.random_uniform_initializer(0, 0.01), name='hidden')
            #     # n = DenseLayer(n, n_units=5, act=tf.nn.relu, W_init=tf.random_uniform_initializer(0, 0.01), name='hidden2')
            #     n = DenseLayer(n, n_units=1, act=None, name='V')
            #     self.v = n.outputs
        def get_model(inputs_shape):
            ni = tl.layers.Input(inputs_shape, name='state')
            nn = tl.layers.Dense(n_units=30, act=tf.nn.relu6, W_init=tf.random_uniform_initializer(0, 0.01), name='hidden')(ni)
            nn = tl.layers.Dense(n_units=5, act=tf.nn.relu, W_init=tf.random_uniform_initializer(0, 0.01), name='hidden2')(nn)
            nn = tl.layers.Dense(n_units=1, act=None, name='value')(nn)
            return tl.models.Model(inputs=ni, outputs=nn, name="Critic")
        self.model = get_model([1, n_features])
        self.model.train()
            # with tf.variable_scope('squared_TD_error'):
            #     # TD_error = r + lambd * V(newS) - V(S)
            #     self.td_error = self.r + LAMBDA * self.v_ - self.v
            #     self.loss = tf.square(self.td_error)
            # with tf.variable_scope('train'):
                # self.train_op = tf.train.AdamOptimizer(lr).minimize(self.loss)
        self.optimizer = tf.train.AdamOptimizer(lr)

</source>
</class>

<class classid="28" nclones="3" nlines="17" similarity="100">
<source file="systems/TensorLayer-2.0.2/examples/quantized_net/tutorial_ternaryweight_cifar10_tfrecord.py" startline="64" endline="94" pcid="681">
def data_to_tfrecord(images, labels, filename):
    """Save data into TFRecord."""
    if os.path.isfile(filename):
        print("%s exists" % filename)
        return
    print("Converting data into %s ..." % filename)
    # cwd = os.getcwd()
    writer = tf.python_io.TFRecordWriter(filename)
    for index, img in enumerate(images):
        img_raw = img.tobytes()
        # Visualize a image
        # tl.visualize.frame(np.asarray(img, dtype=np.uint8), second=1, saveable=False, name='frame', fig_idx=1236)
        label = int(labels[index])
        # print(label)
        # Convert the bytes back to image as follow:
        # image = Image.frombytes('RGB', (32, 32), img_raw)
        # image = np.fromstring(img_raw, np.float32)
        # image = image.reshape([32, 32, 3])
        # tl.visualize.frame(np.asarray(image, dtype=np.uint8), second=1, saveable=False, name='frame', fig_idx=1236)
        example = tf.train.Example(
            features=tf.train.Features(
                feature={
                    "label": tf.train.Feature(int64_list=tf.train.Int64List(value=[label])),
                    'img_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])),
                }
            )
        )
        writer.write(example.SerializeToString())  # Serialize To String
    writer.close()


</source>
<source file="systems/TensorLayer-2.0.2/examples/quantized_net/tutorial_dorefanet_cifar10_tfrecord.py" startline="65" endline="95" pcid="686">
def data_to_tfrecord(images, labels, filename):
    """Save data into TFRecord."""
    if os.path.isfile(filename):
        print("%s exists" % filename)
        return
    print("Converting data into %s ..." % filename)
    # cwd = os.getcwd()
    writer = tf.python_io.TFRecordWriter(filename)
    for index, img in enumerate(images):
        img_raw = img.tobytes()
        # Visualize a image
        # tl.visualize.frame(np.asarray(img, dtype=np.uint8), second=1, saveable=False, name='frame', fig_idx=1236)
        label = int(labels[index])
        # print(label)
        # Convert the bytes back to image as follow:
        # image = Image.frombytes('RGB', (32, 32), img_raw)
        # image = np.fromstring(img_raw, np.float32)
        # image = image.reshape([32, 32, 3])
        # tl.visualize.frame(np.asarray(image, dtype=np.uint8), second=1, saveable=False, name='frame', fig_idx=1236)
        example = tf.train.Example(
            features=tf.train.Features(
                feature={
                    "label": tf.train.Feature(int64_list=tf.train.Int64List(value=[label])),
                    'img_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])),
                }
            )
        )
        writer.write(example.SerializeToString())  # Serialize To String
    writer.close()


</source>
<source file="systems/TensorLayer-2.0.2/examples/quantized_net/tutorial_binarynet_cifar10_tfrecord.py" startline="65" endline="95" pcid="691">
def data_to_tfrecord(images, labels, filename):
    """Save data into TFRecord."""
    if os.path.isfile(filename):
        print("%s exists" % filename)
        return
    print("Converting data into %s ..." % filename)
    # cwd = os.getcwd()
    writer = tf.python_io.TFRecordWriter(filename)
    for index, img in enumerate(images):
        img_raw = img.tobytes()
        # Visualize a image
        # tl.visualize.frame(np.asarray(img, dtype=np.uint8), second=1, saveable=False, name='frame', fig_idx=1236)
        label = int(labels[index])
        # print(label)
        # Convert the bytes back to image as follow:
        # image = Image.frombytes('RGB', (32, 32), img_raw)
        # image = np.fromstring(img_raw, np.float32)
        # image = image.reshape([32, 32, 3])
        # tl.visualize.frame(np.asarray(image, dtype=np.uint8), second=1, saveable=False, name='frame', fig_idx=1236)
        example = tf.train.Example(
            features=tf.train.Features(
                feature={
                    "label": tf.train.Feature(int64_list=tf.train.Int64List(value=[label])),
                    'img_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])),
                }
            )
        )
        writer.write(example.SerializeToString())  # Serialize To String
    writer.close()


</source>
</class>

<class classid="29" nclones="3" nlines="24" similarity="100">
<source file="systems/TensorLayer-2.0.2/examples/quantized_net/tutorial_ternaryweight_cifar10_tfrecord.py" startline="95" endline="140" pcid="682">
def read_and_decode(filename, is_train=None):
    """Return tensor to read from TFRecord."""
    filename_queue = tf.train.string_input_producer([filename])
    reader = tf.TFRecordReader()
    _, serialized_example = reader.read(filename_queue)
    features = tf.parse_single_example(
        serialized_example, features={
            'label': tf.FixedLenFeature([], tf.int64),
            'img_raw': tf.FixedLenFeature([], tf.string),
        }
    )
    # You can do more image distortion here for training data
    img = tf.decode_raw(features['img_raw'], tf.float32)
    img = tf.reshape(img, [32, 32, 3])
    # img = tf.cast(img, tf.float32) #* (1. / 255) - 0.5
    if is_train ==True:
        # 1. Randomly crop a [height, width] section of the image.
        img = tf.random_crop(img, [24, 24, 3])

        # 2. Randomly flip the image horizontally.
        img = tf.image.random_flip_left_right(img)

        # 3. Randomly change brightness.
        img = tf.image.random_brightness(img, max_delta=63)

        # 4. Randomly change contrast.
        img = tf.image.random_contrast(img, lower=0.2, upper=1.8)

        # 5. Subtract off the mean and divide by the variance of the pixels.
        img = tf.image.per_image_standardization(img)

    elif is_train == False:
        # 1. Crop the central [height, width] of the image.
        img = tf.image.resize_image_with_crop_or_pad(img, 24, 24)

        # 2. Subtract off the mean and divide by the variance of the pixels.
        img = tf.image.per_image_standardization(img)

    elif is_train == None:
        img = img

    label = tf.cast(features['label'], tf.int32)
    return img, label


# Save data into TFRecord files
</source>
<source file="systems/TensorLayer-2.0.2/examples/quantized_net/tutorial_dorefanet_cifar10_tfrecord.py" startline="96" endline="141" pcid="687">
def read_and_decode(filename, is_train=None):
    """Return tensor to read from TFRecord."""
    filename_queue = tf.train.string_input_producer([filename])
    reader = tf.TFRecordReader()
    _, serialized_example = reader.read(filename_queue)
    features = tf.parse_single_example(
        serialized_example, features={
            'label': tf.FixedLenFeature([], tf.int64),
            'img_raw': tf.FixedLenFeature([], tf.string),
        }
    )
    # You can do more image distortion here for training data
    img = tf.decode_raw(features['img_raw'], tf.float32)
    img = tf.reshape(img, [32, 32, 3])
    # img = tf.cast(img, tf.float32) #* (1. / 255) - 0.5
    if is_train ==True:
        # 1. Randomly crop a [height, width] section of the image.
        img = tf.random_crop(img, [24, 24, 3])

        # 2. Randomly flip the image horizontally.
        img = tf.image.random_flip_left_right(img)

        # 3. Randomly change brightness.
        img = tf.image.random_brightness(img, max_delta=63)

        # 4. Randomly change contrast.
        img = tf.image.random_contrast(img, lower=0.2, upper=1.8)

        # 5. Subtract off the mean and divide by the variance of the pixels.
        img = tf.image.per_image_standardization(img)

    elif is_train == False:
        # 1. Crop the central [height, width] of the image.
        img = tf.image.resize_image_with_crop_or_pad(img, 24, 24)

        # 2. Subtract off the mean and divide by the variance of the pixels.
        img = tf.image.per_image_standardization(img)

    elif is_train == None:
        img = img

    label = tf.cast(features['label'], tf.int32)
    return img, label


# Save data into TFRecord files
</source>
<source file="systems/TensorLayer-2.0.2/examples/quantized_net/tutorial_binarynet_cifar10_tfrecord.py" startline="96" endline="141" pcid="692">
def read_and_decode(filename, is_train=None):
    """Return tensor to read from TFRecord."""
    filename_queue = tf.train.string_input_producer([filename])
    reader = tf.TFRecordReader()
    _, serialized_example = reader.read(filename_queue)
    features = tf.parse_single_example(
        serialized_example, features={
            'label': tf.FixedLenFeature([], tf.int64),
            'img_raw': tf.FixedLenFeature([], tf.string),
        }
    )
    # You can do more image distortion here for training data
    img = tf.decode_raw(features['img_raw'], tf.float32)
    img = tf.reshape(img, [32, 32, 3])
    # img = tf.cast(img, tf.float32) #* (1. / 255) - 0.5
    if is_train ==True:
        # 1. Randomly crop a [height, width] section of the image.
        img = tf.random_crop(img, [24, 24, 3])

        # 2. Randomly flip the image horizontally.
        img = tf.image.random_flip_left_right(img)

        # 3. Randomly change brightness.
        img = tf.image.random_brightness(img, max_delta=63)

        # 4. Randomly change contrast.
        img = tf.image.random_contrast(img, lower=0.2, upper=1.8)

        # 5. Subtract off the mean and divide by the variance of the pixels.
        img = tf.image.per_image_standardization(img)

    elif is_train == False:
        # 1. Crop the central [height, width] of the image.
        img = tf.image.resize_image_with_crop_or_pad(img, 24, 24)

        # 2. Subtract off the mean and divide by the variance of the pixels.
        img = tf.image.per_image_standardization(img)

    elif is_train == None:
        img = img

    label = tf.cast(features['label'], tf.int32)
    return img, label


# Save data into TFRecord files
</source>
</class>

<class classid="30" nclones="3" nlines="22" similarity="86">
<source file="systems/TensorLayer-2.0.2/examples/quantized_net/tutorial_ternaryweight_cifar10_tfrecord.py" startline="162" endline="196" pcid="683">
    def model(x_crop, y_, reuse):
        """For more simplified CNN APIs, check tensorlayer.org."""
        with tf.variable_scope("model", reuse=reuse):
            net = tl.layers.InputLayer(x_crop, name='input')
            net = tl.layers.Conv2d(net, 64, (5, 5), (1, 1), act=tf.nn.relu, padding='SAME', name='cnn1')
            net = tl.layers.MaxPool2d(net, (3, 3), (2, 2), padding='SAME', name='pool1')
            net = tl.layers.LocalResponseNormLayer(net, 4, 1.0, 0.001 / 9.0, 0.75, name='norm1')
            net = tl.layers.TernaryConv2d(net, 64, (5, 5), (1, 1), act=tf.nn.relu, padding='SAME', name='cnn2')
            net = tl.layers.LocalResponseNormLayer(net, 4, 1.0, 0.001 / 9.0, 0.75, name='norm2')
            net = tl.layers.MaxPool2d(net, (3, 3), (2, 2), padding='SAME', name='pool2')
            net = tl.layers.FlattenLayer(net, name='flatten')
            net = tl.layers.TernaryDenseLayer(net, 384, act=tf.nn.relu, name='d1relu')
            net = tl.layers.TernaryDenseLayer(net, 192, act=tf.nn.relu, name='d2relu')
            net = tl.layers.DenseLayer(net, 10, act=None, name='output')
            y = net.outputs

            ce = tl.cost.cross_entropy(y, y_, name='cost')
            # L2 for the MLP, without this, the accuracy will be reduced by 15%.
            L2 = 0
            for p in tl.layers.get_variables_with_name('relu/W', True, True):
                L2 += tf.contrib.layers.l2_regularizer(0.004)(p)
            cost = ce + L2

            # correct_prediction = tf.equal(tf.argmax(tf.nn.softmax(y), 1), y_)
            correct_prediction = tf.equal(tf.cast(tf.argmax(y, 1), tf.int32), y_)
            acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

            return net, cost, acc

    # You can also use placeholder to feed_dict in data after using
    # val, l = sess.run([x_train_batch, y_train_batch]) to get the data
    # x_crop = tf.placeholder(tf.float32, shape=[batch_size, 24, 24, 3])
    # y_ = tf.placeholder(tf.int32, shape=[batch_size,])
    # cost, acc, network = model(x_crop, y_, None)

</source>
<source file="systems/TensorLayer-2.0.2/examples/quantized_net/tutorial_dorefanet_cifar10_tfrecord.py" startline="163" endline="197" pcid="688">
    def model(x_crop, y_, reuse):
        """For more simplified CNN APIs, check tensorlayer.org."""
        with tf.variable_scope("model", reuse=reuse):
            net = tl.layers.InputLayer(x_crop, name='input')
            net = tl.layers.Conv2d(net, 64, (5, 5), (1, 1), act=tf.nn.relu, padding='SAME', name='cnn1')
            net = tl.layers.MaxPool2d(net, (3, 3), (2, 2), padding='SAME', name='pool1')
            net = tl.layers.LocalResponseNormLayer(net, 4, 1.0, 0.001 / 9.0, 0.75, name='norm1')
            net = tl.layers.DorefaConv2d(net, 1, 3, 64, (5, 5), (1, 1), tf.nn.relu, padding='SAME', name='cnn2')
            net = tl.layers.LocalResponseNormLayer(net, 4, 1.0, 0.001 / 9.0, 0.75, name='norm2')
            net = tl.layers.MaxPool2d(net, (3, 3), (2, 2), padding='SAME', name='pool2')
            net = tl.layers.FlattenLayer(net, name='flatten')
            net = tl.layers.DorefaDenseLayer(net, 1, 3, 384, act=tf.nn.relu, name='d1relu')
            net = tl.layers.DorefaDenseLayer(net, 1, 3, 192, act=tf.nn.relu, name='d2relu')
            net = tl.layers.DenseLayer(net, 10, act=None, name='output')
            y = net.outputs

            ce = tl.cost.cross_entropy(y, y_, name='cost')
            # L2 for the MLP, without this, the accuracy will be reduced by 15%.
            L2 = 0
            for p in tl.layers.get_variables_with_name('relu/W', True, True):
                L2 += tf.contrib.layers.l2_regularizer(0.004)(p)
            cost = ce + L2

            # correct_prediction = tf.equal(tf.argmax(tf.nn.softmax(y), 1), y_)
            correct_prediction = tf.equal(tf.cast(tf.argmax(y, 1), tf.int32), y_)
            acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

            return net, cost, acc

    # You can also use placeholder to feed_dict in data after using
    # val, l = sess.run([x_train_batch, y_train_batch]) to get the data
    # x_crop = tf.placeholder(tf.float32, shape=[batch_size, 24, 24, 3])
    # y_ = tf.placeholder(tf.int32, shape=[batch_size,])
    # cost, acc, network = model(x_crop, y_, None)

</source>
<source file="systems/TensorLayer-2.0.2/examples/quantized_net/tutorial_binarynet_cifar10_tfrecord.py" startline="163" endline="201" pcid="693">
    def model(x_crop, y_, reuse):
        """For more simplified CNN APIs, check tensorlayer.org."""
        with tf.variable_scope("model", reuse=reuse):
            net = tl.layers.InputLayer(x_crop, name='input')
            net = tl.layers.Conv2d(net, 64, (5, 5), (1, 1), act=tf.nn.relu, padding='SAME', name='cnn1')
            net = tl.layers.SignLayer(net)
            net = tl.layers.MaxPool2d(net, (3, 3), (2, 2), padding='SAME', name='pool1')
            net = tl.layers.LocalResponseNormLayer(net, 4, 1.0, 0.001 / 9.0, 0.75, name='norm1')
            net = tl.layers.BinaryConv2d(net, 64, (5, 5), (1, 1), act=tf.nn.relu, padding='SAME', name='cnn2')
            net = tl.layers.LocalResponseNormLayer(net, 4, 1.0, 0.001 / 9.0, 0.75, name='norm2')
            net = tl.layers.MaxPool2d(net, (3, 3), (2, 2), padding='SAME', name='pool2')
            net = tl.layers.FlattenLayer(net, name='flatten')
            net = tl.layers.SignLayer(net)
            net = tl.layers.BinaryDenseLayer(net, 384, act=tf.nn.relu, name='d1relu')
            net = tl.layers.SignLayer(net)
            net = tl.layers.BinaryDenseLayer(net, 192, act=tf.nn.relu, name='d2relu')
            net = tl.layers.DenseLayer(net, 10, act=None, name='output')

            y = net.outputs

            ce = tl.cost.cross_entropy(y, y_, name='cost')
            # L2 for the MLP, without this, the accuracy will be reduced by 15%.
            L2 = 0
            for p in tl.layers.get_variables_with_name('relu/W', True, True):
                L2 += tf.contrib.layers.l2_regularizer(0.004)(p)
            cost = ce + L2

            # correct_prediction = tf.equal(tf.argmax(tf.nn.softmax(y), 1), y_)
            correct_prediction = tf.equal(tf.cast(tf.argmax(y, 1), tf.int32), y_)
            acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

            return net, cost, acc

    # You can also use placeholder to feed_dict in data after using
    # val, l = sess.run([x_train_batch, y_train_batch]) to get the data
    # x_crop = tf.placeholder(tf.float32, shape=[batch_size, 24, 24, 3])
    # y_ = tf.placeholder(tf.int32, shape=[batch_size,])
    # cost, acc, network = model(x_crop, y_, None)

</source>
</class>

<class classid="31" nclones="3" nlines="16" similarity="80">
<source file="systems/TensorLayer-2.0.2/examples/quantized_net/tutorial_ternaryweight_mnist_cnn.py" startline="24" endline="51" pcid="684">
def model(x, is_train=True, reuse=False):
    # In BNN, all the layers inputs are binary, with the exception of the first layer.
    # ref: https://github.com/itayhubara/BinaryNet.tf/blob/master/models/BNN_cifar10.py
    with tf.variable_scope("binarynet", reuse=reuse):
        net = tl.layers.InputLayer(x, name='input')
        net = tl.layers.TernaryConv2d(net, 32, (5, 5), (1, 1), padding='SAME', b_init=None, name='bcnn1')
        net = tl.layers.MaxPool2d(net, (2, 2), (2, 2), padding='SAME', name='pool1')
        net = tl.layers.BatchNormLayer(net, act=tl.act.htanh, is_train=is_train, name='bn1')

        # net = tl.layers.SignLayer(net)
        net = tl.layers.TernaryConv2d(net, 64, (5, 5), (1, 1), padding='SAME', b_init=None, name='bcnn2')
        net = tl.layers.MaxPool2d(net, (2, 2), (2, 2), padding='SAME', name='pool2')
        net = tl.layers.BatchNormLayer(net, act=tl.act.htanh, is_train=is_train, name='bn2')

        net = tl.layers.FlattenLayer(net)
        # net = tl.layers.DropoutLayer(net, 0.8, True, is_train, name='drop1')
        # net = tl.layers.SignLayer(net)
        net = tl.layers.TernaryDenseLayer(net, 256, b_init=None, name='dense')
        net = tl.layers.BatchNormLayer(net, act=tl.act.htanh, is_train=is_train, name='bn3')

        # net = tl.layers.DropoutLayer(net, 0.8, True, is_train, name='drop2')
        # net = tl.layers.SignLayer(net)
        net = tl.layers.TernaryDenseLayer(net, 10, b_init=None, name='bout')
        net = tl.layers.BatchNormLayer(net, is_train=is_train, name='bno')
    return net


# define inferences
</source>
<source file="systems/TensorLayer-2.0.2/examples/quantized_net/tutorial_binarynet_mnist_cnn.py" startline="24" endline="51" pcid="690">
def model(x, is_train=True, reuse=False):
    # In BNN, all the layers inputs are binary, with the exception of the first layer.
    # ref: https://github.com/itayhubara/BinaryNet.tf/blob/master/models/BNN_cifar10.py
    with tf.variable_scope("binarynet", reuse=reuse):
        net = tl.layers.InputLayer(x, name='input')
        net = tl.layers.BinaryConv2d(net, 32, (5, 5), (1, 1), padding='SAME', b_init=None, name='bcnn1')
        net = tl.layers.MaxPool2d(net, (2, 2), (2, 2), padding='SAME', name='pool1')
        net = tl.layers.BatchNormLayer(net, act=tl.act.htanh, is_train=is_train, name='bn1')

        net = tl.layers.SignLayer(net)
        net = tl.layers.BinaryConv2d(net, 64, (5, 5), (1, 1), padding='SAME', b_init=None, name='bcnn2')
        net = tl.layers.MaxPool2d(net, (2, 2), (2, 2), padding='SAME', name='pool2')
        net = tl.layers.BatchNormLayer(net, act=tl.act.htanh, is_train=is_train, name='bn2')

        net = tl.layers.FlattenLayer(net)
        # net = tl.layers.DropoutLayer(net, 0.8, True, is_train, name='drop1')
        net = tl.layers.SignLayer(net)
        net = tl.layers.BinaryDenseLayer(net, 256, b_init=None, name='dense')
        net = tl.layers.BatchNormLayer(net, act=tl.act.htanh, is_train=is_train, name='bn3')

        # net = tl.layers.DropoutLayer(net, 0.8, True, is_train, name='drop2')
        net = tl.layers.SignLayer(net)
        net = tl.layers.BinaryDenseLayer(net, 10, b_init=None, name='bout')
        net = tl.layers.BatchNormLayer(net, is_train=is_train, name='bno')
    return net


# define inferences
</source>
<source file="systems/TensorLayer-2.0.2/examples/quantized_net/tutorial_dorefanet_mnist_cnn.py" startline="24" endline="51" pcid="685">
def model(x, is_train=True, reuse=False):
    # In BNN, all the layers inputs are binary, with the exception of the first layer.
    # ref: https://github.com/itayhubara/BinaryNet.tf/blob/master/models/BNN_cifar10.py
    with tf.variable_scope("binarynet", reuse=reuse):
        net = tl.layers.InputLayer(x, name='input')
        net = tl.layers.DorefaConv2d(net, 1, 3, 32, (5, 5), (1, 1), padding='SAME', b_init=None, name='bcnn1')  #pylint: disable=bare-except
        net = tl.layers.MaxPool2d(net, (2, 2), (2, 2), padding='SAME', name='pool1')
        net = tl.layers.BatchNormLayer(net, act=tl.act.htanh, is_train=is_train, name='bn1')

        # net = tl.layers.SignLayer(net)
        net = tl.layers.DorefaConv2d(net, 1, 3, 64, (5, 5), (1, 1), padding='SAME', b_init=None, name='bcnn2')  #pylint: disable=bare-except
        net = tl.layers.MaxPool2d(net, (2, 2), (2, 2), padding='SAME', name='pool2')
        net = tl.layers.BatchNormLayer(net, act=tl.act.htanh, is_train=is_train, name='bn2')

        net = tl.layers.FlattenLayer(net)
        # net = tl.layers.DropoutLayer(net, 0.8, True, is_train, name='drop1')
        # net = tl.layers.SignLayer(net)
        net = tl.layers.DorefaDenseLayer(net, 1, 3, 256, b_init=None, name='dense')
        net = tl.layers.BatchNormLayer(net, act=tl.act.htanh, is_train=is_train, name='bn3')

        # net = tl.layers.DropoutLayer(net, 0.8, True, is_train, name='drop2')
        # net = tl.layers.SignLayer(net)
        net = tl.layers.DenseLayer(net, 10, b_init=None, name='bout')
        net = tl.layers.BatchNormLayer(net, is_train=is_train, name='bno')
    return net


# define inferences
</source>
</class>

<class classid="32" nclones="4" nlines="19" similarity="78">
<source file="systems/TensorLayer-2.0.2/tensorlayer/cost.py" startline="548" endline="595" pcid="797">
# Regularization Functions
def li_regularizer(scale, scope=None):
    """Li regularization removes the neurons of previous layer. The `i` represents `inputs`.
    Returns a function that can be used to apply group li regularization to weights.
    The implementation follows `TensorFlow contrib <https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/regularizers.py>`__.

    Parameters
    ----------
    scale : float
        A scalar multiplier `Tensor`. 0.0 disables the regularizer.
    scope: str
        An optional scope name for this function.

    Returns
    --------
    A function with signature `li(weights, name=None)` that apply Li regularization.

    Raises
    ------
    ValueError : if scale is outside of the range [0.0, 1.0] or if scale is not a float.

    """
    if isinstance(scale, numbers.Integral):
        raise ValueError('scale cannot be an integer: %s' % scale)
    if isinstance(scale, numbers.Real):
        if scale < 0.:
            raise ValueError('Setting a scale less than 0 on a regularizer: %g' % scale)
        if scale >= 1.:
            raise ValueError('Setting a scale greater than 1 on a regularizer: %g' % scale)
        if scale == 0.:
            logging.info('Scale of 0 disables regularizer.')
            return lambda _, name=None: None

    def li(weights):
        """Applies li regularization to weights."""
        with tf.name_scope('li_regularizer') as scope:
            my_scale = ops.convert_to_tensor(scale, dtype=weights.dtype.base_dtype, name='scale')
            # if tf.__version__ <= '0.12':
            #     standard_ops_fn = standard_ops.mul
            # else:
            standard_ops_fn = standard_ops.multiply
            return standard_ops_fn(
                my_scale, standard_ops.reduce_sum(standard_ops.sqrt(standard_ops.reduce_sum(tf.square(weights), 1))),
                name=scope
            )

    return li

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/cost.py" startline="596" endline="642" pcid="799">

def lo_regularizer(scale):
    """Lo regularization removes the neurons of current layer. The `o` represents `outputs`
    Returns a function that can be used to apply group lo regularization to weights.
    The implementation follows `TensorFlow contrib <https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/regularizers.py>`__.

    Parameters
    ----------
    scale : float
        A scalar multiplier `Tensor`. 0.0 disables the regularizer.

    Returns
    -------
    A function with signature `lo(weights, name=None)` that apply Lo regularization.

    Raises
    ------
    ValueError : If scale is outside of the range [0.0, 1.0] or if scale is not a float.

    """
    if isinstance(scale, numbers.Integral):
        raise ValueError('scale cannot be an integer: %s' % scale)

    if isinstance(scale, numbers.Real):
        if scale < 0.:
            raise ValueError('Setting a scale less than 0 on a regularizer: %g' % scale)
        if scale >= 1.:
            raise ValueError('Setting a scale greater than 1 on a regularizer: %g' % scale)
        if scale == 0.:
            logging.info('Scale of 0 disables regularizer.')
            return lambda _, name=None: None

    def lo(weights, name='lo_regularizer'):
        """Applies group column regularization to weights."""
        with tf.name_scope(name) as scope:
            my_scale = ops.convert_to_tensor(scale, dtype=weights.dtype.base_dtype, name='scale')
            # if tf.__version__ <= '0.12':
            #     standard_ops_fn = standard_ops.mul
            # else:
            standard_ops_fn = standard_ops.multiply
            return standard_ops_fn(
                my_scale, standard_ops.reduce_sum(standard_ops.sqrt(standard_ops.reduce_sum(tf.square(weights), 0))),
                name=scope
            )

    return lo

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/cost.py" startline="689" endline="735" pcid="803">

def maxnorm_o_regularizer(scale):
    """Max-norm output regularization removes the neurons of current layer.
    Returns a function that can be used to apply max-norm regularization to each column of weight matrix.
    The implementation follows `TensorFlow contrib <https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/regularizers.py>`__.

    Parameters
    ----------
    scale : float
        A scalar multiplier `Tensor`. 0.0 disables the regularizer.

    Returns
    ---------
    A function with signature `mn_o(weights, name=None)` that apply Lo regularization.

    Raises
    ---------
    ValueError : If scale is outside of the range [0.0, 1.0] or if scale is not a float.

    """
    if isinstance(scale, numbers.Integral):
        raise ValueError('scale cannot be an integer: %s' % scale)

    if isinstance(scale, numbers.Real):
        if scale < 0.:
            raise ValueError('Setting a scale less than 0 on a regularizer: %g' % scale)
        # if scale >= 1.:
        #   raise ValueError('Setting a scale greater than 1 on a regularizer: %g' %
        #                    scale)
        if scale == 0.:
            logging.info('Scale of 0 disables regularizer.')
            return lambda _, name=None: None

    def mn_o(weights, name='maxnorm_o_regularizer'):
        """Applies max-norm regularization to weights."""
        with tf.name_scope(name) as scope:
            my_scale = ops.convert_to_tensor(scale, dtype=weights.dtype.base_dtype, name='scale')
            if tf.__version__ <= '0.12':
                standard_ops_fn = standard_ops.mul
            else:
                standard_ops_fn = standard_ops.multiply
            return standard_ops_fn(
                my_scale, standard_ops.reduce_sum(standard_ops.reduce_max(standard_ops.abs(weights), 0)), name=scope
            )

    return mn_o

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/cost.py" startline="736" endline="782" pcid="805">

def maxnorm_i_regularizer(scale):
    """Max-norm input regularization removes the neurons of previous layer.
    Returns a function that can be used to apply max-norm regularization to each row of weight matrix.
    The implementation follows `TensorFlow contrib <https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/regularizers.py>`__.

    Parameters
    ----------
    scale : float
        A scalar multiplier `Tensor`. 0.0 disables the regularizer.

    Returns
    ---------
    A function with signature `mn_i(weights, name=None)` that apply Lo regularization.

    Raises
    ---------
    ValueError : If scale is outside of the range [0.0, 1.0] or if scale is not a float.

    """
    if isinstance(scale, numbers.Integral):
        raise ValueError('scale cannot be an integer: %s' % scale)

    if isinstance(scale, numbers.Real):
        if scale < 0.:
            raise ValueError('Setting a scale less than 0 on a regularizer: %g' % scale)
        # if scale >= 1.:
        #   raise ValueError('Setting a scale greater than 1 on a regularizer: %g' %
        #                    scale)
        if scale == 0.:
            logging.info('Scale of 0 disables regularizer.')
            return lambda _, name=None: None

    def mn_i(weights, name='maxnorm_i_regularizer'):
        """Applies max-norm regularization to weights."""
        with tf.name_scope(name) as scope:
            my_scale = ops.convert_to_tensor(scale, dtype=weights.dtype.base_dtype, name='scale')
            if tf.__version__ <= '0.12':
                standard_ops_fn = standard_ops.mul
            else:
                standard_ops_fn = standard_ops.multiply
            return standard_ops_fn(
                my_scale, standard_ops.reduce_sum(standard_ops.reduce_max(standard_ops.abs(weights), 1)), name=scope
            )

    return mn_i

</source>
</class>

<class classid="33" nclones="2" nlines="10" similarity="100">
<source file="systems/TensorLayer-2.0.2/tensorlayer/models/vgg.py" startline="197" endline="258" pcid="847">
def vgg16(pretrained=False, end_with='outputs', mode='dynamic', name=None):
    """Pre-trained VGG16 model.

    Parameters
    ------------
    pretrained : boolean
        Whether to load pretrained weights. Default False.
    end_with : str
        The end point of the model. Default ``fc3_relu`` i.e. the whole model.
    mode : str.
        Model building mode, 'dynamic' or 'static'. Default 'dynamic'.
    name : None or str
        A unique layer name.

    Examples
    ---------
    Classify ImageNet classes with VGG16, see `tutorial_models_vgg.py <https://github.com/tensorlayer/tensorlayer/blob/master/example/tutorial_models_vgg.py>`__
    With TensorLayer

    >>> # get the whole model, without pre-trained VGG parameters
    >>> vgg = tl.models.vgg16()
    >>> # get the whole model, restore pre-trained VGG parameters
    >>> vgg = tl.models.vgg16(pretrained=True)
    >>> # use for inferencing
    >>> output = vgg(img, is_train=False)
    >>> probs = tf.nn.softmax(output)[0].numpy()

    Extract features with VGG16 and Train a classifier with 100 classes

    >>> # get VGG without the last layer
    >>> cnn = tl.models.vgg16(end_with='fc2_relu', mode='static').as_layer()
    >>> # add one more layer and build a new model
    >>> ni = Input([None, 224, 224, 3], name="inputs")
    >>> nn = cnn(ni)
    >>> nn = tl.layers.Dense(n_units=100, name='out')(nn)
    >>> model = tl.models.Model(inputs=ni, outputs=nn)
    >>> # train your own classifier (only update the last layer)
    >>> train_params = model.get_layer('out').trainable_weights

    Reuse model

    >>> # in dynamic model, we can directly use the same model
    >>> # in static model
    >>> vgg_layer = tl.models.vgg16().as_layer()
    >>> ni_1 = tl.layers.Input([None, 224, 244, 3])
    >>> ni_2 = tl.layers.Input([None, 224, 244, 3])
    >>> a_1 = vgg_layer(ni_1)
    >>> a_2 = vgg_layer(ni_2)
    >>> M = Model(inputs=[ni_1, ni_2], outputs=[a_1, a_2])

    """
    if mode == 'dynamic':
        model = VGG(layer_type='vgg16', batch_norm=False, end_with=end_with, name=name)
    elif mode == 'static':
        model = VGG_static(layer_type='vgg16', batch_norm=False, end_with=end_with, name=name)
    else:
        raise Exception("No such mode %s" % mode)
    if pretrained:
        restore_model(model, layer_type='vgg16')
    return model


</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/models/vgg.py" startline="259" endline="320" pcid="848">
def vgg19(pretrained=False, end_with='outputs', mode='dynamic', name=None):
    """Pre-trained VGG19 model.

    Parameters
    ------------
    pretrained : boolean
        Whether to load pretrained weights. Default False.
    end_with : str
        The end point of the model. Default ``fc3_relu`` i.e. the whole model.
    mode : str.
        Model building mode, 'dynamic' or 'static'. Default 'dynamic'.
    name : None or str
        A unique layer name.

    Examples
    ---------
    Classify ImageNet classes with VGG19, see `tutorial_models_vgg.py <https://github.com/tensorlayer/tensorlayer/blob/master/example/tutorial_models_vgg.py>`__
    With TensorLayer

    >>> # get the whole model, without pre-trained VGG parameters
    >>> vgg = tl.models.vgg19()
    >>> # get the whole model, restore pre-trained VGG parameters
    >>> vgg = tl.models.vgg19(pretrained=True)
    >>> # use for inferencing
    >>> output = vgg(img, is_train=False)
    >>> probs = tf.nn.softmax(output)[0].numpy()

    Extract features with VGG19 and Train a classifier with 100 classes

    >>> # get VGG without the last layer
    >>> cnn = tl.models.vgg19(end_with='fc2_relu', mode='static').as_layer()
    >>> # add one more layer and build a new model
    >>> ni = Input([None, 224, 224, 3], name="inputs")
    >>> nn = cnn(ni)
    >>> nn = tl.layers.Dense(n_units=100, name='out')(nn)
    >>> model = tl.models.Model(inputs=ni, outputs=nn)
    >>> # train your own classifier (only update the last layer)
    >>> train_params = model.get_layer('out').trainable_weights

    Reuse model

    >>> # in dynamic model, we can directly use the same model
    >>> # in static model
    >>> vgg_layer = tl.models.vgg19().as_layer()
    >>> ni_1 = tl.layers.Input([None, 224, 244, 3])
    >>> ni_2 = tl.layers.Input([None, 224, 244, 3])
    >>> a_1 = vgg_layer(ni_1)
    >>> a_2 = vgg_layer(ni_2)
    >>> M = Model(inputs=[ni_1, ni_2], outputs=[a_1, a_2])

    """
    if mode == 'dynamic':
        model = VGG(layer_type='vgg19', batch_norm=False, end_with=end_with, name=name)
    elif mode == 'static':
        model = VGG_static(layer_type='vgg19', batch_norm=False, end_with=end_with, name=name)
    else:
        raise Exception("No such mode %s" % mode)
    if pretrained:
        restore_model(model, layer_type='vgg19')
    return model


</source>
</class>

<class classid="34" nclones="2" nlines="20" similarity="80">
<source file="systems/TensorLayer-2.0.2/tensorlayer/optimizers/amsgrad.py" startline="79" endline="106" pcid="887">
    def _apply_dense(self, grad, var):
        beta1_power = math_ops.cast(self._beta1_power, var.dtype.base_dtype)
        beta2_power = math_ops.cast(self._beta2_power, var.dtype.base_dtype)
        lr_t = math_ops.cast(self._lr_t, var.dtype.base_dtype)
        beta1_t = math_ops.cast(self._beta1_t, var.dtype.base_dtype)
        beta2_t = math_ops.cast(self._beta2_t, var.dtype.base_dtype)
        epsilon_t = math_ops.cast(self._epsilon_t, var.dtype.base_dtype)

        lr = (lr_t * math_ops.sqrt(1 - beta2_power) / (1 - beta1_power))

        # m_t = beta1 * m + (1 - beta1) * g_t
        m = self.get_slot(var, "m")
        m_scaled_g_values = grad * (1 - beta1_t)
        m_t = state_ops.assign(m, beta1_t * m + m_scaled_g_values, use_locking=self._use_locking)

        # v_t = beta2 * v + (1 - beta2) * (g_t * g_t)
        v = self.get_slot(var, "v")
        v_scaled_g_values = (grad * grad) * (1 - beta2_t)
        v_t = state_ops.assign(v, beta2_t * v + v_scaled_g_values, use_locking=self._use_locking)

        # amsgrad
        vhat = self.get_slot(var, "vhat")
        vhat_t = state_ops.assign(vhat, math_ops.maximum(v_t, vhat))
        v_sqrt = math_ops.sqrt(vhat_t)

        var_update = state_ops.assign_sub(var, lr * m_t / (v_sqrt + epsilon_t), use_locking=self._use_locking)
        return control_flow_ops.group(*[var_update, m_t, v_t, vhat_t])

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/optimizers/amsgrad.py" startline="107" endline="135" pcid="888">
    def _resource_apply_dense(self, grad, var):
        var = var.handle
        beta1_power = math_ops.cast(self._beta1_power, grad.dtype.base_dtype)
        beta2_power = math_ops.cast(self._beta2_power, grad.dtype.base_dtype)
        lr_t = math_ops.cast(self._lr_t, grad.dtype.base_dtype)
        beta1_t = math_ops.cast(self._beta1_t, grad.dtype.base_dtype)
        beta2_t = math_ops.cast(self._beta2_t, grad.dtype.base_dtype)
        epsilon_t = math_ops.cast(self._epsilon_t, grad.dtype.base_dtype)

        lr = (lr_t * math_ops.sqrt(1 - beta2_power) / (1 - beta1_power))

        # m_t = beta1 * m + (1 - beta1) * g_t
        m = self.get_slot(var, "m").handle
        m_scaled_g_values = grad * (1 - beta1_t)
        m_t = state_ops.assign(m, beta1_t * m + m_scaled_g_values, use_locking=self._use_locking)

        # v_t = beta2 * v + (1 - beta2) * (g_t * g_t)
        v = self.get_slot(var, "v").handle
        v_scaled_g_values = (grad * grad) * (1 - beta2_t)
        v_t = state_ops.assign(v, beta2_t * v + v_scaled_g_values, use_locking=self._use_locking)

        # amsgrad
        vhat = self.get_slot(var, "vhat").handle
        vhat_t = state_ops.assign(vhat, math_ops.maximum(v_t, vhat))
        v_sqrt = math_ops.sqrt(vhat_t)

        var_update = state_ops.assign_sub(var, lr * m_t / (v_sqrt + epsilon_t), use_locking=self._use_locking)
        return control_flow_ops.group(*[var_update, m_t, v_t, vhat_t])

</source>
</class>

<class classid="35" nclones="2" nlines="32" similarity="84">
<source file="systems/TensorLayer-2.0.2/tensorlayer/visualize.py" startline="403" endline="463" pcid="921">
def CNN2d(CNN=None, second=10, saveable=True, name='cnn', fig_idx=3119362):
    """Display a group of RGB or Greyscale CNN masks.

    Parameters
    ----------
    CNN : numpy.array
        The image. e.g: 64 5x5 RGB images can be (5, 5, 3, 64).
    second : int
        The display second(s) for the image(s), if saveable is False.
    saveable : boolean
        Save or plot the figure.
    name : str
        A name to save the image, if saveable is True.
    fig_idx : int
        The matplotlib figure index.

    Examples
    --------
    >>> tl.visualize.CNN2d(network.all_params[0].eval(), second=10, saveable=True, name='cnn1_mnist', fig_idx=2012)

    """
    import matplotlib.pyplot as plt
    # tl.logging.info(CNN.shape)    # (5, 5, 3, 64)
    # exit()
    n_mask = CNN.shape[3]
    n_row = CNN.shape[0]
    n_col = CNN.shape[1]
    n_color = CNN.shape[2]
    row = int(np.sqrt(n_mask))
    col = int(np.ceil(n_mask / row))
    plt.ion()  # active mode
    fig = plt.figure(fig_idx)
    count = 1
    for _ir in range(1, row + 1):
        for _ic in range(1, col + 1):
            if count > n_mask:
                break
            fig.add_subplot(col, row, count)
            # tl.logging.info(CNN[:,:,:,count-1].shape, n_row, n_col)   # (5, 1, 32) 5 5
            # exit()
            # plt.imshow(
            #         np.reshape(CNN[count-1,:,:,:], (n_row, n_col)),
            #         cmap='gray', interpolation="nearest")     # theano
            if n_color == 1:
                plt.imshow(np.reshape(CNN[:, :, :, count - 1], (n_row, n_col)), cmap='gray', interpolation="nearest")
            elif n_color == 3:
                plt.imshow(
                    np.reshape(CNN[:, :, :, count - 1], (n_row, n_col, n_color)), cmap='gray', interpolation="nearest"
                )
            else:
                raise Exception("Unknown n_color")
            plt.gca().xaxis.set_major_locator(plt.NullLocator())  # distable tick
            plt.gca().yaxis.set_major_locator(plt.NullLocator())
            count = count + 1
    if saveable:
        plt.savefig(name + '.pdf', format='pdf')
    else:
        plt.draw()
        plt.pause(second)


</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/visualize.py" startline="464" endline="528" pcid="922">
def images2d(images=None, second=10, saveable=True, name='images', dtype=None, fig_idx=3119362):
    """Display a group of RGB or Greyscale images.

    Parameters
    ----------
    images : numpy.array
        The images.
    second : int
        The display second(s) for the image(s), if saveable is False.
    saveable : boolean
        Save or plot the figure.
    name : str
        A name to save the image, if saveable is True.
    dtype : None or numpy data type
        The data type for displaying the images.
    fig_idx : int
        matplotlib figure index.

    Examples
    --------
    >>> X_train, y_train, X_test, y_test = tl.files.load_cifar10_dataset(shape=(-1, 32, 32, 3), plotable=False)
    >>> tl.visualize.images2d(X_train[0:100,:,:,:], second=10, saveable=False, name='cifar10', dtype=np.uint8, fig_idx=20212)

    """
    import matplotlib.pyplot as plt
    # tl.logging.info(images.shape)    # (50000, 32, 32, 3)
    # exit()
    if dtype:
        images = np.asarray(images, dtype=dtype)
    n_mask = images.shape[0]
    n_row = images.shape[1]
    n_col = images.shape[2]
    n_color = images.shape[3]
    row = int(np.sqrt(n_mask))
    col = int(np.ceil(n_mask / row))
    plt.ion()  # active mode
    fig = plt.figure(fig_idx)
    count = 1
    for _ir in range(1, row + 1):
        for _ic in range(1, col + 1):
            if count > n_mask:
                break
            fig.add_subplot(col, row, count)
            # tl.logging.info(images[:,:,:,count-1].shape, n_row, n_col)   # (5, 1, 32) 5 5
            # plt.imshow(
            #         np.reshape(images[count-1,:,:,:], (n_row, n_col)),
            #         cmap='gray', interpolation="nearest")     # theano
            if n_color == 1:
                plt.imshow(np.reshape(images[count - 1, :, :], (n_row, n_col)), cmap='gray', interpolation="nearest")
                # plt.title(name)
            elif n_color == 3:
                plt.imshow(images[count - 1, :, :], cmap='gray', interpolation="nearest")
                # plt.title(name)
            else:
                raise Exception("Unknown n_color")
            plt.gca().xaxis.set_major_locator(plt.NullLocator())  # distable tick
            plt.gca().yaxis.set_major_locator(plt.NullLocator())
            count = count + 1
    if saveable:
        plt.savefig(name + '.pdf', format='pdf')
    else:
        plt.draw()
        plt.pause(second)


</source>
</class>

<class classid="36" nclones="2" nlines="18" similarity="77">
<source file="systems/TensorLayer-2.0.2/tensorlayer/db.py" startline="111" endline="170" pcid="963">
    def save_model(self, network=None, model_name='model', **kwargs):
        """Save model architecture and parameters into database, timestamp will be added automatically.

        Parameters
        ----------
        network : TensorLayer Model
            TensorLayer Model instance.
        model_name : str
            The name/key of model.
        kwargs : other events
            Other events, such as name, accuracy, loss, step number and etc (optinal).

        Examples
        ---------
        Save model architecture and parameters into database.
        >>> db.save_model(net, accuracy=0.8, loss=2.3, name='second_model')

        Load one model with parameters from database (run this in other script)
        >>> net = db.find_top_model(accuracy=0.8, loss=2.3)

        Find and load the latest model.
        >>> net = db.find_top_model(sort=[("time", pymongo.DESCENDING)])
        >>> net = db.find_top_model(sort=[("time", -1)])

        Find and load the oldest model.
        >>> net = db.find_top_model(sort=[("time", pymongo.ASCENDING)])
        >>> net = db.find_top_model(sort=[("time", 1)])

        Get model information
        >>> net._accuracy
        ... 0.8

        Returns
        ---------
        boolean : True for success, False for fail.
        """
        kwargs.update({'model_name': model_name})
        self._fill_project_info(kwargs)  # put project_name into kwargs

        # params = network.get_all_params()
        params = network.all_weights

        s = time.time()

        # kwargs.update({'architecture': network.all_graphs, 'time': datetime.utcnow()})
        kwargs.update({'architecture': network.config, 'time': datetime.utcnow()})

        try:
            params_id = self.model_fs.put(self._serialization(params))
            kwargs.update({'params_id': params_id, 'time': datetime.utcnow()})
            self.db.Model.insert_one(kwargs)
            print("[Database] Save model: SUCCESS, took: {}s".format(round(time.time() - s, 2)))
            return True
        except Exception as e:
            exc_type, exc_obj, exc_tb = sys.exc_info()
            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]
            logging.info("{}  {}  {}  {}  {}".format(exc_type, exc_obj, fname, exc_tb.tb_lineno, e))
            print("[Database] Save model: FAIL")
            return False

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/db.py" startline="258" endline="301" pcid="966">
    def save_dataset(self, dataset=None, dataset_name=None, **kwargs):
        """Saves one dataset into database, timestamp will be added automatically.

        Parameters
        ----------
        dataset : any type
            The dataset you want to store.
        dataset_name : str
            The name of dataset.
        kwargs : other events
            Other events, such as description, author and etc (optinal).

        Examples
        ----------
        Save dataset
        >>> db.save_dataset([X_train, y_train, X_test, y_test], 'mnist', description='this is a tutorial')

        Get dataset
        >>> dataset = db.find_top_dataset('mnist')

        Returns
        ---------
        boolean : Return True if save success, otherwise, return False.
        """
        self._fill_project_info(kwargs)
        if dataset_name is None:
            raise Exception("dataset_name is None, please give a dataset name")
        kwargs.update({'dataset_name': dataset_name})

        s = time.time()
        try:
            dataset_id = self.dataset_fs.put(self._serialization(dataset))
            kwargs.update({'dataset_id': dataset_id, 'time': datetime.utcnow()})
            self.db.Dataset.insert_one(kwargs)
            # print("[Database] Save params: {} SUCCESS, took: {}s".format(file_name, round(time.time()-s, 2)))
            print("[Database] Save dataset: SUCCESS, took: {}s".format(round(time.time() - s, 2)))
            return True
        except Exception as e:
            exc_type, exc_obj, exc_tb = sys.exc_info()
            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]
            logging.info("{}  {}  {}  {}  {}".format(exc_type, exc_obj, fname, exc_tb.tb_lineno, e))
            print("[Database] Save dataset: FAIL")
            return False

</source>
</class>

<class classid="37" nclones="2" nlines="28" similarity="70">
<source file="systems/TensorLayer-2.0.2/tensorlayer/db.py" startline="171" endline="244" pcid="964">
    def find_top_model(self, sort=None, model_name='model', **kwargs):
        """Finds and returns a model architecture and its parameters from the database which matches the requirement.

        Parameters
        ----------
        sort : List of tuple
            PyMongo sort comment, search "PyMongo find one sorting" and `collection level operations <http://api.mongodb.com/python/current/api/pymongo/collection.html>`__ for more details.
        model_name : str or None
            The name/key of model.
        kwargs : other events
            Other events, such as name, accuracy, loss, step number and etc (optinal).

        Examples
        ---------
        - see ``save_model``.

        Returns
        ---------
        network : TensorLayer Model
            Note that, the returned network contains all information of the document (record), e.g. if you saved accuracy in the document, you can get the accuracy by using ``net._accuracy``.
        """
        # print(kwargs)   # {}
        kwargs.update({'model_name': model_name})
        self._fill_project_info(kwargs)

        s = time.time()

        d = self.db.Model.find_one(filter=kwargs, sort=sort)

        # _temp_file_name = '_find_one_model_ztemp_file'
        if d is not None:
            params_id = d['params_id']
            graphs = d['architecture']
            _datetime = d['time']
            # exists_or_mkdir(_temp_file_name, False)
            # with open(os.path.join(_temp_file_name, 'graph.pkl'), 'wb') as file:
            #     pickle.dump(graphs, file, protocol=pickle.HIGHEST_PROTOCOL)
        else:
            print("[Database] FAIL! Cannot find model: {}".format(kwargs))
            return False
        try:
            params = self._deserialization(self.model_fs.get(params_id).read())
            # TODO : restore model and load weights
            network = static_graph2net(graphs)
            assign_weights(weights=params, network=network)
            # np.savez(os.path.join(_temp_file_name, 'params.npz'), params=params)
            #
            # network = load_graph_and_params(name=_temp_file_name, sess=sess)
            # del_folder(_temp_file_name)

            pc = self.db.Model.find(kwargs)
            print(
                "[Database] Find one model SUCCESS. kwargs:{} sort:{} save time:{} took: {}s".format(
                    kwargs, sort, _datetime, round(time.time() - s, 2)
                )
            )

            # FIXME : not sure what's this for
            # put all informations of model into the TL layer
            # for key in d:
            #     network.__dict__.update({"_%s" % key: d[key]})

            # check whether more parameters match the requirement
            params_id_list = pc.distinct('params_id')
            n_params = len(params_id_list)
            if n_params != 1:
                print("     Note that there are {} models match the kwargs".format(n_params))
            return network
        except Exception as e:
            exc_type, exc_obj, exc_tb = sys.exc_info()
            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]
            logging.info("{}  {}  {}  {}  {}".format(exc_type, exc_obj, fname, exc_tb.tb_lineno, e))
            return False

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/db.py" startline="302" endline="360" pcid="967">
    def find_top_dataset(self, dataset_name=None, sort=None, **kwargs):
        """Finds and returns a dataset from the database which matches the requirement.

        Parameters
        ----------
        dataset_name : str
            The name of dataset.
        sort : List of tuple
            PyMongo sort comment, search "PyMongo find one sorting" and `collection level operations <http://api.mongodb.com/python/current/api/pymongo/collection.html>`__ for more details.
        kwargs : other events
            Other events, such as description, author and etc (optinal).

        Examples
        ---------
        Save dataset
        >>> db.save_dataset([X_train, y_train, X_test, y_test], 'mnist', description='this is a tutorial')

        Get dataset
        >>> dataset = db.find_top_dataset('mnist')
        >>> datasets = db.find_datasets('mnist')

        Returns
        --------
        dataset : the dataset or False
            Return False if nothing found.

        """

        self._fill_project_info(kwargs)
        if dataset_name is None:
            raise Exception("dataset_name is None, please give a dataset name")
        kwargs.update({'dataset_name': dataset_name})

        s = time.time()

        d = self.db.Dataset.find_one(filter=kwargs, sort=sort)

        if d is not None:
            dataset_id = d['dataset_id']
        else:
            print("[Database] FAIL! Cannot find dataset: {}".format(kwargs))
            return False
        try:
            dataset = self._deserialization(self.dataset_fs.get(dataset_id).read())
            pc = self.db.Dataset.find(kwargs)
            print("[Database] Find one dataset SUCCESS, {} took: {}s".format(kwargs, round(time.time() - s, 2)))

            # check whether more datasets match the requirement
            dataset_id_list = pc.distinct('dataset_id')
            n_dataset = len(dataset_id_list)
            if n_dataset != 1:
                print("     Note that there are {} datasets match the requirement".format(n_dataset))
            return dataset
        except Exception as e:
            exc_type, exc_obj, exc_tb = sys.exc_info()
            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]
            logging.info("{}  {}  {}  {}  {}".format(exc_type, exc_obj, fname, exc_tb.tb_lineno, e))
            return False

</source>
</class>

<class classid="38" nclones="2" nlines="18" similarity="73">
<source file="systems/TensorLayer-2.0.2/tensorlayer/prepro.py" startline="1099" endline="1149" pcid="1005">
    -------
    numpy.array
        A list of processed images.

    """
    if is_random:
        shear = np.random.uniform(-intensity, intensity)
    else:
        shear = intensity
    shear_matrix = np.array([[1, -np.sin(shear), 0], [0, np.cos(shear), 0], [0, 0, 1]])

    h, w = x[0].shape[row_index], x[0].shape[col_index]
    transform_matrix = transform_matrix_offset_center(shear_matrix, h, w)
    results = []
    for data in x:
        results.append(affine_transform(data, transform_matrix, channel_index, fill_mode, cval, order))
    return np.asarray(results)


def shear2(
        x, shear=(0.1, 0.1), is_random=False, row_index=0, col_index=1, channel_index=2, fill_mode='nearest', cval=0.,
        order=1
):
    """Shear an image randomly or non-randomly.

    Parameters
    -----------
    x : numpy.array
        An image with dimension of [row, col, channel] (default).
    shear : tuple of two floats
        Percentage of shear for height and width direction (0, 1).
    is_random : boolean
        If True, randomly shear. Default is False.
    row_index col_index and channel_index : int
        Index of row, col and channel, default (0, 1, 2), for theano (1, 2, 0).
    fill_mode : str
        Method to fill missing pixel, default `nearest`, more options `constant`, `reflect` or `wrap`, see `scipy ndimage affine_transform <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.affine_transform.html>`__
    cval : float
        Value used for points outside the boundaries of the input if mode='constant'. Default is 0.0.
    order : int
        The order of interpolation. The order has to be in the range 0-5. See ``tl.prepro.affine_transform`` and `scipy ndimage affine_transform <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.affine_transform.html>`__

    Returns
    -------
    numpy.array
        A processed image.

    References
    -----------
    - `Affine transformation <https://uk.mathworks.com/discovery/affine-transformation.html>`__

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/prepro.py" startline="1150" endline="1190" pcid="1006">
    """
    if len(shear) != 2:
        raise AssertionError(
            "shear should be tuple of 2 floats, or you want to use tl.prepro.shear rather than tl.prepro.shear2 ?"
        )
    if isinstance(shear, tuple):
        shear = list(shear)
    if is_random:
        shear[0] = np.random.uniform(-shear[0], shear[0])
        shear[1] = np.random.uniform(-shear[1], shear[1])

    shear_matrix = np.array([[1, shear[0], 0], \
                            [shear[1], 1, 0], \
                            [0, 0, 1]])

    h, w = x.shape[row_index], x.shape[col_index]
    transform_matrix = transform_matrix_offset_center(shear_matrix, h, w)
    x = affine_transform(x, transform_matrix, channel_index, fill_mode, cval, order)
    return x


def shear_multi2(
        x, shear=(0.1, 0.1), is_random=False, row_index=0, col_index=1, channel_index=2, fill_mode='nearest', cval=0.,
        order=1
):
    """Shear images with the same arguments, randomly or non-randomly.
    Usually be used for image segmentation which x=[X, Y], X and Y should be matched.

    Parameters
    -----------
    x : list of numpy.array
        List of images with dimension of [n_images, row, col, channel] (default).
    others : args
        See ``tl.prepro.shear2``.

    Returns
    -------
    numpy.array
        A list of processed images.

    """
</source>
</class>

<class classid="39" nclones="2" nlines="13" similarity="71">
<source file="systems/TensorLayer-2.0.2/tensorlayer/prepro.py" startline="2032" endline="2070" pcid="1026">
    # flatx = np.reshape(x, (x.shape))
    # flatx = np.reshape(x, (x.shape[0], ))
    # tl.logging.info(flatx.shape)  # (160, 176, 1)
    whitex = np.dot(flatx, principal_components)
    x = np.reshape(whitex, (x.shape[0], x.shape[1], x.shape[2]))
    return x


# developing
# def barrel_transform(x, intensity):
#     # https://github.com/fchollet/keras/blob/master/keras/preprocessing/image.py
#     # TODO
#     pass
#
# def barrel_transform_multi(x, intensity):
#     # https://github.com/fchollet/keras/blob/master/keras/preprocessing/image.py
#     # TODO
#     pass


# channel shift
def channel_shift(x, intensity, is_random=False, channel_index=2):
    """Shift the channels of an image, randomly or non-randomly, see `numpy.rollaxis <https://docs.scipy.org/doc/numpy/reference/generated/numpy.rollaxis.html>`__.

    Parameters
    -----------
    x : numpy.array
        An image with dimension of [row, col, channel] (default).
    intensity : float
        Intensity of shifting.
    is_random : boolean
        If True, randomly shift. Default is False.
    channel_index : int
        Index of channel. Default is 2.

    Returns
    -------
    numpy.array
        A processed image.
</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/prepro.py" startline="2071" endline="2104" pcid="1027">

    """
    if is_random:
        factor = np.random.uniform(-intensity, intensity)
    else:
        factor = intensity
    x = np.rollaxis(x, channel_index, 0)
    min_x, max_x = np.min(x), np.max(x)
    channel_images = [np.clip(x_channel + factor, min_x, max_x) for x_channel in x]
    x = np.stack(channel_images, axis=0)
    x = np.rollaxis(x, 0, channel_index + 1)
    return x
    # x = np.rollaxis(x, channel_index, 0)
    # min_x, max_x = np.min(x), np.max(x)
    # channel_images = [np.clip(x_channel + np.random.uniform(-intensity, intensity), min_x, max_x)
    #                   for x_channel in x]
    # x = np.stack(channel_images, axis=0)
    # x = np.rollaxis(x, 0, channel_index+1)
    # return x


def channel_shift_multi(x, intensity, is_random=False, channel_index=2):
    """Shift the channels of images with the same arguments, randomly or non-randomly, see `numpy.rollaxis <https://docs.scipy.org/doc/numpy/reference/generated/numpy.rollaxis.html>`__.
    Usually be used for image segmentation which x=[X, Y], X and Y should be matched.

    Parameters
    -----------
    x : list of numpy.array
        List of images with dimension of [n_images, row, col, channel] (default).
    others : args
        See ``tl.prepro.channel_shift``.

    Returns
    -------
</source>
</class>

<class classid="40" nclones="3" nlines="74" similarity="75">
<source file="systems/TensorLayer-2.0.2/tensorlayer/prepro.py" startline="2831" endline="2983" pcid="1048">
        return im, coords_new
    else:
        return im, coords


# im = np.zeros([80, 100, 3])    # as an image with shape width=100, height=80
# _, coords = obj_box_imresize(im, coords=[[20, 40, 30, 30], [10, 20, 20, 20]], size=[160, 200], is_rescale=False)
# tl.logging.info(coords)
# #   [[40, 80, 60, 60], [20, 40, 40, 40]]
# _, coords = obj_box_imresize(im, coords=[[20, 40, 30, 30]], size=[40, 100], is_rescale=False)
# tl.logging.info(coords)
# #   [20, 20, 30, 15]
# _, coords = obj_box_imresize(im, coords=[[20, 40, 30, 30]], size=[60, 150], is_rescale=False)
# tl.logging.info(coords)
# #   [30, 30, 45, 22]
# im2, coords = obj_box_imresize(im, coords=[[0.2, 0.4, 0.3, 0.3]], size=[160, 200], is_rescale=True)
# tl.logging.info(coords, im2.shape)
# # [0.2, 0.4, 0.3, 0.3] (160, 200, 3)
# exit()


def obj_box_crop(
        im, classes=None, coords=None, wrg=100, hrg=100, is_rescale=False, is_center=False, is_random=False,
        thresh_wh=0.02, thresh_wh2=12.
):
    """Randomly or centrally crop an image, and compute the new bounding box coordinates.
    Objects outside the cropped image will be removed.

    Parameters
    -----------
    im : numpy.array
        An image with dimension of [row, col, channel] (default).
    classes : list of int or None
        Class IDs.
    coords : list of list of 4 int/float or None
        Coordinates [[x, y, w, h], [x, y, w, h], ...]
    wrg hrg and is_random : args
        See ``tl.prepro.crop``.
    is_rescale : boolean
        Set to True, if the input coordinates are rescaled to [0, 1]. Default is False.
    is_center : boolean, default False
        Set to True, if the x and y of coordinates are the centroid (i.e. darknet format). Default is False.
    thresh_wh : float
        Threshold, remove the box if its ratio of width(height) to image size less than the threshold.
    thresh_wh2 : float
        Threshold, remove the box if its ratio of width to height or vice verse higher than the threshold.

    Returns
    -------
    numpy.array
        A processed image
    list of int
        A list of classes
    list of list of 4 numbers
        A list of new bounding boxes.

    """
    if classes is None:
        classes = []
    if coords is None:
        coords = []

    h, w = im.shape[0], im.shape[1]

    if (h <= hrg) or (w <= wrg):
        raise AssertionError("The size of cropping should smaller than the original image")

    if is_random:
        h_offset = int(np.random.uniform(0, h - hrg) - 1)
        w_offset = int(np.random.uniform(0, w - wrg) - 1)
        h_end = hrg + h_offset
        w_end = wrg + w_offset
        im_new = im[h_offset:h_end, w_offset:w_end]
    else:  # central crop
        h_offset = int(np.floor((h - hrg) / 2.))
        w_offset = int(np.floor((w - wrg) / 2.))
        h_end = h_offset + hrg
        w_end = w_offset + wrg
        im_new = im[h_offset:h_end, w_offset:w_end]

    #              w
    #   _____________________________
    #   |  h/w offset               |
    #   |       -------             |
    # h |       |     |             |
    #   |       |     |             |
    #   |       -------             |
    #   |            h/w end        |
    #   |___________________________|

    def _get_coord(coord):
        """Input pixel-unit [x, y, w, h] format, then make sure [x, y] it is the up-left coordinates,
        before getting the new coordinates.
        Boxes outsides the cropped image will be removed.

        """
        if is_center:
            coord = obj_box_coord_centroid_to_upleft(coord)

        ##======= pixel unit format and upleft, w, h ==========##

        # x = np.clip( coord[0] - w_offset, 0, w_end - w_offset)
        # y = np.clip( coord[1] - h_offset, 0, h_end - h_offset)
        # w = np.clip( coord[2]           , 0, w_end - w_offset)
        # h = np.clip( coord[3]           , 0, h_end - h_offset)

        x = coord[0] - w_offset
        y = coord[1] - h_offset
        w = coord[2]
        h = coord[3]

        if x < 0:
            if x + w <= 0:
                return None
            w = w + x
            x = 0
        elif x > im_new.shape[1]:  # object outside the cropped image
            return None

        if y < 0:
            if y + h <= 0:
                return None
            h = h + y
            y = 0
        elif y > im_new.shape[0]:  # object outside the cropped image
            return None

        if (x is not None) and (x + w > im_new.shape[1]):  # box outside the cropped image
            w = im_new.shape[1] - x

        if (y is not None) and (y + h > im_new.shape[0]):  # box outside the cropped image
            h = im_new.shape[0] - y

        if (w / (h + 1.) > thresh_wh2) or (h / (w + 1.) > thresh_wh2):  # object shape strange: too narrow
            # tl.logging.info('xx', w, h)
            return None

        if (w / (im_new.shape[1] * 1.) < thresh_wh) or (h / (im_new.shape[0] * 1.) <
                                                        thresh_wh):  # object shape strange: too narrow
            # tl.logging.info('yy', w, im_new.shape[1], h, im_new.shape[0])
            return None

        coord = [x, y, w, h]

        ## convert back if input format is center.
        if is_center:
            coord = obj_box_coord_upleft_to_centroid(coord)

        return coord

    coords_new = list()
    classes_new = list()
    for i, _ in enumerate(coords):
</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/prepro.py" startline="2984" endline="3118" pcid="1050">
        coord = coords[i]

        if len(coord) != 4:
            raise AssertionError("coordinate should be 4 values : [x, y, w, h]")

        if is_rescale:
            # for scaled coord, upscaled before process and scale back in the end.
            coord = obj_box_coord_scale_to_pixelunit(coord, im.shape)
            coord = _get_coord(coord)
            if coord is not None:
                coord = obj_box_coord_rescale(coord, im_new.shape)
                coords_new.append(coord)
                classes_new.append(classes[i])
        else:
            coord = _get_coord(coord)
            if coord is not None:
                coords_new.append(coord)
                classes_new.append(classes[i])
    return im_new, classes_new, coords_new


def obj_box_shift(
        im, classes=None, coords=None, wrg=0.1, hrg=0.1, row_index=0, col_index=1, channel_index=2, fill_mode='nearest',
        cval=0., order=1, is_rescale=False, is_center=False, is_random=False, thresh_wh=0.02, thresh_wh2=12.
):
    """Shift an image randomly or non-randomly, and compute the new bounding box coordinates.
    Objects outside the cropped image will be removed.

    Parameters
    -----------
    im : numpy.array
        An image with dimension of [row, col, channel] (default).
    classes : list of int or None
        Class IDs.
    coords : list of list of 4 int/float or None
        Coordinates [[x, y, w, h], [x, y, w, h], ...]
    wrg, hrg row_index col_index channel_index is_random fill_mode cval and order : see ``tl.prepro.shift``.
    is_rescale : boolean
        Set to True, if the input coordinates are rescaled to [0, 1]. Default is False.
    is_center : boolean
        Set to True, if the x and y of coordinates are the centroid (i.e. darknet format). Default is False.
    thresh_wh : float
        Threshold, remove the box if its ratio of width(height) to image size less than the threshold.
    thresh_wh2 : float
        Threshold, remove the box if its ratio of width to height or vice verse higher than the threshold.


    Returns
    -------
    numpy.array
        A processed image
    list of int
        A list of classes
    list of list of 4 numbers
        A list of new bounding boxes.

    """
    if classes is None:
        classes = []
    if coords is None:
        coords = []

    imh, imw = im.shape[row_index], im.shape[col_index]

    if (hrg >= 1.0) and (hrg <= 0.) and (wrg >= 1.0) and (wrg <= 0.):
        raise AssertionError("shift range should be (0, 1)")

    if is_random:
        tx = np.random.uniform(-hrg, hrg) * imh
        ty = np.random.uniform(-wrg, wrg) * imw
    else:
        tx, ty = hrg * imh, wrg * imw
    translation_matrix = np.array([[1, 0, tx], [0, 1, ty], [0, 0, 1]])

    transform_matrix = translation_matrix  # no need to do offset
    im_new = affine_transform(im, transform_matrix, channel_index, fill_mode, cval, order)

    # modified from obj_box_crop
    def _get_coord(coord):
        """Input pixel-unit [x, y, w, h] format, then make sure [x, y] it is the up-left coordinates,
        before getting the new coordinates.
        Boxes outsides the cropped image will be removed.

        """
        if is_center:
            coord = obj_box_coord_centroid_to_upleft(coord)

        ##======= pixel unit format and upleft, w, h ==========##
        x = coord[0] - ty  # only change this
        y = coord[1] - tx  # only change this
        w = coord[2]
        h = coord[3]

        if x < 0:
            if x + w <= 0:
                return None
            w = w + x
            x = 0
        elif x > im_new.shape[1]:  # object outside the cropped image
            return None

        if y < 0:
            if y + h <= 0:
                return None
            h = h + y
            y = 0
        elif y > im_new.shape[0]:  # object outside the cropped image
            return None

        if (x is not None) and (x + w > im_new.shape[1]):  # box outside the cropped image
            w = im_new.shape[1] - x

        if (y is not None) and (y + h > im_new.shape[0]):  # box outside the cropped image
            h = im_new.shape[0] - y

        if (w / (h + 1.) > thresh_wh2) or (h / (w + 1.) > thresh_wh2):  # object shape strange: too narrow
            # tl.logging.info('xx', w, h)
            return None

        if (w / (im_new.shape[1] * 1.) < thresh_wh) or (h / (im_new.shape[0] * 1.) <
                                                        thresh_wh):  # object shape strange: too narrow
            # tl.logging.info('yy', w, im_new.shape[1], h, im_new.shape[0])
            return None

        coord = [x, y, w, h]

        ## convert back if input format is center.
        if is_center:
            coord = obj_box_coord_upleft_to_centroid(coord)

        return coord

    coords_new = list()
    classes_new = list()
    for i, _ in enumerate(coords):
</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/prepro.py" startline="3119" endline="3255" pcid="1052">
        coord = coords[i]

        if len(coord) != 4:
            raise AssertionError("coordinate should be 4 values : [x, y, w, h]")

        if is_rescale:
            # for scaled coord, upscaled before process and scale back in the end.
            coord = obj_box_coord_scale_to_pixelunit(coord, im.shape)
            coord = _get_coord(coord)
            if coord is not None:
                coord = obj_box_coord_rescale(coord, im_new.shape)
                coords_new.append(coord)
                classes_new.append(classes[i])
        else:
            coord = _get_coord(coord)
            if coord is not None:
                coords_new.append(coord)
                classes_new.append(classes[i])
    return im_new, classes_new, coords_new


def obj_box_zoom(
        im, classes=None, coords=None, zoom_range=(0.9, 1.1), row_index=0, col_index=1, channel_index=2,
        fill_mode='nearest', cval=0., order=1, is_rescale=False, is_center=False, is_random=False, thresh_wh=0.02,
        thresh_wh2=12.
):
    """Zoom in and out of a single image, randomly or non-randomly, and compute the new bounding box coordinates.
    Objects outside the cropped image will be removed.

    Parameters
    -----------
    im : numpy.array
        An image with dimension of [row, col, channel] (default).
    classes : list of int or None
        Class IDs.
    coords : list of list of 4 int/float or None
        Coordinates [[x, y, w, h], [x, y, w, h], ...].
    zoom_range row_index col_index channel_index is_random fill_mode cval and order : see ``tl.prepro.zoom``.
    is_rescale : boolean
        Set to True, if the input coordinates are rescaled to [0, 1]. Default is False.
    is_center : boolean
        Set to True, if the x and y of coordinates are the centroid. (i.e. darknet format). Default is False.
    thresh_wh : float
        Threshold, remove the box if its ratio of width(height) to image size less than the threshold.
    thresh_wh2 : float
        Threshold, remove the box if its ratio of width to height or vice verse higher than the threshold.

    Returns
    -------
    numpy.array
        A processed image
    list of int
        A list of classes
    list of list of 4 numbers
        A list of new bounding boxes.

    """
    if classes is None:
        classes = []
    if coords is None:
        coords = []

    if len(zoom_range) != 2:
        raise Exception('zoom_range should be a tuple or list of two floats. ' 'Received arg: ', zoom_range)
    if is_random:
        if zoom_range[0] == 1 and zoom_range[1] == 1:
            zx, zy = 1, 1
            tl.logging.info(" random_zoom : not zoom in/out")
        else:
            zx, zy = np.random.uniform(zoom_range[0], zoom_range[1], 2)
    else:
        zx, zy = zoom_range
    # tl.logging.info(zx, zy)
    zoom_matrix = np.array([[zx, 0, 0], [0, zy, 0], [0, 0, 1]])

    h, w = im.shape[row_index], im.shape[col_index]
    transform_matrix = transform_matrix_offset_center(zoom_matrix, h, w)
    im_new = affine_transform(im, transform_matrix, channel_index, fill_mode, cval, order)

    # modified from obj_box_crop
    def _get_coord(coord):
        """Input pixel-unit [x, y, w, h] format, then make sure [x, y] it is the up-left coordinates,
        before getting the new coordinates.
        Boxes outsides the cropped image will be removed.

        """
        if is_center:
            coord = obj_box_coord_centroid_to_upleft(coord)

        # ======= pixel unit format and upleft, w, h ==========
        x = (coord[0] - im.shape[1] / 2) / zy + im.shape[1] / 2  # only change this
        y = (coord[1] - im.shape[0] / 2) / zx + im.shape[0] / 2  # only change this
        w = coord[2] / zy  # only change this
        h = coord[3] / zx  # only change thisS

        if x < 0:
            if x + w <= 0:
                return None
            w = w + x
            x = 0
        elif x > im_new.shape[1]:  # object outside the cropped image
            return None

        if y < 0:
            if y + h <= 0:
                return None
            h = h + y
            y = 0
        elif y > im_new.shape[0]:  # object outside the cropped image
            return None

        if (x is not None) and (x + w > im_new.shape[1]):  # box outside the cropped image
            w = im_new.shape[1] - x

        if (y is not None) and (y + h > im_new.shape[0]):  # box outside the cropped image
            h = im_new.shape[0] - y

        if (w / (h + 1.) > thresh_wh2) or (h / (w + 1.) > thresh_wh2):  # object shape strange: too narrow
            # tl.logging.info('xx', w, h)
            return None

        if (w / (im_new.shape[1] * 1.) < thresh_wh) or (h / (im_new.shape[0] * 1.) <
                                                        thresh_wh):  # object shape strange: too narrow
            # tl.logging.info('yy', w, im_new.shape[1], h, im_new.shape[0])
            return None

        coord = [x, y, w, h]

        # convert back if input format is center.
        if is_center:
            coord = obj_box_coord_upleft_to_centroid(coord)

        return coord

    coords_new = list()
    classes_new = list()
    for i, _ in enumerate(coords):
</source>
</class>

<class classid="41" nclones="2" nlines="16" similarity="88">
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/embedding.py" startline="354" endline="371" pcid="1086">
    def __init__(
            self,
            vocabulary_size,
            embedding_size,
            E_init=tl.initializers.random_uniform(-0.1, 0.1),
            name=None,  #'embedding',
    ):
        super(Embedding, self).__init__(name)
        self.vocabulary_size = vocabulary_size
        self.embedding_size = embedding_size
        self.E_init = E_init

        if not self._built:
            self.build(tuple())
            self._built = True

        logging.info("Embedding %s: (%d, %d)" % (self.name, self.vocabulary_size, self.embedding_size))

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/embedding.py" startline="448" endline="468" pcid="1090">
    def __init__(
            self,
            vocabulary_size,
            embedding_size,
            pad_value=0,
            E_init=tl.initializers.random_uniform(-0.1, 0.1),
            name=None,  # 'average_embedding',
    ):

        super(AverageEmbedding, self).__init__(name)
        self.vocabulary_size = vocabulary_size
        self.embedding_size = embedding_size
        self.pad_value = pad_value
        self.E_init = E_init

        if not self._built:
            self.build(tuple())
            self._built = True

        logging.info("AverageEmbedding %s: (%d, %d)" % (self.name, self.vocabulary_size, self.embedding_size))

</source>
</class>

<class classid="42" nclones="19" nlines="32" similarity="70">
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/ternary_conv.py" startline="63" endline="106" pcid="1094">
    def __init__(
            self,
            n_filter=32,
            filter_size=(3, 3),
            strides=(1, 1),
            act=None,
            padding='SAME',
            use_gemm=False,
            data_format="channels_last",
            dilation_rate=(1, 1),
            W_init=tl.initializers.truncated_normal(stddev=0.02),
            b_init=tl.initializers.constant(value=0.0),
            in_channels=None,
            name=None  # 'ternary_cnn2d',
    ):
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.use_gemm = use_gemm
        self.data_format = data_format
        self.dilation_rate = self._dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "TernaryConv2d %s: n_filter: %d filter_size: %s strides: %s pad: %s act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

        if use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        if len(self.strides) != 2:
            raise ValueError("len(strides) should be 2.")

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/group_conv.py" startline="61" endline="98" pcid="1143">
    def __init__(
            self,
            n_filter=32,
            filter_size=(3, 3),
            strides=(2, 2),
            n_group=2,
            act=None,
            padding='SAME',
            data_format='channels_last',
            dilation_rate=(1, 1),
            W_init=tl.initializers.truncated_normal(stddev=0.02),
            b_init=tl.initializers.constant(value=0.0),
            in_channels=None,
            name=None  # 'groupconv',
    ):  # Windaway
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.strides = self._strides = strides
        self.n_group = n_group
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = self._dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "GroupConv2d %s: n_filter: %d size: %s strides: %s n_group: %d pad: %s act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), n_group, padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/depthwise_conv.py" startline="71" endline="106" pcid="1147">
    def __init__(
            self,
            filter_size=(3, 3),
            strides=(1, 1),
            act=None,
            padding='SAME',
            data_format='channels_last',
            dilation_rate=(1, 1),
            depth_multiplier=1,
            W_init=tl.initializers.truncated_normal(stddev=0.02),
            b_init=tl.initializers.constant(value=0.0),
            in_channels=None,
            name=None  # 'depthwise_conv2d'
    ):
        super().__init__(name, act=act)
        self.filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.dilation_rate = self._dilation_rate = dilation_rate
        self.data_format = data_format
        self.depth_multiplier = depth_multiplier
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "DepthwiseConv2d %s: filter_size: %s strides: %s pad: %s act: %s" % (
                self.name, str(filter_size), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/simplified_conv.py" startline="59" endline="94" pcid="1183">
    def __init__(
            self,
            n_filter=32,
            filter_size=5,
            stride=1,
            act=None,
            padding='SAME',
            data_format="channels_last",
            dilation_rate=1,
            W_init=tl.initializers.truncated_normal(stddev=0.02),
            b_init=tl.initializers.constant(value=0.0),
            in_channels=None,
            name=None  # 'conv1d'
    ):
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.stride = stride
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "Conv1d %s: n_filter: %d filter_size: %s stride: %d pad: %s act: %s" % (
                self.name, n_filter, filter_size, stride, padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/simplified_conv.py" startline="322" endline="357" pcid="1191">
    def __init__(
            self,
            n_filter=32,
            filter_size=(3, 3, 3),
            strides=(1, 1, 1),
            act=None,
            padding='SAME',
            data_format='channels_last',
            dilation_rate=(1, 1, 1),
            W_init=tl.initializers.truncated_normal(stddev=0.02),
            b_init=tl.initializers.constant(value=0.0),
            in_channels=None,
            name=None  # 'conv3d',
    ):
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self._strides = self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self._dilation_rate = self.dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "Conv3d %s: n_filter: %d filter_size: %s strides: %s pad: %s act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/quan_conv.py" startline="68" endline="115" pcid="1171">
    def __init__(
            self,
            bitW=8,
            bitA=8,
            n_filter=32,
            filter_size=(3, 3),
            strides=(1, 1),
            act=None,
            padding='SAME',
            use_gemm=False,
            data_format="channels_last",
            dilation_rate=(1, 1),
            W_init=tl.initializers.truncated_normal(stddev=0.02),
            b_init=tl.initializers.constant(value=0.0),
            in_channels=None,
            name=None  # 'quan_cnn2d',
    ):
        super().__init__(name, act=act)
        self.bitW = bitW
        self.bitA = bitA
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.use_gemm = use_gemm
        self.data_format = data_format
        self.dilation_rate = self._dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "QuanConv2d %s: n_filter: %d filter_size: %s strides: %s pad: %s act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

        if self.use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        if len(self.strides) != 2:
            raise ValueError("len(strides) should be 2.")

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/dorefa_conv.py" startline="67" endline="114" pcid="1118">
    def __init__(
            self,
            bitW=1,
            bitA=3,
            n_filter=32,
            filter_size=(3, 3),
            strides=(1, 1),
            act=None,
            padding='SAME',
            use_gemm=False,
            data_format="channels_last",
            dilation_rate=(1, 1),
            W_init=tl.initializers.truncated_normal(stddev=0.02),
            b_init=tl.initializers.constant(value=0.0),
            in_channels=None,
            name=None  # 'dorefa_cnn2d',
    ):
        super().__init__(name, act=act)
        self.bitW = bitW
        self.bitA = bitA
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.use_gemm = use_gemm
        self.data_format = data_format
        self.dilation_rate = self._dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "DorefaConv2d %s: n_filter: %d filter_size: %s strides: %s pad: %s act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

        if self.use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        if len(self.strides) != 2:
            raise ValueError("len(strides) should be 2.")

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/binary_conv.py" startline="63" endline="106" pcid="1098">
    def __init__(
            self,
            n_filter=32,
            filter_size=(3, 3),
            strides=(1, 1),
            act=None,
            padding='SAME',
            use_gemm=False,
            data_format="channels_last",
            dilation_rate=(1, 1),
            W_init=tl.initializers.truncated_normal(stddev=0.02),
            b_init=tl.initializers.constant(value=0.0),
            in_channels=None,
            name=None  # 'binary_cnn2d',
    ):
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.use_gemm = use_gemm
        self.data_format = data_format
        self._dilation_rate = self.dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "BinaryConv2d %s: n_filter: %d filter_size: %s strides: %s pad: %s act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

        if use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        if len(self.strides) != 2:
            raise ValueError("len(strides) should be 2.")

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/separable_conv.py" startline="210" endline="253" pcid="1179">
    def __init__(
            self,
            n_filter=100,
            filter_size=(3, 3),
            strides=(1, 1),
            act=None,
            padding='valid',
            data_format='channels_last',
            dilation_rate=(1, 1),
            depth_multiplier=1,
            depthwise_init=None,
            pointwise_init=None,
            b_init=tl.initializers.constant(value=0.0),
            # depthwise_regularizer=None,
            # pointwise_regularizer=None,
            # bias_regularizer=None,
            # activity_regularizer=None,
            # depthwise_constraint=None,
            # pointwise_constraint=None,
            # W_init=tf.truncated_normal_initializer(stddev=0.1),
            # b_init=tf.constant_initializer(value=0.0),
            in_channels=None,
            name=None  # 'seperable2d',
    ):
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = dilation_rate
        self.depth_multiplier = depth_multiplier
        self.depthwise_init = depthwise_init
        self.pointwise_init = pointwise_init
        self.b_init = b_init
        self.in_channels = in_channels

        logging.info(
            "SeparableConv2d  %s: n_filter: %d filter_size: %s filter_size: %s depth_multiplier: %d act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), depth_multiplier,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/simplified_conv.py" startline="189" endline="224" pcid="1187">
    def __init__(
            self,
            n_filter=32,
            filter_size=(3, 3),
            strides=(1, 1),
            act=None,
            padding='SAME',
            data_format='channels_last',
            dilation_rate=(1, 1),
            W_init=tl.initializers.truncated_normal(stddev=0.02),
            b_init=tl.initializers.constant(value=0.0),
            in_channels=None,
            name=None  # 'conv2d',
    ):
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self._strides = self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self._dilation_rate = self.dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "Conv2d %s: n_filter: %d filter_size: %s strides: %s pad: %s act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/separable_conv.py" startline="63" endline="106" pcid="1175">
    def __init__(
            self,
            n_filter=100,
            filter_size=3,
            strides=1,
            act=None,
            padding='valid',
            data_format='channels_last',
            dilation_rate=1,
            depth_multiplier=1,
            depthwise_init=None,
            pointwise_init=None,
            b_init=tl.initializers.constant(value=0.0),
            # depthwise_regularizer=None,
            # pointwise_regularizer=None,
            # bias_regularizer=None,
            # activity_regularizer=None,
            # depthwise_constraint=None,
            # pointwise_constraint=None,
            # W_init=tf.truncated_normal_initializer(stddev=0.1),
            # b_init=tf.constant_initializer(value=0.0),
            in_channels=None,
            name=None  # 'seperable1d',
    ):
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = dilation_rate
        self.depth_multiplier = depth_multiplier
        self.depthwise_init = depthwise_init
        self.pointwise_init = pointwise_init
        self.b_init = b_init
        self.in_channels = in_channels

        logging.info(
            "SeparableConv1d  %s: n_filter: %d filter_size: %s strides: %s depth_multiplier: %d act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), depth_multiplier,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/expert_conv.py" startline="299" endline="332" pcid="1110">
    def __init__(
            self,
            act=None,
            shape=(2, 2, 2, 3, 32),
            strides=(1, 2, 2, 2, 1),
            padding='SAME',
            data_format='NDHWC',
            dilation_rate=(1, 1, 1, 1, 1),
            W_init=tl.initializers.truncated_normal(stddev=0.02),
            b_init=tl.initializers.constant(value=0.0),
            name=None  # 'cnn3d_layer'
    ):
        super().__init__(name, act=act)
        self.n_filter = shape[-1]
        self.filter_size = (shape[0], shape[1], shape[2])
        self.shape = shape
        self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = shape[-2]

        self.build(None)
        self._built = True

        logging.info(
            "Conv3dLayer %s: shape: %s strides: %s pad: %s act: %s" % (
                self.name, str(shape), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/expert_deconv.py" startline="330" endline="363" pcid="1159">
    def __init__(
            self,
            act=None,
            shape=(2, 2, 2, 128, 256),
            outputs_shape=(1, 12, 32, 32, 128),
            strides=(1, 2, 2, 2, 1),
            padding='SAME',
            data_format='NDHWC',
            dilation_rate=(1, 1, 1, 1, 1),
            W_init=tl.initializers.truncated_normal(stddev=0.02),
            b_init=tl.initializers.constant(value=0.0),
            name=None  # 'decnn3d_layer',
    ):
        super().__init__(name, act=act)
        self.shape = shape
        self.outputs_shape = outputs_shape
        self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = self.shape[-1]

        self.build(None)
        self._built = True

        logging.info(
            "DeConv3dLayer %s: shape: %s out_shape: %s strides: %s pad: %s act: %s" % (
                self.name, str(shape), str(outputs_shape), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/expert_deconv.py" startline="204" endline="237" pcid="1155">
    def __init__(
            self,
            act=None,
            shape=(3, 3, 128, 256),
            outputs_shape=(1, 256, 256, 128),
            strides=(1, 2, 2, 1),
            padding='SAME',
            data_format='NHWC',
            dilation_rate=(1, 1, 1, 1),
            W_init=tl.initializers.truncated_normal(stddev=0.02),
            b_init=tl.initializers.constant(value=0.0),
            name=None  # 'decnn2d_layer',
    ):
        super().__init__(name, act=act)
        self.shape = shape
        self.outputs_shape = outputs_shape
        self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = self.shape[-1]

        self.build(None)
        self._built = True

        logging.info(
            "DeConv2dLayer %s: shape: %s out_shape: %s strides: %s pad: %s act: %s" % (
                self.name, str(shape), str(outputs_shape), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/expert_conv.py" startline="181" endline="214" pcid="1106">
    def __init__(
            self,
            act=None,
            shape=(5, 5, 1, 100),
            strides=(1, 1, 1, 1),
            padding='SAME',
            data_format='NHWC',
            dilation_rate=(1, 1, 1, 1),
            W_init=tl.initializers.truncated_normal(stddev=0.02),
            b_init=tl.initializers.constant(value=0.0),
            name=None  # 'cnn2d_layer',
    ):
        super().__init__(name, act=act)
        self.n_filter = shape[-1]
        self.filter_size = (shape[0], shape[1])
        self.shape = shape
        self.strides = strides
        self.dilation_rate = dilation_rate
        self.padding = padding
        self.data_format = data_format
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = shape[-2]

        self.build(None)
        self._built = True

        logging.info(
            "Conv2dLayer %s: shape: %s strides: %s pad: %s act: %s" % (
                self.name, str(shape), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/expert_conv.py" startline="62" endline="95" pcid="1102">
    def __init__(
            self,
            act=None,
            shape=(5, 1, 5),
            stride=1,
            padding='SAME',
            data_format='NWC',
            dilation_rate=1,
            W_init=tl.initializers.truncated_normal(stddev=0.02),
            b_init=tl.initializers.constant(value=0.0),
            name=None  # 'cnn1d_layer',
    ):
        super().__init__(name, act=act)
        self.n_filter = shape[-1]
        self.filter_size = shape[0]
        self.shape = shape
        self.stride = stride
        self.dilation_rate = dilation_rate
        self.padding = padding
        self.data_format = data_format
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = shape[-2]

        self.build(None)
        self._built = True

        logging.info(
            "Conv1dLayer %s: shape: %s stride: %s pad: %s act: %s" % (
                self.name, str(shape), str(stride), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/expert_deconv.py" startline="70" endline="103" pcid="1151">
    def __init__(
            self,
            act=None,
            shape=(3, 128, 256),
            outputs_shape=(1, 256, 128),
            strides=(1, 2, 1),
            padding='SAME',
            data_format='NWC',
            dilation_rate=(1, 1, 1),
            W_init=tl.initializers.truncated_normal(stddev=0.02),
            b_init=tl.initializers.constant(value=0.0),
            name=None  # 'decnn1d_layer',
    ):
        super().__init__(name, act=act)
        self.shape = shape
        self.outputs_shape = outputs_shape
        self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = self.shape[-1]

        self.build(None)
        self._built = True

        logging.info(
            "DeConv1dLayer %s: shape: %s out_shape: %s strides: %s pad: %s act: %s" % (
                self.name, str(shape), str(outputs_shape), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/simplified_deconv.py" startline="188" endline="225" pcid="1167">
    def __init__(
            self,
            n_filter=32,
            filter_size=(3, 3, 3),
            strides=(2, 2, 2),
            padding='SAME',
            act=None,
            data_format='channels_last',
            W_init=tl.initializers.truncated_normal(stddev=0.02),
            b_init=tl.initializers.constant(value=0.0),
            in_channels=None,
            name=None  # 'decnn3d'
    ):
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels,

        # Attention: To build, we need not only the in_channels!
        # if self.in_channels:
        #     self.build(None)
        #     self._built = True

        logging.info(
            "DeConv3d %s: n_filters: %s strides: %s pad: %s act: %s" % (
                self.name, str(n_filter), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

        if len(strides) != 3:
            raise ValueError("len(strides) should be 3, DeConv3d and DeConv3dLayer are different.")

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/deformable_conv.py" startline="73" endline="172" pcid="1132">
    def __init__(
            self,
            offset_layer=None,
            # shape=(3, 3, 1, 100),
            n_filter=32,
            filter_size=(3, 3),
            act=None,
            padding='SAME',
            W_init=tl.initializers.truncated_normal(stddev=0.02),
            b_init=tl.initializers.constant(value=0.0),
            in_channels=None,
            name=None  # 'deformable_conv_2d',
    ):
        super().__init__(name, act=act)

        self.offset_layer = offset_layer
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.padding = padding
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        self.kernel_n = filter_size[0] * filter_size[1]
        if self.offset_layer.get_shape()[-1] != 2 * self.kernel_n:
            raise AssertionError("offset.get_shape()[-1] is not equal to: %d" % 2 * self.kernel_n)

        logging.info(
            "DeformableConv2d %s: n_filter: %d, filter_size: %s act: %s" % (
                self.name, self.n_filter, str(self.filter_size
                                             ), self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

        # try:
        #     pre_channel = int(prev_layer.outputs.get_shape()[-1])
        # except Exception:  # if pre_channel is ?, it happens when using Spatial Transformer Net
        #     pre_channel = 1
        #     logging.info("[warnings] unknow input channels, set to 1")
        # shape = (filter_size[0], filter_size[1], pre_channel, n_filter)

        # with tf.compat.v1.variable_scope(name):
        #     offset = self.offset_layer # .outputs
        #
        #     # if offset.get_shape()[-1] != 2 * shape[0] * shape[1]:
        #     #     raise AssertionError("offset.get_shape()[-1] is not equal to: %d" % 2 * shape[0] * shape[1])
        #
        #     # Grid initialisation
        #     input_h = int(self.inputs.get_shape()[1])
        #     input_w = int(self.inputs.get_shape()[2])
        #     # kernel_n = shape[0] * shape[1]
        #     initial_offsets = tf.stack(
        #         tf.meshgrid(tf.range(shape[0]), tf.range(shape[1]), indexing='ij')
        #     )  # initial_offsets --> (kh, kw, 2)
        #     initial_offsets = tf.reshape(initial_offsets, (-1, 2))  # initial_offsets --> (n, 2)
        #     initial_offsets = tf.expand_dims(initial_offsets, 0)  # initial_offsets --> (1, n, 2)
        #     initial_offsets = tf.expand_dims(initial_offsets, 0)  # initial_offsets --> (1, 1, n, 2)
        #     initial_offsets = tf.tile(initial_offsets, [input_h, input_w, 1, 1])  # initial_offsets --> (h, w, n, 2)
        #     initial_offsets = tf.cast(initial_offsets, 'float32')
        #     grid = tf.meshgrid(
        #         tf.range(-int((shape[0] - 1) / 2.0), int(input_h - int((shape[0] - 1) / 2.0)), 1),
        #         tf.range(-int((shape[1] - 1) / 2.0), int(input_w - int((shape[1] - 1) / 2.0)), 1), indexing='ij'
        #     )
        #
        #     grid = tf.stack(grid, axis=-1)
        #     grid = tf.cast(grid, 'float32')  # grid --> (h, w, 2)
        #     grid = tf.expand_dims(grid, 2)  # grid --> (h, w, 1, 2)
        #     grid = tf.tile(grid, [1, 1, self.kernel_n, 1])  # grid --> (h, w, n, 2)
        #     grid_offset = grid + initial_offsets  # grid_offset --> (h, w, n, 2)
        #
        #     input_deform = self._tf_batch_map_offsets(self.inputs, offset, grid_offset)
        #
        #     # W = tf.compat.v1.get_variable(
        #     #     name='W_deformableconv2d', shape=[1, 1, shape[0] * shape[1], shape[-2], shape[-1]], initializer=W_init,
        #     #     dtype=LayersConfig.tf_dtype,
        #     # )
        #
        #     # _tensor = tf.nn.conv3d(input_deform, W, strides=[1, 1, 1, 1, 1], padding='VALID', name=None)
        #     # _tensor = tf.nn.conv3d(
        #     #     input=input_deform,
        #     #     filters=W,
        #     #     strides=[1, 1, 1, 1, 1],
        #     #     padding='VALID',
        #     #     name=None
        #     # )
        #
        #     # if b_init:
        #     #     b = tf.compat.v1.get_variable(
        #     #         name='b_deformableconv2d', shape=(shape[-1]), initializer=b_init, # dtype=LayersConfig.tf_dtype,
        #     #     )
        #     #
        #     #     _tensor = tf.nn.bias_add(_tensor, b, name='bias_add')
        #
        #     # self.outputs = tf.reshape(
        #     #     tensor=self._apply_activation(_tensor),
        #     #     shape=[tf.shape(input=self.inputs)[0], input_h, input_w, shape[-1]]
        #     # )
        #
        # # self._add_layers(self.outputs)

</source>
</class>

<class classid="43" nclones="20" nlines="13" similarity="80">
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/ternary_conv.py" startline="107" endline="122" pcid="1095">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/simplified_deconv.py" startline="104" endline="119" pcid="1164">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/simplified_conv.py" startline="95" endline="110" pcid="1184">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', stride={stride}, padding={padding}'
        )
        if self.dilation_rate != 1:
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/dorefa_conv.py" startline="115" endline="130" pcid="1119">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/deformable_conv.py" startline="173" endline="186" pcid="1133">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', padding={padding}'
        )
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/simplified_deconv.py" startline="226" endline="241" pcid="1168">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        # if self.dilation_rate != (1,) * len(self.dilation_rate):
        #     s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/separable_conv.py" startline="107" endline="122" pcid="1176">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', stride={strides}, padding={padding}'
        )
        if self.dilation_rate != 1:
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/separable_conv.py" startline="254" endline="269" pcid="1180">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', stride={strides}, padding={padding}'
        )
        if self.dilation_rate != 1:
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/depthwise_conv.py" startline="107" endline="124" pcid="1148">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(
            classname=self.__class__.__name__, n_filter=self.in_channels * self.depth_multiplier, **self.__dict__
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/simplified_conv.py" startline="358" endline="373" pcid="1192">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/quan_conv.py" startline="116" endline="131" pcid="1172">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/expert_conv.py" startline="96" endline="111" pcid="1103">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', stride={stride}, padding={padding}'
        )
        if self.dilation_rate != 1:
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/simplified_conv.py" startline="225" endline="240" pcid="1188">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/binary_conv.py" startline="107" endline="122" pcid="1099">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/expert_deconv.py" startline="104" endline="121" pcid="1152">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(
            classname=self.__class__.__name__, n_filter=self.shape[-2], filter_size=self.shape[0], **self.__dict__
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/group_conv.py" startline="99" endline="114" pcid="1144">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/expert_conv.py" startline="215" endline="232" pcid="1107">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != [
                1,
        ] * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/expert_conv.py" startline="333" endline="350" pcid="1111">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != [
                1,
        ] * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/expert_deconv.py" startline="238" endline="256" pcid="1156">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(
            classname=self.__class__.__name__, n_filter=self.shape[-2], filter_size=(self.shape[0], self.shape[1]),
            **self.__dict__
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/expert_deconv.py" startline="364" endline="382" pcid="1160">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(
            classname=self.__class__.__name__, n_filter=self.shape[-2],
            filter_size=(self.shape[0], self.shape[1], self.shape[2]), **self.__dict__
        )

</source>
</class>

<class classid="44" nclones="8" nlines="19" similarity="70">
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/ternary_conv.py" startline="123" endline="144" pcid="1096">
    def build(self, inputs_shape):
        if self.data_format == 'channels_last':
            self.data_format = 'NHWC'
            if self.in_channels is None:
                self.in_channels = inputs_shape[-1]
            self._strides = [1, self._strides[0], self._strides[1], 1]
            self._dilation_rate = [1, self._dilation_rate[0], self._dilation_rate[1], 1]
        elif self.data_format == 'channels_first':
            self.data_format = 'NCHW'
            if self.in_channels is None:
                self.in_channels = inputs_shape[1]
            self._strides = [1, 1, self._strides[0], self._strides[1]]
            self._dilation_rate = [1, 1, self._dilation_rate[0], self._dilation_rate[1]]
        else:
            raise Exception("data_format should be either channels_last or channels_first")

        self.filter_shape = (self.filter_size[0], self.filter_size[1], self.in_channels, self.n_filter)

        self.W = self._get_weights("filters", shape=self.filter_shape, init=self.W_init)
        if self.b_init:
            self.b = self._get_weights("biases", shape=(self.n_filter, ), init=self.b_init)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/dorefa_conv.py" startline="131" endline="152" pcid="1120">
    def build(self, inputs_shape):
        if self.data_format == 'channels_last':
            self.data_format = 'NHWC'
            if self.in_channels is None:
                self.in_channels = inputs_shape[-1]
            self._strides = [1, self._strides[0], self._strides[1], 1]
            self._dilation_rate = [1, self._dilation_rate[0], self._dilation_rate[1], 1]
        elif self.data_format == 'channels_first':
            self.data_format = 'NCHW'
            if self.in_channels is None:
                self.in_channels = inputs_shape[1]
            self._strides = [1, 1, self._strides[0], self._strides[1]]
            self._dilation_rate = [1, 1, self._dilation_rate[0], self._dilation_rate[1]]
        else:
            raise Exception("data_format should be either channels_last or channels_first")

        self.filter_shape = (self.filter_size[0], self.filter_size[1], self.in_channels, self.n_filter)

        self.W = self._get_weights("filters", shape=self.filter_shape, init=self.W_init)
        if self.b_init:
            self.b = self._get_weights("biases", shape=(self.n_filter, ), init=self.b_init)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/group_conv.py" startline="115" endline="144" pcid="1145">
    def build(self, inputs_shape):

        if self.data_format == 'channels_last':
            self.data_format = 'NHWC'
            if self.in_channels is None:
                self.in_channels = inputs_shape[-1]
            self._strides = [1, self._strides[0], self._strides[1], 1]
            self._dilation_rate = [1, self._dilation_rate[0], self._dilation_rate[1], 1]
        elif self.data_format == 'channels_first':
            self.data_format = 'NCHW'
            if self.in_channels is None:
                self.in_channels = inputs_shape[1]
            self._strides = [1, 1, self._strides[0], self._strides[1]]
            self._dilation_rate = [1, 1, self._dilation_rate[0], self._dilation_rate[1]]
        else:
            raise Exception("data_format should be either channels_last or channels_first")

        self.groupConv = lambda i, k: tf.nn.conv2d(
            i, k, strides=self._strides, padding=self.padding, data_format=self.data_format, dilations=self.
            _dilation_rate, name=self.name
        )

        self.filter_shape = (
            self.filter_size[0], self.filter_size[1], int(self.in_channels / self.n_group), self.n_filter
        )

        self.We = self._get_weights("filters", shape=self.filter_shape, init=self.W_init)
        if self.b_init:
            self.b = self._get_weights("biases", shape=self.n_filter, init=self.b_init)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/simplified_conv.py" startline="374" endline="398" pcid="1193">
    def build(self, inputs_shape):
        if self.data_format == 'channels_last':
            self.data_format = 'NDHWC'
            if self.in_channels is None:
                self.in_channels = inputs_shape[-1]
            self._strides = [1, self._strides[0], self._strides[1], self._strides[2], 1]
            self._dilation_rate = [1, self.dilation_rate[0], self.dilation_rate[1], self.dilation_rate[2], 1]
        elif self.data_format == 'channels_first':
            self.data_format = 'NCDHW'
            if self.in_channels is None:
                self.in_channels = inputs_shape[1]
            self._strides = [1, 1, self._strides[0], self._strides[1], self._strides[2]]
            self._dilation_rate = [1, 1, self._dilation_rate[0], self._dilation_rate[1], self._dilation_rate[2]]
        else:
            raise Exception("data_format should be either channels_last or channels_first")

        self.filter_shape = (
            self.filter_size[0], self.filter_size[1], self.filter_size[2], self.in_channels, self.n_filter
        )

        self.W = self._get_weights("filters", shape=self.filter_shape, init=self.W_init)

        if self.b_init:
            self.b = self._get_weights("biases", shape=(self.n_filter, ), init=self.b_init)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/depthwise_conv.py" startline="125" endline="147" pcid="1149">
    def build(self, inputs_shape):
        if self.data_format == 'channels_last':
            self.data_format = 'NHWC'
            if self.in_channels is None:
                self.in_channels = inputs_shape[-1]
            self._strides = [1, self._strides[0], self._strides[1], 1]
            self._dilation_rate = [1, self._dilation_rate[0], self._dilation_rate[1], 1]
        elif self.data_format == 'channels_first':
            self.data_format = 'NCHW'
            if self.in_channels is None:
                self.in_channels = inputs_shape[1]
            self._strides = [1, 1, self._strides[0], self._strides[1]]
            self._dilation_rate = [1, 1, self._dilation_rate[0], self._dilation_rate[1]]
        else:
            raise Exception("data_format should be either channels_last or channels_first")

        self.filter_shape = (self.filter_size[0], self.filter_size[1], self.in_channels, self.depth_multiplier)

        self.W = self._get_weights("filters", shape=self.filter_shape, init=self.W_init)

        if self.b_init:
            self.b = self._get_weights("biases", shape=(self.in_channels * self.depth_multiplier), init=self.b_init)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/quan_conv.py" startline="132" endline="153" pcid="1173">
    def build(self, inputs_shape):
        if self.data_format == 'channels_last':
            self.data_format = 'NHWC'
            if self.in_channels is None:
                self.in_channels = inputs_shape[-1]
            self._strides = [1, self._strides[0], self._strides[1], 1]
            self._dilation_rate = [1, self._dilation_rate[0], self._dilation_rate[1], 1]
        elif self.data_format == 'channels_first':
            self.data_format = 'NCHW'
            if self.in_channels is None:
                self.in_channels = inputs_shape[1]
            self._strides = [1, 1, self._strides[0], self._strides[1]]
            self._dilation_rate = [1, 1, self._dilation_rate[0], self._dilation_rate[1]]
        else:
            raise Exception("data_format should be either channels_last or channels_first")

        self.filter_shape = (self.filter_size[0], self.filter_size[1], self.in_channels, self.n_filter)

        self.W = self._get_weights("filters", shape=self.filter_shape, init=self.W_init)
        if self.b_init:
            self.b = self._get_weights("biases", shape=(self.n_filter, ), init=self.b_init)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/binary_conv.py" startline="123" endline="144" pcid="1100">
    def build(self, inputs_shape):
        if self.data_format == 'channels_last':
            self.data_format = 'NHWC'
            if self.in_channels is None:
                self.in_channels = inputs_shape[-1]
            self._strides = [1, self._strides[0], self._strides[1], 1]
            self._dilation_rate = [1, self._dilation_rate[0], self._dilation_rate[1], 1]
        elif self.data_format == 'channels_first':
            self.data_format = 'NCHW'
            if self.in_channels is None:
                self.in_channels = inputs_shape[1]
            self._strides = [1, 1, self._strides[0], self._strides[1]]
            self._dilation_rate = [1, 1, self._dilation_rate[0], self._dilation_rate[1]]
        else:
            raise Exception("data_format should be either channels_last or channels_first")

        self.filter_shape = (self.filter_size[0], self.filter_size[1], self.in_channels, self.n_filter)

        self.W = self._get_weights("filters", shape=self.filter_shape, init=self.W_init)
        if self.b_init:
            self.b = self._get_weights("biases", shape=(self.n_filter, ), init=self.b_init)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/simplified_conv.py" startline="241" endline="263" pcid="1189">
    def build(self, inputs_shape):
        if self.data_format == 'channels_last':
            self.data_format = 'NHWC'
            if self.in_channels is None:
                self.in_channels = inputs_shape[-1]
            self._strides = [1, self._strides[0], self._strides[1], 1]
            self._dilation_rate = [1, self._dilation_rate[0], self._dilation_rate[1], 1]
        elif self.data_format == 'channels_first':
            self.data_format = 'NCHW'
            if self.in_channels is None:
                self.in_channels = inputs_shape[1]
            self._strides = [1, 1, self._strides[0], self._strides[1]]
            self._dilation_rate = [1, 1, self._dilation_rate[0], self._dilation_rate[1]]
        else:
            raise Exception("data_format should be either channels_last or channels_first")

        self.filter_shape = (self.filter_size[0], self.filter_size[1], self.in_channels, self.n_filter)

        self.W = self._get_weights("filters", shape=self.filter_shape, init=self.W_init)

        if self.b_init:
            self.b = self._get_weights("biases", shape=(self.n_filter, ), init=self.b_init)

</source>
</class>

<class classid="45" nclones="4" nlines="11" similarity="75">
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/ternary_conv.py" startline="145" endline="162" pcid="1097">
    def forward(self, inputs):

        alpha = compute_alpha(self.W)

        W_ = ternary_operation(self.W)
        W_ = tf.multiply(alpha, W_)

        outputs = tf.nn.conv2d(
            input=inputs, filters=W_, strides=self._strides, padding=self.padding, data_format=self.data_format,
            dilations=self._dilation_rate, name=self.name
        )

        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)

        return outputs
</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/dorefa_conv.py" startline="153" endline="169" pcid="1121">
    def forward(self, inputs):

        inputs = quantize_active(cabs(inputs), self.bitA)  # Do not remove

        W_ = quantize_weight(self.W, self.bitW)

        outputs = tf.nn.conv2d(
            input=inputs, filters=W_, strides=self._strides, padding=self.padding, data_format=self.data_format,
            dilations=self._dilation_rate, name=self.name
        )

        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)

        return outputs
</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/binary_conv.py" startline="145" endline="159" pcid="1101">
    def forward(self, inputs):

        _W = quantize(self.W)

        outputs = tf.nn.conv2d(
            input=inputs, filters=_W, strides=self._strides, padding=self.padding, data_format=self.data_format,
            dilations=self._dilation_rate, name=self.name
        )

        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)

        return outputs
</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/quan_conv.py" startline="154" endline="170" pcid="1174">
    def forward(self, inputs):

        inputs = quantize_active_overflow(inputs, self.bitA)  # Do not remove

        W_ = quantize_weight_overflow(self.W, self.bitW)

        outputs = tf.nn.conv2d(
            input=inputs, filters=W_, strides=self.strides, padding=self.padding, data_format=self.data_format,
            dilations=self._dilation_rate, name=self.name
        )

        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)

        return outputs
</source>
</class>

<class classid="46" nclones="13" nlines="14" similarity="73">
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/expert_conv.py" startline="117" endline="137" pcid="1105">
    def forward(self, inputs):

        outputs = tf.nn.conv1d(
            input=inputs,
            filters=self.W,
            stride=self.stride,
            padding=self.padding,
            dilations=[
                self.dilation_rate,
            ],
            data_format=self.data_format,
            name=self.name,
        )

        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs


</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/expert_conv.py" startline="357" endline="372" pcid="1113">
    def forward(self, inputs):
        outputs = tf.nn.conv3d(
            input=inputs,
            filters=self.W,
            strides=self.strides,
            padding=self.padding,
            data_format=self.data_format,  #'NDHWC',
            dilations=list(self.dilation_rate),  #[1, 1, 1, 1, 1],
            name=self.name,
        )

        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs
</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/expert_conv.py" startline="238" endline="255" pcid="1109">
    def forward(self, inputs):
        outputs = tf.nn.conv2d(
            input=inputs,
            filters=self.W,
            strides=self.strides,
            padding=self.padding,
            data_format=self.data_format,
            dilations=list(self.dilation_rate),
            name=self.name,
        )

        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs


</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/depthwise_conv.py" startline="148" endline="162" pcid="1150">
    def forward(self, inputs):
        outputs = tf.nn.depthwise_conv2d(
            input=inputs,
            filter=self.W,
            strides=self._strides,
            padding=self.padding,
            data_format=self.data_format,
            dilations=self.dilation_rate,
            name=self.name,
        )
        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs
</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/simplified_conv.py" startline="399" endline="413" pcid="1194">
    def forward(self, inputs):
        outputs = tf.nn.conv3d(
            input=inputs,
            filters=self.W,
            strides=self._strides,
            padding=self.padding,
            data_format=self.data_format,  #'NDHWC',
            dilations=self._dilation_rate,  #[1, 1, 1, 1, 1],
            name=self.name,
        )
        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs
</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/simplified_conv.py" startline="264" endline="280" pcid="1190">
    def forward(self, inputs):
        outputs = tf.nn.conv2d(
            input=inputs,
            filters=self.W,
            strides=self._strides,
            padding=self.padding,
            data_format=self.data_format,  #'NHWC',
            dilations=self._dilation_rate,  #[1, 1, 1, 1],
            name=self.name,
        )
        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs


</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/simplified_conv.py" startline="131" endline="147" pcid="1186">
    def forward(self, inputs):
        outputs = tf.nn.conv1d(
            input=inputs,
            filters=self.W,
            stride=self.stride,
            padding=self.padding,
            data_format=self.data_format,
            dilations=self.dilation_rate,
            name=self.name,
        )
        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs


</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/expert_deconv.py" startline="262" endline="279" pcid="1158">
    def forward(self, inputs):
        outputs = tf.nn.conv2d_transpose(
            input=inputs,
            filters=self.W,
            output_shape=self.outputs_shape,
            strides=self.strides,
            padding=self.padding,
            data_format=self.data_format,
            dilations=list(self.dilation_rate),
            name=self.name,
        )
        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs


</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/expert_deconv.py" startline="127" endline="144" pcid="1154">
    def forward(self, inputs):
        outputs = tf.nn.conv1d_transpose(
            input=inputs,
            filters=self.W,
            output_shape=self.outputs_shape,
            strides=list(self.strides),
            padding=self.padding,
            data_format=self.data_format,
            dilations=list(self.dilation_rate),
            name=self.name,
        )
        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs


</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/pooling.py" startline="169" endline="182" pcid="1381">
    def forward(self, inputs):
        outputs = tf.nn.pool(
            input=inputs,
            window_shape=self._filter_size,
            pooling_type="MAX",
            strides=self._strides,
            padding=self.padding,
            data_format=self.data_format,
            dilations=self._dilation_rate,
            name=self.name,
        )
        return outputs


</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/pooling.py" startline="565" endline="576" pcid="1401">
    def forward(self, inputs):
        outputs = tf.nn.avg_pool3d(
            input=inputs,
            ksize=self.filter_size,
            strides=self._strides,
            padding=self.padding,
            data_format=self.data_format,
            name=self.name,
        )
        return outputs


</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/pooling.py" startline="255" endline="268" pcid="1385">
    def forward(self, inputs):
        outputs = tf.nn.pool(
            input=inputs,
            window_shape=self._filter_size,
            pooling_type="AVG",
            padding=self.padding,
            dilations=None,  # TODO: support dilations
            strides=self._strides,
            name=self.name,
            data_format=self.data_format
        )
        return outputs


</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/pooling.py" startline="484" endline="495" pcid="1397">
    def forward(self, inputs):
        outputs = tf.nn.max_pool3d(
            input=inputs,
            ksize=self.filter_size,
            strides=self._strides,
            padding=self.padding,
            data_format=self.data_format,
            name=self.name,
        )
        return outputs


</source>
</class>

<class classid="47" nclones="2" nlines="83" similarity="70">
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/quan_conv_bn.py" startline="94" endline="220" pcid="1114">
    def __init__(
            self,
            prev_layer,
            n_filter=32,
            filter_size=(3, 3),
            strides=(1, 1),
            padding='SAME',
            act=None,
            decay=0.9,
            epsilon=1e-5,
            is_train=False,
            gamma_init=tf.compat.v1.initializers.ones,
            beta_init=tf.compat.v1.initializers.zeros,
            bitW=8,
            bitA=8,
            use_gemm=False,
            W_init=tf.compat.v1.initializers.truncated_normal(stddev=0.02),
            W_init_args=None,
            use_cudnn_on_gpu=None,
            data_format=None,
            name='quan_cnn2d_bn',
    ):
        super(QuanConv2dWithBN, self).__init__(prev_layer=prev_layer, act=act, W_init_args=W_init_args, name=name)

        logging.info(
            "QuanConv2dWithBN %s: n_filter: %d filter_size: %s strides: %s pad: %s act: %s " % (
                self.name, n_filter, filter_size, str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

        x = self.inputs
        self.inputs = quantize_active_overflow(self.inputs, bitA)  # Do not remove

        if use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        if len(strides) != 2:
            raise ValueError("len(strides) should be 2.")

        try:
            pre_channel = int(prev_layer.outputs.get_shape()[-1])
        except Exception:  # if pre_channel is ?, it happens when using Spatial Transformer Net
            pre_channel = 1
            logging.warning("[warnings] unknow input channels, set to 1")

        shape = (filter_size[0], filter_size[1], pre_channel, n_filter)
        strides = (1, strides[0], strides[1], 1)

        with tf.compat.v1.variable_scope(name):
            W = tf.compat.v1.get_variable(
                name='W_conv2d', shape=shape, initializer=W_init, dtype=LayersConfig.tf_dtype, **self.W_init_args
            )

            conv = tf.nn.conv2d(
                x, W, strides=strides, padding=padding, use_cudnn_on_gpu=use_cudnn_on_gpu, data_format=data_format
            )

            para_bn_shape = conv.get_shape()[-1:]

            if gamma_init:
                scale_para = tf.compat.v1.get_variable(
                    name='scale_para', shape=para_bn_shape, initializer=gamma_init, dtype=LayersConfig.tf_dtype,
                    trainable=is_train
                )
            else:
                scale_para = None

            if beta_init:
                offset_para = tf.compat.v1.get_variable(
                    name='offset_para', shape=para_bn_shape, initializer=beta_init, dtype=LayersConfig.tf_dtype,
                    trainable=is_train
                )
            else:
                offset_para = None

            moving_mean = tf.compat.v1.get_variable(
                'moving_mean', para_bn_shape, initializer=tf.compat.v1.initializers.constant(1.),
                dtype=LayersConfig.tf_dtype, trainable=False
            )

            moving_variance = tf.compat.v1.get_variable(
                'moving_variance',
                para_bn_shape,
                initializer=tf.compat.v1.initializers.constant(1.),
                dtype=LayersConfig.tf_dtype,
                trainable=False,
            )

            mean, variance = tf.nn.moments(x=conv, axes=list(range(len(conv.get_shape()) - 1)))

            update_moving_mean = moving_averages.assign_moving_average(
                moving_mean, mean, decay, zero_debias=False
            )  # if zero_debias=True, has bias

            update_moving_variance = moving_averages.assign_moving_average(
                moving_variance, variance, decay, zero_debias=False
            )  # if zero_debias=True, has bias

            def mean_var_with_update():
                with tf.control_dependencies([update_moving_mean, update_moving_variance]):
                    return tf.identity(mean), tf.identity(variance)

            if is_train:
                mean, var = mean_var_with_update()
            else:
                mean, var = moving_mean, moving_variance

            w_fold = _w_fold(W, scale_para, var, epsilon)
            bias_fold = _bias_fold(offset_para, scale_para, mean, var, epsilon)

            W = quantize_weight_overflow(w_fold, bitW)

            conv_fold = tf.nn.conv2d(
                self.inputs, W, strides=strides, padding=padding, use_cudnn_on_gpu=use_cudnn_on_gpu,
                data_format=data_format
            )

            self.outputs = tf.nn.bias_add(conv_fold, bias_fold, name='bn_bias_add')

            self.outputs = self._apply_activation(self.outputs)

        self._add_layers(self.outputs)

        self._add_params([W, scale_para, offset_para, moving_mean, moving_variance])


</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/dense/quan_dense_bn.py" startline="70" endline="182" pcid="1312">
    def __init__(
            self,
            prev_layer,
            n_units=100,
            act=None,
            decay=0.9,
            epsilon=1e-5,
            is_train=False,
            bitW=8,
            bitA=8,
            gamma_init=tf.compat.v1.initializers.ones,
            beta_init=tf.compat.v1.initializers.zeros,
            use_gemm=False,
            W_init=tf.compat.v1.initializers.truncated_normal(stddev=0.1),
            W_init_args=None,
            name=None,  #'quan_dense_with_bn',
    ):
        super(QuanDenseLayerWithBN, self).__init__(prev_layer=prev_layer, act=act, W_init_args=W_init_args, name=name)

        logging.info(
            "QuanDenseLayerWithBN  %s: %d %s" %
            (self.name, n_units, self.act.__name__ if self.act is not None else 'No Activation')
        )

        if self.inputs.get_shape().ndims != 2:
            raise Exception("The input dimension must be rank 2, please reshape or flatten it")

        if use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        n_in = int(self.inputs.get_shape()[-1])
        x = self.inputs
        self.inputs = quantize_active_overflow(self.inputs, bitA)
        self.n_units = n_units

        with tf.compat.v1.variable_scope(name):

            W = tf.compat.v1.get_variable(
                name='W', shape=(n_in, n_units), initializer=W_init, dtype=LayersConfig.tf_dtype, **self.W_init_args
            )

            mid_out = tf.matmul(x, W)

            para_bn_shape = mid_out.get_shape()[-1:]

            if gamma_init:
                scale_para = tf.compat.v1.get_variable(
                    name='scale_para', shape=para_bn_shape, initializer=gamma_init, dtype=LayersConfig.tf_dtype,
                    trainable=is_train
                )
            else:
                scale_para = None

            if beta_init:
                offset_para = tf.compat.v1.get_variable(
                    name='offset_para', shape=para_bn_shape, initializer=beta_init, dtype=LayersConfig.tf_dtype,
                    trainable=is_train
                )
            else:
                offset_para = None

            moving_mean = tf.compat.v1.get_variable(
                'moving_mean', para_bn_shape, initializer=tf.compat.v1.initializers.constant(1.),
                dtype=LayersConfig.tf_dtype, trainable=False
            )

            moving_variance = tf.compat.v1.get_variable(
                'moving_variance',
                para_bn_shape,
                initializer=tf.compat.v1.initializers.constant(1.),
                dtype=LayersConfig.tf_dtype,
                trainable=False,
            )

            mean, variance = tf.nn.moments(x=mid_out, axes=list(range(len(mid_out.get_shape()) - 1)))

            update_moving_mean = moving_averages.assign_moving_average(
                moving_mean, mean, decay, zero_debias=False
            )  # if zero_debias=True, has bias

            update_moving_variance = moving_averages.assign_moving_average(
                moving_variance, variance, decay, zero_debias=False
            )  # if zero_debias=True, has bias

            def mean_var_with_update():
                with tf.control_dependencies([update_moving_mean, update_moving_variance]):
                    return tf.identity(mean), tf.identity(variance)

            if is_train:
                mean, var = mean_var_with_update()
            else:
                mean, var = moving_mean, moving_variance

            w_fold = _w_fold(W, scale_para, var, epsilon)
            bias_fold = _bias_fold(offset_para, scale_para, mean, var, epsilon)

            W = quantize_weight_overflow(w_fold, bitW)
            # W = tl.act.sign(W)    # dont update ...

            # W = tf.Variable(W)

            self.outputs = tf.matmul(self.inputs, W)
            # self.outputs = xnor_gemm(self.inputs, W) # TODO

            self.outputs = tf.nn.bias_add(self.outputs, bias_fold, name='bias_add')

            self.outputs = self._apply_activation(self.outputs)

        self._add_layers(self.outputs)

        self._add_params([W, scale_para, offset_para, moving_mean, moving_variance])


</source>
</class>

<class classid="48" nclones="8" nlines="21" similarity="72">
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/super_resolution.py" startline="49" endline="69" pcid="1122">
    def __init__(
            self,
            scale=2,
            act=None,
            in_channels=None,
            name=None  # 'subpixel_conv1d'
    ):
        super().__init__(name, act=act)
        self.scale = scale
        self.in_channels = in_channels
        self.out_channels = int(self.in_channels / self.scale)

        if self.in_channels is not None:
            self.build(None)
            self._built = True

        logging.info(
            "SubpixelConv1d  %s: scale: %d act: %s" %
            (self.name, scale, self.act.__name__ if self.act is not None else 'No Activation')
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/super_resolution.py" startline="145" endline="165" pcid="1127">
    def __init__(
            self,
            scale=2,
            n_out_channels=None,
            act=None,
            in_channels=None,
            name=None  # 'subpixel_conv2d'
    ):
        super().__init__(name, act=act)
        self.scale = scale
        self.n_out_channels = n_out_channels
        self.in_channels = in_channels

        if self.in_channels is not None:
            self.build(None)
            self._built = True
        logging.info(
            "SubpixelConv2d  %s: scale: %d act: %s" %
            (self.name, scale, self.act.__name__ if self.act is not None else 'No Activation')
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/dense/binary_dense.py" startline="42" endline="67" pcid="1308">
    def __init__(
            self,
            n_units=100,
            act=None,
            use_gemm=False,
            W_init=tl.initializers.truncated_normal(stddev=0.1),
            b_init=tl.initializers.constant(value=0.0),
            in_channels=None,
            name=None,  #'binary_dense',
    ):
        super().__init__(name, act=act)
        self.n_units = n_units
        self.use_gemm = use_gemm
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels is not None:
            self.build((None, self.in_channels))
            self._built = True

        logging.info(
            "BinaryDense  %s: %d %s" %
            (self.name, n_units, self.act.__name__ if self.act is not None else 'No Activation')
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/dense/ternary_dense.py" startline="42" endline="67" pcid="1292">
    def __init__(
            self,
            n_units=100,
            act=None,
            use_gemm=False,
            W_init=tl.initializers.truncated_normal(stddev=0.1),
            b_init=tl.initializers.constant(value=0.0),
            in_channels=None,
            name=None,  #'ternary_dense',
    ):
        super().__init__(name, act=act)
        self.n_units = n_units
        self.use_gemm = use_gemm
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels is not None:
            self.build((None, self.in_channels))
            self._built = True

        logging.info(
            "TernaryDense  %s: %d %s" %
            (self.name, n_units, self.act.__name__ if self.act is not None else 'No Activation')
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/dense/dorefa_dense.py" startline="47" endline="76" pcid="1288">
    def __init__(
            self,
            bitW=1,
            bitA=3,
            n_units=100,
            act=None,
            use_gemm=False,
            W_init=tl.initializers.truncated_normal(stddev=0.1),
            b_init=tl.initializers.constant(value=0.0),
            in_channels=None,
            name=None,  #'dorefa_dense',
    ):
        super().__init__(name, act=act)
        self.bitW = bitW
        self.bitA = bitA
        self.n_units = n_units
        self.use_gemm = use_gemm
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels is not None:
            self.build((None, self.in_channels))
            self._built = True

        logging.info(
            "DorefaDense  %s: %d %s" %
            (self.name, n_units, self.act.__name__ if self.act is not None else 'No Activation')
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/dense/quan_dense.py" startline="45" endline="74" pcid="1300">
    def __init__(
            self,
            n_units=100,
            act=None,
            bitW=8,
            bitA=8,
            use_gemm=False,
            W_init=tl.initializers.truncated_normal(stddev=0.1),
            b_init=tl.initializers.constant(value=0.0),
            in_channels=None,
            name=None,  #'quan_dense',
    ):
        super().__init__(name, act=act)
        self.n_units = n_units
        self.bitW = bitW
        self.bitA = bitA
        self.use_gemm = use_gemm
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels is not None:
            self.build((None, self.in_channels))
            self._built = True

        logging.info(
            "QuanDense  %s: %d %s" %
            (self.name, n_units, self.act.__name__ if self.act is not None else 'No Activation')
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/dense/base_dense.py" startline="56" endline="81" pcid="1304">
    def __init__(
            self,
            n_units,
            act=None,
            W_init=tl.initializers.truncated_normal(stddev=0.1),
            b_init=tl.initializers.constant(value=0.0),
            in_channels=None,
            name=None,  # 'dense',
    ):

        super(Dense, self).__init__(name, act=act)

        self.n_units = n_units
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels is not None:
            self.build(self.in_channels)
            self._built = True

        logging.info(
            "Dense  %s: %d %s" %
            (self.name, self.n_units, self.act.__name__ if self.act is not None else 'No Activation')
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/dense/dropconnect.py" startline="58" endline="87" pcid="1296">
    def __init__(
            self,
            keep=0.5,
            n_units=100,
            act=None,
            W_init=tl.initializers.truncated_normal(stddev=0.1),
            b_init=tl.initializers.constant(value=0.0),
            in_channels=None,
            name=None,  # 'dropconnect',
    ):
        super().__init__(name, act=act)

        if isinstance(keep, numbers.Real) and not (keep > 0 and keep <= 1):
            raise ValueError("keep must be a scalar tensor or a float in the " "range (0, 1], got %g" % keep)

        self.keep = keep
        self.n_units = n_units
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels is not None:
            self.build((None, self.in_channels))
            self._built = True

        logging.info(
            "DropconnectDense %s: %d %s" %
            (self.name, n_units, self.act.__name__ if self.act is not None else 'No Activation')
        )

</source>
</class>

<class classid="49" nclones="4" nlines="22" similarity="83">
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/simplified_deconv.py" startline="120" endline="144" pcid="1165">
    def build(self, inputs_shape):
        self.layer = tf.keras.layers.Conv2DTranspose(
            filters=self.n_filter,
            kernel_size=self.filter_size,
            strides=self.strides,
            padding=self.padding,
            data_format=self.data_format,
            dilation_rate=self.dilation_rate,
            activation=self.act,
            use_bias=(True if self.b_init is not None else False),
            kernel_initializer=self.W_init,
            bias_initializer=self.b_init,
            # dtype=tf.float32,
            name=self.name,
        )
        if self.data_format == "channels_first":
            self.in_channels = inputs_shape[1]
        else:
            self.in_channels = inputs_shape[-1]
        _out = self.layer(
            tf.convert_to_tensor(np.random.uniform(size=inputs_shape), dtype=np.float32)
        )  #np.random.uniform([1] + list(inputs_shape)))  # initialize weights
        outputs_shape = _out.shape
        self._trainable_weights = self.layer.weights

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/separable_conv.py" startline="123" endline="159" pcid="1177">
    def build(self, inputs_shape):
        self.layer = tf.keras.layers.SeparableConv1D(
            filters=self.n_filter,
            kernel_size=self.filter_size,
            strides=self.strides,
            padding=self.padding,
            data_format=self.data_format,
            dilation_rate=self.dilation_rate,
            depth_multiplier=self.depth_multiplier,
            activation=self.act,
            use_bias=(True if self.b_init is not None else False),
            depthwise_initializer=self.depthwise_init,
            pointwise_initializer=self.pointwise_init,
            bias_initializer=self.b_init,
            # depthwise_regularizer=None,
            # pointwise_regularizer=None,
            # bias_regularizer=None,
            # activity_regularizer=None,
            # depthwise_constraint=None,
            # pointwise_constraint=None,
            # bias_constraint=None,
            trainable=True,
            name=self.name
        )
        if self.data_format == "channels_first":
            self.in_channels = inputs_shape[1]
        else:
            self.in_channels = inputs_shape[-1]

        # _out = self.layer(np.random.uniform([1] + list(inputs_shape)))  # initialize weights
        _out = self.layer(
            tf.convert_to_tensor(np.random.uniform(size=list(inputs_shape)), dtype=np.float)
        )  # initialize weights
        outputs_shape = _out.shape
        # self._add_weights(self.layer.weights)
        self._trainable_weights = self.layer.weights

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/separable_conv.py" startline="270" endline="304" pcid="1181">
    def build(self, inputs_shape):
        self.layer = tf.keras.layers.SeparableConv2D(
            filters=self.n_filter,
            kernel_size=self.filter_size,
            strides=self.strides,
            padding=self.padding,
            data_format=self.data_format,
            dilation_rate=self.dilation_rate,
            depth_multiplier=self.depth_multiplier,
            activation=self.act,
            use_bias=(True if self.b_init is not None else False),
            depthwise_initializer=self.depthwise_init,
            pointwise_initializer=self.pointwise_init,
            bias_initializer=self.b_init,
            # depthwise_regularizer=None,
            # pointwise_regularizer=None,
            # bias_regularizer=None,
            # activity_regularizer=None,
            # depthwise_constraint=None,
            # pointwise_constraint=None,
            # bias_constraint=None,
            trainable=True,
            name=self.name
        )
        if self.data_format == "channels_first":
            self.in_channels = inputs_shape[1]
        else:
            self.in_channels = inputs_shape[-1]
        # _out = self.layer(np.random.uniform([1] + list(inputs_shape)))  # initialize weights
        _out = self.layer(
            tf.convert_to_tensor(np.random.uniform(size=list(inputs_shape)), dtype=np.float)
        )  # initialize weights
        outputs_shape = _out.shape
        self._trainable_weights = self.layer.weights

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/convolution/simplified_deconv.py" startline="242" endline="266" pcid="1169">
    def build(self, inputs_shape):
        self.layer = tf.keras.layers.Conv3DTranspose(
            filters=self.n_filter,
            kernel_size=self.filter_size,
            strides=self.strides,
            padding=self.padding,
            data_format=self.data_format,
            activation=self.act,
            use_bias=(True if self.b_init is not None else False),
            kernel_initializer=self.W_init,
            bias_initializer=self.b_init,
            name=self.name,
        )
        if self.data_format == "channels_first":
            self.in_channels = inputs_shape[1]
        else:
            self.in_channels = inputs_shape[-1]

        _out = self.layer(
            tf.convert_to_tensor(np.random.uniform(size=inputs_shape), dtype=np.float32)
        )  #self.layer(np.random.uniform([1] + list(inputs_shape)))  # initialize weights
        outputs_shape = _out.shape
        # self._add_weights(self.layer.weights)
        self._trainable_weights = self.layer.weights

</source>
</class>

<class classid="50" nclones="2" nlines="12" similarity="91">
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/normalization.py" startline="235" endline="249" pcid="1214">
    def _get_param_shape(self, inputs_shape):
        if self.data_format == 'channels_last':
            axis = len(inputs_shape) - 1
        elif self.data_format == 'channels_first':
            axis = 1
        else:
            raise ValueError('data_format should be either %s or %s' % ('channels_last', 'channels_first'))

        channels = inputs_shape[axis]
        params_shape = [1] * len(inputs_shape)
        params_shape[axis] = channels

        axes = [i for i in range(len(inputs_shape)) if i != axis]
        return params_shape, axes

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/normalization.py" startline="473" endline="487" pcid="1222">
    def _get_param_shape(self, inputs_shape):
        if self.data_format == 'channels_last':
            axis = len(inputs_shape) - 1
        elif self.data_format == 'channels_first':
            axis = 1
        else:
            raise ValueError('data_format should be either %s or %s' % ('channels_last', 'channels_first'))

        channels = inputs_shape[axis]
        params_shape = [1] * len(inputs_shape)
        params_shape[axis] = channels

        axes = [i for i in range(len(inputs_shape)) if i != 0 and i != axis]
        return params_shape, axes

</source>
</class>

<class classid="51" nclones="6" nlines="15" similarity="93">
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/normalization.py" startline="303" endline="321" pcid="1217">
    def _get_param_shape(self, inputs_shape):
        if self.data_format == 'channels_last':
            axis = 2
        elif self.data_format == 'channels_first':
            axis = 1
        else:
            raise ValueError('data_format should be either %s or %s' % ('channels_last', 'channels_first'))

        if self.num_features is None:
            channels = inputs_shape[axis]
        else:
            channels = self.num_features
        params_shape = [1] * 3
        params_shape[axis] = channels

        axes = [i for i in range(3) if i != axis]
        return params_shape, axes


</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/normalization.py" startline="377" endline="395" pcid="1219">
    def _get_param_shape(self, inputs_shape):
        if self.data_format == 'channels_last':
            axis = 4
        elif self.data_format == 'channels_first':
            axis = 1
        else:
            raise ValueError('data_format should be either %s or %s' % ('channels_last', 'channels_first'))

        if self.num_features is None:
            channels = inputs_shape[axis]
        else:
            channels = self.num_features
        params_shape = [1] * 5
        params_shape[axis] = channels

        axes = [i for i in range(5) if i != axis]
        return params_shape, axes


</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/normalization.py" startline="340" endline="358" pcid="1218">
    def _get_param_shape(self, inputs_shape):
        if self.data_format == 'channels_last':
            axis = 3
        elif self.data_format == 'channels_first':
            axis = 1
        else:
            raise ValueError('data_format should be either %s or %s' % ('channels_last', 'channels_first'))

        if self.num_features is None:
            channels = inputs_shape[axis]
        else:
            channels = self.num_features
        params_shape = [1] * 4
        params_shape[axis] = channels

        axes = [i for i in range(4) if i != axis]
        return params_shape, axes


</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/normalization.py" startline="524" endline="542" pcid="1225">
    def _get_param_shape(self, inputs_shape):
        if self.data_format == 'channels_last':
            axis = 2
        elif self.data_format == 'channels_first':
            axis = 1
        else:
            raise ValueError('data_format should be either %s or %s' % ('channels_last', 'channels_first'))

        if self.num_features is None:
            channels = inputs_shape[axis]
        else:
            channels = self.num_features
        params_shape = [1] * 3
        params_shape[axis] = channels

        axes = [i for i in range(3) if i != 0 and i != axis]
        return params_shape, axes


</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/normalization.py" startline="598" endline="617" pcid="1227">
    def _get_param_shape(self, inputs_shape):
        if self.data_format == 'channels_last':
            axis = 4
        elif self.data_format == 'channels_first':
            axis = 1
        else:
            raise ValueError('data_format should be either %s or %s' % ('channels_last', 'channels_first'))

        if self.num_features is None:
            channels = inputs_shape[axis]
        else:
            channels = self.num_features
        params_shape = [1] * 5
        params_shape[axis] = channels

        axes = [i for i in range(5) if i != 0 and i != axis]
        return params_shape, axes


# FIXME : not sure about the correctness, need testing
</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/normalization.py" startline="561" endline="579" pcid="1226">
    def _get_param_shape(self, inputs_shape):
        if self.data_format == 'channels_last':
            axis = 3
        elif self.data_format == 'channels_first':
            axis = 1
        else:
            raise ValueError('data_format should be either %s or %s' % ('channels_last', 'channels_first'))

        if self.num_features is None:
            channels = inputs_shape[axis]
        else:
            channels = self.num_features
        params_shape = [1] * 4
        params_shape[axis] = channels

        axes = [i for i in range(4) if i != 0 and i != axis]
        return params_shape, axes


</source>
</class>

<class classid="52" nclones="2" nlines="10" similarity="70">
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/stack.py" startline="40" endline="51" pcid="1280">
    def __init__(
            self,
            axis=1,
            name=None,  #'stack',
    ):
        super().__init__(name)
        self.axis = axis

        self.build(None)
        self._built = True
        logging.info("Stack %s: axis: %d" % (self.name, self.axis))

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/merge.py" startline="42" endline="55" pcid="1316">
    def __init__(
            self,
            concat_dim=-1,
            name=None,  #'concat',
    ):

        super(Concat, self).__init__(name)
        self.concat_dim = concat_dim

        self.build(None)
        self._built = True

        logging.info("Concat %s: concat_dim: %d" % (self.name, concat_dim))

</source>
</class>

<class classid="53" nclones="3" nlines="10" similarity="100">
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/dense/dorefa_dense.py" startline="77" endline="87" pcid="1289">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = ('{classname}(n_units={n_units}, ' + actstr)
        s += ', bitW={bitW}, bitA={bitA}'
        if self.in_channels is not None:
            s += ', in_channels=\'{in_channels}\''
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/dense/quan_dense.py" startline="75" endline="85" pcid="1301">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = ('{classname}(n_units={n_units}, ' + actstr)
        s += ', bitW={bitW}, bitA={bitA}'
        if self.in_channels is not None:
            s += ', in_channels=\'{in_channels}\''
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/dense/dropconnect.py" startline="88" endline="98" pcid="1297">
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = ('{classname}(n_units={n_units}, ' + actstr)
        s += ', keep={keep}'
        if self.in_channels is not None:
            s += ', in_channels=\'{in_channels}\''
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</source>
</class>

<class classid="54" nclones="4" nlines="11" similarity="81">
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/dense/dorefa_dense.py" startline="88" endline="102" pcid="1290">
    def build(self, inputs_shape):
        if len(inputs_shape) != 2:
            raise Exception("The input dimension must be rank 2, please reshape or flatten it")

        if self.in_channels is None:
            self.in_channels = inputs_shape[1]

        if self.use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        n_in = inputs_shape[-1]
        self.W = self._get_weights("weights", shape=(n_in, self.n_units), init=self.W_init)
        if self.b_init is not None:
            self.b = self._get_weights("biases", shape=(self.n_units), init=self.b_init)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/dense/binary_dense.py" startline="78" endline="92" pcid="1310">
    def build(self, inputs_shape):
        if len(inputs_shape) != 2:
            raise Exception("The input dimension must be rank 2, please reshape or flatten it")

        if self.in_channels is None:
            self.in_channels = inputs_shape[1]

        if self.use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        n_in = inputs_shape[-1]
        self.W = self._get_weights("weights", shape=(n_in, self.n_units), init=self.W_init)
        if self.b_init is not None:
            self.b = self._get_weights("biases", shape=(self.n_units), init=self.b_init)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/dense/quan_dense.py" startline="86" endline="100" pcid="1302">
    def build(self, inputs_shape):
        if len(inputs_shape) != 2:
            raise Exception("The input dimension must be rank 2, please reshape or flatten it")

        if self.in_channels is None:
            self.in_channels = inputs_shape[1]

        if self.use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        n_in = inputs_shape[-1]
        self.W = self._get_weights("weights", shape=(n_in, self.n_units), init=self.W_init)
        if self.b_init is not None:
            self.b = self._get_weights("biases", shape=int(self.n_units), init=self.b_init)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/dense/ternary_dense.py" startline="78" endline="93" pcid="1294">
    def build(self, inputs_shape):
        if len(inputs_shape) != 2:
            raise Exception("The input dimension must be rank 2, please reshape or flatten it")

        if self.in_channels is None:
            self.in_channels = inputs_shape[1]

        if self.use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        n_in = inputs_shape[-1]

        self.W = self._get_weights(var_name="weights", shape=(n_in, self.n_units), init=self.W_init)
        if self.b_init is not None:
            self.b = self._get_weights(var_name="biases", shape=(self.n_units), init=self.b_init)

</source>
</class>

<class classid="55" nclones="2" nlines="20" similarity="71">
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/recurrent.py" startline="107" endline="129" pcid="1351">
    def __init__(
            self,
            cell,
            return_last_output=False,
            return_seq_2d=False,
            return_last_state=True,
            in_channels=None,
            name=None,  # 'rnn'
    ):

        super(RNN, self).__init__(name=name)

        self.cell = cell
        self.return_last_output = return_last_output
        self.return_seq_2d = return_seq_2d
        self.return_last_state = return_last_state

        if in_channels is not None:
            self.build((None, None, in_channels))
            self._built = True

        logging.info("RNN %s: cell: %s, n_units: %s" % (self.name, self.cell.__class__.__name__, self.cell.units))

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/recurrent.py" startline="291" endline="317" pcid="1355">
    def __init__(
            self,
            fw_cell,
            bw_cell,
            return_seq_2d=False,
            return_last_state=False,
            in_channels=None,
            name=None,  # 'birnn'
    ):
        super(BiRNN, self).__init__(name)

        self.fw_cell = fw_cell
        self.bw_cell = bw_cell
        self.return_seq_2d = return_seq_2d
        self.return_last_state = return_last_state

        if in_channels is not None:
            self.build((None, None, in_channels))
            self._built = True

        logging.info(
            "BiRNN %s: fw_cell: %s, fw_n_units: %s, bw_cell: %s, bw_n_units： %s" % (
                self.name, self.fw_cell.__class__.__name__, self.fw_cell.units, self.bw_cell.__class__.__name__,
                self.bw_cell.units
            )
        )

</source>
</class>

<class classid="56" nclones="7" nlines="18" similarity="72">
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/pooling.py" startline="61" endline="82" pcid="1374">
    def __init__(
            self,
            filter_size=(1, 2, 2, 1),
            strides=(1, 2, 2, 1),
            padding='SAME',
            pool=tf.nn.max_pool,
            name=None  # 'pool_pro',
    ):
        super().__init__(name)
        self.filter_size = filter_size
        self.strides = strides
        self.padding = padding
        self.pool = pool

        self.build()
        self._built = True

        logging.info(
            "PoolLayer %s: filter_size: %s strides: %s padding: %s pool: %s" %
            (self.name, str(self.filter_size), str(self.strides), self.padding, pool.__name__)
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/pooling.py" startline="446" endline="467" pcid="1394">
    def __init__(
            self,
            filter_size=(3, 3, 3),
            strides=(2, 2, 2),
            padding='VALID',
            data_format='channels_last',
            name=None  # 'maxpool3d'
    ):
        super().__init__(name)
        self.filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.data_format = data_format

        self.build()
        self._built = True

        logging.info(
            "MaxPool3d %s: filter_size: %s strides: %s padding: %s" %
            (self.name, str(filter_size), str(strides), str(padding))
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/pooling.py" startline="527" endline="548" pcid="1398">
    def __init__(
            self,
            filter_size=(3, 3, 3),
            strides=(2, 2, 2),
            padding='VALID',
            data_format='channels_last',
            name=None  # 'meanpool3d'
    ):
        super().__init__(name)
        self.filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.data_format = data_format

        self.build()
        self._built = True

        logging.info(
            "MeanPool3d %s: filter_size: %s strides: %s padding: %s" %
            (self.name, str(filter_size), str(strides), str(padding))
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/pooling.py" startline="368" endline="391" pcid="1390">
    def __init__(
            self,
            filter_size=(3, 3),
            strides=(2, 2),
            padding='SAME',
            data_format='channels_last',
            name=None  # 'meanpool2d'
    ):
        super().__init__(name)
        self.filter_size = filter_size
        if strides is None:
            strides = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.data_format = data_format

        self.build()
        self._built = True

        logging.info(
            "MeanPool2d %s: filter_size: %s strides: %s padding: %s" %
            (self.name, str(filter_size), str(strides), str(padding))
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/pooling.py" startline="295" endline="318" pcid="1386">
    def __init__(
            self,
            filter_size=(3, 3),
            strides=(2, 2),
            padding='SAME',
            data_format='channels_last',
            name=None  # 'maxpool2d'
    ):
        super().__init__(name)
        self.filter_size = filter_size
        if strides is None:
            strides = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.data_format = data_format

        self.build()
        self._built = True

        logging.info(
            "MaxPool2d %s: filter_size: %s strides: %s padding: %s" %
            (self.name, str(filter_size), str(strides), str(padding))
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/pooling.py" startline="124" endline="147" pcid="1378">
    def __init__(
            self,
            filter_size=3,
            strides=2,
            padding='SAME',
            data_format='channels_last',
            dilation_rate=1,
            name=None  # 'maxpool1d'
    ):
        super().__init__(name)
        self.filter_size = self._filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = self._dilation_rate = dilation_rate

        self.build()
        self._built = True

        logging.info(
            "MaxPool1d %s: filter_size: %s strides: %s padding: %s" %
            (self.name, str(filter_size), str(strides), str(padding))
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/pooling.py" startline="209" endline="232" pcid="1382">
    def __init__(
            self,
            filter_size=3,
            strides=2,
            padding='SAME',
            data_format='channels_last',
            dilation_rate=1,
            name=None  # 'meanpool1d'
    ):
        super().__init__(name)
        self.filter_size = self._filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = self._dilation_rate = dilation_rate

        self.build()
        self._built = True

        logging.info(
            "MeanPool1d %s: filter_size: %s strides: %s padding: %s" %
            (self.name, str(filter_size), str(strides), str(padding))
        )

</source>
</class>

<class classid="57" nclones="2" nlines="10" similarity="100">
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/pooling.py" startline="157" endline="168" pcid="1380">
    def build(self, inputs_shape=None):
        # https://tensorflow.google.cn/versions/r2.0/api_docs/python/tf/nn/pool
        if self.data_format == 'channels_last':
            self.data_format = 'NWC'
        elif self.data_format == 'channels_first':
            self.data_format = 'NCW'
        else:
            raise Exception("unsupported data format")
        self._filter_size = [self.filter_size]
        self._strides = [self.strides]
        self._dilation_rate = [self.dilation_rate]

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/pooling.py" startline="242" endline="254" pcid="1384">
    def build(self, inputs_shape=None):
        # pass
        # https://tensorflow.google.cn/versions/r2.0/api_docs/python/tf/nn/pool
        if self.data_format == 'channels_last':
            self.data_format = 'NWC'
        elif self.data_format == 'channels_first':
            self.data_format = 'NCW'
        else:
            raise Exception("unsupported data format")
        self._filter_size = [self.filter_size]
        self._strides = [self.strides]
        self._dilation_rate = [self.dilation_rate]

</source>
</class>

<class classid="58" nclones="7" nlines="10" similarity="90">
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/pooling.py" startline="597" endline="610" pcid="1402">
    def __init__(
            self,
            data_format="channels_last",
            name=None  # 'globalmaxpool1d'
    ):
        super().__init__(name)

        self.data_format = data_format

        self.build()
        self._built = True

        logging.info("GlobalMaxPool1d %s" % self.name)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/pooling.py" startline="819" endline="832" pcid="1418">
    def __init__(
            self,
            data_format='channels_last',
            name=None  # 'globalmaxpool3d'
    ):
        super().__init__(name)

        self.data_format = data_format

        self.build()
        self._built = True

        logging.info("GlobalMaxPool3d %s" % self.name)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/pooling.py" startline="708" endline="720" pcid="1410">
    def __init__(
            self,
            data_format='channels_last',
            name=None  # 'globalmaxpool2d'
    ):
        super().__init__(name)
        self.data_format = data_format

        self.build()
        self._built = True

        logging.info("GlobalMaxPool2d %s" % self.name)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/pooling.py" startline="763" endline="776" pcid="1414">
    def __init__(
            self,
            data_format='channels_last',
            name=None  # 'globalmeanpool2d'
    ):
        super().__init__(name)

        self.data_format = data_format

        self.build()
        self._built = True

        logging.info("GlobalMeanPool2d %s" % self.name)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/pooling.py" startline="875" endline="887" pcid="1422">
    def __init__(
            self,
            data_format='channels_last',
            name=None  # 'globalmeanpool3d'
    ):
        super().__init__(name)
        self.data_format = data_format

        self.build()
        self._built = True

        logging.info("GlobalMeanPool3d %s" % self.name)

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/pooling.py" startline="931" endline="942" pcid="1426">
    def __init__(
            self,
            mode='TopLeft',
            name=None  # 'cornerpool2d'
    ):
        super().__init__(name)
        self.mode = mode
        self.build()
        self._built = True

        logging.info("CornerPool2d %s : mode: %s" % (self.name, str(mode)))

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/pooling.py" startline="653" endline="665" pcid="1406">
    def __init__(
            self,
            data_format='channels_last',
            name=None  # 'globalmeanpool1d'
    ):
        super().__init__(name)
        self.data_format = data_format

        self.build()
        self._built = True

        logging.info("GlobalMeanPool1d %s" % self.name)

</source>
</class>

<class classid="59" nclones="3" nlines="12" similarity="75">
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/padding.py" startline="101" endline="115" pcid="1434">
    def __init__(
            self,
            padding,
            name=None,  # 'zeropad1d',
    ):
        super().__init__(name)
        self.padding = padding
        logging.info("ZeroPad1d   %s: padding: %s" % (self.name, str(padding)))

        if not isinstance(self.padding, (int, tuple, dict)):
            raise AssertionError()

        self.build()
        self._built = True

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/padding.py" startline="155" endline="170" pcid="1438">
    def __init__(
            self,
            padding,
            name=None,  # 'zeropad2d',
    ):
        super().__init__(name)

        self.padding = padding
        logging.info("ZeroPad2d   %s: padding: %s" % (self.name, str(self.padding)))

        if not isinstance(self.padding, (int, tuple)):
            raise AssertionError("Padding should be of type `int` or `tuple`")

        self.build()
        self._built = True

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/padding.py" startline="210" endline="225" pcid="1442">
    def __init__(
            self,
            padding,
            name=None,  # 'zeropad3d',
    ):
        super().__init__(name)
        self.padding = padding

        logging.info("ZeroPad3d   %s: padding: %s" % (self.name, str(self.padding)))

        if not isinstance(self.padding, (int, tuple)):
            raise AssertionError()

        self.build()
        self._built = True

</source>
</class>

<class classid="60" nclones="2" nlines="19" similarity="100">
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/image_resampling.py" startline="48" endline="72" pcid="1446">
    def __init__(
            self,
            scale,
            method='bilinear',
            antialias=False,
            data_format='channel_last',
            name=None,
    ):
        super(UpSampling2d, self).__init__(name)
        self.method = method
        self.antialias = antialias
        self.data_format = data_format

        logging.info(
            "UpSampling2d %s: scale: %s method: %s antialias: %s" % (self.name, scale, self.method, self.antialias)
        )

        self.build(None)
        self._built = True

        if isinstance(scale, (list, tuple)) and len(scale) != 2:
            raise ValueError("scale must be int or tuple/list of length 2")

        self.scale = (scale, scale) if isinstance(scale, int) else scale

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/image_resampling.py" startline="129" endline="153" pcid="1450">
    def __init__(
            self,
            scale,
            method='bilinear',
            antialias=False,
            data_format='channel_last',
            name=None,
    ):
        super(DownSampling2d, self).__init__(name)
        self.method = method
        self.antialias = antialias
        self.data_format = data_format

        logging.info(
            "DownSampling2d %s: scale: %s method: %s antialias: %s" % (self.name, scale, self.method, self.antialias)
        )

        self.build(None)
        self._built = True

        if isinstance(scale, (list, tuple)) and len(scale) != 2:
            raise ValueError("scale must be int or tuple/list of length 2")

        self.scale = (scale, scale) if isinstance(scale, int) else scale

</source>
</class>

<class classid="61" nclones="2" nlines="10" similarity="80">
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/extend.py" startline="35" endline="47" pcid="1454">
    def __init__(
            self,
            axis,
            name=None  # 'expand_dims',
    ):
        super(ExpandDims, self).__init__(name)
        self.axis = axis

        self.build((None, ))
        self._built = True

        logging.info("ExpandDims  %s: axis: %d" % (self.name, self.axis))

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/scale.py" startline="35" endline="47" pcid="1478">
    def __init__(
            self,
            init_scale=0.05,
            name='scale',
    ):
        super(Scale, self).__init__(name)
        self.init_scale = init_scale

        self.build((None, ))
        self._built = True

        logging.info("Scale  %s: init_scale: %f" % (self.name, self.init_scale))

</source>
</class>

<class classid="62" nclones="3" nlines="18" similarity="94">
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/activation.py" startline="56" endline="77" pcid="1462">
    def __init__(
            self,
            channel_shared=False,
            in_channels=None,
            a_init=truncated_normal(mean=0.0, stddev=0.1),
            name=None  # "prelu"
    ):

        super(PRelu, self).__init__(name)
        self.channel_shared = channel_shared
        self.in_channels = in_channels
        self.a_init = a_init

        if self.channel_shared:
            self.build((None, ))
            self._built = True
        elif self.in_channels is not None:
            self.build((None, self.in_channels))
            self._built = True

        logging.info("PRelu %s: channel_shared: %s" % (self.name, self.channel_shared))

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/activation.py" startline="143" endline="164" pcid="1466">
    def __init__(
            self,
            channel_shared=False,
            in_channels=None,
            a_init=truncated_normal(mean=0.0, stddev=0.1),
            name=None  # "prelu6"
    ):

        super(PRelu6, self).__init__(name)
        self.channel_shared = channel_shared
        self.in_channels = in_channels
        self.a_init = a_init

        if self.channel_shared:
            self.build((None, ))
            self._built = True
        elif self.in_channels is not None:
            self.build((None, self.in_channels))
            self._built = True

        logging.info("PRelu6 %s: channel_shared: %s" % (self.name, self.channel_shared))

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/activation.py" startline="231" endline="252" pcid="1470">
    def __init__(
            self,
            channel_shared=False,
            in_channels=None,
            a_init=truncated_normal(mean=0.0, stddev=0.1),
            name=None  # "ptrelu6"
    ):

        super(PTRelu6, self).__init__(name)
        self.channel_shared = channel_shared
        self.in_channels = in_channels
        self.a_init = a_init

        if self.channel_shared:
            self.build((None, ))
            self._built = True
        elif self.in_channels:
            self.build((None, self.in_channels))
            self._built = True

        logging.info("PTRelu6 %s: channel_shared: %s" % (self.name, self.channel_shared))

</source>
</class>

<class classid="63" nclones="2" nlines="19" similarity="89">
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/lambda_layers.py" startline="104" endline="125" pcid="1556">
    def __init__(
            self,
            fn,
            fn_weights=None,
            fn_args=None,
            name=None,
    ):

        super(Lambda, self).__init__(name=name)
        self.fn = fn
        self._trainable_weights = fn_weights if fn_weights is not None else []
        self.fn_args = fn_args if fn_args is not None else {}

        try:
            fn_name = repr(self.fn)
        except:
            fn_name = 'name not available'
        logging.info("Lambda  %s: func: %s, len_weights: %s" % (self.name, fn_name, len(self._trainable_weights)))

        self.build()
        self._built = True

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/lambda_layers.py" startline="227" endline="250" pcid="1561">
    def __init__(
            self,
            fn,
            fn_weights=None,
            fn_args=None,
            name=None,  #'elementwiselambda',
    ):

        super(ElementwiseLambda, self).__init__(name=name)
        self.fn = fn
        self._trainable_weights = fn_weights if fn_weights is not None else []
        self.fn_args = fn_args if fn_args is not None else {}

        try:
            fn_name = repr(self.fn)
        except:
            fn_name = 'name not available'
        logging.info(
            "ElementwiseLambda  %s: func: %s, len_weights: %s" % (self.name, fn_name, len(self._trainable_weights))
        )

        self.build()
        self._built = True

</source>
</class>

<class classid="64" nclones="2" nlines="13" similarity="100">
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/lambda_layers.py" startline="126" endline="140" pcid="1557">
    def __repr__(self):
        s = '{classname}('
        s += 'fn={fn_name},'
        s += 'len_weights={len_weights},'
        s += 'name=\'{name}\''
        s += ')'
        try:
            fn_name = repr(self.fn)
        except:
            fn_name = 'name not available'
        return s.format(
            classname=self.__class__.__name__, fn_name=fn_name, len_weights=len(self._trainable_weights),
            **self.__dict__
        )

</source>
<source file="systems/TensorLayer-2.0.2/tensorlayer/layers/lambda_layers.py" startline="251" endline="265" pcid="1562">
    def __repr__(self):
        s = '{classname}('
        s += 'fn={fn_name},'
        s += 'len_weights={len_weights},'
        s += 'name=\'{name}\''
        s += ')'
        try:
            fn_name = repr(self.fn)
        except:
            fn_name = 'name not available'
        return s.format(
            classname=self.__class__.__name__, fn_name=fn_name, len_weights=len(self._trainable_weights),
            **self.__dict__
        )

</source>
</class>

</clones>
