<html>
<head>
    <title>NiCad6 Clone Report</title>
    <style type="text/css">
        body {font-family:sans-serif;}
        table {background-color:white; border:0px; padding:0px; border-spacing:4px; width:auto; margin-left:30px; margin-right:auto;}
        td {background-color:rgba(192,212,238,0.8); border:0px; padding:8px; width:auto; vertical-align:top; border-radius:8px}
        pre {background-color:white; padding:4px;}
        a {color:darkblue;}
    </style>
</head>
<body>
<h2>NiCad6 Clone Report</h2>
<table>
<tr style="font-size:14pt">
<td><b>System:</b> &nbsp; TensorLayer-2.2.1</td>
<td><b>Clone pairs:</b> &nbsp; 612</td>
<td><b>Clone classes:</b> &nbsp; 97</td>
</tr>
<tr style="font-size:12pt">
<td style="background-color:white">Clone type: &nbsp; 3-2</td>
<td style="background-color:white">Granularity: &nbsp; functions-blind</td>
<td style="background-color:white">Max diff threshold: &nbsp; 30%</td>
<td style="background-color:white">Clone size: &nbsp; 10 - 2500 lines</td>
<td style="background-color:white">Total functions-blind: &nbsp; 2009</td>
</tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 1:</b> &nbsp; 4 fragments, nominal size 11 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1')" href="javascript:;">
TensorLayer-2.2.1/tests/files/test_utils_saveload.py: 18-32
</a>
<div class="mid" id="frag1" style="display:none"><pre>
def basic_static_model():
    ni = Input((None, 24, 24, 3))
    nn = Conv2d(16, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, name="conv1")(ni)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool1')(nn)

    nn = Conv2d(16, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, name="conv2")(nn)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool2')(nn)

    nn = Flatten(name='flatten')(nn)
    nn = Dense(100, act=None, name="dense1")(nn)
    nn = Dense(10, act=None, name="dense2")(nn)
    M = Model(inputs=ni, outputs=nn, name='basic_static')
    return M


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag56')" href="javascript:;">
TensorLayer-2.2.1/tests/models/test_model_save.py: 17-32
</a>
<div class="mid" id="frag56" style="display:none"><pre>
def basic_static_model(include_top=True):
    ni = Input((None, 24, 24, 3))
    nn = Conv2d(16, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, name="conv1")(ni)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool1')(nn)

    nn = Conv2d(16, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, name="conv2")(nn)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool2')(nn)

    nn = Flatten(name='flatten')(nn)
    nn = Dense(100, act=None, name="dense1")(nn)
    if include_top is True:
        nn = Dense(10, act=None, name="dense2")(nn)
    M = Model(inputs=ni, outputs=nn)
    return M


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag33')" href="javascript:;">
TensorLayer-2.2.1/tests/models/test_model_core.py: 17-31
</a>
<div class="mid" id="frag33" style="display:none"><pre>
def basic_static_model():
    ni = Input((None, 24, 24, 3))
    nn = Conv2d(16, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, name="conv1")(ni)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool1')(nn)

    nn = Conv2d(16, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, name="conv2")(nn)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool2')(nn)

    nn = Flatten(name='flatten')(nn)
    nn = Dense(100, act=None, name="dense1")(nn)
    nn = Dense(10, act=None, name="dense2")(nn)
    M = Model(inputs=ni, outputs=nn)
    return M


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag73')" href="javascript:;">
TensorLayer-2.2.1/tests/models/test_model_save_graph.py: 23-36
</a>
<div class="mid" id="frag73" style="display:none"><pre>
def basic_static_model():
    ni = Input((None, 24, 24, 3))
    nn = Conv2d(16, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, name="conv1")(ni)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool1')(nn)

    nn = Conv2d(16, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, name="conv2")(nn)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool2')(nn)

    nn = Flatten(name='flatten')(nn)
    nn = Dense(100, act=None, name="dense1")(nn)
    M = Model(inputs=ni, outputs=nn)
    return M


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 2:</b> &nbsp; 2 fragments, nominal size 15 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag6')" href="javascript:;">
TensorLayer-2.2.1/tests/files/test_utils_saveload.py: 69-88
</a>
<div class="mid" id="frag6" style="display:none"><pre>
    def test_hdf5(self):
        modify_val = np.zeros_like(self.static_model.all_weights[-2].numpy())
        ori_val = self.static_model.all_weights[-2].numpy()
        tl.files.save_weights_to_hdf5("./model_basic.h5", self.static_model)

        self.static_model.all_weights[-2].assign(modify_val)
        tl.files.load_hdf5_to_weights_in_order("./model_basic.h5", self.static_model)
        self.assertLess(np.max(np.abs(ori_val - self.static_model.all_weights[-2].numpy())), 1e-7)

        self.static_model.all_weights[-2].assign(modify_val)
        tl.files.load_hdf5_to_weights("./model_basic.h5", self.static_model)
        self.assertLess(np.max(np.abs(ori_val - self.static_model.all_weights[-2].numpy())), 1e-7)

        ori_weights = self.static_model._all_weights
        self.static_model._all_weights = self.static_model._all_weights[1:]
        self.static_model.all_weights[-2].assign(modify_val)
        tl.files.load_hdf5_to_weights("./model_basic.h5", self.static_model, skip=True)
        self.assertLess(np.max(np.abs(ori_val - self.static_model.all_weights[-2].numpy())), 1e-7)
        self.static_model._all_weights = ori_weights

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag8')" href="javascript:;">
TensorLayer-2.2.1/tests/files/test_utils_saveload.py: 98-114
</a>
<div class="mid" id="frag8" style="display:none"><pre>
    def test_npz_dict(self):
        modify_val = np.zeros_like(self.dynamic_model.all_weights[-2].numpy())
        ori_val = self.dynamic_model.all_weights[-2].numpy()
        tl.files.save_npz_dict(self.dynamic_model.all_weights, "./model_basic.npz")

        self.dynamic_model.all_weights[-2].assign(modify_val)
        tl.files.load_and_assign_npz_dict("./model_basic.npz", self.dynamic_model)
        self.assertLess(np.max(np.abs(ori_val - self.dynamic_model.all_weights[-2].numpy())), 1e-7)

        ori_weights = self.dynamic_model._all_weights
        self.dynamic_model._all_weights = self.static_model._all_weights[1:]
        self.dynamic_model.all_weights[-2].assign(modify_val)
        tl.files.load_and_assign_npz_dict("./model_basic.npz", self.dynamic_model, skip=True)
        self.assertLess(np.max(np.abs(ori_val - self.dynamic_model.all_weights[-2].numpy())), 1e-7)
        self.dynamic_model._all_weights = ori_weights


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 3:</b> &nbsp; 2 fragments, nominal size 32 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag11')" href="javascript:;">
TensorLayer-2.2.1/tests/models/test_seq2seq_model.py: 47-95
</a>
<div class="mid" id="frag11" style="display:none"><pre>
    def test_basic_simpleSeq2Seq(self):
        model_ = Seq2seq(
            decoder_seq_length=5,
            cell_enc=tf.keras.layers.GRUCell,
            cell_dec=tf.keras.layers.GRUCell,
            n_layer=3,
            n_units=128,
            embedding_layer=tl.layers.Embedding(vocabulary_size=self.vocab_size, embedding_size=self.embedding_size),
        )

        optimizer = tf.optimizers.Adam(learning_rate=0.001)

        for epoch in range(self.num_epochs):
            model_.train()
            trainX, trainY = shuffle(self.trainX, self.trainY)
            total_loss, n_iter = 0, 0
            for X, Y in tqdm(tl.iterate.minibatches(inputs=trainX, targets=trainY, batch_size=self.batch_size,
                                                    shuffle=False), total=self.n_step,
                             desc='Epoch[{}/{}]'.format(epoch + 1, self.num_epochs), leave=False):

                dec_seq = Y[:, :-1]
                target_seq = Y[:, 1:]

                with tf.GradientTape() as tape:
                    ## compute outputs
                    output = model_(inputs=[X, dec_seq])

                    output = tf.reshape(output, [-1, self.vocab_size])

                    loss = cross_entropy_seq(logits=output, target_seqs=target_seq)

                    grad = tape.gradient(loss, model_.all_weights)
                    optimizer.apply_gradients(zip(grad, model_.all_weights))

                total_loss += loss
                n_iter += 1

            model_.eval()
            test_sample = trainX[0:2, :].tolist()

            top_n = 1
            for i in range(top_n):
                prediction = model_([test_sample], seq_length=self.dec_seq_length, start_token=0, top_n=1)
                print("Prediction: &gt;&gt;&gt;&gt;&gt;  ", prediction, "\n Target: &gt;&gt;&gt;&gt;&gt;  ", trainY[0:2, 1:], "\n\n")

            # printing average loss after every epoch
            print('Epoch [{}/{}]: loss {:.4f}'.format(epoch + 1, self.num_epochs, total_loss / n_iter))


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag55')" href="javascript:;">
TensorLayer-2.2.1/tests/models/test_seq2seq_with_attention.py: 59-101
</a>
<div class="mid" id="frag55" style="display:none"><pre>
    def test_basic_simpleSeq2Seq(self):

        model_ = Seq2seqLuongAttention(
            hidden_size=128, cell=tf.keras.layers.SimpleRNNCell,
            embedding_layer=tl.layers.Embedding(vocabulary_size=self.vocab_size,
                                                embedding_size=self.embedding_size), method='dot'
        )
        optimizer = tf.optimizers.Adam(learning_rate=0.001)

        for epoch in range(self.num_epochs):
            model_.train()
            trainX, trainY = shuffle(self.trainX, self.trainY)
            total_loss, n_iter = 0, 0
            for X, Y in tqdm(tl.iterate.minibatches(inputs=trainX, targets=trainY, batch_size=self.batch_size,
                                                    shuffle=False), total=self.n_step,
                             desc='Epoch[{}/{}]'.format(epoch + 1, self.num_epochs), leave=False):
                dec_seq = Y[:, :-1]
                target_seq = Y[:, 1:]

                with tf.GradientTape() as tape:
                    ## compute outputs
                    output = model_(inputs=[X, dec_seq])
                    # print(output)
                    output = tf.reshape(output, [-1, self.vocab_size])

                    loss = cross_entropy_seq(logits=output, target_seqs=target_seq)
                    grad = tape.gradient(loss, model_.trainable_weights)
                    optimizer.apply_gradients(zip(grad, model_.trainable_weights))

                total_loss += loss
                n_iter += 1

            model_.eval()
            test_sample = self.testX[:5, :].tolist()  # Can't capture the sequence.
            top_n = 1
            for i in range(top_n):
                prediction = model_([test_sample], seq_length=self.dec_seq_length, sos=0)
                print("Prediction: &gt;&gt;&gt;&gt;&gt;  ", prediction, "\n Target: &gt;&gt;&gt;&gt;&gt;  ", self.testY[:5, 1:], "\n\n")

            # printing average loss after every epoch
            print('Epoch [{}/{}]: loss {:.4f}'.format(epoch + 1, self.num_epochs, total_loss / n_iter))


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 4:</b> &nbsp; 2 fragments, nominal size 48 lines, similarity 83%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag38')" href="javascript:;">
TensorLayer-2.2.1/tests/models/test_model_core.py: 67-135
</a>
<div class="mid" id="frag38" style="display:none"><pre>
    def test_dynamic_basic(self):
        print('-' * 20, 'test_dynamic_basic', '-' * 20)
        model_basic = basic_dynamic_model()

        # test empty model before calling
        self.assertEqual(model_basic.is_train, None)
        self.assertEqual(model_basic._all_weights, None)
        self.assertEqual(model_basic._inputs, None)
        self.assertEqual(model_basic._outputs, None)
        self.assertEqual(model_basic._model_layer, None)
        self.assertEqual(model_basic._all_layers, None)
        self.assertEqual(model_basic._nodes_fixed, False)

        # test layer and weights access
        all_layers = model_basic.all_layers
        self.assertEqual(len(model_basic.all_layers), 7)
        self.assertEqual(model_basic._all_weights, None)

        self.assertIsNotNone(model_basic.all_weights)
        print([w.name for w in model_basic.all_weights])

        # test model mode
        model_basic.train()
        self.assertEqual(model_basic.is_train, True)
        model_basic.eval()
        self.assertEqual(model_basic.is_train, False)
        model_basic.test()
        self.assertEqual(model_basic.is_train, False)
        model_basic.infer()
        self.assertEqual(model_basic.is_train, False)

        # test as_layer
        try:
            model_basic.as_layer()
        except Exception as e:
            print(e)
        self.assertIsNone(model_basic._model_layer)

        # test print
        try:
            print(model_basic)
        except Exception as e:
            print(e)

        # test forwarding
        inputs = np.random.normal(size=[2, 24, 24, 3]).astype(np.float32)
        outputs1 = model_basic(inputs)
        self.assertEqual(model_basic._nodes_fixed, True)
        self.assertEqual(model_basic.is_train, False)

        try:
            outputs2 = model_basic(inputs, is_train=True)
        except Exception as e:
            print(e)
        outputs2 = model_basic(inputs, is_train=False)
        self.assertEqual(model_basic.is_train, False)

        self.assertLess(np.max(np.abs(outputs1.numpy() - outputs2.numpy())), 1e-7)

        # test layer node
        self.assertEqual(len(model_basic.all_layers[-1]._nodes), 0)
        self.assertEqual(model_basic.all_layers[-2]._nodes_fixed, True)

        # test release_memory
        try:
            model_basic.release_memory()
        except Exception as e:
            print(e)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag39')" href="javascript:;">
TensorLayer-2.2.1/tests/models/test_model_core.py: 136-201
</a>
<div class="mid" id="frag39" style="display:none"><pre>
    def test_static_basic(self):
        print('-' * 20, 'test_static_basic', '-' * 20)
        model_basic = basic_static_model()

        # test empty model before calling
        self.assertEqual(model_basic.is_train, None)
        self.assertEqual(model_basic._all_weights, None)
        self.assertIsNotNone(model_basic._inputs)
        self.assertIsNotNone(model_basic._outputs)
        self.assertEqual(model_basic._model_layer, None)
        self.assertIsNotNone(model_basic._all_layers)
        self.assertIsNotNone(model_basic._nodes_fixed)

        # test layer and weights access
        all_layers = model_basic.all_layers
        self.assertEqual(len(model_basic.all_layers), 8)
        self.assertEqual(model_basic._all_weights, None)

        self.assertIsNotNone(model_basic.all_weights)
        print([w.name for w in model_basic.all_weights])

        # test model mode
        model_basic.train()
        self.assertEqual(model_basic.is_train, True)
        model_basic.eval()
        self.assertEqual(model_basic.is_train, False)
        model_basic.test()
        self.assertEqual(model_basic.is_train, False)
        model_basic.infer()
        self.assertEqual(model_basic.is_train, False)

        # test as_layer
        self.assertIsInstance(model_basic.as_layer(), tl.layers.Layer)
        self.assertIsNotNone(model_basic._model_layer)

        # test print
        try:
            print(model_basic)
        except Exception as e:
            print(e)

        # test forwarding
        inputs = np.random.normal(size=[2, 24, 24, 3]).astype(np.float32)
        outputs1 = model_basic(inputs)
        self.assertEqual(model_basic._nodes_fixed, True)
        self.assertEqual(model_basic.is_train, False)

        try:
            outputs2 = model_basic(inputs, is_train=True)
        except Exception as e:
            print(e)
        outputs2 = model_basic(inputs, is_train=False)
        self.assertEqual(model_basic.is_train, False)

        self.assertLess(np.max(np.abs(outputs1.numpy() - outputs2.numpy())), 1e-7)

        # test layer node
        self.assertEqual(len(model_basic.all_layers[-1]._nodes), 1)
        self.assertEqual(model_basic.all_layers[-2]._nodes_fixed, True)

        # test release_memory
        try:
            model_basic.release_memory()
        except Exception as e:
            print(e)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 5:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag58')" href="javascript:;">
TensorLayer-2.2.1/tests/models/test_model_save.py: 49-60
</a>
<div class="mid" id="frag58" style="display:none"><pre>
    def forward(self, x):
        x = self.conv1(x)
        x = self.pool1(x)
        x = self.conv2(x)
        x = self.pool2(x)
        x = self.flatten(x)
        x = self.dense1(x)
        if self.include_top:
            x = self.dense2(x)
        return x


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag658')" href="javascript:;">
TensorLayer-2.2.1/examples/basic_tutorials/tutorial_mnist_mlp_dynamic.py: 29-40
</a>
<div class="mid" id="frag658" style="display:none"><pre>
    def forward(self, x, foo=None):
        z = self.dropout1(x)
        z = self.dense1(z)
        z = self.dropout2(z)
        z = self.dense2(z)
        z = self.dropout3(z)
        out = self.dense3(z)
        if foo is not None:
            out = tf.nn.relu(out)
        return out


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 6:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag81')" href="javascript:;">
TensorLayer-2.2.1/tests/models/test_model_save_graph.py: 160-172
</a>
<div class="mid" id="frag81" style="display:none"><pre>
def create_base_network(input_shape):
    '''Base network to be shared (eq. to feature extraction).
    '''
    input = Input(shape=input_shape)
    x = Flatten()(input)
    x = Dense(128, act=tf.nn.relu)(x)
    x = Dropout(0.9)(x)
    x = Dense(128, act=tf.nn.relu)(x)
    x = Dropout(0.9)(x)
    x = Dense(128, act=tf.nn.relu)(x)
    return Model(input, x)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag653')" href="javascript:;">
TensorLayer-2.2.1/examples/basic_tutorials/tutorial_mnist_siamese.py: 41-53
</a>
<div class="mid" id="frag653" style="display:none"><pre>
def create_base_network(input_shape):
    '''Base network to be shared (eq. to feature extraction).
    '''
    input = Input(shape=input_shape)
    x = Flatten()(input)
    x = Dense(128, act=tf.nn.relu)(x)
    x = Dropout(0.9)(x)
    x = Dense(128, act=tf.nn.relu)(x)
    x = Dropout(0.9)(x)
    x = Dense(128, act=tf.nn.relu)(x)
    return Model(input, x)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 7:</b> &nbsp; 2 fragments, nominal size 19 lines, similarity 80%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag90')" href="javascript:;">
TensorLayer-2.2.1/tests/models/test_model_save_graph.py: 257-276
</a>
<div class="mid" id="frag90" style="display:none"><pre>
    def test_lambda_layer_no_para_no_args(self):
        x = tl.layers.Input([8, 3], name='input')
        y = tl.layers.Lambda(lambda x: 2 * x, name='lambda')(x)
        M1 = tl.models.Model(x, y)
        M1.save("lambda_no_para_no_args.hdf5")
        M2 = tl.models.Model.load("lambda_no_para_no_args.hdf5")
        print(M1)
        print(M2)
        M1.eval()
        M2.eval()
        npInput = np.zeros((8, 3)) + 3
        output1 = M1(npInput).numpy()
        output2 = M1(npInput).numpy()

        M1_config = RemoveDateInConfig(M1.config)
        M2_config = RemoveDateInConfig(M2.config)

        self.assertEqual((output1 == output2).all(), True)
        self.assertEqual(M1_config, M2_config)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag91')" href="javascript:;">
TensorLayer-2.2.1/tests/models/test_model_save_graph.py: 277-301
</a>
<div class="mid" id="frag91" style="display:none"><pre>
    def test_lambda_layer_no_para_with_args(self):

        def customize_func(x, foo=42):  # x is the inputs, foo is an argument
            return foo * x

        x = tl.layers.Input([8, 3], name='input')
        y = tl.layers.Lambda(customize_func, fn_args={'foo': 3}, name='lambda')(x)
        M1 = tl.models.Model(x, y)
        M1.save("lambda_no_para_with_args.hdf5")
        M2 = tl.models.Model.load("lambda_no_para_with_args.hdf5")
        print(M1)
        print(M2)
        M1.eval()
        M2.eval()
        npInput = np.zeros((8, 3)) + 3
        output1 = M1(npInput).numpy()
        output2 = M2(npInput).numpy()

        M1_config = RemoveDateInConfig(M1.config)
        M2_config = RemoveDateInConfig(M2.config)

        self.assertEqual((output1 == output2).all(), True)
        self.assertEqual((output1 == (np.zeros((8, 3)) + 9)).all(), True)
        self.assertEqual(M1_config, M2_config)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 8:</b> &nbsp; 2 fragments, nominal size 26 lines, similarity 82%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag93')" href="javascript:;">
TensorLayer-2.2.1/tests/models/test_model_save_graph.py: 302-338
</a>
<div class="mid" id="frag93" style="display:none"><pre>
    def test_lambda_layer_keras_model(self):
        input_shape = [100, 5]
        in_2 = tl.layers.Input(input_shape, name='input')
        layers = [
            tf.keras.layers.Dense(10, activation=tf.nn.relu),
            tf.keras.layers.Dense(5, activation=tf.nn.sigmoid),
            tf.keras.layers.Dense(1, activation=tf.nn.relu)
        ]
        perceptron = tf.keras.Sequential(layers)
        # in order to compile keras model and get trainable_variables of the keras model
        _ = perceptron(np.random.random(input_shape).astype(np.float32))
        plambdalayer = tl.layers.Lambda(perceptron, perceptron.trainable_variables)(in_2)
        M2 = tl.models.Model(inputs=in_2, outputs=plambdalayer)

        M2.save('M2_keras.hdf5')
        M4 = Model.load('M2_keras.hdf5')

        M2.eval()
        M4.eval()
        npInput = np.zeros(input_shape) + 3
        output2 = M2(npInput).numpy()
        output4 = M4(npInput).numpy()

        M2_config = RemoveDateInConfig(M2.config)
        M4_config = RemoveDateInConfig(M4.config)

        self.assertEqual((output2 == output4).all(), True)
        self.assertEqual(M2_config, M4_config)

        ori_weights = M4.all_weights
        ori_val = ori_weights[1].numpy()
        modify_val = np.zeros_like(ori_val) + 10
        M4.all_weights[1].assign(modify_val)
        M4 = Model.load('M2_keras.hdf5')

        self.assertLess(np.max(np.abs(ori_val - M4.all_weights[1].numpy())), 1e-7)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag94')" href="javascript:;">
TensorLayer-2.2.1/tests/models/test_model_save_graph.py: 339-371
</a>
<div class="mid" id="frag94" style="display:none"><pre>
    def test_lambda_layer_keras_layer(self):
        input_shape = [100, 5]
        in_1 = tl.layers.Input(input_shape, name='input')
        denselayer = tf.keras.layers.Dense(10, activation=tf.nn.relu)
        # in order to compile keras model and get trainable_variables of the keras model
        _ = denselayer(np.random.random(input_shape).astype(np.float32))
        dlambdalayer = tl.layers.Lambda(denselayer, denselayer.trainable_variables)(in_1)
        M1 = tl.models.Model(inputs=in_1, outputs=dlambdalayer)

        M1.save('M1_keras.hdf5')
        M3 = Model.load('M1_keras.hdf5')

        M1.eval()
        M3.eval()
        npInput = np.zeros(input_shape) + 3
        output1 = M1(npInput).numpy()
        output3 = M3(npInput).numpy()

        M1_config = RemoveDateInConfig(M1.config)
        M3_config = RemoveDateInConfig(M3.config)

        self.assertEqual((output1 == output3).all(), True)
        self.assertEqual(M1_config, M3_config)

        ori_weights = M3.all_weights
        ori_val = ori_weights[1].numpy()
        modify_val = np.zeros_like(ori_val) + 10
        M3.all_weights[1].assign(modify_val)
        M3 = Model.load('M1_keras.hdf5')

        self.assertLess(np.max(np.abs(ori_val - M3.all_weights[1].numpy())), 1e-7)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 9:</b> &nbsp; 3 fragments, nominal size 19 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag96')" href="javascript:;">
TensorLayer-2.2.1/tests/models/test_model_save_graph.py: 378-402
</a>
<div class="mid" id="frag96" style="display:none"><pre>
    def test_elementwise_no_para_with_args(self):
        # z = mean + noise * tf.exp(std * 0.5) + foo
        def func(noise, mean, std, foo=42):
            return mean + noise * tf.exp(std * 0.5) + foo

        noise = tl.layers.Input([100, 1])
        mean = tl.layers.Input([100, 1])
        std = tl.layers.Input([100, 1])
        out = tl.layers.ElementwiseLambda(fn=func, fn_args={'foo': 84}, name='elementwiselambda')([noise, mean, std])
        M1 = Model(inputs=[noise, mean, std], outputs=out)
        M1.save("elementwise_npwa.hdf5")
        M2 = Model.load("elementwise_npwa.hdf5")

        M1.eval()
        M2.eval()
        ipt = [np.zeros((100, 1)) + 11, np.zeros((100, 1)) + 21, np.zeros((100, 1)) + 31]
        output1 = M1(ipt).numpy()
        output2 = M2(ipt).numpy()

        M1_config = RemoveDateInConfig(M1.config)
        M2_config = RemoveDateInConfig(M2.config)

        self.assertEqual((output1 == output2).all(), True)
        self.assertEqual(M1_config, M2_config)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag98')" href="javascript:;">
TensorLayer-2.2.1/tests/models/test_model_save_graph.py: 403-427
</a>
<div class="mid" id="frag98" style="display:none"><pre>
    def test_elementwise_no_para_no_args(self):
        # z = mean + noise * tf.exp(std * 0.5) + foo
        def func(noise, mean, std, foo=42):
            return mean + noise * tf.exp(std * 0.5) + foo

        noise = tl.layers.Input([100, 1])
        mean = tl.layers.Input([100, 1])
        std = tl.layers.Input([100, 1])
        out = tl.layers.ElementwiseLambda(fn=func, name='elementwiselambda')([noise, mean, std])
        M1 = Model(inputs=[noise, mean, std], outputs=out)
        M1.save("elementwise_npna.hdf5")
        M2 = Model.load("elementwise_npna.hdf5")

        M1.eval()
        M2.eval()
        ipt = [np.zeros((100, 1)) + 11, np.zeros((100, 1)) + 21, np.zeros((100, 1)) + 31]
        output1 = M1(ipt).numpy()
        output2 = M2(ipt).numpy()

        M1_config = RemoveDateInConfig(M1.config)
        M2_config = RemoveDateInConfig(M2.config)

        self.assertEqual((output1 == output2).all(), True)
        self.assertEqual(M1_config, M2_config)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag100')" href="javascript:;">
TensorLayer-2.2.1/tests/models/test_model_save_graph.py: 428-481
</a>
<div class="mid" id="frag100" style="display:none"><pre>
    def test_elementwise_lambda_func(self):
        # z = mean + noise * tf.exp(std * 0.5)
        noise = tl.layers.Input([100, 1])
        mean = tl.layers.Input([100, 1])
        std = tl.layers.Input([100, 1])
        out = tl.layers.ElementwiseLambda(fn=lambda x, y, z: x + y * tf.exp(z * 0.5),
                                          name='elementwiselambda')([noise, mean, std])
        M1 = Model(inputs=[noise, mean, std], outputs=out)
        M1.save("elementwise_lambda.hdf5")
        M2 = Model.load("elementwise_lambda.hdf5")

        M1.eval()
        M2.eval()
        ipt = [
            (np.zeros((100, 1)) + 11).astype(np.float32), (np.zeros((100, 1)) + 21).astype(np.float32),
            (np.zeros((100, 1)) + 31).astype(np.float32)
        ]
        output1 = M1(ipt).numpy()
        output2 = M2(ipt).numpy()

        M1_config = RemoveDateInConfig(M1.config)
        M2_config = RemoveDateInConfig(M2.config)

        self.assertEqual((output1 == output2).all(), True)
        self.assertEqual(M1_config, M2_config)

    # # ElementwiseLambda does not support keras layer/model func yet
    # def test_elementwise_keras_model(self):
    #     kerasinput1 = tf.keras.layers.Input(shape=(100, ))
    #     kerasinput2 = tf.keras.layers.Input(shape=(100, ))
    #     kerasconcate = tf.keras.layers.concatenate(inputs=[kerasinput1, kerasinput2])
    #     kerasmodel = tf.keras.models.Model(inputs=[kerasinput1, kerasinput2], outputs=kerasconcate)
    #     _ = kerasmodel([np.random.random([100,]).astype(np.float32), np.random.random([100,]).astype(np.float32)])
    #
    #     input1 = tl.layers.Input([100, 1])
    #     input2 = tl.layers.Input([100, 1])
    #     out = tl.layers.ElementwiseLambda(fn=kerasmodel, name='elementwiselambda')([input1, input2])
    #     M1 = Model(inputs=[input1, input2], outputs=out)
    #     M1.save("elementwise_keras_model.hdf5")
    #     M2 = Model.load("elementwise_keras_model.hdf5")
    #
    #     M1.eval()
    #     M2.eval()
    #     ipt = [np.zeros((100, 1)) + 11, np.zeros((100, 1)) + 21, np.zeros((100, 1)) + 31]
    #     output1 = M1(ipt).numpy()
    #     output2 = M2(ipt).numpy()
    #
    #     M1_config = RemoveDateInConfig(M1.config)
    #     M2_config = RemoveDateInConfig(M2.config)
    #
    #     self.assertEqual((output1 == output2).all(), True)
    #     self.assertEqual(M1_config, M2_config)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 10:</b> &nbsp; 5 fragments, nominal size 29 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag133')" href="javascript:;">
TensorLayer-2.2.1/tests/utils/custom_layers/inception_blocks.py: 19-69
</a>
<div class="mid" id="frag133" style="display:none"><pre>
def block_inception_a(inputs, scope=None, is_train=False):
    """Builds Inception-A block for Inception v4 network."""
    # By default use stride=1 and SAME padding

    with tf.variable_scope(name_or_scope=scope, default_name='BlockInceptionA', values=[inputs]):
        with tf.variable_scope('Branch_0'):
            branch_0, _ = conv_module(
                inputs, n_out_channel=96, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

        with tf.variable_scope('Branch_1'):
            branch_1, _ = conv_module(
                inputs, n_out_channel=64, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_1, _ = conv_module(
                branch_1, n_out_channel=96, filter_size=(3, 3), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_3x3'
            )

        with tf.variable_scope('Branch_2'):
            branch_2, _ = conv_module(
                inputs, n_out_channel=64, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_2, _ = conv_module(
                branch_2, n_out_channel=96, filter_size=(3, 3), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_3x3'
            )

            branch_2, _ = conv_module(
                branch_2, n_out_channel=96, filter_size=(3, 3), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0c_3x3'
            )

        with tf.variable_scope('Branch_3'):
            branch_3 = tl.layers.MeanPool2d(
                inputs, filter_size=(3, 3), strides=(1, 1), padding='SAME', name='AvgPool_0a_3x3'
            )

            branch_3, _ = conv_module(
                branch_3, n_out_channel=96, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_1x1'
            )

        return tl.layers.ConcatLayer([branch_0, branch_1, branch_2, branch_3], concat_dim=3, name='concat_layer')


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag136')" href="javascript:;">
TensorLayer-2.2.1/tests/utils/custom_layers/inception_blocks.py: 169-211
</a>
<div class="mid" id="frag136" style="display:none"><pre>
def block_reduction_b(inputs, scope=None, is_train=False):
    """Builds Reduction-B block for Inception v4 network."""
    # By default use stride=1 and SAME padding

    with tf.variable_scope(scope, 'BlockReductionB', [inputs]):
        with tf.variable_scope('Branch_0'):
            branch_0, _ = conv_module(
                inputs, n_out_channel=192, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_0, _ = conv_module(
                branch_0, n_out_channel=192, filter_size=(3, 3), strides=(2, 2), padding='VALID', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_1a_3x3'
            )

        with tf.variable_scope('Branch_1'):
            branch_1, _ = conv_module(
                inputs, n_out_channel=256, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_1, _ = conv_module(
                branch_1, n_out_channel=256, filter_size=(1, 7), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_1x7'
            )

            branch_1, _ = conv_module(
                branch_1, n_out_channel=320, filter_size=(7, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0c_7x1'
            )

            branch_1, _ = conv_module(
                branch_1, n_out_channel=320, filter_size=(3, 3), strides=(2, 2), padding='VALID', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_1a_3x3'
            )

        with tf.variable_scope('Branch_2'):
            branch_2 = tl.layers.MaxPool2d(inputs, (3, 3), strides=(2, 2), padding='VALID', name='MaxPool_1a_3x3')

        return tl.layers.ConcatLayer([branch_0, branch_1, branch_2], concat_dim=3, name='concat_layer')


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag137')" href="javascript:;">
TensorLayer-2.2.1/tests/utils/custom_layers/inception_blocks.py: 212-279
</a>
<div class="mid" id="frag137" style="display:none"><pre>
def block_inception_c(inputs, scope=None, is_train=False):
    """Builds Inception-C block for Inception v4 network."""
    # By default use stride=1 and SAME padding

    with tf.variable_scope(scope, 'BlockInceptionC', [inputs]):
        with tf.variable_scope('Branch_0'):
            branch_0, _ = conv_module(
                inputs, n_out_channel=256, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

        with tf.variable_scope('Branch_1'):
            branch_1, _ = conv_module(
                inputs, n_out_channel=384, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_1a, _ = conv_module(
                branch_1, n_out_channel=256, filter_size=(1, 3), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_1x3'
            )

            branch_1b, _ = conv_module(
                branch_1, n_out_channel=256, filter_size=(3, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0c_3x1'
            )

            branch_1 = tl.layers.ConcatLayer([branch_1a, branch_1b], concat_dim=3, name='concat_layer')

        with tf.variable_scope('Branch_2'):
            branch_2, _ = conv_module(
                inputs, n_out_channel=384, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_2, _ = conv_module(
                branch_2, n_out_channel=448, filter_size=(3, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_3x1'
            )

            branch_2, _ = conv_module(
                branch_2, n_out_channel=512, filter_size=(1, 3), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0c_1x3'
            )

            branch_2a, _ = conv_module(
                branch_2, n_out_channel=256, filter_size=(1, 3), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0d_1x3'
            )

            branch_2b, _ = conv_module(
                branch_2, n_out_channel=256, filter_size=(3, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0e_3x1'
            )

            branch_2 = tl.layers.ConcatLayer([branch_2a, branch_2b], concat_dim=3, name='concat_layer')

        with tf.variable_scope('Branch_3'):
            branch_3 = tl.layers.MeanPool2d(
                inputs, filter_size=(3, 3), strides=(1, 1), padding='SAME', name='AvgPool_0a_3x3'
            )

            branch_3, _ = conv_module(
                branch_3, n_out_channel=256, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_1x1'
            )

        return tl.layers.ConcatLayer([branch_0, branch_1, branch_2, branch_3], concat_dim=3, name='concat_layer')
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag135')" href="javascript:;">
TensorLayer-2.2.1/tests/utils/custom_layers/inception_blocks.py: 103-168
</a>
<div class="mid" id="frag135" style="display:none"><pre>
def block_inception_b(inputs, scope=None, is_train=False):
    """Builds Inception-B block for Inception v4 network."""
    # By default use stride=1 and SAME padding

    with tf.variable_scope(scope, 'BlockInceptionB', [inputs]):
        with tf.variable_scope('Branch_0'):
            branch_0, _ = conv_module(
                inputs, n_out_channel=384, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

        with tf.variable_scope('Branch_1'):
            branch_1, _ = conv_module(
                inputs, n_out_channel=192, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_1, _ = conv_module(
                branch_1, n_out_channel=224, filter_size=(1, 7), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_1x7'
            )

            branch_1, _ = conv_module(
                branch_1, n_out_channel=256, filter_size=(7, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0c_7x1'
            )

        with tf.variable_scope('Branch_2'):
            branch_2, _ = conv_module(
                inputs, n_out_channel=192, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_2, _ = conv_module(
                branch_2, n_out_channel=192, filter_size=(7, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_7x1'
            )

            branch_2, _ = conv_module(
                branch_2, n_out_channel=224, filter_size=(1, 7), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0c_1x7'
            )

            branch_2, _ = conv_module(
                branch_2, n_out_channel=224, filter_size=(7, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0d_7x1'
            )

            branch_2, _ = conv_module(
                branch_2, n_out_channel=256, filter_size=(1, 7), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0e_1x7'
            )

        with tf.variable_scope('Branch_3'):
            branch_3 = tl.layers.MeanPool2d(
                inputs, filter_size=(3, 3), strides=(1, 1), padding='SAME', name='AvgPool_0a_3x3'
            )

            branch_3, _ = conv_module(
                branch_3, n_out_channel=128, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_1x1'
            )

        return tl.layers.ConcatLayer([branch_0, branch_1, branch_2, branch_3], concat_dim=3, name='concat_layer')


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag134')" href="javascript:;">
TensorLayer-2.2.1/tests/utils/custom_layers/inception_blocks.py: 70-102
</a>
<div class="mid" id="frag134" style="display:none"><pre>
def block_reduction_a(inputs, scope=None, is_train=False):
    """Builds Reduction-A block for Inception v4 network."""
    # By default use stride=1 and SAME padding

    with tf.variable_scope(scope, 'BlockReductionA', [inputs]):
        with tf.variable_scope('Branch_0'):
            branch_0, _ = conv_module(
                inputs, n_out_channel=384, filter_size=(3, 3), strides=(2, 2), padding='VALID', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_1a_3x3'
            )

        with tf.variable_scope('Branch_1'):
            branch_1, _ = conv_module(
                inputs, n_out_channel=192, filter_size=(1, 1), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0a_1x1'
            )

            branch_1, _ = conv_module(
                branch_1, n_out_channel=224, filter_size=(3, 3), strides=(1, 1), padding='SAME', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_0b_3x3'
            )

            branch_1, _ = conv_module(
                branch_1, n_out_channel=256, filter_size=(3, 3), strides=(2, 2), padding='VALID', batch_norm_init=None,
                is_train=is_train, use_batchnorm=True, activation_fn='ReLU', name='Conv2d_1a_3x3'
            )

        with tf.variable_scope('Branch_2'):
            branch_2 = tl.layers.MaxPool2d(inputs, (3, 3), strides=(2, 2), padding='VALID', name='MaxPool_1a_3x3')

        return tl.layers.ConcatLayer([branch_0, branch_1, branch_2], concat_dim=3, name='concat_layer')


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 11:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag167')" href="javascript:;">
TensorLayer-2.2.1/tests/pending/test_documentation.py: 24-35
</a>
<div class="mid" id="frag167" style="display:none"><pre>
    def test_html_documentation(self):
        app = Sphinx(
            self.source_dir,
            self.config_dir,
            self.output_dir,
            self.doctree_dir,
            buildername='html',
            warningiserror=True,
        )
        app.build(force_all=self.all_files)
        # TODO: additional checks here if needed

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag168')" href="javascript:;">
TensorLayer-2.2.1/tests/pending/test_documentation.py: 36-48
</a>
<div class="mid" id="frag168" style="display:none"><pre>
    def test_text_documentation(self):
        # The same, but with different buildername
        app = Sphinx(
            self.source_dir,
            self.config_dir,
            self.output_dir,
            self.doctree_dir,
            buildername='text',
            warningiserror=False,
        )
        app.build(force_all=self.all_files)
        # TODO:  additional checks if needed

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 12:</b> &nbsp; 4 fragments, nominal size 12 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag275')" href="javascript:;">
TensorLayer-2.2.1/tests/pending/test_logging_hyperdash.py: 35-57
</a>
<div class="mid" id="frag275" style="display:none"><pre>
    def test_monitor(self):

        with self.assertNotRaises(Exception):

            hd.HyperDashHandler.set_apikey(self.apikey)

            @hd.monitor("TRAVIS 1 - dogs vs. cats")
            def train_dogs_vs_cats(exp=None):

                # Record the value of hyperparameter gamma for this experiment
                lr = exp.param("learning rate", 0.005)
                tl.logging.debug("Learning Rate: %f" % lr)

                for epoch, accuracy in enumerate([10, 30, 50, 70, 80, 90, 95, 100]):
                    tl.logging.debug("Epoch %d - Accuracy %d%%" % (epoch + 1, accuracy))

                    # Record a numerical performance metric
                    exp.metric(name="accuracy", value=accuracy)

                    time.sleep(0.1)

            train_dogs_vs_cats()

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag281')" href="javascript:;">
TensorLayer-2.2.1/tests/pending/test_logging_hyperdash.py: 107-133
</a>
<div class="mid" id="frag281" style="display:none"><pre>
    def test_Experiment_variant(self):

        with self.assertNotRaises(Exception):

            def train_dogs_vs_cats():

                # Create an experiment with a model name, then autostart
                exp = hd.Experiment("TRAVIS 4 - dogs vs. cats", api_key=self.apikey)

                # Record the value of hyperparameter gamma for this experiment
                lr = exp.param("learning rate", 0.005)
                tl.logging.debug("Learning Rate: %f" % lr)

                for epoch, accuracy in enumerate([10, 30, 50, 70, 80, 90, 95, 100]):
                    tl.logging.debug("Epoch %d - Accuracy %d%%" % (epoch + 1, accuracy))

                    # Record a numerical performance metric
                    exp.metric(name="accuracy", value=accuracy)

                    time.sleep(0.1)

                # Cleanup and mark that the experiment successfully completed
                exp.end()

            train_dogs_vs_cats()


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag277')" href="javascript:;">
TensorLayer-2.2.1/tests/pending/test_logging_hyperdash.py: 58-78
</a>
<div class="mid" id="frag277" style="display:none"><pre>
    def test_monitor_variant(self):

        with self.assertNotRaises(Exception):

            @hd.monitor("TRAVIS 2 - dogs vs. cats", api_key=self.apikey)
            def train_dogs_vs_cats(exp=None):

                # Record the value of hyperparameter gamma for this experiment
                lr = exp.param("learning rate", 0.005)
                tl.logging.debug("Learning Rate: %f" % lr)

                for epoch, accuracy in enumerate([10, 30, 50, 70, 80, 90, 95, 100]):
                    tl.logging.debug("Epoch %d - Accuracy %d%%" % (epoch + 1, accuracy))

                    # Record a numerical performance metric
                    exp.metric(name="accuracy", value=accuracy)

                    time.sleep(0.1)

            train_dogs_vs_cats()

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag279')" href="javascript:;">
TensorLayer-2.2.1/tests/pending/test_logging_hyperdash.py: 79-106
</a>
<div class="mid" id="frag279" style="display:none"><pre>
    def test_Experiment(self):

        hd.HyperDashHandler.set_apikey(self.apikey)

        with self.assertNotRaises(Exception):

            def train_dogs_vs_cats():

                # Create an experiment with a model name, then autostart
                exp = hd.Experiment("TRAVIS 3 - dogs vs. cats")

                # Record the value of hyperparameter gamma for this experiment
                lr = exp.param("learning rate", 0.005)
                tl.logging.debug("Learning Rate: %f" % lr)

                for epoch, accuracy in enumerate([10, 30, 50, 70, 80, 90, 95, 100]):
                    tl.logging.debug("Epoch %d - Accuracy %d%%" % (epoch + 1, accuracy))

                    # Record a numerical performance metric
                    exp.metric(name="accuracy", value=accuracy)

                    time.sleep(0.1)

                # Cleanup and mark that the experiment successfully completed
                exp.end()

            train_dogs_vs_cats()

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 13:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag314')" href="javascript:;">
TensorLayer-2.2.1/tests/test_activations.py: 28-43
</a>
<div class="mid" id="frag314" style="display:none"><pre>
    def test_lrelu(self):
        for i in range(-5, 15):

            if i &gt; 0:
                good_output = i
            else:
                good_output = self.alpha * i

            computed_output = tl.act.leaky_relu(float(i), alpha=self.alpha)

            self.assertAlmostEqual(computed_output.numpy(), good_output, places=5)

        net = tl.layers.Input([10, 2])
        net = tl.layers.Dense(n_units=100, act=lambda x: tl.act.lrelu(x, 0.2), name='dense')(net)
        print(net)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag315')" href="javascript:;">
TensorLayer-2.2.1/tests/test_activations.py: 44-59
</a>
<div class="mid" id="frag315" style="display:none"><pre>
    def test_lrelu6(self):
        for i in range(-5, 15):

            if i &lt; 0:
                good_output = self.alpha * i
            else:
                good_output = min(6, i)

            computed_output = tl.act.leaky_relu6(float(i), alpha=self.alpha)

            self.assertAlmostEqual(computed_output.numpy(), good_output, places=5)

        net = tl.layers.Input([10, 2])
        net = tl.layers.Dense(n_units=100, act=lambda x: tl.act.leaky_relu6(x, 0.2), name='dense')(net)
        print(net)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 14:</b> &nbsp; 2 fragments, nominal size 15 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag334')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layernode.py: 198-223
</a>
<div class="mid" id="frag334" style="display:none"><pre>
        def get_model(inputs_shape):
            ni = Input(inputs_shape)

            ## 1. Localisation network
            # use MLP as the localisation net
            nn = Flatten()(ni)
            nn = Dense(n_units=20, act=tf.nn.tanh)(nn)
            nn = Dropout(keep=0.8)(nn)
            # you can also use CNN instead for MLP as the localisation net

            ## 2. Spatial transformer module (sampler)
            stn = SpatialTransformer2dAffine(out_size=(40, 40), in_channels=20)
            # s = stn((nn, ni))
            nn = stn((nn, ni))
            s = nn

            ## 3. Classifier
            nn = Conv2d(16, (3, 3), (2, 2), act=tf.nn.relu, padding='SAME')(nn)
            nn = Conv2d(16, (3, 3), (2, 2), act=tf.nn.relu, padding='SAME')(nn)
            nn = Flatten()(nn)
            nn = Dense(n_units=1024, act=tf.nn.relu)(nn)
            nn = Dense(n_units=10, act=tf.identity)(nn)

            M = Model(inputs=ni, outputs=[nn, s])
            return M

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag615')" href="javascript:;">
TensorLayer-2.2.1/examples/spatial_transformer_network/tutorial_spatial_transformer_network_static.py: 56-81
</a>
<div class="mid" id="frag615" style="display:none"><pre>
##================== DEFINE MODEL ============================================##
def get_model(inputs_shape):
    ni = Input(inputs_shape)

    ## 1. Localisation network
    # use MLP as the localisation net
    nn = Flatten()(ni)
    nn = Dense(n_units=20, act=tf.nn.tanh)(nn)
    nn = Dropout(keep=0.8)(nn)
    # you can also use CNN instead for MLP as the localisation net

    ## 2. Spatial transformer module (sampler)
    stn = SpatialTransformer2dAffine(out_size=(40, 40), in_channels=20)
    nn = stn((nn, ni))
    s = nn

    ## 3. Classifier
    nn = Conv2d(16, (3, 3), (2, 2), act=tf.nn.relu, padding='SAME')(nn)
    nn = Conv2d(16, (3, 3), (2, 2), act=tf.nn.relu, padding='SAME')(nn)
    nn = Flatten()(nn)
    nn = Dense(n_units=1024, act=tf.nn.relu)(nn)
    nn = Dense(n_units=10, act=tf.identity)(nn)

    M = Model(inputs=ni, outputs=[nn, s])
    return M

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 15:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 84%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag410')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_stack.py: 19-35
</a>
<div class="mid" id="frag410" style="display:none"><pre>
    def setUpClass(cls):
        print("-" * 20, "Layer_Stack_Test", "-" * 20)
        cls.batch_size = 4
        cls.inputs_shape = [cls.batch_size, 10]

        cls.ni = Input(cls.inputs_shape, name='input_layer')
        a = Dense(n_units=5)(cls.ni)
        b = Dense(n_units=5)(cls.ni)
        cls.layer1 = Stack(axis=1)
        cls.n1 = cls.layer1([a, b])
        cls.M = Model(inputs=cls.ni, outputs=cls.n1)

        cls.inputs = tf.random.uniform(cls.inputs_shape)
        cls.n2 = cls.M(cls.inputs, is_train=True)

        print(cls.layer1)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag414')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_stack.py: 50-65
</a>
<div class="mid" id="frag414" style="display:none"><pre>
    def setUpClass(cls):
        print("-" * 20, "Layer_UnStack_Test", "-" * 20)
        cls.batch_size = 4
        cls.inputs_shape = [cls.batch_size, 10]

        cls.ni = Input(cls.inputs_shape, name='input_layer')
        a = Dense(n_units=5)(cls.ni)
        cls.layer1 = UnStack(axis=1)  # unstack in channel axis
        cls.n1 = cls.layer1(a)
        cls.M = Model(inputs=cls.ni, outputs=cls.n1)

        cls.inputs = tf.random.uniform(cls.inputs_shape)
        cls.n2 = cls.M(cls.inputs, is_train=True)

        print(cls.layer1)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 16:</b> &nbsp; 2 fragments, nominal size 19 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag420')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_merge.py: 26-49
</a>
<div class="mid" id="frag420" style="display:none"><pre>
    def test_concat(self):

        class CustomModel(tl.models.Model):

            def __init__(self):
                super(CustomModel, self).__init__()
                self.dense1 = tl.layers.Dense(in_channels=20, n_units=10, act=tf.nn.relu, name='relu1_1')
                self.dense2 = tl.layers.Dense(in_channels=20, n_units=10, act=tf.nn.relu, name='relu2_1')
                self.concat = tl.layers.Concat(concat_dim=1, name='concat_layer')

            def forward(self, inputs):
                d1 = self.dense1(inputs)
                d2 = self.dense2(inputs)
                outputs = self.concat([d1, d2])
                return outputs

        model = CustomModel()
        model.train()
        inputs = tf.convert_to_tensor(np.random.random([4, 20]).astype(np.float32))
        outputs = model(inputs)
        print(model)

        self.assertEqual(outputs.get_shape().as_list(), [4, 20])

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag423')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_merge.py: 50-76
</a>
<div class="mid" id="frag423" style="display:none"><pre>
    def test_elementwise(self):

        class CustomModel(tl.models.Model):

            def __init__(self):
                super(CustomModel, self).__init__()
                self.dense1 = tl.layers.Dense(in_channels=20, n_units=10, act=tf.nn.relu, name='relu1_1')
                self.dense2 = tl.layers.Dense(in_channels=20, n_units=10, act=tf.nn.relu, name='relu2_1')
                self.element = tl.layers.Elementwise(combine_fn=tf.minimum, name='minimum', act=tf.identity)

            def forward(self, inputs):
                d1 = self.dense1(inputs)
                d2 = self.dense2(inputs)
                outputs = self.element([d1, d2])
                return outputs, d1, d2

        model = CustomModel()
        model.train()
        inputs = tf.convert_to_tensor(np.random.random([4, 20]).astype(np.float32))
        outputs, d1, d2 = model(inputs)
        print(model)

        min = tf.minimum(d1, d2)
        self.assertEqual(outputs.get_shape().as_list(), [4, 10])
        self.assertTrue(np.array_equal(min.numpy(), outputs.numpy()))


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 17:</b> &nbsp; 2 fragments, nominal size 36 lines, similarity 97%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag432')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_core_nested.py: 26-71
</a>
<div class="mid" id="frag432" style="display:none"><pre>
    def test_nested_layer_with_inchannels(cls):

        class MyLayer(tl.layers.Layer):

            def __init__(self, name=None):
                super(MyLayer, self).__init__(name=name)
                self.input_layer = tl.layers.Dense(in_channels=50, n_units=20)
                self.build(None)
                self._built = True

            def build(self, inputs_shape=None):
                self.W = self._get_weights('weights', shape=(20, 10))

            def forward(self, inputs):
                inputs = self.input_layer(inputs)
                output = tf.matmul(inputs, self.W)
                return output

        class model(tl.models.Model):

            def __init__(self, name=None):
                super(model, self).__init__(name=name)
                self.layer = MyLayer()

            def forward(self, inputs):
                return self.layer(inputs)

        input = tf.random.normal(shape=(100, 50))
        model_dynamic = model()
        model_dynamic.train()
        cls.assertEqual(model_dynamic(input).shape, (100, 10))
        cls.assertEqual(len(model_dynamic.all_weights), 3)
        cls.assertEqual(len(model_dynamic.trainable_weights), 3)
        model_dynamic.layer.input_layer.b.assign_add(tf.ones((20, )))
        cls.assertEqual(np.sum(model_dynamic.all_weights[-1].numpy() - tf.ones(20, ).numpy()), 0)

        ni = tl.layers.Input(shape=(100, 50))
        nn = MyLayer(name='mylayer1')(ni)
        model_static = tl.models.Model(inputs=ni, outputs=nn)
        model_static.eval()
        cls.assertEqual(model_static(input).shape, (100, 10))
        cls.assertEqual(len(model_static.all_weights), 3)
        cls.assertEqual(len(model_static.trainable_weights), 3)
        model_static.get_layer('mylayer1').input_layer.b.assign_add(tf.ones((20, )))
        cls.assertEqual(np.sum(model_static.all_weights[-1].numpy() - tf.ones(20, ).numpy()), 0)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag438')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_core_nested.py: 72-118
</a>
<div class="mid" id="frag438" style="display:none"><pre>
    def test_nested_layer_without_inchannels(cls):

        class MyLayer(tl.layers.Layer):

            def __init__(self, name=None):
                super(MyLayer, self).__init__(name=name)
                self.input_layer = tl.layers.Dense(n_units=20)  # no need for in_channels here
                self.build(None)
                self._built = True

            def build(self, inputs_shape=None):
                self.W = self._get_weights('weights', shape=(20, 10))

            def forward(self, inputs):
                inputs = self.input_layer(inputs)
                output = tf.matmul(inputs, self.W)
                return output

        class model(tl.models.Model):

            def __init__(self, name=None):
                super(model, self).__init__(name=name)
                self.layer = MyLayer()

            def forward(self, inputs):
                return self.layer(inputs)

        input = tf.random.normal(shape=(100, 50))
        model_dynamic = model()
        model_dynamic.train()
        cls.assertEqual(model_dynamic(input).shape, (100, 10))
        cls.assertEqual(len(model_dynamic.all_weights), 3)
        cls.assertEqual(len(model_dynamic.trainable_weights), 3)
        model_dynamic.layer.input_layer.b.assign_add(tf.ones((20, )))
        cls.assertEqual(np.sum(model_dynamic.all_weights[-1].numpy() - tf.ones(20, ).numpy()), 0)

        ni = tl.layers.Input(shape=(100, 50))
        nn = MyLayer(name='mylayer2')(ni)
        model_static = tl.models.Model(inputs=ni, outputs=nn)
        model_static.eval()
        cls.assertEqual(model_static(input).shape, (100, 10))
        cls.assertEqual(len(model_static.all_weights), 3)
        cls.assertEqual(len(model_static.trainable_weights), 3)
        model_static.get_layer('mylayer2').input_layer.b.assign_add(tf.ones((20, )))
        cls.assertEqual(np.sum(model_static.all_weights[-1].numpy() - tf.ones(20, ).numpy()), 0)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 18:</b> &nbsp; 6 fragments, nominal size 19 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag469')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_recurrent.py: 49-76
</a>
<div class="mid" id="frag469" style="display:none"><pre>
    def test_basic_simplernn(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.RNN(
            cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, dropout=0.1), return_last_output=True,
            return_seq_2d=False, return_last_state=True
        )
        rnn, rnn_state = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn_state[0]])
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()
        assert rnnlayer.is_train

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y, final_state = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag485')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_recurrent.py: 280-306
</a>
<div class="mid" id="frag485" style="display:none"><pre>
    def test_basic_lstmrnn(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.RNN(
            cell=tf.keras.layers.LSTMCell(units=self.hidden_size, dropout=0.1), return_last_output=True,
            return_seq_2d=False, return_last_state=True
        )
        rnn, rnn_state = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn_state[0], rnn_state[1]])
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y, final_h, final_c = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag470')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_recurrent.py: 77-103
</a>
<div class="mid" id="frag470" style="display:none"><pre>
    def test_basic_simplernn_class(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.SimpleRNN(
            units=self.hidden_size, dropout=0.1, return_last_output=True, return_seq_2d=False, return_last_state=True
        )
        rnn, rnn_state = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn_state[0]])
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()
        assert rnnlayer.is_train

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y, final_state = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag487')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_recurrent.py: 333-359
</a>
<div class="mid" id="frag487" style="display:none"><pre>
    def test_basic_grurnn(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.RNN(
            cell=tf.keras.layers.GRUCell(units=self.hidden_size, dropout=0.1), return_last_output=True,
            return_seq_2d=False, return_last_state=True
        )
        rnn, rnn_state = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn_state[0]])
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y, final_h = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag486')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_recurrent.py: 307-332
</a>
<div class="mid" id="frag486" style="display:none"><pre>
    def test_basic_lstmrnn_class(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.LSTMRNN(
            units=self.hidden_size, dropout=0.1, return_last_output=True, return_seq_2d=False, return_last_state=True
        )
        rnn, rnn_state = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn_state[0], rnn_state[1]])
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y, final_h, final_c = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag488')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_recurrent.py: 360-385
</a>
<div class="mid" id="frag488" style="display:none"><pre>
    def test_basic_grurnn_class(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.GRURNN(
            units=self.hidden_size, dropout=0.1, return_last_output=True, return_seq_2d=False, return_last_state=True
        )
        rnn, rnn_state = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn_state[0]])
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y, final_h = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 19:</b> &nbsp; 5 fragments, nominal size 25 lines, similarity 73%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag473')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_recurrent.py: 140-172
</a>
<div class="mid" id="frag473" style="display:none"><pre>
    def test_basic_simplernn_dynamic(self):

        class CustomisedModel(tl.models.Model):

            def __init__(self):
                super(CustomisedModel, self).__init__()
                self.rnnlayer = tl.layers.RNN(
                    cell=tf.keras.layers.SimpleRNNCell(units=8, dropout=0.1), in_channels=4, return_last_output=False,
                    return_seq_2d=False, return_last_state=False
                )
                self.dense = tl.layers.Dense(in_channels=8, n_units=1)

            def forward(self, x):
                z = self.rnnlayer(x)
                z = self.dense(z[:, -1, :])
                return z

        rnn_model = CustomisedModel()
        print(rnn_model)
        optimizer = tf.optimizers.Adam(learning_rate=0.01)
        rnn_model.train()

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag482')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_recurrent.py: 240-279
</a>
<div class="mid" id="frag482" style="display:none"><pre>
    def test_basic_simplernn_dynamic_3(self):

        class CustomisedModel(tl.models.Model):

            def __init__(self):
                super(CustomisedModel, self).__init__()
                self.rnnlayer1 = tl.layers.RNN(
                    cell=tf.keras.layers.SimpleRNNCell(units=8, dropout=0.1), in_channels=4, return_last_output=True,
                    return_last_state=True
                )
                self.rnnlayer2 = tl.layers.RNN(
                    cell=tf.keras.layers.SimpleRNNCell(units=8, dropout=0.1), in_channels=4, return_last_output=True,
                    return_last_state=False
                )
                self.dense = tl.layers.Dense(in_channels=8, n_units=1)

            def forward(self, x):
                _, state = self.rnnlayer1(x[:, :2, :])
                z = self.rnnlayer2(x[:, 2:, :], initial_state=state)
                z = self.dense(z)
                return z

        rnn_model = CustomisedModel()
        print(rnn_model)
        optimizer = tf.optimizers.Adam(learning_rate=0.01)
        rnn_model.train()
        assert rnn_model.rnnlayer1.is_train
        assert rnn_model.rnnlayer2.is_train

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag476')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_recurrent.py: 173-205
</a>
<div class="mid" id="frag476" style="display:none"><pre>
    def test_basic_simplernn_dynamic_class(self):

        class CustomisedModel(tl.models.Model):

            def __init__(self):
                super(CustomisedModel, self).__init__()
                self.rnnlayer = tl.layers.SimpleRNN(
                    units=8, dropout=0.1, in_channels=4, return_last_output=False, return_seq_2d=False,
                    return_last_state=False
                )
                self.dense = tl.layers.Dense(in_channels=8, n_units=1)

            def forward(self, x):
                z = self.rnnlayer(x)
                z = self.dense(z[:, -1, :])
                return z

        rnn_model = CustomisedModel()
        print(rnn_model)
        optimizer = tf.optimizers.Adam(learning_rate=0.01)
        rnn_model.train()

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag491')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_recurrent.py: 453-488
</a>
<div class="mid" id="frag491" style="display:none"><pre>
    def test_basic_birnn_grucell(self):

        class CustomisedModel(tl.models.Model):

            def __init__(self):
                super(CustomisedModel, self).__init__()
                self.rnnlayer = tl.layers.BiRNN(
                    fw_cell=tf.keras.layers.GRUCell(units=8,
                                                    dropout=0.1), bw_cell=tf.keras.layers.GRUCell(units=8, dropout=0.1),
                    in_channels=4, return_seq_2d=False, return_last_state=False
                )
                self.dense = tl.layers.Dense(in_channels=16, n_units=1)
                self.reshape = tl.layers.Reshape([-1, 6])

            def forward(self, x):
                z = self.rnnlayer(x, return_seq_2d=True)
                z = self.dense(z)
                z = self.reshape(z)
                return z

        rnn_model = CustomisedModel()
        print(rnn_model)
        optimizer = tf.optimizers.Adam(learning_rate=0.01)
        rnn_model.train()

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag479')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_recurrent.py: 206-239
</a>
<div class="mid" id="frag479" style="display:none"><pre>
    def test_basic_simplernn_dynamic_2(self):

        class CustomisedModel(tl.models.Model):

            def __init__(self):
                super(CustomisedModel, self).__init__()
                self.rnnlayer = tl.layers.RNN(
                    cell=tf.keras.layers.SimpleRNNCell(units=8, dropout=0.1), in_channels=4, return_last_output=False,
                    return_seq_2d=False, return_last_state=False
                )
                self.dense = tl.layers.Dense(in_channels=8, n_units=1)

            def forward(self, x):
                z = self.rnnlayer(x, return_seq_2d=True)
                z = self.dense(z[-2:, :])
                return z

        rnn_model = CustomisedModel()
        print(rnn_model)
        optimizer = tf.optimizers.Adam(learning_rate=0.01)
        rnn_model.train()
        assert rnn_model.rnnlayer.is_train

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 20:</b> &nbsp; 2 fragments, nominal size 25 lines, similarity 92%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag489')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_recurrent.py: 386-418
</a>
<div class="mid" id="frag489" style="display:none"><pre>
    def test_basic_birnn_simplernncell(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.BiRNN(
            fw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, dropout=0.1),
            bw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size + 1,
                                                  dropout=0.1), return_seq_2d=True, return_last_state=True
        )
        rnn, rnn_fw_state, rnn_bw_state = rnnlayer(inputs)
        dense = tl.layers.Dense(n_units=1)(rnn)
        outputs = tl.layers.Reshape([-1, self.num_steps])(dense)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn, rnn_fw_state[0], rnn_bw_state[0]])
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()
        assert rnnlayer.is_train

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y, r, rfw, rbw = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y2)

            self.assertEqual(
                r.get_shape().as_list(), [self.batch_size * self.num_steps, self.hidden_size + self.hidden_size + 1]
            )
            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag490')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_recurrent.py: 419-452
</a>
<div class="mid" id="frag490" style="display:none"><pre>
    def test_basic_birnn_lstmcell(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.BiRNN(
            fw_cell=tf.keras.layers.LSTMCell(units=self.hidden_size, dropout=0.1),
            bw_cell=tf.keras.layers.LSTMCell(units=self.hidden_size + 1,
                                             dropout=0.1), return_seq_2d=False, return_last_state=True
        )
        rnn, rnn_fw_state, rnn_bw_state = rnnlayer(inputs)
        din = tl.layers.Reshape([-1, self.hidden_size + self.hidden_size + 1])(rnn)
        dense = tl.layers.Dense(n_units=1)(din)
        outputs = tl.layers.Reshape([-1, self.num_steps])(dense)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn, rnn_fw_state[0], rnn_bw_state[0]])
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()
        assert rnnlayer.is_train

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y, r, rfw, rbw = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y2)

            self.assertEqual(
                r.get_shape().as_list(), [self.batch_size, self.num_steps, self.hidden_size + self.hidden_size + 1]
            )
            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 21:</b> &nbsp; 2 fragments, nominal size 27 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag494')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_recurrent.py: 489-522
</a>
<div class="mid" id="frag494" style="display:none"><pre>
    def test_stack_simplernn(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer1 = tl.layers.RNN(
            cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, dropout=0.1), return_last_output=False,
            return_seq_2d=False, return_last_state=False
        )
        rnn1 = rnnlayer1(inputs)
        rnnlayer2 = tl.layers.RNN(
            cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, dropout=0.1), return_last_output=True,
            return_seq_2d=False, return_last_state=False
        )
        rnn2 = rnnlayer2(rnn1)
        outputs = tl.layers.Dense(n_units=1)(rnn2)
        rnn_model = tl.models.Model(inputs=inputs, outputs=outputs)
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()
        assert rnnlayer1.is_train
        assert rnnlayer2.is_train

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag495')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_recurrent.py: 523-559
</a>
<div class="mid" id="frag495" style="display:none"><pre>
    def test_stack_birnn_simplernncell(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.BiRNN(
            fw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, dropout=0.1),
            bw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size + 1,
                                                  dropout=0.1), return_seq_2d=False, return_last_state=False
        )
        rnn = rnnlayer(inputs)
        rnnlayer2 = tl.layers.BiRNN(
            fw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, dropout=0.1),
            bw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size + 1,
                                                  dropout=0.1), return_seq_2d=True, return_last_state=False
        )
        rnn2 = rnnlayer2(rnn)
        dense = tl.layers.Dense(n_units=1)(rnn2)
        outputs = tl.layers.Reshape([-1, self.num_steps])(dense)
        rnn_model = tl.models.Model(inputs=inputs, outputs=outputs)
        print(rnn_model)

        optimizer = tf.optimizers.Adam(learning_rate=0.01)

        rnn_model.train()
        assert rnnlayer.is_train
        assert rnnlayer2.is_train

        for epoch in range(50):
            with tf.GradientTape() as tape:
                pred_y = rnn_model(self.data_x)
                loss = tl.cost.mean_squared_error(pred_y, self.data_y2)

            gradients = tape.gradient(loss, rnn_model.trainable_weights)
            optimizer.apply_gradients(zip(gradients, rnn_model.trainable_weights))

            if (epoch + 1) % 10 == 0:
                print("epoch %d, loss %f" % (epoch, loss))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 22:</b> &nbsp; 4 fragments, nominal size 19 lines, similarity 85%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag496')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_recurrent.py: 560-585
</a>
<div class="mid" id="frag496" style="display:none"><pre>
    def test_basic_simplernn_dropout_1(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.RNN(
            cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, dropout=0.5), return_last_output=True,
            return_seq_2d=False, return_last_state=False
        )
        rnn = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn])
        print(rnn_model)

        rnn_model.train()
        assert rnnlayer.is_train

        pred_y, rnn_1 = rnn_model(self.data_x)
        pred_y, rnn_2 = rnn_model(self.data_x)
        self.assertFalse(np.allclose(rnn_1, rnn_2))

        rnn_model.eval()
        assert not rnnlayer.is_train

        pred_y_1, rnn_1 = rnn_model(self.data_x)
        pred_y_2, rnn_2 = rnn_model(self.data_x)
        self.assertTrue(np.allclose(rnn_1, rnn_2))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag499')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_recurrent.py: 639-665
</a>
<div class="mid" id="frag499" style="display:none"><pre>
    def test_basic_birnn_simplernn_dropout_2(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.BiRNN(
            fw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, recurrent_dropout=0.5),
            bw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size,
                                                  recurrent_dropout=0.5), return_seq_2d=True, return_last_state=False
        )
        rnn = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn])
        print(rnn_model)

        rnn_model.train()
        assert rnnlayer.is_train

        pred_y, rnn_1 = rnn_model(self.data_x)
        pred_y, rnn_2 = rnn_model(self.data_x)
        self.assertFalse(np.allclose(rnn_1, rnn_2))

        rnn_model.eval()
        assert not rnnlayer.is_train

        pred_y_1, rnn_1 = rnn_model(self.data_x)
        pred_y_2, rnn_2 = rnn_model(self.data_x)
        self.assertTrue(np.allclose(rnn_1, rnn_2))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag498')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_recurrent.py: 612-638
</a>
<div class="mid" id="frag498" style="display:none"><pre>
    def test_basic_birnn_simplernn_dropout_1(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.BiRNN(
            fw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, dropout=0.5),
            bw_cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size,
                                                  dropout=0.5), return_seq_2d=True, return_last_state=False
        )
        rnn = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn])
        print(rnn_model)

        rnn_model.train()
        assert rnnlayer.is_train

        pred_y, rnn_1 = rnn_model(self.data_x)
        pred_y, rnn_2 = rnn_model(self.data_x)
        self.assertFalse(np.allclose(rnn_1, rnn_2))

        rnn_model.eval()
        assert not rnnlayer.is_train

        pred_y_1, rnn_1 = rnn_model(self.data_x)
        pred_y_2, rnn_2 = rnn_model(self.data_x)
        self.assertTrue(np.allclose(rnn_1, rnn_2))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag497')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_recurrent.py: 586-611
</a>
<div class="mid" id="frag497" style="display:none"><pre>
    def test_basic_simplernn_dropout_2(self):

        inputs = tl.layers.Input([self.batch_size, self.num_steps, self.embedding_size])
        rnnlayer = tl.layers.RNN(
            cell=tf.keras.layers.SimpleRNNCell(units=self.hidden_size, recurrent_dropout=0.5), return_last_output=True,
            return_seq_2d=False, return_last_state=False
        )
        rnn = rnnlayer(inputs)
        outputs = tl.layers.Dense(n_units=1)(rnn)
        rnn_model = tl.models.Model(inputs=inputs, outputs=[outputs, rnn])
        print(rnn_model)

        rnn_model.train()
        assert rnnlayer.is_train

        pred_y, rnn_1 = rnn_model(self.data_x)
        pred_y, rnn_2 = rnn_model(self.data_x)
        self.assertFalse(np.allclose(rnn_1, rnn_2))

        rnn_model.eval()
        assert not rnnlayer.is_train

        pred_y_1, rnn_1 = rnn_model(self.data_x)
        pred_y_2, rnn_2 = rnn_model(self.data_x)
        self.assertTrue(np.allclose(rnn_1, rnn_2))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 23:</b> &nbsp; 6 fragments, nominal size 15 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag522')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_activation.py: 27-45
</a>
<div class="mid" id="frag522" style="display:none"><pre>
    def test_prelu_1(self):
        inputs = tl.layers.Input([10, 5])
        prelulayer = tl.layers.PRelu(channel_shared=True)
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data.shape)
        for i in range(len(gt)):
            for j in range(len(gt[i])):
                if self.data[i][j] &gt;= 0:
                    gt[i][j] = self.data[i][j]
                else:
                    gt[i][j] = prelulayer.alpha_var_constrained.numpy() * self.data[i][j]

        self.assertTrue(np.array_equal(out.numpy(), gt))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag523')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_activation.py: 46-64
</a>
<div class="mid" id="frag523" style="display:none"><pre>
    def test_prelu_2(self):
        inputs = tl.layers.Input([10, 5])
        prelulayer = tl.layers.PRelu(in_channels=5)
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data.shape)
        for i in range(len(gt)):
            for j in range(len(gt[i])):
                if self.data[i][j] &gt;= 0:
                    gt[i][j] = self.data[i][j]
                else:
                    gt[i][j] = prelulayer.alpha_var_constrained.numpy()[j] * self.data[i][j]

        self.assertTrue(np.array_equal(out.numpy(), gt))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag529')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_activation.py: 171-191
</a>
<div class="mid" id="frag529" style="display:none"><pre>
    def test_ptrelu6_2(self):
        inputs = tl.layers.Input([10, 5])
        prelulayer = tl.layers.PTRelu6(in_channels=5)
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data.shape)
        for i in range(len(gt)):
            for j in range(len(gt[i])):
                if self.data[i][j] &gt;= 0 and self.data[i][j] &lt;= 6:
                    gt[i][j] = self.data[i][j]
                elif self.data[i][j] &gt; 6:
                    gt[i][j] = 6 + prelulayer.alpha_high_constrained.numpy()[j] * (self.data[i][j] - 6)
                else:
                    gt[i][j] = prelulayer.alpha_low_constrained.numpy()[j] * self.data[i][j]

        self.assertTrue(np.allclose(out.numpy(), gt))

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag528')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_activation.py: 149-170
</a>
<div class="mid" id="frag528" style="display:none"><pre>
    def test_ptrelu6_1(self):
        inputs = tl.layers.Input([10, 5])
        prelulayer = tl.layers.PTRelu6(channel_shared=True)
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data.shape)
        for i in range(len(gt)):
            for j in range(len(gt[i])):
                if self.data[i][j] &gt;= 0 and self.data[i][j] &lt;= 6:
                    gt[i][j] = self.data[i][j]
                elif self.data[i][j] &gt; 6:
                    gt[i][j] = 6 + prelulayer.alpha_high_constrained.numpy() * (self.data[i][j] - 6)
                else:
                    gt[i][j] = prelulayer.alpha_low_constrained.numpy() * self.data[i][j]

        # FIXME: Figure out why this assert randomly fail in CI.
        # self.assertTrue(np.array_equal(out.numpy(), gt))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag525')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_activation.py: 85-105
</a>
<div class="mid" id="frag525" style="display:none"><pre>
    def test_prelu6_1(self):
        inputs = tl.layers.Input([10, 5])
        prelulayer = tl.layers.PRelu6(channel_shared=True)
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data.shape)
        for i in range(len(gt)):
            for j in range(len(gt[i])):
                if self.data[i][j] &gt;= 0 and self.data[i][j] &lt;= 6:
                    gt[i][j] = self.data[i][j]
                elif self.data[i][j] &gt; 6:
                    gt[i][j] = 6
                else:
                    gt[i][j] = prelulayer.alpha_var_constrained.numpy() * self.data[i][j]

        self.assertTrue(np.array_equal(out.numpy(), gt))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag526')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_activation.py: 106-126
</a>
<div class="mid" id="frag526" style="display:none"><pre>
    def test_prelu6_2(self):
        inputs = tl.layers.Input([10, 5])
        prelulayer = tl.layers.PRelu6(in_channels=5)
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data.shape)
        for i in range(len(gt)):
            for j in range(len(gt[i])):
                if self.data[i][j] &gt;= 0 and self.data[i][j] &lt;= 6:
                    gt[i][j] = self.data[i][j]
                elif self.data[i][j] &gt; 6:
                    gt[i][j] = 6
                else:
                    gt[i][j] = prelulayer.alpha_var_constrained.numpy()[j] * self.data[i][j]

        self.assertTrue(np.array_equal(out.numpy(), gt))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 24:</b> &nbsp; 3 fragments, nominal size 17 lines, similarity 77%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag524')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_activation.py: 65-84
</a>
<div class="mid" id="frag524" style="display:none"><pre>
    def test_prelu_3(self):
        inputs = tl.layers.Input([10, 10, 5])
        prelulayer = tl.layers.PRelu(in_channels=5)
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data2, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data2.shape)
        for i in range(len(gt)):
            for k in range(len(gt[i])):
                for j in range(len(gt[i][k])):
                    if self.data2[i][k][j] &gt;= 0:
                        gt[i][k][j] = self.data2[i][k][j]
                    else:
                        gt[i][k][j] = prelulayer.alpha_var_constrained.numpy()[j] * self.data2[i][k][j]

        self.assertTrue(np.array_equal(out.numpy(), gt))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag527')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_activation.py: 127-148
</a>
<div class="mid" id="frag527" style="display:none"><pre>
    def test_prelu6_3(self):
        inputs = tl.layers.Input([10, 10, 5])
        prelulayer = tl.layers.PRelu6(in_channels=5)
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data2, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data2.shape)
        for i in range(len(gt)):
            for k in range(len(gt[i])):
                for j in range(len(gt[i][k])):
                    if self.data2[i][k][j] &gt;= 0 and self.data2[i][k][j] &lt;= 6:
                        gt[i][k][j] = self.data2[i][k][j]
                    elif self.data2[i][k][j] &gt; 6:
                        gt[i][k][j] = 6
                    else:
                        gt[i][k][j] = prelulayer.alpha_var_constrained.numpy()[j] * self.data2[i][k][j]

        self.assertTrue(np.array_equal(out.numpy(), gt))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag530')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_activation.py: 192-214
</a>
<div class="mid" id="frag530" style="display:none"><pre>
    def test_ptrelu6_3(self):
        inputs = tl.layers.Input([3, 2, 5])
        prelulayer = tl.layers.PTRelu6()
        prelu = prelulayer(inputs)
        model = tl.models.Model(inputs=inputs, outputs=prelu)
        out = model(self.data2, is_train=True)

        print(prelulayer)

        gt = np.zeros(shape=self.data2.shape)
        for i in range(len(gt)):
            for k in range(len(gt[i])):
                for j in range(len(gt[i][k])):
                    if self.data2[i][k][j] &gt;= 0 and self.data2[i][k][j] &lt;= 6:
                        gt[i][k][j] = self.data2[i][k][j]
                    elif self.data2[i][k][j] &gt; 6:
                        gt[i][k][j] = 6 + prelulayer.alpha_high_constrained.numpy()[j] * (self.data2[i][k][j] - 6)
                    else:
                        gt[i][k][j] = prelulayer.alpha_low_constrained.numpy()[j] * self.data2[i][k][j]

        self.assertTrue(np.allclose(out.numpy(), gt))


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 25:</b> &nbsp; 5 fragments, nominal size 17 lines, similarity 88%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag555')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_dense.py: 20-41
</a>
<div class="mid" id="frag555" style="display:none"><pre>
    def setUpClass(cls):
        print("-" * 20, "Layer_BinaryDense_Test", "-" * 20)
        cls.batch_size = 4
        cls.inputs_shape = [cls.batch_size, 10]

        cls.ni = Input(cls.inputs_shape, name='input_layer')
        cls.layer1 = BinaryDense(n_units=5)
        nn = cls.layer1(cls.ni)
        cls.layer1._nodes_fixed = True
        cls.M = Model(inputs=cls.ni, outputs=nn)

        cls.layer2 = BinaryDense(n_units=5, in_channels=10)
        cls.layer2._nodes_fixed = True

        cls.inputs = tf.ones((cls.inputs_shape))
        cls.n1 = cls.layer1(cls.inputs)
        cls.n2 = cls.layer2(cls.inputs)
        cls.n3 = cls.M(cls.inputs, is_train=True)

        print(cls.layer1)
        print(cls.layer2)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag567')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_dense.py: 136-157
</a>
<div class="mid" id="frag567" style="display:none"><pre>
    def setUpClass(cls):
        print("-" * 20, "Layer_DropconnectDense_Test", "-" * 20)
        cls.batch_size = 4
        cls.inputs_shape = [cls.batch_size, 10]

        cls.ni = Input(cls.inputs_shape, name='input_layer')
        cls.layer1 = DropconnectDense(n_units=5, keep=1.0)
        nn = cls.layer1(cls.ni)
        cls.layer1._nodes_fixed = True
        cls.M = Model(inputs=cls.ni, outputs=nn)

        cls.layer2 = DropconnectDense(n_units=5, in_channels=10, keep=0.01)
        cls.layer2._nodes_fixed = True

        cls.inputs = tf.ones((cls.inputs_shape))
        cls.n1 = cls.layer1(cls.inputs)
        cls.n2 = cls.layer2(cls.inputs)
        cls.n3 = cls.M(cls.inputs, is_train=True)

        print(cls.layer1)
        print(cls.layer2)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag573')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_dense.py: 194-215
</a>
<div class="mid" id="frag573" style="display:none"><pre>
    def setUpClass(cls):
        print("-" * 20, "Layer_QuanDense_Test", "-" * 20)
        cls.batch_size = 4
        cls.inputs_shape = [cls.batch_size, 10]

        cls.ni = Input(cls.inputs_shape, name='input_layer')
        cls.layer1 = QuanDense(n_units=5)
        nn = cls.layer1(cls.ni)
        cls.layer1._nodes_fixed = True
        cls.M = Model(inputs=cls.ni, outputs=nn)

        cls.layer2 = QuanDense(n_units=5, in_channels=10)
        cls.layer2._nodes_fixed = True

        cls.inputs = tf.random.uniform((cls.inputs_shape))
        cls.n1 = cls.layer1(cls.inputs)
        cls.n2 = cls.layer2(cls.inputs)
        cls.n3 = cls.M(cls.inputs, is_train=True)

        print(cls.layer1)
        print(cls.layer2)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag561')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_dense.py: 78-99
</a>
<div class="mid" id="frag561" style="display:none"><pre>
    def setUpClass(cls):
        print("-" * 20, "Layer_DorefaDense_Test", "-" * 20)
        cls.batch_size = 4
        cls.inputs_shape = [cls.batch_size, 10]

        cls.ni = Input(cls.inputs_shape, name='input_layer')
        cls.layer1 = DorefaDense(n_units=5)
        nn = cls.layer1(cls.ni)
        cls.layer1._nodes_fixed = True
        cls.M = Model(inputs=cls.ni, outputs=nn)

        cls.layer2 = DorefaDense(n_units=5, in_channels=10)
        cls.layer2._nodes_fixed = True

        cls.inputs = tf.ones((cls.inputs_shape))
        cls.n1 = cls.layer1(cls.inputs)
        cls.n2 = cls.layer2(cls.inputs)
        cls.n3 = cls.M(cls.inputs, is_train=True)

        print(cls.layer1)
        print(cls.layer2)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag579')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_dense.py: 249-270
</a>
<div class="mid" id="frag579" style="display:none"><pre>
    def setUpClass(cls):
        print("-" * 20, "Layer_BinaryDense_Test", "-" * 20)
        cls.batch_size = 4
        cls.inputs_shape = [cls.batch_size, 10]

        cls.ni = Input(cls.inputs_shape, name='input_layer')
        cls.layer1 = TernaryDense(n_units=5)
        nn = cls.layer1(cls.ni)
        cls.layer1._nodes_fixed = True
        cls.M = Model(inputs=cls.ni, outputs=nn)

        cls.layer2 = TernaryDense(n_units=5, in_channels=10)
        cls.layer2._nodes_fixed = True

        cls.inputs = tf.ones((cls.inputs_shape))
        cls.n1 = cls.layer1(cls.inputs)
        cls.n2 = cls.layer2(cls.inputs)
        cls.n3 = cls.M(cls.inputs, is_train=True)

        print(cls.layer1)
        print(cls.layer2)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 26:</b> &nbsp; 5 fragments, nominal size 14 lines, similarity 85%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag560')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_dense.py: 58-74
</a>
<div class="mid" id="frag560" style="display:none"><pre>
    def test_exception(self):
        try:
            layer = BinaryDense(n_units=5)
            inputs = Input([4, 10, 5], name='ill_inputs')
            out = layer(inputs)
            self.fail('ill inputs')
        except Exception as e:
            print(e)

        try:
            layer = BinaryDense(n_units=5, use_gemm=True)
            out = layer(self.ni)
            self.fail('use gemm')
        except Exception as e:
            print(e)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag572')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_dense.py: 174-190
</a>
<div class="mid" id="frag572" style="display:none"><pre>
    def test_exception(self):
        try:
            layer = DropconnectDense(n_units=5)
            inputs = Input([4, 10, 5], name='ill_inputs')
            out = layer(inputs)
            self.fail('ill inputs')
        except Exception as e:
            print(e)

        try:
            layer = DropconnectDense(n_units=5, keep=0.0)
            self.fail('keep no elements')
        except Exception as e:
            self.assertIsInstance(e, ValueError)
            print(e)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag578')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_dense.py: 229-245
</a>
<div class="mid" id="frag578" style="display:none"><pre>
    def test_exception(self):
        try:
            layer = QuanDense(n_units=5)
            inputs = Input([4, 10, 5], name='ill_inputs')
            out = layer(inputs)
            self.fail('ill inputs')
        except Exception as e:
            print(e)

        try:
            layer = QuanDense(n_units=5, use_gemm=True)
            out = layer(self.ni)
            self.fail('use gemm')
        except Exception as e:
            print(e)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag566')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_dense.py: 116-132
</a>
<div class="mid" id="frag566" style="display:none"><pre>
    def test_exception(self):
        try:
            layer = DorefaDense(n_units=5)
            inputs = Input([4, 10, 5], name='ill_inputs')
            out = layer(inputs)
            self.fail('ill inputs')
        except Exception as e:
            print(e)

        try:
            layer = DorefaDense(n_units=5, use_gemm=True)
            out = layer(self.ni)
            self.fail('use gemm')
        except Exception as e:
            print(e)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag584')" href="javascript:;">
TensorLayer-2.2.1/tests/layers/test_layers_dense.py: 287-303
</a>
<div class="mid" id="frag584" style="display:none"><pre>
    def test_exception(self):
        try:
            layer = TernaryDense(n_units=5)
            inputs = Input([4, 10, 5], name='ill_inputs')
            out = layer(inputs)
            self.fail('ill inputs')
        except Exception as e:
            print(e)

        try:
            layer = TernaryDense(n_units=5, use_gemm=True)
            out = layer(self.ni)
            self.fail('use gemm')
        except Exception as e:
            print(e)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 27:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag609')" href="javascript:;">
TensorLayer-2.2.1/examples/spatial_transformer_network/tutorial_spatial_transformer_network_dynamic.py: 16-36
</a>
<div class="mid" id="frag609" style="display:none"><pre>

def pad_distort_im_fn(x):
    """ Zero pads an image to 40x40, and distort it.

    Examples
    ---------
    x = pad_distort_im_fn(X_train[0])
    print(x, x.shape, x.max())
    tl.vis.save_image(x, '_xd.png')
    tl.vis.save_image(X_train[0], '_x.png')
    """
    b = np.zeros((40, 40, 1), dtype=np.float32)
    o = int((40 - 28) / 2)
    b[o:o + 28, o:o + 28] = x
    x = b
    x = tl.prepro.rotation(x, rg=30, is_random=True, fill_mode='constant')
    x = tl.prepro.shear(x, 0.05, is_random=True, fill_mode='constant')
    x = tl.prepro.shift(x, wrg=0.25, hrg=0.25, is_random=True, fill_mode='constant')
    x = tl.prepro.zoom(x, zoom_range=(0.95, 1.05))
    return x

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag613')" href="javascript:;">
TensorLayer-2.2.1/examples/spatial_transformer_network/tutorial_spatial_transformer_network_static.py: 16-36
</a>
<div class="mid" id="frag613" style="display:none"><pre>

def pad_distort_im_fn(x):
    """ Zero pads an image to 40x40, and distort it.

    Examples
    ---------
    x = pad_distort_im_fn(X_train[0])
    print(x, x.shape, x.max())
    tl.vis.save_image(x, '_xd.png')
    tl.vis.save_image(X_train[0], '_x.png')
    """
    b = np.zeros((40, 40, 1), dtype=np.float32)
    o = int((40 - 28) / 2)
    b[o:o + 28, o:o + 28] = x
    x = b
    x = tl.prepro.rotation(x, rg=30, is_random=True, fill_mode='constant')
    x = tl.prepro.shear(x, 0.05, is_random=True, fill_mode='constant')
    x = tl.prepro.shift(x, wrg=0.25, hrg=0.25, is_random=True, fill_mode='constant')
    x = tl.prepro.zoom(x, zoom_range=(0.95, 1.05))
    return x

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 28:</b> &nbsp; 2 fragments, nominal size 39 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag632')" href="javascript:;">
TensorLayer-2.2.1/examples/text_generation/tutorial_generate_text.py: 42-83
</a>
<div class="mid" id="frag632" style="display:none"><pre>
def basic_clean_str(string):
    """Tokenization/string cleaning for a datasets."""
    string = re.sub(r"\n", " ", string)  # '\n'      --&gt; ' '
    string = re.sub(r"\'s", " \'s", string)  # it's      --&gt; it 's
    string = re.sub(r"\s", " \'s", string)
    string = re.sub(r"\'ve", " have", string)  # they've   --&gt; they have
    string = re.sub(r"\ve", " have", string)
    string = re.sub(r"\'t", " not", string)  # can't     --&gt; can not
    string = re.sub(r"\t", " not", string)
    string = re.sub(r"\'re", " are", string)  # they're   --&gt; they are
    string = re.sub(r"\re", " are", string)
    string = re.sub(r"\'d", "", string)  # I'd (I had, I would) --&gt; I
    string = re.sub(r"\d", "", string)
    string = re.sub(r"\'ll", " will", string)  # I'll      --&gt; I will
    string = re.sub(r"\ll", " will", string)
    string = re.sub(r"\", "  ", string)  # a       --&gt;  a 
    string = re.sub(r"\", "  ", string)
    string = re.sub(r"\"", "  ", string)  # "a"       --&gt; " a "
    string = re.sub(r"\'", "  ", string)  # they'     --&gt; they '
    string = re.sub(r"\", "  ", string)  # they     --&gt; they 
    string = re.sub(r"\.", " . ", string)  # they.     --&gt; they .
    string = re.sub(r"\,", " , ", string)  # they,     --&gt; they ,
    string = re.sub(r"\!", " ! ", string)
    string = re.sub(r"\-", "  ", string)  # "low-cost"--&gt; lost cost
    string = re.sub(r"\(", "  ", string)  # (they)    --&gt; ( they)
    string = re.sub(r"\)", "  ", string)  # ( they)   --&gt; ( they )
    string = re.sub(r"\]", "  ", string)  # they]     --&gt; they ]
    string = re.sub(r"\[", "  ", string)  # they[     --&gt; they [
    string = re.sub(r"\?", "  ", string)  # they?     --&gt; they ?
    string = re.sub(r"\&gt;", "  ", string)  # they&gt;     --&gt; they &gt;
    string = re.sub(r"\&lt;", "  ", string)  # they&lt;     --&gt; they &lt;
    string = re.sub(r"\=", "  ", string)  # easier=   --&gt; easier =
    string = re.sub(r"\;", "  ", string)  # easier;   --&gt; easier ;
    string = re.sub(r"\;", "  ", string)
    string = re.sub(r"\:", "  ", string)  # easier:   --&gt; easier :
    string = re.sub(r"\"", "  ", string)  # easier"   --&gt; easier "
    string = re.sub(r"\$", "  ", string)  # $380      --&gt; $ 380
    string = re.sub(r"\_", "  ", string)  # _100     --&gt; _ 100
    string = re.sub(r"\s{2,}", " ", string)  # Akara is    handsome --&gt; Akara is handsome
    return string.strip().lower()  # lowercase


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag633')" href="javascript:;">
TensorLayer-2.2.1/examples/text_generation/tutorial_generate_text.py: 84-125
</a>
<div class="mid" id="frag633" style="display:none"><pre>
def customized_clean_str(string):
    """Tokenization/string cleaning for a datasets."""
    string = re.sub(r"\n", " ", string)  # '\n'      --&gt; ' '
    string = re.sub(r"\'s", " \'s", string)  # it's      --&gt; it 's
    string = re.sub(r"\s", " \'s", string)
    string = re.sub(r"\'ve", " have", string)  # they've   --&gt; they have
    string = re.sub(r"\ve", " have", string)
    string = re.sub(r"\'t", " not", string)  # can't     --&gt; can not
    string = re.sub(r"\t", " not", string)
    string = re.sub(r"\'re", " are", string)  # they're   --&gt; they are
    string = re.sub(r"\re", " are", string)
    string = re.sub(r"\'d", "", string)  # I'd (I had, I would) --&gt; I
    string = re.sub(r"\d", "", string)
    string = re.sub(r"\'ll", " will", string)  # I'll      --&gt; I will
    string = re.sub(r"\ll", " will", string)
    string = re.sub(r"\", "  ", string)  # a       --&gt;  a 
    string = re.sub(r"\", "  ", string)
    string = re.sub(r"\"", "  ", string)  # "a"       --&gt; " a "
    string = re.sub(r"\'", " ' ", string)  # they'     --&gt; they '
    string = re.sub(r"\", " ' ", string)  # they     --&gt; they '
    string = re.sub(r"\.", " . ", string)  # they.     --&gt; they .
    string = re.sub(r"\,", " , ", string)  # they,     --&gt; they ,
    string = re.sub(r"\-", " ", string)  # "low-cost"--&gt; lost cost
    string = re.sub(r"\(", " ( ", string)  # (they)    --&gt; ( they)
    string = re.sub(r"\)", " ) ", string)  # ( they)   --&gt; ( they )
    string = re.sub(r"\!", " ! ", string)  # they!     --&gt; they !
    string = re.sub(r"\]", " ] ", string)  # they]     --&gt; they ]
    string = re.sub(r"\[", " [ ", string)  # they[     --&gt; they [
    string = re.sub(r"\?", " ? ", string)  # they?     --&gt; they ?
    string = re.sub(r"\&gt;", " &gt; ", string)  # they&gt;     --&gt; they &gt;
    string = re.sub(r"\&lt;", " &lt; ", string)  # they&lt;     --&gt; they &lt;
    string = re.sub(r"\=", " = ", string)  # easier=   --&gt; easier =
    string = re.sub(r"\;", " ; ", string)  # easier;   --&gt; easier ;
    string = re.sub(r"\;", " ; ", string)
    string = re.sub(r"\:", " : ", string)  # easier:   --&gt; easier :
    string = re.sub(r"\"", " \" ", string)  # easier"   --&gt; easier "
    string = re.sub(r"\$", " $ ", string)  # $380      --&gt; $ 380
    string = re.sub(r"\_", " _ ", string)  # _100     --&gt; _ 100
    string = re.sub(r"\s{2,}", " ", string)  # Akara is    handsome --&gt; Akara is handsome
    return string.strip().lower()  # lowercase


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 29:</b> &nbsp; 2 fragments, nominal size 17 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag641')" href="javascript:;">
TensorLayer-2.2.1/examples/basic_tutorials/tutorial_cifar10_cnn_static.py: 23-47
</a>
<div class="mid" id="frag641" style="display:none"><pre>
def get_model(inputs_shape):
    # self defined initialization
    W_init = tl.initializers.truncated_normal(stddev=5e-2)
    W_init2 = tl.initializers.truncated_normal(stddev=0.04)
    b_init2 = tl.initializers.constant(value=0.1)

    # build network
    ni = Input(inputs_shape)
    nn = Conv2d(64, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, W_init=W_init, b_init=None, name='conv1')(ni)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool1')(nn)
    nn = LocalResponseNorm(depth_radius=4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name="norm1")(nn)

    nn = Conv2d(64, (5, 5), (1, 1), padding='SAME', act=tf.nn.relu, W_init=W_init, b_init=None, name='conv2')(nn)
    nn = LocalResponseNorm(depth_radius=4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name="norm2")(nn)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool2')(nn)

    nn = Flatten(name='flatten')(nn)
    nn = Dense(384, act=tf.nn.relu, W_init=W_init2, b_init=b_init2, name='dense1relu')(nn)
    nn = Dense(192, act=tf.nn.relu, W_init=W_init2, b_init=b_init2, name='dense2relu')(nn)
    nn = Dense(10, act=None, W_init=W_init2, name='output')(nn)

    M = Model(inputs=ni, outputs=nn, name='cnn')
    return M


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag642')" href="javascript:;">
TensorLayer-2.2.1/examples/basic_tutorials/tutorial_cifar10_cnn_static.py: 48-73
</a>
<div class="mid" id="frag642" style="display:none"><pre>
def get_model_batchnorm(inputs_shape):
    # self defined initialization
    W_init = tl.initializers.truncated_normal(stddev=5e-2)
    W_init2 = tl.initializers.truncated_normal(stddev=0.04)
    b_init2 = tl.initializers.constant(value=0.1)

    # build network
    ni = Input(inputs_shape)
    nn = Conv2d(64, (5, 5), (1, 1), padding='SAME', W_init=W_init, b_init=None, name='conv1')(ni)
    nn = BatchNorm(decay=0.99, act=tf.nn.relu, name='batch1')(nn)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool1')(nn)

    nn = Conv2d(64, (5, 5), (1, 1), padding='SAME', W_init=W_init, b_init=None, name='conv2')(nn)
    nn = BatchNorm(decay=0.99, act=tf.nn.relu, name='batch2')(nn)
    nn = MaxPool2d((3, 3), (2, 2), padding='SAME', name='pool2')(nn)

    nn = Flatten(name='flatten')(nn)
    nn = Dense(384, act=tf.nn.relu, W_init=W_init2, b_init=b_init2, name='dense1relu')(nn)
    nn = Dense(192, act=tf.nn.relu, W_init=W_init2, b_init=b_init2, name='dense2relu')(nn)
    nn = Dense(10, act=None, W_init=W_init2, name='output')(nn)

    M = Model(inputs=ni, outputs=nn, name='cnn')
    return M


# get the network
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 30:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag671')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_SAC.py: 176-196
</a>
<div class="mid" id="frag671" style="display:none"><pre>
    def __init__(
        self, num_inputs, num_actions, hidden_dim, action_range=1., init_w=3e-3, log_std_min=-20, log_std_max=2
    ):
        super(PolicyNetwork, self).__init__()

        self.log_std_min = log_std_min
        self.log_std_max = log_std_max

        w_init = tf.keras.initializers.glorot_normal(seed=None)
        # w_init = tf.random_uniform_initializer(-init_w, init_w)

        self.linear1 = Dense(n_units=hidden_dim, act=tf.nn.relu, W_init=w_init, in_channels=num_inputs, name='policy1')
        self.linear2 = Dense(n_units=hidden_dim, act=tf.nn.relu, W_init=w_init, in_channels=hidden_dim, name='policy2')
        self.linear3 = Dense(n_units=hidden_dim, act=tf.nn.relu, W_init=w_init, in_channels=hidden_dim, name='policy3')

        self.mean_linear = Dense(n_units=num_actions, W_init=w_init, \
        b_init=tf.random_uniform_initializer(-init_w, init_w), in_channels=hidden_dim, name='policy_mean')
        self.log_std_linear = Dense(n_units=num_actions, W_init=w_init, \
        b_init=tf.random_uniform_initializer(-init_w, init_w), in_channels=hidden_dim, name='policy_logstd')

        self.action_range = action_range
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag685')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/algorithms/sac/sac.py: 43-63
</a>
<div class="mid" id="frag685" style="display:none"><pre>
    def __init__(
        self, num_inputs, num_actions, hidden_dim, action_range=1., init_w=3e-3, log_std_min=-20, log_std_max=2
    ):
        super(PolicyNetwork, self).__init__()

        self.log_std_min = log_std_min
        self.log_std_max = log_std_max

        w_init = tf.keras.initializers.glorot_normal(seed=None)
        # w_init = tf.random_uniform_initializer(-init_w, init_w)

        self.linear1 = Dense(n_units=hidden_dim, act=tf.nn.relu, W_init=w_init, in_channels=num_inputs, name='policy1')
        self.linear2 = Dense(n_units=hidden_dim, act=tf.nn.relu, W_init=w_init, in_channels=hidden_dim, name='policy2')
        self.linear3 = Dense(n_units=hidden_dim, act=tf.nn.relu, W_init=w_init, in_channels=hidden_dim, name='policy3')

        self.mean_linear = Dense(n_units=num_actions, W_init=w_init, \
        b_init=tf.random_uniform_initializer(-init_w, init_w), in_channels=hidden_dim, name='policy_mean')
        self.log_std_linear = Dense(n_units=num_actions, W_init=w_init, \
        b_init=tf.random_uniform_initializer(-init_w, init_w), in_channels=hidden_dim, name='policy_logstd')

        self.action_range = action_range
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 31:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag673')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_SAC.py: 208-227
</a>
<div class="mid" id="frag673" style="display:none"><pre>
        return mean, log_std

    def evaluate(self, state, epsilon=1e-6):
        ''' generate action with state for calculating gradients '''
        state = state.astype(np.float32)
        mean, log_std = self.forward(state)
        std = tf.math.exp(log_std)  # no clip in evaluation, clip affects gradients flow

        normal = Normal(0, 1)
        z = normal.sample()
        action_0 = tf.math.tanh(mean + std * z)  # TanhNormal distribution as actions; reparameterization trick
        action = self.action_range * action_0
        # according to original paper, with an extra last term for normalizing different action range
        log_prob = Normal(mean, std).log_prob(mean + std * z) - tf.math.log(1. - action_0**2 +
                                                                            epsilon) - np.log(self.action_range)
        # both dims of normal.log_prob and -log(1-a**2) are (N,dim_of_action);
        # the Normal.log_prob outputs the same dim of input features instead of 1 dim probability,
        # needs sum up across the dim of actions to get 1 dim probability; or else use Multivariate Normal.
        log_prob = tf.reduce_sum(log_prob, axis=1)[:, np.newaxis]  # expand dim as reduce_sum causes 1 dim reduced

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag687')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/algorithms/sac/sac.py: 75-94
</a>
<div class="mid" id="frag687" style="display:none"><pre>
        return mean, log_std

    def evaluate(self, state, epsilon=1e-6):
        ''' generate action with state for calculating gradients '''
        state = state.astype(np.float32)
        mean, log_std = self.forward(state)
        std = tf.math.exp(log_std)  # no clip in evaluation, clip affects gradients flow

        normal = Normal(0, 1)
        z = normal.sample()
        action_0 = tf.math.tanh(mean + std * z)  # TanhNormal distribution as actions; reparameterization trick
        action = self.action_range * action_0
        # according to original paper, with an extra last term for normalizing different action range
        log_prob = Normal(mean, std).log_prob(mean + std * z) - tf.math.log(1. - action_0**2 +
                                                                            epsilon) - np.log(self.action_range)
        # both dims of normal.log_prob and -log(1-a**2) are (N,dim_of_action);
        # the Normal.log_prob outputs the same dim of input features instead of 1 dim probability,
        # needs sum up across the dim of actions to get 1 dim probability; or else use Multivariate Normal.
        log_prob = tf.reduce_sum(log_prob, axis=1)[:, np.newaxis]  # expand dim as reduce_sum causes 1 dim reduced

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 32:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 90%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag674')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_SAC.py: 228-241
</a>
<div class="mid" id="frag674" style="display:none"><pre>
        return action, log_prob, z, mean, log_std

    def get_action(self, state, deterministic):
        ''' generate action with state for interaction with envronment '''
        mean, log_std = self.forward([state])
        std = tf.math.exp(log_std)

        normal = Normal(0, 1)
        z = normal.sample()
        action = self.action_range * tf.math.tanh(
            mean + std * z
        )  # TanhNormal distribution as actions; reparameterization trick

        action = self.action_range * tf.math.tanh(mean) if deterministic else action
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag688')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/algorithms/sac/sac.py: 95-108
</a>
<div class="mid" id="frag688" style="display:none"><pre>
        return action, log_prob, z, mean, log_std

    def get_action(self, state, deterministic):
        ''' generate action with state for interaction with envronment '''
        mean, log_std = self.forward([state])
        std = tf.math.exp(log_std)

        normal = Normal(0, 1)
        z = normal.sample()
        action = self.action_range * tf.math.tanh(
            mean + std * z
        )  # TanhNormal distribution as actions; reparameterization trick

        action = self.action_range * mean if deterministic else action
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 33:</b> &nbsp; 4 fragments, nominal size 19 lines, similarity 71%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag676')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_SAC.py: 251-273
</a>
<div class="mid" id="frag676" style="display:none"><pre>
class SAC_Trainer():

    def __init__(self, replay_buffer, hidden_dim, action_range, soft_q_lr=3e-4, policy_lr=3e-4, alpha_lr=3e-4):
        self.replay_buffer = replay_buffer

        # initialize all networks
        self.soft_q_net1 = SoftQNetwork(state_dim, action_dim, hidden_dim)
        self.soft_q_net2 = SoftQNetwork(state_dim, action_dim, hidden_dim)
        self.target_soft_q_net1 = SoftQNetwork(state_dim, action_dim, hidden_dim)
        self.target_soft_q_net2 = SoftQNetwork(state_dim, action_dim, hidden_dim)
        self.policy_net = PolicyNetwork(state_dim, action_dim, hidden_dim, action_range)
        self.log_alpha = tf.Variable(0, dtype=np.float32, name='log_alpha')
        self.alpha = tf.math.exp(self.log_alpha)
        print('Soft Q Network (1,2): ', self.soft_q_net1)
        print('Policy Network: ', self.policy_net)

        # initialize weights of target networks
        self.target_soft_q_net1 = self.target_ini(self.soft_q_net1, self.target_soft_q_net1)
        self.target_soft_q_net2 = self.target_ini(self.soft_q_net2, self.target_soft_q_net2)

        self.soft_q_optimizer1 = tf.optimizers.Adam(soft_q_lr)
        self.soft_q_optimizer2 = tf.optimizers.Adam(soft_q_lr)
        self.policy_optimizer = tf.optimizers.Adam(policy_lr)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag690')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/algorithms/sac/sac.py: 118-144
</a>
<div class="mid" id="frag690" style="display:none"><pre>
class SAC_Trainer():

    def __init__(
        self, replay_buffer, hidden_dim, state_dim, action_dim, action_range, soft_q_lr=3e-4, policy_lr=3e-4,
        alpha_lr=3e-4
    ):
        self.replay_buffer = replay_buffer

        # initialize all networks
        self.soft_q_net1 = QNetwork(state_dim, action_dim, hidden_dim)
        self.soft_q_net2 = QNetwork(state_dim, action_dim, hidden_dim)
        self.target_soft_q_net1 = QNetwork(state_dim, action_dim, hidden_dim)
        self.target_soft_q_net2 = QNetwork(state_dim, action_dim, hidden_dim)
        self.policy_net = PolicyNetwork(state_dim, action_dim, hidden_dim, action_range)
        self.log_alpha = tf.Variable(0, dtype=np.float32, name='log_alpha')
        self.alpha = tf.math.exp(self.log_alpha)
        print('Soft Q Network (1,2): ', self.soft_q_net1)
        print('Policy Network: ', self.policy_net)

        # initialize weights of target networks
        self.target_soft_q_net1 = self.target_ini(self.soft_q_net1, self.target_soft_q_net1)
        self.target_soft_q_net2 = self.target_ini(self.soft_q_net2, self.target_soft_q_net2)

        self.soft_q_optimizer1 = tf.optimizers.Adam(soft_q_lr)
        self.soft_q_optimizer2 = tf.optimizers.Adam(soft_q_lr)
        self.policy_optimizer = tf.optimizers.Adam(policy_lr)
        self.alpha_optimizer = tf.optimizers.Adam(alpha_lr)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag702')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/algorithms/td3/td3.py: 132-159
</a>
<div class="mid" id="frag702" style="display:none"><pre>

    def __init__(
        self, replay_buffer, hidden_dim, state_dim, action_dim, action_range, policy_target_update_interval=1,
        q_lr=3e-4, policy_lr=3e-4
    ):
        self.replay_buffer = replay_buffer

        # initialize all networks
        self.q_net1 = QNetwork(state_dim, action_dim, hidden_dim)
        self.q_net2 = QNetwork(state_dim, action_dim, hidden_dim)
        self.target_q_net1 = QNetwork(state_dim, action_dim, hidden_dim)
        self.target_q_net2 = QNetwork(state_dim, action_dim, hidden_dim)
        self.policy_net = PolicyNetwork(state_dim, action_dim, hidden_dim, action_range)
        self.target_policy_net = PolicyNetwork(state_dim, action_dim, hidden_dim, action_range)
        print('Q Network (1,2): ', self.q_net1)
        print('Policy Network: ', self.policy_net)

        # initialize weights of target networks
        self.target_q_net1 = self.target_ini(self.q_net1, self.target_q_net1)
        self.target_q_net2 = self.target_ini(self.q_net2, self.target_q_net2)
        self.target_policy_net = self.target_ini(self.policy_net, self.target_policy_net)

        self.update_cnt = 0
        self.policy_target_update_interval = policy_target_update_interval

        self.q_optimizer1 = tf.optimizers.Adam(q_lr)
        self.q_optimizer2 = tf.optimizers.Adam(q_lr)
        self.policy_optimizer = tf.optimizers.Adam(policy_lr)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1026')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_TD3.py: 242-268
</a>
<div class="mid" id="frag1026" style="display:none"><pre>

    def __init__(
        self, replay_buffer, hidden_dim, action_range, policy_target_update_interval=1, q_lr=3e-4, policy_lr=3e-4
    ):
        self.replay_buffer = replay_buffer

        # initialize all networks
        self.q_net1 = QNetwork(state_dim, action_dim, hidden_dim)
        self.q_net2 = QNetwork(state_dim, action_dim, hidden_dim)
        self.target_q_net1 = QNetwork(state_dim, action_dim, hidden_dim)
        self.target_q_net2 = QNetwork(state_dim, action_dim, hidden_dim)
        self.policy_net = PolicyNetwork(state_dim, action_dim, hidden_dim, action_range)
        self.target_policy_net = PolicyNetwork(state_dim, action_dim, hidden_dim, action_range)
        print('Q Network (1,2): ', self.q_net1)
        print('Policy Network: ', self.policy_net)

        # initialize weights of target networks
        self.target_q_net1 = self.target_ini(self.q_net1, self.target_q_net1)
        self.target_q_net2 = self.target_ini(self.q_net2, self.target_q_net2)
        self.target_policy_net = self.target_ini(self.policy_net, self.target_policy_net)

        self.update_cnt = 0
        self.policy_target_update_interval = policy_target_update_interval

        self.q_optimizer1 = tf.optimizers.Adam(q_lr)
        self.q_optimizer2 = tf.optimizers.Adam(q_lr)
        self.policy_optimizer = tf.optimizers.Adam(policy_lr)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 34:</b> &nbsp; 2 fragments, nominal size 43 lines, similarity 97%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag679')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_SAC.py: 288-347
</a>
<div class="mid" id="frag679" style="display:none"><pre>
        return target_net

    def update(self, batch_size, reward_scale=10., auto_entropy=True, target_entropy=-2, gamma=0.99, soft_tau=1e-2):
        ''' update all networks in SAC '''
        state, action, reward, next_state, done = self.replay_buffer.sample(batch_size)

        reward = reward[:, np.newaxis]  # expand dim
        done = done[:, np.newaxis]

        reward = reward_scale * (reward - np.mean(reward, axis=0)) / (
            np.std(reward, axis=0) + 1e-6
        )  # normalize with batch mean and std; plus a small number to prevent numerical problem

        # Training Q Function
        new_next_action, next_log_prob, _, _, _ = self.policy_net.evaluate(next_state)
        target_q_input = tf.concat([next_state, new_next_action], 1)  # the dim 0 is number of samples
        target_q_min = tf.minimum(
            self.target_soft_q_net1(target_q_input), self.target_soft_q_net2(target_q_input)
        ) - self.alpha * next_log_prob
        target_q_value = reward + (1 - done) * gamma * target_q_min  # if done==1, only reward
        q_input = tf.concat([state, action], 1)  # the dim 0 is number of samples

        with tf.GradientTape() as q1_tape:
            predicted_q_value1 = self.soft_q_net1(q_input)
            q_value_loss1 = tf.reduce_mean(tf.losses.mean_squared_error(predicted_q_value1, target_q_value))
        q1_grad = q1_tape.gradient(q_value_loss1, self.soft_q_net1.trainable_weights)
        self.soft_q_optimizer1.apply_gradients(zip(q1_grad, self.soft_q_net1.trainable_weights))

        with tf.GradientTape() as q2_tape:
            predicted_q_value2 = self.soft_q_net2(q_input)
            q_value_loss2 = tf.reduce_mean(tf.losses.mean_squared_error(predicted_q_value2, target_q_value))
        q2_grad = q2_tape.gradient(q_value_loss2, self.soft_q_net2.trainable_weights)
        self.soft_q_optimizer2.apply_gradients(zip(q2_grad, self.soft_q_net2.trainable_weights))

        # Training Policy Function
        with tf.GradientTape() as p_tape:
            new_action, log_prob, z, mean, log_std = self.policy_net.evaluate(state)
            new_q_input = tf.concat([state, new_action], 1)  # the dim 0 is number of samples
            ''' implementation 1 '''
            predicted_new_q_value = tf.minimum(self.soft_q_net1(new_q_input), self.soft_q_net2(new_q_input))
            # ''' implementation 2 '''
            # predicted_new_q_value = self.soft_q_net1(new_q_input)
            policy_loss = tf.reduce_mean(self.alpha * log_prob - predicted_new_q_value)
        p_grad = p_tape.gradient(policy_loss, self.policy_net.trainable_weights)
        self.policy_optimizer.apply_gradients(zip(p_grad, self.policy_net.trainable_weights))

        # Updating alpha w.r.t entropy
        # alpha: trade-off between exploration (max entropy) and exploitation (max Q)
        if auto_entropy is True:
            with tf.GradientTape() as alpha_tape:
                alpha_loss = -tf.reduce_mean((self.log_alpha * (log_prob + target_entropy)))
            alpha_grad = alpha_tape.gradient(alpha_loss, [self.log_alpha])
            self.alpha_optimizer.apply_gradients(zip(alpha_grad, [self.log_alpha]))
            self.alpha = tf.math.exp(self.log_alpha)
        else:  # fixed alpha
            self.alpha = 1.
            alpha_loss = 0

    # Soft update the target value nets
        self.target_soft_q_net1 = self.target_soft_update(self.soft_q_net1, self.target_soft_q_net1, soft_tau)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag693')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/algorithms/sac/sac.py: 159-218
</a>
<div class="mid" id="frag693" style="display:none"><pre>
        return target_net

    def update(self, batch_size, reward_scale=10., auto_entropy=True, target_entropy=-2, gamma=0.99, soft_tau=1e-2):
        ''' update all networks in SAC '''
        state, action, reward, next_state, done = self.replay_buffer.sample(batch_size)

        reward = reward[:, np.newaxis]  # expand dim
        done = done[:, np.newaxis]

        reward = reward_scale * (reward - np.mean(reward, axis=0)) / (
            np.std(reward, axis=0) + 1e-6
        )  # normalize with batch mean and std

        # Training Q Function
        new_next_action, next_log_prob, _, _, _ = self.policy_net.evaluate(next_state)
        target_q_input = tf.concat([next_state, new_next_action], 1)  # the dim 0 is number of samples
        target_q_min = tf.minimum(
            self.target_soft_q_net1(target_q_input), self.target_soft_q_net2(target_q_input)
        ) - self.alpha * next_log_prob
        target_q_value = reward + (1 - done) * gamma * target_q_min  # if done==1, only reward
        q_input = tf.concat([state, action], 1)  # the dim 0 is number of samples

        with tf.GradientTape() as q1_tape:
            predicted_q_value1 = self.soft_q_net1(q_input)
            q_value_loss1 = tf.reduce_mean(tf.losses.mean_squared_error(predicted_q_value1, target_q_value))
        q1_grad = q1_tape.gradient(q_value_loss1, self.soft_q_net1.trainable_weights)
        self.soft_q_optimizer1.apply_gradients(zip(q1_grad, self.soft_q_net1.trainable_weights))

        with tf.GradientTape() as q2_tape:
            predicted_q_value2 = self.soft_q_net2(q_input)
            q_value_loss2 = tf.reduce_mean(tf.losses.mean_squared_error(predicted_q_value2, target_q_value))
        q2_grad = q2_tape.gradient(q_value_loss2, self.soft_q_net2.trainable_weights)
        self.soft_q_optimizer2.apply_gradients(zip(q2_grad, self.soft_q_net2.trainable_weights))

        # Training Policy Function
        with tf.GradientTape() as p_tape:
            new_action, log_prob, z, mean, log_std = self.policy_net.evaluate(state)
            new_q_input = tf.concat([state, new_action], 1)  # the dim 0 is number of samples
            ''' implementation 1 '''
            predicted_new_q_value = tf.minimum(self.soft_q_net1(new_q_input), self.soft_q_net2(new_q_input))
            ''' implementation 2 '''
            # predicted_new_q_value = self.soft_q_net1(new_q_input)
            policy_loss = tf.reduce_mean(self.alpha * log_prob - predicted_new_q_value)
        p_grad = p_tape.gradient(policy_loss, self.policy_net.trainable_weights)
        self.policy_optimizer.apply_gradients(zip(p_grad, self.policy_net.trainable_weights))

        # Updating alpha w.r.t entropy
        # alpha: trade-off between exploration (max entropy) and exploitation (max Q)
        if auto_entropy is True:
            with tf.GradientTape() as alpha_tape:
                alpha_loss = -tf.reduce_mean((self.log_alpha * (log_prob + target_entropy)))
            alpha_grad = alpha_tape.gradient(alpha_loss, [self.log_alpha])
            self.alpha_optimizer.apply_gradients(zip(alpha_grad, [self.log_alpha]))
            self.alpha = tf.math.exp(self.log_alpha)
        else:  # fixed alpha
            self.alpha = 1.
            alpha_loss = 0

    # Soft update the target value nets
        self.target_soft_q_net1 = self.target_soft_update(self.soft_q_net1, self.target_soft_q_net1, soft_tau)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 35:</b> &nbsp; 2 fragments, nominal size 77 lines, similarity 89%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag696')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/algorithms/sac/sac.py: 236-358
</a>
<div class="mid" id="frag696" style="display:none"><pre>


def learn(env_id, train_episodes, test_episodes=1000, max_steps=150, batch_size=64, explore_steps=500, update_itr=3, hidden_dim=32, \
    soft_q_lr = 3e-4, policy_lr = 3e-4, alpha_lr = 3e-4, policy_target_update_interval = 3, action_range = 1., \
    replay_buffer_size = 5e5, reward_scale = 1. , seed=2, save_interval=500, mode='train', AUTO_ENTROPY = True, DETERMINISTIC = False):
    '''
    parameters
    ----------
    env: learning environment
    train_episodes:  total number of episodes for training
    test_episodes:  total number of episodes for testing
    max_steps:  maximum number of steps for one episode
    batch_size:  udpate batchsize
    explore_steps:  for random action sampling in the beginning of training
    update_itr: repeated updates for single step
    hidden_dim:  size of hidden layers for networks
    soft_q_lr: q_net learning rate
    policy_lr: policy_net learning rate
    alpha_lr: alpha learning rate
    policy_target_update_interval: delayed update for the policy network and target networks
    action_range: range of action value
    replay_buffer_size: size of replay buffer
    reward_scale: value range of reward
    save_interval: timesteps for saving the weights and plotting the results
    mode: train or test
    AUTO_ENTROPY: automatically udpating variable alpha for entropy
    DETERMINISTIC: stochastic action policy if False, otherwise deterministic

    '''
    env = make_env(env_id)
    action_dim = env.action_space.shape[0]
    state_dim = env.observation_space.shape[0]

    np.random.seed(seed)
    tf.random.set_seed(seed)  # reproducible

    replay_buffer = ReplayBuffer(replay_buffer_size)

    sac_trainer=SAC_Trainer(replay_buffer, hidden_dim=hidden_dim, action_dim=action_dim, state_dim=state_dim, action_range=action_range, \
    soft_q_lr=soft_q_lr, policy_lr=policy_lr, alpha_lr=alpha_lr )

    #set train mode
    sac_trainer.soft_q_net1.train()
    sac_trainer.soft_q_net2.train()
    sac_trainer.target_soft_q_net1.train()
    sac_trainer.target_soft_q_net2.train()
    sac_trainer.policy_net.train()

    # training loop
    if mode == 'train':
        frame_idx = 0
        rewards = []
        t0 = time.time()
        for eps in range(train_episodes):
            state = env.reset()
            state = state.astype(np.float32)
            episode_reward = 0
            if frame_idx &lt; 1:
                _ = sac_trainer.policy_net(
                    [state]
                )  # need an extra call here to make inside functions be able to use model.forward

            for step in range(max_steps):
                if frame_idx &gt; explore_steps:
                    action = sac_trainer.policy_net.get_action(state, deterministic=DETERMINISTIC)
                else:
                    action = sac_trainer.policy_net.sample_action()

                next_state, reward, done, _ = env.step(action)
                next_state = next_state.astype(np.float32)
                env.render()
                done = 1 if done ==True else 0

                replay_buffer.push(state, action, reward, next_state, done)

                state = next_state
                episode_reward += reward
                frame_idx += 1

                if len(replay_buffer) &gt; batch_size:
                    for i in range(update_itr):
                        sac_trainer.update(
                            batch_size, reward_scale=reward_scale, auto_entropy=AUTO_ENTROPY,
                            target_entropy=-1. * action_dim
                        )

                if done:
                    break
            if eps % int(save_interval) == 0:
                plot(rewards, Algorithm_name='SAC', Env_name=env_id)
                sac_trainer.save_weights()
            print('Episode: {}/{}  | Episode Reward: {:.4f}  | Running Time: {:.4f}'\
            .format(eps, train_episodes, episode_reward, time.time()-t0 ))
            rewards.append(episode_reward)
        sac_trainer.save_weights()

    if mode == 'test':
        frame_idx = 0
        rewards = []
        t0 = time.time()
        sac_trainer.load_weights()

        for eps in range(test_episodes):
            state = env.reset()
            state = state.astype(np.float32)
            episode_reward = 0
            if frame_idx &lt; 1:
                _ = sac_trainer.policy_net(
                    [state]
                )  # need an extra call to make inside functions be able to use forward

            for step in range(max_steps):
                action = sac_trainer.policy_net.get_action(state, deterministic=DETERMINISTIC)
                next_state, reward, done, _ = env.step(action)
                next_state = next_state.astype(np.float32)
                env.render()
                done = 1 if done ==True else 0

                state = next_state
                episode_reward += reward
                frame_idx += 1

                # if frame_idx % 50 == 0:
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag708')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/algorithms/td3/td3.py: 245-370
</a>
<div class="mid" id="frag708" style="display:none"><pre>

def learn(env_id, train_episodes, test_episodes=1000, max_steps=150, batch_size=64, explore_steps=500, update_itr=3, hidden_dim=32, \
    q_lr = 3e-4, policy_lr = 3e-4, policy_target_update_interval = 3, action_range = 1., \
    replay_buffer_size = 5e5, reward_scale = 1. , seed=2, save_interval=500, explore_noise_scale = 1.0, eval_noise_scale = 0.5, mode='train'):
    '''
    parameters
    ----------
    env: learning environment
    train_episodes:  total number of episodes for training
    test_episodes:  total number of episodes for testing
    max_steps:  maximum number of steps for one episode
    batch_size:  udpate batchsize
    explore_steps:  for random action sampling in the beginning of training
    update_itr: repeated updates for single step
    hidden_dim:  size of hidden layers for networks
    q_lr: q_net learning rate
    policy_lr: policy_net learning rate
    policy_target_update_interval: delayed update for the policy network and target networks
    action_range: range of action value
    replay_buffer_size: size of replay buffer
    reward_scale: value range of reward
    save_interval: timesteps for saving the weights and plotting the results
    explore_noise_scale: range of action noise for exploration
    eval_noise_scale: range of action noise for evaluation of action value
    mode: train or test

    '''
    env = make_env(env_id)  # make env with common.utils and wrappers
    action_dim = env.action_space.shape[0]
    state_dim = env.observation_space.shape[0]

    random.seed(seed)
    np.random.seed(seed)
    tf.random.set_seed(seed)  # reproducible

    # initialization of buffer
    replay_buffer = ReplayBuffer(replay_buffer_size)
    # initialization of trainer
    td3_trainer=TD3_Trainer(replay_buffer, hidden_dim=hidden_dim, state_dim=state_dim, action_dim=action_dim, policy_target_update_interval=policy_target_update_interval, \
    action_range=action_range, q_lr=q_lr, policy_lr=policy_lr )
    # set train mode
    td3_trainer.q_net1.train()
    td3_trainer.q_net2.train()
    td3_trainer.target_q_net1.train()
    td3_trainer.target_q_net2.train()
    td3_trainer.policy_net.train()
    td3_trainer.target_policy_net.train()

    # training loop
    if mode == 'train':
        frame_idx = 0
        rewards = []
        t0 = time.time()
        for eps in range(train_episodes):
            state = env.reset()
            state = state.astype(np.float32)
            episode_reward = 0
            if frame_idx &lt; 1:
                _ = td3_trainer.policy_net(
                    [state]
                )  # need an extra call here to make inside functions be able to use model.forward
                _ = td3_trainer.target_policy_net([state])

            for step in range(max_steps):
                if frame_idx &gt; explore_steps:
                    action = td3_trainer.policy_net.get_action(state, explore_noise_scale=1.0)
                else:
                    action = td3_trainer.policy_net.sample_action()

                next_state, reward, done, _ = env.step(action)
                next_state = next_state.astype(np.float32)
                env.render()
                done = 1 if done ==True else 0

                replay_buffer.push(state, action, reward, next_state, done)

                state = next_state
                episode_reward += reward
                frame_idx += 1

                if len(replay_buffer) &gt; batch_size:
                    for i in range(update_itr):
                        td3_trainer.update(batch_size, eval_noise_scale=0.5, reward_scale=1.)

                if done:
                    break

            if eps % int(save_interval) == 0:
                plot(rewards, Algorithm_name='TD3', Env_name=env_id)
                td3_trainer.save_weights()

            print('Episode: {}/{}  | Episode Reward: {:.4f}  | Running Time: {:.4f}'\
            .format(eps, train_episodes, episode_reward, time.time()-t0 ))
            rewards.append(episode_reward)
        td3_trainer.save_weights()

    if mode == 'test':
        frame_idx = 0
        rewards = []
        t0 = time.time()

        td3_trainer.load_weights()

        for eps in range(test_episodes):
            state = env.reset()
            state = state.astype(np.float32)
            episode_reward = 0
            if frame_idx &lt; 1:
                _ = td3_trainer.policy_net(
                    [state]
                )  # need an extra call to make inside functions be able to use forward
                _ = td3_trainer.target_policy_net([state])

            for step in range(max_steps):
                action = td3_trainer.policy_net.get_action(state, explore_noise_scale=1.0)
                next_state, reward, done, _ = env.step(action)
                next_state = next_state.astype(np.float32)
                env.render()
                done = 1 if done ==True else 0

                state = next_state
                episode_reward += reward
                frame_idx += 1

                # if frame_idx % 50 == 0:
                #     plot(frame_idx, rewards)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 36:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag699')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/algorithms/td3/td3.py: 92-110
</a>
<div class="mid" id="frag699" style="display:none"><pre>

    def evaluate(self, state, eval_noise_scale):
        ''' 
        generate action with state for calculating gradients;
        eval_noise_scale: as the trick of target policy smoothing, for generating noisy actions.
        '''
        state = state.astype(np.float32)
        action = self.forward(state)

        action = self.action_range * action

        # add noise
        normal = Normal(0, 1)
        eval_noise_clip = 2 * eval_noise_scale
        noise = normal.sample(action.shape) * eval_noise_scale
        noise = tf.clip_by_value(noise, -eval_noise_clip, eval_noise_clip)
        action = action + noise

        return action
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1023')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_TD3.py: 202-220
</a>
<div class="mid" id="frag1023" style="display:none"><pre>

    def evaluate(self, state, eval_noise_scale):
        ''' 
        generate action with state for calculating gradients;
        eval_noise_scale: as the trick of target policy smoothing, for generating noisy actions.
        '''
        state = state.astype(np.float32)
        action = self.forward(state)

        action = self.action_range * action

        # add noise
        normal = Normal(0, 1)
        eval_noise_clip = 2 * eval_noise_scale
        noise = normal.sample(action.shape) * eval_noise_scale
        noise = tf.clip_by_value(noise, -eval_noise_clip, eval_noise_clip)
        action = action + noise

        return action
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 37:</b> &nbsp; 2 fragments, nominal size 37 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag705')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/algorithms/td3/td3.py: 174-227
</a>
<div class="mid" id="frag705" style="display:none"><pre>

    def update(self, batch_size, eval_noise_scale, reward_scale=10., gamma=0.9, soft_tau=1e-2):
        ''' update all networks in TD3 '''
        self.update_cnt += 1
        state, action, reward, next_state, done = self.replay_buffer.sample(batch_size)

        reward = reward[:, np.newaxis]  # expand dim
        done = done[:, np.newaxis]

        new_next_action = self.target_policy_net.evaluate(
            next_state, eval_noise_scale=eval_noise_scale
        )  # clipped normal noise
        reward = reward_scale * (reward - np.mean(reward, axis=0)) / (
            np.std(reward, axis=0) + 1e-6
        )  # normalize with batch mean and std; plus a small number to prevent numerical problem

        # Training Q Function
        target_q_input = tf.concat([next_state, new_next_action], 1)  # the dim 0 is number of samples
        target_q_min = tf.minimum(self.target_q_net1(target_q_input), self.target_q_net2(target_q_input))

        target_q_value = reward + (1 - done) * gamma * target_q_min  # if done==1, only reward
        q_input = tf.concat([state, action], 1)  # input of q_net

        with tf.GradientTape() as q1_tape:
            predicted_q_value1 = self.q_net1(q_input)
            q_value_loss1 = tf.reduce_mean(tf.square(predicted_q_value1 - target_q_value))
        q1_grad = q1_tape.gradient(q_value_loss1, self.q_net1.trainable_weights)
        self.q_optimizer1.apply_gradients(zip(q1_grad, self.q_net1.trainable_weights))

        with tf.GradientTape() as q2_tape:
            predicted_q_value2 = self.q_net2(q_input)
            q_value_loss2 = tf.reduce_mean(tf.square(predicted_q_value2 - target_q_value))
        q2_grad = q2_tape.gradient(q_value_loss2, self.q_net2.trainable_weights)
        self.q_optimizer2.apply_gradients(zip(q2_grad, self.q_net2.trainable_weights))

        # Training Policy Function
        if self.update_cnt % self.policy_target_update_interval == 0:
            with tf.GradientTape() as p_tape:
                new_action = self.policy_net.evaluate(
                    state, eval_noise_scale=0.0
                )  # no noise, deterministic policy gradients
                new_q_input = tf.concat([state, new_action], 1)
                # ''' implementation 1 '''
                # predicted_new_q_value = tf.minimum(self.q_net1(new_q_input),self.q_net2(new_q_input))
                ''' implementation 2 '''
                predicted_new_q_value = self.q_net1(new_q_input)
                policy_loss = -tf.reduce_mean(predicted_new_q_value)
            p_grad = p_tape.gradient(policy_loss, self.policy_net.trainable_weights)
            self.policy_optimizer.apply_gradients(zip(p_grad, self.policy_net.trainable_weights))

            # Soft update the target nets
            self.target_q_net1 = self.target_soft_update(self.q_net1, self.target_q_net1, soft_tau)
            self.target_q_net2 = self.target_soft_update(self.q_net2, self.target_q_net2, soft_tau)
            self.target_policy_net = self.target_soft_update(self.policy_net, self.target_policy_net, soft_tau)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1029')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_TD3.py: 283-336
</a>
<div class="mid" id="frag1029" style="display:none"><pre>

    def update(self, batch_size, eval_noise_scale, reward_scale=10., gamma=0.9, soft_tau=1e-2):
        ''' update all networks in TD3 '''
        self.update_cnt += 1
        state, action, reward, next_state, done = self.replay_buffer.sample(batch_size)

        reward = reward[:, np.newaxis]  # expand dim
        done = done[:, np.newaxis]

        new_next_action = self.target_policy_net.evaluate(
            next_state, eval_noise_scale=eval_noise_scale
        )  # clipped normal noise
        reward = reward_scale * (reward - np.mean(reward, axis=0)) / (
            np.std(reward, axis=0) + 1e-6
        )  # normalize with batch mean and std; plus a small number to prevent numerical problem

        # Training Q Function
        target_q_input = tf.concat([next_state, new_next_action], 1)  # the dim 0 is number of samples
        target_q_min = tf.minimum(self.target_q_net1(target_q_input), self.target_q_net2(target_q_input))

        target_q_value = reward + (1 - done) * gamma * target_q_min  # if done==1, only reward
        q_input = tf.concat([state, action], 1)  # input of q_net

        with tf.GradientTape() as q1_tape:
            predicted_q_value1 = self.q_net1(q_input)
            q_value_loss1 = tf.reduce_mean(tf.square(predicted_q_value1 - target_q_value))
        q1_grad = q1_tape.gradient(q_value_loss1, self.q_net1.trainable_weights)
        self.q_optimizer1.apply_gradients(zip(q1_grad, self.q_net1.trainable_weights))

        with tf.GradientTape() as q2_tape:
            predicted_q_value2 = self.q_net2(q_input)
            q_value_loss2 = tf.reduce_mean(tf.square(predicted_q_value2 - target_q_value))
        q2_grad = q2_tape.gradient(q_value_loss2, self.q_net2.trainable_weights)
        self.q_optimizer2.apply_gradients(zip(q2_grad, self.q_net2.trainable_weights))

        # Training Policy Function
        if self.update_cnt % self.policy_target_update_interval == 0:
            with tf.GradientTape() as p_tape:
                new_action = self.policy_net.evaluate(
                    state, eval_noise_scale=0.0
                )  # no noise, deterministic policy gradients
                new_q_input = tf.concat([state, new_action], 1)
                # ''' implementation 1 '''
                # predicted_new_q_value = tf.minimum(self.q_net1(new_q_input),self.q_net2(new_q_input))
                ''' implementation 2 '''
                predicted_new_q_value = self.q_net1(new_q_input)
                policy_loss = -tf.reduce_mean(predicted_new_q_value)
            p_grad = p_tape.gradient(policy_loss, self.policy_net.trainable_weights)
            self.policy_optimizer.apply_gradients(zip(p_grad, self.policy_net.trainable_weights))

            # Soft update the target nets
            self.target_q_net1 = self.target_soft_update(self.q_net1, self.target_q_net1, soft_tau)
            self.target_q_net2 = self.target_soft_update(self.q_net2, self.target_q_net2, soft_tau)
            self.target_policy_net = self.target_soft_update(self.policy_net, self.target_policy_net, soft_tau)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 38:</b> &nbsp; 2 fragments, nominal size 26 lines, similarity 92%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag710')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/algorithms/a3c/a3c.py: 108-136
</a>
<div class="mid" id="frag710" style="display:none"><pre>
    def update_global(
        self, buffer_s, buffer_a, buffer_v_target, globalAC
    ):  # refer to the global Actor-Crtic network for updating it with samples
        ''' update the global critic '''
        with tf.GradientTape() as tape:
            self.v = self.critic(buffer_s)
            self.v_target = buffer_v_target
            td = tf.subtract(self.v_target, self.v, name='TD_error')
            self.c_loss = tf.reduce_mean(tf.square(td))
        self.c_grads = tape.gradient(self.c_loss, self.critic.trainable_weights)
        OPT_C.apply_gradients(zip(self.c_grads, globalAC.critic.trainable_weights))  # local grads applies to global net
        # del tape # Drop the reference to the tape
        ''' update the global actor '''
        with tf.GradientTape() as tape:
            self.mu, self.sigma = self.actor(buffer_s)
            self.test = self.sigma[0]
            self.mu, self.sigma = self.mu * self.A_BOUND[1], self.sigma + 1e-5

            normal_dist = tfd.Normal(self.mu, self.sigma)  # no tf.contrib for tf2.0
            self.a_his = buffer_a  # float32
            log_prob = normal_dist.log_prob(self.a_his)
            exp_v = log_prob * td  # td is from the critic part, no gradients for it
            entropy = normal_dist.entropy()  # encourage exploration
            self.exp_v = self.ENTROPY_BETA * entropy + exp_v
            self.a_loss = tf.reduce_mean(-self.exp_v)
        self.a_grads = tape.gradient(self.a_loss, self.actor.trainable_weights)
        OPT_A.apply_gradients(zip(self.a_grads, globalAC.actor.trainable_weights))  # local grads applies to global net
        return self.test  # for test purpose

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag953')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_A3C.py: 124-152
</a>
<div class="mid" id="frag953" style="display:none"><pre>
    def update_global(
        self, buffer_s, buffer_a, buffer_v_target, globalAC
    ):  # refer to the global Actor-Crtic network for updating it with samples
        ''' update the global critic '''
        with tf.GradientTape() as tape:
            self.v = self.critic(buffer_s)
            self.v_target = buffer_v_target
            td = tf.subtract(self.v_target, self.v, name='TD_error')
            self.c_loss = tf.reduce_mean(tf.square(td))
        self.c_grads = tape.gradient(self.c_loss, self.critic.trainable_weights)
        OPT_C.apply_gradients(zip(self.c_grads, globalAC.critic.trainable_weights))  # local grads applies to global net
        # del tape # Drop the reference to the tape
        ''' update the global actor '''
        with tf.GradientTape() as tape:
            self.mu, self.sigma = self.actor(buffer_s)
            self.test = self.sigma[0]
            self.mu, self.sigma = self.mu * A_BOUND[1], self.sigma + 1e-5

            normal_dist = tfd.Normal(self.mu, self.sigma)  # no tf.contrib for tf2.0
            self.a_his = buffer_a  # float32
            log_prob = normal_dist.log_prob(self.a_his)
            exp_v = log_prob * td  # td is from the critic part, no gradients for it
            entropy = normal_dist.entropy()  # encourage exploration
            self.exp_v = ENTROPY_BETA * entropy + exp_v
            self.a_loss = tf.reduce_mean(-self.exp_v)
        self.a_grads = tape.gradient(self.a_loss, self.actor.trainable_weights)
        OPT_A.apply_gradients(zip(self.a_grads, globalAC.actor.trainable_weights))  # local grads applies to global net
        return self.test  # for test purpose

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 39:</b> &nbsp; 2 fragments, nominal size 44 lines, similarity 88%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag716')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/algorithms/a3c/a3c.py: 180-241
</a>
<div class="mid" id="frag716" style="display:none"><pre>
    def work(self, globalAC):
        global COORD, GLOBAL_RUNNING_R, GLOBAL_EP, OPT_A, OPT_C, t0
        total_step = 1
        buffer_s, buffer_a, buffer_r = [], [], []
        while not COORD.should_stop() and GLOBAL_EP &lt; self.MAX_GLOBAL_EP:
            s = self.env.reset()
            ep_r = 0
            while True:
                # visualize Worker_0 during training
                if self.name == 'Worker_0' and total_step % 30 == 0:
                    self.env.render()
                s = s.astype('float32')  # double to float
                a = self.AC.choose_action(s)
                s_, r, done, _info = self.env.step(a)

                s_ = s_.astype('float32')  # double to float
                # set robot falls reward to -2 instead of -100
                if r == -100: r = -2

                ep_r += r
                buffer_s.append(s)
                buffer_a.append(a)
                buffer_r.append(r)

                if total_step % self.UPDATE_GLOBAL_ITER == 0 or done:  # update global and assign to local net

                    if done:
                        v_s_ = 0  # terminal
                    else:
                        v_s_ = self.AC.critic(s_[np.newaxis, :])[0, 0]  # reduce dim from 2 to 0

                    buffer_v_target = []

                    for r in buffer_r[::-1]:  # reverse buffer r
                        v_s_ = r + self.GAMMA * v_s_
                        buffer_v_target.append(v_s_)

                    buffer_v_target.reverse()

                    buffer_s, buffer_a, buffer_v_target = (
                        np.vstack(buffer_s), np.vstack(buffer_a), np.vstack(buffer_v_target)
                    )
                    # update gradients on global network
                    self.AC.update_global(buffer_s, buffer_a, buffer_v_target.astype('float32'), globalAC)
                    buffer_s, buffer_a, buffer_r = [], [], []

                    # update local network from global network
                    self.AC.pull_global(globalAC)

                s = s_
                total_step += 1
                if done:
                    if len(GLOBAL_RUNNING_R) == 0:  # record running episode reward
                        GLOBAL_RUNNING_R.append(ep_r)
                    else:  # moving average
                        GLOBAL_RUNNING_R.append(0.95 * GLOBAL_RUNNING_R[-1] + 0.05 * ep_r)

                    print('{}, Episode: {}/{}  | Episode Reward: {:.4f}  | Running Time: {:.4f}'\
                    .format(self.name, GLOBAL_EP, self.MAX_GLOBAL_EP, ep_r, time.time()-t0 ))
                    GLOBAL_EP += 1
                    break

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag959')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_A3C.py: 187-257
</a>
<div class="mid" id="frag959" style="display:none"><pre>
    def work(self, globalAC):
        global GLOBAL_RUNNING_R, GLOBAL_EP
        total_step = 1
        buffer_s, buffer_a, buffer_r = [], [], []
        while not COORD.should_stop() and GLOBAL_EP &lt; MAX_GLOBAL_EP:
            s = self.env.reset()
            ep_r = 0
            while True:
                # visualize Worker_0 during training
                if self.name == 'Worker_0' and total_step % 30 == 0:
                    self.env.render()
                s = s.astype('float32')  # double to float
                a = self.AC.choose_action(s)
                s_, r, done, _info = self.env.step(a)

                s_ = s_.astype('float32')  # double to float
                # set robot falls reward to -2 instead of -100
                if r == -100: r = -2

                ep_r += r
                buffer_s.append(s)
                buffer_a.append(a)
                buffer_r.append(r)

                if total_step % UPDATE_GLOBAL_ITER == 0 or done:  # update global and assign to local net

                    if done:
                        v_s_ = 0  # terminal
                    else:
                        v_s_ = self.AC.critic(s_[np.newaxis, :])[0, 0]  # reduce dim from 2 to 0

                    buffer_v_target = []

                    for r in buffer_r[::-1]:  # reverse buffer r
                        v_s_ = r + GAMMA * v_s_
                        buffer_v_target.append(v_s_)

                    buffer_v_target.reverse()

                    buffer_s, buffer_a, buffer_v_target = (
                        np.vstack(buffer_s), np.vstack(buffer_a), np.vstack(buffer_v_target)
                    )
                    # update gradients on global network
                    self.AC.update_global(buffer_s, buffer_a, buffer_v_target.astype('float32'), globalAC)
                    buffer_s, buffer_a, buffer_r = [], [], []

                    # update local network from global network
                    self.AC.pull_global(globalAC)

                s = s_
                total_step += 1
                if done:
                    if len(GLOBAL_RUNNING_R) == 0:  # record running episode reward
                        GLOBAL_RUNNING_R.append(ep_r)
                    else:  # moving average
                        GLOBAL_RUNNING_R.append(0.95 * GLOBAL_RUNNING_R[-1] + 0.05 * ep_r)
                    # print(
                    #     self.name,
                    #     "Episode: ",
                    #     GLOBAL_EP,
                    #     # "| pos: %i" % self.env.unwrapped.hull.position[0],  # number of move
                    #     '| reward: %.1f' % ep_r,
                    #     "| running_reward: %.1f" % GLOBAL_RUNNING_R[-1],
                    #     # '| sigma:', test, # debug
                    #     # 'WIN ' * 5 if self.env.unwrapped.hull.position[0] &gt;= 88 else '',
                    # )
                    print('{}, Episode: {}/{}  | Episode Reward: {:.4f}  | Running Time: {:.4f}'\
                    .format(self.name, GLOBAL_EP, MAX_GLOBAL_EP, ep_r, time.time()-t0 ))
                    GLOBAL_EP += 1
                    break

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 40:</b> &nbsp; 3 fragments, nominal size 25 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag721')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/algorithms/ppo/ppo.py: 120-157
</a>
<div class="mid" id="frag721" style="display:none"><pre>
    def a_train(self, tfs, tfa, tfadv):
        '''
        Update policy network
        :param tfs: state
        :param tfa: act
        :param tfadv: advantage
        :return:
        '''
        tfs = np.array(tfs, np.float32)
        tfa = np.array(tfa, np.float32)
        tfadv = np.array(tfadv, np.float32)
        with tf.GradientTape() as tape:
            mu, sigma = self.actor(tfs)
            pi = tfp.distributions.Normal(mu, sigma)

            mu_old, sigma_old = self.actor_old(tfs)
            oldpi = tfp.distributions.Normal(mu_old, sigma_old)

            # ratio = tf.exp(pi.log_prob(self.tfa) - oldpi.log_prob(self.tfa))
            ratio = pi.prob(tfa) / (oldpi.prob(tfa) + EPS)
            surr = ratio * tfadv
            if METHOD['name'] == 'kl_pen':
                tflam = METHOD['lam']
                kl = tfp.distributions.kl_divergence(oldpi, pi)
                kl_mean = tf.reduce_mean(kl)
                aloss = -(tf.reduce_mean(surr - tflam * kl))
            else:  # clipping method, find this is better
                aloss = -tf.reduce_mean(
                    tf.minimum(surr,
                               tf.clip_by_value(ratio, 1. - METHOD['epsilon'], 1. + METHOD['epsilon']) * tfadv)
                )
        a_gard = tape.gradient(aloss, self.actor.trainable_weights)

        self.actor_opt.apply_gradients(zip(a_gard, self.actor.trainable_weights))

        if METHOD['name'] == 'kl_pen':
            return kl_mean

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag938')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_DPPO.py: 98-135
</a>
<div class="mid" id="frag938" style="display:none"><pre>
    def a_train(self, tfs, tfa, tfadv):
        '''
        Update policy network
        :param tfs: state
        :param tfa: act
        :param tfadv: advantage
        :return:
        '''
        tfs = np.array(tfs, np.float32)
        tfa = np.array(tfa, np.float32)
        tfadv = np.array(tfadv, np.float32)
        with tf.GradientTape() as tape:
            mu, sigma = self.actor(tfs)
            pi = tfp.distributions.Normal(mu, sigma)

            mu_old, sigma_old = self.actor_old(tfs)
            oldpi = tfp.distributions.Normal(mu_old, sigma_old)

            # ratio = tf.exp(pi.log_prob(self.tfa) - oldpi.log_prob(self.tfa))
            ratio = pi.prob(tfa) / (oldpi.prob(tfa) + EPS)
            surr = ratio * tfadv
            if METHOD['name'] == 'kl_pen':
                tflam = METHOD['lam']
                kl = tfp.distributions.kl_divergence(oldpi, pi)
                kl_mean = tf.reduce_mean(kl)
                aloss = -(tf.reduce_mean(surr - tflam * kl))
            else:  # clipping method, find this is better
                aloss = -tf.reduce_mean(
                    tf.minimum(surr,
                               tf.clip_by_value(ratio, 1. - METHOD['epsilon'], 1. + METHOD['epsilon']) * tfadv)
                )
        a_gard = tape.gradient(aloss, self.actor.trainable_weights)

        self.actor_opt.apply_gradients(zip(a_gard, self.actor.trainable_weights))

        if METHOD['name'] == 'kl_pen':
            return kl_mean

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1034')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_PPO.py: 90-127
</a>
<div class="mid" id="frag1034" style="display:none"><pre>
    def a_train(self, tfs, tfa, tfadv):
        '''
        Update policy network
        :param tfs: state
        :param tfa: act
        :param tfadv: advantage
        :return:
        '''
        tfs = np.array(tfs, np.float32)
        tfa = np.array(tfa, np.float32)
        tfadv = np.array(tfadv, np.float32)
        with tf.GradientTape() as tape:
            mu, sigma = self.actor(tfs)
            pi = tfp.distributions.Normal(mu, sigma)

            mu_old, sigma_old = self.actor_old(tfs)
            oldpi = tfp.distributions.Normal(mu_old, sigma_old)

            # ratio = tf.exp(pi.log_prob(self.tfa) - oldpi.log_prob(self.tfa))
            ratio = pi.prob(tfa) / (oldpi.prob(tfa) + EPS)
            surr = ratio * tfadv
            if METHOD['name'] == 'kl_pen':
                tflam = METHOD['lam']
                kl = tfp.distributions.kl_divergence(oldpi, pi)
                kl_mean = tf.reduce_mean(kl)
                aloss = -(tf.reduce_mean(surr - tflam * kl))
            else:  # clipping method, find this is better
                aloss = -tf.reduce_mean(
                    tf.minimum(surr,
                               tf.clip_by_value(ratio, 1. - METHOD['epsilon'], 1. + METHOD['epsilon']) * tfadv)
                )
        a_gard = tape.gradient(aloss, self.actor.trainable_weights)

        self.actor_opt.apply_gradients(zip(a_gard, self.actor.trainable_weights))

        if METHOD['name'] == 'kl_pen':
            return kl_mean

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 41:</b> &nbsp; 2 fragments, nominal size 21 lines, similarity 85%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag725')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/algorithms/ppo/ppo.py: 193-227
</a>
<div class="mid" id="frag725" style="display:none"><pre>
    def update(self, s, a, r):
        '''
        Update parameter with the constraint of KL divergent
        :param s: state
        :param a: act
        :param r: reward
        :return: None
        '''
        s, a, r = s.astype(np.float32), a.astype(np.float32), r.astype(np.float32)

        self.update_old_pi()
        adv = self.cal_adv(s, r)
        # adv = (adv - adv.mean())/(adv.std()+1e-6)  # sometimes helpful

        # update actor
        if METHOD['name'] == 'kl_pen':
            for _ in range(self.a_update_steps):
                kl = self.a_train(s, a, adv)
                if kl &gt; 4 * METHOD['kl_target']:  # this in in google's paper
                    break
            if kl &lt; METHOD['kl_target'] / 1.5:  # adaptive lambda, this is in OpenAI's paper
                METHOD['lam'] /= 2
            elif kl &gt; METHOD['kl_target'] * 1.5:
                METHOD['lam'] *= 2
            METHOD['lam'] = np.clip(
                METHOD['lam'], 1e-4, 10
            )  # sometimes explode, this clipping is MorvanZhou's solution
        else:  # clipping method, find this is better (OpenAI's paper)
            for _ in range(self.a_update_steps):
                self.a_train(s, a, adv)

        # update critic
        for _ in range(self.c_update_steps):
            self.c_train(r, s)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1038')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_PPO.py: 163-197
</a>
<div class="mid" id="frag1038" style="display:none"><pre>
    def update(self, s, a, r):
        '''
        Update parameter with the constraint of KL divergent
        :param s: state
        :param a: act
        :param r: reward
        :return: None
        '''
        s, a, r = s.astype(np.float32), a.astype(np.float32), r.astype(np.float32)

        self.update_old_pi()
        adv = self.cal_adv(s, r)
        # adv = (adv - adv.mean())/(adv.std()+1e-6)  # sometimes helpful

        # update actor
        if METHOD['name'] == 'kl_pen':
            for _ in range(A_UPDATE_STEPS):
                kl = self.a_train(s, a, adv)
                if kl &gt; 4 * METHOD['kl_target']:  # this in in google's paper
                    break
            if kl &lt; METHOD['kl_target'] / 1.5:  # adaptive lambda, this is in OpenAI's paper
                METHOD['lam'] /= 2
            elif kl &gt; METHOD['kl_target'] * 1.5:
                METHOD['lam'] *= 2
            METHOD['lam'] = np.clip(
                METHOD['lam'], 1e-4, 10
            )  # sometimes explode, this clipping is MorvanZhou's solution
        else:  # clipping method, find this is better (OpenAI's paper)
            for _ in range(A_UPDATE_STEPS):
                self.a_train(s, a, adv)

        # update critic
        for _ in range(C_UPDATE_STEPS):
            self.c_train(r, s)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 42:</b> &nbsp; 4 fragments, nominal size 18 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag728')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/algorithms/ppo/ppo.py: 250-270
</a>
<div class="mid" id="frag728" style="display:none"><pre>
    def save_ckpt(self):
        """
        save trained weights
        :return: None
        """
        save_model(
            self.actor,
            'actor',
            'ppo',
        )
        save_model(
            self.actor_old,
            'actor_old',
            'ppo',
        )
        save_model(
            self.critic,
            'critic',
            'ppo',
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag761')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/algorithms/ddpg/ddpg.py: 252-278
</a>
<div class="mid" id="frag761" style="display:none"><pre>
    def load_ckpt(self):
        """
        load trained weights
        :return: None
        """
        load_model(
            self.actor,
            'actor',
            'ddpg',
        )
        load_model(
            self.actor_target,
            'actor_target',
            'ddpg',
        )
        load_model(
            self.critic,
            'critic',
            'ddpg',
        )
        load_model(
            self.critic_target,
            'critic_target',
            'ddpg',
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag760')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/algorithms/ddpg/ddpg.py: 226-251
</a>
<div class="mid" id="frag760" style="display:none"><pre>
    def save_ckpt(self):
        """
        save trained weights
        :return: None
        """
        save_model(
            self.actor,
            'actor',
            'ddpg',
        )
        save_model(
            self.actor_target,
            'actor_target',
            'ddpg',
        )
        save_model(
            self.critic,
            'critic',
            'ddpg',
        )
        save_model(
            self.critic_target,
            'critic_target',
            'ddpg',
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag729')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/algorithms/ppo/ppo.py: 271-294
</a>
<div class="mid" id="frag729" style="display:none"><pre>
    def load_ckpt(self):
        """
        load trained weights
        :return: None
        """
        load_model(
            self.actor,
            'actor',
            'ppo',
        )
        load_model(
            self.actor_old,
            'actor_old',
            'ppo',
        )
        load_model(
            self.critic,
            'critic',
            'ppo',
        )


#####################  hyper parameters  ####################

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 43:</b> &nbsp; 2 fragments, nominal size 22 lines, similarity 90%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag758')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/algorithms/ddpg/ddpg.py: 180-209
</a>
<div class="mid" id="frag758" style="display:none"><pre>
    def learn(self):
        """
        Update parameters
        :return: None
        """
        indices = np.random.choice(len(self.memory), size=self.batch_size)
        bt = self.memory[indices, :]
        bs = bt[:, :self.s_dim]
        ba = bt[:, self.s_dim:self.s_dim + self.a_dim]
        br = bt[:, -self.s_dim - 1:-self.s_dim]
        bs_ = bt[:, -self.s_dim:]

        with tf.GradientTape() as tape:
            a_ = self.actor_target(bs_)
            q_ = self.critic_target([bs_, a_])
            y = br + self.gamma * q_
            q = self.critic([bs, ba])
            td_error = tf.losses.mean_squared_error(y, q)
        c_grads = tape.gradient(td_error, self.critic.trainable_weights)
        self.critic_opt.apply_gradients(zip(c_grads, self.critic.trainable_weights))

        with tf.GradientTape() as tape:
            a = self.actor(bs)
            q = self.critic([bs, a])
            a_loss = -tf.reduce_mean(q)  # maximize the q
        a_grads = tape.gradient(a_loss, self.actor.trainable_weights)
        self.actor_opt.apply_gradients(zip(a_grads, self.actor.trainable_weights))

        self.ema_update()

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1000')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_DDPG.py: 155-184
</a>
<div class="mid" id="frag1000" style="display:none"><pre>
    def learn(self):
        """
        Update parameters
        :return: None
        """
        indices = np.random.choice(MEMORY_CAPACITY, size=BATCH_SIZE)
        bt = self.memory[indices, :]
        bs = bt[:, :self.s_dim]
        ba = bt[:, self.s_dim:self.s_dim + self.a_dim]
        br = bt[:, -self.s_dim - 1:-self.s_dim]
        bs_ = bt[:, -self.s_dim:]

        with tf.GradientTape() as tape:
            a_ = self.actor_target(bs_)
            q_ = self.critic_target([bs_, a_])
            y = br + GAMMA * q_
            q = self.critic([bs, ba])
            td_error = tf.losses.mean_squared_error(y, q)
        c_grads = tape.gradient(td_error, self.critic.trainable_weights)
        self.critic_opt.apply_gradients(zip(c_grads, self.critic.trainable_weights))

        with tf.GradientTape() as tape:
            a = self.actor(bs)
            q = self.critic([bs, a])
            a_loss = -tf.reduce_mean(q)  # maximize the q
        a_grads = tape.gradient(a_loss, self.actor.trainable_weights)
        self.actor_opt.apply_gradients(zip(a_grads, self.actor.trainable_weights))

        self.ema_update()

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 44:</b> &nbsp; 2 fragments, nominal size 17 lines, similarity 82%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag765')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/algorithms/dqn/dqn.py: 169-188
</a>
<div class="mid" id="frag765" style="display:none"><pre>
def atari_parameters(env, **kwargs):
    in_dim = env.observation_space.shape
    policy_dim = env.action_space.n
    params = dict(
        lr=1e-4, number_timesteps=int(1e6), grad_norm=10, batch_size=32, double_q=True, buffer_size=10000,
        exploration_fraction=0.1, exploration_final_eps=0.01, learning_starts=10000, target_network_update_freq=1000,
        gamma=0.99, prioritized_replay=True, prioritized_replay_alpha=0.6, prioritized_replay_beta0=0.4, dueling=True,
        ob_scale=1 / 255.0
    )
    params.update(kwargs)
    network = get_cnn_model(in_dim, policy_dim, params.pop('dueling'))
    norm = params.pop('grad_norm')
    if norm:
        optimizer = tf.optimizers.Adam(learning_rate=params.pop('lr'), clipnorm=norm)
    else:
        optimizer = tf.optimizers.Adam(learning_rate=params.pop('lr'))
    params.update(network=network, optimizer=optimizer)
    return params


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag766')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/algorithms/dqn/dqn.py: 189-208
</a>
<div class="mid" id="frag766" style="display:none"><pre>
def other_parameters(env, **kwargs):
    in_dim = env.observation_space.shape[0]
    policy_dim = env.action_space.n
    params = dict(
        lr=5e-3, grad_norm=None, batch_size=100, number_timesteps=10000, double_q=True, buffer_size=1000,
        exploration_fraction=0.1, exploration_final_eps=0.01, learning_starts=100, target_network_update_freq=50,
        gamma=0.99, prioritized_replay=False, prioritized_replay_alpha=0.6, prioritized_replay_beta0=0.4, dueling=True,
        ob_scale=1
    )
    params.update(kwargs)
    network = get_mlp_model(in_dim, policy_dim, params.pop('dueling'))
    norm = params.pop('grad_norm')
    if norm:
        optimizer = tf.optimizers.Adam(learning_rate=params.pop('lr'), clipnorm=norm)
    else:
        optimizer = tf.optimizers.Adam(learning_rate=params.pop('lr'))
    params.update(network=network, optimizer=optimizer)
    return params


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 45:</b> &nbsp; 2 fragments, nominal size 22 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag789')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/common/wrappers.py: 53-78
</a>
<div class="mid" id="frag789" style="display:none"><pre>
def _make_env(env_id, env_type, seed, reward_scale, frame_stack=True):
    """Make single env"""
    if env_type == 'atari':
        env = gym.make(env_id)
        assert 'NoFrameskip' in env.spec.id
        env = NoopResetEnv(env, noop_max=30)
        env = MaxAndSkipEnv(env, skip=4)
        env = Monitor(env)
        # deepmind wrap
        env = EpisodicLifeEnv(env)
        if 'FIRE' in env.unwrapped.get_action_meanings():
            env = FireResetEnv(env)
        env = WarpFrame(env)
        env = ClipRewardEnv(env)
        if frame_stack:
            env = FrameStack(env, 4)
    elif env_type == 'classic_control':
        env = Monitor(gym.make(env_id))
    else:
        raise NotImplementedError
    if reward_scale != 1:
        env = RewardScaler(env, reward_scale)
    env.seed(seed)
    return env


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag883')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_wrappers.py: 52-77
</a>
<div class="mid" id="frag883" style="display:none"><pre>
def _make_env(env_id, env_type, seed, reward_scale, frame_stack=True):
    """Make single env"""
    if env_type == 'atari':
        env = gym.make(env_id)
        assert 'NoFrameskip' in env.spec.id
        env = NoopResetEnv(env, noop_max=30)
        env = MaxAndSkipEnv(env, skip=4)
        env = Monitor(env)
        # deepmind wrap
        env = EpisodicLifeEnv(env)
        if 'FIRE' in env.unwrapped.get_action_meanings():
            env = FireResetEnv(env)
        env = WarpFrame(env)
        env = ClipRewardEnv(env)
        if frame_stack:
            env = FrameStack(env, 4)
    elif env_type == 'classic_control':
        env = Monitor(gym.make(env_id))
    else:
        raise NotImplementedError
    if reward_scale != 1:
        env = RewardScaler(env, reward_scale)
    env.seed(seed)
    return env


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 46:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag795')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/common/wrappers.py: 119-133
</a>
<div class="mid" id="frag795" style="display:none"><pre>
    def reset(self, **kwargs):
        """ Do no-op action for a number of steps in [1, noop_max]."""
        self.env.reset(**kwargs)
        if self.override_num_noops is not None:
            noops = self.override_num_noops
        else:
            noops = self.unwrapped.np_random.randint(1, self.noop_max + 1)
        assert noops &gt; 0
        obs = None
        for _ in range(noops):
            obs, _, done, _ = self.env.step(self.noop_action)
            if done:
                obs = self.env.reset(**kwargs)
        return obs

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag889')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_wrappers.py: 118-132
</a>
<div class="mid" id="frag889" style="display:none"><pre>
    def reset(self, **kwargs):
        """ Do no-op action for a number of steps in [1, noop_max]."""
        self.env.reset(**kwargs)
        if self.override_num_noops is not None:
            noops = self.override_num_noops
        else:
            noops = self.unwrapped.np_random.randint(1, self.noop_max + 1)
        assert noops &gt; 0
        obs = None
        for _ in range(noops):
            obs, _, done, _ = self.env.step(self.noop_action)
            if done:
                obs = self.env.reset(**kwargs)
        return obs

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 47:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag804')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/common/wrappers.py: 208-225
</a>
<div class="mid" id="frag804" style="display:none"><pre>
    def step(self, action):
        """Repeat action, sum reward, and max over last observations."""
        total_reward = 0.0
        done = info = None
        for i in range(self._skip):
            obs, reward, done, info = self.env.step(action)
            if i == self._skip - 2:
                self._obs_buffer[0] = obs
            if i == self._skip - 1:
                self._obs_buffer[1] = obs
            total_reward += reward
            if done:
                break
        # Note that the observation on the done=True frame doesn't matter
        max_frame = self._obs_buffer.max(axis=0)

        return max_frame, total_reward, done, info

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag898')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_wrappers.py: 207-224
</a>
<div class="mid" id="frag898" style="display:none"><pre>
    def step(self, action):
        """Repeat action, sum reward, and max over last observations."""
        total_reward = 0.0
        done = info = None
        for i in range(self._skip):
            obs, reward, done, info = self.env.step(action)
            if i == self._skip - 2:
                self._obs_buffer[0] = obs
            if i == self._skip - 1:
                self._obs_buffer[1] = obs
            total_reward += reward
            if done:
                break
        # Note that the observation on the done=True frame doesn't matter
        max_frame = self._obs_buffer.max(axis=0)

        return max_frame, total_reward, done, info

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 48:</b> &nbsp; 2 fragments, nominal size 23 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag825')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/common/wrappers.py: 363-387
</a>
<div class="mid" id="frag825" style="display:none"><pre>
def _worker(remote, parent_remote, env_fn_wrapper):
    parent_remote.close()
    env = env_fn_wrapper.x()
    while True:
        cmd, data = remote.recv()
        if cmd == 'step':
            ob, reward, done, info = env.step(data)
            if done:
                ob = env.reset()
            remote.send((ob, reward, done, info))
        elif cmd == 'reset':
            ob = env.reset()
            remote.send(ob)
        elif cmd == 'reset_task':
            ob = env._reset_task()
            remote.send(ob)
        elif cmd == 'close':
            remote.close()
            break
        elif cmd == 'get_spaces':
            remote.send((env.observation_space, env.action_space))
        else:
            raise NotImplementedError


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag919')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_wrappers.py: 362-386
</a>
<div class="mid" id="frag919" style="display:none"><pre>
def _worker(remote, parent_remote, env_fn_wrapper):
    parent_remote.close()
    env = env_fn_wrapper.x()
    while True:
        cmd, data = remote.recv()
        if cmd == 'step':
            ob, reward, done, info = env.step(data)
            if done:
                ob = env.reset()
            remote.send((ob, reward, done, info))
        elif cmd == 'reset':
            ob = env.reset()
            remote.send(ob)
        elif cmd == 'reset_task':
            ob = env._reset_task()
            remote.send(ob)
        elif cmd == 'close':
            remote.close()
            break
        elif cmd == 'get_spaces':
            remote.send((env.observation_space, env.action_space))
        else:
            raise NotImplementedError


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 49:</b> &nbsp; 2 fragments, nominal size 20 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag829')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/common/wrappers.py: 407-435
</a>
<div class="mid" id="frag829" style="display:none"><pre>
    def __init__(self, env_fns):
        """
        envs: list of gym environments to run in subprocesses
        """
        self.num_envs = len(env_fns)

        self.waiting = False
        self.closed = False
        nenvs = len(env_fns)
        self.nenvs = nenvs
        self.remotes, self.work_remotes = zip(*[Pipe() for _ in range(nenvs)])
        zipped_args = zip(self.work_remotes, self.remotes, env_fns)
        self.ps = [
            Process(target=_worker, args=(work_remote, remote, CloudpickleWrapper(env_fn)))
            for (work_remote, remote, env_fn) in zipped_args
        ]

        for p in self.ps:
            # if the main process crashes, we should not cause things to hang
            p.daemon = True
            p.start()
        for remote in self.work_remotes:
            remote.close()

        self.remotes[0].send(('get_spaces', None))
        observation_space, action_space = self.remotes[0].recv()
        self.observation_space = observation_space
        self.action_space = action_space

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag923')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_wrappers.py: 406-434
</a>
<div class="mid" id="frag923" style="display:none"><pre>
    def __init__(self, env_fns):
        """
        envs: list of gym environments to run in subprocesses
        """
        self.num_envs = len(env_fns)

        self.waiting = False
        self.closed = False
        nenvs = len(env_fns)
        self.nenvs = nenvs
        self.remotes, self.work_remotes = zip(*[Pipe() for _ in range(nenvs)])
        zipped_args = zip(self.work_remotes, self.remotes, env_fns)
        self.ps = [
            Process(target=_worker, args=(work_remote, remote, CloudpickleWrapper(env_fn)))
            for (work_remote, remote, env_fn) in zipped_args
        ]

        for p in self.ps:
            # if the main process crashes, we should not cause things to hang
            p.daemon = True
            p.start()
        for remote in self.work_remotes:
            remote.close()

        self.remotes[0].send(('get_spaces', None))
        observation_space, action_space = self.remotes[0].recv()
        self.observation_space = observation_space
        self.action_space = action_space

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 50:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag834')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/common/wrappers.py: 480-491
</a>
<div class="mid" id="frag834" style="display:none"><pre>
    def close(self):
        if self.closed:
            return
        if self.waiting:
            for remote in self.remotes:
                remote.recv()
        for remote in self.remotes:
            remote.send(('close', None))
        for p in self.ps:
            p.join()
            self.closed = True

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag928')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_wrappers.py: 479-490
</a>
<div class="mid" id="frag928" style="display:none"><pre>
    def close(self):
        if self.closed:
            return
        if self.waiting:
            for remote in self.remotes:
                remote.recv()
        for remote in self.remotes:
            remote.send(('close', None))
        for p in self.ps:
            p.join()
            self.closed = True

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 51:</b> &nbsp; 2 fragments, nominal size 22 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag842')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/baselines/common/wrappers.py: 539-563
</a>
<div class="mid" id="frag842" style="display:none"><pre>
def unit_test():
    env_id = 'CartPole-v0'
    unwrapped_env = gym.make(env_id)
    wrapped_env = build_env(env_id, False)
    o = wrapped_env.reset()
    print('Reset {} observation shape {}'.format(env_id, o.shape))
    done = False
    while not done:
        a = unwrapped_env.action_space.sample()
        o_, r, done, info = wrapped_env.step(a)
        print('Take action {} get reward {} info {}'.format(a, r, info))

    env_id = 'PongNoFrameskip-v4'
    nenv = 2
    unwrapped_env = gym.make(env_id)
    wrapped_env = build_env(env_id, True, nenv=nenv)
    o = wrapped_env.reset()
    print('Reset {} observation shape {}'.format(env_id, o.shape))
    for _ in range(1000):
        a = [unwrapped_env.action_space.sample() for _ in range(nenv)]
        a = np.asarray(a, 'int64')
        o_, r, done, info = wrapped_env.step(a)
        print('Take action {} get reward {} info {}'.format(a, r, info))


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag936')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_wrappers.py: 538-562
</a>
<div class="mid" id="frag936" style="display:none"><pre>
def unit_test():
    env_id = 'CartPole-v0'
    unwrapped_env = gym.make(env_id)
    wrapped_env = build_env(env_id, False)
    o = wrapped_env.reset()
    print('Reset {} observation shape {}'.format(env_id, o.shape))
    done = False
    while not done:
        a = unwrapped_env.action_space.sample()
        o_, r, done, info = wrapped_env.step(a)
        print('Take action {} get reward {} info {}'.format(a, r, info))

    env_id = 'PongNoFrameskip-v4'
    nenv = 2
    unwrapped_env = gym.make(env_id)
    wrapped_env = build_env(env_id, True, nenv=nenv)
    o = wrapped_env.reset()
    print('Reset {} observation shape {}'.format(env_id, o.shape))
    for _ in range(1000):
        a = [unwrapped_env.action_space.sample() for _ in range(nenv)]
        a = np.asarray(a, 'int64')
        o_, r, done, info = wrapped_env.step(a)
        print('Take action {} get reward {} info {}'.format(a, r, info))


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 52:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag937')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_DPPO.py: 83-97
</a>
<div class="mid" id="frag937" style="display:none"><pre>
    def __init__(self):

        # critic
        tfs = tl.layers.Input([None, S_DIM], tf.float32, 'state')
        l1 = tl.layers.Dense(100, tf.nn.relu)(tfs)
        v = tl.layers.Dense(1)(l1)
        self.critic = tl.models.Model(tfs, v)
        self.critic.train()

        # actor
        self.actor = self._build_anet('pi', trainable=True)
        self.actor_old = self._build_anet('oldpi', trainable=False)
        self.actor_opt = tf.optimizers.Adam(A_LR)
        self.critic_opt = tf.optimizers.Adam(C_LR)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1033')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_PPO.py: 75-89
</a>
<div class="mid" id="frag1033" style="display:none"><pre>
    def __init__(self):

        # critic
        tfs = tl.layers.Input([None, S_DIM], tf.float32, 'state')
        l1 = tl.layers.Dense(100, tf.nn.relu)(tfs)
        v = tl.layers.Dense(1)(l1)
        self.critic = tl.models.Model(tfs, v)
        self.critic.train()

        # actor
        self.actor = self._build_anet('pi', trainable=True)
        self.actor_old = self._build_anet('oldpi', trainable=False)
        self.actor_opt = tf.optimizers.Adam(A_LR)
        self.critic_opt = tf.optimizers.Adam(C_LR)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 53:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag943')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_DPPO.py: 213-232
</a>
<div class="mid" id="frag943" style="display:none"><pre>
                ROLLING_EVENT.set()  # set roll-out available

    def _build_anet(self, name, trainable):
        '''
        Build policy network
        :param name: name
        :param trainable: trainable flag
        :return: policy network
        '''
        tfs = tl.layers.Input([None, S_DIM], tf.float32, name + '_state')
        l1 = tl.layers.Dense(100, tf.nn.relu, name=name + '_l1')(tfs)
        a = tl.layers.Dense(A_DIM, tf.nn.tanh, name=name + '_a')(l1)
        mu = tl.layers.Lambda(lambda x: x * 2, name=name + '_lambda')(a)
        sigma = tl.layers.Dense(A_DIM, tf.nn.softplus, name=name + '_sigma')(l1)
        model = tl.models.Model(tfs, [mu, sigma], name)

        if trainable:
            model.train()
        else:
            model.eval()
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1039')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_PPO.py: 198-217
</a>
<div class="mid" id="frag1039" style="display:none"><pre>
    def _build_anet(self, name, trainable):
        '''
        Build policy network
        :param name: name
        :param trainable: trainable flag
        :return: policy network
        '''
        tfs = tl.layers.Input([None, S_DIM], tf.float32, name + '_state')
        l1 = tl.layers.Dense(100, tf.nn.relu, name=name + '_l1')(tfs)
        a = tl.layers.Dense(A_DIM, tf.nn.tanh, name=name + '_a')(l1)
        mu = tl.layers.Lambda(lambda x: x * 2, name=name + '_lambda')(a)
        sigma = tl.layers.Dense(A_DIM, tf.nn.softplus, name=name + '_sigma')(l1)
        model = tl.models.Model(tfs, [mu, sigma], name)

        if trainable:
            model.train()
        else:
            model.eval()
        return model

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 54:</b> &nbsp; 2 fragments, nominal size 20 lines, similarity 80%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag962')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_C51.py: 116-140
</a>
<div class="mid" id="frag962" style="display:none"><pre>
    def __init__(self, name):
        super(CNN, self).__init__(name=name)
        h, w, in_channels = in_dim
        dense_in_channels = 64 * ((h - 28) // 8) * ((w - 28) // 8)
        self.conv1 = tl.layers.Conv2d(
            32, (8, 8), (4, 4), tf.nn.relu, 'VALID', in_channels=in_channels, name='conv2d_1',
            W_init=tf.initializers.GlorotUniform()
        )
        self.conv2 = tl.layers.Conv2d(
            64, (4, 4), (2, 2), tf.nn.relu, 'VALID', in_channels=32, name='conv2d_2',
            W_init=tf.initializers.GlorotUniform()
        )
        self.conv3 = tl.layers.Conv2d(
            64, (3, 3), (1, 1), tf.nn.relu, 'VALID', in_channels=64, name='conv2d_3',
            W_init=tf.initializers.GlorotUniform()
        )
        self.flatten = tl.layers.Flatten(name='flatten')
        self.preq = tl.layers.Dense(
            256, tf.nn.relu, in_channels=dense_in_channels, name='pre_q', W_init=tf.initializers.GlorotUniform()
        )
        self.qvalue = tl.layers.Dense(
            out_dim * atom_num, in_channels=256, name='q', W_init=tf.initializers.GlorotUniform()
        )
        self.reshape = tl.layers.Reshape((-1, out_dim, atom_num))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1046')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_DQN_variants.py: 157-183
</a>
<div class="mid" id="frag1046" style="display:none"><pre>
    def __init__(self, name):
        super(CNN, self).__init__(name=name)
        h, w, in_channels = in_dim
        dense_in_channels = 64 * ((h - 28) // 8) * ((w - 28) // 8)
        self.conv1 = tl.layers.Conv2d(
            32, (8, 8), (4, 4), tf.nn.relu, 'VALID', in_channels=in_channels, name='conv2d_1',
            W_init=tf.initializers.GlorotUniform()
        )
        self.conv2 = tl.layers.Conv2d(
            64, (4, 4), (2, 2), tf.nn.relu, 'VALID', in_channels=32, name='conv2d_2',
            W_init=tf.initializers.GlorotUniform()
        )
        self.conv3 = tl.layers.Conv2d(
            64, (3, 3), (1, 1), tf.nn.relu, 'VALID', in_channels=64, name='conv2d_3',
            W_init=tf.initializers.GlorotUniform()
        )
        self.flatten = tl.layers.Flatten(name='flatten')
        self.preq = tl.layers.Dense(
            256, tf.nn.relu, in_channels=dense_in_channels, name='pre_q', W_init=tf.initializers.GlorotUniform()
        )
        self.qvalue = tl.layers.Dense(out_dim, in_channels=256, name='q', W_init=tf.initializers.GlorotUniform())
        self.pres = tl.layers.Dense(
            256, tf.nn.relu, in_channels=dense_in_channels, name='pre_s', W_init=tf.initializers.GlorotUniform()
        )
        self.svalue = tl.layers.Dense(1, in_channels=256, name='state', W_init=tf.initializers.GlorotUniform())
        self.noise_scale = 0

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 55:</b> &nbsp; 2 fragments, nominal size 16 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag967')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_C51.py: 165-181
</a>
<div class="mid" id="frag967" style="display:none"><pre>
    def _encode_sample(self, idxes):
        b_o, b_a, b_r, b_o_, b_d = [], [], [], [], []
        for i in idxes:
            o, a, r, o_, d = self._storage[i]
            b_o.append(o)
            b_a.append(a)
            b_r.append(r)
            b_o_.append(o_)
            b_d.append(d)
        return (
            np.stack(b_o).astype('float32') * ob_scale,
            np.stack(b_a).astype('int32'),
            np.stack(b_r).astype('float32'),
            np.stack(b_o_).astype('float32') * ob_scale,
            np.stack(b_d).astype('float32'),
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1051')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_DQN_variants.py: 231-247
</a>
<div class="mid" id="frag1051" style="display:none"><pre>
    def _encode_sample(self, idxes):
        b_o, b_a, b_r, b_o_, b_d = [], [], [], [], []
        for i in idxes:
            o, a, r, o_, d = self._storage[i]
            b_o.append(o)
            b_a.append(a)
            b_r.append(r)
            b_o_.append(o_)
            b_d.append(d)
        return (
            np.stack(b_o).astype('float32') * ob_scale,
            np.stack(b_a).astype('int32'),
            np.stack(b_r).astype('float32'),
            np.stack(b_o_).astype('float32') * ob_scale,
            np.stack(b_d).astype('float32'),
        )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 56:</b> &nbsp; 2 fragments, nominal size 17 lines, similarity 94%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag971')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_C51.py: 203-219
</a>
<div class="mid" id="frag971" style="display:none"><pre>
    def __init__(self):
        model = MLP if qnet_type == 'MLP' else CNN
        self.qnet = model('q')
        if args.mode == 'train':
            self.qnet.train()
            self.targetqnet = model('targetq')
            self.targetqnet.infer()
            sync(self.qnet, self.targetqnet)
        else:
            self.qnet.infer()
            tl.files.load_and_assign_npz(name=args.save_path, network=self.qnet)
        self.niter = 0
        if clipnorm is not None:
            self.optimizer = tf.optimizers.Adam(learning_rate=lr, clipnorm=clipnorm)
        else:
            self.optimizer = tf.optimizers.Adam(learning_rate=lr)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1057')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_DQN_variants.py: 279-296
</a>
<div class="mid" id="frag1057" style="display:none"><pre>
    def __init__(self):
        model = MLP if qnet_type == 'MLP' else CNN
        self.qnet = model('q')
        if args.mode == 'train':
            self.qnet.train()
            self.targetqnet = model('targetq')
            self.targetqnet.infer()
            sync(self.qnet, self.targetqnet)
        else:
            self.qnet.infer()
            tl.files.load_and_assign_npz(name=args.save_path, network=self.qnet)
        self.niter = 0
        if clipnorm is not None:
            self.optimizer = tf.optimizers.Adam(learning_rate=lr, clipnorm=clipnorm)
        else:
            self.optimizer = tf.optimizers.Adam(learning_rate=lr)
        self.noise_scale = noise_scale

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 57:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag976')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_AC.py: 84-100
</a>
<div class="mid" id="frag976" style="display:none"><pre>
    def __init__(self, n_features, n_actions, lr=0.001):

        def get_model(inputs_shape):
            ni = tl.layers.Input(inputs_shape, name='state')
            nn = tl.layers.Dense(
                n_units=30, act=tf.nn.relu6, W_init=tf.random_uniform_initializer(0, 0.01), name='hidden'
            )(ni)
            nn = tl.layers.Dense(
                n_units=10, act=tf.nn.relu6, W_init=tf.random_uniform_initializer(0, 0.01), name='hidden2'
            )(nn)
            nn = tl.layers.Dense(n_units=n_actions, name='actions')(nn)
            return tl.models.Model(inputs=ni, outputs=nn, name="Actor")

        self.model = get_model([None, n_features])
        self.model.train()
        self.optimizer = tf.optimizers.Adam(lr)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag983')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_AC.py: 131-148
</a>
<div class="mid" id="frag983" style="display:none"><pre>
    def __init__(self, n_features, lr=0.01):

        def get_model(inputs_shape):
            ni = tl.layers.Input(inputs_shape, name='state')
            nn = tl.layers.Dense(
                n_units=30, act=tf.nn.relu6, W_init=tf.random_uniform_initializer(0, 0.01), name='hidden'
            )(ni)
            nn = tl.layers.Dense(
                n_units=5, act=tf.nn.relu, W_init=tf.random_uniform_initializer(0, 0.01), name='hidden2'
            )(nn)
            nn = tl.layers.Dense(n_units=1, act=None, name='value')(nn)
            return tl.models.Model(inputs=ni, outputs=nn, name="Critic")

        self.model = get_model([1, n_features])
        self.model.train()

        self.optimizer = tf.optimizers.Adam(lr)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 58:</b> &nbsp; 2 fragments, nominal size 21 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1045')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_DQN_variants.py: 126-154
</a>
<div class="mid" id="frag1045" style="display:none"><pre>
    def forward(self, ni):
        feature = self.h1(ni)

        # apply noise to all linear layer
        if self.noise_scale != 0:
            noises = []
            for layer in [self.qvalue, self.svalue]:
                for var in layer.trainable_weights:
                    noise = tf.random.normal(tf.shape(var), 0, self.noise_scale)
                    noises.append(noise)
                    var.assign_add(noise)

        qvalue = self.qvalue(feature)
        svalue = self.svalue(feature)

        if self.noise_scale != 0:
            idx = 0
            for layer in [self.qvalue, self.svalue]:
                for var in layer.trainable_weights:
                    var.assign_sub(noises[idx])
                    idx += 1

        if dueling:
            # dueling network
            return svalue + qvalue - tf.reduce_mean(qvalue, 1, keepdims=True)
        else:
            return qvalue


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1047')" href="javascript:;">
TensorLayer-2.2.1/examples/reinforcement_learning/tutorial_DQN_variants.py: 184-213
</a>
<div class="mid" id="frag1047" style="display:none"><pre>
    def forward(self, ni):
        feature = self.flatten(self.conv3(self.conv2(self.conv1(ni))))

        # apply noise to all linear layer
        if self.noise_scale != 0:
            noises = []
            for layer in [self.preq, self.qvalue, self.pres, self.svalue]:
                for var in layer.trainable_weights:
                    noise = tf.random.normal(tf.shape(var), 0, self.noise_scale)
                    noises.append(noise)
                    var.assign_add(noise)

        qvalue = self.qvalue(self.preq(feature))
        svalue = self.svalue(self.pres(feature))

        if self.noise_scale != 0:
            idx = 0
            for layer in [self.preq, self.qvalue, self.pres, self.svalue]:
                for var in layer.trainable_weights:
                    var.assign_sub(noises[idx])
                    idx += 1

        if dueling:
            # dueling network
            return svalue + qvalue - tf.reduce_mean(qvalue, 1, keepdims=True)
        else:
            return qvalue


# ##############################  Replay  ####################################
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 59:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1063')" href="javascript:;">
TensorLayer-2.2.1/examples/data_process/tutorial_tfrecord.py: 77-94
</a>
<div class="mid" id="frag1063" style="display:none"><pre>
def read_and_decode(filename):
    # generate a queue with a given file name
    raw_dataset = tf.data.TFRecordDataset([filename]).shuffle(1000).batch(4)
    for serialized_example in raw_dataset:
        features = tf.io.parse_example(
            serialized_example, features={
                'label': tf.io.FixedLenFeature([], tf.int64),
                'img_raw': tf.io.FixedLenFeature([], tf.string),
            }
        )
        # You can do more image distortion here for training data
        img_batch = tf.io.decode_raw(features['img_raw'], tf.uint8)
        img_batch = tf.reshape(img_batch, [4, 224, 224, 3])
        # img = tf.cast(img, tf.float32) * (1. / 255) - 0.5
        label_batch = tf.cast(features['label'], tf.int32)
        yield img_batch, label_batch


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1071')" href="javascript:;">
TensorLayer-2.2.1/examples/data_process/tutorial_tfrecord2.py: 63-80
</a>
<div class="mid" id="frag1071" style="display:none"><pre>
def read_and_decode(filename):
    batchsize = 4
    raw_dataset = tf.data.TFRecordDataset([filename]).shuffle(1000).batch(batchsize)
    for serialized_example in raw_dataset:
        features = tf.io.parse_example(
            serialized_example, features={
                'label': tf.io.FixedLenFeature([], tf.int64),
                'img_raw': tf.io.FixedLenFeature([], tf.string),
            }
        )
        # You can do more image distortion here for training data
        img_batch = tf.io.decode_raw(features['img_raw'], tf.uint8)
        img_batch = tf.reshape(img_batch, [-1, 32, 32, 3])
        # img = tf.cast(img, tf.float32) #* (1. / 255) - 0.5    # don't need to cast here, as it is float32 already
        label_batch = tf.cast(features['label'], tf.int32)
        yield img_batch, label_batch


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 60:</b> &nbsp; 3 fragments, nominal size 17 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1114')" href="javascript:;">
TensorLayer-2.2.1/examples/quantized_net/tutorial_ternaryweight_cifar10_tfrecord.py: 64-94
</a>
<div class="mid" id="frag1114" style="display:none"><pre>
def data_to_tfrecord(images, labels, filename):
    """Save data into TFRecord."""
    if os.path.isfile(filename):
        print("%s exists" % filename)
        return
    print("Converting data into %s ..." % filename)
    # cwd = os.getcwd()
    writer = tf.python_io.TFRecordWriter(filename)
    for index, img in enumerate(images):
        img_raw = img.tobytes()
        # Visualize a image
        # tl.visualize.frame(np.asarray(img, dtype=np.uint8), second=1, saveable=False, name='frame', fig_idx=1236)
        label = int(labels[index])
        # print(label)
        # Convert the bytes back to image as follow:
        # image = Image.frombytes('RGB', (32, 32), img_raw)
        # image = np.fromstring(img_raw, np.float32)
        # image = image.reshape([32, 32, 3])
        # tl.visualize.frame(np.asarray(image, dtype=np.uint8), second=1, saveable=False, name='frame', fig_idx=1236)
        example = tf.train.Example(
            features=tf.train.Features(
                feature={
                    "label": tf.train.Feature(int64_list=tf.train.Int64List(value=[label])),
                    'img_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])),
                }
            )
        )
        writer.write(example.SerializeToString())  # Serialize To String
    writer.close()


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1119')" href="javascript:;">
TensorLayer-2.2.1/examples/quantized_net/tutorial_dorefanet_cifar10_tfrecord.py: 65-95
</a>
<div class="mid" id="frag1119" style="display:none"><pre>
def data_to_tfrecord(images, labels, filename):
    """Save data into TFRecord."""
    if os.path.isfile(filename):
        print("%s exists" % filename)
        return
    print("Converting data into %s ..." % filename)
    # cwd = os.getcwd()
    writer = tf.python_io.TFRecordWriter(filename)
    for index, img in enumerate(images):
        img_raw = img.tobytes()
        # Visualize a image
        # tl.visualize.frame(np.asarray(img, dtype=np.uint8), second=1, saveable=False, name='frame', fig_idx=1236)
        label = int(labels[index])
        # print(label)
        # Convert the bytes back to image as follow:
        # image = Image.frombytes('RGB', (32, 32), img_raw)
        # image = np.fromstring(img_raw, np.float32)
        # image = image.reshape([32, 32, 3])
        # tl.visualize.frame(np.asarray(image, dtype=np.uint8), second=1, saveable=False, name='frame', fig_idx=1236)
        example = tf.train.Example(
            features=tf.train.Features(
                feature={
                    "label": tf.train.Feature(int64_list=tf.train.Int64List(value=[label])),
                    'img_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])),
                }
            )
        )
        writer.write(example.SerializeToString())  # Serialize To String
    writer.close()


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1124')" href="javascript:;">
TensorLayer-2.2.1/examples/quantized_net/tutorial_binarynet_cifar10_tfrecord.py: 65-95
</a>
<div class="mid" id="frag1124" style="display:none"><pre>
def data_to_tfrecord(images, labels, filename):
    """Save data into TFRecord."""
    if os.path.isfile(filename):
        print("%s exists" % filename)
        return
    print("Converting data into %s ..." % filename)
    # cwd = os.getcwd()
    writer = tf.python_io.TFRecordWriter(filename)
    for index, img in enumerate(images):
        img_raw = img.tobytes()
        # Visualize a image
        # tl.visualize.frame(np.asarray(img, dtype=np.uint8), second=1, saveable=False, name='frame', fig_idx=1236)
        label = int(labels[index])
        # print(label)
        # Convert the bytes back to image as follow:
        # image = Image.frombytes('RGB', (32, 32), img_raw)
        # image = np.fromstring(img_raw, np.float32)
        # image = image.reshape([32, 32, 3])
        # tl.visualize.frame(np.asarray(image, dtype=np.uint8), second=1, saveable=False, name='frame', fig_idx=1236)
        example = tf.train.Example(
            features=tf.train.Features(
                feature={
                    "label": tf.train.Feature(int64_list=tf.train.Int64List(value=[label])),
                    'img_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])),
                }
            )
        )
        writer.write(example.SerializeToString())  # Serialize To String
    writer.close()


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 61:</b> &nbsp; 3 fragments, nominal size 24 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1115')" href="javascript:;">
TensorLayer-2.2.1/examples/quantized_net/tutorial_ternaryweight_cifar10_tfrecord.py: 95-140
</a>
<div class="mid" id="frag1115" style="display:none"><pre>
def read_and_decode(filename, is_train=None):
    """Return tensor to read from TFRecord."""
    filename_queue = tf.train.string_input_producer([filename])
    reader = tf.TFRecordReader()
    _, serialized_example = reader.read(filename_queue)
    features = tf.parse_single_example(
        serialized_example, features={
            'label': tf.FixedLenFeature([], tf.int64),
            'img_raw': tf.FixedLenFeature([], tf.string),
        }
    )
    # You can do more image distortion here for training data
    img = tf.decode_raw(features['img_raw'], tf.float32)
    img = tf.reshape(img, [32, 32, 3])
    # img = tf.cast(img, tf.float32) #* (1. / 255) - 0.5
    if is_train ==True:
        # 1. Randomly crop a [height, width] section of the image.
        img = tf.random_crop(img, [24, 24, 3])

        # 2. Randomly flip the image horizontally.
        img = tf.image.random_flip_left_right(img)

        # 3. Randomly change brightness.
        img = tf.image.random_brightness(img, max_delta=63)

        # 4. Randomly change contrast.
        img = tf.image.random_contrast(img, lower=0.2, upper=1.8)

        # 5. Subtract off the mean and divide by the variance of the pixels.
        img = tf.image.per_image_standardization(img)

    elif is_train == False:
        # 1. Crop the central [height, width] of the image.
        img = tf.image.resize_image_with_crop_or_pad(img, 24, 24)

        # 2. Subtract off the mean and divide by the variance of the pixels.
        img = tf.image.per_image_standardization(img)

    elif is_train == None:
        img = img

    label = tf.cast(features['label'], tf.int32)
    return img, label


# Save data into TFRecord files
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1125')" href="javascript:;">
TensorLayer-2.2.1/examples/quantized_net/tutorial_binarynet_cifar10_tfrecord.py: 96-141
</a>
<div class="mid" id="frag1125" style="display:none"><pre>
def read_and_decode(filename, is_train=None):
    """Return tensor to read from TFRecord."""
    filename_queue = tf.train.string_input_producer([filename])
    reader = tf.TFRecordReader()
    _, serialized_example = reader.read(filename_queue)
    features = tf.parse_single_example(
        serialized_example, features={
            'label': tf.FixedLenFeature([], tf.int64),
            'img_raw': tf.FixedLenFeature([], tf.string),
        }
    )
    # You can do more image distortion here for training data
    img = tf.decode_raw(features['img_raw'], tf.float32)
    img = tf.reshape(img, [32, 32, 3])
    # img = tf.cast(img, tf.float32) #* (1. / 255) - 0.5
    if is_train ==True:
        # 1. Randomly crop a [height, width] section of the image.
        img = tf.random_crop(img, [24, 24, 3])

        # 2. Randomly flip the image horizontally.
        img = tf.image.random_flip_left_right(img)

        # 3. Randomly change brightness.
        img = tf.image.random_brightness(img, max_delta=63)

        # 4. Randomly change contrast.
        img = tf.image.random_contrast(img, lower=0.2, upper=1.8)

        # 5. Subtract off the mean and divide by the variance of the pixels.
        img = tf.image.per_image_standardization(img)

    elif is_train == False:
        # 1. Crop the central [height, width] of the image.
        img = tf.image.resize_image_with_crop_or_pad(img, 24, 24)

        # 2. Subtract off the mean and divide by the variance of the pixels.
        img = tf.image.per_image_standardization(img)

    elif is_train == None:
        img = img

    label = tf.cast(features['label'], tf.int32)
    return img, label


# Save data into TFRecord files
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1120')" href="javascript:;">
TensorLayer-2.2.1/examples/quantized_net/tutorial_dorefanet_cifar10_tfrecord.py: 96-141
</a>
<div class="mid" id="frag1120" style="display:none"><pre>
def read_and_decode(filename, is_train=None):
    """Return tensor to read from TFRecord."""
    filename_queue = tf.train.string_input_producer([filename])
    reader = tf.TFRecordReader()
    _, serialized_example = reader.read(filename_queue)
    features = tf.parse_single_example(
        serialized_example, features={
            'label': tf.FixedLenFeature([], tf.int64),
            'img_raw': tf.FixedLenFeature([], tf.string),
        }
    )
    # You can do more image distortion here for training data
    img = tf.decode_raw(features['img_raw'], tf.float32)
    img = tf.reshape(img, [32, 32, 3])
    # img = tf.cast(img, tf.float32) #* (1. / 255) - 0.5
    if is_train ==True:
        # 1. Randomly crop a [height, width] section of the image.
        img = tf.random_crop(img, [24, 24, 3])

        # 2. Randomly flip the image horizontally.
        img = tf.image.random_flip_left_right(img)

        # 3. Randomly change brightness.
        img = tf.image.random_brightness(img, max_delta=63)

        # 4. Randomly change contrast.
        img = tf.image.random_contrast(img, lower=0.2, upper=1.8)

        # 5. Subtract off the mean and divide by the variance of the pixels.
        img = tf.image.per_image_standardization(img)

    elif is_train == False:
        # 1. Crop the central [height, width] of the image.
        img = tf.image.resize_image_with_crop_or_pad(img, 24, 24)

        # 2. Subtract off the mean and divide by the variance of the pixels.
        img = tf.image.per_image_standardization(img)

    elif is_train == None:
        img = img

    label = tf.cast(features['label'], tf.int32)
    return img, label


# Save data into TFRecord files
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 62:</b> &nbsp; 3 fragments, nominal size 23 lines, similarity 86%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1116')" href="javascript:;">
TensorLayer-2.2.1/examples/quantized_net/tutorial_ternaryweight_cifar10_tfrecord.py: 162-196
</a>
<div class="mid" id="frag1116" style="display:none"><pre>
    def model(x_crop, y_, reuse):
        """For more simplified CNN APIs, check tensorlayer.org."""
        with tf.variable_scope("model", reuse=reuse):
            net = tl.layers.InputLayer(x_crop, name='input')
            net = tl.layers.Conv2d(net, 64, (5, 5), (1, 1), act=tf.nn.relu, padding='SAME', name='cnn1')
            net = tl.layers.MaxPool2d(net, (3, 3), (2, 2), padding='SAME', name='pool1')
            net = tl.layers.LocalResponseNormLayer(net, 4, 1.0, 0.001 / 9.0, 0.75, name='norm1')
            net = tl.layers.TernaryConv2d(net, 64, (5, 5), (1, 1), act=tf.nn.relu, padding='SAME', name='cnn2')
            net = tl.layers.LocalResponseNormLayer(net, 4, 1.0, 0.001 / 9.0, 0.75, name='norm2')
            net = tl.layers.MaxPool2d(net, (3, 3), (2, 2), padding='SAME', name='pool2')
            net = tl.layers.FlattenLayer(net, name='flatten')
            net = tl.layers.TernaryDenseLayer(net, 384, act=tf.nn.relu, name='d1relu')
            net = tl.layers.TernaryDenseLayer(net, 192, act=tf.nn.relu, name='d2relu')
            net = tl.layers.DenseLayer(net, 10, act=None, name='output')
            y = net.outputs

            ce = tl.cost.cross_entropy(y, y_, name='cost')
            # L2 for the MLP, without this, the accuracy will be reduced by 15%.
            L2 = 0
            for p in tl.layers.get_variables_with_name('relu/W', True, True):
                L2 += tf.contrib.layers.l2_regularizer(0.004)(p)
            cost = ce + L2

            # correct_prediction = tf.equal(tf.argmax(tf.nn.softmax(y), 1), y_)
            correct_prediction = tf.equal(tf.cast(tf.argmax(y, 1), tf.int32), y_)
            acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

            return net, cost, acc

    # You can also use placeholder to feed_dict in data after using
    # val, l = sess.run([x_train_batch, y_train_batch]) to get the data
    # x_crop = tf.placeholder(tf.float32, shape=[batch_size, 24, 24, 3])
    # y_ = tf.placeholder(tf.int32, shape=[batch_size,])
    # cost, acc, network = model(x_crop, y_, None)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1126')" href="javascript:;">
TensorLayer-2.2.1/examples/quantized_net/tutorial_binarynet_cifar10_tfrecord.py: 163-201
</a>
<div class="mid" id="frag1126" style="display:none"><pre>
    def model(x_crop, y_, reuse):
        """For more simplified CNN APIs, check tensorlayer.org."""
        with tf.variable_scope("model", reuse=reuse):
            net = tl.layers.InputLayer(x_crop, name='input')
            net = tl.layers.Conv2d(net, 64, (5, 5), (1, 1), act=tf.nn.relu, padding='SAME', name='cnn1')
            net = tl.layers.SignLayer(net)
            net = tl.layers.MaxPool2d(net, (3, 3), (2, 2), padding='SAME', name='pool1')
            net = tl.layers.LocalResponseNormLayer(net, 4, 1.0, 0.001 / 9.0, 0.75, name='norm1')
            net = tl.layers.BinaryConv2d(net, 64, (5, 5), (1, 1), act=tf.nn.relu, padding='SAME', name='cnn2')
            net = tl.layers.LocalResponseNormLayer(net, 4, 1.0, 0.001 / 9.0, 0.75, name='norm2')
            net = tl.layers.MaxPool2d(net, (3, 3), (2, 2), padding='SAME', name='pool2')
            net = tl.layers.FlattenLayer(net, name='flatten')
            net = tl.layers.SignLayer(net)
            net = tl.layers.BinaryDenseLayer(net, 384, act=tf.nn.relu, name='d1relu')
            net = tl.layers.SignLayer(net)
            net = tl.layers.BinaryDenseLayer(net, 192, act=tf.nn.relu, name='d2relu')
            net = tl.layers.DenseLayer(net, 10, act=None, name='output')

            y = net.outputs

            ce = tl.cost.cross_entropy(y, y_, name='cost')
            # L2 for the MLP, without this, the accuracy will be reduced by 15%.
            L2 = 0
            for p in tl.layers.get_variables_with_name('relu/W', True, True):
                L2 += tf.contrib.layers.l2_regularizer(0.004)(p)
            cost = ce + L2

            # correct_prediction = tf.equal(tf.argmax(tf.nn.softmax(y), 1), y_)
            correct_prediction = tf.equal(tf.cast(tf.argmax(y, 1), tf.int32), y_)
            acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

            return net, cost, acc

    # You can also use placeholder to feed_dict in data after using
    # val, l = sess.run([x_train_batch, y_train_batch]) to get the data
    # x_crop = tf.placeholder(tf.float32, shape=[batch_size, 24, 24, 3])
    # y_ = tf.placeholder(tf.int32, shape=[batch_size,])
    # cost, acc, network = model(x_crop, y_, None)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1121')" href="javascript:;">
TensorLayer-2.2.1/examples/quantized_net/tutorial_dorefanet_cifar10_tfrecord.py: 163-197
</a>
<div class="mid" id="frag1121" style="display:none"><pre>
    def model(x_crop, y_, reuse):
        """For more simplified CNN APIs, check tensorlayer.org."""
        with tf.variable_scope("model", reuse=reuse):
            net = tl.layers.InputLayer(x_crop, name='input')
            net = tl.layers.Conv2d(net, 64, (5, 5), (1, 1), act=tf.nn.relu, padding='SAME', name='cnn1')
            net = tl.layers.MaxPool2d(net, (3, 3), (2, 2), padding='SAME', name='pool1')
            net = tl.layers.LocalResponseNormLayer(net, 4, 1.0, 0.001 / 9.0, 0.75, name='norm1')
            net = tl.layers.DorefaConv2d(net, 1, 3, 64, (5, 5), (1, 1), tf.nn.relu, padding='SAME', name='cnn2')
            net = tl.layers.LocalResponseNormLayer(net, 4, 1.0, 0.001 / 9.0, 0.75, name='norm2')
            net = tl.layers.MaxPool2d(net, (3, 3), (2, 2), padding='SAME', name='pool2')
            net = tl.layers.FlattenLayer(net, name='flatten')
            net = tl.layers.DorefaDenseLayer(net, 1, 3, 384, act=tf.nn.relu, name='d1relu')
            net = tl.layers.DorefaDenseLayer(net, 1, 3, 192, act=tf.nn.relu, name='d2relu')
            net = tl.layers.DenseLayer(net, 10, act=None, name='output')
            y = net.outputs

            ce = tl.cost.cross_entropy(y, y_, name='cost')
            # L2 for the MLP, without this, the accuracy will be reduced by 15%.
            L2 = 0
            for p in tl.layers.get_variables_with_name('relu/W', True, True):
                L2 += tf.contrib.layers.l2_regularizer(0.004)(p)
            cost = ce + L2

            # correct_prediction = tf.equal(tf.argmax(tf.nn.softmax(y), 1), y_)
            correct_prediction = tf.equal(tf.cast(tf.argmax(y, 1), tf.int32), y_)
            acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

            return net, cost, acc

    # You can also use placeholder to feed_dict in data after using
    # val, l = sess.run([x_train_batch, y_train_batch]) to get the data
    # x_crop = tf.placeholder(tf.float32, shape=[batch_size, 24, 24, 3])
    # y_ = tf.placeholder(tf.int32, shape=[batch_size,])
    # cost, acc, network = model(x_crop, y_, None)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 63:</b> &nbsp; 3 fragments, nominal size 15 lines, similarity 80%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1117')" href="javascript:;">
TensorLayer-2.2.1/examples/quantized_net/tutorial_ternaryweight_mnist_cnn.py: 24-51
</a>
<div class="mid" id="frag1117" style="display:none"><pre>
def model(x, is_train=True, reuse=False):
    # In BNN, all the layers inputs are binary, with the exception of the first layer.
    # ref: https://github.com/itayhubara/BinaryNet.tf/blob/master/models/BNN_cifar10.py
    with tf.variable_scope("binarynet", reuse=reuse):
        net = tl.layers.InputLayer(x, name='input')
        net = tl.layers.TernaryConv2d(net, 32, (5, 5), (1, 1), padding='SAME', b_init=None, name='bcnn1')
        net = tl.layers.MaxPool2d(net, (2, 2), (2, 2), padding='SAME', name='pool1')
        net = tl.layers.BatchNormLayer(net, act=tl.act.htanh, is_train=is_train, name='bn1')

        # net = tl.layers.SignLayer(net)
        net = tl.layers.TernaryConv2d(net, 64, (5, 5), (1, 1), padding='SAME', b_init=None, name='bcnn2')
        net = tl.layers.MaxPool2d(net, (2, 2), (2, 2), padding='SAME', name='pool2')
        net = tl.layers.BatchNormLayer(net, act=tl.act.htanh, is_train=is_train, name='bn2')

        net = tl.layers.FlattenLayer(net)
        # net = tl.layers.DropoutLayer(net, 0.8, True, is_train, name='drop1')
        # net = tl.layers.SignLayer(net)
        net = tl.layers.TernaryDenseLayer(net, 256, b_init=None, name='dense')
        net = tl.layers.BatchNormLayer(net, act=tl.act.htanh, is_train=is_train, name='bn3')

        # net = tl.layers.DropoutLayer(net, 0.8, True, is_train, name='drop2')
        # net = tl.layers.SignLayer(net)
        net = tl.layers.TernaryDenseLayer(net, 10, b_init=None, name='bout')
        net = tl.layers.BatchNormLayer(net, is_train=is_train, name='bno')
    return net


# define inferences
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1118')" href="javascript:;">
TensorLayer-2.2.1/examples/quantized_net/tutorial_dorefanet_mnist_cnn.py: 24-51
</a>
<div class="mid" id="frag1118" style="display:none"><pre>
def model(x, is_train=True, reuse=False):
    # In BNN, all the layers inputs are binary, with the exception of the first layer.
    # ref: https://github.com/itayhubara/BinaryNet.tf/blob/master/models/BNN_cifar10.py
    with tf.variable_scope("binarynet", reuse=reuse):
        net = tl.layers.InputLayer(x, name='input')
        net = tl.layers.DorefaConv2d(net, 1, 3, 32, (5, 5), (1, 1), padding='SAME', b_init=None, name='bcnn1')  #pylint: disable=bare-except
        net = tl.layers.MaxPool2d(net, (2, 2), (2, 2), padding='SAME', name='pool1')
        net = tl.layers.BatchNormLayer(net, act=tl.act.htanh, is_train=is_train, name='bn1')

        # net = tl.layers.SignLayer(net)
        net = tl.layers.DorefaConv2d(net, 1, 3, 64, (5, 5), (1, 1), padding='SAME', b_init=None, name='bcnn2')  #pylint: disable=bare-except
        net = tl.layers.MaxPool2d(net, (2, 2), (2, 2), padding='SAME', name='pool2')
        net = tl.layers.BatchNormLayer(net, act=tl.act.htanh, is_train=is_train, name='bn2')

        net = tl.layers.FlattenLayer(net)
        # net = tl.layers.DropoutLayer(net, 0.8, True, is_train, name='drop1')
        # net = tl.layers.SignLayer(net)
        net = tl.layers.DorefaDenseLayer(net, 1, 3, 256, b_init=None, name='dense')
        net = tl.layers.BatchNormLayer(net, act=tl.act.htanh, is_train=is_train, name='bn3')

        # net = tl.layers.DropoutLayer(net, 0.8, True, is_train, name='drop2')
        # net = tl.layers.SignLayer(net)
        net = tl.layers.DenseLayer(net, 10, b_init=None, name='bout')
        net = tl.layers.BatchNormLayer(net, is_train=is_train, name='bno')
    return net


# define inferences
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1123')" href="javascript:;">
TensorLayer-2.2.1/examples/quantized_net/tutorial_binarynet_mnist_cnn.py: 24-51
</a>
<div class="mid" id="frag1123" style="display:none"><pre>
def model(x, is_train=True, reuse=False):
    # In BNN, all the layers inputs are binary, with the exception of the first layer.
    # ref: https://github.com/itayhubara/BinaryNet.tf/blob/master/models/BNN_cifar10.py
    with tf.variable_scope("binarynet", reuse=reuse):
        net = tl.layers.InputLayer(x, name='input')
        net = tl.layers.BinaryConv2d(net, 32, (5, 5), (1, 1), padding='SAME', b_init=None, name='bcnn1')
        net = tl.layers.MaxPool2d(net, (2, 2), (2, 2), padding='SAME', name='pool1')
        net = tl.layers.BatchNormLayer(net, act=tl.act.htanh, is_train=is_train, name='bn1')

        net = tl.layers.SignLayer(net)
        net = tl.layers.BinaryConv2d(net, 64, (5, 5), (1, 1), padding='SAME', b_init=None, name='bcnn2')
        net = tl.layers.MaxPool2d(net, (2, 2), (2, 2), padding='SAME', name='pool2')
        net = tl.layers.BatchNormLayer(net, act=tl.act.htanh, is_train=is_train, name='bn2')

        net = tl.layers.FlattenLayer(net)
        # net = tl.layers.DropoutLayer(net, 0.8, True, is_train, name='drop1')
        net = tl.layers.SignLayer(net)
        net = tl.layers.BinaryDenseLayer(net, 256, b_init=None, name='dense')
        net = tl.layers.BatchNormLayer(net, act=tl.act.htanh, is_train=is_train, name='bn3')

        # net = tl.layers.DropoutLayer(net, 0.8, True, is_train, name='drop2')
        net = tl.layers.SignLayer(net)
        net = tl.layers.BinaryDenseLayer(net, 10, b_init=None, name='bout')
        net = tl.layers.BatchNormLayer(net, is_train=is_train, name='bno')
    return net


# define inferences
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 64:</b> &nbsp; 4 fragments, nominal size 19 lines, similarity 78%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1230')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/cost.py: 548-595
</a>
<div class="mid" id="frag1230" style="display:none"><pre>
# Regularization Functions
def li_regularizer(scale, scope=None):
    """Li regularization removes the neurons of previous layer. The `i` represents `inputs`.
    Returns a function that can be used to apply group li regularization to weights.
    The implementation follows `TensorFlow contrib &lt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/regularizers.py&gt;`__.

    Parameters
    ----------
    scale : float
        A scalar multiplier `Tensor`. 0.0 disables the regularizer.
    scope: str
        An optional scope name for this function.

    Returns
    --------
    A function with signature `li(weights, name=None)` that apply Li regularization.

    Raises
    ------
    ValueError : if scale is outside of the range [0.0, 1.0] or if scale is not a float.

    """
    if isinstance(scale, numbers.Integral):
        raise ValueError('scale cannot be an integer: %s' % scale)
    if isinstance(scale, numbers.Real):
        if scale &lt; 0.:
            raise ValueError('Setting a scale less than 0 on a regularizer: %g' % scale)
        if scale &gt;= 1.:
            raise ValueError('Setting a scale greater than 1 on a regularizer: %g' % scale)
        if scale == 0.:
            logging.info('Scale of 0 disables regularizer.')
            return lambda _, name=None: None

    def li(weights):
        """Applies li regularization to weights."""
        with tf.name_scope('li_regularizer') as scope:
            my_scale = ops.convert_to_tensor(scale, dtype=weights.dtype.base_dtype, name='scale')
            # if tf.__version__ &lt;= '0.12':
            #     standard_ops_fn = standard_ops.mul
            # else:
            standard_ops_fn = standard_ops.multiply
            return standard_ops_fn(
                my_scale, standard_ops.reduce_sum(standard_ops.sqrt(standard_ops.reduce_sum(tf.square(weights), 1))),
                name=scope
            )

    return li

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1232')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/cost.py: 596-642
</a>
<div class="mid" id="frag1232" style="display:none"><pre>

def lo_regularizer(scale):
    """Lo regularization removes the neurons of current layer. The `o` represents `outputs`
    Returns a function that can be used to apply group lo regularization to weights.
    The implementation follows `TensorFlow contrib &lt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/regularizers.py&gt;`__.

    Parameters
    ----------
    scale : float
        A scalar multiplier `Tensor`. 0.0 disables the regularizer.

    Returns
    -------
    A function with signature `lo(weights, name=None)` that apply Lo regularization.

    Raises
    ------
    ValueError : If scale is outside of the range [0.0, 1.0] or if scale is not a float.

    """
    if isinstance(scale, numbers.Integral):
        raise ValueError('scale cannot be an integer: %s' % scale)

    if isinstance(scale, numbers.Real):
        if scale &lt; 0.:
            raise ValueError('Setting a scale less than 0 on a regularizer: %g' % scale)
        if scale &gt;= 1.:
            raise ValueError('Setting a scale greater than 1 on a regularizer: %g' % scale)
        if scale == 0.:
            logging.info('Scale of 0 disables regularizer.')
            return lambda _, name=None: None

    def lo(weights, name='lo_regularizer'):
        """Applies group column regularization to weights."""
        with tf.name_scope(name) as scope:
            my_scale = ops.convert_to_tensor(scale, dtype=weights.dtype.base_dtype, name='scale')
            # if tf.__version__ &lt;= '0.12':
            #     standard_ops_fn = standard_ops.mul
            # else:
            standard_ops_fn = standard_ops.multiply
            return standard_ops_fn(
                my_scale, standard_ops.reduce_sum(standard_ops.sqrt(standard_ops.reduce_sum(tf.square(weights), 0))),
                name=scope
            )

    return lo

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1236')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/cost.py: 689-735
</a>
<div class="mid" id="frag1236" style="display:none"><pre>

def maxnorm_o_regularizer(scale):
    """Max-norm output regularization removes the neurons of current layer.
    Returns a function that can be used to apply max-norm regularization to each column of weight matrix.
    The implementation follows `TensorFlow contrib &lt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/regularizers.py&gt;`__.

    Parameters
    ----------
    scale : float
        A scalar multiplier `Tensor`. 0.0 disables the regularizer.

    Returns
    ---------
    A function with signature `mn_o(weights, name=None)` that apply Lo regularization.

    Raises
    ---------
    ValueError : If scale is outside of the range [0.0, 1.0] or if scale is not a float.

    """
    if isinstance(scale, numbers.Integral):
        raise ValueError('scale cannot be an integer: %s' % scale)

    if isinstance(scale, numbers.Real):
        if scale &lt; 0.:
            raise ValueError('Setting a scale less than 0 on a regularizer: %g' % scale)
        # if scale &gt;= 1.:
        #   raise ValueError('Setting a scale greater than 1 on a regularizer: %g' %
        #                    scale)
        if scale == 0.:
            logging.info('Scale of 0 disables regularizer.')
            return lambda _, name=None: None

    def mn_o(weights, name='maxnorm_o_regularizer'):
        """Applies max-norm regularization to weights."""
        with tf.name_scope(name) as scope:
            my_scale = ops.convert_to_tensor(scale, dtype=weights.dtype.base_dtype, name='scale')
            if tf.__version__ &lt;= '0.12':
                standard_ops_fn = standard_ops.mul
            else:
                standard_ops_fn = standard_ops.multiply
            return standard_ops_fn(
                my_scale, standard_ops.reduce_sum(standard_ops.reduce_max(standard_ops.abs(weights), 0)), name=scope
            )

    return mn_o

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1238')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/cost.py: 736-782
</a>
<div class="mid" id="frag1238" style="display:none"><pre>

def maxnorm_i_regularizer(scale):
    """Max-norm input regularization removes the neurons of previous layer.
    Returns a function that can be used to apply max-norm regularization to each row of weight matrix.
    The implementation follows `TensorFlow contrib &lt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/regularizers.py&gt;`__.

    Parameters
    ----------
    scale : float
        A scalar multiplier `Tensor`. 0.0 disables the regularizer.

    Returns
    ---------
    A function with signature `mn_i(weights, name=None)` that apply Lo regularization.

    Raises
    ---------
    ValueError : If scale is outside of the range [0.0, 1.0] or if scale is not a float.

    """
    if isinstance(scale, numbers.Integral):
        raise ValueError('scale cannot be an integer: %s' % scale)

    if isinstance(scale, numbers.Real):
        if scale &lt; 0.:
            raise ValueError('Setting a scale less than 0 on a regularizer: %g' % scale)
        # if scale &gt;= 1.:
        #   raise ValueError('Setting a scale greater than 1 on a regularizer: %g' %
        #                    scale)
        if scale == 0.:
            logging.info('Scale of 0 disables regularizer.')
            return lambda _, name=None: None

    def mn_i(weights, name='maxnorm_i_regularizer'):
        """Applies max-norm regularization to weights."""
        with tf.name_scope(name) as scope:
            my_scale = ops.convert_to_tensor(scale, dtype=weights.dtype.base_dtype, name='scale')
            if tf.__version__ &lt;= '0.12':
                standard_ops_fn = standard_ops.mul
            else:
                standard_ops_fn = standard_ops.multiply
            return standard_ops_fn(
                my_scale, standard_ops.reduce_sum(standard_ops.reduce_max(standard_ops.abs(weights), 1)), name=scope
            )

    return mn_i

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 65:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1282')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/models/vgg.py: 199-260
</a>
<div class="mid" id="frag1282" style="display:none"><pre>
def vgg16(pretrained=False, end_with='outputs', mode='dynamic', name=None):
    """Pre-trained VGG16 model.

    Parameters
    ------------
    pretrained : boolean
        Whether to load pretrained weights. Default False.
    end_with : str
        The end point of the model. Default ``fc3_relu`` i.e. the whole model.
    mode : str.
        Model building mode, 'dynamic' or 'static'. Default 'dynamic'.
    name : None or str
        A unique layer name.

    Examples
    ---------
    Classify ImageNet classes with VGG16, see `tutorial_models_vgg.py &lt;https://github.com/tensorlayer/tensorlayer/blob/master/example/tutorial_models_vgg.py&gt;`__
    With TensorLayer

    &gt;&gt;&gt; # get the whole model, without pre-trained VGG parameters
    &gt;&gt;&gt; vgg = tl.models.vgg16()
    &gt;&gt;&gt; # get the whole model, restore pre-trained VGG parameters
    &gt;&gt;&gt; vgg = tl.models.vgg16(pretrained=True)
    &gt;&gt;&gt; # use for inferencing
    &gt;&gt;&gt; output = vgg(img, is_train=False)
    &gt;&gt;&gt; probs = tf.nn.softmax(output)[0].numpy()

    Extract features with VGG16 and Train a classifier with 100 classes

    &gt;&gt;&gt; # get VGG without the last layer
    &gt;&gt;&gt; cnn = tl.models.vgg16(end_with='fc2_relu', mode='static').as_layer()
    &gt;&gt;&gt; # add one more layer and build a new model
    &gt;&gt;&gt; ni = Input([None, 224, 224, 3], name="inputs")
    &gt;&gt;&gt; nn = cnn(ni)
    &gt;&gt;&gt; nn = tl.layers.Dense(n_units=100, name='out')(nn)
    &gt;&gt;&gt; model = tl.models.Model(inputs=ni, outputs=nn)
    &gt;&gt;&gt; # train your own classifier (only update the last layer)
    &gt;&gt;&gt; train_params = model.get_layer('out').trainable_weights

    Reuse model

    &gt;&gt;&gt; # in dynamic model, we can directly use the same model
    &gt;&gt;&gt; # in static model
    &gt;&gt;&gt; vgg_layer = tl.models.vgg16().as_layer()
    &gt;&gt;&gt; ni_1 = tl.layers.Input([None, 224, 244, 3])
    &gt;&gt;&gt; ni_2 = tl.layers.Input([None, 224, 244, 3])
    &gt;&gt;&gt; a_1 = vgg_layer(ni_1)
    &gt;&gt;&gt; a_2 = vgg_layer(ni_2)
    &gt;&gt;&gt; M = Model(inputs=[ni_1, ni_2], outputs=[a_1, a_2])

    """
    if mode == 'dynamic':
        model = VGG(layer_type='vgg16', batch_norm=False, end_with=end_with, name=name)
    elif mode == 'static':
        model = VGG_static(layer_type='vgg16', batch_norm=False, end_with=end_with, name=name)
    else:
        raise Exception("No such mode %s" % mode)
    if pretrained:
        restore_model(model, layer_type='vgg16')
    return model


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1283')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/models/vgg.py: 261-322
</a>
<div class="mid" id="frag1283" style="display:none"><pre>
def vgg19(pretrained=False, end_with='outputs', mode='dynamic', name=None):
    """Pre-trained VGG19 model.

    Parameters
    ------------
    pretrained : boolean
        Whether to load pretrained weights. Default False.
    end_with : str
        The end point of the model. Default ``fc3_relu`` i.e. the whole model.
    mode : str.
        Model building mode, 'dynamic' or 'static'. Default 'dynamic'.
    name : None or str
        A unique layer name.

    Examples
    ---------
    Classify ImageNet classes with VGG19, see `tutorial_models_vgg.py &lt;https://github.com/tensorlayer/tensorlayer/blob/master/example/tutorial_models_vgg.py&gt;`__
    With TensorLayer

    &gt;&gt;&gt; # get the whole model, without pre-trained VGG parameters
    &gt;&gt;&gt; vgg = tl.models.vgg19()
    &gt;&gt;&gt; # get the whole model, restore pre-trained VGG parameters
    &gt;&gt;&gt; vgg = tl.models.vgg19(pretrained=True)
    &gt;&gt;&gt; # use for inferencing
    &gt;&gt;&gt; output = vgg(img, is_train=False)
    &gt;&gt;&gt; probs = tf.nn.softmax(output)[0].numpy()

    Extract features with VGG19 and Train a classifier with 100 classes

    &gt;&gt;&gt; # get VGG without the last layer
    &gt;&gt;&gt; cnn = tl.models.vgg19(end_with='fc2_relu', mode='static').as_layer()
    &gt;&gt;&gt; # add one more layer and build a new model
    &gt;&gt;&gt; ni = Input([None, 224, 224, 3], name="inputs")
    &gt;&gt;&gt; nn = cnn(ni)
    &gt;&gt;&gt; nn = tl.layers.Dense(n_units=100, name='out')(nn)
    &gt;&gt;&gt; model = tl.models.Model(inputs=ni, outputs=nn)
    &gt;&gt;&gt; # train your own classifier (only update the last layer)
    &gt;&gt;&gt; train_params = model.get_layer('out').trainable_weights

    Reuse model

    &gt;&gt;&gt; # in dynamic model, we can directly use the same model
    &gt;&gt;&gt; # in static model
    &gt;&gt;&gt; vgg_layer = tl.models.vgg19().as_layer()
    &gt;&gt;&gt; ni_1 = tl.layers.Input([None, 224, 244, 3])
    &gt;&gt;&gt; ni_2 = tl.layers.Input([None, 224, 244, 3])
    &gt;&gt;&gt; a_1 = vgg_layer(ni_1)
    &gt;&gt;&gt; a_2 = vgg_layer(ni_2)
    &gt;&gt;&gt; M = Model(inputs=[ni_1, ni_2], outputs=[a_1, a_2])

    """
    if mode == 'dynamic':
        model = VGG(layer_type='vgg19', batch_norm=False, end_with=end_with, name=name)
    elif mode == 'static':
        model = VGG_static(layer_type='vgg19', batch_norm=False, end_with=end_with, name=name)
    else:
        raise Exception("No such mode %s" % mode)
    if pretrained:
        restore_model(model, layer_type='vgg19')
    return model


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 66:</b> &nbsp; 2 fragments, nominal size 20 lines, similarity 80%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1336')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/optimizers/amsgrad.py: 79-106
</a>
<div class="mid" id="frag1336" style="display:none"><pre>
    def _apply_dense(self, grad, var):
        beta1_power = math_ops.cast(self._beta1_power, var.dtype.base_dtype)
        beta2_power = math_ops.cast(self._beta2_power, var.dtype.base_dtype)
        lr_t = math_ops.cast(self._lr_t, var.dtype.base_dtype)
        beta1_t = math_ops.cast(self._beta1_t, var.dtype.base_dtype)
        beta2_t = math_ops.cast(self._beta2_t, var.dtype.base_dtype)
        epsilon_t = math_ops.cast(self._epsilon_t, var.dtype.base_dtype)

        lr = (lr_t * math_ops.sqrt(1 - beta2_power) / (1 - beta1_power))

        # m_t = beta1 * m + (1 - beta1) * g_t
        m = self.get_slot(var, "m")
        m_scaled_g_values = grad * (1 - beta1_t)
        m_t = state_ops.assign(m, beta1_t * m + m_scaled_g_values, use_locking=self._use_locking)

        # v_t = beta2 * v + (1 - beta2) * (g_t * g_t)
        v = self.get_slot(var, "v")
        v_scaled_g_values = (grad * grad) * (1 - beta2_t)
        v_t = state_ops.assign(v, beta2_t * v + v_scaled_g_values, use_locking=self._use_locking)

        # amsgrad
        vhat = self.get_slot(var, "vhat")
        vhat_t = state_ops.assign(vhat, math_ops.maximum(v_t, vhat))
        v_sqrt = math_ops.sqrt(vhat_t)

        var_update = state_ops.assign_sub(var, lr * m_t / (v_sqrt + epsilon_t), use_locking=self._use_locking)
        return control_flow_ops.group(*[var_update, m_t, v_t, vhat_t])

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1337')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/optimizers/amsgrad.py: 107-135
</a>
<div class="mid" id="frag1337" style="display:none"><pre>
    def _resource_apply_dense(self, grad, var):
        var = var.handle
        beta1_power = math_ops.cast(self._beta1_power, grad.dtype.base_dtype)
        beta2_power = math_ops.cast(self._beta2_power, grad.dtype.base_dtype)
        lr_t = math_ops.cast(self._lr_t, grad.dtype.base_dtype)
        beta1_t = math_ops.cast(self._beta1_t, grad.dtype.base_dtype)
        beta2_t = math_ops.cast(self._beta2_t, grad.dtype.base_dtype)
        epsilon_t = math_ops.cast(self._epsilon_t, grad.dtype.base_dtype)

        lr = (lr_t * math_ops.sqrt(1 - beta2_power) / (1 - beta1_power))

        # m_t = beta1 * m + (1 - beta1) * g_t
        m = self.get_slot(var, "m").handle
        m_scaled_g_values = grad * (1 - beta1_t)
        m_t = state_ops.assign(m, beta1_t * m + m_scaled_g_values, use_locking=self._use_locking)

        # v_t = beta2 * v + (1 - beta2) * (g_t * g_t)
        v = self.get_slot(var, "v").handle
        v_scaled_g_values = (grad * grad) * (1 - beta2_t)
        v_t = state_ops.assign(v, beta2_t * v + v_scaled_g_values, use_locking=self._use_locking)

        # amsgrad
        vhat = self.get_slot(var, "vhat").handle
        vhat_t = state_ops.assign(vhat, math_ops.maximum(v_t, vhat))
        v_sqrt = math_ops.sqrt(vhat_t)

        var_update = state_ops.assign_sub(var, lr * m_t / (v_sqrt + epsilon_t), use_locking=self._use_locking)
        return control_flow_ops.group(*[var_update, m_t, v_t, vhat_t])

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 67:</b> &nbsp; 2 fragments, nominal size 32 lines, similarity 84%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1370')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/visualize.py: 403-463
</a>
<div class="mid" id="frag1370" style="display:none"><pre>
def CNN2d(CNN=None, second=10, saveable=True, name='cnn', fig_idx=3119362):
    """Display a group of RGB or Greyscale CNN masks.

    Parameters
    ----------
    CNN : numpy.array
        The image. e.g: 64 5x5 RGB images can be (5, 5, 3, 64).
    second : int
        The display second(s) for the image(s), if saveable is False.
    saveable : boolean
        Save or plot the figure.
    name : str
        A name to save the image, if saveable is True.
    fig_idx : int
        The matplotlib figure index.

    Examples
    --------
    &gt;&gt;&gt; tl.visualize.CNN2d(network.all_params[0].eval(), second=10, saveable=True, name='cnn1_mnist', fig_idx=2012)

    """
    import matplotlib.pyplot as plt
    # tl.logging.info(CNN.shape)    # (5, 5, 3, 64)
    # exit()
    n_mask = CNN.shape[3]
    n_row = CNN.shape[0]
    n_col = CNN.shape[1]
    n_color = CNN.shape[2]
    row = int(np.sqrt(n_mask))
    col = int(np.ceil(n_mask / row))
    plt.ion()  # active mode
    fig = plt.figure(fig_idx)
    count = 1
    for _ir in range(1, row + 1):
        for _ic in range(1, col + 1):
            if count &gt; n_mask:
                break
            fig.add_subplot(col, row, count)
            # tl.logging.info(CNN[:,:,:,count-1].shape, n_row, n_col)   # (5, 1, 32) 5 5
            # exit()
            # plt.imshow(
            #         np.reshape(CNN[count-1,:,:,:], (n_row, n_col)),
            #         cmap='gray', interpolation="nearest")     # theano
            if n_color == 1:
                plt.imshow(np.reshape(CNN[:, :, :, count - 1], (n_row, n_col)), cmap='gray', interpolation="nearest")
            elif n_color == 3:
                plt.imshow(
                    np.reshape(CNN[:, :, :, count - 1], (n_row, n_col, n_color)), cmap='gray', interpolation="nearest"
                )
            else:
                raise Exception("Unknown n_color")
            plt.gca().xaxis.set_major_locator(plt.NullLocator())  # distable tick
            plt.gca().yaxis.set_major_locator(plt.NullLocator())
            count = count + 1
    if saveable:
        plt.savefig(name + '.pdf', format='pdf')
    else:
        plt.draw()
        plt.pause(second)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1371')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/visualize.py: 464-528
</a>
<div class="mid" id="frag1371" style="display:none"><pre>
def images2d(images=None, second=10, saveable=True, name='images', dtype=None, fig_idx=3119362):
    """Display a group of RGB or Greyscale images.

    Parameters
    ----------
    images : numpy.array
        The images.
    second : int
        The display second(s) for the image(s), if saveable is False.
    saveable : boolean
        Save or plot the figure.
    name : str
        A name to save the image, if saveable is True.
    dtype : None or numpy data type
        The data type for displaying the images.
    fig_idx : int
        matplotlib figure index.

    Examples
    --------
    &gt;&gt;&gt; X_train, y_train, X_test, y_test = tl.files.load_cifar10_dataset(shape=(-1, 32, 32, 3), plotable=False)
    &gt;&gt;&gt; tl.visualize.images2d(X_train[0:100,:,:,:], second=10, saveable=False, name='cifar10', dtype=np.uint8, fig_idx=20212)

    """
    import matplotlib.pyplot as plt
    # tl.logging.info(images.shape)    # (50000, 32, 32, 3)
    # exit()
    if dtype:
        images = np.asarray(images, dtype=dtype)
    n_mask = images.shape[0]
    n_row = images.shape[1]
    n_col = images.shape[2]
    n_color = images.shape[3]
    row = int(np.sqrt(n_mask))
    col = int(np.ceil(n_mask / row))
    plt.ion()  # active mode
    fig = plt.figure(fig_idx)
    count = 1
    for _ir in range(1, row + 1):
        for _ic in range(1, col + 1):
            if count &gt; n_mask:
                break
            fig.add_subplot(col, row, count)
            # tl.logging.info(images[:,:,:,count-1].shape, n_row, n_col)   # (5, 1, 32) 5 5
            # plt.imshow(
            #         np.reshape(images[count-1,:,:,:], (n_row, n_col)),
            #         cmap='gray', interpolation="nearest")     # theano
            if n_color == 1:
                plt.imshow(np.reshape(images[count - 1, :, :], (n_row, n_col)), cmap='gray', interpolation="nearest")
                # plt.title(name)
            elif n_color == 3:
                plt.imshow(images[count - 1, :, :], cmap='gray', interpolation="nearest")
                # plt.title(name)
            else:
                raise Exception("Unknown n_color")
            plt.gca().xaxis.set_major_locator(plt.NullLocator())  # distable tick
            plt.gca().yaxis.set_major_locator(plt.NullLocator())
            count = count + 1
    if saveable:
        plt.savefig(name + '.pdf', format='pdf')
    else:
        plt.draw()
        plt.pause(second)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 68:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 77%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1412')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/db.py: 111-170
</a>
<div class="mid" id="frag1412" style="display:none"><pre>
    def save_model(self, network=None, model_name='model', **kwargs):
        """Save model architecture and parameters into database, timestamp will be added automatically.

        Parameters
        ----------
        network : TensorLayer Model
            TensorLayer Model instance.
        model_name : str
            The name/key of model.
        kwargs : other events
            Other events, such as name, accuracy, loss, step number and etc (optinal).

        Examples
        ---------
        Save model architecture and parameters into database.
        &gt;&gt;&gt; db.save_model(net, accuracy=0.8, loss=2.3, name='second_model')

        Load one model with parameters from database (run this in other script)
        &gt;&gt;&gt; net = db.find_top_model(accuracy=0.8, loss=2.3)

        Find and load the latest model.
        &gt;&gt;&gt; net = db.find_top_model(sort=[("time", pymongo.DESCENDING)])
        &gt;&gt;&gt; net = db.find_top_model(sort=[("time", -1)])

        Find and load the oldest model.
        &gt;&gt;&gt; net = db.find_top_model(sort=[("time", pymongo.ASCENDING)])
        &gt;&gt;&gt; net = db.find_top_model(sort=[("time", 1)])

        Get model information
        &gt;&gt;&gt; net._accuracy
        ... 0.8

        Returns
        ---------
        boolean : True for success, False for fail.
        """
        kwargs.update({'model_name': model_name})
        self._fill_project_info(kwargs)  # put project_name into kwargs

        # params = network.get_all_params()
        params = network.all_weights

        s = time.time()

        # kwargs.update({'architecture': network.all_graphs, 'time': datetime.utcnow()})
        kwargs.update({'architecture': network.config, 'time': datetime.utcnow()})

        try:
            params_id = self.model_fs.put(self._serialization(params))
            kwargs.update({'params_id': params_id, 'time': datetime.utcnow()})
            self.db.Model.insert_one(kwargs)
            print("[Database] Save model: SUCCESS, took: {}s".format(round(time.time() - s, 2)))
            return True
        except Exception as e:
            exc_type, exc_obj, exc_tb = sys.exc_info()
            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]
            logging.info("{}  {}  {}  {}  {}".format(exc_type, exc_obj, fname, exc_tb.tb_lineno, e))
            print("[Database] Save model: FAIL")
            return False

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1415')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/db.py: 258-301
</a>
<div class="mid" id="frag1415" style="display:none"><pre>
    def save_dataset(self, dataset=None, dataset_name=None, **kwargs):
        """Saves one dataset into database, timestamp will be added automatically.

        Parameters
        ----------
        dataset : any type
            The dataset you want to store.
        dataset_name : str
            The name of dataset.
        kwargs : other events
            Other events, such as description, author and etc (optinal).

        Examples
        ----------
        Save dataset
        &gt;&gt;&gt; db.save_dataset([X_train, y_train, X_test, y_test], 'mnist', description='this is a tutorial')

        Get dataset
        &gt;&gt;&gt; dataset = db.find_top_dataset('mnist')

        Returns
        ---------
        boolean : Return True if save success, otherwise, return False.
        """
        self._fill_project_info(kwargs)
        if dataset_name is None:
            raise Exception("dataset_name is None, please give a dataset name")
        kwargs.update({'dataset_name': dataset_name})

        s = time.time()
        try:
            dataset_id = self.dataset_fs.put(self._serialization(dataset))
            kwargs.update({'dataset_id': dataset_id, 'time': datetime.utcnow()})
            self.db.Dataset.insert_one(kwargs)
            # print("[Database] Save params: {} SUCCESS, took: {}s".format(file_name, round(time.time()-s, 2)))
            print("[Database] Save dataset: SUCCESS, took: {}s".format(round(time.time() - s, 2)))
            return True
        except Exception as e:
            exc_type, exc_obj, exc_tb = sys.exc_info()
            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]
            logging.info("{}  {}  {}  {}  {}".format(exc_type, exc_obj, fname, exc_tb.tb_lineno, e))
            print("[Database] Save dataset: FAIL")
            return False

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 69:</b> &nbsp; 2 fragments, nominal size 28 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1413')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/db.py: 171-244
</a>
<div class="mid" id="frag1413" style="display:none"><pre>
    def find_top_model(self, sort=None, model_name='model', **kwargs):
        """Finds and returns a model architecture and its parameters from the database which matches the requirement.

        Parameters
        ----------
        sort : List of tuple
            PyMongo sort comment, search "PyMongo find one sorting" and `collection level operations &lt;http://api.mongodb.com/python/current/api/pymongo/collection.html&gt;`__ for more details.
        model_name : str or None
            The name/key of model.
        kwargs : other events
            Other events, such as name, accuracy, loss, step number and etc (optinal).

        Examples
        ---------
        - see ``save_model``.

        Returns
        ---------
        network : TensorLayer Model
            Note that, the returned network contains all information of the document (record), e.g. if you saved accuracy in the document, you can get the accuracy by using ``net._accuracy``.
        """
        # print(kwargs)   # {}
        kwargs.update({'model_name': model_name})
        self._fill_project_info(kwargs)

        s = time.time()

        d = self.db.Model.find_one(filter=kwargs, sort=sort)

        # _temp_file_name = '_find_one_model_ztemp_file'
        if d is not None:
            params_id = d['params_id']
            graphs = d['architecture']
            _datetime = d['time']
            # exists_or_mkdir(_temp_file_name, False)
            # with open(os.path.join(_temp_file_name, 'graph.pkl'), 'wb') as file:
            #     pickle.dump(graphs, file, protocol=pickle.HIGHEST_PROTOCOL)
        else:
            print("[Database] FAIL! Cannot find model: {}".format(kwargs))
            return False
        try:
            params = self._deserialization(self.model_fs.get(params_id).read())
            # TODO : restore model and load weights
            network = static_graph2net(graphs)
            assign_weights(weights=params, network=network)
            # np.savez(os.path.join(_temp_file_name, 'params.npz'), params=params)
            #
            # network = load_graph_and_params(name=_temp_file_name, sess=sess)
            # del_folder(_temp_file_name)

            pc = self.db.Model.find(kwargs)
            print(
                "[Database] Find one model SUCCESS. kwargs:{} sort:{} save time:{} took: {}s".format(
                    kwargs, sort, _datetime, round(time.time() - s, 2)
                )
            )

            # FIXME : not sure what's this for
            # put all informations of model into the TL layer
            # for key in d:
            #     network.__dict__.update({"_%s" % key: d[key]})

            # check whether more parameters match the requirement
            params_id_list = pc.distinct('params_id')
            n_params = len(params_id_list)
            if n_params != 1:
                print("     Note that there are {} models match the kwargs".format(n_params))
            return network
        except Exception as e:
            exc_type, exc_obj, exc_tb = sys.exc_info()
            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]
            logging.info("{}  {}  {}  {}  {}".format(exc_type, exc_obj, fname, exc_tb.tb_lineno, e))
            return False

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1416')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/db.py: 302-360
</a>
<div class="mid" id="frag1416" style="display:none"><pre>
    def find_top_dataset(self, dataset_name=None, sort=None, **kwargs):
        """Finds and returns a dataset from the database which matches the requirement.

        Parameters
        ----------
        dataset_name : str
            The name of dataset.
        sort : List of tuple
            PyMongo sort comment, search "PyMongo find one sorting" and `collection level operations &lt;http://api.mongodb.com/python/current/api/pymongo/collection.html&gt;`__ for more details.
        kwargs : other events
            Other events, such as description, author and etc (optinal).

        Examples
        ---------
        Save dataset
        &gt;&gt;&gt; db.save_dataset([X_train, y_train, X_test, y_test], 'mnist', description='this is a tutorial')

        Get dataset
        &gt;&gt;&gt; dataset = db.find_top_dataset('mnist')
        &gt;&gt;&gt; datasets = db.find_datasets('mnist')

        Returns
        --------
        dataset : the dataset or False
            Return False if nothing found.

        """

        self._fill_project_info(kwargs)
        if dataset_name is None:
            raise Exception("dataset_name is None, please give a dataset name")
        kwargs.update({'dataset_name': dataset_name})

        s = time.time()

        d = self.db.Dataset.find_one(filter=kwargs, sort=sort)

        if d is not None:
            dataset_id = d['dataset_id']
        else:
            print("[Database] FAIL! Cannot find dataset: {}".format(kwargs))
            return False
        try:
            dataset = self._deserialization(self.dataset_fs.get(dataset_id).read())
            pc = self.db.Dataset.find(kwargs)
            print("[Database] Find one dataset SUCCESS, {} took: {}s".format(kwargs, round(time.time() - s, 2)))

            # check whether more datasets match the requirement
            dataset_id_list = pc.distinct('dataset_id')
            n_dataset = len(dataset_id_list)
            if n_dataset != 1:
                print("     Note that there are {} datasets match the requirement".format(n_dataset))
            return dataset
        except Exception as e:
            exc_type, exc_obj, exc_tb = sys.exc_info()
            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]
            logging.info("{}  {}  {}  {}  {}".format(exc_type, exc_obj, fname, exc_tb.tb_lineno, e))
            return False

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 70:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 71%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1445')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/prepro.py: 728-766
</a>
<div class="mid" id="frag1445" style="display:none"><pre>
    Examples
    ---------
    &gt;&gt;&gt; x --&gt; [row, col, 1]
    &gt;&gt;&gt; x = tl.prepro.rotation(x, rg=40, is_random=False)
    &gt;&gt;&gt; tl.vis.save_image(x, 'im.png')

    """
    if is_random:
        theta = np.pi / 180 * np.random.uniform(-rg, rg)
    else:
        theta = np.pi / 180 * rg
    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0], [np.sin(theta), np.cos(theta), 0], [0, 0, 1]])

    h, w = x.shape[row_index], x.shape[col_index]
    transform_matrix = transform_matrix_offset_center(rotation_matrix, h, w)
    x = affine_transform(x, transform_matrix, channel_index, fill_mode, cval, order)
    return x


def rotation_multi(
    x, rg=20, is_random=False, row_index=0, col_index=1, channel_index=2, fill_mode='nearest', cval=0., order=1
):
    """Rotate multiple images with the same arguments, randomly or non-randomly.
    Usually be used for image segmentation which x=[X, Y], X and Y should be matched.

    Parameters
    -----------
    x : list of numpy.array
        List of images with dimension of [n_images, row, col, channel] (default).
    others : args
        See ``tl.prepro.rotation``.

    Returns
    -------
    numpy.array
        A list of processed images.

    Examples
    --------
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1453')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/prepro.py: 1063-1095
</a>
<div class="mid" id="frag1453" style="display:none"><pre>
        A processed image.

    References
    -----------
    - `Affine transformation &lt;https://uk.mathworks.com/discovery/affine-transformation.html&gt;`__

    """
    if is_random:
        shear = np.random.uniform(-intensity, intensity)
    else:
        shear = intensity
    shear_matrix = np.array([[1, -np.sin(shear), 0], [0, np.cos(shear), 0], [0, 0, 1]])

    h, w = x.shape[row_index], x.shape[col_index]
    transform_matrix = transform_matrix_offset_center(shear_matrix, h, w)
    x = affine_transform(x, transform_matrix, channel_index, fill_mode, cval, order)
    return x


def shear_multi(
    x, intensity=0.1, is_random=False, row_index=0, col_index=1, channel_index=2, fill_mode='nearest', cval=0., order=1
):
    """Shear images with the same arguments, randomly or non-randomly.
    Usually be used for image segmentation which x=[X, Y], X and Y should be matched.

    Parameters
    -----------
    x : list of numpy.array
        List of images with dimension of [n_images, row, col, channel] (default).
    others : args
        See ``tl.prepro.shear``.

    Returns
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 71:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 73%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1454')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/prepro.py: 1096-1146
</a>
<div class="mid" id="frag1454" style="display:none"><pre>
    -------
    numpy.array
        A list of processed images.

    """
    if is_random:
        shear = np.random.uniform(-intensity, intensity)
    else:
        shear = intensity
    shear_matrix = np.array([[1, -np.sin(shear), 0], [0, np.cos(shear), 0], [0, 0, 1]])

    h, w = x[0].shape[row_index], x[0].shape[col_index]
    transform_matrix = transform_matrix_offset_center(shear_matrix, h, w)
    results = []
    for data in x:
        results.append(affine_transform(data, transform_matrix, channel_index, fill_mode, cval, order))
    return np.asarray(results)


def shear2(
    x, shear=(0.1, 0.1), is_random=False, row_index=0, col_index=1, channel_index=2, fill_mode='nearest', cval=0.,
    order=1
):
    """Shear an image randomly or non-randomly.

    Parameters
    -----------
    x : numpy.array
        An image with dimension of [row, col, channel] (default).
    shear : tuple of two floats
        Percentage of shear for height and width direction (0, 1).
    is_random : boolean
        If True, randomly shear. Default is False.
    row_index col_index and channel_index : int
        Index of row, col and channel, default (0, 1, 2), for theano (1, 2, 0).
    fill_mode : str
        Method to fill missing pixel, default `nearest`, more options `constant`, `reflect` or `wrap`, see `scipy ndimage affine_transform &lt;https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.affine_transform.html&gt;`__
    cval : float
        Value used for points outside the boundaries of the input if mode='constant'. Default is 0.0.
    order : int
        The order of interpolation. The order has to be in the range 0-5. See ``tl.prepro.affine_transform`` and `scipy ndimage affine_transform &lt;https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.affine_transform.html&gt;`__

    Returns
    -------
    numpy.array
        A processed image.

    References
    -----------
    - `Affine transformation &lt;https://uk.mathworks.com/discovery/affine-transformation.html&gt;`__

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1455')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/prepro.py: 1147-1187
</a>
<div class="mid" id="frag1455" style="display:none"><pre>
    """
    if len(shear) != 2:
        raise AssertionError(
            "shear should be tuple of 2 floats, or you want to use tl.prepro.shear rather than tl.prepro.shear2 ?"
        )
    if isinstance(shear, tuple):
        shear = list(shear)
    if is_random:
        shear[0] = np.random.uniform(-shear[0], shear[0])
        shear[1] = np.random.uniform(-shear[1], shear[1])

    shear_matrix = np.array([[1, shear[0], 0], \
                            [shear[1], 1, 0], \
                            [0, 0, 1]])

    h, w = x.shape[row_index], x.shape[col_index]
    transform_matrix = transform_matrix_offset_center(shear_matrix, h, w)
    x = affine_transform(x, transform_matrix, channel_index, fill_mode, cval, order)
    return x


def shear_multi2(
    x, shear=(0.1, 0.1), is_random=False, row_index=0, col_index=1, channel_index=2, fill_mode='nearest', cval=0.,
    order=1
):
    """Shear images with the same arguments, randomly or non-randomly.
    Usually be used for image segmentation which x=[X, Y], X and Y should be matched.

    Parameters
    -----------
    x : list of numpy.array
        List of images with dimension of [n_images, row, col, channel] (default).
    others : args
        See ``tl.prepro.shear2``.

    Returns
    -------
    numpy.array
        A list of processed images.

    """
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 72:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 71%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1475')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/prepro.py: 2029-2067
</a>
<div class="mid" id="frag1475" style="display:none"><pre>
    # flatx = np.reshape(x, (x.shape))
    # flatx = np.reshape(x, (x.shape[0], ))
    # tl.logging.info(flatx.shape)  # (160, 176, 1)
    whitex = np.dot(flatx, principal_components)
    x = np.reshape(whitex, (x.shape[0], x.shape[1], x.shape[2]))
    return x


# developing
# def barrel_transform(x, intensity):
#     # https://github.com/fchollet/keras/blob/master/keras/preprocessing/image.py
#     # TODO
#     pass
#
# def barrel_transform_multi(x, intensity):
#     # https://github.com/fchollet/keras/blob/master/keras/preprocessing/image.py
#     # TODO
#     pass


# channel shift
def channel_shift(x, intensity, is_random=False, channel_index=2):
    """Shift the channels of an image, randomly or non-randomly, see `numpy.rollaxis &lt;https://docs.scipy.org/doc/numpy/reference/generated/numpy.rollaxis.html&gt;`__.

    Parameters
    -----------
    x : numpy.array
        An image with dimension of [row, col, channel] (default).
    intensity : float
        Intensity of shifting.
    is_random : boolean
        If True, randomly shift. Default is False.
    channel_index : int
        Index of channel. Default is 2.

    Returns
    -------
    numpy.array
        A processed image.
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1476')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/prepro.py: 2068-2101
</a>
<div class="mid" id="frag1476" style="display:none"><pre>

    """
    if is_random:
        factor = np.random.uniform(-intensity, intensity)
    else:
        factor = intensity
    x = np.rollaxis(x, channel_index, 0)
    min_x, max_x = np.min(x), np.max(x)
    channel_images = [np.clip(x_channel + factor, min_x, max_x) for x_channel in x]
    x = np.stack(channel_images, axis=0)
    x = np.rollaxis(x, 0, channel_index + 1)
    return x
    # x = np.rollaxis(x, channel_index, 0)
    # min_x, max_x = np.min(x), np.max(x)
    # channel_images = [np.clip(x_channel + np.random.uniform(-intensity, intensity), min_x, max_x)
    #                   for x_channel in x]
    # x = np.stack(channel_images, axis=0)
    # x = np.rollaxis(x, 0, channel_index+1)
    # return x


def channel_shift_multi(x, intensity, is_random=False, channel_index=2):
    """Shift the channels of images with the same arguments, randomly or non-randomly, see `numpy.rollaxis &lt;https://docs.scipy.org/doc/numpy/reference/generated/numpy.rollaxis.html&gt;`__.
    Usually be used for image segmentation which x=[X, Y], X and Y should be matched.

    Parameters
    -----------
    x : list of numpy.array
        List of images with dimension of [n_images, row, col, channel] (default).
    others : args
        See ``tl.prepro.channel_shift``.

    Returns
    -------
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 73:</b> &nbsp; 3 fragments, nominal size 75 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1497')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/prepro.py: 2828-2980
</a>
<div class="mid" id="frag1497" style="display:none"><pre>
        return im, coords_new
    else:
        return im, coords


# im = np.zeros([80, 100, 3])    # as an image with shape width=100, height=80
# _, coords = obj_box_imresize(im, coords=[[20, 40, 30, 30], [10, 20, 20, 20]], size=[160, 200], is_rescale=False)
# tl.logging.info(coords)
# #   [[40, 80, 60, 60], [20, 40, 40, 40]]
# _, coords = obj_box_imresize(im, coords=[[20, 40, 30, 30]], size=[40, 100], is_rescale=False)
# tl.logging.info(coords)
# #   [20, 20, 30, 15]
# _, coords = obj_box_imresize(im, coords=[[20, 40, 30, 30]], size=[60, 150], is_rescale=False)
# tl.logging.info(coords)
# #   [30, 30, 45, 22]
# im2, coords = obj_box_imresize(im, coords=[[0.2, 0.4, 0.3, 0.3]], size=[160, 200], is_rescale=True)
# tl.logging.info(coords, im2.shape)
# # [0.2, 0.4, 0.3, 0.3] (160, 200, 3)
# exit()


def obj_box_crop(
    im, classes=None, coords=None, wrg=100, hrg=100, is_rescale=False, is_center=False, is_random=False, thresh_wh=0.02,
    thresh_wh2=12.
):
    """Randomly or centrally crop an image, and compute the new bounding box coordinates.
    Objects outside the cropped image will be removed.

    Parameters
    -----------
    im : numpy.array
        An image with dimension of [row, col, channel] (default).
    classes : list of int or None
        Class IDs.
    coords : list of list of 4 int/float or None
        Coordinates [[x, y, w, h], [x, y, w, h], ...]
    wrg hrg and is_random : args
        See ``tl.prepro.crop``.
    is_rescale : boolean
        Set to True, if the input coordinates are rescaled to [0, 1]. Default is False.
    is_center : boolean, default False
        Set to True, if the x and y of coordinates are the centroid (i.e. darknet format). Default is False.
    thresh_wh : float
        Threshold, remove the box if its ratio of width(height) to image size less than the threshold.
    thresh_wh2 : float
        Threshold, remove the box if its ratio of width to height or vice verse higher than the threshold.

    Returns
    -------
    numpy.array
        A processed image
    list of int
        A list of classes
    list of list of 4 numbers
        A list of new bounding boxes.

    """
    if classes is None:
        classes = []
    if coords is None:
        coords = []

    h, w = im.shape[0], im.shape[1]

    if (h &lt;= hrg) or (w &lt;= wrg):
        raise AssertionError("The size of cropping should smaller than the original image")

    if is_random:
        h_offset = int(np.random.uniform(0, h - hrg) - 1)
        w_offset = int(np.random.uniform(0, w - wrg) - 1)
        h_end = hrg + h_offset
        w_end = wrg + w_offset
        im_new = im[h_offset:h_end, w_offset:w_end]
    else:  # central crop
        h_offset = int(np.floor((h - hrg) / 2.))
        w_offset = int(np.floor((w - wrg) / 2.))
        h_end = h_offset + hrg
        w_end = w_offset + wrg
        im_new = im[h_offset:h_end, w_offset:w_end]

    #              w
    #   _____________________________
    #   |  h/w offset               |
    #   |       -------             |
    # h |       |     |             |
    #   |       |     |             |
    #   |       -------             |
    #   |            h/w end        |
    #   |___________________________|

    def _get_coord(coord):
        """Input pixel-unit [x, y, w, h] format, then make sure [x, y] it is the up-left coordinates,
        before getting the new coordinates.
        Boxes outsides the cropped image will be removed.

        """
        if is_center:
            coord = obj_box_coord_centroid_to_upleft(coord)

        ##======= pixel unit format and upleft, w, h ==========##

        # x = np.clip( coord[0] - w_offset, 0, w_end - w_offset)
        # y = np.clip( coord[1] - h_offset, 0, h_end - h_offset)
        # w = np.clip( coord[2]           , 0, w_end - w_offset)
        # h = np.clip( coord[3]           , 0, h_end - h_offset)

        x = coord[0] - w_offset
        y = coord[1] - h_offset
        w = coord[2]
        h = coord[3]

        if x &lt; 0:
            if x + w &lt;= 0:
                return None
            w = w + x
            x = 0
        elif x &gt; im_new.shape[1]:  # object outside the cropped image
            return None

        if y &lt; 0:
            if y + h &lt;= 0:
                return None
            h = h + y
            y = 0
        elif y &gt; im_new.shape[0]:  # object outside the cropped image
            return None

        if (x is not None) and (x + w &gt; im_new.shape[1]):  # box outside the cropped image
            w = im_new.shape[1] - x

        if (y is not None) and (y + h &gt; im_new.shape[0]):  # box outside the cropped image
            h = im_new.shape[0] - y

        if (w / (h + 1.) &gt; thresh_wh2) or (h / (w + 1.) &gt; thresh_wh2):  # object shape strange: too narrow
            # tl.logging.info('xx', w, h)
            return None

        if (w / (im_new.shape[1] * 1.) &lt; thresh_wh) or (h / (im_new.shape[0] * 1.) &lt;
                                                        thresh_wh):  # object shape strange: too narrow
            # tl.logging.info('yy', w, im_new.shape[1], h, im_new.shape[0])
            return None

        coord = [x, y, w, h]

        ## convert back if input format is center.
        if is_center:
            coord = obj_box_coord_upleft_to_centroid(coord)

        return coord

    coords_new = list()
    classes_new = list()
    for i, _ in enumerate(coords):
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1501')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/prepro.py: 3116-3252
</a>
<div class="mid" id="frag1501" style="display:none"><pre>
        coord = coords[i]

        if len(coord) != 4:
            raise AssertionError("coordinate should be 4 values : [x, y, w, h]")

        if is_rescale:
            # for scaled coord, upscaled before process and scale back in the end.
            coord = obj_box_coord_scale_to_pixelunit(coord, im.shape)
            coord = _get_coord(coord)
            if coord is not None:
                coord = obj_box_coord_rescale(coord, im_new.shape)
                coords_new.append(coord)
                classes_new.append(classes[i])
        else:
            coord = _get_coord(coord)
            if coord is not None:
                coords_new.append(coord)
                classes_new.append(classes[i])
    return im_new, classes_new, coords_new


def obj_box_zoom(
    im, classes=None, coords=None, zoom_range=(0.9, 1.1), row_index=0, col_index=1, channel_index=2,
    fill_mode='nearest', cval=0., order=1, is_rescale=False, is_center=False, is_random=False, thresh_wh=0.02,
    thresh_wh2=12.
):
    """Zoom in and out of a single image, randomly or non-randomly, and compute the new bounding box coordinates.
    Objects outside the cropped image will be removed.

    Parameters
    -----------
    im : numpy.array
        An image with dimension of [row, col, channel] (default).
    classes : list of int or None
        Class IDs.
    coords : list of list of 4 int/float or None
        Coordinates [[x, y, w, h], [x, y, w, h], ...].
    zoom_range row_index col_index channel_index is_random fill_mode cval and order : see ``tl.prepro.zoom``.
    is_rescale : boolean
        Set to True, if the input coordinates are rescaled to [0, 1]. Default is False.
    is_center : boolean
        Set to True, if the x and y of coordinates are the centroid. (i.e. darknet format). Default is False.
    thresh_wh : float
        Threshold, remove the box if its ratio of width(height) to image size less than the threshold.
    thresh_wh2 : float
        Threshold, remove the box if its ratio of width to height or vice verse higher than the threshold.

    Returns
    -------
    numpy.array
        A processed image
    list of int
        A list of classes
    list of list of 4 numbers
        A list of new bounding boxes.

    """
    if classes is None:
        classes = []
    if coords is None:
        coords = []

    if len(zoom_range) != 2:
        raise Exception('zoom_range should be a tuple or list of two floats. ' 'Received arg: ', zoom_range)
    if is_random:
        if zoom_range[0] == 1 and zoom_range[1] == 1:
            zx, zy = 1, 1
            tl.logging.info(" random_zoom : not zoom in/out")
        else:
            zx, zy = np.random.uniform(zoom_range[0], zoom_range[1], 2)
    else:
        zx, zy = zoom_range
    # tl.logging.info(zx, zy)
    zoom_matrix = np.array([[zx, 0, 0], [0, zy, 0], [0, 0, 1]])

    h, w = im.shape[row_index], im.shape[col_index]
    transform_matrix = transform_matrix_offset_center(zoom_matrix, h, w)
    im_new = affine_transform(im, transform_matrix, channel_index, fill_mode, cval, order)

    # modified from obj_box_crop
    def _get_coord(coord):
        """Input pixel-unit [x, y, w, h] format, then make sure [x, y] it is the up-left coordinates,
        before getting the new coordinates.
        Boxes outsides the cropped image will be removed.

        """
        if is_center:
            coord = obj_box_coord_centroid_to_upleft(coord)

        # ======= pixel unit format and upleft, w, h ==========
        x = (coord[0] - im.shape[1] / 2) / zy + im.shape[1] / 2  # only change this
        y = (coord[1] - im.shape[0] / 2) / zx + im.shape[0] / 2  # only change this
        w = coord[2] / zy  # only change this
        h = coord[3] / zx  # only change thisS

        if x &lt; 0:
            if x + w &lt;= 0:
                return None
            w = w + x
            x = 0
        elif x &gt; im_new.shape[1]:  # object outside the cropped image
            return None

        if y &lt; 0:
            if y + h &lt;= 0:
                return None
            h = h + y
            y = 0
        elif y &gt; im_new.shape[0]:  # object outside the cropped image
            return None

        if (x is not None) and (x + w &gt; im_new.shape[1]):  # box outside the cropped image
            w = im_new.shape[1] - x

        if (y is not None) and (y + h &gt; im_new.shape[0]):  # box outside the cropped image
            h = im_new.shape[0] - y

        if (w / (h + 1.) &gt; thresh_wh2) or (h / (w + 1.) &gt; thresh_wh2):  # object shape strange: too narrow
            # tl.logging.info('xx', w, h)
            return None

        if (w / (im_new.shape[1] * 1.) &lt; thresh_wh) or (h / (im_new.shape[0] * 1.) &lt;
                                                        thresh_wh):  # object shape strange: too narrow
            # tl.logging.info('yy', w, im_new.shape[1], h, im_new.shape[0])
            return None

        coord = [x, y, w, h]

        # convert back if input format is center.
        if is_center:
            coord = obj_box_coord_upleft_to_centroid(coord)

        return coord

    coords_new = list()
    classes_new = list()
    for i, _ in enumerate(coords):
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1499')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/prepro.py: 2981-3115
</a>
<div class="mid" id="frag1499" style="display:none"><pre>
        coord = coords[i]

        if len(coord) != 4:
            raise AssertionError("coordinate should be 4 values : [x, y, w, h]")

        if is_rescale:
            # for scaled coord, upscaled before process and scale back in the end.
            coord = obj_box_coord_scale_to_pixelunit(coord, im.shape)
            coord = _get_coord(coord)
            if coord is not None:
                coord = obj_box_coord_rescale(coord, im_new.shape)
                coords_new.append(coord)
                classes_new.append(classes[i])
        else:
            coord = _get_coord(coord)
            if coord is not None:
                coords_new.append(coord)
                classes_new.append(classes[i])
    return im_new, classes_new, coords_new


def obj_box_shift(
    im, classes=None, coords=None, wrg=0.1, hrg=0.1, row_index=0, col_index=1, channel_index=2, fill_mode='nearest',
    cval=0., order=1, is_rescale=False, is_center=False, is_random=False, thresh_wh=0.02, thresh_wh2=12.
):
    """Shift an image randomly or non-randomly, and compute the new bounding box coordinates.
    Objects outside the cropped image will be removed.

    Parameters
    -----------
    im : numpy.array
        An image with dimension of [row, col, channel] (default).
    classes : list of int or None
        Class IDs.
    coords : list of list of 4 int/float or None
        Coordinates [[x, y, w, h], [x, y, w, h], ...]
    wrg, hrg row_index col_index channel_index is_random fill_mode cval and order : see ``tl.prepro.shift``.
    is_rescale : boolean
        Set to True, if the input coordinates are rescaled to [0, 1]. Default is False.
    is_center : boolean
        Set to True, if the x and y of coordinates are the centroid (i.e. darknet format). Default is False.
    thresh_wh : float
        Threshold, remove the box if its ratio of width(height) to image size less than the threshold.
    thresh_wh2 : float
        Threshold, remove the box if its ratio of width to height or vice verse higher than the threshold.


    Returns
    -------
    numpy.array
        A processed image
    list of int
        A list of classes
    list of list of 4 numbers
        A list of new bounding boxes.

    """
    if classes is None:
        classes = []
    if coords is None:
        coords = []

    imh, imw = im.shape[row_index], im.shape[col_index]

    if (hrg &gt;= 1.0) and (hrg &lt;= 0.) and (wrg &gt;= 1.0) and (wrg &lt;= 0.):
        raise AssertionError("shift range should be (0, 1)")

    if is_random:
        tx = np.random.uniform(-hrg, hrg) * imh
        ty = np.random.uniform(-wrg, wrg) * imw
    else:
        tx, ty = hrg * imh, wrg * imw
    translation_matrix = np.array([[1, 0, tx], [0, 1, ty], [0, 0, 1]])

    transform_matrix = translation_matrix  # no need to do offset
    im_new = affine_transform(im, transform_matrix, channel_index, fill_mode, cval, order)

    # modified from obj_box_crop
    def _get_coord(coord):
        """Input pixel-unit [x, y, w, h] format, then make sure [x, y] it is the up-left coordinates,
        before getting the new coordinates.
        Boxes outsides the cropped image will be removed.

        """
        if is_center:
            coord = obj_box_coord_centroid_to_upleft(coord)

        ##======= pixel unit format and upleft, w, h ==========##
        x = coord[0] - ty  # only change this
        y = coord[1] - tx  # only change this
        w = coord[2]
        h = coord[3]

        if x &lt; 0:
            if x + w &lt;= 0:
                return None
            w = w + x
            x = 0
        elif x &gt; im_new.shape[1]:  # object outside the cropped image
            return None

        if y &lt; 0:
            if y + h &lt;= 0:
                return None
            h = h + y
            y = 0
        elif y &gt; im_new.shape[0]:  # object outside the cropped image
            return None

        if (x is not None) and (x + w &gt; im_new.shape[1]):  # box outside the cropped image
            w = im_new.shape[1] - x

        if (y is not None) and (y + h &gt; im_new.shape[0]):  # box outside the cropped image
            h = im_new.shape[0] - y

        if (w / (h + 1.) &gt; thresh_wh2) or (h / (w + 1.) &gt; thresh_wh2):  # object shape strange: too narrow
            # tl.logging.info('xx', w, h)
            return None

        if (w / (im_new.shape[1] * 1.) &lt; thresh_wh) or (h / (im_new.shape[0] * 1.) &lt;
                                                        thresh_wh):  # object shape strange: too narrow
            # tl.logging.info('yy', w, im_new.shape[1], h, im_new.shape[0])
            return None

        coord = [x, y, w, h]

        ## convert back if input format is center.
        if is_center:
            coord = obj_box_coord_upleft_to_centroid(coord)

        return coord

    coords_new = list()
    classes_new = list()
    for i, _ in enumerate(coords):
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 74:</b> &nbsp; 2 fragments, nominal size 16 lines, similarity 88%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1535')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/embedding.py: 354-371
</a>
<div class="mid" id="frag1535" style="display:none"><pre>
    def __init__(
        self,
        vocabulary_size,
        embedding_size,
        E_init=tl.initializers.random_uniform(-0.1, 0.1),
        name=None,  #'embedding',
    ):
        super(Embedding, self).__init__(name)
        self.vocabulary_size = vocabulary_size
        self.embedding_size = embedding_size
        self.E_init = E_init

        if not self._built:
            self.build(tuple())
            self._built = True

        logging.info("Embedding %s: (%d, %d)" % (self.name, self.vocabulary_size, self.embedding_size))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1539')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/embedding.py: 448-468
</a>
<div class="mid" id="frag1539" style="display:none"><pre>
    def __init__(
        self,
        vocabulary_size,
        embedding_size,
        pad_value=0,
        E_init=tl.initializers.random_uniform(-0.1, 0.1),
        name=None,  # 'average_embedding',
    ):

        super(AverageEmbedding, self).__init__(name)
        self.vocabulary_size = vocabulary_size
        self.embedding_size = embedding_size
        self.pad_value = pad_value
        self.E_init = E_init

        if not self._built:
            self.build(tuple())
            self._built = True

        logging.info("AverageEmbedding %s: (%d, %d)" % (self.name, self.vocabulary_size, self.embedding_size))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 75:</b> &nbsp; 19 fragments, nominal size 32 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1543')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/ternary_conv.py: 63-106
</a>
<div class="mid" id="frag1543" style="display:none"><pre>
    def __init__(
        self,
        n_filter=32,
        filter_size=(3, 3),
        strides=(1, 1),
        act=None,
        padding='SAME',
        use_gemm=False,
        data_format="channels_last",
        dilation_rate=(1, 1),
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None  # 'ternary_cnn2d',
    ):
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.use_gemm = use_gemm
        self.data_format = data_format
        self.dilation_rate = self._dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "TernaryConv2d %s: n_filter: %d filter_size: %s strides: %s pad: %s act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

        if use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        if len(self.strides) != 2:
            raise ValueError("len(strides) should be 2.")

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1592')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/group_conv.py: 61-98
</a>
<div class="mid" id="frag1592" style="display:none"><pre>
    def __init__(
        self,
        n_filter=32,
        filter_size=(3, 3),
        strides=(2, 2),
        n_group=2,
        act=None,
        padding='SAME',
        data_format='channels_last',
        dilation_rate=(1, 1),
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None  # 'groupconv',
    ):  # Windaway
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.strides = self._strides = strides
        self.n_group = n_group
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = self._dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "GroupConv2d %s: n_filter: %d size: %s strides: %s n_group: %d pad: %s act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), n_group, padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1620')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/quan_conv.py: 68-115
</a>
<div class="mid" id="frag1620" style="display:none"><pre>
    def __init__(
        self,
        bitW=8,
        bitA=8,
        n_filter=32,
        filter_size=(3, 3),
        strides=(1, 1),
        act=None,
        padding='SAME',
        use_gemm=False,
        data_format="channels_last",
        dilation_rate=(1, 1),
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None  # 'quan_cnn2d',
    ):
        super().__init__(name, act=act)
        self.bitW = bitW
        self.bitA = bitA
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.use_gemm = use_gemm
        self.data_format = data_format
        self.dilation_rate = self._dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "QuanConv2d %s: n_filter: %d filter_size: %s strides: %s pad: %s act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

        if self.use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        if len(self.strides) != 2:
            raise ValueError("len(strides) should be 2.")

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1567')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/dorefa_conv.py: 67-114
</a>
<div class="mid" id="frag1567" style="display:none"><pre>
    def __init__(
        self,
        bitW=1,
        bitA=3,
        n_filter=32,
        filter_size=(3, 3),
        strides=(1, 1),
        act=None,
        padding='SAME',
        use_gemm=False,
        data_format="channels_last",
        dilation_rate=(1, 1),
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None  # 'dorefa_cnn2d',
    ):
        super().__init__(name, act=act)
        self.bitW = bitW
        self.bitA = bitA
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.use_gemm = use_gemm
        self.data_format = data_format
        self.dilation_rate = self._dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "DorefaConv2d %s: n_filter: %d filter_size: %s strides: %s pad: %s act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

        if self.use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        if len(self.strides) != 2:
            raise ValueError("len(strides) should be 2.")

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1547')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/binary_conv.py: 63-106
</a>
<div class="mid" id="frag1547" style="display:none"><pre>
    def __init__(
        self,
        n_filter=32,
        filter_size=(3, 3),
        strides=(1, 1),
        act=None,
        padding='SAME',
        use_gemm=False,
        data_format="channels_last",
        dilation_rate=(1, 1),
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None  # 'binary_cnn2d',
    ):
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.use_gemm = use_gemm
        self.data_format = data_format
        self._dilation_rate = self.dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "BinaryConv2d %s: n_filter: %d filter_size: %s strides: %s pad: %s act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

        if use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        if len(self.strides) != 2:
            raise ValueError("len(strides) should be 2.")

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1628')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/separable_conv.py: 210-253
</a>
<div class="mid" id="frag1628" style="display:none"><pre>
    def __init__(
        self,
        n_filter=100,
        filter_size=(3, 3),
        strides=(1, 1),
        act=None,
        padding='valid',
        data_format='channels_last',
        dilation_rate=(1, 1),
        depth_multiplier=1,
        depthwise_init=None,
        pointwise_init=None,
        b_init=tl.initializers.constant(value=0.0),
        # depthwise_regularizer=None,
        # pointwise_regularizer=None,
        # bias_regularizer=None,
        # activity_regularizer=None,
        # depthwise_constraint=None,
        # pointwise_constraint=None,
        # W_init=tf.truncated_normal_initializer(stddev=0.1),
        # b_init=tf.constant_initializer(value=0.0),
        in_channels=None,
        name=None  # 'seperable2d',
    ):
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = dilation_rate
        self.depth_multiplier = depth_multiplier
        self.depthwise_init = depthwise_init
        self.pointwise_init = pointwise_init
        self.b_init = b_init
        self.in_channels = in_channels

        logging.info(
            "SeparableConv2d  %s: n_filter: %d filter_size: %s filter_size: %s depth_multiplier: %d act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), depth_multiplier,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1640')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/simplified_conv.py: 322-357
</a>
<div class="mid" id="frag1640" style="display:none"><pre>
    def __init__(
        self,
        n_filter=32,
        filter_size=(3, 3, 3),
        strides=(1, 1, 1),
        act=None,
        padding='SAME',
        data_format='channels_last',
        dilation_rate=(1, 1, 1),
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None  # 'conv3d',
    ):
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self._strides = self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self._dilation_rate = self.dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "Conv3d %s: n_filter: %d filter_size: %s strides: %s pad: %s act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1596')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/depthwise_conv.py: 71-106
</a>
<div class="mid" id="frag1596" style="display:none"><pre>
    def __init__(
        self,
        filter_size=(3, 3),
        strides=(1, 1),
        act=None,
        padding='SAME',
        data_format='channels_last',
        dilation_rate=(1, 1),
        depth_multiplier=1,
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None  # 'depthwise_conv2d'
    ):
        super().__init__(name, act=act)
        self.filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.dilation_rate = self._dilation_rate = dilation_rate
        self.data_format = data_format
        self.depth_multiplier = depth_multiplier
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "DepthwiseConv2d %s: filter_size: %s strides: %s pad: %s act: %s" % (
                self.name, str(filter_size), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1632')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/simplified_conv.py: 59-94
</a>
<div class="mid" id="frag1632" style="display:none"><pre>
    def __init__(
        self,
        n_filter=32,
        filter_size=5,
        stride=1,
        act=None,
        padding='SAME',
        data_format="channels_last",
        dilation_rate=1,
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None  # 'conv1d'
    ):
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.stride = stride
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "Conv1d %s: n_filter: %d filter_size: %s stride: %d pad: %s act: %s" % (
                self.name, n_filter, filter_size, stride, padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1636')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/simplified_conv.py: 189-224
</a>
<div class="mid" id="frag1636" style="display:none"><pre>
    def __init__(
        self,
        n_filter=32,
        filter_size=(3, 3),
        strides=(1, 1),
        act=None,
        padding='SAME',
        data_format='channels_last',
        dilation_rate=(1, 1),
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None  # 'conv2d',
    ):
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self._strides = self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self._dilation_rate = self.dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels:
            self.build(None)
            self._built = True

        logging.info(
            "Conv2d %s: n_filter: %d filter_size: %s strides: %s pad: %s act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1624')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/separable_conv.py: 63-106
</a>
<div class="mid" id="frag1624" style="display:none"><pre>
    def __init__(
        self,
        n_filter=100,
        filter_size=3,
        strides=1,
        act=None,
        padding='valid',
        data_format='channels_last',
        dilation_rate=1,
        depth_multiplier=1,
        depthwise_init=None,
        pointwise_init=None,
        b_init=tl.initializers.constant(value=0.0),
        # depthwise_regularizer=None,
        # pointwise_regularizer=None,
        # bias_regularizer=None,
        # activity_regularizer=None,
        # depthwise_constraint=None,
        # pointwise_constraint=None,
        # W_init=tf.truncated_normal_initializer(stddev=0.1),
        # b_init=tf.constant_initializer(value=0.0),
        in_channels=None,
        name=None  # 'seperable1d',
    ):
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = dilation_rate
        self.depth_multiplier = depth_multiplier
        self.depthwise_init = depthwise_init
        self.pointwise_init = pointwise_init
        self.b_init = b_init
        self.in_channels = in_channels

        logging.info(
            "SeparableConv1d  %s: n_filter: %d filter_size: %s strides: %s depth_multiplier: %d act: %s" % (
                self.name, n_filter, str(filter_size), str(strides), depth_multiplier,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1551')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/expert_conv.py: 62-95
</a>
<div class="mid" id="frag1551" style="display:none"><pre>
    def __init__(
        self,
        act=None,
        shape=(5, 1, 5),
        stride=1,
        padding='SAME',
        data_format='NWC',
        dilation_rate=1,
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        name=None  # 'cnn1d_layer',
    ):
        super().__init__(name, act=act)
        self.n_filter = shape[-1]
        self.filter_size = shape[0]
        self.shape = shape
        self.stride = stride
        self.dilation_rate = dilation_rate
        self.padding = padding
        self.data_format = data_format
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = shape[-2]

        self.build(None)
        self._built = True

        logging.info(
            "Conv1dLayer %s: shape: %s stride: %s pad: %s act: %s" % (
                self.name, str(shape), str(stride), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1604')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/expert_deconv.py: 204-237
</a>
<div class="mid" id="frag1604" style="display:none"><pre>
    def __init__(
        self,
        act=None,
        shape=(3, 3, 128, 256),
        outputs_shape=(1, 256, 256, 128),
        strides=(1, 2, 2, 1),
        padding='SAME',
        data_format='NHWC',
        dilation_rate=(1, 1, 1, 1),
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        name=None  # 'decnn2d_layer',
    ):
        super().__init__(name, act=act)
        self.shape = shape
        self.outputs_shape = outputs_shape
        self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = self.shape[-1]

        self.build(None)
        self._built = True

        logging.info(
            "DeConv2dLayer %s: shape: %s out_shape: %s strides: %s pad: %s act: %s" % (
                self.name, str(shape), str(outputs_shape), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1608')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/expert_deconv.py: 330-363
</a>
<div class="mid" id="frag1608" style="display:none"><pre>
    def __init__(
        self,
        act=None,
        shape=(2, 2, 2, 128, 256),
        outputs_shape=(1, 12, 32, 32, 128),
        strides=(1, 2, 2, 2, 1),
        padding='SAME',
        data_format='NDHWC',
        dilation_rate=(1, 1, 1, 1, 1),
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        name=None  # 'decnn3d_layer',
    ):
        super().__init__(name, act=act)
        self.shape = shape
        self.outputs_shape = outputs_shape
        self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = self.shape[-1]

        self.build(None)
        self._built = True

        logging.info(
            "DeConv3dLayer %s: shape: %s out_shape: %s strides: %s pad: %s act: %s" % (
                self.name, str(shape), str(outputs_shape), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1555')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/expert_conv.py: 181-214
</a>
<div class="mid" id="frag1555" style="display:none"><pre>
    def __init__(
        self,
        act=None,
        shape=(5, 5, 1, 100),
        strides=(1, 1, 1, 1),
        padding='SAME',
        data_format='NHWC',
        dilation_rate=(1, 1, 1, 1),
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        name=None  # 'cnn2d_layer',
    ):
        super().__init__(name, act=act)
        self.n_filter = shape[-1]
        self.filter_size = (shape[0], shape[1])
        self.shape = shape
        self.strides = strides
        self.dilation_rate = dilation_rate
        self.padding = padding
        self.data_format = data_format
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = shape[-2]

        self.build(None)
        self._built = True

        logging.info(
            "Conv2dLayer %s: shape: %s strides: %s pad: %s act: %s" % (
                self.name, str(shape), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1616')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/simplified_deconv.py: 188-225
</a>
<div class="mid" id="frag1616" style="display:none"><pre>
    def __init__(
        self,
        n_filter=32,
        filter_size=(3, 3, 3),
        strides=(2, 2, 2),
        padding='SAME',
        act=None,
        data_format='channels_last',
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None  # 'decnn3d'
    ):
        super().__init__(name, act=act)
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels,

        # Attention: To build, we need not only the in_channels!
        # if self.in_channels:
        #     self.build(None)
        #     self._built = True

        logging.info(
            "DeConv3d %s: n_filters: %s strides: %s pad: %s act: %s" % (
                self.name, str(n_filter), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

        if len(strides) != 3:
            raise ValueError("len(strides) should be 3, DeConv3d and DeConv3dLayer are different.")

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1600')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/expert_deconv.py: 70-103
</a>
<div class="mid" id="frag1600" style="display:none"><pre>
    def __init__(
        self,
        act=None,
        shape=(3, 128, 256),
        outputs_shape=(1, 256, 128),
        strides=(1, 2, 1),
        padding='SAME',
        data_format='NWC',
        dilation_rate=(1, 1, 1),
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        name=None  # 'decnn1d_layer',
    ):
        super().__init__(name, act=act)
        self.shape = shape
        self.outputs_shape = outputs_shape
        self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = self.shape[-1]

        self.build(None)
        self._built = True

        logging.info(
            "DeConv1dLayer %s: shape: %s out_shape: %s strides: %s pad: %s act: %s" % (
                self.name, str(shape), str(outputs_shape), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1559')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/expert_conv.py: 299-332
</a>
<div class="mid" id="frag1559" style="display:none"><pre>
    def __init__(
        self,
        act=None,
        shape=(2, 2, 2, 3, 32),
        strides=(1, 2, 2, 2, 1),
        padding='SAME',
        data_format='NDHWC',
        dilation_rate=(1, 1, 1, 1, 1),
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        name=None  # 'cnn3d_layer'
    ):
        super().__init__(name, act=act)
        self.n_filter = shape[-1]
        self.filter_size = (shape[0], shape[1], shape[2])
        self.shape = shape
        self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = dilation_rate
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = shape[-2]

        self.build(None)
        self._built = True

        logging.info(
            "Conv3dLayer %s: shape: %s strides: %s pad: %s act: %s" % (
                self.name, str(shape), str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1581')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/deformable_conv.py: 73-172
</a>
<div class="mid" id="frag1581" style="display:none"><pre>
    def __init__(
        self,
        offset_layer=None,
        # shape=(3, 3, 1, 100),
        n_filter=32,
        filter_size=(3, 3),
        act=None,
        padding='SAME',
        W_init=tl.initializers.truncated_normal(stddev=0.02),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None  # 'deformable_conv_2d',
    ):
        super().__init__(name, act=act)

        self.offset_layer = offset_layer
        self.n_filter = n_filter
        self.filter_size = filter_size
        self.padding = padding
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        self.kernel_n = filter_size[0] * filter_size[1]
        if self.offset_layer.get_shape()[-1] != 2 * self.kernel_n:
            raise AssertionError("offset.get_shape()[-1] is not equal to: %d" % 2 * self.kernel_n)

        logging.info(
            "DeformableConv2d %s: n_filter: %d, filter_size: %s act: %s" % (
                self.name, self.n_filter, str(self.filter_size
                                             ), self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

        # try:
        #     pre_channel = int(prev_layer.outputs.get_shape()[-1])
        # except Exception:  # if pre_channel is ?, it happens when using Spatial Transformer Net
        #     pre_channel = 1
        #     logging.info("[warnings] unknow input channels, set to 1")
        # shape = (filter_size[0], filter_size[1], pre_channel, n_filter)

        # with tf.compat.v1.variable_scope(name):
        #     offset = self.offset_layer # .outputs
        #
        #     # if offset.get_shape()[-1] != 2 * shape[0] * shape[1]:
        #     #     raise AssertionError("offset.get_shape()[-1] is not equal to: %d" % 2 * shape[0] * shape[1])
        #
        #     # Grid initialisation
        #     input_h = int(self.inputs.get_shape()[1])
        #     input_w = int(self.inputs.get_shape()[2])
        #     # kernel_n = shape[0] * shape[1]
        #     initial_offsets = tf.stack(
        #         tf.meshgrid(tf.range(shape[0]), tf.range(shape[1]), indexing='ij')
        #     )  # initial_offsets --&gt; (kh, kw, 2)
        #     initial_offsets = tf.reshape(initial_offsets, (-1, 2))  # initial_offsets --&gt; (n, 2)
        #     initial_offsets = tf.expand_dims(initial_offsets, 0)  # initial_offsets --&gt; (1, n, 2)
        #     initial_offsets = tf.expand_dims(initial_offsets, 0)  # initial_offsets --&gt; (1, 1, n, 2)
        #     initial_offsets = tf.tile(initial_offsets, [input_h, input_w, 1, 1])  # initial_offsets --&gt; (h, w, n, 2)
        #     initial_offsets = tf.cast(initial_offsets, 'float32')
        #     grid = tf.meshgrid(
        #         tf.range(-int((shape[0] - 1) / 2.0), int(input_h - int((shape[0] - 1) / 2.0)), 1),
        #         tf.range(-int((shape[1] - 1) / 2.0), int(input_w - int((shape[1] - 1) / 2.0)), 1), indexing='ij'
        #     )
        #
        #     grid = tf.stack(grid, axis=-1)
        #     grid = tf.cast(grid, 'float32')  # grid --&gt; (h, w, 2)
        #     grid = tf.expand_dims(grid, 2)  # grid --&gt; (h, w, 1, 2)
        #     grid = tf.tile(grid, [1, 1, self.kernel_n, 1])  # grid --&gt; (h, w, n, 2)
        #     grid_offset = grid + initial_offsets  # grid_offset --&gt; (h, w, n, 2)
        #
        #     input_deform = self._tf_batch_map_offsets(self.inputs, offset, grid_offset)
        #
        #     # W = tf.compat.v1.get_variable(
        #     #     name='W_deformableconv2d', shape=[1, 1, shape[0] * shape[1], shape[-2], shape[-1]], initializer=W_init,
        #     #     dtype=LayersConfig.tf_dtype,
        #     # )
        #
        #     # _tensor = tf.nn.conv3d(input_deform, W, strides=[1, 1, 1, 1, 1], padding='VALID', name=None)
        #     # _tensor = tf.nn.conv3d(
        #     #     input=input_deform,
        #     #     filters=W,
        #     #     strides=[1, 1, 1, 1, 1],
        #     #     padding='VALID',
        #     #     name=None
        #     # )
        #
        #     # if b_init:
        #     #     b = tf.compat.v1.get_variable(
        #     #         name='b_deformableconv2d', shape=(shape[-1]), initializer=b_init, # dtype=LayersConfig.tf_dtype,
        #     #     )
        #     #
        #     #     _tensor = tf.nn.bias_add(_tensor, b, name='bias_add')
        #
        #     # self.outputs = tf.reshape(
        #     #     tensor=self._apply_activation(_tensor),
        #     #     shape=[tf.shape(input=self.inputs)[0], input_h, input_w, shape[-1]]
        #     # )
        #
        # # self._add_layers(self.outputs)

</pre></div>
</td>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 76:</b> &nbsp; 20 fragments, nominal size 13 lines, similarity 80%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1544')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/ternary_conv.py: 107-122
</a>
<div class="mid" id="frag1544" style="display:none"><pre>
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1593')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/group_conv.py: 99-114
</a>
<div class="mid" id="frag1593" style="display:none"><pre>
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1613')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/simplified_deconv.py: 104-119
</a>
<div class="mid" id="frag1613" style="display:none"><pre>
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1601')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/expert_deconv.py: 104-121
</a>
<div class="mid" id="frag1601" style="display:none"><pre>
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(
            classname=self.__class__.__name__, n_filter=self.shape[-2], filter_size=self.shape[0], **self.__dict__
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1597')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/depthwise_conv.py: 107-124
</a>
<div class="mid" id="frag1597" style="display:none"><pre>
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(
            classname=self.__class__.__name__, n_filter=self.in_channels * self.depth_multiplier, **self.__dict__
        )

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1556')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/expert_conv.py: 215-232
</a>
<div class="mid" id="frag1556" style="display:none"><pre>
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != [
                1,
        ] * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1621')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/quan_conv.py: 116-131
</a>
<div class="mid" id="frag1621" style="display:none"><pre>
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1625')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/separable_conv.py: 107-122
</a>
<div class="mid" id="frag1625" style="display:none"><pre>
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', stride={strides}, padding={padding}'
        )
        if self.dilation_rate != 1:
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1629')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/separable_conv.py: 254-269
</a>
<div class="mid" id="frag1629" style="display:none"><pre>
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', stride={strides}, padding={padding}'
        )
        if self.dilation_rate != 1:
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1633')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/simplified_conv.py: 95-110
</a>
<div class="mid" id="frag1633" style="display:none"><pre>
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', stride={stride}, padding={padding}'
        )
        if self.dilation_rate != 1:
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1568')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/dorefa_conv.py: 115-130
</a>
<div class="mid" id="frag1568" style="display:none"><pre>
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1637')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/simplified_conv.py: 225-240
</a>
<div class="mid" id="frag1637" style="display:none"><pre>
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1552')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/expert_conv.py: 96-111
</a>
<div class="mid" id="frag1552" style="display:none"><pre>
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', stride={stride}, padding={padding}'
        )
        if self.dilation_rate != 1:
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1548')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/binary_conv.py: 107-122
</a>
<div class="mid" id="frag1548" style="display:none"><pre>
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1641')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/simplified_conv.py: 358-373
</a>
<div class="mid" id="frag1641" style="display:none"><pre>
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1560')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/expert_conv.py: 333-350
</a>
<div class="mid" id="frag1560" style="display:none"><pre>
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != [
                1,
        ] * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1617')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/simplified_deconv.py: 226-241
</a>
<div class="mid" id="frag1617" style="display:none"><pre>
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        # if self.dilation_rate != (1,) * len(self.dilation_rate):
        #     s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1582')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/deformable_conv.py: 173-186
</a>
<div class="mid" id="frag1582" style="display:none"><pre>
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', padding={padding}'
        )
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1605')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/expert_deconv.py: 238-256
</a>
<div class="mid" id="frag1605" style="display:none"><pre>
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(
            classname=self.__class__.__name__, n_filter=self.shape[-2], filter_size=(self.shape[0], self.shape[1]),
            **self.__dict__
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1609')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/expert_deconv.py: 364-382
</a>
<div class="mid" id="frag1609" style="display:none"><pre>
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = (
            '{classname}(in_channels={in_channels}, out_channels={n_filter}, kernel_size={filter_size}'
            ', strides={strides}, padding={padding}'
        )
        if self.dilation_rate != (1, ) * len(self.dilation_rate):
            s += ', dilation={dilation_rate}'
        if self.b_init is None:
            s += ', bias=False'
        s += (', ' + actstr)
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(
            classname=self.__class__.__name__, n_filter=self.shape[-2],
            filter_size=(self.shape[0], self.shape[1], self.shape[2]), **self.__dict__
        )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 77:</b> &nbsp; 8 fragments, nominal size 19 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1545')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/ternary_conv.py: 123-144
</a>
<div class="mid" id="frag1545" style="display:none"><pre>
    def build(self, inputs_shape):
        if self.data_format == 'channels_last':
            self.data_format = 'NHWC'
            if self.in_channels is None:
                self.in_channels = inputs_shape[-1]
            self._strides = [1, self._strides[0], self._strides[1], 1]
            self._dilation_rate = [1, self._dilation_rate[0], self._dilation_rate[1], 1]
        elif self.data_format == 'channels_first':
            self.data_format = 'NCHW'
            if self.in_channels is None:
                self.in_channels = inputs_shape[1]
            self._strides = [1, 1, self._strides[0], self._strides[1]]
            self._dilation_rate = [1, 1, self._dilation_rate[0], self._dilation_rate[1]]
        else:
            raise Exception("data_format should be either channels_last or channels_first")

        self.filter_shape = (self.filter_size[0], self.filter_size[1], self.in_channels, self.n_filter)

        self.W = self._get_weights("filters", shape=self.filter_shape, init=self.W_init)
        if self.b_init:
            self.b = self._get_weights("biases", shape=(self.n_filter, ), init=self.b_init)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1594')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/group_conv.py: 115-144
</a>
<div class="mid" id="frag1594" style="display:none"><pre>
    def build(self, inputs_shape):

        if self.data_format == 'channels_last':
            self.data_format = 'NHWC'
            if self.in_channels is None:
                self.in_channels = inputs_shape[-1]
            self._strides = [1, self._strides[0], self._strides[1], 1]
            self._dilation_rate = [1, self._dilation_rate[0], self._dilation_rate[1], 1]
        elif self.data_format == 'channels_first':
            self.data_format = 'NCHW'
            if self.in_channels is None:
                self.in_channels = inputs_shape[1]
            self._strides = [1, 1, self._strides[0], self._strides[1]]
            self._dilation_rate = [1, 1, self._dilation_rate[0], self._dilation_rate[1]]
        else:
            raise Exception("data_format should be either channels_last or channels_first")

        self.groupConv = lambda i, k: tf.nn.conv2d(
            i, k, strides=self._strides, padding=self.padding, data_format=self.data_format, dilations=self.
            _dilation_rate, name=self.name
        )

        self.filter_shape = (
            self.filter_size[0], self.filter_size[1], int(self.in_channels / self.n_group), self.n_filter
        )

        self.We = self._get_weights("filters", shape=self.filter_shape, init=self.W_init)
        if self.b_init:
            self.b = self._get_weights("biases", shape=self.n_filter, init=self.b_init)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1638')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/simplified_conv.py: 241-263
</a>
<div class="mid" id="frag1638" style="display:none"><pre>
    def build(self, inputs_shape):
        if self.data_format == 'channels_last':
            self.data_format = 'NHWC'
            if self.in_channels is None:
                self.in_channels = inputs_shape[-1]
            self._strides = [1, self._strides[0], self._strides[1], 1]
            self._dilation_rate = [1, self._dilation_rate[0], self._dilation_rate[1], 1]
        elif self.data_format == 'channels_first':
            self.data_format = 'NCHW'
            if self.in_channels is None:
                self.in_channels = inputs_shape[1]
            self._strides = [1, 1, self._strides[0], self._strides[1]]
            self._dilation_rate = [1, 1, self._dilation_rate[0], self._dilation_rate[1]]
        else:
            raise Exception("data_format should be either channels_last or channels_first")

        self.filter_shape = (self.filter_size[0], self.filter_size[1], self.in_channels, self.n_filter)

        self.W = self._get_weights("filters", shape=self.filter_shape, init=self.W_init)

        if self.b_init:
            self.b = self._get_weights("biases", shape=(self.n_filter, ), init=self.b_init)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1598')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/depthwise_conv.py: 125-147
</a>
<div class="mid" id="frag1598" style="display:none"><pre>
    def build(self, inputs_shape):
        if self.data_format == 'channels_last':
            self.data_format = 'NHWC'
            if self.in_channels is None:
                self.in_channels = inputs_shape[-1]
            self._strides = [1, self._strides[0], self._strides[1], 1]
            self._dilation_rate = [1, self._dilation_rate[0], self._dilation_rate[1], 1]
        elif self.data_format == 'channels_first':
            self.data_format = 'NCHW'
            if self.in_channels is None:
                self.in_channels = inputs_shape[1]
            self._strides = [1, 1, self._strides[0], self._strides[1]]
            self._dilation_rate = [1, 1, self._dilation_rate[0], self._dilation_rate[1]]
        else:
            raise Exception("data_format should be either channels_last or channels_first")

        self.filter_shape = (self.filter_size[0], self.filter_size[1], self.in_channels, self.depth_multiplier)

        self.W = self._get_weights("filters", shape=self.filter_shape, init=self.W_init)

        if self.b_init:
            self.b = self._get_weights("biases", shape=(self.in_channels * self.depth_multiplier), init=self.b_init)

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1549')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/binary_conv.py: 123-144
</a>
<div class="mid" id="frag1549" style="display:none"><pre>
    def build(self, inputs_shape):
        if self.data_format == 'channels_last':
            self.data_format = 'NHWC'
            if self.in_channels is None:
                self.in_channels = inputs_shape[-1]
            self._strides = [1, self._strides[0], self._strides[1], 1]
            self._dilation_rate = [1, self._dilation_rate[0], self._dilation_rate[1], 1]
        elif self.data_format == 'channels_first':
            self.data_format = 'NCHW'
            if self.in_channels is None:
                self.in_channels = inputs_shape[1]
            self._strides = [1, 1, self._strides[0], self._strides[1]]
            self._dilation_rate = [1, 1, self._dilation_rate[0], self._dilation_rate[1]]
        else:
            raise Exception("data_format should be either channels_last or channels_first")

        self.filter_shape = (self.filter_size[0], self.filter_size[1], self.in_channels, self.n_filter)

        self.W = self._get_weights("filters", shape=self.filter_shape, init=self.W_init)
        if self.b_init:
            self.b = self._get_weights("biases", shape=(self.n_filter, ), init=self.b_init)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1569')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/dorefa_conv.py: 131-152
</a>
<div class="mid" id="frag1569" style="display:none"><pre>
    def build(self, inputs_shape):
        if self.data_format == 'channels_last':
            self.data_format = 'NHWC'
            if self.in_channels is None:
                self.in_channels = inputs_shape[-1]
            self._strides = [1, self._strides[0], self._strides[1], 1]
            self._dilation_rate = [1, self._dilation_rate[0], self._dilation_rate[1], 1]
        elif self.data_format == 'channels_first':
            self.data_format = 'NCHW'
            if self.in_channels is None:
                self.in_channels = inputs_shape[1]
            self._strides = [1, 1, self._strides[0], self._strides[1]]
            self._dilation_rate = [1, 1, self._dilation_rate[0], self._dilation_rate[1]]
        else:
            raise Exception("data_format should be either channels_last or channels_first")

        self.filter_shape = (self.filter_size[0], self.filter_size[1], self.in_channels, self.n_filter)

        self.W = self._get_weights("filters", shape=self.filter_shape, init=self.W_init)
        if self.b_init:
            self.b = self._get_weights("biases", shape=(self.n_filter, ), init=self.b_init)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1622')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/quan_conv.py: 132-153
</a>
<div class="mid" id="frag1622" style="display:none"><pre>
    def build(self, inputs_shape):
        if self.data_format == 'channels_last':
            self.data_format = 'NHWC'
            if self.in_channels is None:
                self.in_channels = inputs_shape[-1]
            self._strides = [1, self._strides[0], self._strides[1], 1]
            self._dilation_rate = [1, self._dilation_rate[0], self._dilation_rate[1], 1]
        elif self.data_format == 'channels_first':
            self.data_format = 'NCHW'
            if self.in_channels is None:
                self.in_channels = inputs_shape[1]
            self._strides = [1, 1, self._strides[0], self._strides[1]]
            self._dilation_rate = [1, 1, self._dilation_rate[0], self._dilation_rate[1]]
        else:
            raise Exception("data_format should be either channels_last or channels_first")

        self.filter_shape = (self.filter_size[0], self.filter_size[1], self.in_channels, self.n_filter)

        self.W = self._get_weights("filters", shape=self.filter_shape, init=self.W_init)
        if self.b_init:
            self.b = self._get_weights("biases", shape=(self.n_filter, ), init=self.b_init)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1642')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/simplified_conv.py: 374-398
</a>
<div class="mid" id="frag1642" style="display:none"><pre>
    def build(self, inputs_shape):
        if self.data_format == 'channels_last':
            self.data_format = 'NDHWC'
            if self.in_channels is None:
                self.in_channels = inputs_shape[-1]
            self._strides = [1, self._strides[0], self._strides[1], self._strides[2], 1]
            self._dilation_rate = [1, self.dilation_rate[0], self.dilation_rate[1], self.dilation_rate[2], 1]
        elif self.data_format == 'channels_first':
            self.data_format = 'NCDHW'
            if self.in_channels is None:
                self.in_channels = inputs_shape[1]
            self._strides = [1, 1, self._strides[0], self._strides[1], self._strides[2]]
            self._dilation_rate = [1, 1, self._dilation_rate[0], self._dilation_rate[1], self._dilation_rate[2]]
        else:
            raise Exception("data_format should be either channels_last or channels_first")

        self.filter_shape = (
            self.filter_size[0], self.filter_size[1], self.filter_size[2], self.in_channels, self.n_filter
        )

        self.W = self._get_weights("filters", shape=self.filter_shape, init=self.W_init)

        if self.b_init:
            self.b = self._get_weights("biases", shape=(self.n_filter, ), init=self.b_init)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 78:</b> &nbsp; 4 fragments, nominal size 11 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1546')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/ternary_conv.py: 145-162
</a>
<div class="mid" id="frag1546" style="display:none"><pre>
    def forward(self, inputs):

        alpha = compute_alpha(self.W)

        W_ = ternary_operation(self.W)
        W_ = tf.multiply(alpha, W_)

        outputs = tf.nn.conv2d(
            input=inputs, filters=W_, strides=self._strides, padding=self.padding, data_format=self.data_format,
            dilations=self._dilation_rate, name=self.name
        )

        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)

        return outputs
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1623')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/quan_conv.py: 154-170
</a>
<div class="mid" id="frag1623" style="display:none"><pre>
    def forward(self, inputs):

        inputs = quantize_active_overflow(inputs, self.bitA)  # Do not remove

        W_ = quantize_weight_overflow(self.W, self.bitW)

        outputs = tf.nn.conv2d(
            input=inputs, filters=W_, strides=self.strides, padding=self.padding, data_format=self.data_format,
            dilations=self._dilation_rate, name=self.name
        )

        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)

        return outputs
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1550')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/binary_conv.py: 145-159
</a>
<div class="mid" id="frag1550" style="display:none"><pre>
    def forward(self, inputs):

        _W = quantize(self.W)

        outputs = tf.nn.conv2d(
            input=inputs, filters=_W, strides=self._strides, padding=self.padding, data_format=self.data_format,
            dilations=self._dilation_rate, name=self.name
        )

        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)

        return outputs
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1570')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/dorefa_conv.py: 153-169
</a>
<div class="mid" id="frag1570" style="display:none"><pre>
    def forward(self, inputs):

        inputs = quantize_active(cabs(inputs), self.bitA)  # Do not remove

        W_ = quantize_weight(self.W, self.bitW)

        outputs = tf.nn.conv2d(
            input=inputs, filters=W_, strides=self._strides, padding=self.padding, data_format=self.data_format,
            dilations=self._dilation_rate, name=self.name
        )

        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)

        return outputs
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 79:</b> &nbsp; 13 fragments, nominal size 15 lines, similarity 73%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1554')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/expert_conv.py: 117-137
</a>
<div class="mid" id="frag1554" style="display:none"><pre>
    def forward(self, inputs):

        outputs = tf.nn.conv1d(
            input=inputs,
            filters=self.W,
            stride=self.stride,
            padding=self.padding,
            dilations=[
                self.dilation_rate,
            ],
            data_format=self.data_format,
            name=self.name,
        )

        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1607')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/expert_deconv.py: 262-279
</a>
<div class="mid" id="frag1607" style="display:none"><pre>
    def forward(self, inputs):
        outputs = tf.nn.conv2d_transpose(
            input=inputs,
            filters=self.W,
            output_shape=self.outputs_shape,
            strides=self.strides,
            padding=self.padding,
            data_format=self.data_format,
            dilations=list(self.dilation_rate),
            name=self.name,
        )
        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1603')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/expert_deconv.py: 127-144
</a>
<div class="mid" id="frag1603" style="display:none"><pre>
    def forward(self, inputs):
        outputs = tf.nn.conv1d_transpose(
            input=inputs,
            filters=self.W,
            output_shape=self.outputs_shape,
            strides=list(self.strides),
            padding=self.padding,
            data_format=self.data_format,
            dilations=list(self.dilation_rate),
            name=self.name,
        )
        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1643')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/simplified_conv.py: 399-413
</a>
<div class="mid" id="frag1643" style="display:none"><pre>
    def forward(self, inputs):
        outputs = tf.nn.conv3d(
            input=inputs,
            filters=self.W,
            strides=self._strides,
            padding=self.padding,
            data_format=self.data_format,  #'NDHWC',
            dilations=self._dilation_rate,  #[1, 1, 1, 1, 1],
            name=self.name,
        )
        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1639')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/simplified_conv.py: 264-280
</a>
<div class="mid" id="frag1639" style="display:none"><pre>
    def forward(self, inputs):
        outputs = tf.nn.conv2d(
            input=inputs,
            filters=self.W,
            strides=self._strides,
            padding=self.padding,
            data_format=self.data_format,  #'NHWC',
            dilations=self._dilation_rate,  #[1, 1, 1, 1],
            name=self.name,
        )
        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1558')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/expert_conv.py: 238-255
</a>
<div class="mid" id="frag1558" style="display:none"><pre>
    def forward(self, inputs):
        outputs = tf.nn.conv2d(
            input=inputs,
            filters=self.W,
            strides=self.strides,
            padding=self.padding,
            data_format=self.data_format,
            dilations=list(self.dilation_rate),
            name=self.name,
        )

        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1635')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/simplified_conv.py: 131-147
</a>
<div class="mid" id="frag1635" style="display:none"><pre>
    def forward(self, inputs):
        outputs = tf.nn.conv1d(
            input=inputs,
            filters=self.W,
            stride=self.stride,
            padding=self.padding,
            data_format=self.data_format,
            dilations=self.dilation_rate,
            name=self.name,
        )
        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1562')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/expert_conv.py: 357-372
</a>
<div class="mid" id="frag1562" style="display:none"><pre>
    def forward(self, inputs):
        outputs = tf.nn.conv3d(
            input=inputs,
            filters=self.W,
            strides=self.strides,
            padding=self.padding,
            data_format=self.data_format,  #'NDHWC',
            dilations=list(self.dilation_rate),  #[1, 1, 1, 1, 1],
            name=self.name,
        )

        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1599')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/depthwise_conv.py: 148-162
</a>
<div class="mid" id="frag1599" style="display:none"><pre>
    def forward(self, inputs):
        outputs = tf.nn.depthwise_conv2d(
            input=inputs,
            filter=self.W,
            strides=self._strides,
            padding=self.padding,
            data_format=self.data_format,
            dilations=self.dilation_rate,
            name=self.name,
        )
        if self.b_init:
            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')
        if self.act:
            outputs = self.act(outputs)
        return outputs
</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1826')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/pooling.py: 169-182
</a>
<div class="mid" id="frag1826" style="display:none"><pre>
    def forward(self, inputs):
        outputs = tf.nn.pool(
            input=inputs,
            window_shape=self._filter_size,
            pooling_type="MAX",
            strides=self._strides,
            padding=self.padding,
            data_format=self.data_format,
            dilations=self._dilation_rate,
            name=self.name,
        )
        return outputs


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1846')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/pooling.py: 565-576
</a>
<div class="mid" id="frag1846" style="display:none"><pre>
    def forward(self, inputs):
        outputs = tf.nn.avg_pool3d(
            input=inputs,
            ksize=self.filter_size,
            strides=self._strides,
            padding=self.padding,
            data_format=self.data_format,
            name=self.name,
        )
        return outputs


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1842')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/pooling.py: 484-495
</a>
<div class="mid" id="frag1842" style="display:none"><pre>
    def forward(self, inputs):
        outputs = tf.nn.max_pool3d(
            input=inputs,
            ksize=self.filter_size,
            strides=self._strides,
            padding=self.padding,
            data_format=self.data_format,
            name=self.name,
        )
        return outputs


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1830')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/pooling.py: 255-268
</a>
<div class="mid" id="frag1830" style="display:none"><pre>
    def forward(self, inputs):
        outputs = tf.nn.pool(
            input=inputs,
            window_shape=self._filter_size,
            pooling_type="AVG",
            padding=self.padding,
            dilations=None,  # TODO: support dilations
            strides=self._strides,
            name=self.name,
            data_format=self.data_format
        )
        return outputs


</pre></div>
</td>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 80:</b> &nbsp; 2 fragments, nominal size 83 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1563')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/quan_conv_bn.py: 94-220
</a>
<div class="mid" id="frag1563" style="display:none"><pre>
    def __init__(
        self,
        prev_layer,
        n_filter=32,
        filter_size=(3, 3),
        strides=(1, 1),
        padding='SAME',
        act=None,
        decay=0.9,
        epsilon=1e-5,
        is_train=False,
        gamma_init=tf.compat.v1.initializers.ones,
        beta_init=tf.compat.v1.initializers.zeros,
        bitW=8,
        bitA=8,
        use_gemm=False,
        W_init=tf.compat.v1.initializers.truncated_normal(stddev=0.02),
        W_init_args=None,
        use_cudnn_on_gpu=None,
        data_format=None,
        name='quan_cnn2d_bn',
    ):
        super(QuanConv2dWithBN, self).__init__(prev_layer=prev_layer, act=act, W_init_args=W_init_args, name=name)

        logging.info(
            "QuanConv2dWithBN %s: n_filter: %d filter_size: %s strides: %s pad: %s act: %s " % (
                self.name, n_filter, filter_size, str(strides), padding,
                self.act.__name__ if self.act is not None else 'No Activation'
            )
        )

        x = self.inputs
        self.inputs = quantize_active_overflow(self.inputs, bitA)  # Do not remove

        if use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        if len(strides) != 2:
            raise ValueError("len(strides) should be 2.")

        try:
            pre_channel = int(prev_layer.outputs.get_shape()[-1])
        except Exception:  # if pre_channel is ?, it happens when using Spatial Transformer Net
            pre_channel = 1
            logging.warning("[warnings] unknow input channels, set to 1")

        shape = (filter_size[0], filter_size[1], pre_channel, n_filter)
        strides = (1, strides[0], strides[1], 1)

        with tf.compat.v1.variable_scope(name):
            W = tf.compat.v1.get_variable(
                name='W_conv2d', shape=shape, initializer=W_init, dtype=LayersConfig.tf_dtype, **self.W_init_args
            )

            conv = tf.nn.conv2d(
                x, W, strides=strides, padding=padding, use_cudnn_on_gpu=use_cudnn_on_gpu, data_format=data_format
            )

            para_bn_shape = conv.get_shape()[-1:]

            if gamma_init:
                scale_para = tf.compat.v1.get_variable(
                    name='scale_para', shape=para_bn_shape, initializer=gamma_init, dtype=LayersConfig.tf_dtype,
                    trainable=is_train
                )
            else:
                scale_para = None

            if beta_init:
                offset_para = tf.compat.v1.get_variable(
                    name='offset_para', shape=para_bn_shape, initializer=beta_init, dtype=LayersConfig.tf_dtype,
                    trainable=is_train
                )
            else:
                offset_para = None

            moving_mean = tf.compat.v1.get_variable(
                'moving_mean', para_bn_shape, initializer=tf.compat.v1.initializers.constant(1.),
                dtype=LayersConfig.tf_dtype, trainable=False
            )

            moving_variance = tf.compat.v1.get_variable(
                'moving_variance',
                para_bn_shape,
                initializer=tf.compat.v1.initializers.constant(1.),
                dtype=LayersConfig.tf_dtype,
                trainable=False,
            )

            mean, variance = tf.nn.moments(x=conv, axes=list(range(len(conv.get_shape()) - 1)))

            update_moving_mean = moving_averages.assign_moving_average(
                moving_mean, mean, decay, zero_debias=False
            )  # if zero_debias=True, has bias

            update_moving_variance = moving_averages.assign_moving_average(
                moving_variance, variance, decay, zero_debias=False
            )  # if zero_debias=True, has bias

            def mean_var_with_update():
                with tf.control_dependencies([update_moving_mean, update_moving_variance]):
                    return tf.identity(mean), tf.identity(variance)

            if is_train:
                mean, var = mean_var_with_update()
            else:
                mean, var = moving_mean, moving_variance

            w_fold = _w_fold(W, scale_para, var, epsilon)
            bias_fold = _bias_fold(offset_para, scale_para, mean, var, epsilon)

            W = quantize_weight_overflow(w_fold, bitW)

            conv_fold = tf.nn.conv2d(
                self.inputs, W, strides=strides, padding=padding, use_cudnn_on_gpu=use_cudnn_on_gpu,
                data_format=data_format
            )

            self.outputs = tf.nn.bias_add(conv_fold, bias_fold, name='bn_bias_add')

            self.outputs = self._apply_activation(self.outputs)

        self._add_layers(self.outputs)

        self._add_params([W, scale_para, offset_para, moving_mean, moving_variance])


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1765')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/dense/quan_dense_bn.py: 70-182
</a>
<div class="mid" id="frag1765" style="display:none"><pre>
    def __init__(
        self,
        prev_layer,
        n_units=100,
        act=None,
        decay=0.9,
        epsilon=1e-5,
        is_train=False,
        bitW=8,
        bitA=8,
        gamma_init=tf.compat.v1.initializers.ones,
        beta_init=tf.compat.v1.initializers.zeros,
        use_gemm=False,
        W_init=tf.compat.v1.initializers.truncated_normal(stddev=0.05),
        W_init_args=None,
        name=None,  #'quan_dense_with_bn',
    ):
        super(QuanDenseLayerWithBN, self).__init__(prev_layer=prev_layer, act=act, W_init_args=W_init_args, name=name)

        logging.info(
            "QuanDenseLayerWithBN  %s: %d %s" %
            (self.name, n_units, self.act.__name__ if self.act is not None else 'No Activation')
        )

        if self.inputs.get_shape().ndims != 2:
            raise Exception("The input dimension must be rank 2, please reshape or flatten it")

        if use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        n_in = int(self.inputs.get_shape()[-1])
        x = self.inputs
        self.inputs = quantize_active_overflow(self.inputs, bitA)
        self.n_units = n_units

        with tf.compat.v1.variable_scope(name):

            W = tf.compat.v1.get_variable(
                name='W', shape=(n_in, n_units), initializer=W_init, dtype=LayersConfig.tf_dtype, **self.W_init_args
            )

            mid_out = tf.matmul(x, W)

            para_bn_shape = mid_out.get_shape()[-1:]

            if gamma_init:
                scale_para = tf.compat.v1.get_variable(
                    name='scale_para', shape=para_bn_shape, initializer=gamma_init, dtype=LayersConfig.tf_dtype,
                    trainable=is_train
                )
            else:
                scale_para = None

            if beta_init:
                offset_para = tf.compat.v1.get_variable(
                    name='offset_para', shape=para_bn_shape, initializer=beta_init, dtype=LayersConfig.tf_dtype,
                    trainable=is_train
                )
            else:
                offset_para = None

            moving_mean = tf.compat.v1.get_variable(
                'moving_mean', para_bn_shape, initializer=tf.compat.v1.initializers.constant(1.),
                dtype=LayersConfig.tf_dtype, trainable=False
            )

            moving_variance = tf.compat.v1.get_variable(
                'moving_variance',
                para_bn_shape,
                initializer=tf.compat.v1.initializers.constant(1.),
                dtype=LayersConfig.tf_dtype,
                trainable=False,
            )

            mean, variance = tf.nn.moments(x=mid_out, axes=list(range(len(mid_out.get_shape()) - 1)))

            update_moving_mean = moving_averages.assign_moving_average(
                moving_mean, mean, decay, zero_debias=False
            )  # if zero_debias=True, has bias

            update_moving_variance = moving_averages.assign_moving_average(
                moving_variance, variance, decay, zero_debias=False
            )  # if zero_debias=True, has bias

            def mean_var_with_update():
                with tf.control_dependencies([update_moving_mean, update_moving_variance]):
                    return tf.identity(mean), tf.identity(variance)

            if is_train:
                mean, var = mean_var_with_update()
            else:
                mean, var = moving_mean, moving_variance

            w_fold = _w_fold(W, scale_para, var, epsilon)
            bias_fold = _bias_fold(offset_para, scale_para, mean, var, epsilon)

            W = quantize_weight_overflow(w_fold, bitW)
            # W = tl.act.sign(W)    # dont update ...

            # W = tf.Variable(W)

            self.outputs = tf.matmul(self.inputs, W)
            # self.outputs = xnor_gemm(self.inputs, W) # TODO

            self.outputs = tf.nn.bias_add(self.outputs, bias_fold, name='bias_add')

            self.outputs = self._apply_activation(self.outputs)

        self._add_layers(self.outputs)

        self._add_params([W, scale_para, offset_para, moving_mean, moving_variance])


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 81:</b> &nbsp; 8 fragments, nominal size 21 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1571')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/super_resolution.py: 49-69
</a>
<div class="mid" id="frag1571" style="display:none"><pre>
    def __init__(
        self,
        scale=2,
        act=None,
        in_channels=None,
        name=None  # 'subpixel_conv1d'
    ):
        super().__init__(name, act=act)
        self.scale = scale
        self.in_channels = in_channels
        self.out_channels = int(self.in_channels / self.scale)

        if self.in_channels is not None:
            self.build(None)
            self._built = True

        logging.info(
            "SubpixelConv1d  %s: scale: %d act: %s" %
            (self.name, scale, self.act.__name__ if self.act is not None else 'No Activation')
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1576')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/super_resolution.py: 143-163
</a>
<div class="mid" id="frag1576" style="display:none"><pre>
    def __init__(
        self,
        scale=2,
        n_out_channels=None,
        act=None,
        in_channels=None,
        name=None  # 'subpixel_conv2d'
    ):
        super().__init__(name, act=act)
        self.scale = scale
        self.n_out_channels = n_out_channels
        self.in_channels = in_channels

        if self.in_channels is not None:
            self.build(None)
            self._built = True
        logging.info(
            "SubpixelConv2d  %s: scale: %d act: %s" %
            (self.name, scale, self.act.__name__ if self.act is not None else 'No Activation')
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1761')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/dense/binary_dense.py: 42-67
</a>
<div class="mid" id="frag1761" style="display:none"><pre>
    def __init__(
        self,
        n_units=100,
        act=None,
        use_gemm=False,
        W_init=tl.initializers.truncated_normal(stddev=0.05),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None,  #'binary_dense',
    ):
        super().__init__(name, act=act)
        self.n_units = n_units
        self.use_gemm = use_gemm
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels is not None:
            self.build((None, self.in_channels))
            self._built = True

        logging.info(
            "BinaryDense  %s: %d %s" %
            (self.name, n_units, self.act.__name__ if self.act is not None else 'No Activation')
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1745')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/dense/ternary_dense.py: 42-67
</a>
<div class="mid" id="frag1745" style="display:none"><pre>
    def __init__(
        self,
        n_units=100,
        act=None,
        use_gemm=False,
        W_init=tl.initializers.truncated_normal(stddev=0.05),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None,  #'ternary_dense',
    ):
        super().__init__(name, act=act)
        self.n_units = n_units
        self.use_gemm = use_gemm
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels is not None:
            self.build((None, self.in_channels))
            self._built = True

        logging.info(
            "TernaryDense  %s: %d %s" %
            (self.name, n_units, self.act.__name__ if self.act is not None else 'No Activation')
        )

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1757')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/dense/base_dense.py: 56-81
</a>
<div class="mid" id="frag1757" style="display:none"><pre>
    def __init__(
        self,
        n_units,
        act=None,
        W_init=tl.initializers.truncated_normal(stddev=0.05),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None,  # 'dense',
    ):

        super(Dense, self).__init__(name, act=act)

        self.n_units = n_units
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels is not None:
            self.build(self.in_channels)
            self._built = True

        logging.info(
            "Dense  %s: %d %s" %
            (self.name, self.n_units, self.act.__name__ if self.act is not None else 'No Activation')
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1753')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/dense/quan_dense.py: 45-74
</a>
<div class="mid" id="frag1753" style="display:none"><pre>
    def __init__(
        self,
        n_units=100,
        act=None,
        bitW=8,
        bitA=8,
        use_gemm=False,
        W_init=tl.initializers.truncated_normal(stddev=0.05),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None,  #'quan_dense',
    ):
        super().__init__(name, act=act)
        self.n_units = n_units
        self.bitW = bitW
        self.bitA = bitA
        self.use_gemm = use_gemm
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels is not None:
            self.build((None, self.in_channels))
            self._built = True

        logging.info(
            "QuanDense  %s: %d %s" %
            (self.name, n_units, self.act.__name__ if self.act is not None else 'No Activation')
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1741')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/dense/dorefa_dense.py: 47-76
</a>
<div class="mid" id="frag1741" style="display:none"><pre>
    def __init__(
        self,
        bitW=1,
        bitA=3,
        n_units=100,
        act=None,
        use_gemm=False,
        W_init=tl.initializers.truncated_normal(stddev=0.05),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None,  #'dorefa_dense',
    ):
        super().__init__(name, act=act)
        self.bitW = bitW
        self.bitA = bitA
        self.n_units = n_units
        self.use_gemm = use_gemm
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels is not None:
            self.build((None, self.in_channels))
            self._built = True

        logging.info(
            "DorefaDense  %s: %d %s" %
            (self.name, n_units, self.act.__name__ if self.act is not None else 'No Activation')
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1749')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/dense/dropconnect.py: 59-88
</a>
<div class="mid" id="frag1749" style="display:none"><pre>
    def __init__(
        self,
        keep=0.5,
        n_units=100,
        act=None,
        W_init=tl.initializers.truncated_normal(stddev=0.05),
        b_init=tl.initializers.constant(value=0.0),
        in_channels=None,
        name=None,  # 'dropconnect',
    ):
        super().__init__(name, act=act)

        if isinstance(keep, numbers.Real) and not (keep &gt; 0 and keep &lt;= 1):
            raise ValueError("keep must be a scalar tensor or a float in the " "range (0, 1], got %g" % keep)

        self.keep = keep
        self.n_units = n_units
        self.W_init = W_init
        self.b_init = b_init
        self.in_channels = in_channels

        if self.in_channels is not None:
            self.build((None, self.in_channels))
            self._built = True

        logging.info(
            "DropconnectDense %s: %d %s" %
            (self.name, n_units, self.act.__name__ if self.act is not None else 'No Activation')
        )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 82:</b> &nbsp; 4 fragments, nominal size 22 lines, similarity 83%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1614')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/simplified_deconv.py: 120-144
</a>
<div class="mid" id="frag1614" style="display:none"><pre>
    def build(self, inputs_shape):
        self.layer = tf.keras.layers.Conv2DTranspose(
            filters=self.n_filter,
            kernel_size=self.filter_size,
            strides=self.strides,
            padding=self.padding,
            data_format=self.data_format,
            dilation_rate=self.dilation_rate,
            activation=self.act,
            use_bias=(True if self.b_init is not None else False),
            kernel_initializer=self.W_init,
            bias_initializer=self.b_init,
            # dtype=tf.float32,
            name=self.name,
        )
        if self.data_format == "channels_first":
            self.in_channels = inputs_shape[1]
        else:
            self.in_channels = inputs_shape[-1]
        _out = self.layer(
            tf.convert_to_tensor(np.random.uniform(size=inputs_shape), dtype=np.float32)
        )  #np.random.uniform([1] + list(inputs_shape)))  # initialize weights
        outputs_shape = _out.shape
        self._trainable_weights = self.layer.weights

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1630')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/separable_conv.py: 270-304
</a>
<div class="mid" id="frag1630" style="display:none"><pre>
    def build(self, inputs_shape):
        self.layer = tf.keras.layers.SeparableConv2D(
            filters=self.n_filter,
            kernel_size=self.filter_size,
            strides=self.strides,
            padding=self.padding,
            data_format=self.data_format,
            dilation_rate=self.dilation_rate,
            depth_multiplier=self.depth_multiplier,
            activation=self.act,
            use_bias=(True if self.b_init is not None else False),
            depthwise_initializer=self.depthwise_init,
            pointwise_initializer=self.pointwise_init,
            bias_initializer=self.b_init,
            # depthwise_regularizer=None,
            # pointwise_regularizer=None,
            # bias_regularizer=None,
            # activity_regularizer=None,
            # depthwise_constraint=None,
            # pointwise_constraint=None,
            # bias_constraint=None,
            trainable=True,
            name=self.name
        )
        if self.data_format == "channels_first":
            self.in_channels = inputs_shape[1]
        else:
            self.in_channels = inputs_shape[-1]
        # _out = self.layer(np.random.uniform([1] + list(inputs_shape)))  # initialize weights
        _out = self.layer(
            tf.convert_to_tensor(np.random.uniform(size=list(inputs_shape)), dtype=np.float)
        )  # initialize weights
        outputs_shape = _out.shape
        self._trainable_weights = self.layer.weights

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1618')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/simplified_deconv.py: 242-266
</a>
<div class="mid" id="frag1618" style="display:none"><pre>
    def build(self, inputs_shape):
        self.layer = tf.keras.layers.Conv3DTranspose(
            filters=self.n_filter,
            kernel_size=self.filter_size,
            strides=self.strides,
            padding=self.padding,
            data_format=self.data_format,
            activation=self.act,
            use_bias=(True if self.b_init is not None else False),
            kernel_initializer=self.W_init,
            bias_initializer=self.b_init,
            name=self.name,
        )
        if self.data_format == "channels_first":
            self.in_channels = inputs_shape[1]
        else:
            self.in_channels = inputs_shape[-1]

        _out = self.layer(
            tf.convert_to_tensor(np.random.uniform(size=inputs_shape), dtype=np.float32)
        )  #self.layer(np.random.uniform([1] + list(inputs_shape)))  # initialize weights
        outputs_shape = _out.shape
        # self._add_weights(self.layer.weights)
        self._trainable_weights = self.layer.weights

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1626')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/convolution/separable_conv.py: 123-159
</a>
<div class="mid" id="frag1626" style="display:none"><pre>
    def build(self, inputs_shape):
        self.layer = tf.keras.layers.SeparableConv1D(
            filters=self.n_filter,
            kernel_size=self.filter_size,
            strides=self.strides,
            padding=self.padding,
            data_format=self.data_format,
            dilation_rate=self.dilation_rate,
            depth_multiplier=self.depth_multiplier,
            activation=self.act,
            use_bias=(True if self.b_init is not None else False),
            depthwise_initializer=self.depthwise_init,
            pointwise_initializer=self.pointwise_init,
            bias_initializer=self.b_init,
            # depthwise_regularizer=None,
            # pointwise_regularizer=None,
            # bias_regularizer=None,
            # activity_regularizer=None,
            # depthwise_constraint=None,
            # pointwise_constraint=None,
            # bias_constraint=None,
            trainable=True,
            name=self.name
        )
        if self.data_format == "channels_first":
            self.in_channels = inputs_shape[1]
        else:
            self.in_channels = inputs_shape[-1]

        # _out = self.layer(np.random.uniform([1] + list(inputs_shape)))  # initialize weights
        _out = self.layer(
            tf.convert_to_tensor(np.random.uniform(size=list(inputs_shape)), dtype=np.float)
        )  # initialize weights
        outputs_shape = _out.shape
        # self._add_weights(self.layer.weights)
        self._trainable_weights = self.layer.weights

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 83:</b> &nbsp; 3 fragments, nominal size 15 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1675')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/normalization.py: 499-517
</a>
<div class="mid" id="frag1675" style="display:none"><pre>
    def _get_param_shape(self, inputs_shape):
        if self.data_format == 'channels_last':
            axis = 2
        elif self.data_format == 'channels_first':
            axis = 1
        else:
            raise ValueError('data_format should be either %s or %s' % ('channels_last', 'channels_first'))

        if self.num_features is None:
            channels = inputs_shape[axis]
        else:
            channels = self.num_features
        params_shape = [1] * 3
        params_shape[axis] = channels

        axes = [i for i in range(3) if i != 0 and i != axis]
        return params_shape, axes


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1676')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/normalization.py: 536-554
</a>
<div class="mid" id="frag1676" style="display:none"><pre>
    def _get_param_shape(self, inputs_shape):
        if self.data_format == 'channels_last':
            axis = 3
        elif self.data_format == 'channels_first':
            axis = 1
        else:
            raise ValueError('data_format should be either %s or %s' % ('channels_last', 'channels_first'))

        if self.num_features is None:
            channels = inputs_shape[axis]
        else:
            channels = self.num_features
        params_shape = [1] * 4
        params_shape[axis] = channels

        axes = [i for i in range(4) if i != 0 and i != axis]
        return params_shape, axes


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1677')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/normalization.py: 573-592
</a>
<div class="mid" id="frag1677" style="display:none"><pre>
    def _get_param_shape(self, inputs_shape):
        if self.data_format == 'channels_last':
            axis = 4
        elif self.data_format == 'channels_first':
            axis = 1
        else:
            raise ValueError('data_format should be either %s or %s' % ('channels_last', 'channels_first'))

        if self.num_features is None:
            channels = inputs_shape[axis]
        else:
            channels = self.num_features
        params_shape = [1] * 5
        params_shape[axis] = channels

        axes = [i for i in range(5) if i != 0 and i != axis]
        return params_shape, axes


# FIXME : not sure about the correctness, need testing
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 84:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1733')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/stack.py: 40-51
</a>
<div class="mid" id="frag1733" style="display:none"><pre>
    def __init__(
        self,
        axis=1,
        name=None,  #'stack',
    ):
        super().__init__(name)
        self.axis = axis

        self.build(None)
        self._built = True
        logging.info("Stack %s: axis: %d" % (self.name, self.axis))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1769')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/merge.py: 42-55
</a>
<div class="mid" id="frag1769" style="display:none"><pre>
    def __init__(
        self,
        concat_dim=-1,
        name=None,  #'concat',
    ):

        super(Concat, self).__init__(name)
        self.concat_dim = concat_dim

        self.build(None)
        self._built = True

        logging.info("Concat %s: concat_dim: %d" % (self.name, concat_dim))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 85:</b> &nbsp; 3 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1742')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/dense/dorefa_dense.py: 77-87
</a>
<div class="mid" id="frag1742" style="display:none"><pre>
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = ('{classname}(n_units={n_units}, ' + actstr)
        s += ', bitW={bitW}, bitA={bitA}'
        if self.in_channels is not None:
            s += ', in_channels=\'{in_channels}\''
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1754')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/dense/quan_dense.py: 75-85
</a>
<div class="mid" id="frag1754" style="display:none"><pre>
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = ('{classname}(n_units={n_units}, ' + actstr)
        s += ', bitW={bitW}, bitA={bitA}'
        if self.in_channels is not None:
            s += ', in_channels=\'{in_channels}\''
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1750')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/dense/dropconnect.py: 89-99
</a>
<div class="mid" id="frag1750" style="display:none"><pre>
    def __repr__(self):
        actstr = self.act.__name__ if self.act is not None else 'No Activation'
        s = ('{classname}(n_units={n_units}, ' + actstr)
        s += ', keep={keep}'
        if self.in_channels is not None:
            s += ', in_channels=\'{in_channels}\''
        if self.name is not None:
            s += ', name=\'{name}\''
        s += ')'
        return s.format(classname=self.__class__.__name__, **self.__dict__)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 86:</b> &nbsp; 4 fragments, nominal size 11 lines, similarity 81%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1743')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/dense/dorefa_dense.py: 88-102
</a>
<div class="mid" id="frag1743" style="display:none"><pre>
    def build(self, inputs_shape):
        if len(inputs_shape) != 2:
            raise Exception("The input dimension must be rank 2, please reshape or flatten it")

        if self.in_channels is None:
            self.in_channels = inputs_shape[1]

        if self.use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        n_in = inputs_shape[-1]
        self.W = self._get_weights("weights", shape=(n_in, self.n_units), init=self.W_init)
        if self.b_init is not None:
            self.b = self._get_weights("biases", shape=(self.n_units), init=self.b_init)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1755')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/dense/quan_dense.py: 86-100
</a>
<div class="mid" id="frag1755" style="display:none"><pre>
    def build(self, inputs_shape):
        if len(inputs_shape) != 2:
            raise Exception("The input dimension must be rank 2, please reshape or flatten it")

        if self.in_channels is None:
            self.in_channels = inputs_shape[1]

        if self.use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        n_in = inputs_shape[-1]
        self.W = self._get_weights("weights", shape=(n_in, self.n_units), init=self.W_init)
        if self.b_init is not None:
            self.b = self._get_weights("biases", shape=int(self.n_units), init=self.b_init)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1747')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/dense/ternary_dense.py: 78-93
</a>
<div class="mid" id="frag1747" style="display:none"><pre>
    def build(self, inputs_shape):
        if len(inputs_shape) != 2:
            raise Exception("The input dimension must be rank 2, please reshape or flatten it")

        if self.in_channels is None:
            self.in_channels = inputs_shape[1]

        if self.use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        n_in = inputs_shape[-1]

        self.W = self._get_weights(var_name="weights", shape=(n_in, self.n_units), init=self.W_init)
        if self.b_init is not None:
            self.b = self._get_weights(var_name="biases", shape=(self.n_units), init=self.b_init)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1763')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/dense/binary_dense.py: 78-92
</a>
<div class="mid" id="frag1763" style="display:none"><pre>
    def build(self, inputs_shape):
        if len(inputs_shape) != 2:
            raise Exception("The input dimension must be rank 2, please reshape or flatten it")

        if self.in_channels is None:
            self.in_channels = inputs_shape[1]

        if self.use_gemm:
            raise Exception("TODO. The current version use tf.matmul for inferencing.")

        n_in = inputs_shape[-1]
        self.W = self._get_weights("weights", shape=(n_in, self.n_units), init=self.W_init)
        if self.b_init is not None:
            self.b = self._get_weights("biases", shape=(self.n_units), init=self.b_init)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 87:</b> &nbsp; 2 fragments, nominal size 20 lines, similarity 71%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1804')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/recurrent.py: 140-162
</a>
<div class="mid" id="frag1804" style="display:none"><pre>
    def __init__(
        self,
        cell,
        return_last_output=False,
        return_seq_2d=False,
        return_last_state=True,
        in_channels=None,
        name=None,  # 'rnn'
    ):

        super(RNN, self).__init__(name=name)

        self.cell = cell
        self.return_last_output = return_last_output
        self.return_seq_2d = return_seq_2d
        self.return_last_state = return_last_state

        if in_channels is not None:
            self.build((None, None, in_channels))
            self._built = True

        logging.info("RNN %s: cell: %s, n_units: %s" % (self.name, self.cell.__class__.__name__, self.cell.units))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1811')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/recurrent.py: 634-660
</a>
<div class="mid" id="frag1811" style="display:none"><pre>
    def __init__(
        self,
        fw_cell,
        bw_cell,
        return_seq_2d=False,
        return_last_state=False,
        in_channels=None,
        name=None,  # 'birnn'
    ):
        super(BiRNN, self).__init__(name)

        self.fw_cell = fw_cell
        self.bw_cell = bw_cell
        self.return_seq_2d = return_seq_2d
        self.return_last_state = return_last_state

        if in_channels is not None:
            self.build((None, None, in_channels))
            self._built = True

        logging.info(
            "BiRNN %s: fw_cell: %s, fw_n_units: %s, bw_cell: %s, bw_n_units %s" % (
                self.name, self.fw_cell.__class__.__name__, self.fw_cell.units, self.bw_cell.__class__.__name__,
                self.bw_cell.units
            )
        )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 88:</b> &nbsp; 3 fragments, nominal size 13 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1808')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/recurrent.py: 390-405
</a>
<div class="mid" id="frag1808" style="display:none"><pre>
    def __init__(
        self,
        units,
        return_last_output=False,
        return_seq_2d=False,
        return_last_state=True,
        in_channels=None,
        name=None,  # 'simplernn'
        **kwargs
    ):
        super(SimpleRNN, self).__init__(
            cell=tf.keras.layers.SimpleRNNCell(units=units, **kwargs), return_last_output=return_last_output,
            return_seq_2d=return_seq_2d, return_last_state=return_last_state, in_channels=in_channels, name=name
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1810')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/recurrent.py: 546-561
</a>
<div class="mid" id="frag1810" style="display:none"><pre>
    def __init__(
        self,
        units,
        return_last_output=False,
        return_seq_2d=False,
        return_last_state=True,
        in_channels=None,
        name=None,  # 'lstmrnn'
        **kwargs
    ):
        super(LSTMRNN, self).__init__(
            cell=tf.keras.layers.LSTMCell(units=units, **kwargs), return_last_output=return_last_output,
            return_seq_2d=return_seq_2d, return_last_state=return_last_state, in_channels=in_channels, name=name
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1809')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/recurrent.py: 468-483
</a>
<div class="mid" id="frag1809" style="display:none"><pre>
    def __init__(
        self,
        units,
        return_last_output=False,
        return_seq_2d=False,
        return_last_state=True,
        in_channels=None,
        name=None,  # 'grurnn'
        **kwargs
    ):
        super(GRURNN, self).__init__(
            cell=tf.keras.layers.GRUCell(units=units, **kwargs), return_last_output=return_last_output,
            return_seq_2d=return_seq_2d, return_last_state=return_last_state, in_channels=in_channels, name=name
        )


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 89:</b> &nbsp; 7 fragments, nominal size 18 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1819')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/pooling.py: 61-82
</a>
<div class="mid" id="frag1819" style="display:none"><pre>
    def __init__(
        self,
        filter_size=(1, 2, 2, 1),
        strides=(1, 2, 2, 1),
        padding='SAME',
        pool=tf.nn.max_pool,
        name=None  # 'pool_pro',
    ):
        super().__init__(name)
        self.filter_size = filter_size
        self.strides = strides
        self.padding = padding
        self.pool = pool

        self.build()
        self._built = True

        logging.info(
            "PoolLayer %s: filter_size: %s strides: %s padding: %s pool: %s" %
            (self.name, str(self.filter_size), str(self.strides), self.padding, pool.__name__)
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1843')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/pooling.py: 527-548
</a>
<div class="mid" id="frag1843" style="display:none"><pre>
    def __init__(
        self,
        filter_size=(3, 3, 3),
        strides=(2, 2, 2),
        padding='VALID',
        data_format='channels_last',
        name=None  # 'meanpool3d'
    ):
        super().__init__(name)
        self.filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.data_format = data_format

        self.build()
        self._built = True

        logging.info(
            "MeanPool3d %s: filter_size: %s strides: %s padding: %s" %
            (self.name, str(filter_size), str(strides), str(padding))
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1839')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/pooling.py: 446-467
</a>
<div class="mid" id="frag1839" style="display:none"><pre>
    def __init__(
        self,
        filter_size=(3, 3, 3),
        strides=(2, 2, 2),
        padding='VALID',
        data_format='channels_last',
        name=None  # 'maxpool3d'
    ):
        super().__init__(name)
        self.filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.data_format = data_format

        self.build()
        self._built = True

        logging.info(
            "MaxPool3d %s: filter_size: %s strides: %s padding: %s" %
            (self.name, str(filter_size), str(strides), str(padding))
        )

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1823')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/pooling.py: 124-147
</a>
<div class="mid" id="frag1823" style="display:none"><pre>
    def __init__(
        self,
        filter_size=3,
        strides=2,
        padding='SAME',
        data_format='channels_last',
        dilation_rate=1,
        name=None  # 'maxpool1d'
    ):
        super().__init__(name)
        self.filter_size = self._filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = self._dilation_rate = dilation_rate

        self.build()
        self._built = True

        logging.info(
            "MaxPool1d %s: filter_size: %s strides: %s padding: %s" %
            (self.name, str(filter_size), str(strides), str(padding))
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1831')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/pooling.py: 295-318
</a>
<div class="mid" id="frag1831" style="display:none"><pre>
    def __init__(
        self,
        filter_size=(3, 3),
        strides=(2, 2),
        padding='SAME',
        data_format='channels_last',
        name=None  # 'maxpool2d'
    ):
        super().__init__(name)
        self.filter_size = filter_size
        if strides is None:
            strides = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.data_format = data_format

        self.build()
        self._built = True

        logging.info(
            "MaxPool2d %s: filter_size: %s strides: %s padding: %s" %
            (self.name, str(filter_size), str(strides), str(padding))
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1827')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/pooling.py: 209-232
</a>
<div class="mid" id="frag1827" style="display:none"><pre>
    def __init__(
        self,
        filter_size=3,
        strides=2,
        padding='SAME',
        data_format='channels_last',
        dilation_rate=1,
        name=None  # 'meanpool1d'
    ):
        super().__init__(name)
        self.filter_size = self._filter_size = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = self._dilation_rate = dilation_rate

        self.build()
        self._built = True

        logging.info(
            "MeanPool1d %s: filter_size: %s strides: %s padding: %s" %
            (self.name, str(filter_size), str(strides), str(padding))
        )

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1835')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/pooling.py: 368-391
</a>
<div class="mid" id="frag1835" style="display:none"><pre>
    def __init__(
        self,
        filter_size=(3, 3),
        strides=(2, 2),
        padding='SAME',
        data_format='channels_last',
        name=None  # 'meanpool2d'
    ):
        super().__init__(name)
        self.filter_size = filter_size
        if strides is None:
            strides = filter_size
        self.strides = self._strides = strides
        self.padding = padding
        self.data_format = data_format

        self.build()
        self._built = True

        logging.info(
            "MeanPool2d %s: filter_size: %s strides: %s padding: %s" %
            (self.name, str(filter_size), str(strides), str(padding))
        )

</pre></div>
</td>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 90:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1825')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/pooling.py: 157-168
</a>
<div class="mid" id="frag1825" style="display:none"><pre>
    def build(self, inputs_shape=None):
        # https://tensorflow.google.cn/versions/r2.0/api_docs/python/tf/nn/pool
        if self.data_format == 'channels_last':
            self.data_format = 'NWC'
        elif self.data_format == 'channels_first':
            self.data_format = 'NCW'
        else:
            raise Exception("unsupported data format")
        self._filter_size = [self.filter_size]
        self._strides = [self.strides]
        self._dilation_rate = [self.dilation_rate]

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1829')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/pooling.py: 242-254
</a>
<div class="mid" id="frag1829" style="display:none"><pre>
    def build(self, inputs_shape=None):
        # pass
        # https://tensorflow.google.cn/versions/r2.0/api_docs/python/tf/nn/pool
        if self.data_format == 'channels_last':
            self.data_format = 'NWC'
        elif self.data_format == 'channels_first':
            self.data_format = 'NCW'
        else:
            raise Exception("unsupported data format")
        self._filter_size = [self.filter_size]
        self._strides = [self.strides]
        self._dilation_rate = [self.dilation_rate]

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 91:</b> &nbsp; 7 fragments, nominal size 10 lines, similarity 90%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1847')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/pooling.py: 597-610
</a>
<div class="mid" id="frag1847" style="display:none"><pre>
    def __init__(
        self,
        data_format="channels_last",
        name=None  # 'globalmaxpool1d'
    ):
        super().__init__(name)

        self.data_format = data_format

        self.build()
        self._built = True

        logging.info("GlobalMaxPool1d %s" % self.name)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1867')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/pooling.py: 875-887
</a>
<div class="mid" id="frag1867" style="display:none"><pre>
    def __init__(
        self,
        data_format='channels_last',
        name=None  # 'globalmeanpool3d'
    ):
        super().__init__(name)
        self.data_format = data_format

        self.build()
        self._built = True

        logging.info("GlobalMeanPool3d %s" % self.name)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1855')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/pooling.py: 708-720
</a>
<div class="mid" id="frag1855" style="display:none"><pre>
    def __init__(
        self,
        data_format='channels_last',
        name=None  # 'globalmaxpool2d'
    ):
        super().__init__(name)
        self.data_format = data_format

        self.build()
        self._built = True

        logging.info("GlobalMaxPool2d %s" % self.name)

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1859')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/pooling.py: 763-776
</a>
<div class="mid" id="frag1859" style="display:none"><pre>
    def __init__(
        self,
        data_format='channels_last',
        name=None  # 'globalmeanpool2d'
    ):
        super().__init__(name)

        self.data_format = data_format

        self.build()
        self._built = True

        logging.info("GlobalMeanPool2d %s" % self.name)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1851')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/pooling.py: 653-665
</a>
<div class="mid" id="frag1851" style="display:none"><pre>
    def __init__(
        self,
        data_format='channels_last',
        name=None  # 'globalmeanpool1d'
    ):
        super().__init__(name)
        self.data_format = data_format

        self.build()
        self._built = True

        logging.info("GlobalMeanPool1d %s" % self.name)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1863')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/pooling.py: 819-832
</a>
<div class="mid" id="frag1863" style="display:none"><pre>
    def __init__(
        self,
        data_format='channels_last',
        name=None  # 'globalmaxpool3d'
    ):
        super().__init__(name)

        self.data_format = data_format

        self.build()
        self._built = True

        logging.info("GlobalMaxPool3d %s" % self.name)

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1871')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/pooling.py: 931-942
</a>
<div class="mid" id="frag1871" style="display:none"><pre>
    def __init__(
        self,
        mode='TopLeft',
        name=None  # 'cornerpool2d'
    ):
        super().__init__(name)
        self.mode = mode
        self.build()
        self._built = True

        logging.info("CornerPool2d %s : mode: %s" % (self.name, str(mode)))

</pre></div>
</td>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 92:</b> &nbsp; 3 fragments, nominal size 12 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1879')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/padding.py: 101-115
</a>
<div class="mid" id="frag1879" style="display:none"><pre>
    def __init__(
        self,
        padding,
        name=None,  # 'zeropad1d',
    ):
        super().__init__(name)
        self.padding = padding
        logging.info("ZeroPad1d   %s: padding: %s" % (self.name, str(padding)))

        if not isinstance(self.padding, (int, tuple, dict)):
            raise AssertionError()

        self.build()
        self._built = True

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1883')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/padding.py: 155-170
</a>
<div class="mid" id="frag1883" style="display:none"><pre>
    def __init__(
        self,
        padding,
        name=None,  # 'zeropad2d',
    ):
        super().__init__(name)

        self.padding = padding
        logging.info("ZeroPad2d   %s: padding: %s" % (self.name, str(self.padding)))

        if not isinstance(self.padding, (int, tuple)):
            raise AssertionError("Padding should be of type `int` or `tuple`")

        self.build()
        self._built = True

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1887')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/padding.py: 210-225
</a>
<div class="mid" id="frag1887" style="display:none"><pre>
    def __init__(
        self,
        padding,
        name=None,  # 'zeropad3d',
    ):
        super().__init__(name)
        self.padding = padding

        logging.info("ZeroPad3d   %s: padding: %s" % (self.name, str(self.padding)))

        if not isinstance(self.padding, (int, tuple)):
            raise AssertionError()

        self.build()
        self._built = True

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 93:</b> &nbsp; 2 fragments, nominal size 19 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1891')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/image_resampling.py: 48-72
</a>
<div class="mid" id="frag1891" style="display:none"><pre>
    def __init__(
        self,
        scale,
        method='bilinear',
        antialias=False,
        data_format='channel_last',
        name=None,
    ):
        super(UpSampling2d, self).__init__(name)
        self.method = method
        self.antialias = antialias
        self.data_format = data_format

        logging.info(
            "UpSampling2d %s: scale: %s method: %s antialias: %s" % (self.name, scale, self.method, self.antialias)
        )

        self.build(None)
        self._built = True

        if isinstance(scale, (list, tuple)) and len(scale) != 2:
            raise ValueError("scale must be int or tuple/list of length 2")

        self.scale = (scale, scale) if isinstance(scale, int) else scale

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1895')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/image_resampling.py: 129-153
</a>
<div class="mid" id="frag1895" style="display:none"><pre>
    def __init__(
        self,
        scale,
        method='bilinear',
        antialias=False,
        data_format='channel_last',
        name=None,
    ):
        super(DownSampling2d, self).__init__(name)
        self.method = method
        self.antialias = antialias
        self.data_format = data_format

        logging.info(
            "DownSampling2d %s: scale: %s method: %s antialias: %s" % (self.name, scale, self.method, self.antialias)
        )

        self.build(None)
        self._built = True

        if isinstance(scale, (list, tuple)) and len(scale) != 2:
            raise ValueError("scale must be int or tuple/list of length 2")

        self.scale = (scale, scale) if isinstance(scale, int) else scale

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 94:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 80%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1899')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/extend.py: 35-47
</a>
<div class="mid" id="frag1899" style="display:none"><pre>
    def __init__(
        self,
        axis,
        name=None  # 'expand_dims',
    ):
        super(ExpandDims, self).__init__(name)
        self.axis = axis

        self.build((None, ))
        self._built = True

        logging.info("ExpandDims  %s: axis: %d" % (self.name, self.axis))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1923')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/scale.py: 35-47
</a>
<div class="mid" id="frag1923" style="display:none"><pre>
    def __init__(
        self,
        init_scale=0.05,
        name='scale',
    ):
        super(Scale, self).__init__(name)
        self.init_scale = init_scale

        self.build((None, ))
        self._built = True

        logging.info("Scale  %s: init_scale: %f" % (self.name, self.init_scale))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 95:</b> &nbsp; 3 fragments, nominal size 18 lines, similarity 94%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1907')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/activation.py: 56-77
</a>
<div class="mid" id="frag1907" style="display:none"><pre>
    def __init__(
        self,
        channel_shared=False,
        in_channels=None,
        a_init=truncated_normal(mean=0.0, stddev=0.05),
        name=None  # "prelu"
    ):

        super(PRelu, self).__init__(name)
        self.channel_shared = channel_shared
        self.in_channels = in_channels
        self.a_init = a_init

        if self.channel_shared:
            self.build((None, ))
            self._built = True
        elif self.in_channels is not None:
            self.build((None, self.in_channels))
            self._built = True

        logging.info("PRelu %s: channel_shared: %s" % (self.name, self.channel_shared))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1915')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/activation.py: 231-252
</a>
<div class="mid" id="frag1915" style="display:none"><pre>
    def __init__(
        self,
        channel_shared=False,
        in_channels=None,
        a_init=truncated_normal(mean=0.0, stddev=0.05),
        name=None  # "ptrelu6"
    ):

        super(PTRelu6, self).__init__(name)
        self.channel_shared = channel_shared
        self.in_channels = in_channels
        self.a_init = a_init

        if self.channel_shared:
            self.build((None, ))
            self._built = True
        elif self.in_channels:
            self.build((None, self.in_channels))
            self._built = True

        logging.info("PTRelu6 %s: channel_shared: %s" % (self.name, self.channel_shared))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1911')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/activation.py: 143-164
</a>
<div class="mid" id="frag1911" style="display:none"><pre>
    def __init__(
        self,
        channel_shared=False,
        in_channels=None,
        a_init=truncated_normal(mean=0.0, stddev=0.05),
        name=None  # "prelu6"
    ):

        super(PRelu6, self).__init__(name)
        self.channel_shared = channel_shared
        self.in_channels = in_channels
        self.a_init = a_init

        if self.channel_shared:
            self.build((None, ))
            self._built = True
        elif self.in_channels is not None:
            self.build((None, self.in_channels))
            self._built = True

        logging.info("PRelu6 %s: channel_shared: %s" % (self.name, self.channel_shared))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 96:</b> &nbsp; 2 fragments, nominal size 19 lines, similarity 89%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2001')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/lambda_layers.py: 104-125
</a>
<div class="mid" id="frag2001" style="display:none"><pre>
    def __init__(
        self,
        fn,
        fn_weights=None,
        fn_args=None,
        name=None,
    ):

        super(Lambda, self).__init__(name=name)
        self.fn = fn
        self._trainable_weights = fn_weights if fn_weights is not None else []
        self.fn_args = fn_args if fn_args is not None else {}

        try:
            fn_name = repr(self.fn)
        except:
            fn_name = 'name not available'
        logging.info("Lambda  %s: func: %s, len_weights: %s" % (self.name, fn_name, len(self._trainable_weights)))

        self.build()
        self._built = True

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2006')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/lambda_layers.py: 226-249
</a>
<div class="mid" id="frag2006" style="display:none"><pre>
    def __init__(
        self,
        fn,
        fn_weights=None,
        fn_args=None,
        name=None,  #'elementwiselambda',
    ):

        super(ElementwiseLambda, self).__init__(name=name)
        self.fn = fn
        self._trainable_weights = fn_weights if fn_weights is not None else []
        self.fn_args = fn_args if fn_args is not None else {}

        try:
            fn_name = repr(self.fn)
        except:
            fn_name = 'name not available'
        logging.info(
            "ElementwiseLambda  %s: func: %s, len_weights: %s" % (self.name, fn_name, len(self._trainable_weights))
        )

        self.build()
        self._built = True

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 97:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2002')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/lambda_layers.py: 126-140
</a>
<div class="mid" id="frag2002" style="display:none"><pre>
    def __repr__(self):
        s = '{classname}('
        s += 'fn={fn_name},'
        s += 'len_weights={len_weights},'
        s += 'name=\'{name}\''
        s += ')'
        try:
            fn_name = repr(self.fn)
        except:
            fn_name = 'name not available'
        return s.format(
            classname=self.__class__.__name__, fn_name=fn_name, len_weights=len(self._trainable_weights),
            **self.__dict__
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2007')" href="javascript:;">
TensorLayer-2.2.1/tensorlayer/layers/lambda_layers.py: 250-264
</a>
<div class="mid" id="frag2007" style="display:none"><pre>
    def __repr__(self):
        s = '{classname}('
        s += 'fn={fn_name},'
        s += 'len_weights={len_weights},'
        s += 'name=\'{name}\''
        s += ')'
        try:
            fn_name = repr(self.fn)
        except:
            fn_name = 'name not available'
        return s.format(
            classname=self.__class__.__name__, fn_name=fn_name, len_weights=len(self._trainable_weights),
            **self.__dict__
        )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<script language="JavaScript">
function ShowHide(divId) { 
    if(document.getElementById(divId).style.display == 'none') {
        document.getElementById(divId).style.display='block';
    } else { 
        document.getElementById(divId).style.display = 'none';
    } 
}
</script>
</body>
</html>
