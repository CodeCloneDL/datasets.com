<html>
<head>
    <title>NiCad6 Clone Report</title>
    <style type="text/css">
        body {font-family:sans-serif;}
        table {background-color:white; border:0px; padding:0px; border-spacing:4px; width:auto; margin-left:30px; margin-right:auto;}
        td {background-color:rgba(192,212,238,0.8); border:0px; padding:8px; width:auto; vertical-align:top; border-radius:8px}
        pre {background-color:white; padding:4px;}
        a {color:darkblue;}
    </style>
</head>
<body>
<h2>NiCad6 Clone Report</h2>
<table>
<tr style="font-size:14pt">
<td><b>System:</b> &nbsp; allennlp-2.4.0</td>
<td><b>Clone pairs:</b> &nbsp; 299</td>
<td><b>Clone classes:</b> &nbsp; 73</td>
</tr>
<tr style="font-size:12pt">
<td style="background-color:white">Clone type: &nbsp; 3-2</td>
<td style="background-color:white">Granularity: &nbsp; functions-blind</td>
<td style="background-color:white">Max diff threshold: &nbsp; 30%</td>
<td style="background-color:white">Clone size: &nbsp; 10 - 2500 lines</td>
<td style="background-color:white">Total functions-blind: &nbsp; 1392</td>
</tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 1:</b> &nbsp; 2 fragments, nominal size 20 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag15')" href="javascript:;">
allennlp-2.4.0/scripts/tests/ai2_internal/resume_daemon_test.py: 69-91
</a>
<div class="mid" id="frag15" style="display:none"><pre>
    def test_respects_upper_bound_on_resumes(self):
        beaker = Mock()
        experiment_id = "foo"
        start_autoresume(self.connection, experiment_id, 5)
        beaker.get_status.return_value = BeakerStatus.preempted
        for i in range(10):
            beaker.resume.return_value = f"foo{i}"
            resume(self.connection, beaker)
        calls = [
            call.get_status("foo"),
            call.resume("foo"),
            call.get_status("foo0"),
            call.resume("foo0"),
            call.get_status("foo1"),
            call.resume("foo1"),
            call.get_status("foo2"),
            call.resume("foo2"),
            call.get_status("foo3"),
            call.resume("foo3"),
            call.get_status("foo4"),
        ]
        beaker.assert_has_calls(calls)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag16')" href="javascript:;">
allennlp-2.4.0/scripts/tests/ai2_internal/resume_daemon_test.py: 92-109
</a>
<div class="mid" id="frag16" style="display:none"><pre>
    def test_handles_a_realistic_scenario(self):
        beaker = Mock()
        experiment_id = "foo"
        start_autoresume(self.connection, experiment_id, 5)
        beaker.get_status.return_value = BeakerStatus.preempted
        for i in range(10):
            beaker.resume.return_value = f"foo{i}"
            if i == 2:
                beaker.get_status.return_value = BeakerStatus.succeeded
            resume(self.connection, beaker)
        calls = [
            call.get_status("foo"),
            call.resume("foo"),
            call.get_status("foo0"),
            call.resume("foo0"),
            call.get_status("foo1"),
        ]
        beaker.assert_has_calls(calls)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 2:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 83%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag31')" href="javascript:;">
allennlp-2.4.0/allennlp/training/momentum_schedulers/inverted_triangular.py: 21-33
</a>
<div class="mid" id="frag31" style="display:none"><pre>
    def __init__(
        self,
        optimizer: torch.optim.Optimizer,
        cool_down: int,
        warm_up: int,
        ratio: int = 10,
        last_epoch: int = -1,
    ) -&gt; None:
        self.cool_down = cool_down
        self.warm_up = warm_up
        self.ratio = ratio
        super().__init__(optimizer, last_epoch)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag41')" href="javascript:;">
allennlp-2.4.0/allennlp/training/learning_rate_schedulers/noam.py: 29-41
</a>
<div class="mid" id="frag41" style="display:none"><pre>
    def __init__(
        self,
        optimizer: torch.optim.Optimizer,
        model_size: int,
        warmup_steps: int,
        factor: float = 1.0,
        last_epoch: int = -1,
    ) -&gt; None:
        self.warmup_steps = warmup_steps
        self.factor = factor
        self.model_size = model_size
        super().__init__(optimizer, last_epoch=last_epoch)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 3:</b> &nbsp; 14 fragments, nominal size 18 lines, similarity 71%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag59')" href="javascript:;">
allennlp-2.4.0/allennlp/training/learning_rate_schedulers/learning_rate_scheduler.py: 174-191
</a>
<div class="mid" id="frag59" style="display:none"><pre>
    def __init__(
        self,
        optimizer: Optimizer,
        num_warmup_steps: int,
        num_training_steps: int,
        num_cycles: float = 0.5,
        last_epoch: int = -1,
    ) -&gt; None:
        lr_scheduler = get_cosine_schedule_with_warmup(
            optimizer=optimizer,
            num_warmup_steps=num_warmup_steps,
            num_training_steps=num_training_steps,
            num_cycles=num_cycles,
            last_epoch=last_epoch,
        )
        super().__init__(lr_scheduler)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag420')" href="javascript:;">
allennlp-2.4.0/allennlp/modules/seq2vec_encoders/pytorch_seq2vec_wrapper.py: 208-227
</a>
<div class="mid" id="frag420" style="display:none"><pre>
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        go_forward: bool = True,
        recurrent_dropout_probability: float = 0.0,
        use_highway: bool = True,
        use_input_projection_bias: bool = True,
    ) -&gt; None:
        module = AugmentedLstm(
            input_size=input_size,
            hidden_size=hidden_size,
            go_forward=go_forward,
            recurrent_dropout_probability=recurrent_dropout_probability,
            use_highway=use_highway,
            use_input_projection_bias=use_input_projection_bias,
        )
        super().__init__(module=module)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag422')" href="javascript:;">
allennlp-2.4.0/allennlp/modules/seq2vec_encoders/pytorch_seq2vec_wrapper.py: 260-277
</a>
<div class="mid" id="frag422" style="display:none"><pre>
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        num_layers: int,
        recurrent_dropout_probability: float = 0.0,
        layer_dropout_probability: float = 0.0,
        use_highway: bool = True,
    ) -&gt; None:
        module = StackedBidirectionalLstm(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            recurrent_dropout_probability=recurrent_dropout_probability,
            layer_dropout_probability=layer_dropout_probability,
            use_highway=use_highway,
        )
        super().__init__(module=module)
</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag421')" href="javascript:;">
allennlp-2.4.0/allennlp/modules/seq2vec_encoders/pytorch_seq2vec_wrapper.py: 234-253
</a>
<div class="mid" id="frag421" style="display:none"><pre>
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        num_layers: int,
        recurrent_dropout_probability: float = 0.0,
        use_highway: bool = True,
        use_input_projection_bias: bool = True,
    ) -&gt; None:
        module = StackedAlternatingLstm(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            recurrent_dropout_probability=recurrent_dropout_probability,
            use_highway=use_highway,
            use_input_projection_bias=use_input_projection_bias,
        )
        super().__init__(module=module)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag453')" href="javascript:;">
allennlp-2.4.0/allennlp/modules/seq2seq_encoders/pytorch_seq2seq_wrapper.py: 249-269
</a>
<div class="mid" id="frag453" style="display:none"><pre>
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        num_layers: int,
        recurrent_dropout_probability: float = 0.0,
        use_highway: bool = True,
        use_input_projection_bias: bool = True,
        stateful: bool = False,
    ) -&gt; None:
        module = StackedAlternatingLstm(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            recurrent_dropout_probability=recurrent_dropout_probability,
            use_highway=use_highway,
            use_input_projection_bias=use_input_projection_bias,
        )
        super().__init__(module=module, stateful=stateful)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag60')" href="javascript:;">
allennlp-2.4.0/allennlp/training/learning_rate_schedulers/learning_rate_scheduler.py: 199-214
</a>
<div class="mid" id="frag60" style="display:none"><pre>
    def __init__(
        self,
        optimizer: Optimizer,
        num_warmup_steps: int,
        num_training_steps: int,
        num_cycles: int = 1,
        last_epoch: int = -1,
    ) -&gt; None:
        lr_scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(
            optimizer=optimizer,
            num_warmup_steps=num_warmup_steps,
            num_training_steps=num_training_steps,
            num_cycles=num_cycles,
            last_epoch=last_epoch,
        )
        super().__init__(lr_scheduler)
</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag454')" href="javascript:;">
allennlp-2.4.0/allennlp/modules/seq2seq_encoders/pytorch_seq2seq_wrapper.py: 276-294
</a>
<div class="mid" id="frag454" style="display:none"><pre>
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        num_layers: int,
        recurrent_dropout_probability: float = 0.0,
        layer_dropout_probability: float = 0.0,
        use_highway: bool = True,
        stateful: bool = False,
    ) -&gt; None:
        module = StackedBidirectionalLstm(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            recurrent_dropout_probability=recurrent_dropout_probability,
            layer_dropout_probability=layer_dropout_probability,
            use_highway=use_highway,
        )
        super().__init__(module=module, stateful=stateful)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag417')" href="javascript:;">
allennlp-2.4.0/allennlp/modules/seq2vec_encoders/pytorch_seq2vec_wrapper.py: 125-145
</a>
<div class="mid" id="frag417" style="display:none"><pre>
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        num_layers: int = 1,
        bias: bool = True,
        dropout: float = 0.0,
        bidirectional: bool = False,
    ):
        module = torch.nn.GRU(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            bias=bias,
            batch_first=True,
            dropout=dropout,
            bidirectional=bidirectional,
        )
        super().__init__(module=module)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag452')" href="javascript:;">
allennlp-2.4.0/allennlp/modules/seq2seq_encoders/pytorch_seq2seq_wrapper.py: 222-242
</a>
<div class="mid" id="frag452" style="display:none"><pre>
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        go_forward: bool = True,
        recurrent_dropout_probability: float = 0.0,
        use_highway: bool = True,
        use_input_projection_bias: bool = True,
        stateful: bool = False,
    ) -&gt; None:
        module = AugmentedLstm(
            input_size=input_size,
            hidden_size=hidden_size,
            go_forward=go_forward,
            recurrent_dropout_probability=recurrent_dropout_probability,
            use_highway=use_highway,
            use_input_projection_bias=use_input_projection_bias,
        )
        super().__init__(module=module, stateful=stateful)


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag419')" href="javascript:;">
allennlp-2.4.0/allennlp/modules/seq2vec_encoders/pytorch_seq2vec_wrapper.py: 179-201
</a>
<div class="mid" id="frag419" style="display:none"><pre>
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        num_layers: int = 1,
        nonlinearity: str = "tanh",
        bias: bool = True,
        dropout: float = 0.0,
        bidirectional: bool = False,
    ):
        module = torch.nn.RNN(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            nonlinearity=nonlinearity,
            bias=bias,
            batch_first=True,
            dropout=dropout,
            bidirectional=bidirectional,
        )
        super().__init__(module=module)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag450')" href="javascript:;">
allennlp-2.4.0/allennlp/modules/seq2seq_encoders/pytorch_seq2seq_wrapper.py: 164-185
</a>
<div class="mid" id="frag450" style="display:none"><pre>
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        num_layers: int = 1,
        bias: bool = True,
        dropout: float = 0.0,
        bidirectional: bool = False,
        stateful: bool = False,
    ):
        module = torch.nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            bias=bias,
            batch_first=True,
            dropout=dropout,
            bidirectional=bidirectional,
        )
        super().__init__(module=module, stateful=stateful)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag449')" href="javascript:;">
allennlp-2.4.0/allennlp/modules/seq2seq_encoders/pytorch_seq2seq_wrapper.py: 136-157
</a>
<div class="mid" id="frag449" style="display:none"><pre>
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        num_layers: int = 1,
        bias: bool = True,
        dropout: float = 0.0,
        bidirectional: bool = False,
        stateful: bool = False,
    ):
        module = torch.nn.GRU(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            bias=bias,
            batch_first=True,
            dropout=dropout,
            bidirectional=bidirectional,
        )
        super().__init__(module=module, stateful=stateful)


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag418')" href="javascript:;">
allennlp-2.4.0/allennlp/modules/seq2vec_encoders/pytorch_seq2vec_wrapper.py: 152-172
</a>
<div class="mid" id="frag418" style="display:none"><pre>
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        num_layers: int = 1,
        bias: bool = True,
        dropout: float = 0.0,
        bidirectional: bool = False,
    ):
        module = torch.nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            bias=bias,
            batch_first=True,
            dropout=dropout,
            bidirectional=bidirectional,
        )
        super().__init__(module=module)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag451')" href="javascript:;">
allennlp-2.4.0/allennlp/modules/seq2seq_encoders/pytorch_seq2seq_wrapper.py: 192-215
</a>
<div class="mid" id="frag451" style="display:none"><pre>
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        num_layers: int = 1,
        nonlinearity: str = "tanh",
        bias: bool = True,
        dropout: float = 0.0,
        bidirectional: bool = False,
        stateful: bool = False,
    ):
        module = torch.nn.RNN(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            nonlinearity=nonlinearity,
            bias=bias,
            batch_first=True,
            dropout=dropout,
            bidirectional=bidirectional,
        )
        super().__init__(module=module, stateful=stateful)


</pre></div>
</td>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 4:</b> &nbsp; 2 fragments, nominal size 35 lines, similarity 86%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag312')" href="javascript:;">
allennlp-2.4.0/allennlp/modules/maxout.py: 35-76
</a>
<div class="mid" id="frag312" style="display:none"><pre>
    def __init__(
        self,
        input_dim: int,
        num_layers: int,
        output_dims: Union[int, Sequence[int]],
        pool_sizes: Union[int, Sequence[int]],
        dropout: Union[float, Sequence[float]] = 0.0,
    ) -&gt; None:
        super().__init__()
        if not isinstance(output_dims, list):
            output_dims = [output_dims] * num_layers  # type: ignore
        if not isinstance(pool_sizes, list):
            pool_sizes = [pool_sizes] * num_layers  # type: ignore
        if not isinstance(dropout, list):
            dropout = [dropout] * num_layers  # type: ignore
        if len(output_dims) != num_layers:
            raise ConfigurationError(
                "len(output_dims) (%d) != num_layers (%d)" % (len(output_dims), num_layers)
            )
        if len(pool_sizes) != num_layers:
            raise ConfigurationError(
                "len(pool_sizes) (%d) != num_layers (%d)" % (len(pool_sizes), num_layers)
            )
        if len(dropout) != num_layers:
            raise ConfigurationError(
                "len(dropout) (%d) != num_layers (%d)" % (len(dropout), num_layers)
            )

        self._pool_sizes = pool_sizes
        input_dims = [input_dim] + output_dims[:-1]
        linear_layers = []
        for layer_input_dim, layer_output_dim, pool_size in zip(
            input_dims, output_dims, pool_sizes
        ):
            linear_layers.append(torch.nn.Linear(layer_input_dim, layer_output_dim * pool_size))
        self._linear_layers = torch.nn.ModuleList(linear_layers)
        dropout_layers = [torch.nn.Dropout(p=value) for value in dropout]
        self._dropout = torch.nn.ModuleList(dropout_layers)
        self._output_dims = output_dims
        self._output_dim = output_dims[-1]
        self._input_dim = input_dim

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag399')" href="javascript:;">
allennlp-2.4.0/allennlp/modules/feedforward.py: 57-95
</a>
<div class="mid" id="frag399" style="display:none"><pre>
    def __init__(
        self,
        input_dim: int,
        num_layers: int,
        hidden_dims: Union[int, List[int]],
        activations: Union[Activation, List[Activation]],
        dropout: Union[float, List[float]] = 0.0,
    ) -&gt; None:

        super().__init__()
        if not isinstance(hidden_dims, list):
            hidden_dims = [hidden_dims] * num_layers  # type: ignore
        if not isinstance(activations, list):
            activations = [activations] * num_layers  # type: ignore
        if not isinstance(dropout, list):
            dropout = [dropout] * num_layers  # type: ignore
        if len(hidden_dims) != num_layers:
            raise ConfigurationError(
                "len(hidden_dims) (%d) != num_layers (%d)" % (len(hidden_dims), num_layers)
            )
        if len(activations) != num_layers:
            raise ConfigurationError(
                "len(activations) (%d) != num_layers (%d)" % (len(activations), num_layers)
            )
        if len(dropout) != num_layers:
            raise ConfigurationError(
                "len(dropout) (%d) != num_layers (%d)" % (len(dropout), num_layers)
            )
        self._activations = torch.nn.ModuleList(activations)
        input_dims = [input_dim] + hidden_dims[:-1]
        linear_layers = []
        for layer_input_dim, layer_output_dim in zip(input_dims, hidden_dims):
            linear_layers.append(torch.nn.Linear(layer_input_dim, layer_output_dim))
        self._linear_layers = torch.nn.ModuleList(linear_layers)
        dropout_layers = [torch.nn.Dropout(p=value) for value in dropout]
        self._dropout = torch.nn.ModuleList(dropout_layers)
        self._output_dim = hidden_dims[-1]
        self.input_dim = input_dim

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 5:</b> &nbsp; 3 fragments, nominal size 14 lines, similarity 73%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag323')" href="javascript:;">
allennlp-2.4.0/allennlp/modules/matrix_attention/linear_matrix_attention.py: 50-64
</a>
<div class="mid" id="frag323" style="display:none"><pre>
    def __init__(
        self,
        tensor_1_dim: int,
        tensor_2_dim: int,
        combination: str = "x,y",
        activation: Activation = None,
    ) -&gt; None:
        super().__init__()
        self._combination = combination
        combined_dim = util.get_combined_dim(combination, [tensor_1_dim, tensor_2_dim])
        self._weight_vector = Parameter(torch.Tensor(combined_dim))
        self._bias = Parameter(torch.Tensor(1))
        self._activation = activation or Activation.by_name("linear")()
        self.reset_parameters()

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag349')" href="javascript:;">
allennlp-2.4.0/allennlp/modules/attention/linear_attention.py: 49-64
</a>
<div class="mid" id="frag349" style="display:none"><pre>
    def __init__(
        self,
        tensor_1_dim: int,
        tensor_2_dim: int,
        combination: str = "x,y",
        activation: Activation = None,
        normalize: bool = True,
    ) -&gt; None:
        super().__init__(normalize)
        self._combination = combination
        combined_dim = util.get_combined_dim(combination, [tensor_1_dim, tensor_2_dim])
        self._weight_vector = Parameter(torch.Tensor(combined_dim))
        self._bias = Parameter(torch.Tensor(1))
        self._activation = activation or Activation.by_name("linear")()
        self.reset_parameters()

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag354')" href="javascript:;">
allennlp-2.4.0/allennlp/modules/attention/bilinear_attention.py: 36-48
</a>
<div class="mid" id="frag354" style="display:none"><pre>
    def __init__(
        self,
        vector_dim: int,
        matrix_dim: int,
        activation: Activation = None,
        normalize: bool = True,
    ) -&gt; None:
        super().__init__(normalize)
        self._weight_matrix = Parameter(torch.Tensor(vector_dim, matrix_dim))
        self._bias = Parameter(torch.Tensor(1))
        self._activation = activation or Activation.by_name("linear")()
        self.reset_parameters()

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 6:</b> &nbsp; 3 fragments, nominal size 17 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag480')" href="javascript:;">
allennlp-2.4.0/tests/training/util_test.py: 78-94
</a>
<div class="mid" id="frag480" style="display:none"><pre>
    def test_only_train_read_for_vocab(self, caplog):
        params = Params(
            {
                "dataset_reader": {"type": "train-util-test-reader"},
                "train_data_path": "path-to-training-file",
                "data_loader": {"batch_size": 2},
            }
        )
        _ = make_vocab_from_params(params, str(self.TEST_DIR))
        log_messages = "\n".join([rec.message for rec in caplog.records])
        assert "...train-util-test-reader reading from path-to-training-file" in log_messages
        assert "...train-util-test-reader reading from path-to-validation-file" not in log_messages
        assert "...train-util-test-reader reading from path-to-test-file" not in log_messages
        assert "Reading training data" in log_messages
        assert "Reading validation data" not in log_messages
        assert "Reading test data" not in log_messages

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag482')" href="javascript:;">
allennlp-2.4.0/tests/training/util_test.py: 114-133
</a>
<div class="mid" id="frag482" style="display:none"><pre>
    def test_only_specified_datasets_read_for_vocab(self, caplog):
        params = Params(
            {
                "dataset_reader": {"type": "train-util-test-reader"},
                "train_data_path": "path-to-training-file",
                "validation_data_path": "path-to-validation-file",
                "test_data_path": "path-to-test-file",
                "datasets_for_vocab_creation": ["train", "validation"],
                "data_loader": {"batch_size": 2},
            }
        )
        _ = make_vocab_from_params(params, str(self.TEST_DIR))
        log_messages = "\n".join([rec.message for rec in caplog.records])
        assert "...train-util-test-reader reading from path-to-training-file" in log_messages
        assert "...train-util-test-reader reading from path-to-validation-file" in log_messages
        assert "...train-util-test-reader reading from path-to-test-file" not in log_messages
        assert "Reading training data" in log_messages
        assert "Reading validation data" in log_messages
        assert "Reading test data" not in log_messages

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag481')" href="javascript:;">
allennlp-2.4.0/tests/training/util_test.py: 95-113
</a>
<div class="mid" id="frag481" style="display:none"><pre>
    def test_all_datasets_read_for_vocab(self, caplog):
        params = Params(
            {
                "dataset_reader": {"type": "train-util-test-reader"},
                "train_data_path": "path-to-training-file",
                "validation_data_path": "path-to-validation-file",
                "test_data_path": "path-to-test-file",
                "data_loader": {"batch_size": 2},
            }
        )
        _ = make_vocab_from_params(params, str(self.TEST_DIR))
        log_messages = "\n".join([rec.message for rec in caplog.records])
        assert "...train-util-test-reader reading from path-to-training-file" in log_messages
        assert "...train-util-test-reader reading from path-to-validation-file" in log_messages
        assert "...train-util-test-reader reading from path-to-test-file" in log_messages
        assert "Reading training data" in log_messages
        assert "Reading validation data" in log_messages
        assert "Reading test data" in log_messages

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 7:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag484')" href="javascript:;">
allennlp-2.4.0/tests/training/util_test.py: 148-160
</a>
<div class="mid" id="frag484" style="display:none"><pre>
    def test_invalid_datasets_for_vocab_creation(self):
        params = Params(
            {
                "dataset_reader": {"type": "train-util-test-reader"},
                "train_data_path": "path-to-training-file",
                "validation_data_path": "path-to-validation-file",
                "datasets_for_vocab_creation": ["train", "validation", "test"],
                "data_loader": {"batch_size": 2},
            }
        )
        with pytest.raises(ConfigurationError, match="invalid 'datasets_for_vocab_creation' test"):
            make_vocab_from_params(params, str(self.TEST_DIR))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag485')" href="javascript:;">
allennlp-2.4.0/tests/training/util_test.py: 161-175
</a>
<div class="mid" id="frag485" style="display:none"><pre>
    def test_raise_error_if_directory_non_empty(self):
        params = Params(
            {
                "dataset_reader": {"type": "train-util-test-reader"},
                "train_data_path": "path-to-training-file",
                "validation_data_path": "path-to-validation-file",
                "data_loader": {"batch_size": 2},
            }
        )
        os.makedirs(self.TEST_DIR / "vocabulary")
        with open(self.TEST_DIR / "vocabulary" / "blah", "w") as random_file:
            random_file.write("BLAH!")
        with pytest.raises(ConfigurationError, match="The 'vocabulary' directory in the provided"):
            make_vocab_from_params(params, str(self.TEST_DIR))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 8:</b> &nbsp; 3 fragments, nominal size 13 lines, similarity 84%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag510')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/boolean_accuracy_test.py: 73-86
</a>
<div class="mid" id="frag510" style="display:none"><pre>
    def test_distributed_accuracy(self):
        predictions = [torch.tensor([[0, 1], [2, 3]]), torch.tensor([[4, 5], [6, 7]])]
        targets = [torch.tensor([[0, 1], [2, 2]]), torch.tensor([[4, 5], [7, 7]])]
        metric_kwargs = {"predictions": predictions, "gold_labels": targets}
        desired_values = 0.5
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            BooleanAccuracy(),
            metric_kwargs,
            desired_values,
            exact=True,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag512')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/boolean_accuracy_test.py: 101-115
</a>
<div class="mid" id="frag512" style="display:none"><pre>
    def test_multiple_distributed_runs(self):
        predictions = [torch.tensor([[0, 1], [2, 3]]), torch.tensor([[4, 5], [6, 7]])]
        targets = [torch.tensor([[0, 1], [2, 2]]), torch.tensor([[4, 5], [7, 7]])]
        metric_kwargs = {"predictions": predictions, "gold_labels": targets}
        desired_values = 0.5
        run_distributed_test(
            [-1, -1],
            multiple_runs,
            BooleanAccuracy(),
            metric_kwargs,
            desired_values,
            exact=True,
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag511')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/boolean_accuracy_test.py: 87-100
</a>
<div class="mid" id="frag511" style="display:none"><pre>
    def test_distributed_accuracy_unequal_batches(self):
        predictions = [torch.tensor([[0, 1], [2, 3], [4, 5]]), torch.tensor([[6, 7]])]
        targets = [torch.tensor([[0, 1], [2, 2], [4, 5]]), torch.tensor([[7, 7]])]
        metric_kwargs = {"predictions": predictions, "gold_labels": targets}
        desired_values = 0.5
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            BooleanAccuracy(),
            metric_kwargs,
            desired_values,
            exact=True,
        )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 9:</b> &nbsp; 9 fragments, nominal size 15 lines, similarity 82%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag513')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/boolean_accuracy_test.py: 116-134
</a>
<div class="mid" id="frag513" style="display:none"><pre>
def multiple_runs(
    global_rank: int,
    world_size: int,
    gpu_id: Union[int, torch.device],
    metric: BooleanAccuracy,
    metric_kwargs: Dict[str, List[Any]],
    desired_values: Dict[str, Any],
    exact: Union[bool, Tuple[float, float]] = True,
):

    kwargs = {}
    # Use the arguments meant for the process with rank `global_rank`.
    for argname in metric_kwargs:
        kwargs[argname] = metric_kwargs[argname][global_rank]

    for i in range(200):
        metric(**kwargs)

    assert desired_values == metric.get_metric()
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag589')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/attachment_scores_test.py: 194-215
</a>
<div class="mid" id="frag589" style="display:none"><pre>
def multiple_runs(
    global_rank: int,
    world_size: int,
    gpu_id: Union[int, torch.device],
    metric: AttachmentScores,
    metric_kwargs: Dict[str, List[Any]],
    desired_values: Dict[str, Any],
    exact: Union[bool, Tuple[float, float]] = True,
):

    kwargs = {}
    # Use the arguments meant for the process with rank `global_rank`.
    for argname in metric_kwargs:
        kwargs[argname] = metric_kwargs[argname][global_rank]

    for i in range(200):
        metric(**kwargs)

    metrics = metric.get_metric()

    for key in metrics:
        assert desired_values[key] == metrics[key]
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag633')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 461-482
</a>
<div class="mid" id="frag633" style="display:none"><pre>
def multiple_runs(
    global_rank: int,
    world_size: int,
    gpu_id: Union[int, torch.device],
    metric: FBetaMultiLabelMeasure,
    metric_kwargs: Dict[str, List[Any]],
    desired_values: Dict[str, Any],
    exact: Union[bool, Tuple[float, float]] = True,
):

    kwargs = {}
    # Use the arguments meant for the process with rank `global_rank`.
    for argname in metric_kwargs:
        kwargs[argname] = metric_kwargs[argname][global_rank]

    for i in range(200):
        metric(**kwargs)

    metric_values = metric.get_metric()

    for key in desired_values:
        assert_allclose(desired_values[key], metric_values[key])
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag561')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_measure_test.py: 423-444
</a>
<div class="mid" id="frag561" style="display:none"><pre>
def multiple_runs(
    global_rank: int,
    world_size: int,
    gpu_id: Union[int, torch.device],
    metric: FBetaMeasure,
    metric_kwargs: Dict[str, List[Any]],
    desired_values: Dict[str, Any],
    exact: Union[bool, Tuple[float, float]] = True,
):

    kwargs = {}
    # Use the arguments meant for the process with rank `global_rank`.
    for argname in metric_kwargs:
        kwargs[argname] = metric_kwargs[argname][global_rank]

    for i in range(200):
        metric(**kwargs)

    metric_values = metric.get_metric()

    for key in desired_values:
        assert_allclose(desired_values[key], metric_values[key])
</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag541')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/entropy_test.py: 82-100
</a>
<div class="mid" id="frag541" style="display:none"><pre>
def multiple_runs(
    global_rank: int,
    world_size: int,
    gpu_id: Union[int, torch.device],
    metric: Entropy,
    metric_kwargs: Dict[str, List[Any]],
    desired_values: Dict[str, Any],
    exact: Union[bool, Tuple[float, float]] = True,
):

    kwargs = {}
    # Use the arguments meant for the process with rank `global_rank`.
    for argname in metric_kwargs:
        kwargs[argname] = metric_kwargs[argname][global_rank]

    for i in range(200):
        metric(**kwargs)

    assert_allclose(desired_values["entropy"], metric.get_metric()["entropy"])
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag568')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/mean_absolute_error_test.py: 156-174
</a>
<div class="mid" id="frag568" style="display:none"><pre>
def multiple_runs(
    global_rank: int,
    world_size: int,
    gpu_id: Union[int, torch.device],
    metric: MeanAbsoluteError,
    metric_kwargs: Dict[str, List[Any]],
    desired_values: Dict[str, Any],
    exact: Union[bool, Tuple[float, float]] = True,
):

    kwargs = {}
    # Use the arguments meant for the process with rank `global_rank`.
    for argname in metric_kwargs:
        kwargs[argname] = metric_kwargs[argname][global_rank]

    for i in range(200):
        metric(**kwargs)

    assert desired_values["mae"] == metric.get_metric()["mae"]
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag535')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/unigram_recall_test.py: 126-144
</a>
<div class="mid" id="frag535" style="display:none"><pre>
def multiple_runs(
    global_rank: int,
    world_size: int,
    gpu_id: Union[int, torch.device],
    metric: UnigramRecall,
    metric_kwargs: Dict[str, List[Any]],
    desired_values: Dict[str, Any],
    exact: Union[bool, Tuple[float, float]] = True,
):

    kwargs = {}
    # Use the arguments meant for the process with rank `global_rank`.
    for argname in metric_kwargs:
        kwargs[argname] = metric_kwargs[argname][global_rank]

    for i in range(200):
        metric(**kwargs)

    assert desired_values["unigram_recall"] == metric.get_metric()["unigram_recall"]
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag596')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/sequence_accuracy_test.py: 126-144
</a>
<div class="mid" id="frag596" style="display:none"><pre>
def multiple_runs(
    global_rank: int,
    world_size: int,
    gpu_id: Union[int, torch.device],
    metric: SequenceAccuracy,
    metric_kwargs: Dict[str, List[Any]],
    desired_values: Dict[str, Any],
    exact: Union[bool, Tuple[float, float]] = True,
):

    kwargs = {}
    # Use the arguments meant for the process with rank `global_rank`.
    for argname in metric_kwargs:
        kwargs[argname] = metric_kwargs[argname][global_rank]

    for i in range(200):
        metric(**kwargs)

    assert desired_values["accuracy"] == metric.get_metric()["accuracy"]
</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag522')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/evalb_bracketing_scorer_test.py: 109-130
</a>
<div class="mid" id="frag522" style="display:none"><pre>
def multiple_runs(
    global_rank: int,
    world_size: int,
    gpu_id: Union[int, torch.device],
    metric: EvalbBracketingScorer,
    metric_kwargs: Dict[str, List[Any]],
    desired_values: Dict[str, Any],
    exact: Union[bool, Tuple[float, float]] = True,
):

    kwargs = {}
    # Use the arguments meant for the process with rank `global_rank`.
    for argname in metric_kwargs:
        kwargs[argname] = metric_kwargs[argname][global_rank]

    for i in range(200):
        metric(**kwargs)

    metric_values = metric.get_metric()

    for key in desired_values:
        assert desired_values[key] == metric_values[key]
</pre></div>
</td>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 10:</b> &nbsp; 2 fragments, nominal size 19 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag520')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/evalb_bracketing_scorer_test.py: 68-87
</a>
<div class="mid" id="frag520" style="display:none"><pre>
    def test_distributed_evalb(self):
        tree1 = Tree.fromstring("(S (VP (D the) (NP dog)) (VP (V chased) (NP (D the) (N cat))))")
        tree2 = Tree.fromstring("(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))")
        predicted_trees = [[tree1], [tree2]]
        gold_trees = [[tree2], [tree2]]
        metric_kwargs = {"predicted_trees": predicted_trees, "gold_trees": gold_trees}
        desired_values = {
            "evalb_recall": 0.875,
            "evalb_precision": 0.875,
            "evalb_f1_measure": 0.875,
        }
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            EvalbBracketingScorer(),
            metric_kwargs,
            desired_values,
            exact=True,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag521')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/evalb_bracketing_scorer_test.py: 88-108
</a>
<div class="mid" id="frag521" style="display:none"><pre>
    def test_multiple_distributed_runs(self):
        tree1 = Tree.fromstring("(S (VP (D the) (NP dog)) (VP (V chased) (NP (D the) (N cat))))")
        tree2 = Tree.fromstring("(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))")
        predicted_trees = [[tree1], [tree2]]
        gold_trees = [[tree2], [tree2]]
        metric_kwargs = {"predicted_trees": predicted_trees, "gold_trees": gold_trees}
        desired_values = {
            "evalb_recall": 0.875,
            "evalb_precision": 0.875,
            "evalb_f1_measure": 0.875,
        }
        run_distributed_test(
            [-1, -1],
            multiple_runs,
            EvalbBracketingScorer(),
            metric_kwargs,
            desired_values,
            exact=False,
        )


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 11:</b> &nbsp; 2 fragments, nominal size 20 lines, similarity 95%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag527')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/auc_test.py: 98-122
</a>
<div class="mid" id="frag527" style="display:none"><pre>
    def test_distributed_auc(self):
        predictions = torch.randn(8)
        labels = torch.randint(3, 5, (8,), dtype=torch.long)
        # We make sure that the positive label is always present.
        labels[0] = 4
        labels[4] = 4

        false_positive_rates, true_positive_rates, _ = metrics.roc_curve(
            labels.cpu().numpy(), predictions.cpu().numpy(), pos_label=4
        )

        predictions = [predictions[:4], predictions[4:]]
        labels = [labels[:4], labels[4:]]

        metric_kwargs = {"predictions": predictions, "gold_labels": labels}
        desired_auc = metrics.auc(false_positive_rates, true_positive_rates)
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            Auc(positive_label=4),
            metric_kwargs,
            desired_auc,
            exact=False,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag528')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/auc_test.py: 123-147
</a>
<div class="mid" id="frag528" style="display:none"><pre>
    def test_distributed_auc_unequal_batches(self):
        predictions = torch.randn(8)
        labels = torch.randint(3, 5, (8,), dtype=torch.long)
        # We make sure that the positive label is always present.
        labels[0] = 4
        labels[4] = 4

        false_positive_rates, true_positive_rates, _ = metrics.roc_curve(
            labels.cpu().numpy(), predictions.cpu().numpy(), pos_label=4
        )

        predictions = [predictions[:2], predictions[2:]]
        labels = [labels[:2], labels[2:]]

        metric_kwargs = {"predictions": predictions, "gold_labels": labels}
        desired_auc = metrics.auc(false_positive_rates, true_positive_rates)
        with pytest.raises(Exception) as _:
            run_distributed_test(
                [-1, -1],
                global_distributed_metric,
                Auc(positive_label=4),
                metric_kwargs,
                desired_auc,
                exact=False,
            )
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 12:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 90%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag529')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/unigram_recall_test.py: 16-27
</a>
<div class="mid" id="frag529" style="display:none"><pre>
    def test_sequence_recall(self, device: str):
        recall = UnigramRecall()
        gold = torch.tensor([[1, 2, 3], [2, 4, 8], [7, 1, 1]], device=device)
        predictions = torch.tensor(
            [[[1, 2, 3], [1, 2, -1]], [[2, 4, 8], [2, 5, 9]], [[-1, -1, -1], [7, 1, -1]]],
            device=device,
        )

        recall(predictions, gold)
        actual_recall = recall.get_metric()["unigram_recall"]
        assert_allclose(actual_recall, 1)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag590')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/sequence_accuracy_test.py: 16-27
</a>
<div class="mid" id="frag590" style="display:none"><pre>
    def test_sequence_accuracy(self, device: str):
        accuracy = SequenceAccuracy()
        gold = torch.tensor([[1, 2, 3], [2, 4, 8], [0, 1, 1]], device=device)
        predictions = torch.tensor(
            [[[1, 2, 3], [1, 2, -1]], [[2, 4, 8], [2, 5, 9]], [[-1, -1, -1], [0, 1, -1]]],
            device=device,
        )

        accuracy(predictions, gold)
        actual_accuracy = accuracy.get_metric()["accuracy"]
        assert_allclose(actual_accuracy, 2 / 3)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 13:</b> &nbsp; 2 fragments, nominal size 19 lines, similarity 94%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag530')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/unigram_recall_test.py: 29-49
</a>
<div class="mid" id="frag530" style="display:none"><pre>
    def test_sequence_recall_respects_mask(self, device: str):
        recall = UnigramRecall()
        gold = torch.tensor([[2, 4, 8], [1, 2, 3], [7, 1, 1], [11, 14, 17]], device=device)
        predictions = torch.tensor(
            [
                [[2, 4, 8], [2, 5, 9]],  # 3/3
                [[-1, 2, 4], [3, 8, -1]],  # 2/2
                [[-1, -1, -1], [7, 2, -1]],  # 1/2
                [[12, 13, 17], [11, 13, 18]],  # 2/2
            ],
            device=device,
        )
        mask = torch.tensor(
            [[True, True, True], [False, True, True], [True, True, False], [True, False, True]],
            device=device,
        )

        recall(predictions, gold, mask)
        actual_recall = recall.get_metric()["unigram_recall"]
        assert_allclose(actual_recall, 7 / 8)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag591')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/sequence_accuracy_test.py: 29-49
</a>
<div class="mid" id="frag591" style="display:none"><pre>
    def test_sequence_accuracy_respects_mask(self, device: str):
        accuracy = SequenceAccuracy()
        gold = torch.tensor([[1, 2, 3], [2, 4, 8], [0, 1, 1], [11, 13, 17]], device=device)
        predictions = torch.tensor(
            [
                [[1, 2, 3], [1, 2, -1]],
                [[2, 4, 8], [2, 5, 9]],
                [[-1, -1, -1], [0, 1, -1]],
                [[12, 13, 17], [11, 13, 18]],
            ],
            device=device,
        )
        mask = torch.tensor(
            [[False, True, True], [True, True, True], [True, True, False], [True, False, True]],
            device=device,
        )

        accuracy(predictions, gold, mask)
        actual_accuracy = accuracy.get_metric()["accuracy"]
        assert_allclose(actual_accuracy, 3 / 4)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 14:</b> &nbsp; 4 fragments, nominal size 24 lines, similarity 88%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag533')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/unigram_recall_test.py: 69-96
</a>
<div class="mid" id="frag533" style="display:none"><pre>
    def test_distributed_accuracy(self):
        gold = torch.tensor([[2, 4, 8], [1, 2, 3], [7, 1, 1], [11, 14, 17]])
        predictions = torch.tensor(
            [
                [[2, 4, 8], [2, 5, 9]],  # 3/3
                [[-1, 2, 4], [3, 8, -1]],  # 2/2
                [[-1, -1, -1], [7, 2, -1]],  # 1/2
                [[12, 13, 17], [11, 13, 18]],  # 2/2
            ]
        )
        mask = torch.tensor(
            [[True, True, True], [False, True, True], [True, True, False], [True, False, True]]
        )
        gold = [gold[:2], gold[2:]]
        predictions = [predictions[:2], predictions[2:]]
        mask = [mask[:2], mask[2:]]

        metric_kwargs = {"predictions": predictions, "gold_labels": gold, "mask": mask}
        desired_values = {"unigram_recall": 7 / 8}
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            UnigramRecall(),
            metric_kwargs,
            desired_values,
            exact=False,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag594')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/sequence_accuracy_test.py: 69-96
</a>
<div class="mid" id="frag594" style="display:none"><pre>
    def test_distributed_sequence_accuracy(self):
        gold = torch.tensor([[1, 2, 3], [2, 4, 8], [0, 1, 1], [11, 13, 17]])
        predictions = torch.tensor(
            [
                [[1, 2, 3], [1, 2, -1]],
                [[2, 4, 8], [2, 5, 9]],
                [[-1, -1, -1], [0, 1, -1]],
                [[12, 13, 17], [11, 13, 18]],
            ]
        )
        mask = torch.tensor(
            [[False, True, True], [True, True, True], [True, True, False], [True, False, True]],
        )
        gold = [gold[:2], gold[2:]]
        predictions = [predictions[:2], predictions[2:]]
        mask = [mask[:2], mask[2:]]

        metric_kwargs = {"predictions": predictions, "gold_labels": gold, "mask": mask}
        desired_values = {"accuracy": 3 / 4}
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            SequenceAccuracy(),
            metric_kwargs,
            desired_values,
            exact=False,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag534')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/unigram_recall_test.py: 97-125
</a>
<div class="mid" id="frag534" style="display:none"><pre>
    def test_multiple_distributed_runs(self):
        gold = torch.tensor([[2, 4, 8], [1, 2, 3], [7, 1, 1], [11, 14, 17]])
        predictions = torch.tensor(
            [
                [[2, 4, 8], [2, 5, 9]],  # 3/3
                [[-1, 2, 4], [3, 8, -1]],  # 2/2
                [[-1, -1, -1], [7, 2, -1]],  # 1/2
                [[12, 13, 17], [11, 13, 18]],  # 2/2
            ]
        )
        mask = torch.tensor(
            [[True, True, True], [False, True, True], [True, True, False], [True, False, True]]
        )
        gold = [gold[:2], gold[2:]]
        predictions = [predictions[:2], predictions[2:]]
        mask = [mask[:2], mask[2:]]

        metric_kwargs = {"predictions": predictions, "gold_labels": gold, "mask": mask}
        desired_values = {"unigram_recall": 7 / 8}
        run_distributed_test(
            [-1, -1],
            multiple_runs,
            UnigramRecall(),
            metric_kwargs,
            desired_values,
            exact=True,
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag595')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/sequence_accuracy_test.py: 97-125
</a>
<div class="mid" id="frag595" style="display:none"><pre>
    def test_multiple_distributed_runs(self):
        gold = torch.tensor([[1, 2, 3], [2, 4, 8], [0, 1, 1], [11, 13, 17]])
        predictions = torch.tensor(
            [
                [[1, 2, 3], [1, 2, -1]],
                [[2, 4, 8], [2, 5, 9]],
                [[-1, -1, -1], [0, 1, -1]],
                [[12, 13, 17], [11, 13, 18]],
            ]
        )
        mask = torch.tensor(
            [[False, True, True], [True, True, True], [True, True, False], [True, False, True]],
        )
        gold = [gold[:2], gold[2:]]
        predictions = [predictions[:2], predictions[2:]]
        mask = [mask[:2], mask[2:]]

        metric_kwargs = {"predictions": predictions, "gold_labels": gold, "mask": mask}
        desired_values = {"accuracy": 3 / 4}
        run_distributed_test(
            [-1, -1],
            multiple_runs,
            SequenceAccuracy(),
            metric_kwargs,
            desired_values,
            exact=True,
        )


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 15:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag539')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/entropy_test.py: 53-66
</a>
<div class="mid" id="frag539" style="display:none"><pre>
    def test_distributed_entropy(self):
        logits = torch.tensor([[1, 1, 1, 1], [1, 1, 1, 1]], dtype=torch.float)
        logits = [logits[0], logits[1]]
        metric_kwargs = {"logits": logits}
        desired_values = {"entropy": 1.38629436}
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            Entropy(),
            metric_kwargs,
            desired_values,
            exact=False,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag540')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/entropy_test.py: 67-81
</a>
<div class="mid" id="frag540" style="display:none"><pre>
    def test_multiple_distributed_runs(self):
        logits = torch.tensor([[1, 1, 1, 1], [1, 1, 1, 1]], dtype=torch.float)
        logits = [logits[0], logits[1]]
        metric_kwargs = {"logits": logits}
        desired_values = {"entropy": 1.38629436}
        run_distributed_test(
            [-1, -1],
            multiple_runs,
            Entropy(),
            metric_kwargs,
            desired_values,
            exact=False,
        )


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 16:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag545')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_measure_test.py: 69-82
</a>
<div class="mid" id="frag545" style="display:none"><pre>
    def test_fbeta_multiclass_state(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        fbeta = FBetaMeasure()
        fbeta(self.predictions, self.targets)

        # check state
        assert_allclose(fbeta._pred_sum.tolist(), self.pred_sum)
        assert_allclose(fbeta._true_sum.tolist(), self.true_sum)
        assert_allclose(fbeta._true_positive_sum.tolist(), self.true_positive_sum)
        assert_allclose(fbeta._true_negative_sum.tolist(), self.true_negative_sum)
        assert_allclose(fbeta._total_sum.tolist(), self.total_sum)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag617')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 79-92
</a>
<div class="mid" id="frag617" style="display:none"><pre>
    def test_fbeta_multilabel_state(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        fbeta = FBetaMultiLabelMeasure()
        fbeta(self.predictions, self.targets)

        # check state
        assert_allclose(fbeta._pred_sum.tolist(), self.pred_sum)
        assert_allclose(fbeta._true_sum.tolist(), self.true_sum)
        assert_allclose(fbeta._true_positive_sum.tolist(), self.true_positive_sum)
        assert_allclose(fbeta._true_negative_sum.tolist(), self.true_negative_sum)
        assert_allclose(fbeta._total_sum.tolist(), self.total_sum)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 17:</b> &nbsp; 2 fragments, nominal size 15 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag546')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_measure_test.py: 84-104
</a>
<div class="mid" id="frag546" style="display:none"><pre>
    def test_fbeta_multiclass_metric(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        fbeta = FBetaMeasure()
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        # check value
        assert_allclose(precisions, self.desired_precisions)
        assert_allclose(recalls, self.desired_recalls)
        assert_allclose(fscores, self.desired_fscores)

        # check type
        assert isinstance(precisions, List)
        assert isinstance(recalls, List)
        assert isinstance(fscores, List)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag618')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 94-114
</a>
<div class="mid" id="frag618" style="display:none"><pre>
    def test_fbeta_multilabel_metric(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        fbeta = FBetaMultiLabelMeasure()
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        # check value
        assert_allclose(precisions, self.desired_precisions)
        assert_allclose(recalls, self.desired_recalls)
        assert_allclose(fscores, self.desired_fscores)

        # check type
        assert isinstance(precisions, List)
        assert isinstance(recalls, List)
        assert isinstance(fscores, List)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 18:</b> &nbsp; 2 fragments, nominal size 21 lines, similarity 85%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag547')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_measure_test.py: 106-132
</a>
<div class="mid" id="frag547" style="display:none"><pre>
    def test_fbeta_multiclass_with_mask(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        mask = torch.tensor([True, True, True, True, True, False], device=device)

        fbeta = FBetaMeasure()
        fbeta(self.predictions, self.targets, mask)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        assert_allclose(fbeta._pred_sum.tolist(), [1, 3, 0, 1, 0])
        assert_allclose(fbeta._true_sum.tolist(), [2, 1, 0, 1, 1])
        assert_allclose(fbeta._true_positive_sum.tolist(), [1, 1, 0, 1, 0])

        desired_precisions = [1.00, 1 / 3, 0.00, 1.00, 0.00]
        desired_recalls = [0.50, 1.00, 0.00, 1.00, 0.00]
        desired_fscores = [
            (2 * p * r) / (p + r) if p + r != 0.0 else 0.0
            for p, r in zip(desired_precisions, desired_recalls)
        ]
        assert_allclose(precisions, desired_precisions)
        assert_allclose(recalls, desired_recalls)
        assert_allclose(fscores, desired_fscores)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag619')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 116-142
</a>
<div class="mid" id="frag619" style="display:none"><pre>
    def test_fbeta_multilabel_with_mask(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        mask = torch.tensor([True, True, True, True, True, False], device=device).unsqueeze(-1)

        fbeta = FBetaMultiLabelMeasure()
        fbeta(self.predictions, self.targets, mask)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        assert_allclose(fbeta._pred_sum.tolist(), [3, 3, 3, 4, 1])
        assert_allclose(fbeta._true_sum.tolist(), [4, 5, 2, 4, 0])
        assert_allclose(fbeta._true_positive_sum.tolist(), [3, 3, 2, 4, 0])

        desired_precisions = [3 / 3, 3 / 3, 2 / 3, 4 / 4, 0 / 1]
        desired_recalls = [3 / 4, 3 / 5, 2 / 2, 4 / 4, 0.00]
        desired_fscores = [
            (2 * p * r) / (p + r) if p + r != 0.0 else 0.0
            for p, r in zip(desired_precisions, desired_recalls)
        ]
        assert_allclose(precisions, desired_precisions)
        assert_allclose(recalls, desired_recalls)
        assert_allclose(fscores, desired_fscores)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 19:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag548')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_measure_test.py: 134-158
</a>
<div class="mid" id="frag548" style="display:none"><pre>
    def test_fbeta_multiclass_macro_average_metric(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        fbeta = FBetaMeasure(average="macro")
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        # We keep the expected values in CPU because FBetaMeasure returns them in CPU.
        macro_precision = torch.tensor(self.desired_precisions).mean()
        macro_recall = torch.tensor(self.desired_recalls).mean()
        macro_fscore = torch.tensor(self.desired_fscores).mean()
        # check value
        assert_allclose(precisions, macro_precision)
        assert_allclose(recalls, macro_recall)
        assert_allclose(fscores, macro_fscore)

        # check type
        assert isinstance(precisions, float)
        assert isinstance(recalls, float)
        assert isinstance(fscores, float)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag620')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 144-168
</a>
<div class="mid" id="frag620" style="display:none"><pre>
    def test_fbeta_multilabel_macro_average_metric(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        fbeta = FBetaMultiLabelMeasure(average="macro")
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        # We keep the expected values in CPU because FBetaMeasure returns them in CPU.
        macro_precision = torch.tensor(self.desired_precisions).mean()
        macro_recall = torch.tensor(self.desired_recalls).mean()
        macro_fscore = torch.tensor(self.desired_fscores).mean()
        # check value
        assert_allclose(precisions, macro_precision)
        assert_allclose(recalls, macro_recall)
        assert_allclose(fscores, macro_fscore)

        # check type
        assert isinstance(precisions, float)
        assert isinstance(recalls, float)
        assert isinstance(fscores, float)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 20:</b> &nbsp; 4 fragments, nominal size 21 lines, similarity 77%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag549')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_measure_test.py: 160-186
</a>
<div class="mid" id="frag549" style="display:none"><pre>
    def test_fbeta_multiclass_micro_average_metric(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        fbeta = FBetaMeasure(average="micro")
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        # We keep the expected values in CPU because FBetaMeasure returns them in CPU.
        true_positives = torch.tensor([1, 1, 0, 1, 0], dtype=torch.float32)
        false_positives = torch.tensor([0, 3, 0, 0, 0], dtype=torch.float32)
        false_negatives = torch.tensor([2, 0, 0, 0, 1], dtype=torch.float32)
        mean_true_positive = true_positives.mean()
        mean_false_positive = false_positives.mean()
        mean_false_negative = false_negatives.mean()

        micro_precision = mean_true_positive / (mean_true_positive + mean_false_positive)
        micro_recall = mean_true_positive / (mean_true_positive + mean_false_negative)
        micro_fscore = (2 * micro_precision * micro_recall) / (micro_precision + micro_recall)
        # check value
        assert_allclose(precisions, micro_precision)
        assert_allclose(recalls, micro_recall)
        assert_allclose(fscores, micro_fscore)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag552')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_measure_test.py: 232-259
</a>
<div class="mid" id="frag552" style="display:none"><pre>
    def test_fbeta_multiclass_with_micro_average(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        labels = [1, 3]
        fbeta = FBetaMeasure(average="micro", labels=labels)
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        # We keep the expected values in CPU because FBetaMeasure returns them in CPU.
        true_positives = torch.tensor([1, 1], dtype=torch.float32)
        false_positives = torch.tensor([3, 0], dtype=torch.float32)
        false_negatives = torch.tensor([0, 0], dtype=torch.float32)
        mean_true_positive = true_positives.mean()
        mean_false_positive = false_positives.mean()
        mean_false_negative = false_negatives.mean()

        micro_precision = mean_true_positive / (mean_true_positive + mean_false_positive)
        micro_recall = mean_true_positive / (mean_true_positive + mean_false_negative)
        micro_fscore = (2 * micro_precision * micro_recall) / (micro_precision + micro_recall)
        # check value
        assert_allclose(precisions, micro_precision)
        assert_allclose(recalls, micro_recall)
        assert_allclose(fscores, micro_fscore)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag621')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 170-196
</a>
<div class="mid" id="frag621" style="display:none"><pre>
    def test_fbeta_multilabel_micro_average_metric(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        fbeta = FBetaMultiLabelMeasure(average="micro")
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        # We keep the expected values in CPU because FBetaMeasure returns them in CPU.
        true_positives = torch.tensor([3, 3, 2, 4, 0], dtype=torch.float32)
        false_positives = torch.tensor([1, 0, 1, 0, 1], dtype=torch.float32)
        false_negatives = torch.tensor([1, 2, 0, 0, 0], dtype=torch.float32)
        mean_true_positive = true_positives.mean()
        mean_false_positive = false_positives.mean()
        mean_false_negative = false_negatives.mean()

        micro_precision = mean_true_positive / (mean_true_positive + mean_false_positive)
        micro_recall = mean_true_positive / (mean_true_positive + mean_false_negative)
        micro_fscore = (2 * micro_precision * micro_recall) / (micro_precision + micro_recall)
        # check value
        assert_allclose(precisions, micro_precision)
        assert_allclose(recalls, micro_recall)
        assert_allclose(fscores, micro_fscore)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag624')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 242-269
</a>
<div class="mid" id="frag624" style="display:none"><pre>
    def test_fbeta_multilabel_with_micro_average(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        labels = [1, 3]
        fbeta = FBetaMultiLabelMeasure(average="micro", labels=labels)
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        # We keep the expected values in CPU because FBetaMeasure returns them in CPU.
        true_positives = torch.tensor([3, 4], dtype=torch.float32)
        false_positives = torch.tensor([0, 0], dtype=torch.float32)
        false_negatives = torch.tensor([2, 0], dtype=torch.float32)
        mean_true_positive = true_positives.mean()
        mean_false_positive = false_positives.mean()
        mean_false_negative = false_negatives.mean()

        micro_precision = mean_true_positive / (mean_true_positive + mean_false_positive)
        micro_recall = mean_true_positive / (mean_true_positive + mean_false_negative)
        micro_fscore = (2 * micro_precision * micro_recall) / (micro_precision + micro_recall)
        # check value
        assert_allclose(precisions, micro_precision)
        assert_allclose(recalls, micro_recall)
        assert_allclose(fscores, micro_fscore)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 21:</b> &nbsp; 2 fragments, nominal size 15 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag550')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_measure_test.py: 188-207
</a>
<div class="mid" id="frag550" style="display:none"><pre>
    def test_fbeta_multiclass_with_explicit_labels(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        # same prediction but with and explicit label ordering
        fbeta = FBetaMeasure(labels=[4, 3, 2, 1, 0])
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        desired_precisions = self.desired_precisions[::-1]
        desired_recalls = self.desired_recalls[::-1]
        desired_fscores = self.desired_fscores[::-1]
        # check value
        assert_allclose(precisions, desired_precisions)
        assert_allclose(recalls, desired_recalls)
        assert_allclose(fscores, desired_fscores)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag622')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 198-217
</a>
<div class="mid" id="frag622" style="display:none"><pre>
    def test_fbeta_multilabel_with_explicit_labels(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        # same prediction but with and explicit label ordering
        fbeta = FBetaMultiLabelMeasure(labels=[4, 3, 2, 1, 0])
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        desired_precisions = self.desired_precisions[::-1]
        desired_recalls = self.desired_recalls[::-1]
        desired_fscores = self.desired_fscores[::-1]
        # check value
        assert_allclose(precisions, desired_precisions)
        assert_allclose(recalls, desired_recalls)
        assert_allclose(fscores, desired_fscores)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 22:</b> &nbsp; 2 fragments, nominal size 16 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag551')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_measure_test.py: 209-230
</a>
<div class="mid" id="frag551" style="display:none"><pre>
    def test_fbeta_multiclass_with_macro_average(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        labels = [0, 1]
        fbeta = FBetaMeasure(average="macro", labels=labels)
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        # We keep the expected values in CPU because FBetaMeasure returns them in CPU.
        macro_precision = torch.tensor(self.desired_precisions)[labels].mean()
        macro_recall = torch.tensor(self.desired_recalls)[labels].mean()
        macro_fscore = torch.tensor(self.desired_fscores)[labels].mean()

        # check value
        assert_allclose(precisions, macro_precision)
        assert_allclose(recalls, macro_recall)
        assert_allclose(fscores, macro_fscore)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag623')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 219-240
</a>
<div class="mid" id="frag623" style="display:none"><pre>
    def test_fbeta_multilabel_with_macro_average(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        labels = [0, 1]
        fbeta = FBetaMultiLabelMeasure(average="macro", labels=labels)
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        # We keep the expected values in CPU because FBetaMeasure returns them in CPU.
        macro_precision = torch.tensor(self.desired_precisions)[labels].mean()
        macro_recall = torch.tensor(self.desired_recalls)[labels].mean()
        macro_fscore = torch.tensor(self.desired_fscores)[labels].mean()

        # check value
        assert_allclose(precisions, macro_precision)
        assert_allclose(recalls, macro_recall)
        assert_allclose(fscores, macro_fscore)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 23:</b> &nbsp; 2 fragments, nominal size 22 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag553')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_measure_test.py: 261-284
</a>
<div class="mid" id="frag553" style="display:none"><pre>
    def test_fbeta_multiclass_with_weighted_average(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        labels = [0, 1]
        fbeta = FBetaMeasure(average="weighted", labels=labels)
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        weighted_precision, weighted_recall, weighted_fscore, _ = precision_recall_fscore_support(
            self.targets.cpu().numpy(),
            self.predictions.argmax(dim=1).cpu().numpy(),
            labels=labels,
            average="weighted",
        )

        # check value
        assert_allclose(precisions, weighted_precision)
        assert_allclose(recalls, weighted_recall)
        assert_allclose(fscores, weighted_fscore)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag625')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 271-300
</a>
<div class="mid" id="frag625" style="display:none"><pre>
    def test_fbeta_multilabel_with_weighted_average(self, device: str):
        self.predictions = self.predictions.to(device)
        self.targets = self.targets.to(device)

        labels = [0, 1]
        fbeta = FBetaMultiLabelMeasure(average="weighted", labels=labels)
        fbeta(self.predictions, self.targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        weighted_precision, weighted_recall, weighted_fscore, _ = precision_recall_fscore_support(
            self.targets.cpu().numpy(),
            torch.where(
                self.predictions &gt;= fbeta._threshold,
                torch.ones_like(self.predictions),
                torch.zeros_like(self.predictions),
            )
            .cpu()
            .numpy(),
            labels=labels,
            average="weighted",
        )

        # check value
        assert_allclose(precisions, weighted_precision)
        assert_allclose(recalls, weighted_recall)
        assert_allclose(fscores, weighted_fscore)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 24:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 81%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag554')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_measure_test.py: 286-299
</a>
<div class="mid" id="frag554" style="display:none"><pre>
    def test_fbeta_handles_batch_size_of_one(self, device: str):
        predictions = torch.tensor([[0.2862, 0.3479, 0.1627, 0.2033]], device=device)
        targets = torch.tensor([1], device=device)
        mask = torch.tensor([True], device=device)

        fbeta = FBetaMeasure()
        fbeta(predictions, targets, mask)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]

        assert_allclose(precisions, [0.0, 1.0, 0.0, 0.0])
        assert_allclose(recalls, [0.0, 1.0, 0.0, 0.0])

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag626')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 302-315
</a>
<div class="mid" id="frag626" style="display:none"><pre>
    def test_fbeta_multilabel_handles_batch_size_of_one(self, device: str):
        predictions = torch.tensor([[0.2862, 0.5479, 0.1627, 0.2033]], device=device)
        targets = torch.tensor([[0, 1, 0, 0]], device=device)
        mask = torch.tensor([[True]], device=device)

        fbeta = FBetaMultiLabelMeasure()
        fbeta(predictions, targets, mask)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]

        assert_allclose(precisions, [0.0, 1.0, 0.0, 0.0])
        assert_allclose(recalls, [0.0, 1.0, 0.0, 0.0])

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 25:</b> &nbsp; 8 fragments, nominal size 12 lines, similarity 91%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag555')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_measure_test.py: 301-317
</a>
<div class="mid" id="frag555" style="display:none"><pre>
    def test_fbeta_handles_no_prediction_false_last_class(self, device: str):

        predictions = torch.tensor([[0.65, 0.35], [0.0, 0.0]], device=device)
        # preds = [0, NA]
        targets = torch.tensor([0, 0], device=device)

        fbeta = FBetaMeasure()
        fbeta(predictions, targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        assert_allclose(precisions, [1.0, 0.0])
        assert_allclose(recalls, [0.5, 0.0])
        assert_allclose(fscores, [0.6667, 0.0])

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag627')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 317-333
</a>
<div class="mid" id="frag627" style="display:none"><pre>
    def test_fbeta_multilabel_handles_no_prediction_false_last_class(self, device: str):

        predictions = torch.tensor([[0.65, 0.35], [0.0, 0.0]], device=device)
        # preds = [0, NA]
        targets = torch.tensor([[1, 0], [1, 0]], device=device)

        fbeta = FBetaMultiLabelMeasure()
        fbeta(predictions, targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        assert_allclose(precisions, [1.0, 0.0])
        assert_allclose(recalls, [0.5, 0.0])
        assert_allclose(fscores, [0.6667, 0.0])

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag556')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_measure_test.py: 319-335
</a>
<div class="mid" id="frag556" style="display:none"><pre>
    def test_fbeta_handles_no_prediction_true_last_class(self, device: str):

        predictions = torch.tensor([[0.65, 0.35], [0.0, 0.0]], device=device)
        # preds = [0, NA]
        targets = torch.tensor([0, 1], device=device)

        fbeta = FBetaMeasure()
        fbeta(predictions, targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        assert_allclose(precisions, [1.0, 0.0])
        assert_allclose(recalls, [1.0, 0.0])
        assert_allclose(fscores, [1.0, 0.0])

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag630')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 370-385
</a>
<div class="mid" id="frag630" style="display:none"><pre>
    def test_fbeta_multilabel_handles_no_prediction_true_all_class(self, device: str):
        predictions = torch.tensor([[0.65, 0.35], [0.0, 0.0]], device=device)
        # preds = [0, NA]
        targets = torch.tensor([[0, 1], [0, 1]], device=device)

        fbeta = FBetaMultiLabelMeasure()
        fbeta(predictions, targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        assert_allclose(precisions, [0.0, 0.0])
        assert_allclose(recalls, [0.0, 0.0])
        assert_allclose(fscores, [0.0, 0.0])

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag629')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 353-368
</a>
<div class="mid" id="frag629" style="display:none"><pre>
    def test_fbeta_multilabel_handles_no_prediction_true_other_class(self, device: str):
        predictions = torch.tensor([[0.65, 0.35], [0.0, 0.0]], device=device)
        # preds = [0, NA]
        targets = torch.tensor([[0, 1], [1, 0]], device=device)

        fbeta = FBetaMultiLabelMeasure()
        fbeta(predictions, targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        assert_allclose(precisions, [0.0, 0.0])
        assert_allclose(recalls, [0.0, 0.0])
        assert_allclose(fscores, [0.0, 0.0])

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag628')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 335-351
</a>
<div class="mid" id="frag628" style="display:none"><pre>
    def test_fbeta_multilabel_handles_no_prediction_true_last_class(self, device: str):

        predictions = torch.tensor([[0.65, 0.35], [0.0, 0.0]], device=device)
        # preds = [0, NA]
        targets = torch.tensor([[1, 0], [0, 1]], device=device)

        fbeta = FBetaMultiLabelMeasure()
        fbeta(predictions, targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        assert_allclose(precisions, [1.0, 0.0])
        assert_allclose(recalls, [1.0, 0.0])
        assert_allclose(fscores, [1.0, 0.0])

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag558')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_measure_test.py: 355-371
</a>
<div class="mid" id="frag558" style="display:none"><pre>
    def test_fbeta_handles_no_prediction_true_all_class(self, device: str):

        predictions = torch.tensor([[0.65, 0.35], [0.0, 0.0]], device=device)
        # preds = [0, NA]
        targets = torch.tensor([1, 1], device=device)

        fbeta = FBetaMeasure()
        fbeta(predictions, targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        assert_allclose(precisions, [0.0, 0.0])
        assert_allclose(recalls, [0.0, 0.0])
        assert_allclose(fscores, [0.0, 0.0])

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag557')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_measure_test.py: 337-353
</a>
<div class="mid" id="frag557" style="display:none"><pre>
    def test_fbeta_handles_no_prediction_true_other_class(self, device: str):

        predictions = torch.tensor([[0.65, 0.35], [0.0, 0.0]], device=device)
        # preds = [0, NA]
        targets = torch.tensor([1, 0], device=device)

        fbeta = FBetaMeasure()
        fbeta(predictions, targets)
        metric = fbeta.get_metric()
        precisions = metric["precision"]
        recalls = metric["recall"]
        fscores = metric["fscore"]

        assert_allclose(precisions, [0.0, 0.0])
        assert_allclose(recalls, [0.0, 0.0])
        assert_allclose(fscores, [0.0, 0.0])

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 26:</b> &nbsp; 3 fragments, nominal size 22 lines, similarity 80%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag559')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_measure_test.py: 372-396
</a>
<div class="mid" id="frag559" style="display:none"><pre>
    def test_distributed_fbeta_measure(self):
        predictions = [
            torch.tensor(
                [[0.35, 0.25, 0.1, 0.1, 0.2], [0.1, 0.6, 0.1, 0.2, 0.0], [0.1, 0.6, 0.1, 0.2, 0.0]]
            ),
            torch.tensor(
                [[0.1, 0.5, 0.1, 0.2, 0.0], [0.1, 0.2, 0.1, 0.7, 0.0], [0.1, 0.6, 0.1, 0.2, 0.0]]
            ),
        ]
        targets = [torch.tensor([0, 4, 1]), torch.tensor([0, 3, 0])]
        metric_kwargs = {"predictions": predictions, "gold_labels": targets}
        desired_metrics = {
            "precision": self.desired_precisions,
            "recall": self.desired_recalls,
            "fscore": self.desired_fscores,
        }
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            FBetaMeasure(),
            metric_kwargs,
            desired_metrics,
            exact=False,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag560')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_measure_test.py: 397-422
</a>
<div class="mid" id="frag560" style="display:none"><pre>
    def test_multiple_distributed_runs(self):
        predictions = [
            torch.tensor(
                [[0.35, 0.25, 0.1, 0.1, 0.2], [0.1, 0.6, 0.1, 0.2, 0.0], [0.1, 0.6, 0.1, 0.2, 0.0]]
            ),
            torch.tensor(
                [[0.1, 0.5, 0.1, 0.2, 0.0], [0.1, 0.2, 0.1, 0.7, 0.0], [0.1, 0.6, 0.1, 0.2, 0.0]]
            ),
        ]
        targets = [torch.tensor([0, 4, 1]), torch.tensor([0, 3, 0])]
        metric_kwargs = {"predictions": predictions, "gold_labels": targets}
        desired_metrics = {
            "precision": self.desired_precisions,
            "recall": self.desired_recalls,
            "fscore": self.desired_fscores,
        }
        run_distributed_test(
            [-1, -1],
            multiple_runs,
            FBetaMeasure(),
            metric_kwargs,
            desired_metrics,
            exact=False,
        )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag580')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/f1_measure_test.py: 190-213
</a>
<div class="mid" id="frag580" style="display:none"><pre>
    def test_distributed_fbeta_measure(self):
        predictions = [
            torch.tensor(
                [[0.35, 0.25, 0.1, 0.1, 0.2], [0.1, 0.6, 0.1, 0.2, 0.0], [0.1, 0.6, 0.1, 0.2, 0.0]]
            ),
            torch.tensor(
                [[0.1, 0.5, 0.1, 0.2, 0.0], [0.1, 0.2, 0.1, 0.7, 0.0], [0.1, 0.6, 0.1, 0.2, 0.0]]
            ),
        ]
        targets = [torch.tensor([0, 4, 1]), torch.tensor([0, 3, 0])]
        metric_kwargs = {"predictions": predictions, "gold_labels": targets}
        desired_metrics = {
            "precision": 1.0,
            "recall": 0.333333333,
            "f1": 0.499999999,
        }
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            F1Measure(positive_label=0),
            metric_kwargs,
            desired_metrics,
            exact=False,
        )
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 27:</b> &nbsp; 2 fragments, nominal size 32 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag563')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/pearson_correlation_test.py: 30-66
</a>
<div class="mid" id="frag563" style="display:none"><pre>
    def test_pearson_correlation_unmasked_computation(self, device: str):
        pearson_correlation = PearsonCorrelation()
        batch_size = 100
        num_labels = 10
        predictions_1 = torch.randn(batch_size, num_labels, device=device)
        labels_1 = 0.5 * predictions_1 + torch.randn(batch_size, num_labels, device=device)

        predictions_2 = torch.randn(1, device=device).expand(num_labels)
        predictions_2 = predictions_2.unsqueeze(0).expand(batch_size, -1)
        labels_2 = torch.randn(1, device=device).expand(num_labels)
        labels_2 = 0.5 * predictions_2 + labels_2.unsqueeze(0).expand(batch_size, -1)

        # in most cases, the data is constructed like predictions_1, the data of such a batch different.
        # but in a few cases, for example, predictions_2, the data of such a batch is exactly the same.
        predictions_labels = [(predictions_1, labels_1), (predictions_2, labels_2)]

        stride = 10

        for predictions, labels in predictions_labels:
            pearson_correlation.reset()
            for i in range(batch_size // stride):
                timestep_predictions = predictions[stride * i : stride * (i + 1), :]
                timestep_labels = labels[stride * i : stride * (i + 1), :]
                expected_pearson_correlation = pearson_corrcoef(
                    predictions[: stride * (i + 1), :].view(-1).cpu().numpy(),
                    labels[: stride * (i + 1), :].view(-1).cpu().numpy(),
                )
                pearson_correlation(timestep_predictions, timestep_labels)
                assert_allclose(expected_pearson_correlation, pearson_correlation.get_metric())
            # Test reset
            pearson_correlation.reset()
            pearson_correlation(predictions, labels)
            assert_allclose(
                pearson_corrcoef(predictions.view(-1).cpu().numpy(), labels.view(-1).cpu().numpy()),
                pearson_correlation.get_metric(),
            )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag564')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/pearson_correlation_test.py: 68-132
</a>
<div class="mid" id="frag564" style="display:none"><pre>
    def test_pearson_correlation_masked_computation(self, device: str):
        pearson_correlation = PearsonCorrelation()
        batch_size = 100
        num_labels = 10
        predictions_1 = torch.randn(batch_size, num_labels, device=device)
        labels_1 = 0.5 * predictions_1 + torch.randn(batch_size, num_labels, device=device)

        predictions_2 = torch.randn(1, device=device).expand(num_labels)
        predictions_2 = predictions_2.unsqueeze(0).expand(batch_size, -1)
        labels_2 = torch.randn(1, device=device).expand(num_labels)
        labels_2 = 0.5 * predictions_2 + labels_2.unsqueeze(0).expand(batch_size, -1)

        predictions_labels = [(predictions_1, labels_1), (predictions_2, labels_2)]

        # Random binary mask
        mask = torch.randint(0, 2, size=(batch_size, num_labels), device=device).bool()
        stride = 10

        for predictions, labels in predictions_labels:
            pearson_correlation.reset()
            for i in range(batch_size // stride):
                timestep_predictions = predictions[stride * i : stride * (i + 1), :]
                timestep_labels = labels[stride * i : stride * (i + 1), :]
                timestep_mask = mask[stride * i : stride * (i + 1), :]
                expected_pearson_correlation = pearson_corrcoef(
                    predictions[: stride * (i + 1), :].view(-1).cpu().numpy(),
                    labels[: stride * (i + 1), :].view(-1).cpu().numpy(),
                    fweights=mask[: stride * (i + 1), :].view(-1).cpu().numpy(),
                )

                pearson_correlation(timestep_predictions, timestep_labels, timestep_mask)
                assert_allclose(expected_pearson_correlation, pearson_correlation.get_metric())
            # Test reset
            pearson_correlation.reset()
            pearson_correlation(predictions, labels, mask)
            expected_pearson_correlation = pearson_corrcoef(
                predictions.view(-1).cpu().numpy(),
                labels.view(-1).cpu().numpy(),
                fweights=mask.view(-1).cpu().numpy(),
            )

            assert_allclose(expected_pearson_correlation, pearson_correlation.get_metric())

    # Commenting in order to revisit distributed covariance (on which PearsonCorrelation depends) later.

    # def test_distributed_pearson(self):
    #     batch_size = 10
    #     num_labels = 10
    #     predictions = torch.randn(batch_size, num_labels)
    #     labels = 0.5 * predictions + torch.randn(batch_size, num_labels)

    #     expected_pearson_correlation = pearson_corrcoef(
    #         predictions.view(-1).cpu().numpy(), labels.view(-1).cpu().numpy(),
    #     )
    #     predictions = [predictions[:5], predictions[5:]]
    #     labels = [labels[:5], labels[5:]]
    #     metric_kwargs = {"predictions": predictions, "gold_labels": labels}
    #     run_distributed_test(
    #         [-1, -1],
    #         global_distributed_metric,
    #         PearsonCorrelation(),
    #         metric_kwargs,
    #         expected_pearson_correlation,
    #         exact=(0.0001, 1e-01),
    #     )
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 28:</b> &nbsp; 2 fragments, nominal size 35 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag566')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/mean_absolute_error_test.py: 75-114
</a>
<div class="mid" id="frag566" style="display:none"><pre>
    def test_distributed_accuracy(self):
        predictions = [
            torch.tensor(
                [
                    [1.0, 1.5, 1.0],
                    [2.0, 3.0, 3.5],
                ]
            ),
            torch.tensor(
                [
                    [4.0, 5.0, 5.5],
                    [6.0, 7.0, 7.5],
                ]
            ),
        ]
        targets = [
            torch.tensor(
                [
                    [0.0, 1.0, 0.0],
                    [2.0, 2.0, 0.0],
                ]
            ),
            torch.tensor(
                [
                    [4.0, 5.0, 0.0],
                    [7.0, 7.0, 0.0],
                ]
            ),
        ]
        metric_kwargs = {"predictions": predictions, "gold_labels": targets}
        desired_values = {"mae": 21.0 / 12.0}
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            MeanAbsoluteError(),
            metric_kwargs,
            desired_values,
            exact=True,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag567')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/mean_absolute_error_test.py: 115-155
</a>
<div class="mid" id="frag567" style="display:none"><pre>
    def test_multiple_distributed_runs(self):
        predictions = [
            torch.tensor(
                [
                    [1.0, 1.5, 1.0],
                    [2.0, 3.0, 3.5],
                ]
            ),
            torch.tensor(
                [
                    [4.0, 5.0, 5.5],
                    [6.0, 7.0, 7.5],
                ]
            ),
        ]
        targets = [
            torch.tensor(
                [
                    [0.0, 1.0, 0.0],
                    [2.0, 2.0, 0.0],
                ]
            ),
            torch.tensor(
                [
                    [4.0, 5.0, 0.0],
                    [7.0, 7.0, 0.0],
                ]
            ),
        ]
        metric_kwargs = {"predictions": predictions, "gold_labels": targets}
        desired_values = {"mae": 21.0 / 12.0}
        run_distributed_test(
            [-1, -1],
            multiple_runs,
            MeanAbsoluteError(),
            metric_kwargs,
            desired_values,
            exact=True,
        )


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 29:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag570')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/spearman_correlation_test.py: 50-73
</a>
<div class="mid" id="frag570" style="display:none"><pre>
    def test_unmasked_computation(self, device: str):
        spearman_correlation = SpearmanCorrelation()
        batch_size = 10
        num_labels = 10
        predictions1 = torch.randn(batch_size, num_labels, device=device)
        labels1 = 0.5 * predictions1 + torch.randn(batch_size, num_labels, device=device)

        predictions2 = torch.randn(1, device=device).repeat(num_labels)
        predictions2 = predictions2.unsqueeze(0).expand(batch_size, -1)
        labels2 = torch.randn(1, device=device).expand(num_labels)
        labels2 = 0.5 * predictions2 + labels2.unsqueeze(0).expand(batch_size, -1)

        # in most cases, the data is constructed like predictions_1, the data of such a batch different.
        # but in a few cases, for example, predictions_2, the data of such a batch is exactly the same.
        predictions_labels_ = [(predictions1, labels1), (predictions2, labels2)]

        for predictions, labels in predictions_labels_:
            spearman_correlation.reset()
            spearman_correlation(predictions, labels)
            assert_allclose(
                spearman_formula(predictions.reshape(-1), labels.reshape(-1)),
                spearman_correlation.get_metric(),
            )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag571')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/spearman_correlation_test.py: 75-107
</a>
<div class="mid" id="frag571" style="display:none"><pre>
    def test_masked_computation(self, device: str):
        spearman_correlation = SpearmanCorrelation()
        batch_size = 10
        num_labels = 10
        predictions1 = torch.randn(batch_size, num_labels, device=device)
        labels1 = 0.5 * predictions1 + torch.randn(batch_size, num_labels, device=device)

        predictions2 = torch.randn(1, device=device).expand(num_labels)
        predictions2 = predictions2.unsqueeze(0).expand(batch_size, -1)
        labels2 = torch.randn(1, device=device).expand(num_labels)
        labels2 = 0.5 * predictions2 + labels2.unsqueeze(0).expand(batch_size, -1)

        # in most cases, the data is constructed like predictions_1, the data of such a batch different.
        # but in a few cases, for example, predictions_2, the data of such a batch is exactly the same.
        predictions_labels_ = [(predictions1, labels1), (predictions2, labels2)]

        # Random binary mask
        mask = torch.randint(0, 2, size=(batch_size, num_labels), device=device).bool()

        for predictions, labels in predictions_labels_:
            spearman_correlation.reset()
            spearman_correlation(predictions, labels, mask)
            expected_spearman_correlation = spearman_formula(
                predictions.view(-1), labels.view(-1), mask=mask.view(-1)
            )

            # because add mask, a batch of predictions or labels will have many 0,
            # spearman correlation algorithm will dependence the sorting position of a set of numbers,
            # too many identical numbers will result in different calculation results each time
            # but the positive and negative results are the same,
            # so here we only test the positive and negative results of the results.
            assert (expected_spearman_correlation * spearman_correlation.get_metric()) &gt; 0

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 30:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 94%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag573')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/spearman_correlation_test.py: 133-150
</a>
<div class="mid" id="frag573" style="display:none"><pre>
    def test_distributed_spearman(self):
        batch_size = 10
        num_labels = 10
        predictions = torch.randn(batch_size, num_labels)
        labels = 0.5 * predictions + torch.randn(batch_size, num_labels)
        desired_spearman = spearman_formula(predictions.reshape(-1), labels.reshape(-1))
        predictions = [predictions[:5], predictions[5:]]
        labels = [labels[:5], labels[5:]]
        metric_kwargs = {"predictions": predictions, "gold_labels": labels}
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            SpearmanCorrelation(),
            metric_kwargs,
            desired_spearman,
            exact=False,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag574')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/spearman_correlation_test.py: 151-168
</a>
<div class="mid" id="frag574" style="display:none"><pre>
    def test_distributed_spearman_unequal_batches(self):
        batch_size = 10
        num_labels = 10
        predictions = torch.randn(batch_size, num_labels)
        labels = 0.5 * predictions + torch.randn(batch_size, num_labels)
        desired_spearman = spearman_formula(predictions.reshape(-1), labels.reshape(-1))
        predictions = [predictions[:6], predictions[6:]]
        labels = [labels[:6], labels[6:]]
        metric_kwargs = {"predictions": predictions, "gold_labels": labels}
        with pytest.raises(Exception) as _:
            run_distributed_test(
                [-1, -1],
                global_distributed_metric,
                SpearmanCorrelation(),
                metric_kwargs,
                desired_spearman,
                exact=False,
            )
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 31:</b> &nbsp; 4 fragments, nominal size 37 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag576')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/f1_measure_test.py: 25-75
</a>
<div class="mid" id="frag576" style="display:none"><pre>
    def test_f1_measure(self, device: str):
        f1_measure = F1Measure(positive_label=0)
        predictions = torch.tensor(
            [
                [0.35, 0.25, 0.1, 0.1, 0.2],
                [0.1, 0.6, 0.1, 0.2, 0.0],
                [0.1, 0.6, 0.1, 0.2, 0.0],
                [0.1, 0.5, 0.1, 0.2, 0.0],
                [0.1, 0.2, 0.1, 0.7, 0.0],
                [0.1, 0.6, 0.1, 0.2, 0.0],
            ],
            device=device,
        )
        # [True Positive, True Negative, True Negative,
        #  False Negative, True Negative, False Negative]
        targets = torch.tensor([0, 4, 1, 0, 3, 0], device=device)
        f1_measure(predictions, targets)
        metrics = f1_measure.get_metric()
        precision = metrics["precision"]
        recall = metrics["recall"]
        f1 = metrics["f1"]
        assert f1_measure._true_positives == 1.0
        assert f1_measure._true_negatives == 3.0
        assert f1_measure._false_positives == 0.0
        assert f1_measure._false_negatives == 2.0
        f1_measure.reset()
        # check value
        assert_allclose(precision, 1.0)
        assert_allclose(recall, 0.333333333)
        assert_allclose(f1, 0.499999999)
        # check type
        assert isinstance(precision, float)
        assert isinstance(recall, float)
        assert isinstance(f1, float)

        # Test the same thing with a mask:
        mask = torch.tensor([True, False, True, True, True, False], device=device)
        f1_measure(predictions, targets, mask)
        metrics = f1_measure.get_metric()
        precision = metrics["precision"]
        recall = metrics["recall"]
        f1 = metrics["f1"]
        assert f1_measure._true_positives == 1.0
        assert f1_measure._true_negatives == 2.0
        assert f1_measure._false_positives == 0.0
        assert f1_measure._false_negatives == 1.0
        f1_measure.reset()
        assert_allclose(precision, 1.0)
        assert_allclose(recall, 0.5)
        assert_allclose(f1, 0.6666666666)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag579')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/f1_measure_test.py: 149-189
</a>
<div class="mid" id="frag579" style="display:none"><pre>
    def test_f1_measure_works_for_sequences(self, device: str):
        f1_measure = F1Measure(positive_label=0)
        predictions = torch.tensor(
            [
                [[0.35, 0.25, 0.1, 0.1, 0.2], [0.1, 0.6, 0.1, 0.2, 0.0], [0.1, 0.6, 0.1, 0.2, 0.0]],
                [[0.35, 0.25, 0.1, 0.1, 0.2], [0.1, 0.6, 0.1, 0.2, 0.0], [0.1, 0.6, 0.1, 0.2, 0.0]],
            ],
            device=device,
        )
        # [[True Positive, True Negative, True Negative],
        #  [True Positive, True Negative, False Negative]]
        targets = torch.tensor([[0, 3, 4], [0, 1, 0]], device=device)
        f1_measure(predictions, targets)
        metrics = f1_measure.get_metric()
        precision = metrics["precision"]
        recall = metrics["recall"]
        f1 = metrics["f1"]
        assert f1_measure._true_positives == 2.0
        assert f1_measure._true_negatives == 3.0
        assert f1_measure._false_positives == 0.0
        assert f1_measure._false_negatives == 1.0
        f1_measure.reset()
        assert_allclose(precision, 1.0)
        assert_allclose(recall, 0.666666666)
        assert_allclose(f1, 0.8)

        # Test the same thing with a mask:
        mask = torch.tensor([[False, True, False], [True, True, True]], device=device)
        f1_measure(predictions, targets, mask)
        metrics = f1_measure.get_metric()
        precision = metrics["precision"]
        recall = metrics["recall"]
        f1 = metrics["f1"]
        assert f1_measure._true_positives == 1.0
        assert f1_measure._true_negatives == 2.0
        assert f1_measure._false_positives == 0.0
        assert f1_measure._false_negatives == 1.0
        assert_allclose(precision, 1.0)
        assert_allclose(recall, 0.5)
        assert_allclose(f1, 0.66666666666)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag578')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/f1_measure_test.py: 113-147
</a>
<div class="mid" id="frag578" style="display:none"><pre>
    def test_f1_measure_accumulates_and_resets_correctly(self, device: str):
        f1_measure = F1Measure(positive_label=0)
        predictions = torch.tensor(
            [
                [0.35, 0.25, 0.1, 0.1, 0.2],
                [0.1, 0.6, 0.1, 0.2, 0.0],
                [0.1, 0.6, 0.1, 0.2, 0.0],
                [0.1, 0.5, 0.1, 0.2, 0.0],
                [0.1, 0.2, 0.1, 0.7, 0.0],
                [0.1, 0.6, 0.1, 0.2, 0.0],
            ],
            device=device,
        )
        # [True Positive, True Negative, True Negative,
        #  False Negative, True Negative, False Negative]
        targets = torch.tensor([0, 4, 1, 0, 3, 0], device=device)
        f1_measure(predictions, targets)
        f1_measure(predictions, targets)
        metrics = f1_measure.get_metric()
        precision = metrics["precision"]
        recall = metrics["recall"]
        f1 = metrics["f1"]
        assert f1_measure._true_positives == 2.0
        assert f1_measure._true_negatives == 6.0
        assert f1_measure._false_positives == 0.0
        assert f1_measure._false_negatives == 4.0
        f1_measure.reset()
        assert_allclose(precision, 1.0)
        assert_allclose(recall, 0.333333333)
        assert_allclose(f1, 0.499999999)
        assert f1_measure._true_positives == 0.0
        assert f1_measure._true_negatives == 0.0
        assert f1_measure._false_positives == 0.0
        assert f1_measure._false_negatives == 0.0

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag577')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/f1_measure_test.py: 77-111
</a>
<div class="mid" id="frag577" style="display:none"><pre>
    def test_f1_measure_other_positive_label(self, device: str):
        f1_measure = F1Measure(positive_label=1)
        predictions = torch.tensor(
            [
                [0.35, 0.25, 0.1, 0.1, 0.2],
                [0.1, 0.6, 0.1, 0.2, 0.0],
                [0.1, 0.6, 0.1, 0.2, 0.0],
                [0.1, 0.5, 0.1, 0.2, 0.0],
                [0.1, 0.2, 0.1, 0.7, 0.0],
                [0.1, 0.6, 0.1, 0.2, 0.0],
            ],
            device=device,
        )
        # [True Negative, False Positive, True Positive,
        #  False Positive, True Negative, False Positive]
        targets = torch.tensor([0, 4, 1, 0, 3, 0], device=device)
        f1_measure(predictions, targets)
        metrics = f1_measure.get_metric()
        precision = metrics["precision"]
        recall = metrics["recall"]
        f1 = metrics["f1"]
        assert f1_measure._true_positives == 1.0
        assert f1_measure._true_negatives == 2.0
        assert f1_measure._false_positives == 3.0
        assert f1_measure._false_negatives == 0.0
        f1_measure.reset()
        # check value
        assert_allclose(precision, 0.25)
        assert_allclose(recall, 1.0)
        assert_allclose(f1, 0.4)
        # check type
        assert isinstance(precision, float)
        assert isinstance(recall, float)
        assert isinstance(f1, float)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 32:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 84%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag584')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/attachment_scores_test.py: 49-70
</a>
<div class="mid" id="frag584" style="display:none"><pre>
    def test_unlabeled_accuracy_ignores_incorrect_labels(self, device: str):
        self._send_tensors_to_device(device)

        label_predictions = self.label_predictions
        # Change some stuff so our 4 of our label predictions are wrong.
        label_predictions[0, 3:] = 3
        label_predictions[1, 0] = 7
        self.scorer(
            self.predictions, label_predictions, self.gold_indices, self.gold_labels, self.mask
        )

        metrics = self.scorer.get_metric()

        assert metrics["UAS"] == 1.0
        assert metrics["UEM"] == 1.0

        # 4 / 12 labels were wrong and 2 positions
        # are masked, so 6/10 = 0.6 LAS.
        assert metrics["LAS"] == 0.6
        # Neither should have labeled exact match.
        assert metrics["LEM"] == 0.0

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag585')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/attachment_scores_test.py: 72-97
</a>
<div class="mid" id="frag585" style="display:none"><pre>
    def test_labeled_accuracy_is_affected_by_incorrect_heads(self, device: str):
        self._send_tensors_to_device(device)

        predictions = self.predictions
        # Change some stuff so our 4 of our predictions are wrong.
        predictions[0, 3:] = 3
        predictions[1, 0] = 7
        # This one is in the padded part, so it shouldn't affect anything.
        predictions[1, 5] = 7
        self.scorer(
            predictions, self.label_predictions, self.gold_indices, self.gold_labels, self.mask
        )

        metrics = self.scorer.get_metric()

        # 4 heads are incorrect, so the unlabeled score should be
        # 6/10 = 0.6 LAS.
        assert metrics["UAS"] == 0.6
        # All the labels were correct, but some heads
        # were wrong, so the LAS should equal the UAS.
        assert metrics["LAS"] == 0.6

        # Neither batch element had a perfect labeled or unlabeled EM.
        assert metrics["LEM"] == 0.0
        assert metrics["UEM"] == 0.0

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 33:</b> &nbsp; 2 fragments, nominal size 33 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag587')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/attachment_scores_test.py: 113-152
</a>
<div class="mid" id="frag587" style="display:none"><pre>
    def test_distributed_attachment_scores(self):
        predictions = [torch.Tensor([[0, 1, 3, 5, 2, 4]]), torch.Tensor([[0, 3, 2, 1, 0, 0]])]

        gold_indices = [torch.Tensor([[0, 1, 3, 5, 2, 4]]), torch.Tensor([[0, 3, 2, 1, 0, 0]])]

        label_predictions = [
            torch.Tensor([[0, 5, 2, 3, 3, 3]]),
            torch.Tensor([[7, 4, 8, 2, 0, 0]]),
        ]

        gold_labels = [torch.Tensor([[0, 5, 2, 1, 4, 2]]), torch.Tensor([[0, 4, 8, 2, 0, 0]])]

        mask = [
            torch.tensor([[True, True, True, True, True, True]]),
            torch.tensor([[True, True, True, True, False, False]]),
        ]

        metric_kwargs = {
            "predicted_indices": predictions,
            "gold_indices": gold_indices,
            "predicted_labels": label_predictions,
            "gold_labels": gold_labels,
            "mask": mask,
        }

        desired_metrics = {
            "UAS": 1.0,
            "LAS": 0.6,
            "UEM": 1.0,
            "LEM": 0.0,
        }
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            AttachmentScores(),
            metric_kwargs,
            desired_metrics,
            exact=True,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag588')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/attachment_scores_test.py: 153-193
</a>
<div class="mid" id="frag588" style="display:none"><pre>
    def test_multiple_distributed_runs(self):
        predictions = [torch.Tensor([[0, 1, 3, 5, 2, 4]]), torch.Tensor([[0, 3, 2, 1, 0, 0]])]

        gold_indices = [torch.Tensor([[0, 1, 3, 5, 2, 4]]), torch.Tensor([[0, 3, 2, 1, 0, 0]])]

        label_predictions = [
            torch.Tensor([[0, 5, 2, 3, 3, 3]]),
            torch.Tensor([[7, 4, 8, 2, 0, 0]]),
        ]

        gold_labels = [torch.Tensor([[0, 5, 2, 1, 4, 2]]), torch.Tensor([[0, 4, 8, 2, 0, 0]])]

        mask = [
            torch.tensor([[True, True, True, True, True, True]]),
            torch.tensor([[True, True, True, True, False, False]]),
        ]

        metric_kwargs = {
            "predicted_indices": predictions,
            "gold_indices": gold_indices,
            "predicted_labels": label_predictions,
            "gold_labels": gold_labels,
            "mask": mask,
        }

        desired_metrics = {
            "UAS": 1.0,
            "LAS": 0.6,
            "UEM": 1.0,
            "LEM": 0.0,
        }
        run_distributed_test(
            [-1, -1],
            multiple_runs,
            AttachmentScores(),
            metric_kwargs,
            desired_metrics,
            exact=True,
        )


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 34:</b> &nbsp; 3 fragments, nominal size 17 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag611')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/categorical_accuracy_test.py: 152-168
</a>
<div class="mid" id="frag611" style="display:none"><pre>
    def test_distributed_accuracy(self):
        predictions = [
            torch.tensor([[0.35, 0.25, 0.1, 0.1, 0.2]]),
            torch.tensor([[0.1, 0.6, 0.1, 0.2, 0.0]]),
        ]
        targets = [torch.tensor([0]), torch.tensor([3])]
        metric_kwargs = {"predictions": predictions, "gold_labels": targets}
        desired_accuracy = 0.5
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            CategoricalAccuracy(),
            metric_kwargs,
            desired_accuracy,
            exact=False,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag613')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/categorical_accuracy_test.py: 187-203
</a>
<div class="mid" id="frag613" style="display:none"><pre>
    def test_multiple_distributed_runs(self):
        predictions = [
            torch.tensor([[0.35, 0.25, 0.1, 0.1, 0.2]]),
            torch.tensor([[0.1, 0.6, 0.1, 0.2, 0.0]]),
        ]
        targets = [torch.tensor([0]), torch.tensor([3])]
        metric_kwargs = {"predictions": predictions, "gold_labels": targets}
        desired_accuracy = 0.5
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            CategoricalAccuracy(),
            metric_kwargs,
            desired_accuracy,
            exact=True,
            number_of_runs=200,
        )
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag612')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/categorical_accuracy_test.py: 169-186
</a>
<div class="mid" id="frag612" style="display:none"><pre>
    def test_distributed_accuracy_unequal_batches(self):
        predictions = [
            torch.tensor([[0.35, 0.25, 0.1, 0.1, 0.2], [0.1, 0.6, 0.1, 0.2, 0.0]]),
            torch.tensor([[0.1, 0.2, 0.5, 0.2, 0.0]]),
        ]
        targets = [torch.tensor([0, 3]), torch.tensor([0])]
        mask = [torch.tensor([False, True]), torch.tensor([True])]
        metric_kwargs = {"predictions": predictions, "gold_labels": targets, "mask": mask}
        desired_accuracy = 0.5
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            CategoricalAccuracy(top_k=2),
            metric_kwargs,
            desired_accuracy,
            exact=False,
        )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 35:</b> &nbsp; 2 fragments, nominal size 33 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag631')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 386-423
</a>
<div class="mid" id="frag631" style="display:none"><pre>
    def test_distributed_fbeta_multilabel_measure(self):
        predictions = [
            torch.tensor(
                [
                    [0.55, 0.25, 0.10, 0.10, 0.20],
                    [0.10, 0.60, 0.10, 0.95, 0.00],
                    [0.90, 0.80, 0.75, 0.80, 0.00],
                ]
            ),
            torch.tensor(
                [
                    [0.49, 0.50, 0.95, 0.55, 0.00],
                    [0.60, 0.49, 0.60, 0.65, 0.85],
                    [0.85, 0.40, 0.10, 0.20, 0.00],
                ]
            ),
        ]

        targets = [
            torch.tensor([[1, 1, 0, 0, 0], [0, 1, 0, 1, 0], [1, 1, 0, 1, 0]]),
            torch.tensor([[1, 1, 1, 1, 0], [1, 1, 1, 1, 0], [0, 0, 0, 0, 0]]),
        ]

        metric_kwargs = {"predictions": predictions, "gold_labels": targets}
        desired_metrics = {
            "precision": self.desired_precisions,
            "recall": self.desired_recalls,
            "fscore": self.desired_fscores,
        }
        run_distributed_test(
            [-1, -1],
            global_distributed_metric,
            FBetaMultiLabelMeasure(),
            metric_kwargs,
            desired_metrics,
            exact=False,
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag632')" href="javascript:;">
allennlp-2.4.0/tests/training/metrics/fbeta_multi_label_measure_test.py: 424-460
</a>
<div class="mid" id="frag632" style="display:none"><pre>
    def test_multiple_distributed_runs(self):
        predictions = [
            torch.tensor(
                [
                    [0.55, 0.25, 0.10, 0.10, 0.20],
                    [0.10, 0.60, 0.10, 0.95, 0.00],
                    [0.90, 0.80, 0.75, 0.80, 0.00],
                ]
            ),
            torch.tensor(
                [
                    [0.49, 0.50, 0.95, 0.55, 0.00],
                    [0.60, 0.49, 0.60, 0.65, 0.85],
                    [0.85, 0.40, 0.10, 0.20, 0.00],
                ]
            ),
        ]
        targets = [
            torch.tensor([[1, 1, 0, 0, 0], [0, 1, 0, 1, 0], [1, 1, 0, 1, 0]]),
            torch.tensor([[1, 1, 1, 1, 0], [1, 1, 1, 1, 0], [0, 0, 0, 0, 0]]),
        ]
        metric_kwargs = {"predictions": predictions, "gold_labels": targets}
        desired_metrics = {
            "precision": self.desired_precisions,
            "recall": self.desired_recalls,
            "fscore": self.desired_fscores,
        }
        run_distributed_test(
            [-1, -1],
            multiple_runs,
            FBetaMultiLabelMeasure(),
            metric_kwargs,
            desired_metrics,
            exact=False,
        )


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 36:</b> &nbsp; 2 fragments, nominal size 27 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag659')" href="javascript:;">
allennlp-2.4.0/tests/nn/beam_search_test.py: 110-142
</a>
<div class="mid" id="frag659" style="display:none"><pre>
    def test_finished_state(self):
        state = {}
        state["foo"] = torch.tensor([[1, 0, 1], [2, 0, 1], [0, 0, 1], [1, 1, 1], [0, 0, 0]])
        # shape: (batch_size, 3)

        expected_finished_state = {}
        expected_finished_state["foo"] = np.array(
            [
                [1, 0, 1],
                [1, 0, 1],
                [1, 0, 1],
                [2, 0, 1],
                [2, 0, 1],
                [2, 0, 1],
                [0, 0, 1],
                [0, 0, 1],
                [0, 0, 1],
                [1, 1, 1],
                [1, 1, 1],
                [1, 1, 1],
                [0, 0, 0],
                [0, 0, 0],
                [0, 0, 0],
            ]
        )
        # shape: (batch_size x beam_size, 3)

        self._check_results(state=state)

        # check finished state.
        for key, array in expected_finished_state.items():
            np.testing.assert_allclose(state[key].numpy(), array)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag660')" href="javascript:;">
allennlp-2.4.0/tests/nn/beam_search_test.py: 143-178
</a>
<div class="mid" id="frag660" style="display:none"><pre>
    def test_diff_shape_state(self):
        state = {}
        state["decoder_hidden"] = torch.tensor(
            [[1, 0, 1], [2, 0, 1], [0, 0, 1], [1, 1, 1], [0, 0, 0]]
        )
        state["decoder_hidden"] = state["decoder_hidden"].unsqueeze(0).repeat(2, 1, 1)
        # shape: (2, batch_size, 3)

        seq = [
            [1, 0, 1],
            [1, 0, 1],
            [1, 0, 1],
            [2, 0, 1],
            [2, 0, 1],
            [2, 0, 1],
            [0, 0, 1],
            [0, 0, 1],
            [0, 0, 1],
            [1, 1, 1],
            [1, 1, 1],
            [1, 1, 1],
            [0, 0, 0],
            [0, 0, 0],
            [0, 0, 0],
        ]
        seq = [seq] * 2
        expected_finished_state = {}
        expected_finished_state["decoder_hidden"] = np.array(seq)
        # shape: (2, batch_size x beam_size, 3)

        self._check_results(state=state)

        # check finished state.
        for key, array in expected_finished_state.items():
            np.testing.assert_allclose(state[key].numpy(), array)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 37:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 91%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag670')" href="javascript:;">
allennlp-2.4.0/tests/nn/beam_search_test.py: 261-281
</a>
<div class="mid" id="frag670" style="display:none"><pre>
    def test_top_p_search(self):
        initial_predictions = torch.tensor([0] * 5)
        beam_size = 3
        take_step = take_step_with_timestep
        p_sampler = TopPSampler(p=0.8)

        top_p, log_probs = BeamSearch(
            self.end_index, beam_size=beam_size, max_steps=10, sampler=p_sampler
        ).search(initial_predictions, {}, take_step)

        beam_size = beam_size or 1
        batch_size = 5

        # top_p should be shape `(batch_size, beam_size, max_predicted_length)`.
        assert list(top_p.size())[:-1] == [batch_size, beam_size]

        assert ((0 &lt;= top_p) &amp; (top_p &lt;= 5)).all()

        # log_probs should be shape `(batch_size, beam_size, max_predicted_length)`.
        assert list(log_probs.size()) == [batch_size, beam_size]

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag672')" href="javascript:;">
allennlp-2.4.0/tests/nn/beam_search_test.py: 294-314
</a>
<div class="mid" id="frag672" style="display:none"><pre>
    def test_top_k_search(self):
        initial_predictions = torch.tensor([0] * 5)
        beam_size = 3
        take_step = take_step_with_timestep
        k_sampler = TopKSampler(k=5, with_replacement=True)

        top_k, log_probs = BeamSearch(
            self.end_index, beam_size=beam_size, max_steps=10, sampler=k_sampler
        ).search(initial_predictions, {}, take_step)

        beam_size = beam_size or 1
        batch_size = 5

        # top_p should be shape `(batch_size, beam_size, max_predicted_length)`.
        assert list(top_k.size())[:-1] == [batch_size, beam_size]

        assert ((0 &lt;= top_k) &amp; (top_k &lt;= 5)).all()

        # log_probs should be shape `(batch_size, beam_size, max_predicted_length)`.
        assert list(log_probs.size()) == [batch_size, beam_size]

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 38:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 92%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag675')" href="javascript:;">
allennlp-2.4.0/tests/nn/beam_search_test.py: 358-374
</a>
<div class="mid" id="frag675" style="display:none"><pre>
    def test_params_sampling(self):
        beam_search = BeamSearch.from_params(
            Params(
                {
                    "sampler": {
                        "type": "top-k",
                        "k": 4,
                    },
                    "beam_size": 2,
                    "end_index": 7,
                }
            )
        )
        assert beam_search.beam_size == 2
        assert beam_search._end_index == 7
        assert beam_search.sampler is not None

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag676')" href="javascript:;">
allennlp-2.4.0/tests/nn/beam_search_test.py: 375-391
</a>
<div class="mid" id="frag676" style="display:none"><pre>
    def test_params_p_sampling(self):
        beam_search = BeamSearch.from_params(
            Params(
                {
                    "sampler": {
                        "type": "top-p",
                        "p": 0.8,
                    },
                    "beam_size": 2,
                    "end_index": 7,
                }
            )
        )
        assert beam_search.beam_size == 2
        assert beam_search._end_index == 7
        assert beam_search.sampler is not None

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 39:</b> &nbsp; 2 fragments, nominal size 16 lines, similarity 87%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag696')" href="javascript:;">
allennlp-2.4.0/tests/models/archival_test.py: 36-55
</a>
<div class="mid" id="frag696" style="display:none"><pre>
    def setup_method(self):
        super().setup_method()

        self.params = Params(
            {
                "model": {
                    "type": "simple_tagger",
                    "text_field_embedder": {
                        "token_embedders": {"tokens": {"type": "embedding", "embedding_dim": 5}}
                    },
                    "encoder": {"type": "lstm", "input_size": 5, "hidden_size": 7, "num_layers": 2},
                },
                "dataset_reader": {"type": "sequence_tagging"},
                "train_data_path": str(self.FIXTURES_ROOT / "data" / "sequence_tagging.tsv"),
                "validation_data_path": str(self.FIXTURES_ROOT / "data" / "sequence_tagging.tsv"),
                "data_loader": {"batch_size": 2},
                "trainer": {"num_epochs": 2, "optimizer": "adam", "cuda_device": -1},
            }
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1122')" href="javascript:;">
allennlp-2.4.0/tests/commands/find_learning_rate_test.py: 30-48
</a>
<div class="mid" id="frag1122" style="display:none"><pre>
    def setup_method(self):
        super().setup_method()
        self.params = lambda: Params(
            {
                "model": {
                    "type": "simple_tagger",
                    "text_field_embedder": {
                        "token_embedders": {"tokens": {"type": "embedding", "embedding_dim": 5}}
                    },
                    "encoder": {"type": "lstm", "input_size": 5, "hidden_size": 7, "num_layers": 2},
                },
                "dataset_reader": {"type": "sequence_tagging"},
                "train_data_path": str(self.FIXTURES_ROOT / "data" / "sequence_tagging.tsv"),
                "validation_data_path": str(self.FIXTURES_ROOT / "data" / "sequence_tagging.tsv"),
                "data_loader": {"batch_size": 2},
                "trainer": {"cuda_device": -1, "num_epochs": 2, "optimizer": "adam"},
            }
        )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 40:</b> &nbsp; 4 fragments, nominal size 56 lines, similarity 89%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag730')" href="javascript:;">
allennlp-2.4.0/tests/data/token_indexers/elmo_indexer_test.py: 12-68
</a>
<div class="mid" id="frag730" style="display:none"><pre>
    def test_bos_to_char_ids(self):
        indexer = ELMoTokenCharactersIndexer()
        indices = indexer.tokens_to_indices([Token("&lt;S&gt;")], Vocabulary())
        expected_indices = [
            259,
            257,
            260,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
        ]
        assert indices == {"elmo_tokens": [expected_indices]}

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag732')" href="javascript:;">
allennlp-2.4.0/tests/data/token_indexers/elmo_indexer_test.py: 126-182
</a>
<div class="mid" id="frag732" style="display:none"><pre>
    def test_unicode_to_char_ids(self):
        indexer = ELMoTokenCharactersIndexer()
        indices = indexer.tokens_to_indices([Token(chr(256) + "t")], Vocabulary())
        expected_indices = [
            259,
            197,
            129,
            117,
            260,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
        ]
        assert indices == {"elmo_tokens": [expected_indices]}

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag731')" href="javascript:;">
allennlp-2.4.0/tests/data/token_indexers/elmo_indexer_test.py: 69-125
</a>
<div class="mid" id="frag731" style="display:none"><pre>
    def test_eos_to_char_ids(self):
        indexer = ELMoTokenCharactersIndexer()
        indices = indexer.tokens_to_indices([Token("&lt;/S&gt;")], Vocabulary())
        expected_indices = [
            259,
            258,
            260,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
            261,
        ]
        assert indices == {"elmo_tokens": [expected_indices]}

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag734')" href="javascript:;">
allennlp-2.4.0/tests/data/token_indexers/elmo_indexer_test.py: 349-408
</a>
<div class="mid" id="frag734" style="display:none"><pre>
    def test_elmo_indexer_with_additional_tokens(self):
        indexer = ELMoTokenCharactersIndexer(tokens_to_add={"&lt;first&gt;": 1})
        tokens = [Token("&lt;first&gt;")]
        indices = indexer.tokens_to_indices(tokens, Vocabulary())
        expected_indices = [
            [
                259,
                2,
                260,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
                261,
            ]
        ]
        assert indices["elmo_tokens"] == expected_indices

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 41:</b> &nbsp; 15 fragments, nominal size 19 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag743')" href="javascript:;">
allennlp-2.4.0/tests/data/tokenizers/pretrained_transformer_tokenizer_test.py: 10-28
</a>
<div class="mid" id="frag743" style="display:none"><pre>
    def test_splits_roberta(self):
        tokenizer = PretrainedTransformerTokenizer("roberta-base")

        sentence = "A, &lt;mask&gt; AllenNLP sentence."
        expected_tokens = [
            "&lt;s&gt;",
            "A",
            ",",
            "&lt;mask&gt;",
            "Allen",
            "N",
            "LP",
            "sentence",
            ".",
            "&lt;/s&gt;",
        ]
        tokens = [t.text for t in tokenizer.tokenize(sentence)]
        assert tokens == expected_tokens

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag762')" href="javascript:;">
allennlp-2.4.0/tests/data/tokenizers/spacy_tokenizer_test.py: 36-53
</a>
<div class="mid" id="frag762" style="display:none"><pre>
    def test_tokenize_handles_contraction(self):
        # note that "would've" is kept together, while "ain't" is not.
        sentence = "it ain't joe's problem; would been yesterday"
        expected_tokens = [
            "it",
            "ai",
            "n't",
            "joe",
            "'s",
            "problem",
            ";",
            "would",
            "been",
            "yesterday",
        ]
        tokens = [t.text for t in self.word_tokenizer.tokenize(sentence)]
        assert tokens == expected_tokens

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag778')" href="javascript:;">
allennlp-2.4.0/tests/data/tokenizers/letters_digits_tokenizer_test.py: 10-28
</a>
<div class="mid" id="frag778" style="display:none"><pre>
    def test_tokenize_handles_complex_punctuation(self):
        sentence = "this (sentence) has 'crazy' \"punctuation\"."
        expected_tokens = [
            "this",
            "(",
            "sentence",
            ")",
            "has",
            "'",
            "crazy",
            "'",
            '"',
            "punctuation",
            '"',
            ".",
        ]
        tokens = [t.text for t in self.word_tokenizer.tokenize(sentence)]
        assert tokens == expected_tokens

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag744')" href="javascript:;">
allennlp-2.4.0/tests/data/tokenizers/pretrained_transformer_tokenizer_test.py: 29-47
</a>
<div class="mid" id="frag744" style="display:none"><pre>
    def test_splits_cased_bert(self):
        tokenizer = PretrainedTransformerTokenizer("bert-base-cased")

        sentence = "A, [MASK] AllenNLP sentence."
        expected_tokens = [
            "[CLS]",
            "A",
            ",",
            "[MASK]",
            "Allen",
            "##NL",
            "##P",
            "sentence",
            ".",
            "[SEP]",
        ]
        tokens = [t.text for t in tokenizer.tokenize(sentence)]
        assert tokens == expected_tokens

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag754')" href="javascript:;">
allennlp-2.4.0/tests/data/tokenizers/pretrained_transformer_tokenizer_test.py: 245-266
</a>
<div class="mid" id="frag754" style="display:none"><pre>
    def test_intra_word_tokenize_whitespaces(self):
        tokenizer = PretrainedTransformerTokenizer("bert-base-cased")

        sentence = ["A,", " ", "[MASK]", "AllenNLP", "\u007f", "sentence."]
        expected_tokens = [
            "[CLS]",
            "A",
            ",",
            "[MASK]",
            "Allen",
            "##NL",
            "##P",
            "sentence",
            ".",
            "[SEP]",
        ]
        expected_offsets = [(1, 2), None, (3, 3), (4, 6), None, (7, 8)]
        tokens, offsets = tokenizer.intra_word_tokenize(sentence)
        tokens = [t.text for t in tokens]
        assert tokens == expected_tokens
        assert offsets == expected_offsets

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag745')" href="javascript:;">
allennlp-2.4.0/tests/data/tokenizers/pretrained_transformer_tokenizer_test.py: 48-65
</a>
<div class="mid" id="frag745" style="display:none"><pre>
    def test_splits_uncased_bert(self):
        sentence = "A, [MASK] AllenNLP sentence."
        expected_tokens = [
            "[CLS]",
            "a",
            ",",
            "[MASK]",
            "allen",
            "##nl",
            "##p",
            "sentence",
            ".",
            "[SEP]",
        ]
        tokenizer = PretrainedTransformerTokenizer("bert-base-uncased")
        tokens = [t.text for t in tokenizer.tokenize(sentence)]
        assert tokens == expected_tokens

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag766')" href="javascript:;">
allennlp-2.4.0/tests/data/tokenizers/spacy_tokenizer_test.py: 72-94
</a>
<div class="mid" id="frag766" style="display:none"><pre>
    def test_tokenize_handles_special_cases(self):
        # note that the etc. doesn't quite work --- we can special case this if we want.
        sentence = "Mr. and Mrs. Jones, etc., went to, e.g., the store"
        expected_tokens = [
            "Mr.",
            "and",
            "Mrs.",
            "Jones",
            ",",
            "etc",
            ".",
            ",",
            "went",
            "to",
            ",",
            "e.g.",
            ",",
            "the",
            "store",
        ]
        tokens = [t.text for t in self.word_tokenizer.tokenize(sentence)]
        assert tokens == expected_tokens

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag758')" href="javascript:;">
allennlp-2.4.0/tests/data/tokenizers/pretrained_transformer_tokenizer_test.py: 308-325
</a>
<div class="mid" id="frag758" style="display:none"><pre>
    def test_tokenizer_kwargs_default(self):
        text = "Hello there! General Kenobi."
        tokenizer = PretrainedTransformerTokenizer("bert-base-cased")
        original_tokens = [
            "[CLS]",
            "Hello",
            "there",
            "!",
            "General",
            "Ken",
            "##ob",
            "##i",
            ".",
            "[SEP]",
        ]
        tokenized = [token.text for token in tokenizer.tokenize(text)]
        assert tokenized == original_tokens

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag780')" href="javascript:;">
allennlp-2.4.0/tests/data/tokenizers/letters_digits_tokenizer_test.py: 41-62
</a>
<div class="mid" id="frag780" style="display:none"><pre>
    def test_tokenize_handles_splits_all_punctuation(self):
        sentence = "wouldn't.[have] -3.45(m^2)"
        expected_tokens = [
            "wouldn",
            "'",
            "t",
            ".",
            "[",
            "have",
            "]",
            "-",
            "3",
            ".",
            "45",
            "(",
            "m",
            "^",
            "2",
            ")",
        ]
        tokens = [t.text for t in self.word_tokenizer.tokenize(sentence)]
        assert tokens == expected_tokens
</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag751')" href="javascript:;">
allennlp-2.4.0/tests/data/tokenizers/pretrained_transformer_tokenizer_test.py: 160-182
</a>
<div class="mid" id="frag751" style="display:none"><pre>
    def test_token_idx_roberta(self):
        sentence = "A, nave &lt;mask&gt; AllenNLP sentence."
        expected_tokens = [
            "&lt;s&gt;",
            "A",
            ",",
            "nave",  # RoBERTa mangles this. Or maybe it "encodes"?
            "&lt;mask&gt;",
            "Allen",
            "N",
            "LP",
            "sentence",
            ".",
            "&lt;/s&gt;",
        ]
        expected_idxs = [None, 0, 1, 3, 9, 16, 21, 22, 25, 33, None]
        tokenizer = PretrainedTransformerTokenizer("roberta-base")
        tokenized = tokenizer.tokenize(sentence)
        tokens = [t.text for t in tokenized]
        assert tokens == expected_tokens
        idxs = [t.idx for t in tokenized]
        assert idxs == expected_idxs

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag761')" href="javascript:;">
allennlp-2.4.0/tests/data/tokenizers/spacy_tokenizer_test.py: 12-35
</a>
<div class="mid" id="frag761" style="display:none"><pre>
    def test_tokenize_handles_complex_punctuation(self):
        sentence = "this (sentence) has 'crazy' \"punctuation\"."
        expected_tokens = [
            "this",
            "(",
            "sentence",
            ")",
            "has",
            "'",
            "crazy",
            "'",
            '"',
            "punctuation",
            '"',
            ".",
        ]
        tokens = self.word_tokenizer.tokenize(sentence)
        token_text = [t.text for t in tokens]
        assert token_text == expected_tokens
        for token in tokens:
            start = token.idx
            end = start + len(token.text)
            assert sentence[start:end] == token.text

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag747')" href="javascript:;">
allennlp-2.4.0/tests/data/tokenizers/pretrained_transformer_tokenizer_test.py: 94-116
</a>
<div class="mid" id="frag747" style="display:none"><pre>
    def test_token_idx_bert_uncased(self):
        sentence = "A, nave [MASK] AllenNLP sentence."
        expected_tokens = [
            "[CLS]",
            "a",
            ",",
            "naive",  # BERT normalizes this away
            "[MASK]",
            "allen",
            "##nl",
            "##p",
            "sentence",
            ".",
            "[SEP]",
        ]
        expected_idxs = [None, 0, 1, 3, 9, 16, 21, 23, 25, 33, None]
        tokenizer = PretrainedTransformerTokenizer("bert-base-uncased")
        tokenized = tokenizer.tokenize(sentence)
        tokens = [t.text for t in tokenized]
        assert tokens == expected_tokens
        idxs = [t.idx for t in tokenized]
        assert idxs == expected_idxs

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag748')" href="javascript:;">
allennlp-2.4.0/tests/data/tokenizers/pretrained_transformer_tokenizer_test.py: 117-141
</a>
<div class="mid" id="frag748" style="display:none"><pre>
    def test_token_idx_bert_cased(self):
        sentence = "A, nave [MASK] AllenNLP sentence."
        expected_tokens = [
            "[CLS]",
            "A",
            ",",
            "na",
            "##",
            "##ve",
            "[MASK]",
            "Allen",
            "##NL",
            "##P",
            "sentence",
            ".",
            "[SEP]",
        ]
        expected_idxs = [None, 0, 1, 3, 5, 6, 9, 16, 21, 23, 25, 33, None]
        tokenizer = PretrainedTransformerTokenizer("bert-base-cased")
        tokenized = tokenizer.tokenize(sentence)
        tokens = [t.text for t in tokenized]
        assert tokens == expected_tokens
        idxs = [t.idx for t in tokenized]
        assert idxs == expected_idxs

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag746')" href="javascript:;">
allennlp-2.4.0/tests/data/tokenizers/pretrained_transformer_tokenizer_test.py: 66-93
</a>
<div class="mid" id="frag746" style="display:none"><pre>
    def test_splits_reformer_small(self):
        sentence = "A, [MASK] AllenNLP sentence."
        expected_tokens = [
            "A",
            ",",
            "",
            "&lt;unk&gt;",
            "M",
            "A",
            "S",
            "K",
            "&lt;unk&gt;",
            "A",
            "ll",
            "en",
            "N",
            "L",
            "P",
            "s",
            "ent",
            "en",
            "ce",
            ".",
        ]
        tokenizer = PretrainedTransformerTokenizer("google/reformer-crime-and-punishment")
        tokens = [t.text for t in tokenizer.tokenize(sentence)]
        assert tokens == expected_tokens

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag774')" href="javascript:;">
allennlp-2.4.0/tests/data/tokenizers/character_tokenizer_test.py: 6-35
</a>
<div class="mid" id="frag774" style="display:none"><pre>
    def test_splits_into_characters(self):
        tokenizer = CharacterTokenizer(start_tokens=["&lt;S1&gt;", "&lt;S2&gt;"], end_tokens=["&lt;/S2&gt;", "&lt;/S1&gt;"])
        sentence = "A, small sentence."
        tokens = [t.text for t in tokenizer.tokenize(sentence)]
        expected_tokens = [
            "&lt;S1&gt;",
            "&lt;S2&gt;",
            "A",
            ",",
            " ",
            "s",
            "m",
            "a",
            "l",
            "l",
            " ",
            "s",
            "e",
            "n",
            "t",
            "e",
            "n",
            "c",
            "e",
            ".",
            "&lt;/S2&gt;",
            "&lt;/S1&gt;",
        ]
        assert tokens == expected_tokens

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 42:</b> &nbsp; 4 fragments, nominal size 13 lines, similarity 78%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag767')" href="javascript:;">
allennlp-2.4.0/tests/data/tokenizers/spacy_tokenizer_test.py: 95-108
</a>
<div class="mid" id="frag767" style="display:none"><pre>
    def test_batch_tokenization(self):
        sentences = [
            "This is     a sentence",
            "This isn't a sentence.",
            "This is the 3rd     sentence." "Here's the 'fourth' sentence.",
        ]
        batch_split = self.word_tokenizer.batch_tokenize(sentences)
        separately_split = [self.word_tokenizer.tokenize(sentence) for sentence in sentences]
        assert len(batch_split) == len(separately_split)
        for batch_sentence, separate_sentence in zip(batch_split, separately_split):
            assert len(batch_sentence) == len(separate_sentence)
            for batch_word, separate_word in zip(batch_sentence, separate_sentence):
                assert batch_word.text == separate_word.text

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag772')" href="javascript:;">
allennlp-2.4.0/tests/data/tokenizers/sentence_splitter_test.py: 23-35
</a>
<div class="mid" id="frag772" style="display:none"><pre>
    def test_batch_rule_based_sentence_splitting(self):
        text = [
            "This is a sentence. This is a second sentence.",
            "This isn't a sentence. This is a second sentence! This is a third sentence.",
        ]
        batch_split = self.rule_based_splitter.batch_split_sentences(text)
        separately_split = [self.rule_based_splitter.split_sentences(doc) for doc in text]
        assert len(batch_split) == len(separately_split)
        for batch_doc, separate_doc in zip(batch_split, separately_split):
            assert len(batch_doc) == len(separate_doc)
            for batch_sentence, separate_sentence in zip(batch_doc, separate_doc):
                assert batch_sentence == separate_sentence

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag773')" href="javascript:;">
allennlp-2.4.0/tests/data/tokenizers/sentence_splitter_test.py: 36-47
</a>
<div class="mid" id="frag773" style="display:none"><pre>
    def test_batch_dep_parse_sentence_splitting(self):
        text = [
            "This is a sentence. This is a second sentence.",
            "This isn't a sentence. This is a second sentence! This is a third sentence.",
        ]
        batch_split = self.dep_parse_splitter.batch_split_sentences(text)
        separately_split = [self.dep_parse_splitter.split_sentences(doc) for doc in text]
        assert len(batch_split) == len(separately_split)
        for batch_doc, separate_doc in zip(batch_split, separately_split):
            assert len(batch_doc) == len(separate_doc)
            for batch_sentence, separate_sentence in zip(batch_doc, separate_doc):
                assert batch_sentence == separate_sentence
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag775')" href="javascript:;">
allennlp-2.4.0/tests/data/tokenizers/character_tokenizer_test.py: 36-50
</a>
<div class="mid" id="frag775" style="display:none"><pre>
    def test_batch_tokenization(self):
        tokenizer = CharacterTokenizer()
        sentences = [
            "This is a sentence",
            "This isn't a sentence.",
            "This is the 3rd sentence." "Here's the 'fourth' sentence.",
        ]
        batch_tokenized = tokenizer.batch_tokenize(sentences)
        separately_tokenized = [tokenizer.tokenize(sentence) for sentence in sentences]
        assert len(batch_tokenized) == len(separately_tokenized)
        for batch_sentence, separate_sentence in zip(batch_tokenized, separately_tokenized):
            assert len(batch_sentence) == len(separate_sentence)
            for batch_word, separate_word in zip(batch_sentence, separate_sentence):
                assert batch_word.text == separate_word.text

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 43:</b> &nbsp; 2 fragments, nominal size 17 lines, similarity 82%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag781')" href="javascript:;">
allennlp-2.4.0/tests/data/dataset_readers/sequence_tagging_test.py: 6-25
</a>
<div class="mid" id="frag781" style="display:none"><pre>
    def test_default_format(self):
        reader = SequenceTaggingDatasetReader(max_instances=4)
        instances = list(
            reader.read(AllenNlpTestCase.FIXTURES_ROOT / "data" / "sequence_tagging.tsv")
        )

        assert len(instances) == 4
        fields = instances[0].fields
        assert [t.text for t in fields["tokens"].tokens] == ["cats", "are", "animals", "."]
        assert fields["tags"].labels == ["N", "V", "N", "N"]
        fields = instances[1].fields
        assert [t.text for t in fields["tokens"].tokens] == ["dogs", "are", "animals", "."]
        assert fields["tags"].labels == ["N", "V", "N", "N"]
        fields = instances[2].fields
        assert [t.text for t in fields["tokens"].tokens] == ["snakes", "are", "animals", "."]
        assert fields["tags"].labels == ["N", "V", "N", "N"]
        fields = instances[3].fields
        assert [t.text for t in fields["tokens"].tokens] == ["birds", "are", "animals", "."]
        assert fields["tags"].labels == ["N", "V", "N", "N"]

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag782')" href="javascript:;">
allennlp-2.4.0/tests/data/dataset_readers/sequence_tagging_test.py: 26-42
</a>
<div class="mid" id="frag782" style="display:none"><pre>
    def test_brown_corpus_format(self):
        reader = SequenceTaggingDatasetReader(word_tag_delimiter="/")
        instances = list(reader.read(AllenNlpTestCase.FIXTURES_ROOT / "data" / "brown_corpus.txt"))

        assert len(instances) == 4
        fields = instances[0].fields
        assert [t.text for t in fields["tokens"].tokens] == ["cats", "are", "animals", "."]
        assert fields["tags"].labels == ["N", "V", "N", "N"]
        fields = instances[1].fields
        assert [t.text for t in fields["tokens"].tokens] == ["dogs", "are", "animals", "."]
        assert fields["tags"].labels == ["N", "V", "N", "N"]
        fields = instances[2].fields
        assert [t.text for t in fields["tokens"].tokens] == ["snakes", "are", "animals", "."]
        assert fields["tags"].labels == ["N", "V", "N", "N"]
        fields = instances[3].fields
        assert [t.text for t in fields["tokens"].tokens] == ["birds", "are", "animals", "."]
        assert fields["tags"].labels == ["N", "V", "N", "N"]
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 44:</b> &nbsp; 2 fragments, nominal size 16 lines, similarity 93%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag791')" href="javascript:;">
allennlp-2.4.0/tests/data/dataset_readers/conll2003_test.py: 12-32
</a>
<div class="mid" id="frag791" style="display:none"><pre>
    def test_read_from_file_with_deprecated_parameter(self, coding_scheme):
        conll_reader = Conll2003DatasetReader(coding_scheme=coding_scheme)
        instances = ensure_list(
            conll_reader.read(AllenNlpTestCase.FIXTURES_ROOT / "data" / "conll2003.txt")
        )

        if coding_scheme == "IOB1":
            expected_labels = ["I-ORG", "O", "I-PER", "O", "O", "I-LOC", "O"]
        else:
            expected_labels = ["U-ORG", "O", "U-PER", "O", "O", "U-LOC", "O"]

        fields = instances[0].fields
        tokens = [t.text for t in fields["tokens"].tokens]
        assert tokens == ["U.N.", "official", "Ekeus", "heads", "for", "Baghdad", "."]
        assert fields["tags"].labels == expected_labels

        fields = instances[1].fields
        tokens = [t.text for t in fields["tokens"].tokens]
        assert tokens == ["AI2", "engineer", "Joel", "lives", "in", "Seattle", "."]
        assert fields["tags"].labels == expected_labels

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag792')" href="javascript:;">
allennlp-2.4.0/tests/data/dataset_readers/conll2003_test.py: 34-54
</a>
<div class="mid" id="frag792" style="display:none"><pre>
    def test_read_from_file(self, convert_to_coding_scheme):
        conll_reader = Conll2003DatasetReader(convert_to_coding_scheme=convert_to_coding_scheme)
        instances = ensure_list(
            conll_reader.read(AllenNlpTestCase.FIXTURES_ROOT / "data" / "conll2003.txt")
        )

        if convert_to_coding_scheme is None:
            expected_labels = ["I-ORG", "O", "I-PER", "O", "O", "I-LOC", "O"]
        else:
            expected_labels = ["U-ORG", "O", "U-PER", "O", "O", "U-LOC", "O"]

        fields = instances[0].fields
        tokens = [t.text for t in fields["tokens"].tokens]
        assert tokens == ["U.N.", "official", "Ekeus", "heads", "for", "Baghdad", "."]
        assert fields["tags"].labels == expected_labels

        fields = instances[1].fields
        tokens = [t.text for t in fields["tokens"].tokens]
        assert tokens == ["AI2", "engineer", "Joel", "lives", "in", "Seattle", "."]
        assert fields["tags"].labels == expected_labels

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 45:</b> &nbsp; 2 fragments, nominal size 40 lines, similarity 73%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag814')" href="javascript:;">
allennlp-2.4.0/tests/data/fields/list_field_test.py: 174-228
</a>
<div class="mid" id="frag814" style="display:none"><pre>
    def test_as_tensor_can_handle_multiple_token_indexers(self):

        self.field1._token_indexers = self.words_and_characters_indexers
        self.field2._token_indexers = self.words_and_characters_indexers
        self.field3._token_indexers = self.words_and_characters_indexers

        list_field = ListField([self.field1, self.field2, self.field3])
        list_field.index(self.vocab)
        padding_lengths = list_field.get_padding_lengths()
        tensor_dict = list_field.as_tensor(padding_lengths)
        words = tensor_dict["words"]["tokens"].detach().cpu().numpy()
        characters = tensor_dict["characters"]["token_characters"].detach().cpu().numpy()
        numpy.testing.assert_array_almost_equal(
            words, numpy.array([[2, 3, 4, 5, 0], [2, 3, 4, 1, 5], [2, 3, 1, 5, 0]])
        )

        numpy.testing.assert_array_almost_equal(
            characters[0],
            numpy.array(
                [
                    [5, 1, 1, 2, 0, 0, 0, 0, 0],
                    [1, 2, 0, 0, 0, 0, 0, 0, 0],
                    [1, 0, 0, 0, 0, 0, 0, 0, 0],
                    [2, 3, 4, 5, 3, 4, 6, 3, 0],
                    [0, 0, 0, 0, 0, 0, 0, 0, 0],
                ]
            ),
        )

        numpy.testing.assert_array_almost_equal(
            characters[1],
            numpy.array(
                [
                    [5, 1, 1, 2, 0, 0, 0, 0, 0],
                    [1, 2, 0, 0, 0, 0, 0, 0, 0],
                    [1, 0, 0, 0, 0, 0, 0, 0, 0],
                    [1, 1, 1, 1, 3, 1, 3, 4, 5],
                    [2, 3, 4, 5, 3, 4, 6, 3, 0],
                ]
            ),
        )

        numpy.testing.assert_array_almost_equal(
            characters[2],
            numpy.array(
                [
                    [5, 1, 1, 2, 0, 0, 0, 0, 0],
                    [1, 2, 0, 0, 0, 0, 0, 0, 0],
                    [1, 4, 1, 5, 1, 3, 1, 0, 0],
                    [2, 3, 4, 5, 3, 4, 6, 3, 0],
                    [0, 0, 0, 0, 0, 0, 0, 0, 0],
                ]
            ),
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag815')" href="javascript:;">
allennlp-2.4.0/tests/data/fields/list_field_test.py: 229-273
</a>
<div class="mid" id="frag815" style="display:none"><pre>
    def test_as_tensor_can_handle_multiple_token_indexers_and_empty_fields(self):

        self.field1._token_indexers = self.words_and_characters_indexers
        self.field2._token_indexers = self.words_and_characters_indexers
        self.field3._token_indexers = self.words_and_characters_indexers

        list_field = ListField([self.field1.empty_field(), self.field1, self.field2])
        list_field.index(self.vocab)
        padding_lengths = list_field.get_padding_lengths()
        tensor_dict = list_field.as_tensor(padding_lengths)
        words = tensor_dict["words"]["tokens"].detach().cpu().numpy()
        characters = tensor_dict["characters"]["token_characters"].detach().cpu().numpy()

        numpy.testing.assert_array_almost_equal(
            words, numpy.array([[0, 0, 0, 0, 0], [2, 3, 4, 5, 0], [2, 3, 4, 1, 5]])
        )

        numpy.testing.assert_array_almost_equal(characters[0], numpy.zeros([5, 9]))

        numpy.testing.assert_array_almost_equal(
            characters[1],
            numpy.array(
                [
                    [5, 1, 1, 2, 0, 0, 0, 0, 0],
                    [1, 2, 0, 0, 0, 0, 0, 0, 0],
                    [1, 0, 0, 0, 0, 0, 0, 0, 0],
                    [2, 3, 4, 5, 3, 4, 6, 3, 0],
                    [0, 0, 0, 0, 0, 0, 0, 0, 0],
                ]
            ),
        )

        numpy.testing.assert_array_almost_equal(
            characters[2],
            numpy.array(
                [
                    [5, 1, 1, 2, 0, 0, 0, 0, 0],
                    [1, 2, 0, 0, 0, 0, 0, 0, 0],
                    [1, 0, 0, 0, 0, 0, 0, 0, 0],
                    [1, 1, 1, 1, 3, 1, 3, 4, 5],
                    [2, 3, 4, 5, 3, 4, 6, 3, 0],
                ]
            ),
        )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 46:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag864')" href="javascript:;">
allennlp-2.4.0/tests/data/samplers/max_tokens_batch_sampler_test.py: 10-25
</a>
<div class="mid" id="frag864" style="display:none"><pre>
    def test_create_batches_groups_correctly(self):
        sampler = MaxTokensBatchSampler(max_tokens=8, padding_noise=0, sorting_keys=["text"])

        grouped_instances = []
        for indices in sampler.get_batch_indices(self.instances):
            grouped_instances.append([self.instances[idx] for idx in indices])
        expected_groups = [
            [self.instances[4], self.instances[2]],
            [self.instances[0], self.instances[1]],
            [self.instances[3]],
        ]
        for group in grouped_instances:
            assert group in expected_groups
            expected_groups.remove(group)
        assert expected_groups == []

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag877')" href="javascript:;">
allennlp-2.4.0/tests/data/samplers/bucket_batch_sampler_test.py: 11-26
</a>
<div class="mid" id="frag877" style="display:none"><pre>
    def test_create_batches_groups_correctly(self):
        sampler = BucketBatchSampler(batch_size=2, padding_noise=0, sorting_keys=["text"])

        grouped_instances = []
        for indices in sampler.get_batch_indices(self.instances):
            grouped_instances.append([self.instances[idx] for idx in indices])
        expected_groups = [
            [self.instances[4], self.instances[2]],
            [self.instances[0], self.instances[1]],
            [self.instances[3]],
        ]
        for group in grouped_instances:
            assert group in expected_groups
            expected_groups.remove(group)
        assert expected_groups == []

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 47:</b> &nbsp; 2 fragments, nominal size 26 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag865')" href="javascript:;">
allennlp-2.4.0/tests/data/samplers/max_tokens_batch_sampler_test.py: 26-58
</a>
<div class="mid" id="frag865" style="display:none"><pre>
    def test_guess_sorting_key_picks_the_longest_key(self):
        sampler = MaxTokensBatchSampler(max_tokens=8, padding_noise=0)
        instances = []
        short_tokens = [Token(t) for t in ["what", "is", "this", "?"]]
        long_tokens = [Token(t) for t in ["this", "is", "a", "not", "very", "long", "passage"]]
        instances.append(
            Instance(
                {
                    "question": TextField(short_tokens, self.token_indexers),
                    "passage": TextField(long_tokens, self.token_indexers),
                }
            )
        )
        instances.append(
            Instance(
                {
                    "question": TextField(short_tokens, self.token_indexers),
                    "passage": TextField(long_tokens, self.token_indexers),
                }
            )
        )
        instances.append(
            Instance(
                {
                    "question": TextField(short_tokens, self.token_indexers),
                    "passage": TextField(long_tokens, self.token_indexers),
                }
            )
        )
        assert sampler.sorting_keys is None
        sampler._guess_sorting_keys(instances)
        assert sampler.sorting_keys == ["passage"]

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag878')" href="javascript:;">
allennlp-2.4.0/tests/data/samplers/bucket_batch_sampler_test.py: 27-59
</a>
<div class="mid" id="frag878" style="display:none"><pre>
    def test_guess_sorting_key_picks_the_longest_key(self):
        sampler = BucketBatchSampler(batch_size=2, padding_noise=0)
        instances = []
        short_tokens = [Token(t) for t in ["what", "is", "this", "?"]]
        long_tokens = [Token(t) for t in ["this", "is", "a", "not", "very", "long", "passage"]]
        instances.append(
            Instance(
                {
                    "question": TextField(short_tokens, self.token_indexers),
                    "passage": TextField(long_tokens, self.token_indexers),
                }
            )
        )
        instances.append(
            Instance(
                {
                    "question": TextField(short_tokens, self.token_indexers),
                    "passage": TextField(long_tokens, self.token_indexers),
                }
            )
        )
        instances.append(
            Instance(
                {
                    "question": TextField(short_tokens, self.token_indexers),
                    "passage": TextField(long_tokens, self.token_indexers),
                }
            )
        )
        assert sampler.sorting_keys is None
        sampler._guess_sorting_keys(instances)
        assert sampler.sorting_keys == ["passage"]

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 48:</b> &nbsp; 2 fragments, nominal size 25 lines, similarity 88%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag886')" href="javascript:;">
allennlp-2.4.0/tests/data/data_loaders/multitask_data_loader_test.py: 30-55
</a>
<div class="mid" id="frag886" style="display:none"><pre>
    def test_loading(self):
        reader = MultiTaskDatasetReader(
            readers={"a": FakeDatasetReaderA(), "b": FakeDatasetReaderB()}
        )
        data_path = {"a": "ignored", "b": "ignored"}
        scheduler = RoundRobinScheduler(batch_size=4)
        sampler = UniformSampler()
        loader = MultiTaskDataLoader(
            reader=reader,
            data_path=data_path,
            scheduler=scheduler,
            sampler=sampler,
            instances_per_epoch=8,
            max_instances_in_memory={"a": 10, "b": 10},
        )
        vocab = Vocabulary()
        vocab.add_tokens_to_namespace(["A", "B"], "labels")
        loader.index_with(vocab)
        iterator = iter(loader)
        batch = next(iterator)
        assert torch.all(batch["label"] == torch.IntTensor([0, 1, 0, 1]))
        batch = next(iterator)
        assert torch.all(batch["label"] == torch.IntTensor([0, 1, 0, 1]))
        with pytest.raises(StopIteration):
            next(iterator)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag887')" href="javascript:;">
allennlp-2.4.0/tests/data/data_loaders/multitask_data_loader_test.py: 56-81
</a>
<div class="mid" id="frag887" style="display:none"><pre>
    def test_loading_with_sampler(self):
        reader = MultiTaskDatasetReader(
            readers={"a": FakeDatasetReaderA(), "b": FakeDatasetReaderB()}
        )
        data_path = {"a": "ignored", "b": "ignored"}
        scheduler = RoundRobinScheduler(batch_size=4)
        sampler = WeightedSampler({"a": 1, "b": 2})
        loader = MultiTaskDataLoader(
            reader=reader,
            data_path=data_path,
            scheduler=scheduler,
            sampler=sampler,
            instances_per_epoch=9,
        )
        vocab = Vocabulary()
        vocab.add_tokens_to_namespace(["A", "B"], "labels")
        loader.index_with(vocab)
        iterator = iter(loader)
        batch = next(iterator)
        assert torch.all(batch["label"] == torch.IntTensor([0, 1, 0, 1]))
        batch = next(iterator)
        assert torch.all(batch["label"] == torch.IntTensor([0, 1, 1, 1]))
        batch = next(iterator)
        assert torch.all(batch["label"] == torch.IntTensor([1]))
        with pytest.raises(StopIteration):
            next(iterator)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 49:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 89%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag912')" href="javascript:;">
allennlp-2.4.0/tests/common/file_utils_test.py: 182-201
</a>
<div class="mid" id="frag912" style="display:none"><pre>
    def test_resource_to_filename_with_etags(self):
        for url in [
            "http://allenai.org",
            "http://allennlp.org",
            "https://www.google.com",
            "http://pytorch.org",
        ]:
            filename = _resource_to_filename(url, etag="mytag")
            assert "http" not in filename
            pathlib.Path(os.path.join(self.TEST_DIR, filename)).touch()
            json.dump(
                {"url": url, "etag": "mytag"},
                open(os.path.join(self.TEST_DIR, filename + ".json"), "w"),
            )
            back_to_url, etag = filename_to_url(filename, cache_dir=self.TEST_DIR)
            assert back_to_url == url
            assert etag == "mytag"
        baseurl = "http://allenai.org/"
        assert _resource_to_filename(baseurl + "1") != _resource_to_filename(baseurl, etag="1")

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag913')" href="javascript:;">
allennlp-2.4.0/tests/common/file_utils_test.py: 202-219
</a>
<div class="mid" id="frag913" style="display:none"><pre>
    def test_resource_to_filename_with_etags_eliminates_quotes(self):
        for url in [
            "http://allenai.org",
            "http://allennlp.org",
            "https://www.google.com",
            "http://pytorch.org",
        ]:
            filename = _resource_to_filename(url, etag='"mytag"')
            assert "http" not in filename
            pathlib.Path(os.path.join(self.TEST_DIR, filename)).touch()
            json.dump(
                {"url": url, "etag": "mytag"},
                open(os.path.join(self.TEST_DIR, filename + ".json"), "w"),
            )
            back_to_url, etag = filename_to_url(filename, cache_dir=self.TEST_DIR)
            assert back_to_url == url
            assert etag == "mytag"

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 50:</b> &nbsp; 2 fragments, nominal size 21 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag929')" href="javascript:;">
allennlp-2.4.0/tests/common/file_utils_test.py: 459-482
</a>
<div class="mid" id="frag929" style="display:none"><pre>
    def test_cached_path_extract_remote_tar(self):
        url = "http://fake.datastore.com/utf-8.tar.gz"
        byt = open(self.tar_file, "rb").read()

        responses.add(
            responses.GET,
            url,
            body=byt,
            status=200,
            content_type="application/tar+gzip",
            stream=True,
            headers={"Content-Length": str(len(byt))},
        )
        responses.add(
            responses.HEAD,
            url,
            status=200,
            headers={"ETag": "fake-etag"},
        )

        extracted = cached_path(url, cache_dir=self.TEST_DIR, extract_archive=True)
        assert extracted.endswith("-extracted")
        self.check_extracted(extracted)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag930')" href="javascript:;">
allennlp-2.4.0/tests/common/file_utils_test.py: 484-508
</a>
<div class="mid" id="frag930" style="display:none"><pre>
    def test_cached_path_extract_remote_zip(self):
        url = "http://fake.datastore.com/utf-8.zip"
        byt = open(self.zip_file, "rb").read()

        responses.add(
            responses.GET,
            url,
            body=byt,
            status=200,
            content_type="application/zip",
            stream=True,
            headers={"Content-Length": str(len(byt))},
        )
        responses.add(
            responses.HEAD,
            url,
            status=200,
            headers={"ETag": "fake-etag"},
        )

        extracted = cached_path(url, cache_dir=self.TEST_DIR, extract_archive=True)
        assert extracted.endswith("-extracted")
        self.check_extracted(extracted)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 51:</b> &nbsp; 2 fragments, nominal size 26 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag983')" href="javascript:;">
allennlp-2.4.0/tests/common/from_params_test.py: 356-390
</a>
<div class="mid" id="frag983" style="display:none"><pre>
    def test_dict(self):

        from allennlp.common.registrable import Registrable

        class A(Registrable):
            pass

        @A.register("b")
        class B(A):
            def __init__(self, size: int) -&gt; None:
                self.size = size

        class C(Registrable):
            pass

        @C.register("d")
        class D(C):
            def __init__(self, items: Dict[str, A]) -&gt; None:
                self.items = items

        params = Params(
            {
                "type": "d",
                "items": {"first": {"type": "b", "size": 1}, "second": {"type": "b", "size": 2}},
            }
        )
        d = C.from_params(params)

        assert isinstance(d.items, dict)
        assert len(d.items) == 2
        assert all(isinstance(key, str) for key in d.items.keys())
        assert all(isinstance(value, B) for value in d.items.values())
        assert d.items["first"].size == 1
        assert d.items["second"].size == 2

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1028')" href="javascript:;">
allennlp-2.4.0/tests/common/from_params_test.py: 814-847
</a>
<div class="mid" id="frag1028" style="display:none"><pre>
    def test_mapping(self):
        from allennlp.common.registrable import Registrable

        class A(Registrable):
            pass

        @A.register("b")
        class B(A):
            def __init__(self, size: int) -&gt; None:
                self.size = size

        class C(Registrable):
            pass

        @C.register("d")
        class D(C):
            def __init__(self, items: Mapping[str, A]) -&gt; None:
                self.items = items

        params = Params(
            {
                "type": "d",
                "items": {"first": {"type": "b", "size": 1}, "second": {"type": "b", "size": 2}},
            }
        )
        d = C.from_params(params)

        assert isinstance(d.items, Mapping)
        assert len(d.items) == 2
        assert all(isinstance(key, str) for key in d.items.keys())
        assert all(isinstance(value, B) for value in d.items.values())
        assert d.items["first"].size == 1
        assert d.items["second"].size == 2

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 52:</b> &nbsp; 2 fragments, nominal size 23 lines, similarity 78%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag988')" href="javascript:;">
allennlp-2.4.0/tests/common/from_params_test.py: 402-432
</a>
<div class="mid" id="frag988" style="display:none"><pre>
    def test_list(self):

        from allennlp.common.registrable import Registrable

        class A(Registrable):
            pass

        @A.register("b")
        class B(A):
            def __init__(self, size: int) -&gt; None:
                self.size = size

        class C(Registrable):
            pass

        @C.register("d")
        class D(C):
            def __init__(self, items: List[A]) -&gt; None:
                self.items = items

        params = Params(
            {"type": "d", "items": [{"type": "b", "size": 1}, {"type": "b", "size": 2}]}
        )
        d = C.from_params(params)

        assert isinstance(d.items, list)
        assert len(d.items) == 2
        assert all(isinstance(item, B) for item in d.items)
        assert d.items[0].size == 1
        assert d.items[1].size == 2

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1025')" href="javascript:;">
allennlp-2.4.0/tests/common/from_params_test.py: 783-813
</a>
<div class="mid" id="frag1025" style="display:none"><pre>
    def test_iterable(self):
        from allennlp.common.registrable import Registrable

        class A(Registrable):
            pass

        @A.register("b")
        class B(A):
            def __init__(self, size: int) -&gt; None:
                self.size = size

        class C(Registrable):
            pass

        @C.register("d")
        class D(C):
            def __init__(self, items: Iterable[A]) -&gt; None:
                self.items = items

        params = Params(
            {"type": "d", "items": [{"type": "b", "size": 1}, {"type": "b", "size": 2}]}
        )
        d = C.from_params(params)

        assert isinstance(d.items, Iterable)
        items = list(d.items)
        assert len(items) == 2
        assert all(isinstance(item, B) for item in items)
        assert items[0].size == 1
        assert items[1].size == 2

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 53:</b> &nbsp; 2 fragments, nominal size 21 lines, similarity 71%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1048')" href="javascript:;">
allennlp-2.4.0/tests/common/from_params_test.py: 976-1000
</a>
<div class="mid" id="frag1048" style="display:none"><pre>
    def test_from_params_handles_kwargs_in_non_from_params_registered_class(self):
        class Bar(Registrable):
            pass

        class Baz:
            def __init__(self, a: int) -&gt; None:
                self.a = a

        @Bar.register("foo")
        class Foo(Baz):
            def __init__(self, a: int, b: str = None, **kwargs) -&gt; None:
                super().__init__(a)
                self.b = b
                for key, value in kwargs.items():
                    setattr(self, key, value)

        foo = Bar.from_params(Params({"type": "foo", "a": 2, "b": "hi"}))
        assert foo.a == 2
        assert foo.b == "hi"

        foo = Bar.from_params(Params({"type": "foo", "a": 2, "b": "hi", "c": {"2": "3"}}))
        assert foo.a == 2
        assert foo.b == "hi"
        assert foo.c == {"2": "3"}

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1051')" href="javascript:;">
allennlp-2.4.0/tests/common/from_params_test.py: 1001-1027
</a>
<div class="mid" id="frag1051" style="display:none"><pre>
    def test_from_params_does_not_pass_extras_to_non_from_params_registered_class(self):
        class Bar(Registrable):
            pass

        class Baz:
            def __init__(self, a: int, c: Dict[str, str] = None) -&gt; None:
                self.a = a
                self.c = c

        @Bar.register("foo")
        class Foo(Baz):
            def __init__(self, a: int, b: str = None, **kwargs) -&gt; None:
                super().__init__(a, **kwargs)
                self.b = b

        foo = Bar.from_params(Params({"type": "foo", "a": 2, "b": "hi"}))
        assert foo.a == 2
        assert foo.b == "hi"
        assert foo.c is None

        foo = Bar.from_params(
            params=Params({"type": "foo", "a": 2, "b": "hi", "c": {"2": "3"}}), extra="4"
        )
        assert foo.a == 2
        assert foo.b == "hi"
        assert foo.c == {"2": "3"}

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 54:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 85%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1064')" href="javascript:;">
allennlp-2.4.0/tests/common/model_card_test.py: 21-40
</a>
<div class="mid" id="frag1064" style="display:none"><pre>
    def test_init_registered_model(self):
        @Model.register("fake-model")
        class FakeModel(Model):
            """
            This is a fake model with a docstring.

            # Parameters

            fake_param1: str
            fake_param2: int
            """

            def forward(self, **kwargs):
                return {}

        model_card = ModelCard(**{"id": "this-fake-model", "registered_model_name": "fake-model"})

        assert model_card.display_name == "FakeModel"
        assert model_card.model_details.description == "This is a fake model with a docstring."

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1066')" href="javascript:;">
allennlp-2.4.0/tests/common/model_card_test.py: 41-59
</a>
<div class="mid" id="frag1066" style="display:none"><pre>
    def test_init_dict_model(self):
        class FakeModel(Model):
            """
            This is a fake model with a docstring.

            # Parameters

            fake_param1: str
            fake_param2: int
            """

            def forward(self, **kwargs):
                return {}

        model_card = ModelCard(**{"id": "this-fake-model", "model_class": FakeModel})

        assert model_card.display_name == "FakeModel"
        assert model_card.model_details.description == "This is a fake model with a docstring."

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 55:</b> &nbsp; 2 fragments, nominal size 28 lines, similarity 80%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1092')" href="javascript:;">
allennlp-2.4.0/tests/predictors/text_classifier_test.py: 11-44
</a>
<div class="mid" id="frag1092" style="display:none"><pre>
    def test_uses_named_inputs(self):
        inputs = {
            "sentence": "It was the ending that I hated. I was disappointed that it was so bad."
        }

        archive = load_archive(
            self.FIXTURES_ROOT / "basic_classifier" / "serialization" / "model.tar.gz"
        )
        predictor = Predictor.from_archive(archive, "text_classifier")
        result = predictor.predict_json(inputs)

        logits = result.get("logits")
        assert logits is not None
        assert isinstance(logits, list)
        assert len(logits) == 2
        assert all(isinstance(x, float) for x in logits)

        probs = result.get("probs")
        assert probs is not None
        assert isinstance(probs, list)
        assert len(probs) == 2
        assert all(isinstance(x, float) for x in probs)
        assert all(x &gt;= 0 for x in probs)
        assert sum(probs) == approx(1.0)

        label = result.get("label")
        assert label is not None
        assert label in predictor._model.vocab.get_token_to_index_vocabulary(namespace="labels")

        exps = [math.exp(x) for x in logits]
        sum_exps = sum(exps)
        for e, p in zip(exps, probs):
            assert e / sum_exps == approx(p)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1093')" href="javascript:;">
allennlp-2.4.0/tests/predictors/text_classifier_test.py: 45-81
</a>
<div class="mid" id="frag1093" style="display:none"><pre>
    def test_batch_prediction(self):
        batch_inputs = [
            {"sentence": "It was the ending that I hated. I was disappointed that it was so bad."},
            {"sentence": "This one is honestly the worst movie I've ever watched."},
        ]

        archive = load_archive(
            self.FIXTURES_ROOT / "basic_classifier" / "serialization" / "model.tar.gz"
        )
        predictor = Predictor.from_archive(archive, "text_classifier")
        results = predictor.predict_batch_json(batch_inputs)
        assert len(results) == 2

        for result in results:
            logits = result.get("logits")
            assert logits is not None
            assert isinstance(logits, list)
            assert len(logits) == 2
            assert all(isinstance(x, float) for x in logits)

            probs = result.get("probs")
            assert probs is not None
            assert isinstance(probs, list)
            assert len(probs) == 2
            assert all(isinstance(x, float) for x in probs)
            assert all(x &gt;= 0 for x in probs)
            assert sum(probs) == approx(1.0)

            label = result.get("label")
            assert label is not None
            assert label in predictor._model.vocab.get_token_to_index_vocabulary(namespace="labels")

            exps = [math.exp(x) for x in logits]
            sum_exps = sum(exps)
            for e, p in zip(exps, probs):
                assert e / sum_exps == approx(p)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 56:</b> &nbsp; 5 fragments, nominal size 11 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1105')" href="javascript:;">
allennlp-2.4.0/tests/commands/main_test.py: 16-30
</a>
<div class="mid" id="frag1105" style="display:none"><pre>
    def test_fails_on_unknown_command(self):
        sys.argv = [
            "bogus",  # command
            "unknown_model",  # model_name
            "bogus file",  # input_file
            "--output-file",
            "bogus out file",
            "--silent",
        ]

        with pytest.raises(SystemExit) as cm:
            main()

        assert cm.value.code == 2  # argparse code for incorrect usage

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1117')" href="javascript:;">
allennlp-2.4.0/tests/commands/cached_path_test.py: 35-47
</a>
<div class="mid" id="frag1117" style="display:none"><pre>
    def test_remove_with_bad_options(self, capsys):
        sys.argv = [
            "allennlp",
            "cached-path",
            "--cache-dir",
            str(self.TEST_DIR),
            "--remove",
            "--extract-archive",
            "*",
        ]
        with pytest.raises(RuntimeError, match="--extract-archive"):
            main()

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1116')" href="javascript:;">
allennlp-2.4.0/tests/commands/cached_path_test.py: 23-34
</a>
<div class="mid" id="frag1116" style="display:none"><pre>
    def test_inspect_with_bad_options(self, capsys):
        sys.argv = [
            "allennlp",
            "cached-path",
            "--cache-dir",
            str(self.TEST_DIR),
            "--inspect",
            "--extract-archive",
        ]
        with pytest.raises(RuntimeError, match="--extract-archive"):
            main()

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1119')" href="javascript:;">
allennlp-2.4.0/tests/commands/cached_path_test.py: 59-70
</a>
<div class="mid" id="frag1119" style="display:none"><pre>
    def test_remove_empty_cache(self, capsys):
        sys.argv = [
            "allennlp",
            "cached-path",
            "--cache-dir",
            str(self.TEST_DIR),
            "--remove",
            "*",
        ]
        main()
        captured = capsys.readouterr()
        assert "Reclaimed 0B of space" in captured.out
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1118')" href="javascript:;">
allennlp-2.4.0/tests/commands/cached_path_test.py: 48-58
</a>
<div class="mid" id="frag1118" style="display:none"><pre>
    def test_remove_with_missing_positionals(self, capsys):
        sys.argv = [
            "allennlp",
            "cached-path",
            "--cache-dir",
            str(self.TEST_DIR),
            "--remove",
        ]
        with pytest.raises(RuntimeError, match="Missing positional"):
            main()

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 57:</b> &nbsp; 2 fragments, nominal size 16 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1130')" href="javascript:;">
allennlp-2.4.0/tests/interpret/simple_gradient_test.py: 17-37
</a>
<div class="mid" id="frag1130" style="display:none"><pre>
    def test_simple_gradient_basic_text(self):
        inputs = {"sentence": "It was the ending that I hated"}
        archive = load_archive(
            self.FIXTURES_ROOT / "basic_classifier" / "serialization" / "model.tar.gz"
        )
        predictor = Predictor.from_archive(archive, "text_classifier")

        interpreter = SimpleGradient(predictor)
        interpretation = interpreter.saliency_interpret_from_json(inputs)
        assert interpretation is not None
        assert "instance_1" in interpretation
        assert "grad_input_1" in interpretation["instance_1"]
        grad_input_1 = interpretation["instance_1"]["grad_input_1"]
        assert len(grad_input_1) == 7  # 7 words in input

        # two interpretations should be identical for gradient
        repeat_interpretation = interpreter.saliency_interpret_from_json(inputs)
        repeat_grad_input_1 = repeat_interpretation["instance_1"]["grad_input_1"]
        for grad, repeat_grad in zip(grad_input_1, repeat_grad_input_1):
            assert grad == approx(repeat_grad)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1133')" href="javascript:;">
allennlp-2.4.0/tests/interpret/integrated_gradient_test.py: 17-37
</a>
<div class="mid" id="frag1133" style="display:none"><pre>
    def test_integrated_gradient(self):
        inputs = {"sentence": "It was the ending that I hated"}
        archive = load_archive(
            self.FIXTURES_ROOT / "basic_classifier" / "serialization" / "model.tar.gz"
        )
        predictor = Predictor.from_archive(archive, "text_classifier")

        interpreter = IntegratedGradient(predictor)
        interpretation = interpreter.saliency_interpret_from_json(inputs)
        assert interpretation is not None
        assert "instance_1" in interpretation
        assert "grad_input_1" in interpretation["instance_1"]
        grad_input_1 = interpretation["instance_1"]["grad_input_1"]
        assert len(grad_input_1) == 7  # 7 words in input

        # two interpretations should be identical for integrated gradients
        repeat_interpretation = interpreter.saliency_interpret_from_json(inputs)
        repeat_grad_input_1 = repeat_interpretation["instance_1"]["grad_input_1"]
        for grad, repeat_grad in zip(grad_input_1, repeat_grad_input_1):
            assert grad == approx(repeat_grad)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 58:</b> &nbsp; 3 fragments, nominal size 13 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1132')" href="javascript:;">
allennlp-2.4.0/tests/interpret/simple_gradient_test.py: 49-63
</a>
<div class="mid" id="frag1132" style="display:none"><pre>
    def test_interpret_works_with_custom_embedding_layer(self):
        inputs = {"sentence": "It was the ending that I hated"}
        vocab = Vocabulary()
        vocab.add_tokens_to_namespace([w for w in inputs["sentence"].split(" ")])
        model = FakeModelForTestingInterpret(vocab, max_tokens=len(inputs["sentence"].split(" ")))
        predictor = FakePredictorForTestingInterpret(model, TextClassificationJsonReader())
        interpreter = SimpleGradient(predictor)

        interpretation = interpreter.saliency_interpret_from_json(inputs)

        assert interpretation is not None
        assert "instance_1" in interpretation
        assert "grad_input_1" in interpretation["instance_1"]
        grad_input_1 = interpretation["instance_1"]["grad_input_1"]
        assert len(grad_input_1) == 7  # 7 words in input
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1135')" href="javascript:;">
allennlp-2.4.0/tests/interpret/integrated_gradient_test.py: 49-63
</a>
<div class="mid" id="frag1135" style="display:none"><pre>
    def test_interpret_works_with_custom_embedding_layer(self):
        inputs = {"sentence": "It was the ending that I hated"}
        vocab = Vocabulary()
        vocab.add_tokens_to_namespace([w for w in inputs["sentence"].split(" ")])
        model = FakeModelForTestingInterpret(vocab, max_tokens=len(inputs["sentence"].split(" ")))
        predictor = FakePredictorForTestingInterpret(model, TextClassificationJsonReader())
        interpreter = IntegratedGradient(predictor)

        interpretation = interpreter.saliency_interpret_from_json(inputs)

        assert interpretation is not None
        assert "instance_1" in interpretation
        assert "grad_input_1" in interpretation["instance_1"]
        grad_input_1 = interpretation["instance_1"]["grad_input_1"]
        assert len(grad_input_1) == 7  # 7 words in input
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1143')" href="javascript:;">
allennlp-2.4.0/tests/interpret/smooth_gradient_test.py: 42-56
</a>
<div class="mid" id="frag1143" style="display:none"><pre>
    def test_interpret_works_with_custom_embedding_layer(self):
        inputs = {"sentence": "It was the ending that I hated"}
        vocab = Vocabulary()
        vocab.add_tokens_to_namespace([w for w in inputs["sentence"].split(" ")])
        model = FakeModelForTestingInterpret(vocab, max_tokens=len(inputs["sentence"].split(" ")))
        predictor = FakePredictorForTestingInterpret(model, TextClassificationJsonReader())
        interpreter = SmoothGradient(predictor)

        interpretation = interpreter.saliency_interpret_from_json(inputs)

        assert interpretation is not None
        assert "instance_1" in interpretation
        assert "grad_input_1" in interpretation["instance_1"]
        grad_input_1 = interpretation["instance_1"]["grad_input_1"]
        assert len(grad_input_1) == 7  # 7 words in input
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 59:</b> &nbsp; 2 fragments, nominal size 15 lines, similarity 73%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1137')" href="javascript:;">
allennlp-2.4.0/tests/interpret/hotflip_test.py: 20-38
</a>
<div class="mid" id="frag1137" style="display:none"><pre>
    def test_hotflip(self):
        inputs = {"sentence": "I always write unit tests for my code."}

        archive = load_archive(
            self.FIXTURES_ROOT / "basic_classifier" / "serialization" / "model.tar.gz"
        )
        predictor = Predictor.from_archive(archive)

        hotflipper = Hotflip(predictor)
        hotflipper.initialize()
        attack = hotflipper.attack_from_json(inputs, "tokens", "grad_input_1")
        assert attack is not None
        assert "final" in attack
        assert "original" in attack
        assert "outputs" in attack
        assert len(attack["final"][0]) == len(
            attack["original"]
        )  # hotflip replaces words without removing

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1140')" href="javascript:;">
allennlp-2.4.0/tests/interpret/hotflip_test.py: 83-99
</a>
<div class="mid" id="frag1140" style="display:none"><pre>
    def test_interpret_works_with_custom_embedding_layer(self):
        inputs = {"sentence": "I always write unit tests for my code"}
        vocab = Vocabulary()
        vocab.add_tokens_to_namespace([w for w in inputs["sentence"].split(" ")])
        model = FakeModelForTestingInterpret(vocab, max_tokens=len(inputs["sentence"].split(" ")))
        predictor = FakePredictorForTestingInterpret(model, TextClassificationJsonReader())

        hotflipper = Hotflip(predictor)
        hotflipper.initialize()
        attack = hotflipper.attack_from_json(inputs, "tokens", "grad_input_1")
        assert attack is not None
        assert "final" in attack
        assert "original" in attack
        assert "outputs" in attack
        assert len(attack["final"][0]) == len(
            attack["original"]
        )  # hotflip replaces words without removing
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 60:</b> &nbsp; 5 fragments, nominal size 31 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1157')" href="javascript:;">
allennlp-2.4.0/tests/modules/token_embedders/pretrained_transformer_mismatched_embedder_test.py: 18-61
</a>
<div class="mid" id="frag1157" style="display:none"><pre>
    def test_end_to_end(self, train_parameters: bool):
        token_indexer = PretrainedTransformerMismatchedIndexer("bert-base-uncased")

        sentence1 = ["A", ",", "AllenNLP", "sentence", "."]
        sentence2 = ["AllenNLP", "is", "great"]
        tokens1 = [Token(word) for word in sentence1]
        tokens2 = [Token(word) for word in sentence2]

        vocab = Vocabulary()

        params = Params(
            {
                "token_embedders": {
                    "bert": {
                        "type": "pretrained_transformer_mismatched",
                        "model_name": "bert-base-uncased",
                        "train_parameters": train_parameters,
                    }
                }
            }
        )
        token_embedder = BasicTextFieldEmbedder.from_params(vocab=vocab, params=params)

        instance1 = Instance({"tokens": TextField(tokens1, {"bert": token_indexer})})
        instance2 = Instance({"tokens": TextField(tokens2, {"bert": token_indexer})})

        batch = Batch([instance1, instance2])
        batch.index_instances(vocab)

        padding_lengths = batch.get_padding_lengths()
        tensor_dict = batch.as_tensor_dict(padding_lengths)
        tokens = tensor_dict["tokens"]

        assert tokens["bert"]["offsets"].tolist() == [
            [[1, 1], [2, 2], [3, 5], [6, 6], [7, 7]],
            [[1, 3], [4, 4], [5, 5], [0, 0], [0, 0]],
        ]

        # Attention mask
        bert_vectors = token_embedder(tokens)
        assert bert_vectors.size() == (2, max(len(sentence1), len(sentence2)), 768)
        assert not torch.isnan(bert_vectors).any()
        assert bert_vectors.requires_grad == train_parameters

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1159')" href="javascript:;">
allennlp-2.4.0/tests/modules/token_embedders/pretrained_transformer_mismatched_embedder_test.py: 108-148
</a>
<div class="mid" id="frag1159" style="display:none"><pre>
    def test_token_without_wordpieces(self):
        token_indexer = PretrainedTransformerMismatchedIndexer("bert-base-uncased")

        sentence1 = ["A", "", "AllenNLP", "sentence", "."]
        sentence2 = ["AllenNLP", "", "great"]
        tokens1 = [Token(word) for word in sentence1]
        tokens2 = [Token(word) for word in sentence2]
        vocab = Vocabulary()
        params = Params(
            {
                "token_embedders": {
                    "bert": {
                        "type": "pretrained_transformer_mismatched",
                        "model_name": "bert-base-uncased",
                    }
                }
            }
        )
        token_embedder = BasicTextFieldEmbedder.from_params(vocab=vocab, params=params)

        instance1 = Instance({"tokens": TextField(tokens1, {"bert": token_indexer})})
        instance2 = Instance({"tokens": TextField(tokens2, {"bert": token_indexer})})

        batch = Batch([instance1, instance2])
        batch.index_instances(vocab)

        padding_lengths = batch.get_padding_lengths()
        tensor_dict = batch.as_tensor_dict(padding_lengths)
        tokens = tensor_dict["tokens"]

        assert tokens["bert"]["offsets"].tolist() == [
            [[1, 1], [-1, -1], [2, 4], [5, 5], [6, 6]],
            [[1, 3], [-1, -1], [4, 4], [0, 0], [0, 0]],
        ]

        bert_vectors = token_embedder(tokens)
        assert bert_vectors.size() == (2, max(len(sentence1), len(sentence2)), 768)
        assert not torch.isnan(bert_vectors).any()
        assert all(bert_vectors[0, 1] == 0)
        assert all(bert_vectors[1, 1] == 0)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1161')" href="javascript:;">
allennlp-2.4.0/tests/modules/token_embedders/pretrained_transformer_mismatched_embedder_test.py: 183-232
</a>
<div class="mid" id="frag1161" style="display:none"><pre>
    def test_end_to_end_for_first_sub_token_embedding(self, sub_token_mode: str):
        token_indexer = PretrainedTransformerMismatchedIndexer("bert-base-uncased")

        sentence1 = ["A", ",", "AllenNLP", "sentence", "."]
        sentence2 = ["AllenNLP", "is", "open", "source", "NLP", "library"]

        tokens1 = [Token(word) for word in sentence1]
        tokens2 = [Token(word) for word in sentence2]

        vocab = Vocabulary()

        params = Params(
            {
                "token_embedders": {
                    "bert": {
                        "type": "pretrained_transformer_mismatched",
                        "model_name": "bert-base-uncased",
                        "sub_token_mode": sub_token_mode,
                    }
                }
            }
        )
        token_embedder = BasicTextFieldEmbedder.from_params(vocab=vocab, params=params)

        instance1 = Instance({"tokens": TextField(tokens1, {"bert": token_indexer})})
        instance2 = Instance({"tokens": TextField(tokens2, {"bert": token_indexer})})

        batch = Batch([instance1, instance2])
        batch.index_instances(vocab)

        padding_lengths = batch.get_padding_lengths()
        tensor_dict = batch.as_tensor_dict(padding_lengths)
        tokens = tensor_dict["tokens"]

        assert tokens["bert"]["mask"].tolist() == [
            [True, True, True, True, True, False],
            [True, True, True, True, True, True],
        ]

        assert tokens["bert"]["offsets"].tolist() == [
            [[1, 1], [2, 2], [3, 5], [6, 6], [7, 7], [0, 0]],
            [[1, 3], [4, 4], [5, 5], [6, 6], [7, 8], [9, 9]],
        ]

        # Attention mask
        bert_vectors = token_embedder(tokens)

        assert bert_vectors.size() == (2, max(len(sentence1), len(sentence2)), 768)
        assert not torch.isnan(bert_vectors).any()

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1158')" href="javascript:;">
allennlp-2.4.0/tests/modules/token_embedders/pretrained_transformer_mismatched_embedder_test.py: 62-107
</a>
<div class="mid" id="frag1158" style="display:none"><pre>
    def test_long_sequence_splitting_end_to_end(self):
        token_indexer = PretrainedTransformerMismatchedIndexer("bert-base-uncased", max_length=4)

        sentence1 = ["A", ",", "AllenNLP", "sentence", "."]
        sentence2 = ["AllenNLP", "is", "great"]
        tokens1 = [Token(word) for word in sentence1]
        tokens2 = [Token(word) for word in sentence2]

        vocab = Vocabulary()

        params = Params(
            {
                "token_embedders": {
                    "bert": {
                        "type": "pretrained_transformer_mismatched",
                        "model_name": "bert-base-uncased",
                        "max_length": 4,
                    }
                }
            }
        )
        token_embedder = BasicTextFieldEmbedder.from_params(vocab=vocab, params=params)

        instance1 = Instance({"tokens": TextField(tokens1, {"bert": token_indexer})})
        instance2 = Instance({"tokens": TextField(tokens2, {"bert": token_indexer})})

        batch = Batch([instance1, instance2])
        batch.index_instances(vocab)

        padding_lengths = batch.get_padding_lengths()
        tensor_dict = batch.as_tensor_dict(padding_lengths)
        tokens = tensor_dict["tokens"]

        assert tokens["bert"]["mask"].tolist() == [
            [True, True, True, True, True],
            [True, True, True, False, False],
        ]
        assert tokens["bert"]["offsets"].tolist() == [
            [[1, 1], [2, 2], [3, 5], [6, 6], [7, 7]],
            [[1, 3], [4, 4], [5, 5], [0, 0], [0, 0]],
        ]

        bert_vectors = token_embedder(tokens)
        assert bert_vectors.size() == (2, max(len(sentence1), len(sentence2)), 768)
        assert not torch.isnan(bert_vectors).any()

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1162')" href="javascript:;">
allennlp-2.4.0/tests/modules/token_embedders/pretrained_transformer_mismatched_embedder_test.py: 234-269
</a>
<div class="mid" id="frag1162" style="display:none"><pre>
    def test_throws_error_on_incorrect_sub_token_mode(self, sub_token_mode: str):
        token_indexer = PretrainedTransformerMismatchedIndexer("bert-base-uncased")

        sentence1 = ["A", ",", "AllenNLP", "sentence", "."]
        sentence2 = ["AllenNLP", "is", "open", "source", "NLP", "library"]

        tokens1 = [Token(word) for word in sentence1]
        tokens2 = [Token(word) for word in sentence2]

        vocab = Vocabulary()

        params = Params(
            {
                "token_embedders": {
                    "bert": {
                        "type": "pretrained_transformer_mismatched",
                        "model_name": "bert-base-uncased",
                        "sub_token_mode": sub_token_mode,
                    }
                }
            }
        )
        token_embedder = BasicTextFieldEmbedder.from_params(vocab=vocab, params=params)

        instance1 = Instance({"tokens": TextField(tokens1, {"bert": token_indexer})})
        instance2 = Instance({"tokens": TextField(tokens2, {"bert": token_indexer})})

        batch = Batch([instance1, instance2])
        batch.index_instances(vocab)

        padding_lengths = batch.get_padding_lengths()
        tensor_dict = batch.as_tensor_dict(padding_lengths)
        tokens = tensor_dict["tokens"]

        with pytest.raises(ConfigurationError):
            token_embedder(tokens)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 61:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1184')" href="javascript:;">
allennlp-2.4.0/tests/modules/stacked_bidirectional_lstm_test.py: 15-27
</a>
<div class="mid" id="frag1184" style="display:none"><pre>
    def test_stacked_bidirectional_lstm_completes_forward_pass(self):
        input_tensor = torch.rand(4, 5, 3)
        input_tensor[1, 4:, :] = 0.0
        input_tensor[2, 2:, :] = 0.0
        input_tensor[3, 1:, :] = 0.0
        input_tensor = pack_padded_sequence(input_tensor, [5, 4, 2, 1], batch_first=True)
        lstm = StackedBidirectionalLstm(3, 7, 3)
        output, _ = lstm(input_tensor)
        output_sequence, _ = pad_packed_sequence(output, batch_first=True)
        numpy.testing.assert_array_equal(output_sequence.data[1, 4:, :].numpy(), 0.0)
        numpy.testing.assert_array_equal(output_sequence.data[2, 2:, :].numpy(), 0.0)
        numpy.testing.assert_array_equal(output_sequence.data[3, 1:, :].numpy(), 0.0)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1216')" href="javascript:;">
allennlp-2.4.0/tests/modules/stacked_alternating_lstm_test.py: 10-22
</a>
<div class="mid" id="frag1216" style="display:none"><pre>
    def test_stacked_alternating_lstm_completes_forward_pass(self):
        input_tensor = torch.rand(4, 5, 3)
        input_tensor[1, 4:, :] = 0.0
        input_tensor[2, 2:, :] = 0.0
        input_tensor[3, 1:, :] = 0.0
        input_tensor = pack_padded_sequence(input_tensor, [5, 4, 2, 1], batch_first=True)
        lstm = StackedAlternatingLstm(3, 7, 3)
        output, _ = lstm(input_tensor)
        output_sequence, _ = pad_packed_sequence(output, batch_first=True)
        numpy.testing.assert_array_equal(output_sequence.data[1, 4:, :].numpy(), 0.0)
        numpy.testing.assert_array_equal(output_sequence.data[2, 2:, :].numpy(), 0.0)
        numpy.testing.assert_array_equal(output_sequence.data[3, 1:, :].numpy(), 0.0)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 62:</b> &nbsp; 4 fragments, nominal size 12 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1185')" href="javascript:;">
allennlp-2.4.0/tests/modules/stacked_bidirectional_lstm_test.py: 28-42
</a>
<div class="mid" id="frag1185" style="display:none"><pre>
    def test_stacked_bidirectional_lstm_can_build_from_params(self):
        params = Params(
            {
                "type": "stacked_bidirectional_lstm",
                "input_size": 5,
                "hidden_size": 9,
                "num_layers": 3,
            }
        )
        encoder = Seq2SeqEncoder.from_params(params)

        assert encoder.get_input_dim() == 5
        assert encoder.get_output_dim() == 18
        assert encoder.is_bidirectional

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1186')" href="javascript:;">
allennlp-2.4.0/tests/modules/stacked_bidirectional_lstm_test.py: 43-56
</a>
<div class="mid" id="frag1186" style="display:none"><pre>
    def test_stacked_bidirectional_lstm_can_build_from_params_seq2vec(self):
        params = Params(
            {
                "type": "stacked_bidirectional_lstm",
                "input_size": 5,
                "hidden_size": 9,
                "num_layers": 3,
            }
        )
        encoder = Seq2VecEncoder.from_params(params)

        assert encoder.get_input_dim() == 5
        assert encoder.get_output_dim() == 18

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1282')" href="javascript:;">
allennlp-2.4.0/tests/modules/span_extractors/endpoint_span_extractor_test.py: 10-22
</a>
<div class="mid" id="frag1282" style="display:none"><pre>
    def test_endpoint_span_extractor_can_build_from_params(self):
        params = Params(
            {
                "type": "endpoint",
                "input_dim": 7,
                "num_width_embeddings": 5,
                "span_width_embedding_dim": 3,
            }
        )
        extractor = SpanExtractor.from_params(params)
        assert isinstance(extractor, EndpointSpanExtractor)
        assert extractor.get_output_dim() == 17  # 2 * input_dim + span_width_embedding_dim

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1286')" href="javascript:;">
allennlp-2.4.0/tests/modules/span_extractors/bidirectional_endpoint_span_extractor_test.py: 12-24
</a>
<div class="mid" id="frag1286" style="display:none"><pre>
    def test_bidirectional_endpoint_span_extractor_can_build_from_params(self):
        params = Params(
            {
                "type": "bidirectional_endpoint",
                "input_dim": 4,
                "num_width_embeddings": 5,
                "span_width_embedding_dim": 3,
            }
        )
        extractor = SpanExtractor.from_params(params)
        assert isinstance(extractor, BidirectionalEndpointSpanExtractor)
        assert extractor.get_output_dim() == 2 + 2 + 3

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 63:</b> &nbsp; 2 fragments, nominal size 20 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1197')" href="javascript:;">
allennlp-2.4.0/tests/modules/text_field_embedders/basic_text_field_embedder_test.py: 98-120
</a>
<div class="mid" id="frag1197" style="display:none"><pre>
    def test_forward_runs_with_non_bijective_mapping(self):
        elmo_fixtures_path = self.FIXTURES_ROOT / "elmo"
        options_file = str(elmo_fixtures_path / "options.json")
        weight_file = str(elmo_fixtures_path / "lm_weights.hdf5")
        params = Params(
            {
                "token_embedders": {
                    "words": {"type": "embedding", "num_embeddings": 20, "embedding_dim": 2},
                    "elmo": {
                        "type": "elmo_token_embedder",
                        "options_file": options_file,
                        "weight_file": weight_file,
                    },
                }
            }
        )
        token_embedder = BasicTextFieldEmbedder.from_params(vocab=self.vocab, params=params)
        inputs = {
            "words": {"tokens": (torch.rand(3, 6) * 20).long()},
            "elmo": {"elmo_tokens": (torch.rand(3, 6, 50) * 15).long()},
        }
        token_embedder(inputs)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1199')" href="javascript:;">
allennlp-2.4.0/tests/modules/text_field_embedders/basic_text_field_embedder_test.py: 140-162
</a>
<div class="mid" id="frag1199" style="display:none"><pre>
    def test_forward_runs_with_non_bijective_mapping_with_dict(self):
        elmo_fixtures_path = self.FIXTURES_ROOT / "elmo"
        options_file = str(elmo_fixtures_path / "options.json")
        weight_file = str(elmo_fixtures_path / "lm_weights.hdf5")
        params = Params(
            {
                "token_embedders": {
                    "words": {"type": "embedding", "num_embeddings": 20, "embedding_dim": 2},
                    "elmo": {
                        "type": "elmo_token_embedder",
                        "options_file": options_file,
                        "weight_file": weight_file,
                    },
                }
            }
        )
        token_embedder = BasicTextFieldEmbedder.from_params(vocab=self.vocab, params=params)
        inputs = {
            "words": {"tokens": (torch.rand(3, 6) * 20).long()},
            "elmo": {"elmo_tokens": (torch.rand(3, 6, 50) * 15).long()},
        }
        token_embedder(inputs)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 64:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1213')" href="javascript:;">
allennlp-2.4.0/tests/modules/maxout_test.py: 25-45
</a>
<div class="mid" id="frag1213" style="display:none"><pre>
    def test_forward_gives_correct_output(self):
        params = Params(
            {"input_dim": 2, "output_dims": 3, "pool_sizes": 4, "dropout": 0.0, "num_layers": 2}
        )
        maxout = Maxout.from_params(params)

        constant_init = Initializer.from_params(Params({"type": "constant", "val": 1.0}))
        initializer = InitializerApplicator([(".*", constant_init)])
        initializer(maxout)

        input_tensor = torch.FloatTensor([[-3, 1]])
        output = maxout(input_tensor).data.numpy()
        assert output.shape == (1, 3)
        # This output was checked by hand
        # The output of the first maxout layer is [-1, -1, -1], since the
        # matrix multiply gives us [-2]*12. Reshaping and maxing
        # produces [-2, -2, -2] and the bias increments these values.
        # The second layer output is [-2, -2, -2], since the matrix
        # matrix multiply gives us [-3]*12. Reshaping and maxing
        # produces [-3, -3, -3] and the bias increments these values.
        assert_almost_equal(output, [[-2, -2, -2]])
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1274')" href="javascript:;">
allennlp-2.4.0/tests/modules/feedforward_test.py: 55-69
</a>
<div class="mid" id="frag1274" style="display:none"><pre>
    def test_forward_gives_correct_output(self):
        params = Params({"input_dim": 2, "hidden_dims": 3, "activations": "relu", "num_layers": 2})
        feedforward = FeedForward.from_params(params)

        constant_init = Initializer.from_params(Params({"type": "constant", "val": 1.0}))
        initializer = InitializerApplicator([(".*", constant_init)])
        initializer(feedforward)

        input_tensor = torch.FloatTensor([[-3, 1]])
        output = feedforward(input_tensor).data.numpy()
        assert output.shape == (1, 3)
        # This output was checked by hand - ReLU makes output after first hidden layer [0, 0, 0],
        # which then gets a bias added in the second layer to be [1, 1, 1].
        assert_almost_equal(output, [[1, 1, 1]])

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 65:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 89%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1264')" href="javascript:;">
allennlp-2.4.0/tests/modules/seq2vec_encoder_test.py: 10-31
</a>
<div class="mid" id="frag1264" style="display:none"><pre>
    def test_from_params_builders_encoder_correctly(self):
        # We're just making sure parameters get passed through correctly here, and that the basic
        # API works.
        params = Params(
            {
                "type": "lstm",
                "bidirectional": True,
                "num_layers": 3,
                "input_size": 5,
                "hidden_size": 7,
            }
        )
        encoder = Seq2VecEncoder.from_params(params)

        assert encoder.__class__.__name__ == "LstmSeq2VecEncoder"
        assert encoder._module.__class__.__name__ == "LSTM"
        assert encoder._module.num_layers == 3
        assert encoder._module.input_size == 5
        assert encoder._module.hidden_size == 7
        assert encoder._module.bidirectional is True
        assert encoder._module.batch_first is True

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1268')" href="javascript:;">
allennlp-2.4.0/tests/modules/seq2seq_encoder_test.py: 10-33
</a>
<div class="mid" id="frag1268" style="display:none"><pre>
    def test_from_params_builders_encoder_correctly(self):
        # We're just making sure parameters get passed through correctly here, and that the basic
        # API works.
        params = Params(
            {
                "type": "lstm",
                "bidirectional": True,
                "num_layers": 3,
                "input_size": 5,
                "hidden_size": 7,
                "stateful": True,
            }
        )
        encoder = Seq2SeqEncoder.from_params(params)

        assert encoder.__class__.__name__ == "LstmSeq2SeqEncoder"
        assert encoder._module.__class__.__name__ == "LSTM"
        assert encoder._module.num_layers == 3
        assert encoder._module.input_size == 5
        assert encoder._module.hidden_size == 7
        assert encoder._module.bidirectional is True
        assert encoder._module.batch_first is True
        assert encoder.stateful is True

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 66:</b> &nbsp; 2 fragments, nominal size 44 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1288')" href="javascript:;">
allennlp-2.4.0/tests/modules/span_extractors/bidirectional_endpoint_span_extractor_test.py: 29-108
</a>
<div class="mid" id="frag1288" style="display:none"><pre>
    def test_correct_sequence_elements_are_embedded(self):
        sequence_tensor = torch.randn([2, 5, 8])
        # concatentate start and end points together to form our representation
        # for both the forward and backward directions.
        extractor = BidirectionalEndpointSpanExtractor(
            input_dim=8, forward_combination="x,y", backward_combination="x,y"
        )
        indices = torch.LongTensor([[[1, 3], [2, 4]], [[0, 2], [3, 4]]])

        span_representations = extractor(sequence_tensor, indices)

        assert list(span_representations.size()) == [2, 2, 16]
        assert extractor.get_output_dim() == 16
        assert extractor.get_input_dim() == 8

        # We just concatenated the start and end embeddings together, so
        # we can check they match the original indices if we split them apart.
        (
            forward_start_embeddings,
            forward_end_embeddings,
            backward_start_embeddings,
            backward_end_embeddings,
        ) = span_representations.split(4, -1)

        forward_sequence_tensor, backward_sequence_tensor = sequence_tensor.split(4, -1)

        # Forward direction =&gt; subtract 1 from start indices to make them exlusive.
        correct_forward_start_indices = torch.LongTensor([[0, 1], [-1, 2]])
        # This index should be -1, so it will be replaced with a sentinel. Here,
        # we'll set it to a value other than -1 so we can index select the indices and
        # replace it later.
        correct_forward_start_indices[1, 0] = 1

        # Forward direction =&gt; end indices are the same.
        correct_forward_end_indices = torch.LongTensor([[3, 4], [2, 4]])

        # Backward direction =&gt; start indices are exclusive, so add 1 to the end indices.
        correct_backward_start_indices = torch.LongTensor([[4, 5], [3, 5]])
        # These exclusive end indices are outside the tensor, so will be replaced with the end sentinel.
        # Here we replace them with ones so we can index select using these indices without torch
        # complaining.
        correct_backward_start_indices[0, 1] = 1
        correct_backward_start_indices[1, 1] = 1
        # Backward direction =&gt; end indices are inclusive and equal to the forward start indices.
        correct_backward_end_indices = torch.LongTensor([[1, 2], [0, 3]])

        correct_forward_start_embeddings = batched_index_select(
            forward_sequence_tensor.contiguous(), correct_forward_start_indices
        )
        # This element had sequence_tensor index of 0, so it's exclusive index is the start sentinel.
        correct_forward_start_embeddings[1, 0] = extractor._start_sentinel.data
        numpy.testing.assert_array_equal(
            forward_start_embeddings.data.numpy(), correct_forward_start_embeddings.data.numpy()
        )

        correct_forward_end_embeddings = batched_index_select(
            forward_sequence_tensor.contiguous(), correct_forward_end_indices
        )
        numpy.testing.assert_array_equal(
            forward_end_embeddings.data.numpy(), correct_forward_end_embeddings.data.numpy()
        )

        correct_backward_end_embeddings = batched_index_select(
            backward_sequence_tensor.contiguous(), correct_backward_end_indices
        )
        numpy.testing.assert_array_equal(
            backward_end_embeddings.data.numpy(), correct_backward_end_embeddings.data.numpy()
        )

        correct_backward_start_embeddings = batched_index_select(
            backward_sequence_tensor.contiguous(), correct_backward_start_indices
        )
        # This element had sequence_tensor index == sequence_tensor.size(1),
        # so it's exclusive index is the end sentinel.
        correct_backward_start_embeddings[0, 1] = extractor._end_sentinel.data
        correct_backward_start_embeddings[1, 1] = extractor._end_sentinel.data
        numpy.testing.assert_array_equal(
            backward_start_embeddings.data.numpy(), correct_backward_start_embeddings.data.numpy()
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1289')" href="javascript:;">
allennlp-2.4.0/tests/modules/span_extractors/bidirectional_endpoint_span_extractor_test.py: 109-199
</a>
<div class="mid" id="frag1289" style="display:none"><pre>
    def test_correct_sequence_elements_are_embedded_with_a_masked_sequence(self):
        sequence_tensor = torch.randn([2, 5, 8])
        # concatentate start and end points together to form our representation
        # for both the forward and backward directions.
        extractor = BidirectionalEndpointSpanExtractor(
            input_dim=8, forward_combination="x,y", backward_combination="x,y"
        )
        indices = torch.LongTensor(
            [
                [[1, 3], [2, 4]],
                # This span has an end index at the
                # end of the padded sequence.
                [[0, 2], [0, 1]],
            ]
        )
        sequence_mask = torch.tensor(
            [[True, True, True, True, True], [True, True, True, False, False]]
        )

        span_representations = extractor(sequence_tensor, indices, sequence_mask=sequence_mask)

        # We just concatenated the start and end embeddings together, so
        # we can check they match the original indices if we split them apart.
        (
            forward_start_embeddings,
            forward_end_embeddings,
            backward_start_embeddings,
            backward_end_embeddings,
        ) = span_representations.split(4, -1)

        forward_sequence_tensor, backward_sequence_tensor = sequence_tensor.split(4, -1)

        # Forward direction =&gt; subtract 1 from start indices to make them exlusive.
        correct_forward_start_indices = torch.LongTensor([[0, 1], [-1, -1]])
        # These indices should be -1, so they'll be replaced with a sentinel. Here,
        # we'll set them to a value other than -1 so we can index select the indices and
        # replace them later.
        correct_forward_start_indices[1, 0] = 1
        correct_forward_start_indices[1, 1] = 1

        # Forward direction =&gt; end indices are the same.
        correct_forward_end_indices = torch.LongTensor([[3, 4], [2, 1]])

        # Backward direction =&gt; start indices are exclusive, so add 1 to the end indices.
        correct_backward_start_indices = torch.LongTensor([[4, 5], [3, 2]])
        # These exclusive backward start indices are outside the tensor, so will be replaced
        # with the end sentinel. Here we replace them with ones so we can index select using
        # these indices without torch complaining.
        correct_backward_start_indices[0, 1] = 1

        # Backward direction =&gt; end indices are inclusive and equal to the forward start indices.
        correct_backward_end_indices = torch.LongTensor([[1, 2], [0, 0]])

        correct_forward_start_embeddings = batched_index_select(
            forward_sequence_tensor.contiguous(), correct_forward_start_indices
        )
        # This element had sequence_tensor index of 0, so it's exclusive index is the start sentinel.
        correct_forward_start_embeddings[1, 0] = extractor._start_sentinel.data
        correct_forward_start_embeddings[1, 1] = extractor._start_sentinel.data
        numpy.testing.assert_array_equal(
            forward_start_embeddings.data.numpy(), correct_forward_start_embeddings.data.numpy()
        )

        correct_forward_end_embeddings = batched_index_select(
            forward_sequence_tensor.contiguous(), correct_forward_end_indices
        )
        numpy.testing.assert_array_equal(
            forward_end_embeddings.data.numpy(), correct_forward_end_embeddings.data.numpy()
        )

        correct_backward_end_embeddings = batched_index_select(
            backward_sequence_tensor.contiguous(), correct_backward_end_indices
        )
        numpy.testing.assert_array_equal(
            backward_end_embeddings.data.numpy(), correct_backward_end_embeddings.data.numpy()
        )

        correct_backward_start_embeddings = batched_index_select(
            backward_sequence_tensor.contiguous(), correct_backward_start_indices
        )
        # This element had sequence_tensor index == sequence_tensor.size(1),
        # so it's exclusive index is the end sentinel.
        correct_backward_start_embeddings[0, 1] = extractor._end_sentinel.data
        # This element has sequence_tensor index == the masked length of the batch element,
        # so it should be the end_sentinel even though it isn't greater than sequence_tensor.size(1).
        correct_backward_start_embeddings[1, 0] = extractor._end_sentinel.data

        numpy.testing.assert_array_equal(
            backward_start_embeddings.data.numpy(), correct_backward_start_embeddings.data.numpy()
        )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 67:</b> &nbsp; 2 fragments, nominal size 17 lines, similarity 88%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1305')" href="javascript:;">
allennlp-2.4.0/tests/modules/time_distributed_test.py: 39-60
</a>
<div class="mid" id="frag1305" style="display:none"><pre>
    def test_time_distributed_reshapes_multiple_inputs_with_pass_through_tensor_correctly(self):
        class FakeModule(Module):
            @overrides
            def forward(self, input_tensor, tensor_to_pass_through=None, another_tensor=None):

                return input_tensor + tensor_to_pass_through + another_tensor

        module = FakeModule()
        distributed_module = TimeDistributed(module)

        input_tensor1 = torch.LongTensor([[[1, 2], [3, 4]]])
        input_to_pass_through = torch.LongTensor([3, 7])
        input_tensor2 = torch.LongTensor([[[4, 2], [9, 1]]])

        output = distributed_module(
            input_tensor1,
            tensor_to_pass_through=input_to_pass_through,
            another_tensor=input_tensor2,
            pass_through=["tensor_to_pass_through"],
        )
        assert_almost_equal(output.data.numpy(), [[[8, 11], [15, 12]]])

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1307')" href="javascript:;">
allennlp-2.4.0/tests/modules/time_distributed_test.py: 61-81
</a>
<div class="mid" id="frag1307" style="display:none"><pre>
    def test_time_distributed_reshapes_multiple_inputs_with_pass_through_non_tensor_correctly(self):
        class FakeModule(Module):
            @overrides
            def forward(self, input_tensor, number=0, another_tensor=None):

                return input_tensor + number + another_tensor

        module = FakeModule()
        distributed_module = TimeDistributed(module)

        input_tensor1 = torch.LongTensor([[[1, 2], [3, 4]]])
        input_number = 5
        input_tensor2 = torch.LongTensor([[[4, 2], [9, 1]]])

        output = distributed_module(
            input_tensor1,
            number=input_number,
            another_tensor=input_tensor2,
            pass_through=["number"],
        )
        assert_almost_equal(output.data.numpy(), [[[10, 9], [17, 10]]])
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 68:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 91%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1310')" href="javascript:;">
allennlp-2.4.0/tests/modules/augmented_lstm_test.py: 28-43
</a>
<div class="mid" id="frag1310" style="display:none"><pre>
    def test_variable_length_sequences_return_correctly_padded_outputs(self):
        sorted_tensor, sorted_sequence, _, _ = sort_batch_by_length(
            self.random_tensor, self.sequence_lengths
        )
        tensor = pack_padded_sequence(
            sorted_tensor, sorted_sequence.data.tolist(), batch_first=True
        )
        lstm = AugmentedLstm(10, 11)
        output, _ = lstm(tensor)
        output_sequence, _ = pad_packed_sequence(output, batch_first=True)

        numpy.testing.assert_array_equal(output_sequence.data[1, 6:, :].numpy(), 0.0)
        numpy.testing.assert_array_equal(output_sequence.data[2, 4:, :].numpy(), 0.0)
        numpy.testing.assert_array_equal(output_sequence.data[3, 3:, :].numpy(), 0.0)
        numpy.testing.assert_array_equal(output_sequence.data[4, 2:, :].numpy(), 0.0)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1311')" href="javascript:;">
allennlp-2.4.0/tests/modules/augmented_lstm_test.py: 44-59
</a>
<div class="mid" id="frag1311" style="display:none"><pre>
    def test_variable_length_sequences_run_backward_return_correctly_padded_outputs(self):
        sorted_tensor, sorted_sequence, _, _ = sort_batch_by_length(
            self.random_tensor, self.sequence_lengths
        )
        tensor = pack_padded_sequence(
            sorted_tensor, sorted_sequence.data.tolist(), batch_first=True
        )
        lstm = AugmentedLstm(10, 11, go_forward=False)
        output, _ = lstm(tensor)
        output_sequence, _ = pad_packed_sequence(output, batch_first=True)

        numpy.testing.assert_array_equal(output_sequence.data[1, 6:, :].numpy(), 0.0)
        numpy.testing.assert_array_equal(output_sequence.data[2, 4:, :].numpy(), 0.0)
        numpy.testing.assert_array_equal(output_sequence.data[3, 3:, :].numpy(), 0.0)
        numpy.testing.assert_array_equal(output_sequence.data[4, 2:, :].numpy(), 0.0)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 69:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1328')" href="javascript:;">
allennlp-2.4.0/tests/modules/seq2vec_encoders/pytorch_seq2vec_wrapper_test.py: 15-26
</a>
<div class="mid" id="frag1328" style="display:none"><pre>
    def test_get_dimensions_is_correct(self):
        lstm = LSTM(bidirectional=True, num_layers=3, input_size=2, hidden_size=7, batch_first=True)
        encoder = PytorchSeq2VecWrapper(lstm)
        assert encoder.get_output_dim() == 14
        assert encoder.get_input_dim() == 2
        lstm = LSTM(
            bidirectional=False, num_layers=3, input_size=2, hidden_size=7, batch_first=True
        )
        encoder = PytorchSeq2VecWrapper(lstm)
        assert encoder.get_output_dim() == 7
        assert encoder.get_input_dim() == 2

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1356')" href="javascript:;">
allennlp-2.4.0/tests/modules/seq2seq_encoders/pytorch_seq2seq_wrapper_test.py: 15-26
</a>
<div class="mid" id="frag1356" style="display:none"><pre>
    def test_get_dimension_is_correct(self):
        lstm = LSTM(bidirectional=True, num_layers=3, input_size=2, hidden_size=7, batch_first=True)
        encoder = PytorchSeq2SeqWrapper(lstm)
        assert encoder.get_output_dim() == 14
        assert encoder.get_input_dim() == 2
        lstm = LSTM(
            bidirectional=False, num_layers=3, input_size=2, hidden_size=7, batch_first=True
        )
        encoder = PytorchSeq2SeqWrapper(lstm)
        assert encoder.get_output_dim() == 7
        assert encoder.get_input_dim() == 2

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 70:</b> &nbsp; 4 fragments, nominal size 22 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1330')" href="javascript:;">
allennlp-2.4.0/tests/modules/seq2vec_encoders/pytorch_seq2vec_wrapper_test.py: 35-63
</a>
<div class="mid" id="frag1330" style="display:none"><pre>
    def test_forward_pulls_out_correct_tensor_with_sequence_lengths(self):
        lstm = LSTM(bidirectional=True, num_layers=3, input_size=3, hidden_size=7, batch_first=True)
        encoder = PytorchSeq2VecWrapper(lstm)

        input_tensor = torch.rand([5, 7, 3])
        input_tensor[1, 6:, :] = 0
        input_tensor[2, 4:, :] = 0
        input_tensor[3, 2:, :] = 0
        input_tensor[4, 1:, :] = 0
        mask = torch.ones(5, 7).bool()
        mask[1, 6:] = False
        mask[2, 4:] = False
        mask[3, 2:] = False
        mask[4, 1:] = False

        sequence_lengths = get_lengths_from_binary_sequence_mask(mask)
        packed_sequence = pack_padded_sequence(
            input_tensor, sequence_lengths.tolist(), batch_first=True
        )
        _, state = lstm(packed_sequence)
        # Transpose output state, extract the last forward and backward states and
        # reshape to be of dimension (batch_size, 2 * hidden_size).
        reshaped_state = state[0].transpose(0, 1)[:, -2:, :].contiguous()
        explicitly_concatenated_state = torch.cat(
            [reshaped_state[:, 0, :].squeeze(1), reshaped_state[:, 1, :].squeeze(1)], -1
        )
        encoder_output = encoder(input_tensor, mask)
        assert_almost_equal(encoder_output.data.numpy(), explicitly_concatenated_state.data.numpy())

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1359')" href="javascript:;">
allennlp-2.4.0/tests/modules/seq2seq_encoders/pytorch_seq2seq_wrapper_test.py: 57-79
</a>
<div class="mid" id="frag1359" style="display:none"><pre>
    def test_forward_pulls_out_correct_tensor_with_sequence_lengths(self):
        lstm = LSTM(bidirectional=True, num_layers=3, input_size=3, hidden_size=7, batch_first=True)
        encoder = PytorchSeq2SeqWrapper(lstm)
        input_tensor = torch.rand([5, 7, 3])
        input_tensor[1, 6:, :] = 0
        input_tensor[2, 4:, :] = 0
        input_tensor[3, 2:, :] = 0
        input_tensor[4, 1:, :] = 0
        mask = torch.ones(5, 7).bool()
        mask[1, 6:] = False
        mask[2, 4:] = False
        mask[3, 2:] = False
        mask[4, 1:] = False

        sequence_lengths = get_lengths_from_binary_sequence_mask(mask)
        packed_sequence = pack_padded_sequence(
            input_tensor, sequence_lengths.data.tolist(), batch_first=True
        )
        lstm_output, _ = lstm(packed_sequence)
        encoder_output = encoder(input_tensor, mask)
        lstm_tensor, _ = pad_packed_sequence(lstm_output, batch_first=True)
        assert_almost_equal(encoder_output.data.numpy(), lstm_tensor.data.numpy())

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1332')" href="javascript:;">
allennlp-2.4.0/tests/modules/seq2vec_encoders/pytorch_seq2vec_wrapper_test.py: 88-120
</a>
<div class="mid" id="frag1332" style="display:none"><pre>
    def test_forward_pulls_out_correct_tensor_with_unsorted_batches(self):
        lstm = LSTM(bidirectional=True, num_layers=3, input_size=3, hidden_size=7, batch_first=True)
        encoder = PytorchSeq2VecWrapper(lstm)

        input_tensor = torch.rand([5, 7, 3])
        input_tensor[0, 3:, :] = 0
        input_tensor[1, 4:, :] = 0
        input_tensor[2, 2:, :] = 0
        input_tensor[3, 6:, :] = 0
        mask = torch.ones(5, 7).bool()
        mask[0, 3:] = False
        mask[1, 4:] = False
        mask[2, 2:] = False
        mask[3, 6:] = False

        sequence_lengths = get_lengths_from_binary_sequence_mask(mask)
        sorted_inputs, sorted_sequence_lengths, restoration_indices, _ = sort_batch_by_length(
            input_tensor, sequence_lengths
        )
        packed_sequence = pack_padded_sequence(
            sorted_inputs, sorted_sequence_lengths.tolist(), batch_first=True
        )
        _, state = lstm(packed_sequence)
        # Transpose output state, extract the last forward and backward states and
        # reshape to be of dimension (batch_size, 2 * hidden_size).
        sorted_transposed_state = state[0].transpose(0, 1).index_select(0, restoration_indices)
        reshaped_state = sorted_transposed_state[:, -2:, :].contiguous()
        explicitly_concatenated_state = torch.cat(
            [reshaped_state[:, 0, :].squeeze(1), reshaped_state[:, 1, :].squeeze(1)], -1
        )
        encoder_output = encoder(input_tensor, mask)
        assert_almost_equal(encoder_output.data.numpy(), explicitly_concatenated_state.data.numpy())

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1360')" href="javascript:;">
allennlp-2.4.0/tests/modules/seq2seq_encoders/pytorch_seq2seq_wrapper_test.py: 80-108
</a>
<div class="mid" id="frag1360" style="display:none"><pre>
    def test_forward_pulls_out_correct_tensor_for_unsorted_batches(self):
        lstm = LSTM(bidirectional=True, num_layers=3, input_size=3, hidden_size=7, batch_first=True)
        encoder = PytorchSeq2SeqWrapper(lstm)
        input_tensor = torch.rand([5, 7, 3])
        input_tensor[0, 3:, :] = 0
        input_tensor[1, 4:, :] = 0
        input_tensor[2, 2:, :] = 0
        input_tensor[3, 6:, :] = 0
        mask = torch.ones(5, 7).bool()
        mask[0, 3:] = False
        mask[1, 4:] = False
        mask[2, 2:] = False
        mask[3, 6:] = False

        sequence_lengths = get_lengths_from_binary_sequence_mask(mask)
        sorted_inputs, sorted_sequence_lengths, restoration_indices, _ = sort_batch_by_length(
            input_tensor, sequence_lengths
        )
        packed_sequence = pack_padded_sequence(
            sorted_inputs, sorted_sequence_lengths.data.tolist(), batch_first=True
        )
        lstm_output, _ = lstm(packed_sequence)
        encoder_output = encoder(input_tensor, mask)
        lstm_tensor, _ = pad_packed_sequence(lstm_output, batch_first=True)
        assert_almost_equal(
            encoder_output.data.numpy(),
            lstm_tensor.index_select(0, restoration_indices).data.numpy(),
        )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 71:</b> &nbsp; 2 fragments, nominal size 19 lines, similarity 89%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1331')" href="javascript:;">
allennlp-2.4.0/tests/modules/seq2vec_encoders/pytorch_seq2vec_wrapper_test.py: 64-87
</a>
<div class="mid" id="frag1331" style="display:none"><pre>
    def test_forward_works_even_with_empty_sequences(self):
        lstm = LSTM(
            bidirectional=True, num_layers=3, input_size=3, hidden_size=11, batch_first=True
        )
        encoder = PytorchSeq2VecWrapper(lstm)

        tensor = torch.rand([5, 7, 3])
        tensor[1, 6:, :] = 0
        tensor[2, :, :] = 0
        tensor[3, 2:, :] = 0
        tensor[4, :, :] = 0
        mask = torch.ones(5, 7).bool()
        mask[1, 6:] = False
        mask[2, :] = False
        mask[3, 2:] = False
        mask[4, :] = False

        results = encoder(tensor, mask)

        for i in (0, 1, 3):
            assert not (results[i] == 0.0).data.all()
        for i in (2, 4):
            assert (results[i] == 0.0).data.all()

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1357')" href="javascript:;">
allennlp-2.4.0/tests/modules/seq2seq_encoders/pytorch_seq2seq_wrapper_test.py: 27-48
</a>
<div class="mid" id="frag1357" style="display:none"><pre>
    def test_forward_works_even_with_empty_sequences(self):
        lstm = LSTM(bidirectional=True, num_layers=3, input_size=3, hidden_size=7, batch_first=True)
        encoder = PytorchSeq2SeqWrapper(lstm)

        tensor = torch.rand([5, 7, 3])
        tensor[1, 6:, :] = 0
        tensor[2, :, :] = 0
        tensor[3, 2:, :] = 0
        tensor[4, :, :] = 0
        mask = torch.ones(5, 7).bool()
        mask[1, 6:] = False
        mask[2, :] = False
        mask[3, 2:] = False
        mask[4, :] = False

        results = encoder(tensor, mask)

        for i in (0, 1, 3):
            assert not (results[i] == 0.0).data.all()
        for i in (2, 4):
            assert (results[i] == 0.0).data.all()

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 72:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 71%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1353')" href="javascript:;">
allennlp-2.4.0/tests/modules/seq2seq_encoders/gated_cnn_encoder_test.py: 8-21
</a>
<div class="mid" id="frag1353" style="display:none"><pre>
    def test_gated_cnn_encoder(self):
        cnn_encoder = GatedCnnEncoder(
            input_dim=32,
            layers=[[[4, 32]], [[1, 16], [5, 16], [1, 32]], [[1, 64], [5, 64], [1, 32]]],
        )

        token_embeddings = torch.rand(5, 10, 32)
        mask = torch.ones(5, 10).bool()
        mask[0, 7:] = False
        mask[1, 5:] = False

        output = cnn_encoder(token_embeddings, mask)
        assert list(output.size()) == [5, 10, 64]

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1355')" href="javascript:;">
allennlp-2.4.0/tests/modules/seq2seq_encoders/gated_cnn_encoder_test.py: 35-50
</a>
<div class="mid" id="frag1355" style="display:none"><pre>
    def test_gated_cnn_encoder_layers(self):
        cnn_encoder = GatedCnnEncoder(
            input_dim=32,
            layers=[[[4, 32]], [[1, 16], [5, 16], [1, 32]], [[1, 64], [5, 64], [1, 32]]],
            return_all_layers=True,
        )

        token_embeddings = torch.rand(5, 10, 32)
        mask = torch.ones(5, 10).bool()
        mask[0, 7:] = False
        mask[1, 5:] = False

        output = cnn_encoder(token_embeddings, mask)
        assert len(output) == 3
        concat_layers = torch.cat([layer.unsqueeze(1) for layer in output], dim=1)
        assert list(concat_layers.size()) == [5, 3, 10, 64]
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 73:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1363')" href="javascript:;">
allennlp-2.4.0/tests/modules/seq2seq_encoders/pytorch_seq2seq_wrapper_test.py: 127-141
</a>
<div class="mid" id="frag1363" style="display:none"><pre>
    def test_wrapper_works_when_passed_state_with_zero_length_sequences(self):
        lstm = LSTM(bidirectional=True, num_layers=3, input_size=3, hidden_size=7, batch_first=True)
        encoder = PytorchSeq2SeqWrapper(lstm)
        input_tensor = torch.rand([5, 7, 3])
        mask = torch.ones(5, 7).bool()
        mask[0, 3:] = False
        mask[1, 4:] = False
        mask[2, 0:] = False
        mask[3, 6:] = False

        # Initial states are of shape (num_layers * num_directions, batch_size, hidden_dim)
        initial_states = torch.randn(6, 5, 7), torch.randn(6, 5, 7)

        _ = encoder(input_tensor, mask, initial_states)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1364')" href="javascript:;">
allennlp-2.4.0/tests/modules/seq2seq_encoders/pytorch_seq2seq_wrapper_test.py: 142-155
</a>
<div class="mid" id="frag1364" style="display:none"><pre>
    def test_wrapper_can_call_backward_with_zero_length_sequences(self):
        lstm = LSTM(bidirectional=True, num_layers=3, input_size=3, hidden_size=7, batch_first=True)
        encoder = PytorchSeq2SeqWrapper(lstm)
        input_tensor = torch.rand([5, 7, 3])
        mask = torch.ones(5, 7).bool()
        mask[0, 3:] = False
        mask[1, 4:] = False
        mask[2, 0:] = 0  # zero length False
        mask[3, 6:] = False

        output = encoder(input_tensor, mask)

        output.sum().backward()

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<script language="JavaScript">
function ShowHide(divId) { 
    if(document.getElementById(divId).style.display == 'none') {
        document.getElementById(divId).style.display='block';
    } else { 
        document.getElementById(divId).style.display = 'none';
    } 
}
</script>
</body>
</html>
