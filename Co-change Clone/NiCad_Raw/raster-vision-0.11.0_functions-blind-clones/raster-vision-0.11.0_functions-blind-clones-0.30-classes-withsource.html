<html>
<head>
    <title>NiCad6 Clone Report</title>
    <style type="text/css">
        body {font-family:sans-serif;}
        table {background-color:white; border:0px; padding:0px; border-spacing:4px; width:auto; margin-left:30px; margin-right:auto;}
        td {background-color:rgba(192,212,238,0.8); border:0px; padding:8px; width:auto; vertical-align:top; border-radius:8px}
        pre {background-color:white; padding:4px;}
        a {color:darkblue;}
    </style>
</head>
<body>
<h2>NiCad6 Clone Report</h2>
<table>
<tr style="font-size:14pt">
<td><b>System:</b> &nbsp; raster-vision-0.11.0</td>
<td><b>Clone pairs:</b> &nbsp; 438</td>
<td><b>Clone classes:</b> &nbsp; 164</td>
</tr>
<tr style="font-size:12pt">
<td style="background-color:white">Clone type: &nbsp; 3-2</td>
<td style="background-color:white">Granularity: &nbsp; functions-blind</td>
<td style="background-color:white">Max diff threshold: &nbsp; 30%</td>
<td style="background-color:white">Clone size: &nbsp; 10 - 2500 lines</td>
<td style="background-color:white">Total functions-blind: &nbsp; 2959</td>
</tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 1:</b> &nbsp; 2 fragments, nominal size 16 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag29')" href="javascript:;">
raster-vision-0.11.0/rastervision/cli/main.py: 226-246
</a>
<div class="mid" id="frag29" style="display:none"><pre>
    def add_to_parser(self, parser, ctx):
        def parser_process(value, state):
            value = str(value)
            while state.rargs:
                value = '{} {}'.format(value, state.rargs.pop(0))
            self._previous_parser_process(value, state)

        retval = super(OptionEatAll, self).add_to_parser(parser, ctx)

        for name in self.opts:
            our_parser = parser._long_opt.get(name) or parser._short_opt.get(
                name)
            if our_parser:
                self._eat_all_parser = our_parser
                self._previous_parser_process = our_parser.process
                our_parser.process = parser_process
                break

        return retval


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1905')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/cli.py: 17-37
</a>
<div class="mid" id="frag1905" style="display:none"><pre>
    def add_to_parser(self, parser, ctx):
        def parser_process(value, state):
            value = str(value)
            while state.rargs:
                value = '{} {}'.format(value, state.rargs.pop(0))
            self._previous_parser_process(value, state)

        retval = super(OptionEatAll, self).add_to_parser(parser, ctx)

        for name in self.opts:
            our_parser = parser._long_opt.get(name) or parser._short_opt.get(
                name)
            if our_parser:
                self._eat_all_parser = our_parser
                self._previous_parser_process = our_parser.process
                our_parser.process = parser_process
                break

        return retval


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 2:</b> &nbsp; 5 fragments, nominal size 19 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag33')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/pytorch_semantic_segmentation_config.py: 13-32
</a>
<div class="mid" id="frag33" style="display:none"><pre>
    def __init__(self,
                 batch_size=None,
                 lr=None,
                 one_cycle=None,
                 num_epochs=None,
                 model_arch=None,
                 sync_interval=None,
                 debug=None,
                 log_tensorboard=None,
                 run_tensorboard=None):
        self.batch_size = batch_size
        self.lr = lr
        self.one_cycle = one_cycle
        self.num_epochs = num_epochs
        self.model_arch = model_arch
        self.sync_interval = sync_interval
        self.debug = debug
        self.log_tensorboard = log_tensorboard
        self.run_tensorboard = run_tensorboard

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1107')" href="javascript:;">
raster-vision-0.11.0/rastervision/evaluation/class_evaluation_item.py: 13-32
</a>
<div class="mid" id="frag1107" style="display:none"><pre>
    def __init__(self,
                 precision=None,
                 recall=None,
                 f1=None,
                 count_error=None,
                 gt_count=0,
                 class_id=None,
                 class_name=None,
                 conf_mat=None):
        self.precision = precision
        self.recall = recall
        self.f1 = f1
        self.count_error = count_error
        # Ground truth count of elements (boxes for object detection, pixels
        # for segmentation, cells for classification).
        self.gt_count = gt_count
        self.conf_mat = conf_mat
        self.class_id = class_id
        self.class_name = class_name

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1949')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/evaluation/class_evaluation_item.py: 13-32
</a>
<div class="mid" id="frag1949" style="display:none"><pre>
    def __init__(self,
                 precision=None,
                 recall=None,
                 f1=None,
                 count_error=None,
                 gt_count=0,
                 class_id=None,
                 class_name=None,
                 conf_mat=None):
        self.precision = precision
        self.recall = recall
        self.f1 = f1
        self.count_error = count_error
        # Ground truth count of elements (boxes for object detection, pixels
        # for segmentation, cells for classification).
        self.gt_count = gt_count
        self.conf_mat = conf_mat
        self.class_id = class_id
        self.class_name = class_name

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag38')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/pytorch_object_detection_config.py: 13-32
</a>
<div class="mid" id="frag38" style="display:none"><pre>
    def __init__(self,
                 batch_size=None,
                 lr=None,
                 one_cycle=None,
                 num_epochs=None,
                 model_arch=None,
                 sync_interval=None,
                 log_tensorboard=None,
                 run_tensorboard=None,
                 debug=None):
        self.batch_size = batch_size
        self.lr = lr
        self.one_cycle = one_cycle
        self.num_epochs = num_epochs
        self.model_arch = model_arch
        self.sync_interval = sync_interval
        self.log_tensorboard = log_tensorboard
        self.run_tensorboard = run_tensorboard
        self.debug = debug

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag163')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/pytorch_chip_classification_config.py: 13-38
</a>
<div class="mid" id="frag163" style="display:none"><pre>
    def __init__(self,
                 batch_size=None,
                 lr=None,
                 one_cycle=None,
                 num_epochs=None,
                 model_arch=None,
                 sync_interval=None,
                 debug=None,
                 log_tensorboard=None,
                 run_tensorboard=None,
                 rare_classes=None,
                 desired_prob=None,
                 augmentors=[]):
        self.batch_size = batch_size
        self.lr = lr
        self.one_cycle = one_cycle
        self.num_epochs = num_epochs
        self.model_arch = model_arch
        self.sync_interval = sync_interval
        self.debug = debug
        self.log_tensorboard = log_tensorboard
        self.run_tensorboard = run_tensorboard
        self.rare_classes = rare_classes
        self.desired_prob = desired_prob
        self.augmentors = augmentors

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 3:</b> &nbsp; 3 fragments, nominal size 23 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag36')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/pytorch_semantic_segmentation_config.py: 51-100
</a>
<div class="mid" id="frag36" style="display:none"><pre>
    def with_train_options(self,
                           batch_size=8,
                           lr=1e-4,
                           one_cycle=True,
                           num_epochs=5,
                           model_arch='resnet50',
                           sync_interval=1,
                           debug=False,
                           log_tensorboard=True,
                           run_tensorboard=True):
        """Set options for training models.

        Args:
            batch_size: (int) the batch size
            lr: (float) the learning rate if using a fixed LR
                (ie. one_cycle is False),
                or the maximum LR to use if one_cycle is True
            one_cycle: (bool) True if cyclic learning rate scheduler should
                be used. This
                cycles the LR once during the course of training and seems to
                result in a pretty consistent improvement. See lr for more
                details.
            num_epochs: (int) number of epochs (sweeps through training set) to
                train model for
            model_arch: (str) classification model backbone to use for DeepLabV3
                architecture. Currently, only Resnet50 works.
            sync_interval: (int) sync training directory to cloud every
                sync_interval epochs.
            debug: (bool) if True, save debug chips (ie. visualizations of
                input to model during training) during training and use
                single-core for creating minibatches.
            log_tensorboard: (bool) if True, write events to Tensorboard log
                file
            run_tensorboard: (bool) if True, run a Tensorboard server at
                port 6006 that uses the logs generated by the log_tensorboard
                option
        """
        b = deepcopy(self)
        b.train_opts = TrainOptions(
            batch_size=batch_size,
            lr=lr,
            one_cycle=one_cycle,
            num_epochs=num_epochs,
            model_arch=model_arch,
            sync_interval=sync_interval,
            debug=debug,
            log_tensorboard=log_tensorboard,
            run_tensorboard=run_tensorboard)
        return b

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag41')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/pytorch_object_detection_config.py: 52-102
</a>
<div class="mid" id="frag41" style="display:none"><pre>
    def with_train_options(self,
                           batch_size=8,
                           lr=1e-4,
                           one_cycle=True,
                           num_epochs=5,
                           model_arch='resnet18',
                           sync_interval=1,
                           log_tensorboard=True,
                           run_tensorboard=True,
                           debug=False):
        """Set options for training models.

        Args:
            batch_size: (int) the batch size
            lr: (float) the learning rate if using a fixed LR
                (ie. one_cycle is False),
                or the maximum LR to use if one_cycle is True
            one_cycle: (bool) True if cyclic learning rate scheduler should
                be used. This
                cycles the LR once during the course of training and seems to
                result in a pretty consistent improvement. See lr for more
                details.
            num_epochs: (int) number of epochs (sweeps through training set) to
                train model for
            model_arch: (str) classification model backbone to use.
                Any Resnet option in torchvision.models is valid,
                for example, resnet18.
            sync_interval: (int) sync training directory to cloud every
                sync_interval epochs.
            log_tensorboard: (bool) if True, write events to Tensorboard log
                file
            run_tensorboard: (bool) if True, run a Tensorboard server at
                port 6006 that uses the logs generated by the log_tensorboard
                option
            debug: (bool) if True, save debug chips (ie. visualizations of
                input to model during training) during training and use
                single-core for creating minibatches.
        """
        b = deepcopy(self)
        b.train_opts = TrainOptions(
            batch_size=batch_size,
            lr=lr,
            one_cycle=one_cycle,
            num_epochs=num_epochs,
            model_arch=model_arch,
            sync_interval=sync_interval,
            log_tensorboard=log_tensorboard,
            run_tensorboard=run_tensorboard,
            debug=debug)
        return b

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag166')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/pytorch_chip_classification_config.py: 57-124
</a>
<div class="mid" id="frag166" style="display:none"><pre>
    def with_train_options(self,
                           batch_size=8,
                           lr=1e-4,
                           one_cycle=True,
                           num_epochs=1,
                           model_arch='resnet18',
                           sync_interval=1,
                           debug=False,
                           log_tensorboard=True,
                           run_tensorboard=True,
                           rare_classes=[],
                           desired_prob=None,
                           augmentors=[]):
        """Set options for training models.

        Args:
            batch_size: (int) the batch size
            weight_decay: (float) the weight decay
            lr: (float) the learning rate if using a fixed LR
                (ie. one_cycle is False),
                or the maximum LR to use if one_cycle is True
            one_cycle: (bool) True if cyclic learning rate scheduler should
                be used. This
                cycles the LR once during the course of training and seems to
                result in a pretty consistent improvement. See lr for more
                details.
            num_epochs: (int) number of epochs (sweeps through training set) to
                train model for
            model_arch: (str) Any classification model option in
                torchvision.models is valid, for example, resnet18.
            sync_interval: (int) sync training directory to cloud every
                sync_interval epochs.
            debug: (bool) if True, save debug chips (ie. visualizations of
                input to model during training) during training and use
                single-core for creating minibatches.
            log_tensorboard: (bool) if True, write events to Tensorboard log
                file
            run_tensorboard: (bool) if True, run a Tensorboard server at
                port 6006 that uses the logs generated by the log_tensorboard
                option
            rare_classes: (list) of integers with class indices that should be
                oversampled during the training. The goal is to reduce the effect
                of severe class imbalance influencing training.
            desired_prob: (float) when a list of rare classes is given, a single
                float can be given (between 0.0 and 1.0) indicating the desired
                probability of the rare classes. If e.g. set to 0.5, the change of
                drawing any rare class sample is 0.5.
            augmentors: (list of str) any of ['Blur', 'RandomRotate90', 'HorizontalFlip',
                'VerticalFlip', 'GaussianBlur', or 'GaussNoise', 'RGBShift', 'ToGray'].
                These use the default settings for each of the transforms in
                https://albumentations.readthedocs.io
        """
        b = deepcopy(self)
        b.train_opts = TrainOptions(
            batch_size=batch_size,
            lr=lr,
            one_cycle=one_cycle,
            num_epochs=num_epochs,
            model_arch=model_arch,
            sync_interval=sync_interval,
            debug=debug,
            log_tensorboard=log_tensorboard,
            run_tensorboard=run_tensorboard,
            rare_classes=rare_classes,
            desired_prob=desired_prob,
            augmentors=augmentors)
        return b

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 4:</b> &nbsp; 3 fragments, nominal size 11 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag48')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/keras_classification/utils.py: 16-31
</a>
<div class="mid" id="frag48" style="display:none"><pre>
def make_dir(path, check_empty=False, force_empty=False, use_dirname=False):
    directory = path
    if use_dirname:
        directory = os.path.dirname(path)

    if force_empty and os.path.isdir(directory):
        shutil.rmtree(directory)

    os.makedirs(directory, exist_ok=True)

    is_empty = len(os.listdir(directory)) == 0
    if check_empty and not is_empty:
        raise ValueError(
            '{} needs to be an empty directory!'.format(directory))


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag285')" href="javascript:;">
raster-vision-0.11.0/rastervision/filesystem/local_filesystem.py: 9-35
</a>
<div class="mid" id="frag285" style="display:none"><pre>
def make_dir(path, check_empty=False, force_empty=False, use_dirname=False):
    """Make a local directory.

    Args:
        path: path to directory
        check_empty: if True, check that directory is empty
        force_empty: if True, delete files if necessary to make directory
            empty
        use_dirname: if True, use the the parent directory as path

    Raises:
        ValueError if check_empty is True and directory is not empty
    """
    directory = path
    if use_dirname:
        directory = os.path.abspath(os.path.dirname(path))

    if force_empty and os.path.isdir(directory):
        shutil.rmtree(directory)

    os.makedirs(directory, exist_ok=True)

    if check_empty and any(os.scandir(directory)):
        raise ValueError(
            '{} needs to be an empty directory!'.format(directory))


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1488')" href="javascript:;">
raster-vision-0.11.0/rastervision2/pipeline/file_system/local_file_system.py: 9-35
</a>
<div class="mid" id="frag1488" style="display:none"><pre>
def make_dir(path, check_empty=False, force_empty=False, use_dirname=False):
    """Make a local directory.

    Args:
        path: path to directory
        check_empty: if True, check that directory is empty
        force_empty: if True, delete files if necessary to make directory
            empty
        use_dirname: if True, use the the parent directory as path

    Raises:
        ValueError if check_empty is True and directory is not empty
    """
    directory = path
    if use_dirname:
        directory = os.path.abspath(os.path.dirname(path))

    if force_empty and os.path.isdir(directory):
        shutil.rmtree(directory)

    os.makedirs(directory, exist_ok=True)

    if check_empty and any(os.scandir(directory)):
        raise ValueError(
            '{} needs to be an empty directory!'.format(directory))


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 5:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 94%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag90')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/torch_utils/semantic_segmentation/train.py: 8-30
</a>
<div class="mid" id="frag90" style="display:none"><pre>
def train_epoch(model, device, data_loader, opt, loss_fn, step_scheduler=None):
    model.train()
    total_loss = 0.0
    num_samples = 0

    with click.progressbar(data_loader, label='Training') as bar:
        for batch_ind, (x, y) in enumerate(bar):
            x = x.to(device)
            y = y.to(device)

            opt.zero_grad()
            out = model(x)['out']
            loss = loss_fn(out, y)
            loss.backward()
            total_loss += loss.item()
            opt.step()
            if step_scheduler:
                step_scheduler.step()
            num_samples += x.shape[0]

    return total_loss / num_samples


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag147')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/torch_utils/chip_classification/train.py: 8-30
</a>
<div class="mid" id="frag147" style="display:none"><pre>
def train_epoch(model, device, data_loader, opt, loss_fn, step_scheduler=None):
    model.train()
    total_loss = 0.0
    num_samples = 0

    with click.progressbar(data_loader, label='Training') as bar:
        for batch_ind, (x, y) in enumerate(bar):
            x = x.to(device)
            y = y.to(device)

            opt.zero_grad()
            out = model(x)
            loss = loss_fn(out, y)
            loss.backward()
            total_loss += loss.item()
            opt.step()
            if step_scheduler:
                step_scheduler.step()
            num_samples += x.shape[0]

    return total_loss / num_samples


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 6:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag95')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/torch_utils/object_detection/model.py: 11-29
</a>
<div class="mid" id="frag95" style="display:none"><pre>
def get_out_channels(model):
    out = {}

    def make_save_output(layer_name):
        def save_output(layer, input, output):
            out[layer_name] = output.shape[1]

        return save_output

    model.layer1.register_forward_hook(make_save_output('layer1'))
    model.layer2.register_forward_hook(make_save_output('layer2'))
    model.layer3.register_forward_hook(make_save_output('layer3'))
    model.layer4.register_forward_hook(make_save_output('layer4'))

    model(torch.empty((1, 3, 128, 128)))
    return [out['layer1'], out['layer2'], out['layer3'], out['layer4']]


# This fixes a bug in torchvision.
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1399')" href="javascript:;">
raster-vision-0.11.0/rastervision2/pytorch_learner/object_detection_utils.py: 325-343
</a>
<div class="mid" id="frag1399" style="display:none"><pre>
def get_out_channels(model):
    out = {}

    def make_save_output(layer_name):
        def save_output(layer, input, output):
            out[layer_name] = output.shape[1]

        return save_output

    model.layer1.register_forward_hook(make_save_output('layer1'))
    model.layer2.register_forward_hook(make_save_output('layer2'))
    model.layer3.register_forward_hook(make_save_output('layer3'))
    model.layer4.register_forward_hook(make_save_output('layer4'))

    model(torch.empty((1, 3, 128, 128)))
    return [out['layer1'], out['layer2'], out['layer3'], out['layer4']]


# This fixes a bug in torchvision.
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 7:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag98')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/torch_utils/object_detection/model.py: 30-46
</a>
<div class="mid" id="frag98" style="display:none"><pre>
def resnet_fpn_backbone(backbone_name, pretrained):
    backbone = resnet.__dict__[backbone_name](
        pretrained=pretrained, norm_layer=misc_nn_ops.FrozenBatchNorm2d)

    # freeze layers
    for name, parameter in backbone.named_parameters():
        if 'layer2' not in name and 'layer3' not in name and 'layer4' not in name:
            parameter.requires_grad_(False)

    return_layers = {'layer1': 0, 'layer2': 1, 'layer3': 2, 'layer4': 3}

    out_channels = 256
    in_channels_list = get_out_channels(backbone)
    return BackboneWithFPN(backbone, return_layers, in_channels_list,
                           out_channels)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1402')" href="javascript:;">
raster-vision-0.11.0/rastervision2/pytorch_learner/object_detection_utils.py: 344-360
</a>
<div class="mid" id="frag1402" style="display:none"><pre>
def resnet_fpn_backbone(backbone_name, pretrained):
    backbone = resnet.__dict__[backbone_name](
        pretrained=pretrained, norm_layer=misc_nn_ops.FrozenBatchNorm2d)

    # freeze layers
    for name, parameter in backbone.named_parameters():
        if 'layer2' not in name and 'layer3' not in name and 'layer4' not in name:
            parameter.requires_grad_(False)

    return_layers = {'layer1': 0, 'layer2': 1, 'layer3': 2, 'layer4': 3}

    out_channels = 256
    in_channels_list = get_out_channels(backbone)
    return BackboneWithFPN(backbone, return_layers, in_channels_list,
                           out_channels)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 8:</b> &nbsp; 2 fragments, nominal size 39 lines, similarity 78%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag100')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/torch_utils/object_detection/model.py: 66-128
</a>
<div class="mid" id="frag100" style="display:none"><pre>
    def forward(self, input, targets=None):
        """Forward pass

        Args:
            input: tensor&lt;n, 3, h, w&gt; with batch of images
            targets: None or list&lt;BoxList&gt; of length n with boxes and labels

        Returns:
            if targets is None, returns list&lt;BoxList&gt; of length n, containing
            boxes, labels, and scores for boxes with score &gt; 0.05. Further
            filtering based on score should be done before considering the
            prediction "final".

            if targets is a list, returns the losses as dict with keys from
            self.subloss_names.
        """
        if targets:
            # Add bogus background class box for each image to workaround
            # the inability of torchvision to train on images with
            # no ground truth boxes. This is important for being able
            # to handle negative chips generated by RV.
            new_targets = []
            for x, y in zip(input, targets):
                h, w = x.shape[1:]
                boxes = torch.cat(
                    [
                        y.boxes,
                        torch.tensor([[0., 0, h, w]], device=input.device)
                    ],
                    dim=0)
                labels = torch.cat(
                    [
                        y.get_field('labels'),
                        torch.tensor([0], device=input.device)
                    ],
                    dim=0)
                bl = BoxList(boxes, labels=labels)
                new_targets.append(bl)
            targets = new_targets

            _targets = [bl.xyxy() for bl in targets]
            _targets = [{
                'boxes': bl.boxes,
                'labels': bl.get_field('labels')
            } for bl in _targets]
            loss_dict = self.model(input, _targets)
            loss_dict['total_loss'] = sum(list(loss_dict.values()))
            return loss_dict

        out = self.model(input)
        boxlists = [
            BoxList(
                _out['boxes'], labels=_out['labels'],
                scores=_out['scores']).yxyx() for _out in out
        ]

        # Remove bogus background boxes.
        new_boxlists = []
        for bl in boxlists:
            labels = bl.get_field('labels')
            non_zero_inds = labels != 0
            new_boxlists.append(bl.ind_filter(non_zero_inds))
        return new_boxlists
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1405')" href="javascript:;">
raster-vision-0.11.0/rastervision2/pytorch_learner/object_detection_utils.py: 422-491
</a>
<div class="mid" id="frag1405" style="display:none"><pre>
    def forward(self, input, targets=None):
        """Forward pass

        Args:
            input: tensor&lt;n, 3, h, w&gt; with batch of images
            targets: None or list&lt;BoxList&gt; of length n with boxes and class_ids

        Returns:
            if targets is None, returns list&lt;BoxList&gt; of length n, containing
            boxes, class_ids, and scores for boxes with score &gt; 0.05. Further
            filtering based on score should be done before considering the
            prediction "final".

            if targets is a list, returns the losses as dict with keys from
            self.subloss_names.
        """
        if targets:
            # Add bogus background class box for each image to workaround
            # the inability of torchvision to train on images with
            # no ground truth boxes. This is important for being able
            # to handle negative chips generated by RV.
            # See https://github.com/pytorch/vision/issues/1598

            # Note class_ids must start at 1.
            new_targets = []
            for x, y in zip(input, targets):
                h, w = x.shape[1:]
                boxes = torch.cat(
                    [
                        y.boxes,
                        torch.tensor([[0., 0, h, w]], device=input.device)
                    ],
                    dim=0)
                class_ids = torch.cat(
                    [
                        y.get_field('class_ids') + 1,
                        torch.tensor(
                            [self.null_class_id + 1], device=input.device),
                    ],
                    dim=0)
                bl = BoxList(boxes, class_ids=class_ids)
                new_targets.append(bl)
            targets = new_targets

            _targets = [bl.xyxy() for bl in targets]
            _targets = [{
                'boxes': bl.boxes,
                'labels': bl.get_field('class_ids')
            } for bl in _targets]
            loss_dict = self.model(input, _targets)
            loss_dict['total_loss'] = sum(list(loss_dict.values()))

            return loss_dict

        out = self.model(input)
        boxlists = [
            BoxList(
                _out['boxes'], class_ids=_out['labels'],
                scores=_out['scores']).yxyx() for _out in out
        ]

        # Remove bogus background boxes.
        new_boxlists = []
        for bl in boxlists:
            class_ids = bl.get_field('class_ids') - 1
            non_null_inds = class_ids != self.null_class_id
            bl = bl.ind_filter(non_null_inds)
            bl.extras['class_ids'] -= 1
            new_boxlists.append(bl)
        return new_boxlists
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 9:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag112')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/torch_utils/object_detection/boxlist.py: 67-78
</a>
<div class="mid" id="frag112" style="display:none"><pre>
    def cat(box_lists):
        boxes = []
        extras = defaultdict(list)
        for bl in box_lists:
            boxes.append(bl.boxes)
            for k, v in bl.extras.items():
                extras[k].append(v)
        boxes = torch.cat(boxes)
        for k, v in extras.items():
            extras[k] = torch.cat(v)
        return BoxList(boxes, **extras)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1387')" href="javascript:;">
raster-vision-0.11.0/rastervision2/pytorch_learner/object_detection_utils.py: 185-196
</a>
<div class="mid" id="frag1387" style="display:none"><pre>
    def cat(box_lists):
        boxes = []
        extras = defaultdict(list)
        for bl in box_lists:
            boxes.append(bl.boxes)
            for k, v in bl.extras.items():
                extras[k].append(v)
        boxes = torch.cat(boxes)
        for k, v in extras.items():
            extras[k] = torch.cat(v)
        return BoxList(boxes, **extras)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 10:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag113')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/torch_utils/object_detection/boxlist.py: 79-94
</a>
<div class="mid" id="frag113" style="display:none"><pre>
    def equal(self, other):
        if len(other) != len(self):
            return False

        # Ignore order of boxes.
        extras = [(v.float().unsqueeze(1) if v.ndim == 1 else v.float())
                  for v in self.extras.values()]
        cat_arr = torch.cat([self.boxes] + extras, 1)
        self_tups = set([tuple([x.item() for x in row]) for row in cat_arr])

        extras = [(v.float().unsqueeze(1) if v.ndim == 1 else v.float())
                  for v in other.extras.values()]
        cat_arr = torch.cat([other.boxes] + extras, 1)
        other_tups = set([tuple([x.item() for x in row]) for row in cat_arr])
        return self_tups == other_tups

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1388')" href="javascript:;">
raster-vision-0.11.0/rastervision2/pytorch_learner/object_detection_utils.py: 197-212
</a>
<div class="mid" id="frag1388" style="display:none"><pre>
    def equal(self, other):
        if len(other) != len(self):
            return False

        # Ignore order of boxes.
        extras = [(v.float().unsqueeze(1) if v.ndim == 1 else v.float())
                  for v in self.extras.values()]
        cat_arr = torch.cat([self.boxes] + extras, 1)
        self_tups = set([tuple([x.item() for x in row]) for row in cat_arr])

        extras = [(v.float().unsqueeze(1) if v.ndim == 1 else v.float())
                  for v in other.extras.values()]
        cat_arr = torch.cat([other.boxes] + extras, 1)
        other_tups = set([tuple([x.item() for x in row]) for row in cat_arr])
        return self_tups == other_tups

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 11:</b> &nbsp; 2 fragments, nominal size 35 lines, similarity 91%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag136')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/torch_utils/object_detection/metrics.py: 12-54
</a>
<div class="mid" id="frag136" style="display:none"><pre>
def get_coco_gt(targets, num_labels):
    images = []
    annotations = []
    ann_id = 1
    for img_id, target in enumerate(targets, 1):
        # Use fake height, width, and filename because they don't matter.
        images.append({
            'id': img_id,
            'height': 1000,
            'width': 1000,
            'file_name': '{}.png'.format(img_id)
        })
        boxes, labels = target.boxes, target.get_field('labels')
        for box, label in zip(boxes, labels):
            box = box.float().tolist()
            label = label.item()
            annotations.append({
                'id':
                ann_id,
                'image_id':
                img_id,
                'category_id':
                label,
                'area': (box[2] - box[0]) * (box[3] - box[1]),
                'bbox': [box[1], box[0], box[3] - box[1], box[2] - box[0]],
                'iscrowd':
                0
            })
            ann_id += 1

    categories = [{
        'id': label,
        'name': str(label),
        'supercategory': 'super'
    } for label in range(num_labels)]
    coco = {
        'images': images,
        'annotations': annotations,
        'categories': categories
    }
    return coco


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1373')" href="javascript:;">
raster-vision-0.11.0/rastervision2/pytorch_learner/object_detection_utils.py: 23-65
</a>
<div class="mid" id="frag1373" style="display:none"><pre>
def get_coco_gt(targets, num_class_ids):
    images = []
    annotations = []
    ann_id = 1
    for img_id, target in enumerate(targets, 1):
        # Use fake height, width, and filename because they don't matter.
        images.append({
            'id': img_id,
            'height': 1000,
            'width': 1000,
            'file_name': '{}.png'.format(img_id)
        })
        boxes, class_ids = target.boxes, target.get_field('class_ids')
        for box, class_id in zip(boxes, class_ids):
            box = box.float().tolist()
            class_id = class_id.item()
            annotations.append({
                'id':
                ann_id,
                'image_id':
                img_id,
                'category_id':
                class_id + 1,
                'area': (box[2] - box[0]) * (box[3] - box[1]),
                'bbox': [box[1], box[0], box[3] - box[1], box[2] - box[0]],
                'iscrowd':
                0
            })
            ann_id += 1

    categories = [{
        'id': class_id + 1,
        'name': str(class_id + 1),
        'supercategory': 'super'
    } for class_id in range(num_class_ids)]
    coco = {
        'images': images,
        'annotations': annotations,
        'categories': categories
    }
    return coco


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 12:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 83%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag137')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/torch_utils/object_detection/metrics.py: 55-74
</a>
<div class="mid" id="frag137" style="display:none"><pre>
def get_coco_preds(outputs):
    preds = []
    for img_id, output in enumerate(outputs, 1):
        for box, label, score in zip(output.boxes, output.get_field('labels'),
                                     output.get_field('scores')):
            box = box.float().tolist()
            label = label.item()
            score = score.item()
            preds.append({
                'image_id':
                img_id,
                'category_id':
                label,
                'bbox': [box[1], box[0], box[3] - box[1], box[2] - box[0]],
                'score':
                score
            })
    return preds


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1374')" href="javascript:;">
raster-vision-0.11.0/rastervision2/pytorch_learner/object_detection_utils.py: 66-86
</a>
<div class="mid" id="frag1374" style="display:none"><pre>
def get_coco_preds(outputs):
    preds = []
    for img_id, output in enumerate(outputs, 1):
        for box, class_id, score in zip(output.boxes,
                                        output.get_field('class_ids'),
                                        output.get_field('scores')):
            box = box.float().tolist()
            class_id = class_id.item() + 1
            score = score.item()
            preds.append({
                'image_id':
                img_id,
                'category_id':
                class_id,
                'bbox': [box[1], box[0], box[3] - box[1], box[2] - box[0]],
                'score':
                score
            })
    return preds


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 13:</b> &nbsp; 2 fragments, nominal size 17 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag138')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/torch_utils/object_detection/metrics.py: 75-113
</a>
<div class="mid" id="frag138" style="display:none"><pre>
def compute_coco_eval(outputs, targets, num_labels):
    """Return mAP averaged over 0.5-0.95 using pycocotools eval.

    Note: boxes are in (ymin, xmin, ymax, xmax) format with values ranging
        from 0 to h or w.

    Args:
        outputs: (list) of length m containing dicts of form
            {'boxes': &lt;tensor with shape (n, 4)&gt;,
             'labels': &lt;tensor with shape (n,)&gt;,
             'scores': &lt;tensor with shape (n,)&gt;}
        targets: (list) of length m containing dicts of form
            {'boxes': &lt;tensor with shape (n, 4)&gt;,
             'labels': &lt;tensor with shape (n,)&gt;}
    """
    with tempfile.TemporaryDirectory() as tmp_dir:
        preds = get_coco_preds(outputs)
        # ap is undefined when there are no predicted boxes
        if len(preds) == 0:
            return None

        gt = get_coco_gt(targets, num_labels)
        gt_path = join(tmp_dir, 'gt.json')
        json_to_file(gt, gt_path)
        coco_gt = COCO(gt_path)

        pycocotools.coco.unicode = None
        coco_preds = coco_gt.loadRes(preds)

        ann_type = 'bbox'
        coco_eval = COCOeval(coco_gt, coco_preds, ann_type)

        coco_eval.evaluate()
        coco_eval.accumulate()
        coco_eval.summarize()

        return coco_eval


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1375')" href="javascript:;">
raster-vision-0.11.0/rastervision2/pytorch_learner/object_detection_utils.py: 87-125
</a>
<div class="mid" id="frag1375" style="display:none"><pre>
def compute_coco_eval(outputs, targets, num_class_ids):
    """Return mAP averaged over 0.5-0.95 using pycocotools eval.

    Note: boxes are in (ymin, xmin, ymax, xmax) format with values ranging
        from 0 to h or w.

    Args:
        outputs: (list) of length m containing dicts of form
            {'boxes': &lt;tensor with shape (n, 4)&gt;,
             'class_ids': &lt;tensor with shape (n,)&gt;,
             'scores': &lt;tensor with shape (n,)&gt;}
        targets: (list) of length m containing dicts of form
            {'boxes': &lt;tensor with shape (n, 4)&gt;,
             'class_ids': &lt;tensor with shape (n,)&gt;}
    """
    with tempfile.TemporaryDirectory() as tmp_dir:
        preds = get_coco_preds(outputs)
        # ap is undefined when there are no predicted boxes
        if len(preds) == 0:
            return None

        gt = get_coco_gt(targets, num_class_ids)
        gt_path = join(tmp_dir, 'gt.json')
        json_to_file(gt, gt_path)
        coco_gt = COCO(gt_path)

        pycocotools.coco.unicode = None
        coco_preds = coco_gt.loadRes(preds)

        ann_type = 'bbox'
        coco_eval = COCOeval(coco_gt, coco_preds, ann_type)

        coco_eval.evaluate()
        coco_eval.accumulate()
        coco_eval.summarize()

        return coco_eval


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 14:</b> &nbsp; 2 fragments, nominal size 30 lines, similarity 86%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag140')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/torch_utils/object_detection/plot.py: 4-38
</a>
<div class="mid" id="frag140" style="display:none"><pre>
def plot_xy(ax, x, y=None, label_names=None):
    ax.imshow(x.permute(1, 2, 0))

    if y is not None:
        scores = y.get_field('scores')
        for box_ind, (box, label) in enumerate(
                zip(y.boxes, y.get_field('labels'))):
            rect = patches.Rectangle(
                (box[1], box[0]),
                box[3] - box[1],
                box[2] - box[0],
                linewidth=1,
                edgecolor='cyan',
                facecolor='none')
            ax.add_patch(rect)

            label_name = label_names[label]
            if scores is not None:
                score = scores[box_ind]
                label_name += ' {:.2f}'.format(score)

            h, w = x.shape[1:]
            label_height = h * 0.03
            label_width = w * 0.15
            rect = patches.Rectangle(
                (box[1], box[0] - label_height),
                label_width,
                label_height,
                color='cyan')
            ax.add_patch(rect)

            ax.text(
                box[1] + w * 0.003, box[0] - h * 0.003, label_name, fontsize=7)

    ax.axis('off')
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1403')" href="javascript:;">
raster-vision-0.11.0/rastervision2/pytorch_learner/object_detection_utils.py: 361-396
</a>
<div class="mid" id="frag1403" style="display:none"><pre>
def plot_xyz(ax, x, y, class_names, z=None):
    ax.imshow(x.permute(1, 2, 0))
    y = y if z is None else z

    scores = y.get_field('scores')
    for box_ind, (box, class_id) in enumerate(
            zip(y.boxes, y.get_field('class_ids'))):
        rect = patches.Rectangle(
            (box[1], box[0]),
            box[3] - box[1],
            box[2] - box[0],
            linewidth=1,
            edgecolor='cyan',
            facecolor='none')
        ax.add_patch(rect)

        box_label = class_names[class_id]
        if scores is not None:
            score = scores[box_ind]
            box_label += ' {:.2f}'.format(score)

        h, w = x.shape[1:]
        label_height = h * 0.03
        label_width = w * 0.15
        rect = patches.Rectangle(
            (box[1], box[0] - label_height),
            label_width,
            label_height,
            color='cyan')
        ax.add_patch(rect)

        ax.text(box[1] + w * 0.003, box[0] - h * 0.003, box_label, fontsize=7)

    ax.axis('off')


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 15:</b> &nbsp; 3 fragments, nominal size 19 lines, similarity 94%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag152')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/pytorch_semantic_segmentation.py: 40-78
</a>
<div class="mid" id="frag152" style="display:none"><pre>
def make_debug_chips(databunch, class_map, tmp_dir, train_uri, max_count=30):
    """Save debug chips for a Databunch for a semantic segmentation dataset.

    This saves a plot for each example in the training and validation sets into
    train-debug-chips.zip and valid-debug-chips.zip under the train_uri. This
    is useful for making sure we are feeding correct data into the model.

    Args:
        databunch: DataBunch for semantic segmentation
        class_map: (rv.ClassMap) class map used to map class ids to colors
        tmp_dir: (str) path to temp directory
        train_uri: (str) URI of root of training output
        max_count: (int) maximum number of chips to generate. If None,
            generates all of them.
    """

    def _make_debug_chips(split):
        debug_chips_dir = join(tmp_dir, '{}-debug-chips'.format(split))
        zip_path = join(tmp_dir, '{}-debug-chips.zip'.format(split))
        zip_uri = join(train_uri, '{}-debug-chips.zip'.format(split))
        make_dir(debug_chips_dir)
        ds = databunch.train_ds if split == 'train' else databunch.valid_ds
        for i, (x, y) in enumerate(ds):
            if i &gt;= max_count:
                break

            fig, ax = plt.subplots(1)
            plot_xy(ax, x, class_map, y=y)
            plt.savefig(
                join(debug_chips_dir, '{}.png'.format(i)), figsize=(6, 6))
            plt.close()

        zipdir(debug_chips_dir, zip_path)
        upload_or_copy(zip_path, zip_uri)

    _make_debug_chips('train')
    _make_debug_chips('valid')


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag204')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/pytorch_object_detection.py: 37-75
</a>
<div class="mid" id="frag204" style="display:none"><pre>
def make_debug_chips(databunch, class_map, tmp_dir, train_uri, max_count=30):
    """Save debug chips for a DataBunch.

    This saves a plot for each example in the training and validation sets into
    train-debug-chips.zip and valid-debug-chips.zip under the train_uri. This
    is useful for making sure we are feeding correct data into the model.

    Args:
        data: DataBunch for an object detection problem
        class_map: (rv.ClassMap) class map used to map class ids to colors
        tmp_dir: (str) path to temp directory
        train_uri: (str) URI of root of training output
        max_count: (int) maximum number of chips to generate. If None,
            generates all of them.
    """

    def _make_debug_chips(split):
        debug_chips_dir = join(tmp_dir, '{}-debug-chips'.format(split))
        zip_path = join(tmp_dir, '{}-debug-chips.zip'.format(split))
        zip_uri = join(train_uri, '{}-debug-chips.zip'.format(split))
        make_dir(debug_chips_dir)
        ds = databunch.train_ds if split == 'train' else databunch.valid_ds
        for i, (x, y) in enumerate(ds):
            if i &gt;= max_count:
                break

            fig, ax = plt.subplots(1)
            plot_xy(ax, x, y, ds.label_names)
            plt.savefig(
                join(debug_chips_dir, '{}.png'.format(i)), figsize=(6, 6))
            plt.close()

        zipdir(debug_chips_dir, zip_path)
        upload_or_copy(zip_path, zip_uri)

    _make_debug_chips('train')
    _make_debug_chips('val')


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag228')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/pytorch_chip_classification.py: 39-77
</a>
<div class="mid" id="frag228" style="display:none"><pre>
def make_debug_chips(databunch, class_map, tmp_dir, train_uri, max_count=30):
    """Save debug chips for a Databunch for a chip classification dataset

    This saves a plot for each example in the training and validation sets into
    train-debug-chips.zip and valid-debug-chips.zip under the train_uri. This
    is useful for making sure we are feeding correct data into the model.

    Args:
        databunch: DataBunch for chip classification
        class_map: (rv.ClassMap) class map used to map class ids to colors
        tmp_dir: (str) path to temp directory
        train_uri: (str) URI of root of training output
        max_count: (int) maximum number of chips to generate. If None,
            generates all of them.
    """

    def _make_debug_chips(split):
        debug_chips_dir = join(tmp_dir, '{}-debug-chips'.format(split))
        zip_path = join(tmp_dir, '{}-debug-chips.zip'.format(split))
        zip_uri = join(train_uri, '{}-debug-chips.zip'.format(split))
        make_dir(debug_chips_dir)
        ds = databunch.train_ds if split == 'train' else databunch.valid_ds
        for i, (x, y) in enumerate(ds):
            if i &gt;= max_count:
                break

            fig, ax = plt.subplots(1)
            plot_xy(ax, x, y, databunch.label_names)
            plt.savefig(
                join(debug_chips_dir, '{}.png'.format(i)), figsize=(6, 6))
            plt.close()

        zipdir(debug_chips_dir, zip_path)
        upload_or_copy(zip_path, zip_uri)

    _make_debug_chips('train')
    _make_debug_chips('valid')


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 16:</b> &nbsp; 3 fragments, nominal size 11 lines, similarity 83%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag154')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/pytorch_semantic_segmentation.py: 82-104
</a>
<div class="mid" id="frag154" style="display:none"><pre>
    def __init__(self, task_config, backend_opts, train_opts):
        """Constructor.

        Args:
            task_config: (SemanticSegmentationConfig)
            backend_opts: (simple_backend_config.BackendOptions)
            train_opts: (pytorch_semantic_segmentation_backend_config.TrainOptions)
        """
        self.task_config = task_config
        self.backend_opts = backend_opts
        self.train_opts = train_opts
        self.inf_learner = None

        torch_cache_dir = '/opt/data/torch-cache'
        os.environ['TORCH_HOME'] = torch_cache_dir

        self.model = None
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        log.info('Device = {}'.format(self.device))
        # TODO move this into the SemanticSegmentation RV task
        self.class_map = self.task_config.class_map.copy()
        self.class_map.add_nodata_item()

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag206')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/pytorch_object_detection.py: 79-99
</a>
<div class="mid" id="frag206" style="display:none"><pre>
    def __init__(self, task_config, backend_opts, train_opts):
        """Constructor.

        Args:
            task_config: (ChipClassificationConfig)
            backend_opts: (simple_backend_config.BackendOptions)
            train_opts: (pytorch_chip_classification_config.TrainOptions)
        """
        self.task_config = task_config
        self.backend_opts = backend_opts
        self.train_opts = train_opts
        self.inf_learner = None

        # Setup caching for torchvision pretrained models.
        torch_cache_dir = '/opt/data/torch-cache'
        os.environ['TORCH_HOME'] = torch_cache_dir

        self.model = None
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        log.info('Device = {}'.format(self.device))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag230')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/pytorch_chip_classification.py: 81-100
</a>
<div class="mid" id="frag230" style="display:none"><pre>
    def __init__(self, task_config, backend_opts, train_opts):
        """Constructor.

        Args:
            task_config: (ChipClassificationConfig)
            backend_opts: (simple_backend_config.BackendOptions)
            train_opts: (pytorch_chip_classification_config.TrainOptions)
        """
        self.task_config = task_config
        self.backend_opts = backend_opts
        self.train_opts = train_opts
        self.inf_learner = None

        torch_cache_dir = '/opt/data/torch-cache'
        os.environ['TORCH_HOME'] = torch_cache_dir

        self.model = None
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        log.info('Device = {}'.format(self.device))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 17:</b> &nbsp; 3 fragments, nominal size 19 lines, similarity 71%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag157')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/pytorch_semantic_segmentation.py: 142-187
</a>
<div class="mid" id="frag157" style="display:none"><pre>
    def process_sceneset_results(self, training_results, validation_results,
                                 tmp_dir):
        """Write zip file with chips for a set of scenes.

        This writes a zip file for a group of scenes at {chip_uri}/{uuid}.zip containing:
        train/img/{scene_id}-{ind}.png
        train/labels/{scene_id}-{ind}.png
        val/img/{scene_id}-{ind}.png
        val/labels/{scene_id}-{ind}.png

        This method is called once per instance of the chip command.
        A number of instances of the chip command can run simultaneously to
        process chips in parallel. The uuid in the path above is what allows
        separate instances to avoid overwriting each others' output.

        Args:
            training_results: list of directories generated by process_scene_data
                that all hold training chips
            validation_results: list of directories generated by process_scene_data
                that all hold validation chips
        """
        self.log_options()

        group = str(uuid.uuid4())
        group_uri = join(self.backend_opts.chip_uri, '{}.zip'.format(group))
        group_path = get_local_path(group_uri, tmp_dir)
        make_dir(group_path, use_dirname=True)

        with zipfile.ZipFile(group_path, 'w', zipfile.ZIP_DEFLATED) as zipf:

            def _write_zip(results, split):
                for scene_dir in results:
                    scene_paths = glob.glob(join(scene_dir, '**/*.png'))
                    for p in scene_paths:
                        zipf.write(
                            p,
                            join(
                                '{}/{}'.format(split,
                                               dirname(p).split('/')[-1]),
                                basename(p)))

            _write_zip(training_results, 'train')
            _write_zip(validation_results, 'valid')

        upload_or_copy(group_path, group_uri)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag209')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/pytorch_object_detection.py: 165-200
</a>
<div class="mid" id="frag209" style="display:none"><pre>
    def process_sceneset_results(self, training_results, validation_results,
                                 tmp_dir):
        """After all scenes have been processed, process the result set.

        This writes a zip file for a group of scenes at {chip_uri}/{uuid}.zip
        containing:
        train/{scene_id}-{ind}.png
        train/{scene_id}-labels.json
        valid/{scene_id}-{ind}.png
        valid/{scene_id}-labels.json

        Args:
            training_results: dependent on the ml_backend's process_scene_data
            validation_results: dependent on the ml_backend's
                process_scene_data
        """
        self.log_options()

        group = str(uuid.uuid4())
        group_uri = join(self.backend_opts.chip_uri, '{}.zip'.format(group))
        group_path = get_local_path(group_uri, tmp_dir)
        make_dir(group_path, use_dirname=True)

        with zipfile.ZipFile(group_path, 'w', zipfile.ZIP_DEFLATED) as zipf:

            def _write_zip(results, split):
                for scene_dir in results:
                    scene_paths = glob.glob(join(scene_dir, '*'))
                    for p in scene_paths:
                        zipf.write(p, join(split, basename(p)))

            _write_zip(training_results, 'train')
            _write_zip(validation_results, 'valid')

        upload_or_copy(group_path, group_uri)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag233')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/pytorch_chip_classification.py: 137-176
</a>
<div class="mid" id="frag233" style="display:none"><pre>
    def process_sceneset_results(self, training_results, validation_results,
                                 tmp_dir):
        """Write zip file with chips for a set of scenes.

        This writes a zip file for a group of scenes at {chip_uri}/{uuid}.zip containing:
        train-img/{class_name}/{scene_id}-{ind}.png
        valid-img/{class_name}/{scene_id}-{ind}.png

        This method is called once per instance of the chip command.
        A number of instances of the chip command can run simultaneously to
        process chips in parallel. The uuid in the path above is what allows
        separate instances to avoid overwriting each others' output.

        Args:
            training_results: list of directories generated by process_scene_data
                that all hold training chips
            validation_results: list of directories generated by process_scene_data
                that all hold validation chips
        """
        self.log_options()

        group = str(uuid.uuid4())
        group_uri = join(self.backend_opts.chip_uri, '{}.zip'.format(group))
        group_path = get_local_path(group_uri, tmp_dir)
        make_dir(group_path, use_dirname=True)

        with zipfile.ZipFile(group_path, 'w', zipfile.ZIP_DEFLATED) as zipf:

            def _write_zip(scene_dirs, split):
                for scene_dir in scene_dirs:
                    scene_paths = glob.glob(join(scene_dir, '**/*.png'))
                    for path in scene_paths:
                        class_name, fn = path.split('/')[-2:]
                        zipf.write(path, join(split, class_name, fn))

            _write_zip(training_results, 'train')
            _write_zip(validation_results, 'valid')

        upload_or_copy(group_path, group_uri)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 18:</b> &nbsp; 3 fragments, nominal size 116 lines, similarity 90%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag159')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/pytorch_semantic_segmentation.py: 188-352
</a>
<div class="mid" id="frag159" style="display:none"><pre>
    def train(self, tmp_dir):
        """Train a model.

        This downloads any previous output saved to the train_uri,
        starts training (or resumes from a checkpoint), periodically
        syncs contents of train_dir to train_uri and after training finishes.

        Args:
            tmp_dir: (str) path to temp directory
        """
        self.log_options()

        # Sync output of previous training run from cloud.
        train_uri = self.backend_opts.train_uri
        train_dir = get_local_path(train_uri, tmp_dir)
        make_dir(train_dir)
        sync_from_dir(train_uri, train_dir)

        # Get zip file for each group, and unzip them into chip_dir.
        chip_dir = join(tmp_dir, 'chips')
        make_dir(chip_dir)
        for zip_uri in list_paths(self.backend_opts.chip_uri, 'zip'):
            zip_path = download_if_needed(zip_uri, tmp_dir)
            with zipfile.ZipFile(zip_path, 'r') as zipf:
                zipf.extractall(chip_dir)

        # Setup data loader.
        batch_size = self.train_opts.batch_size
        chip_size = self.task_config.chip_size
        class_names = self.class_map.get_class_names()
        databunch = build_databunch(chip_dir, chip_size, batch_size,
                                    class_names)
        log.info(databunch)
        num_labels = len(databunch.label_names)
        if self.train_opts.debug:
            make_debug_chips(databunch, self.class_map, tmp_dir, train_uri)

        # Setup model
        num_labels = len(databunch.label_names)
        model = get_model(
            self.train_opts.model_arch, num_labels, pretrained=True)
        model = model.to(self.device)
        model_path = join(train_dir, 'model')

        # Load weights from a pretrained model.
        pretrained_uri = self.backend_opts.pretrained_uri
        if pretrained_uri:
            log.info('Loading weights from pretrained_uri: {}'.format(
                pretrained_uri))
            pretrained_path = download_if_needed(pretrained_uri, tmp_dir)
            model.load_state_dict(
                torch.load(pretrained_path, map_location=self.device))

        # Possibly resume training from checkpoint.
        start_epoch = 0
        train_state_path = join(train_dir, 'train_state.json')
        if isfile(train_state_path):
            log.info('Resuming from checkpoint: {}\n'.format(model_path))
            train_state = file_to_json(train_state_path)
            start_epoch = train_state['epoch'] + 1
            model.load_state_dict(
                torch.load(model_path, map_location=self.device))

        # Write header of log CSV file.
        metric_names = ['precision', 'recall', 'f1']
        log_path = join(train_dir, 'log.csv')
        if not isfile(log_path):
            with open(log_path, 'w') as log_file:
                log_writer = csv.writer(log_file)
                row = ['epoch', 'time', 'train_loss'] + metric_names
                log_writer.writerow(row)

        # Setup Tensorboard logging.
        if self.train_opts.log_tensorboard:
            log_dir = join(train_dir, 'tb-logs')
            make_dir(log_dir)
            tb_writer = SummaryWriter(log_dir=log_dir)
            if self.train_opts.run_tensorboard:
                log.info('Starting tensorboard process')
                tensorboard_process = Popen(
                    ['tensorboard', '--logdir={}'.format(log_dir)])
                terminate_at_exit(tensorboard_process)

        # Setup optimizer, loss, and LR scheduler.
        loss_fn = torch.nn.CrossEntropyLoss()
        lr = self.train_opts.lr
        opt = optim.Adam(model.parameters(), lr=lr)
        step_scheduler, epoch_scheduler = None, None
        num_epochs = self.train_opts.num_epochs

        if self.train_opts.one_cycle and num_epochs &gt; 1:
            steps_per_epoch = len(databunch.train_ds) // batch_size
            total_steps = num_epochs * steps_per_epoch
            step_size_up = (num_epochs // 2) * steps_per_epoch
            step_size_down = total_steps - step_size_up
            step_scheduler = CyclicLR(
                opt,
                base_lr=lr / 10,
                max_lr=lr,
                step_size_up=step_size_up,
                step_size_down=step_size_down,
                cycle_momentum=False)
            for _ in range(start_epoch * steps_per_epoch):
                step_scheduler.step()

        # Training loop.
        for epoch in range(start_epoch, num_epochs):
            # Train one epoch.
            log.info('-----------------------------------------------------')
            log.info('epoch: {}'.format(epoch))
            start = time.time()
            train_loss = train_epoch(model, self.device, databunch.train_dl,
                                     opt, loss_fn, step_scheduler)
            if epoch_scheduler:
                epoch_scheduler.step()
            log.info('train loss: {}'.format(train_loss))

            # Validate one epoch.
            metrics = validate_epoch(model, self.device, databunch.valid_dl,
                                     num_labels)
            log.info('validation metrics: {}'.format(metrics))

            # Print elapsed time for epoch.
            end = time.time()
            epoch_time = datetime.timedelta(seconds=end - start)
            log.info('epoch elapsed time: {}'.format(epoch_time))

            # Save model and state.
            torch.save(model.state_dict(), model_path)
            train_state = {'epoch': epoch}
            json_to_file(train_state, train_state_path)

            # Append to log CSV file.
            with open(log_path, 'a') as log_file:
                log_writer = csv.writer(log_file)
                row = [epoch, epoch_time, train_loss]
                row += [metrics[k] for k in metric_names]
                log_writer.writerow(row)

            # Write to Tensorboard log.
            if self.train_opts.log_tensorboard:
                for key, val in metrics.items():
                    tb_writer.add_scalar(key, val, epoch)
                tb_writer.add_scalar('train_loss', train_loss, epoch)
                for name, param in model.named_parameters():
                    tb_writer.add_histogram(name, param, epoch)
                tb_writer.flush()

            if (train_uri.startswith('s3://')
                    and (((epoch + 1) % self.train_opts.sync_interval) == 0)):
                sync_to_dir(train_dir, train_uri)

        # Close Tensorboard.
        if self.train_opts.log_tensorboard:
            tb_writer.close()
            if self.train_opts.run_tensorboard:
                tensorboard_process.terminate()

        # Since model is exported every epoch, we need some other way to
        # show that training is finished.
        str_to_file('done!', self.backend_opts.train_done_uri)

        # Sync output to cloud.
        sync_to_dir(train_dir, self.backend_opts.train_uri)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag235')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/pytorch_chip_classification.py: 177-344
</a>
<div class="mid" id="frag235" style="display:none"><pre>
    def train(self, tmp_dir):
        """Train a model.

        This downloads any previous output saved to the train_uri,
        starts training (or resumes from a checkpoint), periodically
        syncs contents of train_dir to train_uri and after training finishes.

        Args:
            tmp_dir: (str) path to temp directory
        """
        self.log_options()

        # Sync output of previous training run from cloud.
        train_uri = self.backend_opts.train_uri
        train_dir = get_local_path(train_uri, tmp_dir)
        make_dir(train_dir)
        sync_from_dir(train_uri, train_dir)

        # Get zip file for each group, and unzip them into chip_dir.
        chip_dir = join(tmp_dir, 'chips')
        make_dir(chip_dir)
        for zip_uri in list_paths(self.backend_opts.chip_uri, 'zip'):
            zip_path = download_if_needed(zip_uri, tmp_dir)
            with zipfile.ZipFile(zip_path, 'r') as zipf:
                zipf.extractall(chip_dir)

        # Setup data loader.
        batch_size = self.train_opts.batch_size
        chip_size = self.task_config.chip_size
        augmentors = self.train_opts.augmentors
        databunch = build_databunch(
            chip_dir, chip_size, batch_size,
            self.task_config.class_map.get_class_names(),
            self.train_opts.rare_classes, self.train_opts.desired_prob,
            augmentors)
        log.info(databunch)
        num_labels = len(databunch.label_names)
        if self.train_opts.debug:
            make_debug_chips(databunch, self.task_config.class_map, tmp_dir,
                             train_uri)

        # Setup model
        num_labels = len(databunch.label_names)
        model = get_model(
            self.train_opts.model_arch, num_labels, pretrained=True)
        model = model.to(self.device)
        model_path = join(train_dir, 'model')

        # Load weights from a pretrained model.
        pretrained_uri = self.backend_opts.pretrained_uri
        if pretrained_uri:
            log.info('Loading weights from pretrained_uri: {}'.format(
                pretrained_uri))
            pretrained_path = download_if_needed(pretrained_uri, tmp_dir)
            model.load_state_dict(
                torch.load(pretrained_path, map_location=self.device))

        # Possibly resume training from checkpoint.
        start_epoch = 0
        train_state_path = join(train_dir, 'train_state.json')
        if isfile(train_state_path):
            log.info('Resuming from checkpoint: {}\n'.format(model_path))
            train_state = file_to_json(train_state_path)
            start_epoch = train_state['epoch'] + 1
            model.load_state_dict(
                torch.load(model_path, map_location=self.device))

        # Write header of log CSV file.
        metric_names = ['precision', 'recall', 'f1']
        log_path = join(train_dir, 'log.csv')
        if not isfile(log_path):
            with open(log_path, 'w') as log_file:
                log_writer = csv.writer(log_file)
                row = ['epoch', 'time', 'train_loss'] + metric_names
                log_writer.writerow(row)

        # Setup Tensorboard logging.
        if self.train_opts.log_tensorboard:
            log_dir = join(train_dir, 'tb-logs')
            make_dir(log_dir)
            tb_writer = SummaryWriter(log_dir=log_dir)
            if self.train_opts.run_tensorboard:
                log.info('Starting tensorboard process')
                tensorboard_process = Popen(
                    ['tensorboard', '--logdir={}'.format(log_dir)])
                terminate_at_exit(tensorboard_process)

        # Setup optimizer, loss, and LR scheduler.
        loss_fn = torch.nn.CrossEntropyLoss()
        lr = self.train_opts.lr
        opt = optim.Adam(model.parameters(), lr=lr)
        step_scheduler, epoch_scheduler = None, None
        num_epochs = self.train_opts.num_epochs

        if self.train_opts.one_cycle and num_epochs &gt; 1:
            steps_per_epoch = len(databunch.train_ds) // batch_size
            total_steps = num_epochs * steps_per_epoch
            step_size_up = (num_epochs // 2) * steps_per_epoch
            step_size_down = total_steps - step_size_up
            step_scheduler = CyclicLR(
                opt,
                base_lr=lr / 10,
                max_lr=lr,
                step_size_up=step_size_up,
                step_size_down=step_size_down,
                cycle_momentum=False)
            for _ in range(start_epoch * steps_per_epoch):
                step_scheduler.step()

        # Training loop.
        for epoch in range(start_epoch, num_epochs):
            # Train one epoch.
            log.info('-----------------------------------------------------')
            log.info('epoch: {}'.format(epoch))
            start = time.time()
            train_loss = train_epoch(model, self.device, databunch.train_dl,
                                     opt, loss_fn, step_scheduler)
            if epoch_scheduler:
                epoch_scheduler.step()
            log.info('train loss: {}'.format(train_loss))

            # Validate one epoch.
            metrics = validate_epoch(model, self.device, databunch.valid_dl,
                                     num_labels)
            log.info('validation metrics: {}'.format(metrics))

            # Print elapsed time for epoch.
            end = time.time()
            epoch_time = datetime.timedelta(seconds=end - start)
            log.info('epoch elapsed time: {}'.format(epoch_time))

            # Save model and state.
            torch.save(model.state_dict(), model_path)
            train_state = {'epoch': epoch}
            json_to_file(train_state, train_state_path)

            # Append to log CSV file.
            with open(log_path, 'a') as log_file:
                log_writer = csv.writer(log_file)
                row = [epoch, epoch_time, train_loss]
                row += [metrics[k] for k in metric_names]
                log_writer.writerow(row)

            # Write to Tensorboard log.
            if self.train_opts.log_tensorboard:
                for key, val in metrics.items():
                    tb_writer.add_scalar(key, val, epoch)
                tb_writer.add_scalar('train_loss', train_loss, epoch)
                for name, param in model.named_parameters():
                    tb_writer.add_histogram(name, param, epoch)
                tb_writer.flush()

            if (train_uri.startswith('s3://')
                    and (((epoch + 1) % self.train_opts.sync_interval) == 0)):
                sync_to_dir(train_dir, train_uri)

        # Close Tensorboard.
        if self.train_opts.log_tensorboard:
            tb_writer.close()
            if self.train_opts.run_tensorboard:
                tensorboard_process.terminate()

        # Mark that the command has completed.
        str_to_file('done!', self.backend_opts.train_done_uri)

        # Sync output to cloud.
        sync_to_dir(train_dir, self.backend_opts.train_uri)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag211')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/pytorch_object_detection.py: 201-363
</a>
<div class="mid" id="frag211" style="display:none"><pre>
    def train(self, tmp_dir):
        """Train a model.

        This downloads any previous output saved to the train_uri,
        starts training (or resumes from a checkpoint), periodically
        syncs contents of train_dir to train_uri and after training finishes.

        Args:
            tmp_dir: (str) path to temp directory
        """
        self.log_options()

        # Sync output of previous training run from cloud.
        train_uri = self.backend_opts.train_uri
        train_dir = get_local_path(train_uri, tmp_dir)
        make_dir(train_dir)
        sync_from_dir(train_uri, train_dir)

        # Get zip file for each group, and unzip them into chip_dir.
        chip_dir = join(tmp_dir, 'chips')
        make_dir(chip_dir)
        for zip_uri in list_paths(self.backend_opts.chip_uri, 'zip'):
            zip_path = download_if_needed(zip_uri, tmp_dir)
            with zipfile.ZipFile(zip_path, 'r') as zipf:
                zipf.extractall(chip_dir)

        # Setup dataset and dataloaders.
        batch_size = self.train_opts.batch_size
        chip_size = self.task_config.chip_size
        databunch = build_databunch(chip_dir, chip_size, batch_size)
        log.info(databunch)
        num_labels = len(databunch.label_names)
        if self.train_opts.debug:
            make_debug_chips(databunch, self.task_config.class_map, tmp_dir,
                             train_uri)

        # Setup model
        num_labels = len(databunch.label_names)
        model = MyFasterRCNN(
            self.train_opts.model_arch, num_labels, chip_size, pretrained=True)
        model = model.to(self.device)
        model_path = join(train_dir, 'model')

        # Load weights from a pretrained model.
        pretrained_uri = self.backend_opts.pretrained_uri
        if pretrained_uri:
            log.info('Loading weights from pretrained_uri: {}'.format(
                pretrained_uri))
            pretrained_path = download_if_needed(pretrained_uri, tmp_dir)
            model.load_state_dict(
                torch.load(pretrained_path, map_location=self.device))

        # Possibly resume training from checkpoint.
        start_epoch = 0
        train_state_path = join(train_dir, 'train_state.json')
        if isfile(train_state_path):
            log.info('Resuming from checkpoint: {}\n'.format(model_path))
            train_state = file_to_json(train_state_path)
            start_epoch = train_state['epoch'] + 1
            model.load_state_dict(
                torch.load(model_path, map_location=self.device))

        # Write header of log CSV file.
        log_path = join(train_dir, 'log.csv')
        if not isfile(log_path):
            with open(log_path, 'w') as log_file:
                log_writer = csv.writer(log_file)
                row = ['epoch'] + ['map50', 'time'] + model.subloss_names
                log_writer.writerow(row)

        # Setup Tensorboard logging.
        if self.train_opts.log_tensorboard:
            log_dir = join(train_dir, 'tb-logs')
            make_dir(log_dir)
            tb_writer = SummaryWriter(log_dir=log_dir)
            if self.train_opts.run_tensorboard:
                log.info('Starting tensorboard process')
                tensorboard_process = Popen(
                    ['tensorboard', '--logdir={}'.format(log_dir)])
                terminate_at_exit(tensorboard_process)

        # Setup optimizer.
        lr = self.train_opts.lr
        opt = optim.Adam(model.parameters(), lr=lr)
        step_scheduler, epoch_scheduler = None, None
        num_epochs = self.train_opts.num_epochs

        if self.train_opts.one_cycle and num_epochs &gt; 1:
            steps_per_epoch = len(databunch.train_ds) // batch_size
            total_steps = num_epochs * steps_per_epoch
            step_size_up = (num_epochs // 2) * steps_per_epoch
            step_size_down = total_steps - step_size_up
            step_scheduler = CyclicLR(
                opt,
                base_lr=lr / 10,
                max_lr=lr,
                step_size_up=step_size_up,
                step_size_down=step_size_down,
                cycle_momentum=False)
            for _ in range(start_epoch * steps_per_epoch):
                step_scheduler.step()

        # Training loop.
        for epoch in range(start_epoch, num_epochs):
            # Train one epoch.
            log.info('-----------------------------------------------------')
            log.info('epoch: {}'.format(epoch))
            start = time.time()
            train_loss = train_epoch(model, self.device, databunch.train_dl,
                                     opt, step_scheduler, epoch_scheduler)
            if epoch_scheduler:
                epoch_scheduler.step()
            log.info('train loss: {}'.format(train_loss))

            # Validate one epoch.
            metrics = validate_epoch(model, self.device, databunch.valid_dl,
                                     num_labels)
            log.info('validation metrics: {}'.format(metrics))

            # Print elapsed time for epoch.
            end = time.time()
            epoch_time = datetime.timedelta(seconds=end - start)
            log.info('epoch elapsed time: {}'.format(epoch_time))

            # Save model and state.
            torch.save(model.state_dict(), model_path)
            train_state = {'epoch': epoch}
            json_to_file(train_state, train_state_path)

            # Append to log CSV file.
            with open(log_path, 'a') as log_file:
                log_writer = csv.writer(log_file)
                row = [epoch]
                row += [metrics['map50'], epoch_time]
                row += [train_loss[k] for k in model.subloss_names]
                log_writer.writerow(row)

            # Write to Tensorboard log.
            if self.train_opts.log_tensorboard:
                for key, val in metrics.items():
                    tb_writer.add_scalar(key, val, epoch)
                for key, val in train_loss.items():
                    tb_writer.add_scalar(key, val, epoch)
                for name, param in model.named_parameters():
                    tb_writer.add_histogram(name, param, epoch)
                tb_writer.flush()

            if (train_uri.startswith('s3://')
                    and (((epoch + 1) % self.train_opts.sync_interval) == 0)):
                sync_to_dir(train_dir, train_uri)

        # Close Tensorboard.
        if self.train_opts.log_tensorboard:
            tb_writer.close()
            if self.train_opts.run_tensorboard:
                tensorboard_process.terminate()

        # Mark that the command has completed.
        str_to_file('done!', self.backend_opts.train_done_uri)

        # Sync output to cloud.
        sync_to_dir(train_dir, self.backend_opts.train_uri)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 19:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 90%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag160')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/pytorch_semantic_segmentation.py: 353-366
</a>
<div class="mid" id="frag160" style="display:none"><pre>
    def load_model(self, tmp_dir):
        """Load the model in preparation for one or more prediction calls."""
        if self.model is None:
            model_uri = self.backend_opts.model_uri
            model_path = download_if_needed(model_uri, tmp_dir)

            num_classes = len(self.class_map)
            model = get_model(
                self.train_opts.model_arch, num_classes, pretrained=False)
            model = model.to(self.device)
            model.load_state_dict(
                torch.load(model_path, map_location=self.device))
            self.model = model

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag236')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/pytorch_chip_classification.py: 345-358
</a>
<div class="mid" id="frag236" style="display:none"><pre>
    def load_model(self, tmp_dir):
        """Load the model in preparation for one or more prediction calls."""
        if self.model is None:
            model_uri = self.backend_opts.model_uri
            model_path = download_if_needed(model_uri, tmp_dir)

            num_classes = len(self.task_config.class_map)
            model = get_model(
                self.train_opts.model_arch, num_classes, pretrained=False)
            model = model.to(self.device)
            model.load_state_dict(
                torch.load(model_path, map_location=self.device))
            self.model = model

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 20:</b> &nbsp; 7 fragments, nominal size 11 lines, similarity 71%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag238')" href="javascript:;">
raster-vision-0.11.0/rastervision/backend/simple_backend_config.py: 16-28
</a>
<div class="mid" id="frag238" style="display:none"><pre>
    def __init__(self,
                 chip_uri=None,
                 train_uri=None,
                 train_done_uri=None,
                 model_uri=None,
                 pretrained_uri=None):
        self.chip_uri = chip_uri
        self.train_uri = train_uri
        self.train_done_uri = train_done_uri
        self.model_uri = model_uri
        self.pretrained_uri = pretrained_uri


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1174')" href="javascript:;">
raster-vision-0.11.0/rastervision/task/task_config.py: 11-22
</a>
<div class="mid" id="frag1174" style="display:none"><pre>
    def __init__(self,
                 task_type,
                 predict_batch_size=10,
                 predict_package_uri=None,
                 debug=True,
                 predict_debug_uri=None):
        self.task_type = task_type
        self.predict_batch_size = predict_batch_size
        self.predict_package_uri = predict_package_uri
        self.debug = debug
        self.predict_debug_uri = predict_debug_uri

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag458')" href="javascript:;">
raster-vision-0.11.0/rastervision/command/aux_command.py: 5-43
</a>
<div class="mid" id="frag458" style="display:none"><pre>
    def __init__(self,
                 split_on=None,
                 inputs=lambda config: None,
                 outputs=lambda config: None,
                 include_by_default=False,
                 required_fields=None):
        """Instantiate an AuxCommandOptions object.

        Args:
            split_on (str): The property of the configuration to use when splitting.
            The configuration at this property must be a list.

            inputs: A function that, given the configuration, returns a list of
            URIs that are inputs into the command. Along with outputs, this allows
            Raster Vision to correctly determine if there are any missing inputs, or
            if the command has already been run. It will also allow the command to
            be run in the right sequence if run with other commands that will produce
            this command's inputs as their outputs.

            outputs: A function that, given the configuration, returns a list of
            URIs that are outputs of the command. See the details on inputs.

            include_by_default: Set this to True if you want this command to run
            by default, meaning it will run every time no specific commands are issued
            on the command line (e.g. how a standard command would run).

            required_fields: Set this to properties of the configuration that are
            required. If the user of the command does not set values into those
            configuration properties, an error will be thrown at configuration building
            time.

        """
        self.split_on = split_on
        self.inputs = inputs
        self.outputs = outputs
        self.include_by_default = include_by_default
        self.required_fields = required_fields


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag725')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/scene_config.py: 15-26
</a>
<div class="mid" id="frag725" style="display:none"><pre>
class SceneConfig(BundledConfigMixin, Config):
    def __init__(self,
                 id,
                 raster_source,
                 label_source=None,
                 label_store=None,
                 aoi_uris=None):
        self.id = id
        self.raster_source = raster_source
        self.label_source = label_source
        self.label_store = label_store
        self.aoi_uris = aoi_uris
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag623')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/scene.py: 7-30
</a>
<div class="mid" id="frag623" style="display:none"><pre>
    def __init__(self,
                 id,
                 raster_source,
                 ground_truth_label_source=None,
                 prediction_label_store=None,
                 aoi_polygons=None):
        """Construct a new Scene.

        Args:
            id: ID for this scene
            raster_source: RasterSource for this scene
            ground_truth_label_store: optional LabelSource
            prediction_label_store: optional LabelStore
            aoi: Optional list of AOI polygons
        """
        self.id = id
        self.raster_source = raster_source
        self.ground_truth_label_source = ground_truth_label_source
        self.prediction_label_store = prediction_label_store
        if aoi_polygons is None:
            self.aoi_polygons = []
        else:
            self.aoi_polygons = aoi_polygons

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag767')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/vector_source/vector_source.py: 111-138
</a>
<div class="mid" id="frag767" style="display:none"><pre>
    def __init__(self,
                 crs_transformer,
                 line_bufs=None,
                 point_bufs=None,
                 class_inf_opts=None):
        """Constructor.

        Args:
            crs_transformer: (CRSTransformer)
            line_bufs: (dict or None) If none, uses default buffer value of 1. Otherwise,
                a map from class_id to number of pixels to buffer by. If the buffer value
                is None, then no buffering will be performed and the LineString or Point
                won't get converted to a Polygon. Not converting to Polygon is
                incompatible with the currently available LabelSources, but may be useful
                in the future.
            point_bufs: (dict or None) same as above, but used for buffering Points into
                Polygons.
            class_inf_opts: (ClassInferenceOptions)
        """
        self.crs_transformer = crs_transformer
        self.line_bufs = line_bufs
        self.point_bufs = point_bufs
        if class_inf_opts is None:
            class_inf_opts = ClassInferenceOptions()
        self.class_inference = ClassInference(class_inf_opts)

        self.geojson = None

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1680')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/scene.py: 7-30
</a>
<div class="mid" id="frag1680" style="display:none"><pre>
    def __init__(self,
                 id,
                 raster_source,
                 ground_truth_label_source=None,
                 prediction_label_store=None,
                 aoi_polygons=None):
        """Construct a new Scene.

        Args:
            id: ID for this scene
            raster_source: RasterSource for this scene
            ground_truth_label_store: optional LabelSource
            prediction_label_store: optional LabelStore
            aoi: Optional list of AOI polygons
        """
        self.id = id
        self.raster_source = raster_source
        self.ground_truth_label_source = ground_truth_label_source
        self.prediction_label_store = prediction_label_store
        if aoi_polygons is None:
            self.aoi_polygons = []
        else:
            self.aoi_polygons = aoi_polygons

</pre></div>
</td>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 21:</b> &nbsp; 2 fragments, nominal size 17 lines, similarity 88%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag292')" href="javascript:;">
raster-vision-0.11.0/rastervision/filesystem/local_filesystem.py: 72-93
</a>
<div class="mid" id="frag292" style="display:none"><pre>
    def sync_from_dir(src_dir_uri: str,
                      dest_dir_uri: str,
                      delete: bool = False) -&gt; None:
        if src_dir_uri == dest_dir_uri:
            return

        if delete:
            shutil.rmtree(dest_dir_uri)

        # https://stackoverflow.com/a/15824216/841563
        def recursive_overwrite(src, dest):
            if os.path.isdir(src):
                if not os.path.isdir(dest):
                    os.makedirs(dest)
                    for entry in os.scandir(src):
                        recursive_overwrite(entry.path,
                                            os.path.join(dest, entry.name))
            else:
                shutil.copyfile(src, dest)

        recursive_overwrite(src_dir_uri, dest_dir_uri)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1495')" href="javascript:;">
raster-vision-0.11.0/rastervision2/pipeline/file_system/local_file_system.py: 74-94
</a>
<div class="mid" id="frag1495" style="display:none"><pre>
    def sync_from_dir(src_dir_uri: str, dst_dir: str,
                      delete: bool = False) -&gt; None:
        if src_dir_uri == dst_dir:
            return

        if delete:
            shutil.rmtree(dst_dir)

        # https://stackoverflow.com/a/15824216/841563
        def recursive_overwrite(src, dest):
            if os.path.isdir(src):
                if not os.path.isdir(dest):
                    os.makedirs(dest)
                    for entry in os.scandir(src):
                        recursive_overwrite(entry.path,
                                            os.path.join(dest, entry.name))
            else:
                shutil.copyfile(src, dest)

        recursive_overwrite(src_dir_uri, dst_dir)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 22:</b> &nbsp; 4 fragments, nominal size 10 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag322')" href="javascript:;">
raster-vision-0.11.0/rastervision/command/analyze_command_config.py: 26-38
</a>
<div class="mid" id="frag322" style="display:none"><pre>

    def to_proto(self):
        msg = super().to_proto()
        task = self.task.to_proto()
        scenes = list(map(lambda s: s.to_proto(), self.scenes))
        analyzers = list(map(lambda a: a.to_proto(), self.analyzers))

        msg.MergeFrom(
            CommandConfigMsg(
                analyze_config=CommandConfigMsg.AnalyzeConfig(
                    task=task, scenes=scenes, analyzers=analyzers)))

        return msg
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag424')" href="javascript:;">
raster-vision-0.11.0/rastervision/command/predict_command_config.py: 37-50
</a>
<div class="mid" id="frag424" style="display:none"><pre>

    def to_proto(self):
        msg = super().to_proto()

        task = self.task.to_proto()
        backend = self.backend.to_proto()
        scenes = list(map(lambda s: s.to_proto(), self.scenes))

        msg.MergeFrom(
            CommandConfigMsg(
                predict_config=CommandConfigMsg.PredictConfig(
                    task=task, backend=backend, scenes=scenes)))

        return msg
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag410')" href="javascript:;">
raster-vision-0.11.0/rastervision/command/eval_command_config.py: 33-45
</a>
<div class="mid" id="frag410" style="display:none"><pre>

    def to_proto(self):
        msg = super().to_proto()
        task = self.task.to_proto()
        scenes = list(map(lambda s: s.to_proto(), self.scenes))
        evaluators = list(map(lambda e: e.to_proto(), self.evaluators))

        msg.MergeFrom(
            CommandConfigMsg(
                eval_config=CommandConfigMsg.EvalConfig(
                    task=task, scenes=scenes, evaluators=evaluators)))

        return msg
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag440')" href="javascript:;">
raster-vision-0.11.0/rastervision/command/bundle_command_config.py: 32-46
</a>
<div class="mid" id="frag440" style="display:none"><pre>

    def to_proto(self):
        msg = super().to_proto()

        task = self.task.to_proto()
        backend = self.backend.to_proto()
        scene = self.scene.to_proto()
        analyzers = list(map(lambda a: a.to_proto(), self.analyzers))

        b = CommandConfigMsg.BundleConfig(
            task=task, backend=backend, scene=scene, analyzers=analyzers)

        msg.MergeFrom(CommandConfigMsg(bundle_config=b))

        return msg
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 23:</b> &nbsp; 5 fragments, nominal size 11 lines, similarity 71%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag324')" href="javascript:;">
raster-vision-0.11.0/rastervision/command/analyze_command_config.py: 50-60
</a>
<div class="mid" id="frag324" style="display:none"><pre>
class AnalyzeCommandConfigBuilder(CommandConfigBuilder):
    def __init__(self, command_type, prev=None):
        super().__init__(command_type, prev)
        if prev is None:
            self.task = None
            self.scenes = None
            self.analyzers = None
        else:
            self.task = prev.task
            self.scenes = prev.scenes
            self.analyzers = prev.analyzers
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag442')" href="javascript:;">
raster-vision-0.11.0/rastervision/command/bundle_command_config.py: 58-70
</a>
<div class="mid" id="frag442" style="display:none"><pre>
class BundleCommandConfigBuilder(CommandConfigBuilder):
    def __init__(self, command_type, prev=None):
        super().__init__(command_type, prev)
        if prev is None:
            self.task = None
            self.backend = None
            self.scene = None
            self.analyzers = None
        else:
            self.task = prev.task
            self.backend = prev.backend
            self.scene = prev.scene
            self.analyzers = prev.analyzers
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag412')" href="javascript:;">
raster-vision-0.11.0/rastervision/command/eval_command_config.py: 57-67
</a>
<div class="mid" id="frag412" style="display:none"><pre>
class EvalCommandConfigBuilder(CommandConfigBuilder):
    def __init__(self, command_type, prev=None):
        super().__init__(command_type, prev)
        if prev is None:
            self.task = None
            self.scenes = None
            self.evaluators = None
        else:
            self.task = prev.task
            self.scenes = prev.scenes
            self.evaluators = prev.evaluators
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag427')" href="javascript:;">
raster-vision-0.11.0/rastervision/command/predict_command_config.py: 68-78
</a>
<div class="mid" id="frag427" style="display:none"><pre>
        return commands


class PredictCommandConfigBuilder(CommandConfigBuilder):
    def __init__(self, command_type, prev=None):
        super().__init__(command_type, prev)
        if prev is None:
            self.task = None
            self.backend = None
            self.scenes = []
        else:
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag397')" href="javascript:;">
raster-vision-0.11.0/rastervision/command/chip_command_config.py: 85-99
</a>
<div class="mid" id="frag397" style="display:none"><pre>
            commands.append(c)
        return commands


class ChipCommandConfigBuilder(CommandConfigBuilder):
    def __init__(self, command_type, prev=None):
        super().__init__(command_type, prev)
        if prev is None:
            self.task = None
            self.backend = None
            self.augmentors = []
            self.train_scenes = []
            self.val_scenes = []
        else:
            self.task = prev.task
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 24:</b> &nbsp; 5 fragments, nominal size 10 lines, similarity 71%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag327')" href="javascript:;">
raster-vision-0.11.0/rastervision/command/analyze_command_config.py: 77-91
</a>
<div class="mid" id="frag327" style="display:none"><pre>

    def from_proto(self, msg):
        b = super().from_proto(msg)

        conf = msg.analyze_config

        task = rv.TaskConfig.from_proto(conf.task)
        scenes = list(map(rv.SceneConfig.from_proto, conf.scenes))
        analyzers = list(map(rv.AnalyzerConfig.from_proto, conf.analyzers))

        b = b.with_task(task)
        b = b.with_scenes(scenes)
        b = b.with_analyzers(analyzers)

        return b
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag445')" href="javascript:;">
raster-vision-0.11.0/rastervision/command/bundle_command_config.py: 99-115
</a>
<div class="mid" id="frag445" style="display:none"><pre>

    def from_proto(self, msg):
        b = super().from_proto(msg)

        conf = msg.bundle_config

        task = rv.TaskConfig.from_proto(conf.task)
        backend = rv.BackendConfig.from_proto(conf.backend)
        scene = rv.SceneConfig.from_proto(conf.scene)
        analyzers = list(map(rv.AnalyzerConfig.from_proto, conf.analyzers))

        b = b.with_task(task)
        b = b.with_backend(backend)
        b = b.with_scene(scene)
        b = b.with_analyzers(analyzers)

        return b
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag400')" href="javascript:;">
raster-vision-0.11.0/rastervision/command/chip_command_config.py: 129-147
</a>
<div class="mid" id="frag400" style="display:none"><pre>
        self.validate()
        return ChipCommandConfig(self.root_uri, self.split_id, self.task,
                                 self.backend, self.augmentors,
                                 self.train_scenes, self.val_scenes)

    def from_proto(self, msg):
        b = super().from_proto(msg)

        conf = msg.chip_config

        task = rv.TaskConfig.from_proto(conf.task)
        backend = rv.BackendConfig.from_proto(conf.backend)
        augmentors = list(map(rv.AugmentorConfig.from_proto, conf.augmentors))
        train_scenes = list(map(rv.SceneConfig.from_proto, conf.train_scenes))
        val_scenes = list(map(rv.SceneConfig.from_proto, conf.val_scenes))

        b = b.with_task(task)
        b = b.with_backend(backend)
        b = b.with_augmentors(augmentors)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag430')" href="javascript:;">
raster-vision-0.11.0/rastervision/command/predict_command_config.py: 97-111
</a>
<div class="mid" id="frag430" style="display:none"><pre>
        self.validate()
        return PredictCommandConfig(self.root_uri, self.split_id, self.task,
                                    self.backend, self.scenes)

    def from_proto(self, msg):
        b = super().from_proto(msg)

        conf = msg.predict_config

        task = rv.TaskConfig.from_proto(conf.task)
        backend = rv.BackendConfig.from_proto(conf.backend)
        scenes = list(map(rv.SceneConfig.from_proto, conf.scenes))

        b = b.with_task(task)
        b = b.with_backend(backend)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag415')" href="javascript:;">
raster-vision-0.11.0/rastervision/command/eval_command_config.py: 99-113
</a>
<div class="mid" id="frag415" style="display:none"><pre>

    def from_proto(self, msg):
        b = super().from_proto(msg)

        conf = msg.eval_config

        task = rv.TaskConfig.from_proto(conf.task)
        scenes = list(map(rv.SceneConfig.from_proto, conf.scenes))
        evaluators = list(map(rv.EvaluatorConfig.from_proto, conf.evaluators))

        b = b.with_task(task)
        b = b.with_scenes(scenes)
        b = b.with_evaluators(evaluators)

        return b
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 25:</b> &nbsp; 3 fragments, nominal size 11 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag351')" href="javascript:;">
raster-vision-0.11.0/rastervision/command/predict_command.py: 10-24
</a>
<div class="mid" id="frag351" style="display:none"><pre>
    def run(self, tmp_dir=None):
        if not tmp_dir:
            tmp_dir = self.get_tmp_dir()
        msg = 'Making predictions...'

        cc = self.command_config

        backend = cc.backend.create_backend(cc.task)
        task = cc.task.create_task(backend)

        scenes = list(
            map(lambda s: s.create_scene(cc.task, tmp_dir), cc.scenes))

        click.echo(click.style(msg, fg='green'))
        task.predict(scenes, tmp_dir)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag461')" href="javascript:;">
raster-vision-0.11.0/rastervision/command/eval_command.py: 10-24
</a>
<div class="mid" id="frag461" style="display:none"><pre>
    def run(self, tmp_dir=None):
        if not tmp_dir:
            tmp_dir = self.get_tmp_dir()

        cc = self.command_config

        scenes = list(
            map(lambda s: s.create_scene(cc.task, tmp_dir), cc.scenes))
        evaluators = list(map(lambda a: a.create_evaluator(), cc.evaluators))

        for evaluator in evaluators:
            msg = 'Running evaluator: {}...'.format(type(evaluator).__name__)
            click.echo(click.style(msg, fg='green'))

            evaluator.process(scenes, tmp_dir)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag437')" href="javascript:;">
raster-vision-0.11.0/rastervision/command/analyze_command.py: 10-24
</a>
<div class="mid" id="frag437" style="display:none"><pre>
    def run(self, tmp_dir=None):
        if not tmp_dir:
            tmp_dir = self.get_tmp_dir()

        cc = self.command_config

        analyzers = list(map(lambda a: a.create_analyzer(), cc.analyzers))
        scenes = list(
            map(lambda s: s.create_scene(cc.task, tmp_dir), cc.scenes))

        for analyzer in analyzers:
            msg = 'Running analyzer: {}...'.format(type(analyzer).__name__)
            click.echo(click.style(msg, fg='green'))

            analyzer.process(scenes, tmp_dir)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 26:</b> &nbsp; 2 fragments, nominal size 37 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag372')" href="javascript:;">
raster-vision-0.11.0/rastervision/command/aux/cogify_command.py: 15-73
</a>
<div class="mid" id="frag372" style="display:none"><pre>
def gdal_cog_commands(input_path,
                      tmp_dir,
                      block_size=DEFAULT_BLOCK_SIZE,
                      resample_method=DEFAULT_RESAMPLE_METHOD,
                      compression=DEFAULT_COMPRESSION,
                      overviews=None):
    """
    GDAL commands to create a COG from an input file.
    Returns a tuple (commands, output_path)
    """

    if not overviews:
        overviews = DEFAULT_OVERVIEWS

    def get_output_path(command):
        fname = os.path.splitext(os.path.basename(input_path))[0]
        return os.path.join(tmp_dir, '{}-{}.tif'.format(fname, command))

    compression = compression.lower()

    def add_compression(cmd, overview=False):
        if compression != 'none':
            if not overview:
                return cmd[:1] + ['-co', 'compress={}'.format(compression)
                                  ] + cmd[1:]
            else:
                return cmd[:1] + [
                    '--config', 'COMPRESS_OVERVIEW', compression
                ] + cmd[1:]
        else:
            return cmd

    # Step 1: Translate to a GeoTiff.
    translate_path = get_output_path('translate')
    translate = add_compression([
        'gdal_translate', '-of', 'GTiff', '-co', 'tiled=YES', '-co',
        'BIGTIFF=IF_SAFER', input_path, translate_path
    ])

    # Step 2: Add overviews
    add_overviews = add_compression(
        ['gdaladdo', '-r', resample_method, translate_path] + list(
            map(lambda x: str(x), overviews)),
        overview=True)

    # Step 3: Translate to COG
    output_path = get_output_path('cog')

    create_cog = add_compression([
        'gdal_translate', '-co', 'TILED=YES', '-co', 'COPY_SRC_OVERVIEWS=YES',
        '-co', 'BLOCKXSIZE={}'.format(block_size), '-co',
        'BLOCKYSIZE={}'.format(block_size), '-co', 'BIGTIFF=IF_SAFER',
        '--config', 'GDAL_TIFF_OVR_BLOCKSIZE',
        str(block_size), translate_path, output_path
    ])

    return ([translate, add_overviews, create_cog], output_path)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1855')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/utils/cog.py: 15-73
</a>
<div class="mid" id="frag1855" style="display:none"><pre>
def gdal_cog_commands(input_path,
                      tmp_dir,
                      block_size=DEFAULT_BLOCK_SIZE,
                      resample_method=DEFAULT_RESAMPLE_METHOD,
                      compression=DEFAULT_COMPRESSION,
                      overviews=None):
    """
    GDAL commands to create a COG from an input file.
    Returns a tuple (commands, output_path)
    """

    if not overviews:
        overviews = DEFAULT_OVERVIEWS

    def get_output_path(command):
        fname = os.path.splitext(os.path.basename(input_path))[0]
        return os.path.join(tmp_dir, '{}-{}.tif'.format(fname, command))

    compression = compression.lower()

    def add_compression(cmd, overview=False):
        if compression != 'none':
            if not overview:
                return cmd[:1] + ['-co', 'compress={}'.format(compression)
                                  ] + cmd[1:]
            else:
                return cmd[:1] + [
                    '--config', 'COMPRESS_OVERVIEW', compression
                ] + cmd[1:]
        else:
            return cmd

    # Step 1: Translate to a GeoTiff.
    translate_path = get_output_path('translate')
    translate = add_compression([
        'gdal_translate', '-of', 'GTiff', '-co', 'tiled=YES', '-co',
        'BIGTIFF=IF_SAFER', input_path, translate_path
    ])

    # Step 2: Add overviews
    add_overviews = add_compression(
        ['gdaladdo', '-r', resample_method, translate_path] + list(
            map(lambda x: str(x), overviews)),
        overview=True)

    # Step 3: Translate to COG
    output_path = get_output_path('cog')

    create_cog = add_compression([
        'gdal_translate', '-co', 'TILED=YES', '-co', 'COPY_SRC_OVERVIEWS=YES',
        '-co', 'BLOCKXSIZE={}'.format(block_size), '-co',
        'BLOCKYSIZE={}'.format(block_size), '-co', 'BIGTIFF=IF_SAFER',
        '--config', 'GDAL_TIFF_OVR_BLOCKSIZE',
        str(block_size), translate_path, output_path
    ])

    return ([translate, add_overviews, create_cog], output_path)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 27:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag375')" href="javascript:;">
raster-vision-0.11.0/rastervision/command/aux/cogify_command.py: 74-86
</a>
<div class="mid" id="frag375" style="display:none"><pre>
def run_cmd(cmd):
    p = Popen(cmd)
    (out, err) = p.communicate(input)
    if p.returncode != 0:
        s = 'Command failed:\n'
        s += ' '.join(cmd) + '\n\n'
        if out:
            s += out + '\n\n'
        if err:
            s += err
        raise Exception(s)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1858')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/utils/cog.py: 74-86
</a>
<div class="mid" id="frag1858" style="display:none"><pre>
def run_cmd(cmd):
    p = Popen(cmd)
    (out, err) = p.communicate(input)
    if p.returncode != 0:
        s = 'Command failed:\n'
        s += ' '.join(cmd) + '\n\n'
        if out:
            s += out + '\n\n'
        if err:
            s += err
        raise Exception(s)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 28:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag376')" href="javascript:;">
raster-vision-0.11.0/rastervision/command/aux/cogify_command.py: 87-108
</a>
<div class="mid" id="frag376" style="display:none"><pre>
def create_cog(source_uri,
               dest_uri,
               local_dir,
               block_size=DEFAULT_BLOCK_SIZE,
               resample_method=DEFAULT_RESAMPLE_METHOD,
               compression=DEFAULT_COMPRESSION,
               overviews=None):
    local_path = download_or_copy(source_uri, local_dir)

    commands, output_path = gdal_cog_commands(
        local_path,
        local_dir,
        block_size=block_size,
        resample_method=resample_method,
        compression=compression,
        overviews=overviews)
    for command in commands:
        run_cmd(command)

    upload_or_copy(output_path, dest_uri)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1859')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/utils/cog.py: 87-106
</a>
<div class="mid" id="frag1859" style="display:none"><pre>
def create_cog(source_uri,
               dest_uri,
               local_dir,
               block_size=DEFAULT_BLOCK_SIZE,
               resample_method=DEFAULT_RESAMPLE_METHOD,
               compression=DEFAULT_COMPRESSION,
               overviews=None):
    local_path = download_or_copy(source_uri, local_dir)

    commands, output_path = gdal_cog_commands(
        local_path,
        local_dir,
        block_size=block_size,
        resample_method=resample_method,
        compression=compression,
        overviews=overviews)
    for command in commands:
        run_cmd(command)

    upload_or_copy(output_path, dest_uri)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 29:</b> &nbsp; 3 fragments, nominal size 11 lines, similarity 90%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag393')" href="javascript:;">
raster-vision-0.11.0/rastervision/command/chip_command_config.py: 23-36
</a>
<div class="mid" id="frag393" style="display:none"><pre>

    def create_command(self, tmp_dir=None):
        if len(self.train_scenes) == 0 and len(self.val_scenes) == 0:
            return NoOpCommand()

        if not tmp_dir:
            _tmp_dir = RVConfig.get_tmp_dir()
            tmp_dir = _tmp_dir.name
        else:
            _tmp_dir = tmp_dir

        retval = ChipCommand(self)
        retval.set_tmp_dir(_tmp_dir)
        return retval
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag409')" href="javascript:;">
raster-vision-0.11.0/rastervision/command/eval_command_config.py: 19-32
</a>
<div class="mid" id="frag409" style="display:none"><pre>

    def create_command(self, tmp_dir=None):
        if len(self.scenes) == 0 or len(self.evaluators) == 0:
            return NoOpCommand()

        if not tmp_dir:
            _tmp_dir = RVConfig.get_tmp_dir()
            tmp_dir = _tmp_dir.name
        else:
            _tmp_dir = tmp_dir

        retval = EvalCommand(self)
        retval.set_tmp_dir(_tmp_dir)
        return retval
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag423')" href="javascript:;">
raster-vision-0.11.0/rastervision/command/predict_command_config.py: 23-36
</a>
<div class="mid" id="frag423" style="display:none"><pre>

    def create_command(self, tmp_dir=None):
        if len(self.scenes) == 0:
            return NoOpCommand()

        if not tmp_dir:
            _tmp_dir = RVConfig.get_tmp_dir()
            tmp_dir = _tmp_dir.name
        else:
            _tmp_dir = tmp_dir

        retval = PredictCommand(self)
        retval.set_tmp_dir(_tmp_dir)
        return retval
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 30:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag547')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label_source/object_detection_label_source_config.py: 75-93
</a>
<div class="mid" id="frag547" style="display:none"><pre>
    def with_vector_source(self, vector_source):
        """Set the vector_source.

        Args:
            vector_source (str or VectorSource) if a string, assume it is
                a URI and use the default provider to construct a VectorSource.
        """
        if isinstance(vector_source, str):
            return self.with_uri(vector_source)

        b = deepcopy(self)
        if isinstance(vector_source, VectorSourceConfig):
            b.config['vector_source'] = vector_source
        else:
            raise rv.ConfigError(
                'vector_source must be of type str or VectorSource')

        return b

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag644')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/raster_source/rasterized_source_config.py: 142-160
</a>
<div class="mid" id="frag644" style="display:none"><pre>
            vector_source = VectorSourceConfig.from_proto(
                msg.rasterized_source.vector_source)
            rasterizer_options = msg.rasterized_source.rasterizer_options

        return b \
            .with_vector_source(vector_source) \
            .with_rasterizer_options(
                rasterizer_options.background_class_id,
                rasterizer_options.all_touched)

    def with_vector_source(self, vector_source):
        """Set the vector_source.

        Args:
            vector_source (str or VectorSource) if a string, assume it is
                a URI and use the default provider to construct a VectorSource.
        """
        if isinstance(vector_source, str):
            return self.with_uri(vector_source)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 31:</b> &nbsp; 2 fragments, nominal size 22 lines, similarity 86%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag557')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label_source/segmentation_class_transformer.py: 8-50
</a>
<div class="mid" id="frag557" style="display:none"><pre>
    def __init__(self, class_map):
        color_to_class = dict(
            [(item.color, item.id) for item in class_map.get_items()])

        # color int to class
        color_int_to_class = dict(
            zip([color_to_integer(c) for c in color_to_class.keys()],
                color_to_class.values()))

        def color_int_to_class_fn(color: int) -&gt; int:
            # Convert unspecified colors to class 0 which is "don't care"
            return color_int_to_class.get(color, 0x00)

        self.transform_color_int_to_class = \
            np.vectorize(color_int_to_class_fn, otypes=[np.uint8])

        # class to color triple
        class_to_color_triple = dict(
            zip(color_to_class.values(),
                [color_to_triple(c) for c in color_to_class.keys()]))

        def class_to_channel_color(channel: int, class_id: int) -&gt; int:
            """Given a channel (red, green, or blue) and a class, return the
            intensity of that channel.

            Args:
                 channel: An integer with value 0, 1, or 2
                      representing the channel.
                 class_id: The class id represented as an integer.
            Returns:
                 The intensity of the channel for the color associated
                      with the given class.
            """
            default_triple = (0x00, 0x00, 0x00)
            return class_to_color_triple.get(class_id, default_triple)[channel]

        class_to_r = np.vectorize(
            lambda c: class_to_channel_color(0, c), otypes=[np.uint8])
        class_to_g = np.vectorize(
            lambda c: class_to_channel_color(1, c), otypes=[np.uint8])
        class_to_b = np.vectorize(
            lambda c: class_to_channel_color(2, c), otypes=[np.uint8])
        self.transform_class_to_color = [class_to_r, class_to_g, class_to_b]
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1637')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/label_source/segmentation_class_transformer.py: 8-48
</a>
<div class="mid" id="frag1637" style="display:none"><pre>
    def __init__(self, class_config):
        color_to_class = class_config.get_color_to_class_id()
        color_int_to_class = dict(
            zip([color_to_integer(c) for c in color_to_class.keys()],
                color_to_class.values()))
        null_class_id = class_config.get_null_class_id()

        def color_int_to_class_fn(color: int) -&gt; int:
            # Convert unspecified colors to null class
            return color_int_to_class.get(color, null_class_id)

        self.transform_color_int_to_class = \
            np.vectorize(color_int_to_class_fn, otypes=[np.uint8])

        # class to color triple
        class_to_color_triple = dict(
            zip(color_to_class.values(),
                [color_to_triple(c) for c in color_to_class.keys()]))

        def class_to_channel_color(channel: int, class_id: int) -&gt; int:
            """Given a channel (red, green, or blue) and a class, return the
            intensity of that channel.

            Args:
                 channel: An integer with value 0, 1, or 2
                      representing the channel.
                 class_id: The class id represented as an integer.
            Returns:
                 The intensity of the channel for the color associated
                      with the given class.
            """
            default_triple = (0x00, 0x00, 0x00)
            return class_to_color_triple.get(class_id, default_triple)[channel]

        class_to_r = np.vectorize(
            lambda c: class_to_channel_color(0, c), otypes=[np.uint8])
        class_to_g = np.vectorize(
            lambda c: class_to_channel_color(1, c), otypes=[np.uint8])
        class_to_b = np.vectorize(
            lambda c: class_to_channel_color(2, c), otypes=[np.uint8])
        self.transform_class_to_color = [class_to_r, class_to_g, class_to_b]
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 32:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 84%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag565')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label_source/semantic_segmentation_label_source.py: 33-59
</a>
<div class="mid" id="frag565" style="display:none"><pre>
    def enough_target_pixels(self, window: Box, target_count_threshold: int,
                             target_classes: List[int]) -&gt; bool:
        """Given a window, answer whether the window contains enough pixels in
        the target classes.

        Args:
             window: The larger window from-which the sub-window will
                  be clipped.
             target_count_threshold:  Minimum number of target pixels.
             target_classes: The classes of interest.  The given
                  window is examined to make sure that it contains a
                  sufficient number of target pixels.
        Returns:
             True (the window does contain interesting pixels) or False.
        """
        raw_labels = self.source.get_raw_chip(window)
        if self.class_transformer is not None:
            labels = self.class_transformer.rgb_to_class(raw_labels)
        else:
            labels = np.squeeze(raw_labels)

        target_count = 0
        for class_id in target_classes:
            target_count = target_count + (labels == class_id).sum()

        return target_count &gt;= target_count_threshold

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1646')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/label_source/semantic_segmentation_label_source.py: 55-85
</a>
<div class="mid" id="frag1646" style="display:none"><pre>
    def enough_target_pixels(self, window: Box, target_count_threshold: int,
                             target_classes: List[int]) -&gt; bool:
        """Given a window, answer whether the window contains enough pixels in
        the target classes.

        Args:
             window: The larger window from-which the sub-window will
                  be clipped.
             target_count_threshold:  Minimum number of target pixels.
             target_classes: The classes of interest.  The given
                  window is examined to make sure that it contains a
                  sufficient number of target pixels.
        Returns:
             True (the window does contain interesting pixels) or False.
        """
        raw_labels = self.raster_source.get_raw_chip(window)

        if self.class_transformer is not None:
            labels = self.class_transformer.rgb_to_class(raw_labels)
        else:
            labels = np.squeeze(raw_labels)

        labels = fill_edge(labels, window, self.raster_source.get_extent(),
                           self.null_class_id)

        target_count = 0
        for class_id in target_classes:
            target_count = target_count + (labels == class_id).sum()

        return target_count &gt;= target_count_threshold

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 33:</b> &nbsp; 2 fragments, nominal size 26 lines, similarity 96%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag571')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label_source/chip_classification_label_source.py: 11-74
</a>
<div class="mid" id="frag571" style="display:none"><pre>
def infer_cell(cell, str_tree, ioa_thresh, use_intersection_over_cell,
               background_class_id, pick_min_class_id):
    """Infer the class_id of a cell given a set of polygons.

    Given a cell and a set of polygons, the problem is to infer the class_id
    that best captures the content of the cell. This is non-trivial since there
    can be multiple polygons of differing classes overlapping with the cell.
    Any polygons that sufficiently overlaps with the cell are in the running for
    setting the class_id. If there are none in the running, the cell is either
    considered null or background. See args for more details.

    Args:
        cell: Box
        str_tree: (STRtree) collection of geoms in scene used for geometric queries.
            The geoms need to have class_id monkey-patched onto them.
        ioa_thresh: (float) the minimum IOA of a polygon and cell for that
            polygon to be a candidate for setting the class_id
        use_intersection_over_cell: (bool) If true, then use the area of the
            cell as the denominator in the IOA. Otherwise, use the area of the
            polygon.
        background_class_id: (None or int) If not None, class_id to use as the
            background class; ie. the one that is used when a window contains
            no boxes. If not set, empty windows have None set as their class_id
            which is considered a null value.
        pick_min_class_id: If true, the class_id for a cell is the minimum
            class_id of the boxes in that cell. Otherwise, pick the class_id of
            the box covering the greatest area.
    """
    cell_geom = cell.to_shapely()
    inter_polys = str_tree.query(cell_geom)

    inter_over_cells = []
    inter_over_polys = []
    class_ids = []

    # Find polygons whose intersection with the cell is big enough.
    for poly in inter_polys:
        inter = poly.intersection(cell_geom)
        inter_over_cell = inter.area / cell_geom.area
        inter_over_poly = inter.area / poly.area

        if use_intersection_over_cell:
            enough_inter = inter_over_cell &gt;= ioa_thresh
        else:
            enough_inter = inter_over_poly &gt;= ioa_thresh

        if enough_inter:
            inter_over_cells.append(inter_over_cell)
            inter_over_polys.append(inter_over_poly)
            class_ids.append(poly.class_id)

    # Infer class id for cell.
    if len(class_ids) == 0:
        class_id = (None if background_class_id == 0 else background_class_id)
    elif pick_min_class_id:
        class_id = min(class_ids)
    else:
        # Pick class_id of the polygon with the biggest intersection over
        # cell. If there is a tie, pick the first.
        class_id = class_ids[np.argmax(inter_over_cells)]

    return class_id


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1651')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/label_source/chip_classification_label_source.py: 18-81
</a>
<div class="mid" id="frag1651" style="display:none"><pre>
def infer_cell(cell, str_tree, ioa_thresh, use_intersection_over_cell,
               background_class_id, pick_min_class_id):
    """Infer the class_id of a cell given a set of polygons.

    Given a cell and a set of polygons, the problem is to infer the class_id
    that best captures the content of the cell. This is non-trivial since there
    can be multiple polygons of differing classes overlapping with the cell.
    Any polygons that sufficiently overlaps with the cell are in the running for
    setting the class_id. If there are none in the running, the cell is either
    considered null or background. See args for more details.

    Args:
        cell: Box
        str_tree: (STRtree) collection of geoms in scene used for geometric queries.
            The geoms need to have class_id monkey-patched onto them.
        ioa_thresh: (float) the minimum IOA of a polygon and cell for that
            polygon to be a candidate for setting the class_id
        use_intersection_over_cell: (bool) If true, then use the area of the
            cell as the denominator in the IOA. Otherwise, use the area of the
            polygon.
        background_class_id: (None or int) If not None, class_id to use as the
            background class; ie. the one that is used when a window contains
            no boxes. If not set, empty windows have None set as their class_id
            which is considered a null value.
        pick_min_class_id: If true, the class_id for a cell is the minimum
            class_id of the boxes in that cell. Otherwise, pick the class_id of
            the box covering the greatest area.
    """
    cell_geom = cell.to_shapely()
    inter_polys = str_tree.query(cell_geom)

    inter_over_cells = []
    inter_over_polys = []
    class_ids = []

    # Find polygons whose intersection with the cell is big enough.
    for poly in inter_polys:
        inter = poly.intersection(cell_geom)
        inter_over_cell = inter.area / cell_geom.area
        inter_over_poly = inter.area / poly.area

        if use_intersection_over_cell:
            enough_inter = inter_over_cell &gt;= ioa_thresh
        else:
            enough_inter = inter_over_poly &gt;= ioa_thresh

        if enough_inter:
            inter_over_cells.append(inter_over_cell)
            inter_over_polys.append(inter_over_poly)
            class_ids.append(poly.class_id)

    # Infer class id for cell.
    if len(class_ids) == 0:
        class_id = background_class_id
    elif pick_min_class_id:
        class_id = min(class_ids)
    else:
        # Pick class_id of the polygon with the biggest intersection over
        # cell. If there is a tie, pick the first.
        class_id = class_ids[np.argmax(inter_over_cells)]

    return class_id


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 34:</b> &nbsp; 2 fragments, nominal size 17 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag572')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label_source/chip_classification_label_source.py: 75-111
</a>
<div class="mid" id="frag572" style="display:none"><pre>
def infer_labels(geojson, extent, cell_size, ioa_thresh,
                 use_intersection_over_cell, pick_min_class_id,
                 background_class_id):
    """Infer ChipClassificationLabels grid from GeoJSON containing polygons.

    Given GeoJSON with polygons associated with class_ids, infer a grid of
    cells and class_ids that best captures the contents of each cell. See infer_cell for
    info on the args.

    Args:
        geojson: dict in normalized GeoJSON format (see VectorSource)
        extent: Box representing the bounds of the grid

    Returns:
        ChipClassificationLabels
    """
    labels = ChipClassificationLabels()
    cells = extent.get_windows(cell_size, cell_size)

    # We need to associate class_id with each geom. Monkey-patching it onto the geom
    # seems like a bad idea, but it's the only straightforward way of doing this
    # that I've been able to find.
    geoms = []
    for f in geojson['features']:
        g = shape(f['geometry'])
        g.class_id = f['properties']['class_id']
        geoms.append(g)
    str_tree = STRtree(geoms)

    for cell in cells:
        class_id = infer_cell(cell, str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        labels.set_cell(cell, class_id)
    return labels


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1652')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/label_source/chip_classification_label_source.py: 82-118
</a>
<div class="mid" id="frag1652" style="display:none"><pre>
def infer_labels(geojson, extent, cell_sz, ioa_thresh,
                 use_intersection_over_cell, pick_min_class_id,
                 background_class_id):
    """Infer ChipClassificationLabels grid from GeoJSON containing polygons.

    Given GeoJSON with polygons associated with class_ids, infer a grid of
    cells and class_ids that best captures the contents of each cell. See infer_cell for
    info on the args.

    Args:
        geojson: dict in normalized GeoJSON format (see VectorSource)
        extent: Box representing the bounds of the grid

    Returns:
        ChipClassificationLabels
    """
    labels = ChipClassificationLabels()
    cells = extent.get_windows(cell_sz, cell_sz)

    # We need to associate class_id with each geom. Monkey-patching it onto the geom
    # seems like a bad idea, but it's the only straightforward way of doing this
    # that I've been able to find.
    geoms = []
    for f in geojson['features']:
        g = shape(f['geometry'])
        g.class_id = f['properties']['class_id']
        geoms.append(g)
    str_tree = STRtree(geoms)

    for cell in cells:
        class_id = infer_cell(cell, str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        labels.set_cell(cell, class_id)
    return labels


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 35:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag573')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label_source/chip_classification_label_source.py: 112-144
</a>
<div class="mid" id="frag573" style="display:none"><pre>
def read_labels(geojson, extent=None):
    """Convert GeoJSON to ChipClassificationLabels.

    If the GeoJSON already contains a grid of cells, then it can be constructed
    in a straightforward manner without having to infer the class of cells.

    If extent is given, only labels that intersect with the extent are returned.

    Args:
        geojson: dict in normalized GeoJSON format (see VectorSource)
        extent: Box in pixel coords

    Returns:
       ChipClassificationLabels
    """
    labels = ChipClassificationLabels()

    for f in geojson['features']:
        geom = shape(f['geometry'])
        (xmin, ymin, xmax, ymax) = geom.bounds
        cell = Box(ymin, xmin, ymax, xmax)
        if extent is not None and not cell.to_shapely().intersects(
                extent.to_shapely()):
            continue

        props = f['properties']
        class_id = props['class_id']
        scores = props.get('scores')
        labels.set_cell(cell, class_id, scores)

    return labels


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1653')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/label_source/chip_classification_label_source.py: 119-151
</a>
<div class="mid" id="frag1653" style="display:none"><pre>
def read_labels(geojson, extent=None):
    """Convert GeoJSON to ChipClassificationLabels.

    If the GeoJSON already contains a grid of cells, then it can be constructed
    in a straightforward manner without having to infer the class of cells.

    If extent is given, only labels that intersect with the extent are returned.

    Args:
        geojson: dict in normalized GeoJSON format (see VectorSource)
        extent: Box in pixel coords

    Returns:
       ChipClassificationLabels
    """
    labels = ChipClassificationLabels()

    for f in geojson['features']:
        geom = shape(f['geometry'])
        (xmin, ymin, xmax, ymax) = geom.bounds
        cell = Box(ymin, xmin, ymax, xmax)
        if extent is not None and not cell.to_shapely().intersects(
                extent.to_shapely()):
            continue

        props = f['properties']
        class_id = props['class_id']
        scores = props.get('scores')
        labels.set_cell(cell, class_id, scores)

    return labels


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 36:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag594')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/activate_mixin.py: 46-67
</a>
<div class="mid" id="frag594" style="display:none"><pre>
    def activate(self):
        if hasattr(self, '_mixin_activated'):
            if self._mixin_activated:
                raise ActivationError('This {} is already activated'.format(
                    type(self)))

        def do_activate():
            self._mixin_activated = True
            self._activate()

        def do_deactivate():
            self._deactivate()
            self._mixin_activated = False

        a = ActivateMixin.ActivateContextManager(do_activate, do_deactivate)
        subcomponents = self._subcomponents_to_activate()
        if subcomponents:
            return ActivateMixin.CompositeContextManager(
                a, ActivateMixin.compose(*subcomponents))
        else:
            return a

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1664')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/activate_mixin.py: 47-68
</a>
<div class="mid" id="frag1664" style="display:none"><pre>
    def activate(self):
        if hasattr(self, '_mixin_activated'):
            if self._mixin_activated:
                raise ActivationError('This {} is already activated'.format(
                    type(self)))

        def do_activate():
            self._mixin_activated = True
            self._activate()

        def do_deactivate():
            self._deactivate()
            self._mixin_activated = False

        a = ActivateMixin.ActivateContextManager(do_activate, do_deactivate)
        subcomponents = self._subcomponents_to_activate()
        if subcomponents:
            return ActivateMixin.CompositeContextManager(
                a, ActivateMixin.compose(*subcomponents))
        else:
            return a

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 37:</b> &nbsp; 3 fragments, nominal size 25 lines, similarity 79%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag602')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/utils.py: 1-49
</a>
<div class="mid" id="frag602" style="display:none"><pre>
def boxes_to_geojson(boxes, class_ids, crs_transformer, class_map,
                     scores=None):
    """Convert boxes and associated data into a GeoJSON dict.

    Args:
        boxes: list of Box in pixel row/col format.
        class_ids: list of int (one for each box)
        crs_transformer: CRSTransformer used to convert pixel coords to map
            coords in the GeoJSON
        class_map: ClassMap used to infer class_name from class_id
        scores: optional list of score or scores.
                If floats (one for each box), property name will be "score".
                If lists of floats, property name will be "scores".

    Returns:
        dict in GeoJSON format
    """
    features = []
    for box_ind, box in enumerate(boxes):
        polygon = box.geojson_coordinates()
        polygon = [list(crs_transformer.pixel_to_map(p)) for p in polygon]

        class_id = int(class_ids[box_ind])
        class_name = class_map.get_by_id(class_id).name

        feature = {
            'type': 'Feature',
            'geometry': {
                'type': 'Polygon',
                'coordinates': [polygon]
            },
            'properties': {
                'class_id': class_id,
                'class_name': class_name
            }
        }

        if scores is not None:
            box_scores = scores[box_ind]

            if box_scores is not None:
                if type(box_scores) is list:
                    feature['properties']['scores'] = box_scores
                else:
                    feature['properties']['score'] = box_scores

        features.append(feature)

    return {'type': 'FeatureCollection', 'features': features}
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag939')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label_store/utils.py: 1-49
</a>
<div class="mid" id="frag939" style="display:none"><pre>
def boxes_to_geojson(boxes, class_ids, crs_transformer, class_map,
                     scores=None):
    """Convert boxes and associated data into a GeoJSON dict.

    Args:
        boxes: list of Box in pixel row/col format.
        class_ids: list of int (one for each box)
        crs_transformer: CRSTransformer used to convert pixel coords to map
            coords in the GeoJSON
        class_map: ClassMap used to infer class_name from class_id
        scores: optional list of score or scores.
                If floats (one for each box), property name will be "score".
                If lists of floats, property name will be "scores".

    Returns:
        dict in GeoJSON format
    """
    features = []
    for box_ind, box in enumerate(boxes):
        polygon = box.geojson_coordinates()
        polygon = [list(crs_transformer.pixel_to_map(p)) for p in polygon]

        class_id = int(class_ids[box_ind])
        class_name = class_map.get_by_id(class_id).name

        feature = {
            'type': 'Feature',
            'geometry': {
                'type': 'Polygon',
                'coordinates': [polygon]
            },
            'properties': {
                'class_id': class_id,
                'class_name': class_name
            }
        }

        if scores is not None:
            box_scores = scores[box_ind]

            if box_scores is not None:
                if type(box_scores) is list:
                    feature['properties']['scores'] = box_scores
                else:
                    feature['properties']['score'] = box_scores

        features.append(feature)

    return {'type': 'FeatureCollection', 'features': features}
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1836')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/label_store/utils.py: 1-53
</a>
<div class="mid" id="frag1836" style="display:none"><pre>
def boxes_to_geojson(  # noqa
        boxes,  # noqa
        class_ids,
        crs_transformer,
        class_config,
        scores=None):
    """Convert boxes and associated data into a GeoJSON dict.

    Args:
        boxes: list of Box in pixel row/col format.
        class_ids: list of int (one for each box)
        crs_transformer: CRSTransformer used to convert pixel coords to map
            coords in the GeoJSON
        class_config: ClassConfig
        scores: optional list of score or scores.
                If floats (one for each box), property name will be "score".
                If lists of floats, property name will be "scores".

    Returns:
        dict in GeoJSON format
    """
    features = []
    for box_ind, box in enumerate(boxes):
        polygon = box.geojson_coordinates()
        polygon = [list(crs_transformer.pixel_to_map(p)) for p in polygon]

        class_id = int(class_ids[box_ind])
        class_name = class_config.get_name(class_id)

        feature = {
            'type': 'Feature',
            'geometry': {
                'type': 'Polygon',
                'coordinates': [polygon]
            },
            'properties': {
                'class_id': class_id,
                'class_name': class_name
            }
        }

        if scores is not None:
            box_scores = scores[box_ind]

            if box_scores is not None:
                if type(box_scores) is list:
                    feature['properties']['scores'] = box_scores
                else:
                    feature['properties']['score'] = box_scores

        features.append(feature)

    return {'type': 'FeatureCollection', 'features': features}
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 38:</b> &nbsp; 2 fragments, nominal size 23 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag611')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/raster_transformer/stats_transformer.py: 19-66
</a>
<div class="mid" id="frag611" style="display:none"><pre>

    def transform(self, chip, channel_order=None):
        """Transform a chip.

        Transforms non-uint8 to uint8 values using raster_stats.

        Args:
            chip: ndarray of shape [height, width, channels] This is assumed to already
                have the channel_order applied to it if channel_order is set. In other
                words, channels should be equal to len(channel_order).
            channel_order: list of indices of channels that were extracted from the
                raw imagery.

        Returns:
            [height, width, channels] uint8 numpy array

        """
        if chip.dtype != np.uint8:
            if self.raster_stats:
                if channel_order is None:
                    channel_order = np.arange(chip.shape[2])

                # Subtract mean and divide by std to get zscores.
                means = np.array(self.raster_stats.means)
                means = means[np.newaxis, np.newaxis, channel_order].astype(
                    np.float)
                stds = np.array(self.raster_stats.stds)
                stds = stds[np.newaxis, np.newaxis, channel_order].astype(
                    np.float)

                # Don't transform NODATA zero values.
                nodata = chip == 0

                chip = chip - means
                chip = chip / stds

                # Make zscores that fall between -3 and 3 span 0 to 255.
                chip += 3
                chip /= 6

                chip = np.clip(chip, 0, 1)
                chip *= 255
                chip = chip.astype(np.uint8)

                chip[nodata] = 0
            else:
                raise ValueError('raster_stats not defined.')

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1678')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/raster_transformer/stats_transformer.py: 19-66
</a>
<div class="mid" id="frag1678" style="display:none"><pre>

    def transform(self, chip, channel_order=None):
        """Transform a chip.

        Transforms non-uint8 to uint8 values using raster_stats.

        Args:
            chip: ndarray of shape [height, width, channels] This is assumed to already
                have the channel_order applied to it if channel_order is set. In other
                words, channels should be equal to len(channel_order).
            channel_order: list of indices of channels that were extracted from the
                raw imagery.

        Returns:
            [height, width, channels] uint8 numpy array

        """
        if chip.dtype != np.uint8:
            if self.raster_stats:
                if channel_order is None:
                    channel_order = np.arange(chip.shape[2])

                # Subtract mean and divide by std to get zscores.
                means = np.array(self.raster_stats.means)
                means = means[np.newaxis, np.newaxis, channel_order].astype(
                    np.float)
                stds = np.array(self.raster_stats.stds)
                stds = stds[np.newaxis, np.newaxis, channel_order].astype(
                    np.float)

                # Don't transform NODATA zero values.
                nodata = chip == 0

                chip = chip - means
                chip = chip / stds

                # Make zscores that fall between -3 and 3 span 0 to 255.
                chip += 3
                chip /= 6

                chip = np.clip(chip, 0, 1)
                chip *= 255
                chip = chip.astype(np.uint8)

                chip[nodata] = 0
            else:
                raise ValueError('raster_stats not defined.')

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 39:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag633')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/raster_source/rasterized_source_config.py: 33-44
</a>
<div class="mid" id="frag633" style="display:none"><pre>
                all_touched=self.all_touched)

    def __init__(self,
                 vector_source,
                 rasterizer_options,
                 transformers=None,
                 channel_order=None):
        super().__init__(
            source_type=rv.RASTERIZED_SOURCE,
            transformers=transformers,
            channel_order=channel_order)
        self.vector_source = vector_source
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag671')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/raster_source/rasterio_source_config.py: 11-24
</a>
<div class="mid" id="frag671" style="display:none"><pre>

class RasterioSourceConfig(RasterSourceConfig):
    def __init__(self,
                 uris,
                 x_shift_meters=0.0,
                 y_shift_meters=0.0,
                 transformers=None,
                 channel_order=None):
        super().__init__(
            source_type=rv.RASTERIO_SOURCE,
            transformers=transformers,
            channel_order=channel_order)
        self.uris = uris
        self.x_shift_meters = x_shift_meters
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 40:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag649')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/raster_source/rasterio_source.py: 40-67
</a>
<div class="mid" id="frag649" style="display:none"><pre>
def load_window(image_dataset, window=None, is_masked=False):
    """Load a window of an image using Rasterio.

    Args:
        image_dataset: a Rasterio dataset
        window: ((row_start, row_stop), (col_start, col_stop)) or
        ((y_min, y_max), (x_min, x_max))
        is_masked: If True, read a masked array from rasterio

    Returns:
        np.ndarray of shape (height, width, channels) where channels is the number of
            channels in the image_dataset.
    """
    if is_masked:
        im = image_dataset.read(window=window, boundless=True, masked=True)
        im = np.ma.filled(im, fill_value=0)
    else:
        im = image_dataset.read(window=window, boundless=True)

    # Handle non-zero NODATA values by setting the data to 0.
    for channel, nodata in enumerate(image_dataset.nodatavals):
        if nodata is not None and nodata != 0:
            im[channel, im[channel] == nodata] = 0

    im = np.transpose(im, axes=[1, 2, 0])
    return im


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1686')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/raster_source/rasterio_source.py: 40-67
</a>
<div class="mid" id="frag1686" style="display:none"><pre>
def load_window(image_dataset, window=None, is_masked=False):
    """Load a window of an image using Rasterio.

    Args:
        image_dataset: a Rasterio dataset
        window: ((row_start, row_stop), (col_start, col_stop)) or
        ((y_min, y_max), (x_min, x_max))
        is_masked: If True, read a masked array from rasterio

    Returns:
        np.ndarray of shape (height, width, channels) where channels is the number of
            channels in the image_dataset.
    """
    if is_masked:
        im = image_dataset.read(window=window, boundless=True, masked=True)
        im = np.ma.filled(im, fill_value=0)
    else:
        im = image_dataset.read(window=window, boundless=True)

    # Handle non-zero NODATA values by setting the data to 0.
    for channel, nodata in enumerate(image_dataset.nodatavals):
        if nodata is not None and nodata != 0:
            im[channel, im[channel] == nodata] = 0

    im = np.transpose(im, axes=[1, 2, 0])
    return im


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 41:</b> &nbsp; 2 fragments, nominal size 38 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag650')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/raster_source/rasterio_source.py: 69-128
</a>
<div class="mid" id="frag650" style="display:none"><pre>
    def __init__(self,
                 uris,
                 raster_transformers,
                 temp_dir,
                 channel_order=None,
                 x_shift_meters=0.0,
                 y_shift_meters=0.0):
        """Constructor.

        This RasterSource can read any file that can be opened by Rasterio/GDAL
        including georeferenced formats such as GeoTIFF and non-georeferenced formats
        such as JPG. See https://www.gdal.org/formats_list.html for more details.

        If channel_order is None, then use non-alpha channels. This also sets any
        masked or NODATA pixel values to be zeros.

        Args:
            channel_order: list of indices of channels to extract from raw imagery
        """
        self.uris = uris
        self.temp_dir = temp_dir
        self.image_temp_dir = None
        self.image_dataset = None
        self.x_shift_meters = x_shift_meters
        self.y_shift_meters = y_shift_meters

        num_channels = None

        # Activate in order to get information out of the raster
        with self.activate():
            num_channels = self.image_dataset.count
            if channel_order is None:
                colorinterp = self.image_dataset.colorinterp
                if colorinterp:
                    channel_order = [
                        i for i, color_interp in enumerate(colorinterp)
                        if color_interp != ColorInterp.alpha
                    ]
                else:
                    channel_order = list(range(0, num_channels))
            self.validate_channel_order(channel_order, num_channels)

            mask_flags = self.image_dataset.mask_flag_enums
            self.is_masked = any(
                [m for m in mask_flags if m != MaskFlags.all_valid])

            self.height = self.image_dataset.height
            self.width = self.image_dataset.width

            # Get 1x1 chip and apply raster transformers to test dtype.
            test_chip = self.get_raw_chip(Box.make_square(0, 0, 1))
            test_chip = test_chip[:, :, channel_order]
            for transformer in raster_transformers:
                test_chip = transformer.transform(test_chip, channel_order)
            self.dtype = test_chip.dtype

            self._set_crs_transformer()

        super().__init__(channel_order, num_channels, raster_transformers)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1687')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/raster_source/rasterio_source.py: 69-128
</a>
<div class="mid" id="frag1687" style="display:none"><pre>
    def __init__(self,
                 uris,
                 raster_transformers,
                 tmp_dir,
                 channel_order=None,
                 x_shift=0.0,
                 y_shift=0.0):
        """Constructor.

        This RasterSource can read any file that can be opened by Rasterio/GDAL
        including georeferenced formats such as GeoTIFF and non-georeferenced formats
        such as JPG. See https://www.gdal.org/formats_list.html for more details.

        If channel_order is None, then use non-alpha channels. This also sets any
        masked or NODATA pixel values to be zeros.

        Args:
            channel_order: list of indices of channels to extract from raw imagery
        """
        self.uris = uris
        self.tmp_dir = tmp_dir
        self.image_tmp_dir = None
        self.image_dataset = None
        self.x_shift = x_shift
        self.y_shift = y_shift

        num_channels = None

        # Activate in order to get information out of the raster
        with self.activate():
            num_channels = self.image_dataset.count
            if channel_order is None:
                colorinterp = self.image_dataset.colorinterp
                if colorinterp:
                    channel_order = [
                        i for i, color_interp in enumerate(colorinterp)
                        if color_interp != ColorInterp.alpha
                    ]
                else:
                    channel_order = list(range(0, num_channels))
            self.validate_channel_order(channel_order, num_channels)

            mask_flags = self.image_dataset.mask_flag_enums
            self.is_masked = any(
                [m for m in mask_flags if m != MaskFlags.all_valid])

            self.height = self.image_dataset.height
            self.width = self.image_dataset.width

            # Get 1x1 chip and apply raster transformers to test dtype.
            test_chip = self.get_raw_chip(Box.make_square(0, 0, 1))
            test_chip = test_chip[:, :, channel_order]
            for transformer in raster_transformers:
                test_chip = transformer.transform(test_chip, channel_order)
            self.dtype = test_chip.dtype

            self._set_crs_transformer()

        super().__init__(channel_order, num_channels, raster_transformers)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 42:</b> &nbsp; 2 fragments, nominal size 27 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag659')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/raster_source/rasterio_source.py: 181-222
</a>
<div class="mid" id="frag659" style="display:none"><pre>
    def _get_shifted_window(self, window):
        do_shift = self.x_shift_meters != 0.0 or self.y_shift_meters != 0.0
        if do_shift:
            ymin, xmin, ymax, xmax = window.tuple_format()
            width = window.get_width()
            height = window.get_height()

            # Transform image coordinates into world coordinates
            transform = self.image_dataset.transform
            xmin2, ymin2 = transform * (xmin, ymin)

            # Transform from world coordinates to WGS84
            if self.crs != wgs84_proj4 and self.proj:
                lon, lat = pyproj.transform(self.proj, wgs84, xmin2, ymin2)
            else:
                lon, lat = xmin2, ymin2

            # Shift.  This is performed by computing the shifts in
            # meters to shifts in degrees.  Those shifts are then
            # applied to the WGS84 coordinate.
            #
            # Courtesy of https://gis.stackexchange.com/questions/2951/algorithm-for-offsetting-a-latitude-longitude-by-some-amount-of-meters  # noqa
            lat_radians = math.pi * lat / 180.0
            dlon = Decimal(self.x_shift_meters) / Decimal(
                meters_per_degree * math.cos(lat_radians))
            dlat = Decimal(self.y_shift_meters) / Decimal(meters_per_degree)
            lon = float(Decimal(lon) + dlon)
            lat = float(Decimal(lat) + dlat)

            # Transform from WGS84 to world coordinates
            if self.crs != wgs84_proj4 and self.proj:
                xmin3, ymin3 = pyproj.transform(wgs84, self.proj, lon, lat)
                xmin3 = int(round(xmin3))
                ymin3 = int(round(ymin3))
            else:
                xmin3, ymin3 = lon, lat

            # Trasnform from world coordinates back into image coordinates
            xmin4, ymin4 = ~transform * (xmin3, ymin3)

            window = Box(ymin4, xmin4, ymin4 + height, xmin4 + width)
        return window
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1696')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/raster_source/rasterio_source.py: 181-222
</a>
<div class="mid" id="frag1696" style="display:none"><pre>
    def _get_shifted_window(self, window):
        do_shift = self.x_shift != 0.0 or self.y_shift != 0.0
        if do_shift:
            ymin, xmin, ymax, xmax = window.tuple_format()
            width = window.get_width()
            height = window.get_height()

            # Transform image coordinates into world coordinates
            transform = self.image_dataset.transform
            xmin2, ymin2 = transform * (xmin, ymin)

            # Transform from world coordinates to WGS84
            if self.crs != wgs84_proj4 and self.proj:
                lon, lat = pyproj.transform(self.proj, wgs84, xmin2, ymin2)
            else:
                lon, lat = xmin2, ymin2

            # Shift.  This is performed by computing the shifts in
            # meters to shifts in degrees.  Those shifts are then
            # applied to the WGS84 coordinate.
            #
            # Courtesy of https://gis.stackexchange.com/questions/2951/algorithm-for-offsetting-a-latitude-longitude-by-some-amount-of-meters  # noqa
            lat_radians = math.pi * lat / 180.0
            dlon = Decimal(self.x_shift) / Decimal(
                meters_per_degree * math.cos(lat_radians))
            dlat = Decimal(self.y_shift) / Decimal(meters_per_degree)
            lon = float(Decimal(lon) + dlon)
            lat = float(Decimal(lat) + dlat)

            # Transform from WGS84 to world coordinates
            if self.crs != wgs84_proj4 and self.proj:
                xmin3, ymin3 = pyproj.transform(wgs84, self.proj, lon, lat)
                xmin3 = int(round(xmin3))
                ymin3 = int(round(ymin3))
            else:
                xmin3, ymin3 = lon, lat

            # Trasnform from world coordinates back into image coordinates
            xmin4, ymin4 = ~transform * (xmin3, ymin3)

            window = Box(ymin4, xmin4, ymin4 + height, xmin4 + width)
        return window
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 43:</b> &nbsp; 8 fragments, nominal size 11 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag678')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/raster_source/rasterio_source_config.py: 76-88
</a>
<div class="mid" id="frag678" style="display:none"><pre>

class RasterioSourceConfigBuilder(RasterSourceConfigBuilder):
    """This RasterSource can read any file that can be opened by Rasterio/GDAL.

    This includes georeferenced formats such as GeoTIFF and non-georeferenced formats
    such as JPG. See https://www.gdal.org/formats_list.html for more details.
    """

    def __init__(self, prev=None):
        config = {}
        if prev:
            config = {
                'uris': prev.uris,
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag780')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/vector_source/geojson_vector_source_config.py: 46-58
</a>
<div class="mid" id="frag780" style="display:none"><pre>
    def __init__(self, prev=None):
        config = {}
        if prev:
            config = {
                'uri': prev.uri,
                'class_id_to_filter': prev.class_id_to_filter,
                'default_class_id': prev.default_class_id,
                'line_bufs': prev.line_bufs,
                'point_bufs': prev.point_bufs
            }

        super().__init__(GeoJSONVectorSourceConfig, config)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1167')" href="javascript:;">
raster-vision-0.11.0/rastervision/task/semantic_segmentation_config.py: 82-95
</a>
<div class="mid" id="frag1167" style="display:none"><pre>
    def __init__(self, prev=None):
        config = {}
        if prev:
            config = {
                'predict_batch_size': prev.predict_batch_size,
                'predict_package_uri': prev.predict_package_uri,
                'debug': prev.debug,
                'class_map': prev.class_map,
                'chip_size': prev.chip_size,
                'predict_chip_size': prev.predict_chip_size,
                'chip_options': prev.chip_options
            }
        super().__init__(SemanticSegmentationConfig, config)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag737')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/scene_config.py: 147-159
</a>
<div class="mid" id="frag737" style="display:none"><pre>
    def from_proto(msg):
        """Creates a SceneConfig from the specificed protobuf message
        """
        return SceneConfigBuilder().from_proto(msg).build()


class SceneConfigBuilder(ConfigBuilder):
    def __init__(self, prev=None):
        config = {}
        if prev:
            config = {
                'id': prev.id,
                'raster_source': prev.raster_source,
</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag933')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label_store/semantic_segmentation_raster_store_config.py: 146-157
</a>
<div class="mid" id="frag933" style="display:none"><pre>

class SemanticSegmentationRasterStoreConfigBuilder(LabelStoreConfigBuilder):
    def __init__(self, prev=None):
        config = {}
        if prev:
            config = {
                'uri': prev.uri,
                'vector_output': prev.vector_output,
                'rgb': prev.rgb,
            }

        super().__init__(SemanticSegmentationRasterStoreConfig, config)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1133')" href="javascript:;">
raster-vision-0.11.0/rastervision/task/chip_classification_config.py: 44-56
</a>
<div class="mid" id="frag1133" style="display:none"><pre>
    def __init__(self, prev=None):
        config = {}
        if prev:
            config = {
                'class_map': prev.class_map,
                'chip_size': prev.chip_size,
                'predict_batch_size': prev.predict_batch_size,
                'predict_package_uri': prev.predict_package_uri,
                'debug': prev.debug,
                'predict_debug_uri': prev.predict_debug_uri
            }
        super().__init__(ChipClassificationConfig, config)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1194')" href="javascript:;">
raster-vision-0.11.0/rastervision/task/object_detection_config.py: 80-94
</a>
<div class="mid" id="frag1194" style="display:none"><pre>
    def __init__(self, prev=None):
        config = {}
        if prev:
            config = {
                'predict_batch_size': prev.predict_batch_size,
                'predict_package_uri': prev.predict_package_uri,
                'debug': prev.debug,
                'predict_debug_uri': prev.predict_debug_uri,
                'class_map': prev.class_map,
                'chip_size': prev.chip_size,
                'chip_options': prev.chip_options,
                'predict_options': prev.predict_options
            }
        super().__init__(ObjectDetectionConfig, config)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag753')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/vector_source/vector_tile_vector_source_config.py: 58-72
</a>
<div class="mid" id="frag753" style="display:none"><pre>
    def __init__(self, prev=None):
        config = {}
        if prev:
            config = {
                'uri': prev.uri,
                'zoom': prev.zoom,
                'id_field': prev.id_field,
                'class_id_to_filter': prev.class_id_to_filter,
                'default_class_id': prev.default_class_id,
                'line_bufs': prev.line_bufs,
                'point_bufs': prev.point_bufs
            }

        super().__init__(VectorTileVectorSourceConfig, config)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 44:</b> &nbsp; 2 fragments, nominal size 30 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag684')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/raster_source/rasterized_source.py: 16-64
</a>
<div class="mid" id="frag684" style="display:none"><pre>
def geoms_to_raster(str_tree, rasterizer_options, window, extent):
    background_class_id = rasterizer_options.background_class_id
    all_touched = rasterizer_options.all_touched

    log.debug('Cropping shapes to window...')
    # Crop shapes against window, remove empty shapes, and put in window frame of
    # reference.
    window_geom = window.to_shapely()
    shapes = str_tree.query(window_geom)
    shapes = [(s, s.class_id) for s in shapes]
    shapes = [(s.intersection(window_geom), c) for s, c in shapes]
    shapes = [(s, c) for s, c in shapes if not s.is_empty]

    def to_window_frame(x, y, z=None):
        return (x - window.xmin, y - window.ymin)

    shapes = [(shapely.ops.transform(to_window_frame, s), c)
              for s, c in shapes]
    log.debug('# of shapes in window: {}'.format(len(shapes)))

    out_shape = (window.get_height(), window.get_width())

    # rasterize needs to be passed &gt;= 1 shapes.
    if shapes:
        log.debug('rasterio.rasterize()...')
        raster = rasterize(
            shapes,
            out_shape=out_shape,
            fill=background_class_id,
            dtype=np.uint8,
            all_touched=all_touched)
    else:
        raster = np.full(out_shape, background_class_id, dtype=np.uint8)

    # Ensure that parts of window outside of extent have zero values which are counted as
    # the don't-care class for segmentation.
    valid_window = window_geom.intersection(extent.to_shapely())
    if valid_window.is_empty:
        raster[:, :] = 0
    else:
        vw = shapely.ops.transform(to_window_frame, valid_window)
        vw = Box.from_shapely(vw).to_int()
        new_raster = np.zeros(out_shape)
        new_raster[vw.ymin:vw.ymax, vw.xmin:vw.xmax] = \
            raster[vw.ymin:vw.ymax, vw.xmin:vw.xmax]
        raster = new_raster

    return raster

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1708')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/raster_source/rasterized_source.py: 15-50
</a>
<div class="mid" id="frag1708" style="display:none"><pre>
def geoms_to_raster(str_tree, rasterizer_config, window, extent):
    background_class_id = rasterizer_config.background_class_id
    all_touched = rasterizer_config.all_touched

    log.debug('Cropping shapes to window...')
    # Crop shapes against window, remove empty shapes, and put in window frame of
    # reference.
    window_geom = window.to_shapely()
    shapes = str_tree.query(window_geom)
    shapes = [(s, s.class_id) for s in shapes]
    shapes = [(s.intersection(window_geom), c) for s, c in shapes]
    shapes = [(s, c) for s, c in shapes if not s.is_empty]

    def to_window_frame(x, y, z=None):
        return (x - window.xmin, y - window.ymin)

    shapes = [(transform(to_window_frame, s), c) for s, c in shapes]
    log.debug('# of shapes in window: {}'.format(len(shapes)))

    out_shape = (window.get_height(), window.get_width())

    # rasterize needs to be passed &gt;= 1 shapes.
    if shapes:
        log.debug('rasterio.rasterize()...')
        raster = rasterize(
            shapes,
            out_shape=out_shape,
            fill=background_class_id,
            dtype=np.uint8,
            all_touched=all_touched)
    else:
        raster = np.full(out_shape, background_class_id, dtype=np.uint8)

    return raster


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 45:</b> &nbsp; 2 fragments, nominal size 15 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag749')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/vector_source/vector_tile_vector_source_config.py: 12-29
</a>
<div class="mid" id="frag749" style="display:none"><pre>
    def __init__(self,
                 uri,
                 zoom,
                 id_field,
                 class_id_to_filter=None,
                 default_class_id=1,
                 line_bufs=None,
                 point_bufs=None):
        self.uri = uri
        self.zoom = zoom
        self.id_field = id_field
        super().__init__(
            rv.VECTOR_TILE_SOURCE,
            class_id_to_filter=class_id_to_filter,
            default_class_id=default_class_id,
            line_bufs=line_bufs,
            point_bufs=point_bufs)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag776')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/vector_source/geojson_vector_source_config.py: 11-24
</a>
<div class="mid" id="frag776" style="display:none"><pre>
    def __init__(self,
                 uri,
                 class_id_to_filter=None,
                 default_class_id=1,
                 line_bufs=None,
                 point_bufs=None):
        self.uri = uri
        super().__init__(
            rv.GEOJSON_SOURCE,
            class_id_to_filter=class_id_to_filter,
            default_class_id=default_class_id,
            line_bufs=line_bufs,
            point_bufs=point_bufs)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 46:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag751')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/vector_source/vector_tile_vector_source_config.py: 37-50
</a>
<div class="mid" id="frag751" style="display:none"><pre>
    def create_source(self, crs_transformer=None, extent=None, class_map=None):
        return VectorTileVectorSource(
            self.uri,
            self.zoom,
            self.id_field,
            crs_transformer,
            extent,
            line_bufs=self.line_bufs,
            point_bufs=self.point_bufs,
            class_inf_opts=ClassInferenceOptions(
                class_map=class_map,
                class_id_to_filter=self.class_id_to_filter,
                default_class_id=self.default_class_id))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag778')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/vector_source/geojson_vector_source_config.py: 30-40
</a>
<div class="mid" id="frag778" style="display:none"><pre>
    def create_source(self, crs_transformer=None, extent=None, class_map=None):
        return GeoJSONVectorSource(
            self.uri,
            crs_transformer,
            line_bufs=self.line_bufs,
            point_bufs=self.point_bufs,
            class_inf_opts=ClassInferenceOptions(
                class_map=class_map,
                class_id_to_filter=self.class_id_to_filter,
                default_class_id=self.default_class_id))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 47:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag762')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/vector_source/class_inference.py: 67-84
</a>
<div class="mid" id="frag762" style="display:none"><pre>
    def transform_geojson(self, geojson):
        """Transform GeoJSON by appending class_ids and removing features with no class.

        For each feature in geojson, the class_id is inferred and is set into
        feature['properties']. If the class_id is None (because none of the rules apply
        and the default_class_id is None), the feature is dropped.
        """
        new_features = []
        for feature in geojson['features']:
            class_id = self.infer_class_id(feature)
            if class_id is not None:
                feature = copy.deepcopy(feature)
                properties = feature.get('properties', {})
                properties['class_id'] = class_id
                feature['properties'] = properties
                new_features.append(feature)
        new_geojson = {'type': 'FeatureCollection', 'features': new_features}
        return new_geojson
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1732')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/vector_source/class_inference.py: 57-74
</a>
<div class="mid" id="frag1732" style="display:none"><pre>
    def transform_geojson(self, geojson):
        """Transform GeoJSON by appending class_ids and removing features with no class.

        For each feature in geojson, the class_id is inferred and is set into
        feature['properties']. If the class_id is None (because none of the rules apply
        and the default_class_id is None), the feature is dropped.
        """
        new_features = []
        for feature in geojson['features']:
            class_id = self.infer_class_id(feature)
            if class_id is not None:
                feature = copy.deepcopy(feature)
                properties = feature.get('properties', {})
                properties['class_id'] = class_id
                feature['properties'] = properties
                new_features.append(feature)
        new_geojson = {'type': 'FeatureCollection', 'features': new_features}
        return new_geojson
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 48:</b> &nbsp; 2 fragments, nominal size 64 lines, similarity 96%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag763')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/vector_source/vector_source.py: 10-107
</a>
<div class="mid" id="frag763" style="display:none"><pre>
def transform_geojson(geojson,
                      crs_transformer,
                      line_bufs=None,
                      point_bufs=None,
                      to_map_coords=False):
    def is_empty_feat(f):
        # This was added to handle empty geoms which appear when using
        # OSM vector tiles.
        return ((not f.get('geometry'))
                or ((not f['geometry'].get('coordinates')) and
                    (not f['geometry'].get('geometries'))))

    new_features = []
    for f in geojson['features']:
        if is_empty_feat(f):
            continue

        geom = shape(f['geometry'])

        # Convert map to pixel coords. We need to convert to pixel coords before applying
        # buffering because those values are assumed to be in pixel units.
        def m2p(x, y, z=None):
            return crs_transformer.map_to_pixel((x, y))

        geom = shapely.ops.transform(m2p, geom)

        # Split GeometryCollection into list of geoms.
        geoms = [geom]
        if geom.geom_type == 'GeometryCollection':
            geoms = list(geom)

        # Split any MultiX to list of X.
        new_geoms = []
        for g in geoms:
            if g.geom_type in [
                    'MultiPolygon', 'MultiPoint', 'MultiLineString'
            ]:
                new_geoms.extend(list(g))
            else:
                new_geoms.append(g)
        geoms = new_geoms

        # Buffer geoms.
        class_id = f['properties']['class_id']
        new_geoms = []
        for g in geoms:
            if g.geom_type == 'LineString':
                line_buf = 1
                if line_bufs is not None:
                    line_buf = line_bufs.get(class_id, 1)
                # If line_buf for the class_id was explicitly set as None, then
                # don't buffer.
                if line_buf is not None:
                    g = g.buffer(line_buf)
                new_geoms.append(g)
            elif g.geom_type == 'Point':
                point_buf = 1
                if point_bufs is not None:
                    point_buf = point_bufs.get(class_id, 1)
                # If point_buf for the class_id was explicitly set as None, then
                # don't buffer.
                if point_buf is not None:
                    g = g.buffer(point_buf)
                new_geoms.append(g)
            else:
                # Use buffer trick to handle self-intersecting polygons. Buffer returns
                # a MultiPolygon if there is a bowtie, so we have to convert it to a
                # list of Polygons.
                poly_buf = g.buffer(0)
                if poly_buf.geom_type == 'MultiPolygon':
                    new_geoms.extend(list(poly_buf))
                else:
                    new_geoms.append(poly_buf)
        geoms = new_geoms

        # Convert back to map coords if desired. This is here so the QGIS plugin can
        # take the GeoJSON produced by a VectorSource and display it on a map.
        if to_map_coords:

            def p2m(x, y, z=None):
                return crs_transformer.pixel_to_map((x, y))

            geoms = [shapely.ops.transform(p2m, g) for g in geoms]

        for g in geoms:
            new_f = {
                'type': 'Feature',
                'geometry': mapping(g),
                'properties': f['properties']
            }
            # Have to check for empty features again which could have been introduced
            # when splitting apart multi-geoms.
            if not is_empty_feat(new_f):
                new_features.append(new_f)

    return {'type': 'FeatureCollection', 'features': new_features}


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1733')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/vector_source/vector_source.py: 16-113
</a>
<div class="mid" id="frag1733" style="display:none"><pre>
def transform_geojson(geojson,
                      crs_transformer,
                      line_bufs=None,
                      point_bufs=None,
                      to_map_coords=False):
    def is_empty_feat(f):
        # This was added to handle empty geoms which appear when using
        # OSM vector tiles.
        return ((not f.get('geometry'))
                or ((not f['geometry'].get('coordinates')) and
                    (not f['geometry'].get('geometries'))))

    new_features = []
    for f in geojson['features']:
        if is_empty_feat(f):
            continue

        geom = shape(f['geometry'])

        # Convert map to pixel coords. We need to convert to pixel coords before applying
        # buffering because those values are assumed to be in pixel units.
        def m2p(x, y, z=None):
            return crs_transformer.map_to_pixel((x, y))

        geom = transform(m2p, geom)

        # Split GeometryCollection into list of geoms.
        geoms = [geom]
        if geom.geom_type == 'GeometryCollection':
            geoms = list(geom)

        # Split any MultiX to list of X.
        new_geoms = []
        for g in geoms:
            if g.geom_type in [
                    'MultiPolygon', 'MultiPoint', 'MultiLineString'
            ]:
                new_geoms.extend(list(g))
            else:
                new_geoms.append(g)
        geoms = new_geoms

        # Buffer geoms.
        class_id = f['properties']['class_id']
        new_geoms = []
        for g in geoms:
            if g.geom_type == 'LineString':
                line_buf = 1
                if line_bufs is not None:
                    line_buf = line_bufs.get(class_id, 1)
                # If line_buf for the class_id was explicitly set as None, then
                # don't buffer.
                if line_buf is not None:
                    g = g.buffer(line_buf)
                new_geoms.append(g)
            elif g.geom_type == 'Point':
                point_buf = 1
                if point_bufs is not None:
                    point_buf = point_bufs.get(class_id, 1)
                # If point_buf for the class_id was explicitly set as None, then
                # don't buffer.
                if point_buf is not None:
                    g = g.buffer(point_buf)
                new_geoms.append(g)
            else:
                # Use buffer trick to handle self-intersecting polygons. Buffer returns
                # a MultiPolygon if there is a bowtie, so we have to convert it to a
                # list of Polygons.
                poly_buf = g.buffer(0)
                if poly_buf.geom_type == 'MultiPolygon':
                    new_geoms.extend(list(poly_buf))
                else:
                    new_geoms.append(poly_buf)
        geoms = new_geoms

        # Convert back to map coords if desired. This is here so the QGIS plugin can
        # take the GeoJSON produced by a VectorSource and display it on a map.
        if to_map_coords:

            def p2m(x, y, z=None):
                return crs_transformer.pixel_to_map((x, y))

            geoms = [transform(p2m, g) for g in geoms]

        for g in geoms:
            new_f = {
                'type': 'Feature',
                'geometry': mapping(g),
                'properties': f['properties']
            }
            # Have to check for empty features again which could have been introduced
            # when splitting apart multi-geoms.
            if not is_empty_feat(new_f):
                new_features.append(new_f)

    return {'type': 'FeatureCollection', 'features': new_features}


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 49:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 80%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag768')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/vector_source/vector_source.py: 139-163
</a>
<div class="mid" id="frag768" style="display:none"><pre>
    def get_geojson(self, to_map_coords=False):
        """Return normalized GeoJSON.

        This infers a class_id property for each feature, converts to pixels coords (by
        default), removes empty features, splits apart multi-geoms and geom collections
        into single geometries, and buffers lines and points into Polygons.

        Args:
            to_map_coords: If true, will return GeoJSON in map coordinates.

        Returns:
            dict in GeoJSON format
        """
        if self.geojson is None:
            self.geojson = self._get_geojson()

        geojson = transform_geojson(
            self.geojson,
            self.crs_transformer,
            self.line_bufs,
            self.point_bufs,
            to_map_coords=to_map_coords)

        return geojson

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1738')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/vector_source/vector_source.py: 129-153
</a>
<div class="mid" id="frag1738" style="display:none"><pre>
    def get_geojson(self, to_map_coords=False):
        """Return normalized GeoJSON.

        This infers a class_id property for each feature, converts to pixels coords (by
        default), removes empty features, splits apart multi-geoms and geom collections
        into single geometries, and buffers lines and points into Polygons.

        Args:
            to_map_coords: If true, will return GeoJSON in map coordinates.

        Returns:
            dict in GeoJSON format
        """
        if self.geojson is None:
            self.geojson = self._get_geojson()

        geojson = transform_geojson(
            self.geojson,
            self.crs_transformer,
            self.vs_config.line_bufs,
            self.vs_config.point_bufs,
            to_map_coords=to_map_coords)

        return geojson

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 50:</b> &nbsp; 2 fragments, nominal size 23 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag793')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/vector_source/label_maker/filter.py: 38-63
</a>
<div class="mid" id="frag793" style="display:none"><pre>
def _compile(filt):
    """Return a string represented the compiled filter function"""
    if not filt:
        return 'True'
    op = filt[0]
    if len(filt) == 1:
        return 'False' if op == 'any' else 'True'
    if op in ['==', '!=', '&lt;', '&gt;', '&lt;=', '&gt;=']:
        return _compile_comparison_op(filt[1], filt[2], op)
    elif op == 'any':
        return _compile_logical_op(filt[1:], ' or ')
    elif op == 'all':
        return _compile_logical_op(filt[1:], ' and ')
    elif op == 'none':
        return _compile_negation(_compile_logical_op(filt[1:], ' or '))
    elif op == 'in':
        return _compile_in_op(filt[1], filt[2:])
    elif op == '!in':
        return _compile_negation(_compile_in_op(filt[1], filt[2:]))
    elif op == 'has':
        return _compile_has_op(filt[1])
    elif op == '!has':
        return _compile_negation(_compile_has_op(filt[1]))
    return 'True'


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1744')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/vector_source/label_maker/filter.py: 38-63
</a>
<div class="mid" id="frag1744" style="display:none"><pre>
def _compile(filt):
    """Return a string represented the compiled filter function"""
    if not filt:
        return 'True'
    op = filt[0]
    if len(filt) == 1:
        return 'False' if op == 'any' else 'True'
    if op in ['==', '!=', '&lt;', '&gt;', '&lt;=', '&gt;=']:
        return _compile_comparison_op(filt[1], filt[2], op)
    elif op == 'any':
        return _compile_logical_op(filt[1:], ' or ')
    elif op == 'all':
        return _compile_logical_op(filt[1:], ' and ')
    elif op == 'none':
        return _compile_negation(_compile_logical_op(filt[1:], ' or '))
    elif op == 'in':
        return _compile_in_op(filt[1], filt[2:])
    elif op == '!in':
        return _compile_negation(_compile_in_op(filt[1], filt[2:]))
    elif op == 'has':
        return _compile_has_op(filt[1])
    elif op == '!has':
        return _compile_negation(_compile_has_op(filt[1]))
    return 'True'


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 51:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag826')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label/chip_classification_labels.py: 24-34
</a>
<div class="mid" id="frag826" style="display:none"><pre>
    def filter_by_aoi(self, aoi_polygons):
        result = ChipClassificationLabels()
        for cell in self.cell_to_class_id:
            cell_box = Box.from_tuple(cell)
            cell_poly = cell_box.to_shapely()
            for aoi in aoi_polygons:
                if cell_poly.within(aoi):
                    (class_id, scores) = self.cell_to_class_id[cell]
                    result.set_cell(cell_box, class_id, scores)
        return result

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1756')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/label/chip_classification_labels.py: 24-34
</a>
<div class="mid" id="frag1756" style="display:none"><pre>
    def filter_by_aoi(self, aoi_polygons):
        result = ChipClassificationLabels()
        for cell in self.cell_to_class_id:
            cell_box = Box.from_tuple(cell)
            cell_poly = cell_box.to_shapely()
            for aoi in aoi_polygons:
                if cell_poly.within(aoi):
                    (class_id, scores) = self.cell_to_class_id[cell]
                    result.set_cell(cell_box, class_id, scores)
        return result

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 52:</b> &nbsp; 2 fragments, nominal size 19 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag841')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label/object_detection_labels.py: 53-75
</a>
<div class="mid" id="frag841" style="display:none"><pre>
    def filter_by_aoi(self, aoi_polygons):
        boxes = self.get_boxes()
        class_ids = self.get_class_ids()
        scores = self.get_scores()

        new_boxes = []
        new_class_ids = []
        new_scores = []
        for box, class_id, score in zip(boxes, class_ids, scores):
            box_poly = box.to_shapely()
            for aoi in aoi_polygons:
                if box_poly.within(aoi):
                    new_boxes.append(box.npbox_format())
                    new_class_ids.append(class_id)
                    new_scores.append(score)
                    break

        if len(new_boxes) == 0:
            return ObjectDetectionLabels.make_empty()

        return ObjectDetectionLabels(
            np.array(new_boxes), np.array(new_class_ids), np.array(new_scores))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1771')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/label/object_detection_labels.py: 53-75
</a>
<div class="mid" id="frag1771" style="display:none"><pre>
    def filter_by_aoi(self, aoi_polygons):
        boxes = self.get_boxes()
        class_ids = self.get_class_ids()
        scores = self.get_scores()

        new_boxes = []
        new_class_ids = []
        new_scores = []
        for box, class_id, score in zip(boxes, class_ids, scores):
            box_poly = box.to_shapely()
            for aoi in aoi_polygons:
                if box_poly.within(aoi):
                    new_boxes.append(box.npbox_format())
                    new_class_ids.append(class_id)
                    new_scores.append(score)
                    break

        if len(new_boxes) == 0:
            return ObjectDetectionLabels.make_empty()

        return ObjectDetectionLabels(
            np.array(new_boxes), np.array(new_class_ids), np.array(new_scores))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 53:</b> &nbsp; 2 fragments, nominal size 23 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag844')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label/object_detection_labels.py: 92-131
</a>
<div class="mid" id="frag844" style="display:none"><pre>
    def from_geojson(geojson, extent=None):
        """Convert GeoJSON to ObjectDetectionLabels object.

        If extent is provided, filter out the boxes that lie "more than a little
        bit" outside the extent.

        Args:
            geojson: (dict) normalized GeoJSON (see VectorSource)
            extent: (Box) in pixel coords

        Returns:
            ObjectDetectionLabels
        """
        boxes = []
        class_ids = []
        scores = []

        for f in geojson['features']:
            geom = shape(f['geometry'])
            (xmin, ymin, xmax, ymax) = geom.bounds
            boxes.append(Box(ymin, xmin, ymax, xmax))

            props = f['properties']
            class_ids.append(props['class_id'])
            scores.append(props.get('score', 1.0))

        if len(boxes):
            boxes = np.array(
                [box.npbox_format() for box in boxes], dtype=float)
            class_ids = np.array(class_ids)
            scores = np.array(scores)
            labels = ObjectDetectionLabels(boxes, class_ids, scores=scores)
        else:
            labels = ObjectDetectionLabels.make_empty()

        if extent is not None:
            labels = ObjectDetectionLabels.get_overlapping(
                labels, extent, ioa_thresh=0.8, clip=True)
        return labels

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1774')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/label/object_detection_labels.py: 92-131
</a>
<div class="mid" id="frag1774" style="display:none"><pre>
    def from_geojson(geojson, extent=None):
        """Convert GeoJSON to ObjectDetectionLabels object.

        If extent is provided, filter out the boxes that lie "more than a little
        bit" outside the extent.

        Args:
            geojson: (dict) normalized GeoJSON (see VectorSource)
            extent: (Box) in pixel coords

        Returns:
            ObjectDetectionLabels
        """
        boxes = []
        class_ids = []
        scores = []

        for f in geojson['features']:
            geom = shape(f['geometry'])
            (xmin, ymin, xmax, ymax) = geom.bounds
            boxes.append(Box(ymin, xmin, ymax, xmax))

            props = f['properties']
            class_ids.append(props['class_id'])
            scores.append(props.get('score', 1.0))

        if len(boxes):
            boxes = np.array(
                [box.npbox_format() for box in boxes], dtype=float)
            class_ids = np.array(class_ids)
            scores = np.array(scores)
            labels = ObjectDetectionLabels(boxes, class_ids, scores=scores)
        else:
            labels = ObjectDetectionLabels.make_empty()

        if extent is not None:
            labels = ObjectDetectionLabels.get_overlapping(
                labels, extent, ioa_thresh=0.8, clip=True)
        return labels

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 54:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 81%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag860')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label/tfod_utils/np_box_list.py: 31-49
</a>
<div class="mid" id="frag860" style="display:none"><pre>
  def __init__(self, data):
    """Constructs box collection.
    Args:
      data: a numpy array of shape [N, 4] representing box coordinates
    Raises:
      ValueError: if bbox data is not a numpy array
      ValueError: if invalid dimensions for bbox data
    """
    if not isinstance(data, np.ndarray):
      raise ValueError('data must be a numpy array.')
    if len(data.shape) != 2 or data.shape[1] != 4:
      raise ValueError('Invalid dimensions for box data.')
    if data.dtype != np.float32 and data.dtype != np.float64:
      raise ValueError('Invalid data type for box data: float is required.')
    if not self._is_valid_boxes(data):
      raise ValueError('Invalid box data. data must be a numpy array of '
                       'N*[y_min, x_min, y_max, x_max]')
    self.data = {'boxes': data}

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1790')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/label/tfod_utils/np_box_list.py: 30-49
</a>
<div class="mid" id="frag1790" style="display:none"><pre>
    def __init__(self, data):
        """Constructs box collection.
    Args:
      data: a numpy array of shape [N, 4] representing box coordinates
    Raises:
      ValueError: if bbox data is not a numpy array
      ValueError: if invalid dimensions for bbox data
    """
        if not isinstance(data, np.ndarray):
            raise ValueError('data must be a numpy array.')
        if len(data.shape) != 2 or data.shape[1] != 4:
            raise ValueError('Invalid dimensions for box data.')
        if data.dtype != np.float32 and data.dtype != np.float64:
            raise ValueError(
                'Invalid data type for box data: float is required.')
        if not self._is_valid_boxes(data):
            raise ValueError('Invalid box data. data must be a numpy array of '
                             'N*[y_min, x_min, y_max, x_max]')
        self.data = {'boxes': data}

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 55:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag873')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label/tfod_utils/np_box_list_ops.py: 84-114
</a>
<div class="mid" id="frag873" style="display:none"><pre>
def gather(boxlist, indices, fields=None):
  """Gather boxes from BoxList according to indices and return new BoxList.
  By default, gather returns boxes corresponding to the input index list, as
  well as all additional fields stored in the boxlist (indexing into the
  first dimension).  However one can optionally only gather from a
  subset of fields.
  Args:
    boxlist: BoxList holding N boxes
    indices: a 1-d numpy array of type int_
    fields: (optional) list of fields to also gather from.  If None (default),
        all fields are gathered from.  Pass an empty fields list to only gather
        the box coordinates.
  Returns:
    subboxlist: a BoxList corresponding to the subset of the input BoxList
        specified by indices
  Raises:
    ValueError: if specified field is not contained in boxlist or if the
        indices are not of type int_
  """
  if indices.size:
    if np.amax(indices) &gt;= boxlist.num_boxes() or np.amin(indices) &lt; 0:
      raise ValueError('indices are out of valid range.')
  subboxlist = np_box_list.BoxList(boxlist.get()[indices, :])
  if fields is None:
    fields = boxlist.get_extra_fields()
  for field in fields:
    extra_field_data = boxlist.get_field(field)
    subboxlist.add_field(field, extra_field_data[indices, ...])
  return subboxlist


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1803')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/label/tfod_utils/np_box_list_ops.py: 83-113
</a>
<div class="mid" id="frag1803" style="display:none"><pre>
def gather(boxlist, indices, fields=None):
    """Gather boxes from BoxList according to indices and return new BoxList.
  By default, gather returns boxes corresponding to the input index list, as
  well as all additional fields stored in the boxlist (indexing into the
  first dimension).  However one can optionally only gather from a
  subset of fields.
  Args:
    boxlist: BoxList holding N boxes
    indices: a 1-d numpy array of type int_
    fields: (optional) list of fields to also gather from.  If None (default),
        all fields are gathered from.  Pass an empty fields list to only gather
        the box coordinates.
  Returns:
    subboxlist: a BoxList corresponding to the subset of the input BoxList
        specified by indices
  Raises:
    ValueError: if specified field is not contained in boxlist or if the
        indices are not of type int_
  """
    if indices.size:
        if np.amax(indices) &gt;= boxlist.num_boxes() or np.amin(indices) &lt; 0:
            raise ValueError('indices are out of valid range.')
    subboxlist = np_box_list.BoxList(boxlist.get()[indices, :])
    if fields is None:
        fields = boxlist.get_extra_fields()
    for field in fields:
        extra_field_data = boxlist.get_field(field)
        subboxlist.add_field(field, extra_field_data[indices, ...])
    return subboxlist


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 56:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag874')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label/tfod_utils/np_box_list_ops.py: 115-141
</a>
<div class="mid" id="frag874" style="display:none"><pre>
def sort_by_field(boxlist, field, order=SortOrder.DESCEND):
  """Sort boxes and associated fields according to a scalar field.
  A common use case is reordering the boxes according to descending scores.
  Args:
    boxlist: BoxList holding N boxes.
    field: A BoxList field for sorting and reordering the BoxList.
    order: (Optional) 'descend' or 'ascend'. Default is descend.
  Returns:
    sorted_boxlist: A sorted BoxList with the field in the specified order.
  Raises:
    ValueError: if specified field does not exist or is not of single dimension.
    ValueError: if the order is not either descend or ascend.
  """
  if not boxlist.has_field(field):
    raise ValueError('Field ' + field + ' does not exist')
  if len(boxlist.get_field(field).shape) != 1:
    raise ValueError('Field ' + field + 'should be single dimension.')
  if order != SortOrder.DESCEND and order != SortOrder.ASCEND:
    raise ValueError('Invalid sort order')

  field_to_sort = boxlist.get_field(field)
  sorted_indices = np.argsort(field_to_sort)
  if order == SortOrder.DESCEND:
    sorted_indices = sorted_indices[::-1]
  return gather(boxlist, sorted_indices)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1804')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/label/tfod_utils/np_box_list_ops.py: 114-140
</a>
<div class="mid" id="frag1804" style="display:none"><pre>
def sort_by_field(boxlist, field, order=SortOrder.DESCEND):
    """Sort boxes and associated fields according to a scalar field.
  A common use case is reordering the boxes according to descending scores.
  Args:
    boxlist: BoxList holding N boxes.
    field: A BoxList field for sorting and reordering the BoxList.
    order: (Optional) 'descend' or 'ascend'. Default is descend.
  Returns:
    sorted_boxlist: A sorted BoxList with the field in the specified order.
  Raises:
    ValueError: if specified field does not exist or is not of single dimension.
    ValueError: if the order is not either descend or ascend.
  """
    if not boxlist.has_field(field):
        raise ValueError('Field ' + field + ' does not exist')
    if len(boxlist.get_field(field).shape) != 1:
        raise ValueError('Field ' + field + 'should be single dimension.')
    if order != SortOrder.DESCEND and order != SortOrder.ASCEND:
        raise ValueError('Invalid sort order')

    field_to_sort = boxlist.get_field(field)
    sorted_indices = np.argsort(field_to_sort)
    if order == SortOrder.DESCEND:
        sorted_indices = sorted_indices[::-1]
    return gather(boxlist, sorted_indices)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 57:</b> &nbsp; 2 fragments, nominal size 42 lines, similarity 95%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag875')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label/tfod_utils/np_box_list_ops.py: 142-212
</a>
<div class="mid" id="frag875" style="display:none"><pre>
def non_max_suppression(boxlist,
                        max_output_size=10000,
                        iou_threshold=1.0,
                        score_threshold=-10.0):
  """Non maximum suppression.
  This op greedily selects a subset of detection bounding boxes, pruning
  away boxes that have high IOU (intersection over union) overlap (&gt; thresh)
  with already selected boxes. In each iteration, the detected bounding box with
  highest score in the available pool is selected.
  Args:
    boxlist: BoxList holding N boxes.  Must contain a 'scores' field
      representing detection scores. All scores belong to the same class.
    max_output_size: maximum number of retained boxes
    iou_threshold: intersection over union threshold.
    score_threshold: minimum score threshold. Remove the boxes with scores
                     less than this value. Default value is set to -10. A very
                     low threshold to pass pretty much all the boxes, unless
                     the user sets a different score threshold.
  Returns:
    a BoxList holding M boxes where M &lt;= max_output_size
  Raises:
    ValueError: if 'scores' field does not exist
    ValueError: if threshold is not in [0, 1]
    ValueError: if max_output_size &lt; 0
  """
  if not boxlist.has_field('scores'):
    raise ValueError('Field scores does not exist')
  if iou_threshold &lt; 0. or iou_threshold &gt; 1.0:
    raise ValueError('IOU threshold must be in [0, 1]')
  if max_output_size &lt; 0:
    raise ValueError('max_output_size must be bigger than 0.')

  boxlist = filter_scores_greater_than(boxlist, score_threshold)
  if boxlist.num_boxes() == 0:
    return boxlist

  boxlist = sort_by_field(boxlist, 'scores')

  # Prevent further computation if NMS is disabled.
  if iou_threshold == 1.0:
    if boxlist.num_boxes() &gt; max_output_size:
      selected_indices = np.arange(max_output_size)
      return gather(boxlist, selected_indices)
    else:
      return boxlist

  boxes = boxlist.get()
  num_boxes = boxlist.num_boxes()
  # is_index_valid is True only for all remaining valid boxes,
  is_index_valid = np.full(num_boxes, 1, dtype=bool)
  selected_indices = []
  num_output = 0
  for i in range(num_boxes):
    if num_output &lt; max_output_size:
      if is_index_valid[i]:
        num_output += 1
        selected_indices.append(i)
        is_index_valid[i] = False
        valid_indices = np.where(is_index_valid)[0]
        if valid_indices.size == 0:
          break

        intersect_over_union = np_box_ops.iou(
            np.expand_dims(boxes[i, :], axis=0), boxes[valid_indices, :])
        intersect_over_union = np.squeeze(intersect_over_union, axis=0)
        is_index_valid[valid_indices] = np.logical_and(
            is_index_valid[valid_indices],
            intersect_over_union &lt;= iou_threshold)
  return gather(boxlist, np.array(selected_indices))


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1805')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/label/tfod_utils/np_box_list_ops.py: 141-212
</a>
<div class="mid" id="frag1805" style="display:none"><pre>
def non_max_suppression(boxlist,
                        max_output_size=10000,
                        iou_threshold=1.0,
                        score_threshold=-10.0):
    """Non maximum suppression.
  This op greedily selects a subset of detection bounding boxes, pruning
  away boxes that have high IOU (intersection over union) overlap (&gt; thresh)
  with already selected boxes. In each iteration, the detected bounding box with
  highest score in the available pool is selected.
  Args:
    boxlist: BoxList holding N boxes.  Must contain a 'scores' field
      representing detection scores. All scores belong to the same class.
    max_output_size: maximum number of retained boxes
    iou_threshold: intersection over union threshold.
    score_threshold: minimum score threshold. Remove the boxes with scores
                     less than this value. Default value is set to -10. A very
                     low threshold to pass pretty much all the boxes, unless
                     the user sets a different score threshold.
  Returns:
    a BoxList holding M boxes where M &lt;= max_output_size
  Raises:
    ValueError: if 'scores' field does not exist
    ValueError: if threshold is not in [0, 1]
    ValueError: if max_output_size &lt; 0
  """
    if not boxlist.has_field('scores'):
        raise ValueError('Field scores does not exist')
    if iou_threshold &lt; 0. or iou_threshold &gt; 1.0:
        raise ValueError('IOU threshold must be in [0, 1]')
    if max_output_size &lt; 0:
        raise ValueError('max_output_size must be bigger than 0.')

    boxlist = filter_scores_greater_than(boxlist, score_threshold)
    if boxlist.num_boxes() == 0:
        return boxlist

    boxlist = sort_by_field(boxlist, 'scores')

    # Prevent further computation if NMS is disabled.
    if iou_threshold == 1.0:
        if boxlist.num_boxes() &gt; max_output_size:
            selected_indices = np.arange(max_output_size)
            return gather(boxlist, selected_indices)
        else:
            return boxlist

    boxes = boxlist.get()
    num_boxes = boxlist.num_boxes()
    # is_index_valid is True only for all remaining valid boxes,
    is_index_valid = np.full(num_boxes, 1, dtype=bool)
    selected_indices = []
    num_output = 0
    for i in range(num_boxes):
        if num_output &lt; max_output_size:
            if is_index_valid[i]:
                num_output += 1
                selected_indices.append(i)
                is_index_valid[i] = False
                valid_indices = np.where(is_index_valid)[0]
                if valid_indices.size == 0:
                    break

                intersect_over_union = np_box_ops.iou(
                    np.expand_dims(boxes[i, :], axis=0),
                    boxes[valid_indices, :])
                intersect_over_union = np.squeeze(intersect_over_union, axis=0)
                is_index_valid[valid_indices] = np.logical_and(
                    is_index_valid[valid_indices],
                    intersect_over_union &lt;= iou_threshold)
    return gather(boxlist, np.array(selected_indices))


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 58:</b> &nbsp; 2 fragments, nominal size 40 lines, similarity 85%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag876')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label/tfod_utils/np_box_list_ops.py: 213-282
</a>
<div class="mid" id="frag876" style="display:none"><pre>
def multi_class_non_max_suppression(boxlist, score_thresh, iou_thresh,
                                    max_output_size):
  """Multi-class version of non maximum suppression.
  This op greedily selects a subset of detection bounding boxes, pruning
  away boxes that have high IOU (intersection over union) overlap (&gt; thresh)
  with already selected boxes.  It operates independently for each class for
  which scores are provided (via the scores field of the input box_list),
  pruning boxes with score less than a provided threshold prior to
  applying NMS.
  Args:
    boxlist: BoxList holding N boxes.  Must contain a 'scores' field
      representing detection scores.  This scores field is a tensor that can
      be 1 dimensional (in the case of a single class) or 2-dimensional, which
      which case we assume that it takes the shape [num_boxes, num_classes].
      We further assume that this rank is known statically and that
      scores.shape[1] is also known (i.e., the number of classes is fixed
      and known at graph construction time).
    score_thresh: scalar threshold for score (low scoring boxes are removed).
    iou_thresh: scalar threshold for IOU (boxes that that high IOU overlap
      with previously selected boxes are removed).
    max_output_size: maximum number of retained boxes per class.
  Returns:
    a BoxList holding M boxes with a rank-1 scores field representing
      corresponding scores for each box with scores sorted in decreasing order
      and a rank-1 classes field representing a class label for each box.
  Raises:
    ValueError: if iou_thresh is not in [0, 1] or if input boxlist does not have
      a valid scores field.
  """
  if not 0 &lt;= iou_thresh &lt;= 1.0:
    raise ValueError('thresh must be between 0 and 1')
  if not isinstance(boxlist, np_box_list.BoxList):
    raise ValueError('boxlist must be a BoxList')
  if not boxlist.has_field('scores'):
    raise ValueError('input boxlist must have \'scores\' field')
  scores = boxlist.get_field('scores')
  if len(scores.shape) == 1:
    scores = np.reshape(scores, [-1, 1])
  elif len(scores.shape) == 2:
    if scores.shape[1] is None:
      raise ValueError('scores field must have statically defined second '
                       'dimension')
  else:
    raise ValueError('scores field must be of rank 1 or 2')
  num_boxes = boxlist.num_boxes()
  num_scores = scores.shape[0]
  num_classes = scores.shape[1]

  if num_boxes != num_scores:
    raise ValueError('Incorrect scores field length: actual vs expected.')

  selected_boxes_list = []
  for class_idx in range(num_classes):
    boxlist_and_class_scores = np_box_list.BoxList(boxlist.get())
    class_scores = np.reshape(scores[0:num_scores, class_idx], [-1])
    boxlist_and_class_scores.add_field('scores', class_scores)
    boxlist_filt = filter_scores_greater_than(boxlist_and_class_scores,
                                              score_thresh)
    nms_result = non_max_suppression(boxlist_filt,
                                     max_output_size=max_output_size,
                                     iou_threshold=iou_thresh,
                                     score_threshold=score_thresh)
    nms_result.add_field(
        'classes', np.zeros_like(nms_result.get_field('scores')) + class_idx)
    selected_boxes_list.append(nms_result)
  selected_boxes = concatenate(selected_boxes_list)
  sorted_boxes = sort_by_field(selected_boxes, 'scores')
  return sorted_boxes


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1806')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/label/tfod_utils/np_box_list_ops.py: 213-285
</a>
<div class="mid" id="frag1806" style="display:none"><pre>
def multi_class_non_max_suppression(boxlist, score_thresh, iou_thresh,
                                    max_output_size):
    """Multi-class version of non maximum suppression.
  This op greedily selects a subset of detection bounding boxes, pruning
  away boxes that have high IOU (intersection over union) overlap (&gt; thresh)
  with already selected boxes.  It operates independently for each class for
  which scores are provided (via the scores field of the input box_list),
  pruning boxes with score less than a provided threshold prior to
  applying NMS.
  Args:
    boxlist: BoxList holding N boxes.  Must contain a 'scores' field
      representing detection scores.  This scores field is a tensor that can
      be 1 dimensional (in the case of a single class) or 2-dimensional, which
      which case we assume that it takes the shape [num_boxes, num_classes].
      We further assume that this rank is known statically and that
      scores.shape[1] is also known (i.e., the number of classes is fixed
      and known at graph construction time).
    score_thresh: scalar threshold for score (low scoring boxes are removed).
    iou_thresh: scalar threshold for IOU (boxes that that high IOU overlap
      with previously selected boxes are removed).
    max_output_size: maximum number of retained boxes per class.
  Returns:
    a BoxList holding M boxes with a rank-1 scores field representing
      corresponding scores for each box with scores sorted in decreasing order
      and a rank-1 classes field representing a class label for each box.
  Raises:
    ValueError: if iou_thresh is not in [0, 1] or if input boxlist does not have
      a valid scores field.
  """
    if not 0 &lt;= iou_thresh &lt;= 1.0:
        raise ValueError('thresh must be between 0 and 1')
    if not isinstance(boxlist, np_box_list.BoxList):
        raise ValueError('boxlist must be a BoxList')
    if not boxlist.has_field('scores'):
        raise ValueError('input boxlist must have \'scores\' field')
    scores = boxlist.get_field('scores')
    if len(scores.shape) == 1:
        scores = np.reshape(scores, [-1, 1])
    elif len(scores.shape) == 2:
        if scores.shape[1] is None:
            raise ValueError(
                'scores field must have statically defined second '
                'dimension')
    else:
        raise ValueError('scores field must be of rank 1 or 2')
    num_boxes = boxlist.num_boxes()
    num_scores = scores.shape[0]
    num_classes = scores.shape[1]

    if num_boxes != num_scores:
        raise ValueError('Incorrect scores field length: actual vs expected.')

    selected_boxes_list = []
    for class_idx in range(num_classes):
        boxlist_and_class_scores = np_box_list.BoxList(boxlist.get())
        class_scores = np.reshape(scores[0:num_scores, class_idx], [-1])
        boxlist_and_class_scores.add_field('scores', class_scores)
        boxlist_filt = filter_scores_greater_than(boxlist_and_class_scores,
                                                  score_thresh)
        nms_result = non_max_suppression(
            boxlist_filt,
            max_output_size=max_output_size,
            iou_threshold=iou_thresh,
            score_threshold=score_thresh)
        nms_result.add_field(
            'classes',
            np.zeros_like(nms_result.get_field('scores')) + class_idx)
        selected_boxes_list.append(nms_result)
    selected_boxes = concatenate(selected_boxes_list)
    sorted_boxes = sort_by_field(selected_boxes, 'scores')
    return sorted_boxes


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 59:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 84%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag877')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label/tfod_utils/np_box_list_ops.py: 283-306
</a>
<div class="mid" id="frag877" style="display:none"><pre>
def scale(boxlist, y_scale, x_scale):
  """Scale box coordinates in x and y dimensions.
  Args:
    boxlist: BoxList holding N boxes
    y_scale: float
    x_scale: float
  Returns:
    boxlist: BoxList holding N boxes
  """
  y_min, x_min, y_max, x_max = np.array_split(boxlist.get(), 4, axis=1)
  y_min = y_scale * y_min
  y_max = y_scale * y_max
  x_min = x_scale * x_min
  x_max = x_scale * x_max
  scaled_boxlist = np_box_list.BoxList(np.hstack([y_min, x_min, y_max, x_max]))

  fields = boxlist.get_extra_fields()
  for field in fields:
    extra_field_data = boxlist.get_field(field)
    scaled_boxlist.add_field(field, extra_field_data)

  return scaled_boxlist


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1807')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/label/tfod_utils/np_box_list_ops.py: 286-310
</a>
<div class="mid" id="frag1807" style="display:none"><pre>
def scale(boxlist, y_scale, x_scale):
    """Scale box coordinates in x and y dimensions.
  Args:
    boxlist: BoxList holding N boxes
    y_scale: float
    x_scale: float
  Returns:
    boxlist: BoxList holding N boxes
  """
    y_min, x_min, y_max, x_max = np.array_split(boxlist.get(), 4, axis=1)
    y_min = y_scale * y_min
    y_max = y_scale * y_max
    x_min = x_scale * x_min
    x_max = x_scale * x_max
    scaled_boxlist = np_box_list.BoxList(
        np.hstack([y_min, x_min, y_max, x_max]))

    fields = boxlist.get_extra_fields()
    for field in fields:
        extra_field_data = boxlist.get_field(field)
        scaled_boxlist.add_field(field, extra_field_data)

    return scaled_boxlist


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 60:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 77%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag878')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label/tfod_utils/np_box_list_ops.py: 307-337
</a>
<div class="mid" id="frag878" style="display:none"><pre>
def clip_to_window(boxlist, window):
  """Clip bounding boxes to a window.
  This op clips input bounding boxes (represented by bounding box
  corners) to a window, optionally filtering out boxes that do not
  overlap at all with the window.
  Args:
    boxlist: BoxList holding M_in boxes
    window: a numpy array of shape [4] representing the
            [y_min, x_min, y_max, x_max] window to which the op
            should clip boxes.
  Returns:
    a BoxList holding M_out boxes where M_out &lt;= M_in
  """
  y_min, x_min, y_max, x_max = np.array_split(boxlist.get(), 4, axis=1)
  win_y_min = window[0]
  win_x_min = window[1]
  win_y_max = window[2]
  win_x_max = window[3]
  y_min_clipped = np.fmax(np.fmin(y_min, win_y_max), win_y_min)
  y_max_clipped = np.fmax(np.fmin(y_max, win_y_max), win_y_min)
  x_min_clipped = np.fmax(np.fmin(x_min, win_x_max), win_x_min)
  x_max_clipped = np.fmax(np.fmin(x_max, win_x_max), win_x_min)
  clipped = np_box_list.BoxList(
      np.hstack([y_min_clipped, x_min_clipped, y_max_clipped, x_max_clipped]))
  clipped = _copy_extra_fields(clipped, boxlist)
  areas = area(clipped)
  nonzero_area_indices = np.reshape(np.nonzero(np.greater(areas, 0.0)),
                                    [-1]).astype(np.int32)
  return gather(clipped, nonzero_area_indices)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1808')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/label/tfod_utils/np_box_list_ops.py: 311-342
</a>
<div class="mid" id="frag1808" style="display:none"><pre>
def clip_to_window(boxlist, window):
    """Clip bounding boxes to a window.
  This op clips input bounding boxes (represented by bounding box
  corners) to a window, optionally filtering out boxes that do not
  overlap at all with the window.
  Args:
    boxlist: BoxList holding M_in boxes
    window: a numpy array of shape [4] representing the
            [y_min, x_min, y_max, x_max] window to which the op
            should clip boxes.
  Returns:
    a BoxList holding M_out boxes where M_out &lt;= M_in
  """
    y_min, x_min, y_max, x_max = np.array_split(boxlist.get(), 4, axis=1)
    win_y_min = window[0]
    win_x_min = window[1]
    win_y_max = window[2]
    win_x_max = window[3]
    y_min_clipped = np.fmax(np.fmin(y_min, win_y_max), win_y_min)
    y_max_clipped = np.fmax(np.fmin(y_max, win_y_max), win_y_min)
    x_min_clipped = np.fmax(np.fmin(x_min, win_x_max), win_x_min)
    x_max_clipped = np.fmax(np.fmin(x_max, win_x_max), win_x_min)
    clipped = np_box_list.BoxList(
        np.hstack([y_min_clipped, x_min_clipped, y_max_clipped,
                   x_max_clipped]))
    clipped = _copy_extra_fields(clipped, boxlist)
    areas = area(clipped)
    nonzero_area_indices = np.reshape(
        np.nonzero(np.greater(areas, 0.0)), [-1]).astype(np.int32)
    return gather(clipped, nonzero_area_indices)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 61:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 85%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag880')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label/tfod_utils/np_box_list_ops.py: 358-387
</a>
<div class="mid" id="frag880" style="display:none"><pre>
def prune_outside_window(boxlist, window):
  """Prunes bounding boxes that fall outside a given window.
  This function prunes bounding boxes that even partially fall outside the given
  window. See also ClipToWindow which only prunes bounding boxes that fall
  completely outside the window, and clips any bounding boxes that partially
  overflow.
  Args:
    boxlist: a BoxList holding M_in boxes.
    window: a numpy array of size 4, representing [ymin, xmin, ymax, xmax]
            of the window.
  Returns:
    pruned_corners: a tensor with shape [M_out, 4] where M_out &lt;= M_in.
    valid_indices: a tensor with shape [M_out] indexing the valid bounding boxes
     in the input tensor.
  """

  y_min, x_min, y_max, x_max = np.array_split(boxlist.get(), 4, axis=1)
  win_y_min = window[0]
  win_x_min = window[1]
  win_y_max = window[2]
  win_x_max = window[3]
  coordinate_violations = np.hstack([np.less(y_min, win_y_min),
                                     np.less(x_min, win_x_min),
                                     np.greater(y_max, win_y_max),
                                     np.greater(x_max, win_x_max)])
  valid_indices = np.reshape(
      np.where(np.logical_not(np.max(coordinate_violations, axis=1))), [-1])
  return gather(boxlist, valid_indices), valid_indices


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1810')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/label/tfod_utils/np_box_list_ops.py: 364-395
</a>
<div class="mid" id="frag1810" style="display:none"><pre>
def prune_outside_window(boxlist, window):
    """Prunes bounding boxes that fall outside a given window.
  This function prunes bounding boxes that even partially fall outside the given
  window. See also ClipToWindow which only prunes bounding boxes that fall
  completely outside the window, and clips any bounding boxes that partially
  overflow.
  Args:
    boxlist: a BoxList holding M_in boxes.
    window: a numpy array of size 4, representing [ymin, xmin, ymax, xmax]
            of the window.
  Returns:
    pruned_corners: a tensor with shape [M_out, 4] where M_out &lt;= M_in.
    valid_indices: a tensor with shape [M_out] indexing the valid bounding boxes
     in the input tensor.
  """

    y_min, x_min, y_max, x_max = np.array_split(boxlist.get(), 4, axis=1)
    win_y_min = window[0]
    win_x_min = window[1]
    win_y_max = window[2]
    win_x_max = window[3]
    coordinate_violations = np.hstack([
        np.less(y_min, win_y_min),
        np.less(x_min, win_x_min),
        np.greater(y_max, win_y_max),
        np.greater(x_max, win_x_max)
    ])
    valid_indices = np.reshape(
        np.where(np.logical_not(np.max(coordinate_violations, axis=1))), [-1])
    return gather(boxlist, valid_indices), valid_indices


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 62:</b> &nbsp; 2 fragments, nominal size 27 lines, similarity 85%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag881')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label/tfod_utils/np_box_list_ops.py: 388-433
</a>
<div class="mid" id="frag881" style="display:none"><pre>
def concatenate(boxlists, fields=None):
  """Concatenate list of BoxLists.
  This op concatenates a list of input BoxLists into a larger BoxList.  It also
  handles concatenation of BoxList fields as long as the field tensor shapes
  are equal except for the first dimension.
  Args:
    boxlists: list of BoxList objects
    fields: optional list of fields to also concatenate.  By default, all
      fields from the first BoxList in the list are included in the
      concatenation.
  Returns:
    a BoxList with number of boxes equal to
      sum([boxlist.num_boxes() for boxlist in BoxList])
  Raises:
    ValueError: if boxlists is invalid (i.e., is not a list, is empty, or
      contains non BoxList objects), or if requested fields are not contained in
      all boxlists
  """
  if not isinstance(boxlists, list):
    raise ValueError('boxlists should be a list')
  if not boxlists:
    raise ValueError('boxlists should have nonzero length')
  for boxlist in boxlists:
    if not isinstance(boxlist, np_box_list.BoxList):
      raise ValueError('all elements of boxlists should be BoxList objects')
  concatenated = np_box_list.BoxList(
      np.vstack([boxlist.get() for boxlist in boxlists]))
  if fields is None:
    fields = boxlists[0].get_extra_fields()
  for field in fields:
    first_field_shape = boxlists[0].get_field(field).shape
    first_field_shape = first_field_shape[1:]
    for boxlist in boxlists:
      if not boxlist.has_field(field):
        raise ValueError('boxlist must contain all requested fields')
      field_shape = boxlist.get_field(field).shape
      field_shape = field_shape[1:]
      if field_shape != first_field_shape:
        raise ValueError('field %s must have same shape for all boxlists '
                         'except for the 0th dimension.' % field)
    concatenated_field = np.concatenate(
        [boxlist.get_field(field) for boxlist in boxlists], axis=0)
    concatenated.add_field(field, concatenated_field)
  return concatenated


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1811')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/label/tfod_utils/np_box_list_ops.py: 396-443
</a>
<div class="mid" id="frag1811" style="display:none"><pre>
def concatenate(boxlists, fields=None):
    """Concatenate list of BoxLists.
  This op concatenates a list of input BoxLists into a larger BoxList.  It also
  handles concatenation of BoxList fields as long as the field tensor shapes
  are equal except for the first dimension.
  Args:
    boxlists: list of BoxList objects
    fields: optional list of fields to also concatenate.  By default, all
      fields from the first BoxList in the list are included in the
      concatenation.
  Returns:
    a BoxList with number of boxes equal to
      sum([boxlist.num_boxes() for boxlist in BoxList])
  Raises:
    ValueError: if boxlists is invalid (i.e., is not a list, is empty, or
      contains non BoxList objects), or if requested fields are not contained in
      all boxlists
  """
    if not isinstance(boxlists, list):
        raise ValueError('boxlists should be a list')
    if not boxlists:
        raise ValueError('boxlists should have nonzero length')
    for boxlist in boxlists:
        if not isinstance(boxlist, np_box_list.BoxList):
            raise ValueError(
                'all elements of boxlists should be BoxList objects')
    concatenated = np_box_list.BoxList(
        np.vstack([boxlist.get() for boxlist in boxlists]))
    if fields is None:
        fields = boxlists[0].get_extra_fields()
    for field in fields:
        first_field_shape = boxlists[0].get_field(field).shape
        first_field_shape = first_field_shape[1:]
        for boxlist in boxlists:
            if not boxlist.has_field(field):
                raise ValueError('boxlist must contain all requested fields')
            field_shape = boxlist.get_field(field).shape
            field_shape = field_shape[1:]
            if field_shape != first_field_shape:
                raise ValueError(
                    'field %s must have same shape for all boxlists '
                    'except for the 0th dimension.' % field)
        concatenated_field = np.concatenate(
            [boxlist.get_field(field) for boxlist in boxlists], axis=0)
        concatenated.add_field(field, concatenated_field)
    return concatenated


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 63:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 84%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag882')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label/tfod_utils/np_box_list_ops.py: 434-462
</a>
<div class="mid" id="frag882" style="display:none"><pre>
def filter_scores_greater_than(boxlist, thresh):
  """Filter to keep only boxes with score exceeding a given threshold.
  This op keeps the collection of boxes whose corresponding scores are
  greater than the input threshold.
  Args:
    boxlist: BoxList holding N boxes.  Must contain a 'scores' field
      representing detection scores.
    thresh: scalar threshold
  Returns:
    a BoxList holding M boxes where M &lt;= N
  Raises:
    ValueError: if boxlist not a BoxList object or if it does not
      have a scores field
  """
  if not isinstance(boxlist, np_box_list.BoxList):
    raise ValueError('boxlist must be a BoxList')
  if not boxlist.has_field('scores'):
    raise ValueError('input boxlist must have \'scores\' field')
  scores = boxlist.get_field('scores')
  if len(scores.shape) &gt; 2:
    raise ValueError('Scores should have rank 1 or 2')
  if len(scores.shape) == 2 and scores.shape[1] != 1:
    raise ValueError('Scores should have rank 1 or have shape '
                     'consistent with [None, 1]')
  high_score_indices = np.reshape(np.where(np.greater(scores, thresh)),
                                  [-1]).astype(np.int32)
  return gather(boxlist, high_score_indices)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1812')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/label/tfod_utils/np_box_list_ops.py: 444-472
</a>
<div class="mid" id="frag1812" style="display:none"><pre>
def filter_scores_greater_than(boxlist, thresh):
    """Filter to keep only boxes with score exceeding a given threshold.
  This op keeps the collection of boxes whose corresponding scores are
  greater than the input threshold.
  Args:
    boxlist: BoxList holding N boxes.  Must contain a 'scores' field
      representing detection scores.
    thresh: scalar threshold
  Returns:
    a BoxList holding M boxes where M &lt;= N
  Raises:
    ValueError: if boxlist not a BoxList object or if it does not
      have a scores field
  """
    if not isinstance(boxlist, np_box_list.BoxList):
        raise ValueError('boxlist must be a BoxList')
    if not boxlist.has_field('scores'):
        raise ValueError('input boxlist must have \'scores\' field')
    scores = boxlist.get_field('scores')
    if len(scores.shape) &gt; 2:
        raise ValueError('Scores should have rank 1 or 2')
    if len(scores.shape) == 2 and scores.shape[1] != 1:
        raise ValueError('Scores should have rank 1 or have shape '
                         'consistent with [None, 1]')
    high_score_indices = np.reshape(
        np.where(np.greater(scores, thresh)), [-1]).astype(np.int32)
    return gather(boxlist, high_score_indices)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 64:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag887')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label/tfod_utils/np_box_ops.py: 34-57
</a>
<div class="mid" id="frag887" style="display:none"><pre>
def intersection(boxes1, boxes2):
  """Compute pairwise intersection areas between boxes.
  Args:
    boxes1: a numpy array with shape [N, 4] holding N boxes
    boxes2: a numpy array with shape [M, 4] holding M boxes
  Returns:
    a numpy array with shape [N*M] representing pairwise intersection area
  """
  [y_min1, x_min1, y_max1, x_max1] = np.split(boxes1, 4, axis=1)
  [y_min2, x_min2, y_max2, x_max2] = np.split(boxes2, 4, axis=1)

  all_pairs_min_ymax = np.minimum(y_max1, np.transpose(y_max2))
  all_pairs_max_ymin = np.maximum(y_min1, np.transpose(y_min2))
  intersect_heights = np.maximum(
      np.zeros(all_pairs_max_ymin.shape),
      all_pairs_min_ymax - all_pairs_max_ymin)
  all_pairs_min_xmax = np.minimum(x_max1, np.transpose(x_max2))
  all_pairs_max_xmin = np.maximum(x_min1, np.transpose(x_min2))
  intersect_widths = np.maximum(
      np.zeros(all_pairs_max_xmin.shape),
      all_pairs_min_xmax - all_pairs_max_xmin)
  return intersect_heights * intersect_widths


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1817')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/label/tfod_utils/np_box_ops.py: 33-56
</a>
<div class="mid" id="frag1817" style="display:none"><pre>
def intersection(boxes1, boxes2):
    """Compute pairwise intersection areas between boxes.
  Args:
    boxes1: a numpy array with shape [N, 4] holding N boxes
    boxes2: a numpy array with shape [M, 4] holding M boxes
  Returns:
    a numpy array with shape [N*M] representing pairwise intersection area
  """
    [y_min1, x_min1, y_max1, x_max1] = np.split(boxes1, 4, axis=1)
    [y_min2, x_min2, y_max2, x_max2] = np.split(boxes2, 4, axis=1)

    all_pairs_min_ymax = np.minimum(y_max1, np.transpose(y_max2))
    all_pairs_max_ymin = np.maximum(y_min1, np.transpose(y_min2))
    intersect_heights = np.maximum(
        np.zeros(all_pairs_max_ymin.shape),
        all_pairs_min_ymax - all_pairs_max_ymin)
    all_pairs_min_xmax = np.minimum(x_max1, np.transpose(x_max2))
    all_pairs_max_xmin = np.maximum(x_min1, np.transpose(x_min2))
    intersect_widths = np.maximum(
        np.zeros(all_pairs_max_xmin.shape),
        all_pairs_min_xmax - all_pairs_max_xmin)
    return intersect_heights * intersect_widths


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 65:</b> &nbsp; 4 fragments, nominal size 11 lines, similarity 81%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag903')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label_store/chip_classification_geojson_store.py: 27-43
</a>
<div class="mid" id="frag903" style="display:none"><pre>
    def save(self, labels):
        """Save labels to URI if writable.

        Note that if the grid is inferred from polygons, only the grid will be
        written, not the original polygons.
        """
        boxes = labels.get_cells()
        class_ids = labels.get_class_ids()
        scores = list(labels.get_scores())
        geojson = boxes_to_geojson(
            boxes,
            class_ids,
            self.crs_transformer,
            self.class_map,
            scores=scores)
        json_to_file(geojson, self.uri)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1844')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/label_store/object_detection_geojson_store.py: 25-37
</a>
<div class="mid" id="frag1844" style="display:none"><pre>
    def save(self, labels):
        """Save labels to URI."""
        boxes = labels.get_boxes()
        class_ids = labels.get_class_ids().tolist()
        scores = labels.get_scores().tolist()
        geojson = boxes_to_geojson(
            boxes,
            class_ids,
            self.crs_transformer,
            self.class_config,
            scores=scores)
        json_to_file(geojson, self.uri)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag947')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label_store/object_detection_geojson_store.py: 23-35
</a>
<div class="mid" id="frag947" style="display:none"><pre>
    def save(self, labels):
        """Save labels to URI."""
        boxes = labels.get_boxes()
        class_ids = labels.get_class_ids().tolist()
        scores = labels.get_scores().tolist()
        geojson = boxes_to_geojson(
            boxes,
            class_ids,
            self.crs_transformer,
            self.class_map,
            scores=scores)
        json_to_file(geojson, self.uri)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1833')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/label_store/chip_classification_geojson_store.py: 26-42
</a>
<div class="mid" id="frag1833" style="display:none"><pre>
    def save(self, labels):
        """Save labels to URI if writable.

        Note that if the grid is inferred from polygons, only the grid will be
        written, not the original polygons.
        """
        boxes = labels.get_cells()
        class_ids = labels.get_class_ids()
        scores = list(labels.get_scores())
        geojson = boxes_to_geojson(
            boxes,
            class_ids,
            self.crs_transformer,
            self.class_config,
            scores=scores)
        json_to_file(geojson, self.uri)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 66:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag922')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label_store/object_detection_geojson_store_config.py: 27-44
</a>
<div class="mid" id="frag922" style="display:none"><pre>
                                           task_config.class_map)

    def update_for_command(self, command_type, experiment_config,
                           context=None):
        if command_type == rv.PREDICT:
            if not self.uri:
                # Construct the  URI for this prediction store,
                # using the scene ID.
                root = experiment_config.predict_uri
                uri = None
                for c in context:
                    if isinstance(c, rv.SceneConfig):
                        uri = os.path.join(root, '{}.json'.format(c.id))
                if uri:
                    self.uri = uri
                else:
                    raise rv.ConfigError(
                        'ObjectDetectionGeoJSONStoreConfig has no '
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag968')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label_store/chip_classification_geojson_store_config.py: 27-44
</a>
<div class="mid" id="frag968" style="display:none"><pre>
                                              task_config.class_map)

    def update_for_command(self, command_type, experiment_config,
                           context=None):
        if command_type == rv.PREDICT:
            if not self.uri:
                # Construct the  URI for this prediction store,
                # using the scene ID.
                root = experiment_config.predict_uri
                uri = None
                for c in context:
                    if isinstance(c, rv.SceneConfig):
                        uri = os.path.join(root, '{}.json'.format(c.id))
                if uri:
                    self.uri = uri
                else:
                    raise rv.ConfigError(
                        'ChipClassificationGeoJSONStoreConfig has no '
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 67:</b> &nbsp; 2 fragments, nominal size 19 lines, similarity 94%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag957')" href="javascript:;">
raster-vision-0.11.0/rastervision/data/label_store/semantic_segmentation_raster_store.py: 16-50
</a>
<div class="mid" id="frag957" style="display:none"><pre>
    def __init__(self,
                 uri,
                 extent,
                 crs_transformer,
                 tmp_dir,
                 vector_output=None,
                 class_map=None):
        """Constructor.

        Args:
            uri: (str) URI of GeoTIFF file used for storing predictions as RGB values
            extent: (Box) The extent of the scene
            crs_transformer: (CRSTransformer)
            tmp_dir: (str) temp directory to use
            vector_output: (None or array of dicts) containing vectorifiction
                configuration information
            class_map: (ClassMap) with color values used to convert class ids to
                RGB values

        """
        self.uri = uri
        self.vector_output = vector_output
        self.extent = extent
        self.crs_transformer = crs_transformer
        self.tmp_dir = tmp_dir
        # Note: can't name this class_transformer due to Python using that attribute
        if class_map:
            self.class_trans = SegmentationClassTransformer(class_map)
        else:
            self.class_trans = None

        self.source = None
        if file_exists(uri):
            self.source = rv.RasterSourceConfig.builder(rv.RASTERIO_SOURCE) \
                                               .with_uri(self.uri) \
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1847')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/data/label_store/semantic_segmentation_label_store.py: 19-52
</a>
<div class="mid" id="frag1847" style="display:none"><pre>
    def __init__(self,
                 uri,
                 extent,
                 crs_transformer,
                 tmp_dir,
                 vector_output=None,
                 class_config=None):
        """Constructor.

        Args:
            uri: (str) URI of GeoTIFF file used for storing predictions as RGB values
            extent: (Box) The extent of the scene
            crs_transformer: (CRSTransformer)
            tmp_dir: (str) temp directory to use
            vector_output: (None or array of VectorOutputConfig) containing
                vectorifiction configuration information
            class_config: (ClassConfig) with color values used to convert
                class ids to RGB value
        """
        self.uri = uri
        self.vector_output = vector_output
        self.extent = extent
        self.crs_transformer = crs_transformer
        self.tmp_dir = tmp_dir
        # Note: can't name this class_transformer due to Python using that attribute
        if class_config:
            self.class_trans = SegmentationClassTransformer(class_config)
        else:
            self.class_trans = None

        self.source = None
        if file_exists(uri):
            self.source = RasterioSourceConfig(uris=[uri]).build(tmp_dir)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 68:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag973')" href="javascript:;">
raster-vision-0.11.0/rastervision/utils/filter_geojson.py: 13-31
</a>
<div class="mid" id="frag973" style="display:none"><pre>
def filter_geojson(labels_uri, output_uri, class_names):
    """Remove features that aren't in class_names and remove class_ids."""
    labels_str = file_to_str(labels_uri)
    labels = json.loads(labels_str)
    filtered_features = []

    for feature in labels['features']:
        feature = copy.deepcopy(feature)
        properties = feature.get('properties')
        if properties:
            class_name = properties.get('class_name') or properties('label')
            if class_name in class_names:
                del properties['class_id']
                filtered_features.append(feature)

    new_labels = {'features': filtered_features}
    str_to_file(json.dumps(new_labels), output_uri)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1860')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/utils/filter_geojson.py: 13-31
</a>
<div class="mid" id="frag1860" style="display:none"><pre>
def filter_geojson(labels_uri, output_uri, class_names):
    """Remove features that aren't in class_names and remove class_ids."""
    labels_str = file_to_str(labels_uri)
    labels = json.loads(labels_str)
    filtered_features = []

    for feature in labels['features']:
        feature = copy.deepcopy(feature)
        properties = feature.get('properties')
        if properties:
            class_name = properties.get('class_name') or properties('label')
            if class_name in class_names:
                del properties['class_id']
                filtered_features.append(feature)

    new_labels = {'features': filtered_features}
    str_to_file(json.dumps(new_labels), output_uri)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 69:</b> &nbsp; 2 fragments, nominal size 73 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag987')" href="javascript:;">
raster-vision-0.11.0/rastervision/utils/zxy2geotiff.py: 51-161
</a>
<div class="mid" id="frag987" style="display:none"><pre>
def _zxy2geotiff(tile_schema, zoom, bounds, output_uri, make_cog=False):
    """Generates a GeoTIFF of a bounded region from a ZXY tile server.

    Args:
        tile_schema: (str) the URI schema for zxy tiles (ie. a slippy map tile server)
            of the form /tileserver-uri/{z}/{x}/{y}.png. If {-y} is used, the tiles
            are assumed to be indexed using TMS coordinates, where the y axis starts
            at the southernmost point. The URI can be for http, S3, or the local
            file system.
        zoom: (int) the zoom level to use when retrieving tiles
        bounds: (list) a list of length 4 containing min_lat, min_lng,
            max_lat, max_lng
        output_uri: (str) where to save the GeoTIFF. The URI can be for http, S3, or the
            local file system
    """
    min_lat, min_lng, max_lat, max_lng = bounds
    if min_lat &gt;= max_lat:
        raise ValueError('min_lat must be &lt; max_lat')
    if min_lng &gt;= max_lng:
        raise ValueError('min_lng must be &lt; max_lng')

    is_tms = False
    if '{-y}' in tile_schema:
        tile_schema = tile_schema.replace('{-y}', '{y}')
        is_tms = True

    tmp_dir_obj = tempfile.TemporaryDirectory()
    tmp_dir = tmp_dir_obj.name

    # Get range of tiles that cover bounds.
    output_path = get_local_path(output_uri, tmp_dir)
    tile_sz = 256
    t = mercantile.tile(min_lng, max_lat, zoom)
    xmin, ymin = t.x, t.y
    t = mercantile.tile(max_lng, min_lat, zoom)
    xmax, ymax = t.x, t.y

    # The supplied bounds are contained within the "tile bounds" -- ie. the
    # bounds of the set of tiles that covers the supplied bounds. Therefore,
    # we need to crop out the imagery that lies within the supplied bounds.
    # We do this by computing a top, bottom, left, and right offset in pixel
    # units of the supplied bounds against the tile bounds. Getting the offsets
    # in pixel units involves converting lng/lat to web mercator units since we
    # assume that is the CRS of the tiles. These offsets are then used to crop
    # individual tiles and place them correctly into the output raster.
    nw_merc_x, nw_merc_y = lnglat2merc(min_lng, max_lat)
    left_pix_offset, top_pix_offset = merc2pixel(xmin, ymin, zoom, nw_merc_x,
                                                 nw_merc_y)

    se_merc_x, se_merc_y = lnglat2merc(max_lng, min_lat)
    se_left_pix_offset, se_top_pix_offset = merc2pixel(xmax, ymax, zoom,
                                                       se_merc_x, se_merc_y)
    right_pix_offset = tile_sz - se_left_pix_offset
    bottom_pix_offset = tile_sz - se_top_pix_offset

    uncropped_height = tile_sz * (ymax - ymin + 1)
    uncropped_width = tile_sz * (xmax - xmin + 1)
    height = uncropped_height - top_pix_offset - bottom_pix_offset
    width = uncropped_width - left_pix_offset - right_pix_offset

    transform = rasterio.transform.from_bounds(nw_merc_x, se_merc_y, se_merc_x,
                                               nw_merc_y, width, height)
    with rasterio.open(
            output_path,
            'w',
            driver='GTiff',
            height=height,
            width=width,
            count=3,
            crs='epsg:3857',
            transform=transform,
            dtype=rasterio.uint8) as dataset:
        out_x = 0
        for xi, x in enumerate(range(xmin, xmax + 1)):
            tile_xmin, tile_xmax = 0, tile_sz - 1
            if x == xmin:
                tile_xmin += left_pix_offset
            if x == xmax:
                tile_xmax -= right_pix_offset
            window_width = tile_xmax - tile_xmin + 1

            out_y = 0
            for yi, y in enumerate(range(ymin, ymax + 1)):
                tile_ymin, tile_ymax = 0, tile_sz - 1
                if y == ymin:
                    tile_ymin += top_pix_offset
                if y == ymax:
                    tile_ymax -= bottom_pix_offset
                window_height = tile_ymax - tile_ymin + 1

                # Convert from xyz to tms if needed.
                # https://gist.github.com/tmcw/4954720
                if is_tms:
                    y = (2**zoom) - y - 1
                tile_uri = tile_schema.format(x=x, y=y, z=zoom)
                tile_path = download_if_needed(tile_uri, tmp_dir)
                img = np.array(Image.open(tile_path))
                img = img[tile_ymin:tile_ymax + 1, tile_xmin:tile_xmax + 1, :]

                window = Window(out_x, out_y, window_width, window_height)
                dataset.write(
                    np.transpose(img[:, :, 0:3], (2, 0, 1)), window=window)
                out_y += window_height
            out_x += window_width

    if make_cog:
        create_cog(output_path, output_uri, tmp_dir)
    else:
        upload_or_copy(output_path, output_uri)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1867')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/utils/zxy2geotiff.py: 51-161
</a>
<div class="mid" id="frag1867" style="display:none"><pre>
def _zxy2geotiff(tile_schema, zoom, bounds, output_uri, make_cog=False):
    """Generates a GeoTIFF of a bounded region from a ZXY tile server.

    Args:
        tile_schema: (str) the URI schema for zxy tiles (ie. a slippy map tile server)
            of the form /tileserver-uri/{z}/{x}/{y}.png. If {-y} is used, the tiles
            are assumed to be indexed using TMS coordinates, where the y axis starts
            at the southernmost point. The URI can be for http, S3, or the local
            file system.
        zoom: (int) the zoom level to use when retrieving tiles
        bounds: (list) a list of length 4 containing min_lat, min_lng,
            max_lat, max_lng
        output_uri: (str) where to save the GeoTIFF. The URI can be for http, S3, or the
            local file system
    """
    min_lat, min_lng, max_lat, max_lng = bounds
    if min_lat &gt;= max_lat:
        raise ValueError('min_lat must be &lt; max_lat')
    if min_lng &gt;= max_lng:
        raise ValueError('min_lng must be &lt; max_lng')

    is_tms = False
    if '{-y}' in tile_schema:
        tile_schema = tile_schema.replace('{-y}', '{y}')
        is_tms = True

    tmp_dir_obj = tempfile.TemporaryDirectory()
    tmp_dir = tmp_dir_obj.name

    # Get range of tiles that cover bounds.
    output_path = get_local_path(output_uri, tmp_dir)
    tile_sz = 256
    t = mercantile.tile(min_lng, max_lat, zoom)
    xmin, ymin = t.x, t.y
    t = mercantile.tile(max_lng, min_lat, zoom)
    xmax, ymax = t.x, t.y

    # The supplied bounds are contained within the "tile bounds" -- ie. the
    # bounds of the set of tiles that covers the supplied bounds. Therefore,
    # we need to crop out the imagery that lies within the supplied bounds.
    # We do this by computing a top, bottom, left, and right offset in pixel
    # units of the supplied bounds against the tile bounds. Getting the offsets
    # in pixel units involves converting lng/lat to web mercator units since we
    # assume that is the CRS of the tiles. These offsets are then used to crop
    # individual tiles and place them correctly into the output raster.
    nw_merc_x, nw_merc_y = lnglat2merc(min_lng, max_lat)
    left_pix_offset, top_pix_offset = merc2pixel(xmin, ymin, zoom, nw_merc_x,
                                                 nw_merc_y)

    se_merc_x, se_merc_y = lnglat2merc(max_lng, min_lat)
    se_left_pix_offset, se_top_pix_offset = merc2pixel(xmax, ymax, zoom,
                                                       se_merc_x, se_merc_y)
    right_pix_offset = tile_sz - se_left_pix_offset
    bottom_pix_offset = tile_sz - se_top_pix_offset

    uncropped_height = tile_sz * (ymax - ymin + 1)
    uncropped_width = tile_sz * (xmax - xmin + 1)
    height = uncropped_height - top_pix_offset - bottom_pix_offset
    width = uncropped_width - left_pix_offset - right_pix_offset

    transform = rasterio.transform.from_bounds(nw_merc_x, se_merc_y, se_merc_x,
                                               nw_merc_y, width, height)
    with rasterio.open(
            output_path,
            'w',
            driver='GTiff',
            height=height,
            width=width,
            count=3,
            crs='epsg:3857',
            transform=transform,
            dtype=rasterio.uint8) as dataset:
        out_x = 0
        for xi, x in enumerate(range(xmin, xmax + 1)):
            tile_xmin, tile_xmax = 0, tile_sz - 1
            if x == xmin:
                tile_xmin += left_pix_offset
            if x == xmax:
                tile_xmax -= right_pix_offset
            window_width = tile_xmax - tile_xmin + 1

            out_y = 0
            for yi, y in enumerate(range(ymin, ymax + 1)):
                tile_ymin, tile_ymax = 0, tile_sz - 1
                if y == ymin:
                    tile_ymin += top_pix_offset
                if y == ymax:
                    tile_ymax -= bottom_pix_offset
                window_height = tile_ymax - tile_ymin + 1

                # Convert from xyz to tms if needed.
                # https://gist.github.com/tmcw/4954720
                if is_tms:
                    y = (2**zoom) - y - 1
                tile_uri = tile_schema.format(x=x, y=y, z=zoom)
                tile_path = download_if_needed(tile_uri, tmp_dir)
                img = np.array(Image.open(tile_path))
                img = img[tile_ymin:tile_ymax + 1, tile_xmin:tile_xmax + 1, :]

                window = Window(out_x, out_y, window_width, window_height)
                dataset.write(
                    np.transpose(img[:, :, 0:3], (2, 0, 1)), window=window)
                out_y += window_height
            out_x += window_width

    if make_cog:
        create_cog(output_path, output_uri, tmp_dir)
    else:
        upload_or_copy(output_path, output_uri)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 70:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1045')" href="javascript:;">
raster-vision-0.11.0/rastervision/evaluation/semantic_segmentation_evaluation.py: 14-25
</a>
<div class="mid" id="frag1045" style="display:none"><pre>
def is_geojson(data):
    if isinstance(data, dict):
        return True
    else:
        try:
            json.loads(data)
            retval = True
        except ValueError:
            retval = False
        return retval


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1908')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/evaluation/semantic_segmentation_evaluation.py: 14-25
</a>
<div class="mid" id="frag1908" style="display:none"><pre>
def is_geojson(data):
    if isinstance(data, dict):
        return True
    else:
        try:
            json.loads(data)
            retval = True
        except ValueError:
            retval = False
        return retval


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 71:</b> &nbsp; 2 fragments, nominal size 28 lines, similarity 85%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1046')" href="javascript:;">
raster-vision-0.11.0/rastervision/evaluation/semantic_segmentation_evaluation.py: 26-58
</a>
<div class="mid" id="frag1046" style="display:none"><pre>
def get_class_eval_item(conf_mat, class_id, class_map):
    class_name = class_map.get_by_id(class_id).name

    if conf_mat.ravel().sum() == 0:
        return ClassEvaluationItem(None, None, None, 0, 0, class_id,
                                   class_name)

    true_pos = conf_mat[class_id, class_id]
    false_pos = conf_mat[1:, class_id].sum() - true_pos
    false_neg = conf_mat[class_id, :].sum() - true_pos
    precision = float(true_pos) / (true_pos + false_pos)
    recall = float(true_pos) / (true_pos + false_neg)
    f1 = 2 * (precision * recall) / (precision + recall)
    count_error = int(false_pos + false_neg)
    gt_count = conf_mat[class_id, :].sum()

    if math.isnan(precision):
        precision = None
    else:
        precision = float(precision)
    if math.isnan(recall):
        recall = None
    else:
        recall = float(recall)
    if math.isnan(f1):
        f1 = None
    else:
        f1 = float(f1)

    return ClassEvaluationItem(precision, recall, f1, count_error, gt_count,
                               class_id, class_name, conf_mat[class_id, :])


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1909')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/evaluation/semantic_segmentation_evaluation.py: 26-59
</a>
<div class="mid" id="frag1909" style="display:none"><pre>
def get_class_eval_item(conf_mat, class_id, class_name, null_class_id):
    if conf_mat.ravel().sum() == 0:
        return ClassEvaluationItem(None, None, None, 0, 0, class_id,
                                   class_name)

    non_null_class_ids = list(range(conf_mat.shape[0]))
    non_null_class_ids.remove(null_class_id)

    true_pos = conf_mat[class_id, class_id]
    false_pos = conf_mat[non_null_class_ids, class_id].sum() - true_pos
    false_neg = conf_mat[class_id, :].sum() - true_pos
    precision = float(true_pos) / (true_pos + false_pos)
    recall = float(true_pos) / (true_pos + false_neg)
    f1 = 2 * (precision * recall) / (precision + recall)
    count_error = int(false_pos + false_neg)
    gt_count = conf_mat[class_id, :].sum()

    if math.isnan(precision):
        precision = None
    else:
        precision = float(precision)
    if math.isnan(recall):
        recall = None
    else:
        recall = float(recall)
    if math.isnan(f1):
        f1 = None
    else:
        f1 = float(f1)

    return ClassEvaluationItem(precision, recall, f1, count_error, gt_count,
                               class_id, class_name, conf_mat[class_id, :])


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 72:</b> &nbsp; 2 fragments, nominal size 45 lines, similarity 95%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1049')" href="javascript:;">
raster-vision-0.11.0/rastervision/evaluation/semantic_segmentation_evaluation.py: 85-150
</a>
<div class="mid" id="frag1049" style="display:none"><pre>
    def compute_vector(self, gt, pred, mode, class_id):
        """Compute evaluation over vector predictions.
            Args:
                gt: Ground-truth GeoJSON.  Either a string (containing
                    unparsed GeoJSON or a file name), or a dictionary
                    containing parsed GeoJSON.
                pred: GeoJSON for predictions.  Either a string
                    (containing unparsed GeoJSON or a file name), or a
                    dictionary containing parsed GeoJSON.
                mode: A string containing either 'buildings' or
                    'polygons'.
                class_id: An integer containing the class id of
                    interest.
        """
        import mask_to_polygons.vectorification as vectorification
        import mask_to_polygons.processing.score as score

        # Ground truth as list of geometries
        def get_geoms(x):
            if is_geojson(x):
                _x = x
                if 'features' in _x.keys():
                    _x = _x['features']
                geoms = []
                for feature in _x:
                    if 'geometry' in feature.keys():
                        geoms.append(feature['geometry'])
                    else:
                        geoms.append(feature)
            else:
                geoms = vectorification.geometries_from_geojson(x)

            return geoms

        gt = get_geoms(gt)
        pred = get_geoms(pred)

        if len(gt) &gt; 0 and len(pred) &gt; 0:
            results = score.spacenet(pred, gt)

            true_positives = results['tp']
            false_positives = results['fp']
            false_negatives = results['fn']
            precision = float(true_positives) / (
                true_positives + false_positives)
            recall = float(true_positives) / (true_positives + false_negatives)
            if precision + recall != 0:
                f1 = 2 * (precision * recall) / (precision + recall)
            else:
                f1 = 0.0
            count_error = int(false_positives + false_negatives)
            gt_count = len(gt)
            class_name = 'vector-{}-{}'.format(
                mode,
                self.class_map.get_by_id(class_id).name)

            evaluation_item = ClassEvaluationItem(precision, recall, f1,
                                                  count_error, gt_count,
                                                  class_id, class_name)

            if hasattr(self, 'class_to_eval_item') and isinstance(
                    self.class_to_eval_item, dict):
                self.class_to_eval_item[class_id] = evaluation_item
            else:
                self.class_to_eval_item = {class_id: evaluation_item}
            self.compute_avg()
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1912')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/evaluation/semantic_segmentation_evaluation.py: 87-151
</a>
<div class="mid" id="frag1912" style="display:none"><pre>
    def compute_vector(self, gt, pred, mode, class_id):
        """Compute evaluation over vector predictions.
            Args:
                gt: Ground-truth GeoJSON.  Either a string (containing
                    unparsed GeoJSON or a file name), or a dictionary
                    containing parsed GeoJSON.
                pred: GeoJSON for predictions.  Either a string
                    (containing unparsed GeoJSON or a file name), or a
                    dictionary containing parsed GeoJSON.
                mode: A string containing either 'buildings' or
                    'polygons'.
                class_id: An integer containing the class id of
                    interest.
        """
        import mask_to_polygons.vectorification as vectorification
        import mask_to_polygons.processing.score as score

        # Ground truth as list of geometries
        def get_geoms(x):
            if is_geojson(x):
                _x = x
                if 'features' in _x.keys():
                    _x = _x['features']
                geoms = []
                for feature in _x:
                    if 'geometry' in feature.keys():
                        geoms.append(feature['geometry'])
                    else:
                        geoms.append(feature)
            else:
                geoms = vectorification.geometries_from_geojson(x)

            return geoms

        gt = get_geoms(gt)
        pred = get_geoms(pred)

        if len(gt) &gt; 0 and len(pred) &gt; 0:
            results = score.spacenet(pred, gt)

            true_positives = results['tp']
            false_positives = results['fp']
            false_negatives = results['fn']
            precision = float(true_positives) / (
                true_positives + false_positives)
            recall = float(true_positives) / (true_positives + false_negatives)
            if precision + recall != 0:
                f1 = 2 * (precision * recall) / (precision + recall)
            else:
                f1 = 0.0
            count_error = int(false_positives + false_negatives)
            gt_count = len(gt)
            class_name = 'vector-{}-{}'.format(
                mode, self.class_config.names[class_id])

            evaluation_item = ClassEvaluationItem(precision, recall, f1,
                                                  count_error, gt_count,
                                                  class_id, class_name)

            if hasattr(self, 'class_to_eval_item') and isinstance(
                    self.class_to_eval_item, dict):
                self.class_to_eval_item[class_id] = evaluation_item
            else:
                self.class_to_eval_item = {class_id: evaluation_item}
            self.compute_avg()
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 73:</b> &nbsp; 2 fragments, nominal size 26 lines, similarity 81%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1053')" href="javascript:;">
raster-vision-0.11.0/rastervision/evaluation/chip_classification_evaluation.py: 20-54
</a>
<div class="mid" id="frag1053" style="display:none"><pre>
    def compute_eval_items(gt_labels, pred_labels, class_map):
        nb_classes = len(class_map)
        class_to_eval_item = {}

        gt_class_ids = []
        pred_class_ids = []

        gt_cells = gt_labels.get_cells()
        for gt_cell in gt_cells:
            gt_class_id = gt_labels.get_cell_class_id(gt_cell)
            pred_class_id = pred_labels.get_cell_class_id(gt_cell)

            if gt_class_id is not None and pred_class_id is not None:
                gt_class_ids.append(gt_class_id)
                pred_class_ids.append(pred_class_id)

        # Add 1 because class_ids start at 1.
        sklabels = np.arange(1 + nb_classes)
        precision, recall, f1, support = metrics.precision_recall_fscore_support(
            gt_class_ids, pred_class_ids, labels=sklabels, warn_for=())

        for class_map_item in class_map.get_items():
            class_id = class_map_item.id
            class_name = class_map_item.name

            eval_item = ClassEvaluationItem(
                float(precision[class_id]),
                float(recall[class_id]),
                float(f1[class_id]),
                gt_count=float(support[class_id]),
                class_id=class_id,
                class_name=class_name)
            class_to_eval_item[class_id] = eval_item

        return class_to_eval_item
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1916')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/evaluation/chip_classification_evaluation.py: 20-50
</a>
<div class="mid" id="frag1916" style="display:none"><pre>
    def compute_eval_items(gt_labels, pred_labels, class_config):
        nb_classes = len(class_config.names)
        class_to_eval_item = {}

        gt_class_ids = []
        pred_class_ids = []

        gt_cells = gt_labels.get_cells()
        for gt_cell in gt_cells:
            gt_class_id = gt_labels.get_cell_class_id(gt_cell)
            pred_class_id = pred_labels.get_cell_class_id(gt_cell)

            if gt_class_id is not None and pred_class_id is not None:
                gt_class_ids.append(gt_class_id)
                pred_class_ids.append(pred_class_id)

        sklabels = np.arange(nb_classes)
        precision, recall, f1, support = metrics.precision_recall_fscore_support(
            gt_class_ids, pred_class_ids, labels=sklabels, warn_for=())

        for class_id, class_name in enumerate(class_config.names):
            eval_item = ClassEvaluationItem(
                float(precision[class_id]),
                float(recall[class_id]),
                float(f1[class_id]),
                gt_count=float(support[class_id]),
                class_id=class_id,
                class_name=class_name)
            class_to_eval_item[class_id] = eval_item

        return class_to_eval_item
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 74:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1056')" href="javascript:;">
raster-vision-0.11.0/rastervision/evaluation/classification_evaluator.py: 23-43
</a>
<div class="mid" id="frag1056" style="display:none"><pre>
    def process(self, scenes, tmp_dir):
        evaluation = self.create_evaluation()

        for scene in scenes:
            log.info('Computing evaluation for scene {}...'.format(scene.id))
            label_source = scene.ground_truth_label_source
            label_store = scene.prediction_label_store
            with ActivateMixin.compose(label_source, label_store):
                ground_truth = label_source.get_labels()
                predictions = label_store.get_labels()

                if scene.aoi_polygons:
                    # Filter labels based on AOI.
                    ground_truth = ground_truth.filter_by_aoi(
                        scene.aoi_polygons)
                    predictions = predictions.filter_by_aoi(scene.aoi_polygons)
                scene_evaluation = self.create_evaluation()
                scene_evaluation.compute(ground_truth, predictions)
                evaluation.merge(scene_evaluation, scene_id=scene.id)
        evaluation.save(self.output_uri)
        self.eval = evaluation
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1919')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/evaluation/classification_evaluator.py: 22-42
</a>
<div class="mid" id="frag1919" style="display:none"><pre>
    def process(self, scenes, tmp_dir):
        evaluation = self.create_evaluation()

        for scene in scenes:
            log.info('Computing evaluation for scene {}...'.format(scene.id))
            label_source = scene.ground_truth_label_source
            label_store = scene.prediction_label_store
            with ActivateMixin.compose(label_source, label_store):
                ground_truth = label_source.get_labels()
                predictions = label_store.get_labels()

                if scene.aoi_polygons:
                    # Filter labels based on AOI.
                    ground_truth = ground_truth.filter_by_aoi(
                        scene.aoi_polygons)
                    predictions = predictions.filter_by_aoi(scene.aoi_polygons)
                scene_evaluation = self.create_evaluation()
                scene_evaluation.compute(ground_truth, predictions)
                evaluation.merge(scene_evaluation, scene_id=scene.id)
        evaluation.save(self.output_uri)
        self.eval = evaluation
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 75:</b> &nbsp; 2 fragments, nominal size 36 lines, similarity 94%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1060')" href="javascript:;">
raster-vision-0.11.0/rastervision/evaluation/object_detection_evaluation.py: 11-55
</a>
<div class="mid" id="frag1060" style="display:none"><pre>
def compute_metrics(gt_labels: ObjectDetectionLabels,
                    pred_labels: ObjectDetectionLabels,
                    num_classes: int,
                    iou_thresh=0.5):
    gt_geoms = [b.to_shapely() for b in gt_labels.get_boxes()]
    gt_classes = gt_labels.get_class_ids() - 1
    pred_geoms = [b.to_shapely() for b in pred_labels.get_boxes()]
    pred_classes = pred_labels.get_class_ids() - 1

    for pred, class_id in zip(pred_geoms, pred_classes):
        pred.class_id = class_id
    pred_tree = shapely.strtree.STRtree(pred_geoms)

    def iou(a, b):
        return a.intersection(b).area / a.union(b).area

    def is_matched(geom):
        return hasattr(geom, 'iou_matched')

    tp = np.zeros((num_classes, ))
    fp = np.zeros((num_classes, ))
    fn = np.zeros((num_classes, ))

    for gt, gt_class in zip(gt_geoms, gt_classes):
        matches = list(
            filter(lambda g: (not is_matched(g)) and g.class_id == gt_class,
                   pred_tree.query(gt)))
        scores = [iou(m, gt) for m in matches]
        if len(scores) &gt; 0:
            max_ind = np.argmax(scores)
            if scores[max_ind] &gt; iou_thresh:
                matches[max_ind].iou_matched = True
                tp[gt_class] += 1
            else:
                fn[gt_class] += 1
        else:
            fn[gt_class] += 1

    for class_id in range(num_classes):
        pred_not_matched = np.array([not is_matched(g) for g in pred_geoms])
        fp[class_id] = np.sum(pred_not_matched[pred_classes == class_id])

    return tp, fp, fn


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1920')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/evaluation/object_detection_evaluation.py: 11-55
</a>
<div class="mid" id="frag1920" style="display:none"><pre>
def compute_metrics(gt_labels: ObjectDetectionLabels,
                    pred_labels: ObjectDetectionLabels,
                    num_classes: int,
                    iou_thresh=0.5):
    gt_geoms = [b.to_shapely() for b in gt_labels.get_boxes()]
    gt_classes = gt_labels.get_class_ids()
    pred_geoms = [b.to_shapely() for b in pred_labels.get_boxes()]
    pred_classes = pred_labels.get_class_ids()

    for pred, class_id in zip(pred_geoms, pred_classes):
        pred.class_id = class_id
    pred_tree = shapely.strtree.STRtree(pred_geoms)

    def iou(a, b):
        return a.intersection(b).area / a.union(b).area

    def is_matched(geom):
        return hasattr(geom, 'iou_matched')

    tp = np.zeros((num_classes, ))
    fp = np.zeros((num_classes, ))
    fn = np.zeros((num_classes, ))

    for gt, gt_class in zip(gt_geoms, gt_classes):
        matches = list(
            filter(lambda g: (not is_matched(g)) and g.class_id == gt_class,
                   pred_tree.query(gt)))
        scores = [iou(m, gt) for m in matches]
        if len(scores) &gt; 0:
            max_ind = np.argmax(scores)
            if scores[max_ind] &gt; iou_thresh:
                matches[max_ind].iou_matched = True
                tp[gt_class] += 1
            else:
                fn[gt_class] += 1
        else:
            fn[gt_class] += 1

    for class_id in range(num_classes):
        pred_not_matched = np.array([not is_matched(g) for g in pred_geoms])
        fp[class_id] = np.sum(pred_not_matched[pred_classes == class_id])

    return tp, fp, fn


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 76:</b> &nbsp; 2 fragments, nominal size 41 lines, similarity 95%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1065')" href="javascript:;">
raster-vision-0.11.0/rastervision/evaluation/object_detection_evaluation.py: 67-112
</a>
<div class="mid" id="frag1065" style="display:none"><pre>
    def compute_eval_items(gt_labels, pred_labels, class_map):
        iou_thresh = 0.5
        num_classes = len(class_map)
        tps, fps, fns = compute_metrics(gt_labels, pred_labels, num_classes,
                                        iou_thresh)
        class_to_eval_item = {}

        for class_ind, (tp, fp, fn) in enumerate(zip(tps, fps, fns)):
            class_id = class_ind + 1
            gt_count = tp + fn
            pred_count = tp + fp
            class_name = class_map.get_by_id(class_id).name

            if gt_count == 0:
                eval_item = ClassEvaluationItem(
                    class_id=class_id, class_name=class_name)
            elif pred_count == 0:
                eval_item = ClassEvaluationItem(
                    precision=None,
                    recall=0,
                    gt_count=gt_count,
                    class_id=class_id,
                    class_name=class_name)
            else:
                prec = tp / (tp + fp)
                recall = tp / (tp + fn)
                f1 = 0.
                if prec + recall != 0.0:
                    f1 = 2 * (prec * recall) / (prec + recall)
                count_err = pred_count - gt_count
                norm_count_err = None
                if gt_count &gt; 0:
                    norm_count_err = count_err / gt_count

                eval_item = ClassEvaluationItem(
                    precision=prec,
                    recall=recall,
                    f1=f1,
                    count_error=norm_count_err,
                    gt_count=gt_count,
                    class_id=class_id,
                    class_name=class_name)

            class_to_eval_item[class_id] = eval_item

        return class_to_eval_item
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1925')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/evaluation/object_detection_evaluation.py: 67-111
</a>
<div class="mid" id="frag1925" style="display:none"><pre>
    def compute_eval_items(gt_labels, pred_labels, class_config):
        iou_thresh = 0.5
        num_classes = len(class_config)
        tps, fps, fns = compute_metrics(gt_labels, pred_labels, num_classes,
                                        iou_thresh)
        class_to_eval_item = {}

        for class_id, (tp, fp, fn) in enumerate(zip(tps, fps, fns)):
            gt_count = tp + fn
            pred_count = tp + fp
            class_name = class_config.get_name(class_id)

            if gt_count == 0:
                eval_item = ClassEvaluationItem(
                    class_id=class_id, class_name=class_name)
            elif pred_count == 0:
                eval_item = ClassEvaluationItem(
                    precision=None,
                    recall=0,
                    gt_count=gt_count,
                    class_id=class_id,
                    class_name=class_name)
            else:
                prec = tp / (tp + fp)
                recall = tp / (tp + fn)
                f1 = 0.
                if prec + recall != 0.0:
                    f1 = 2 * (prec * recall) / (prec + recall)
                count_err = pred_count - gt_count
                norm_count_err = None
                if gt_count &gt; 0:
                    norm_count_err = count_err / gt_count

                eval_item = ClassEvaluationItem(
                    precision=prec,
                    recall=recall,
                    f1=f1,
                    count_error=norm_count_err,
                    gt_count=gt_count,
                    class_id=class_id,
                    class_name=class_name)

            class_to_eval_item[class_id] = eval_item

        return class_to_eval_item
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 77:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1077')" href="javascript:;">
raster-vision-0.11.0/rastervision/evaluation/semantic_segmentation_evaluator.py: 13-31
</a>
<div class="mid" id="frag1077" style="display:none"><pre>
def filter_geojson_by_aoi(geojson, aoi_polygons):
    # Note that this ignores class_id but that's ok because each prediction GeoJSON file
    # covers a single class_id. But, this may change in the future.
    tree = STRtree([shape(f['geometry']) for f in geojson['features']])
    filtered_shapes = []
    for aoi_poly in aoi_polygons:
        shapes_in_aoi = tree.query(aoi_poly)
        for s in shapes_in_aoi:
            s_int = s.intersection(aoi_poly)
            filtered_shapes.append(s_int)

    features = [{
        'type': 'feature',
        'geometry': mapping(s)
    } for s in filtered_shapes]

    return {'type': 'FeatureCollection', 'features': features}


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1926')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/evaluation/semantic_segmentation_evaluator.py: 14-32
</a>
<div class="mid" id="frag1926" style="display:none"><pre>
def filter_geojson_by_aoi(geojson, aoi_polygons):
    # Note that this ignores class_id but that's ok because each prediction GeoJSON file
    # covers a single class_id. But, this may change in the future.
    tree = STRtree([shape(f['geometry']) for f in geojson['features']])
    filtered_shapes = []
    for aoi_poly in aoi_polygons:
        shapes_in_aoi = tree.query(aoi_poly)
        for s in shapes_in_aoi:
            s_int = s.intersection(aoi_poly)
            filtered_shapes.append(s_int)

    features = [{
        'type': 'feature',
        'geometry': mapping(s)
    } for s in filtered_shapes]

    return {'type': 'FeatureCollection', 'features': features}


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 78:</b> &nbsp; 2 fragments, nominal size 45 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1080')" href="javascript:;">
raster-vision-0.11.0/rastervision/evaluation/semantic_segmentation_evaluator.py: 43-92
</a>
<div class="mid" id="frag1080" style="display:none"><pre>
    def process(self, scenes, tmp_dir):
        evaluation = self.create_evaluation()
        vect_evaluation = self.create_evaluation()

        for scene in scenes:
            log.info('Computing evaluation for scene {}...'.format(scene.id))
            label_source = scene.ground_truth_label_source
            label_store = scene.prediction_label_store
            with ActivateMixin.compose(label_source, label_store):
                ground_truth = label_source.get_labels()
                predictions = label_store.get_labels()

                if scene.aoi_polygons:
                    # Filter labels based on AOI.
                    ground_truth = ground_truth.filter_by_aoi(
                        scene.aoi_polygons)
                    predictions = predictions.filter_by_aoi(scene.aoi_polygons)
                scene_evaluation = self.create_evaluation()
                scene_evaluation.compute(ground_truth, predictions)
                evaluation.merge(scene_evaluation, scene_id=scene.id)

            if hasattr(label_source, 'source') and hasattr(
                    label_source.source, 'vector_source') and hasattr(
                        label_store, 'vector_output'):
                gt_geojson = label_source.source.vector_source.get_geojson()
                for vo in label_store.vector_output:
                    pred_geojson_uri = vo['uri']
                    mode = vo['mode']
                    class_id = vo['class_id']
                    pred_geojson_source = GeoJSONVectorSource(
                        pred_geojson_uri,
                        scene.raster_source.get_crs_transformer())
                    pred_geojson = pred_geojson_source.get_geojson()

                    if scene.aoi_polygons:
                        gt_geojson = filter_geojson_by_aoi(
                            gt_geojson, scene.aoi_polygons)
                        pred_geojson = filter_geojson_by_aoi(
                            pred_geojson, scene.aoi_polygons)

                    vect_scene_evaluation = self.create_evaluation()
                    vect_scene_evaluation.compute_vector(
                        gt_geojson, pred_geojson, mode, class_id)
                    vect_evaluation.merge(
                        vect_scene_evaluation, scene_id=scene.id)

        if not evaluation.is_empty():
            evaluation.save(self.output_uri)
        if not vect_evaluation.is_empty():
            vect_evaluation.save(self.vector_output_uri)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1929')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/evaluation/semantic_segmentation_evaluator.py: 44-97
</a>
<div class="mid" id="frag1929" style="display:none"><pre>
    def process(self, scenes, tmp_dir):
        evaluation = self.create_evaluation()
        vect_evaluation = self.create_evaluation()
        null_class_id = self.class_config.get_null_class_id()

        for scene in scenes:
            log.info('Computing evaluation for scene {}...'.format(scene.id))
            label_source = scene.ground_truth_label_source
            label_store = scene.prediction_label_store
            with ActivateMixin.compose(label_source, label_store):
                ground_truth = label_source.get_labels()
                predictions = label_store.get_labels()

                if scene.aoi_polygons:
                    # Filter labels based on AOI.
                    ground_truth = ground_truth.filter_by_aoi(
                        scene.aoi_polygons, null_class_id)
                    predictions = predictions.filter_by_aoi(
                        scene.aoi_polygons, null_class_id)
                scene_evaluation = self.create_evaluation()
                scene_evaluation.compute(ground_truth, predictions)
                evaluation.merge(scene_evaluation, scene_id=scene.id)

            if hasattr(label_source, 'raster_source') and hasattr(
                    label_source.raster_source, 'vector_source') and hasattr(
                        label_store, 'vector_output'):
                gt_geojson = label_source.raster_source.vector_source.get_geojson(
                )
                for vo in label_store.vector_output:
                    pred_geojson_uri = vo.uri
                    mode = vo.get_mode()
                    class_id = vo.class_id
                    pred_geojson_source = GeoJSONVectorSourceConfig(
                        uri=pred_geojson_uri, default_class_id=class_id).build(
                            self.class_config,
                            scene.raster_source.get_crs_transformer())
                    pred_geojson = pred_geojson_source.get_geojson()

                    if scene.aoi_polygons:
                        gt_geojson = filter_geojson_by_aoi(
                            gt_geojson, scene.aoi_polygons)
                        pred_geojson = filter_geojson_by_aoi(
                            pred_geojson, scene.aoi_polygons)

                    vect_scene_evaluation = self.create_evaluation()
                    vect_scene_evaluation.compute_vector(
                        gt_geojson, pred_geojson, mode, class_id)
                    vect_evaluation.merge(
                        vect_scene_evaluation, scene_id=scene.id)

        if not evaluation.is_empty():
            evaluation.save(self.output_uri)
        if not vect_evaluation.is_empty():
            vect_evaluation.save(self.vector_output_uri)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 79:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1102')" href="javascript:;">
raster-vision-0.11.0/rastervision/evaluation/classification_evaluation.py: 41-56
</a>
<div class="mid" id="frag1102" style="display:none"><pre>
    def to_json(self):
        json_rep = []
        for eval_item in self.class_to_eval_item.values():
            json_rep.append(eval_item.to_json())
        if self.avg_item:
            json_rep.append(self.avg_item.to_json())

        if self.scene_to_eval:
            json_rep = {'overall': json_rep}
            scene_to_eval_json = {}
            for scene_id, eval in self.scene_to_eval.items():
                scene_to_eval_json[scene_id] = eval.to_json()
            json_rep['per_scene'] = scene_to_eval_json

        return json_rep

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1944')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/evaluation/classification_evaluation.py: 41-56
</a>
<div class="mid" id="frag1944" style="display:none"><pre>
    def to_json(self):
        json_rep = []
        for eval_item in self.class_to_eval_item.values():
            json_rep.append(eval_item.to_json())
        if self.avg_item:
            json_rep.append(self.avg_item.to_json())

        if self.scene_to_eval:
            json_rep = {'overall': json_rep}
            scene_to_eval_json = {}
            for scene_id, eval in self.scene_to_eval.items():
                scene_to_eval_json[scene_id] = eval.to_json()
            json_rep['per_scene'] = scene_to_eval_json

        return json_rep

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 80:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1104')" href="javascript:;">
raster-vision-0.11.0/rastervision/evaluation/classification_evaluation.py: 66-89
</a>
<div class="mid" id="frag1104" style="display:none"><pre>
    def merge(self, evaluation, scene_id=None):
        """Merge Evaluation for another Scene into this one.

        This is useful for computing the average metrics of a set of scenes.
        The results of the averaging are stored in this Evaluation.

        Args:
            evaluation: Evaluation to merge into this one
        """
        if len(self.class_to_eval_item) == 0:
            self.class_to_eval_item = evaluation.class_to_eval_item
        else:
            for key, other_eval_item in \
                    evaluation.class_to_eval_item.items():
                if self.has_id(key):
                    self.get_by_id(key).merge(other_eval_item)
                else:
                    self.class_to_eval_item[key] = other_eval_item

        self._is_empty = False
        self.compute_avg()

        if scene_id is not None:
            self.scene_to_eval[scene_id] = copy.deepcopy(evaluation)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1946')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/evaluation/classification_evaluation.py: 66-89
</a>
<div class="mid" id="frag1946" style="display:none"><pre>
    def merge(self, evaluation, scene_id=None):
        """Merge Evaluation for another Scene into this one.

        This is useful for computing the average metrics of a set of scenes.
        The results of the averaging are stored in this Evaluation.

        Args:
            evaluation: Evaluation to merge into this one
        """
        if len(self.class_to_eval_item) == 0:
            self.class_to_eval_item = evaluation.class_to_eval_item
        else:
            for key, other_eval_item in \
                    evaluation.class_to_eval_item.items():
                if self.has_id(key):
                    self.get_by_id(key).merge(other_eval_item)
                else:
                    self.class_to_eval_item[key] = other_eval_item

        self._is_empty = False
        self.compute_avg()

        if scene_id is not None:
            self.scene_to_eval[scene_id] = copy.deepcopy(evaluation)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 81:</b> &nbsp; 2 fragments, nominal size 29 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1108')" href="javascript:;">
raster-vision-0.11.0/rastervision/evaluation/class_evaluation_item.py: 33-74
</a>
<div class="mid" id="frag1108" style="display:none"><pre>
    def merge(self, other):
        """Merges another item from a different scene into this one.

        This is used to average metrics over scenes. Merges by taking a
        weighted average (by gt_count) of the metrics.
        """
        if other.gt_count &gt; 0:
            total_gt_count = self.gt_count + other.gt_count
            self_ratio = self.gt_count / total_gt_count
            other_ratio = other.gt_count / total_gt_count

            def weighted_avg(self_val, other_val):
                if self_val is None and other_val is None:
                    return 0.0
                # Handle a single None value by setting them to zero.
                return (self_ratio * (self_val or 0) +
                        other_ratio * (other_val or 0))

            self.precision = weighted_avg(self.precision, other.precision)
            self.recall = weighted_avg(self.recall, other.recall)
            self.f1 = weighted_avg(self.f1, other.f1)
            self.count_error = weighted_avg(self.count_error,
                                            other.count_error)
            self.gt_count = total_gt_count

        if other.conf_mat is not None:
            if self.class_name == 'average':
                if self.conf_mat is None:
                    # Make first row all zeros so that the array indices
                    # correspond to valid class ids (ie. &gt;= 1).
                    self.conf_mat = np.concatenate(
                        [
                            np.zeros_like(other.conf_mat)[np.newaxis, :],
                            np.array(other.conf_mat)[np.newaxis, :]
                        ],
                        axis=0)
                else:
                    self.conf_mat = np.concatenate(
                        [self.conf_mat, other.conf_mat[np.newaxis, :]], axis=0)
            else:
                self.conf_mat += other.conf_mat

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1950')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/evaluation/class_evaluation_item.py: 33-74
</a>
<div class="mid" id="frag1950" style="display:none"><pre>
    def merge(self, other):
        """Merges another item from a different scene into this one.

        This is used to average metrics over scenes. Merges by taking a
        weighted average (by gt_count) of the metrics.
        """
        if other.gt_count &gt; 0:
            total_gt_count = self.gt_count + other.gt_count
            self_ratio = self.gt_count / total_gt_count
            other_ratio = other.gt_count / total_gt_count

            def weighted_avg(self_val, other_val):
                if self_val is None and other_val is None:
                    return 0.0
                # Handle a single None value by setting them to zero.
                return (self_ratio * (self_val or 0) +
                        other_ratio * (other_val or 0))

            self.precision = weighted_avg(self.precision, other.precision)
            self.recall = weighted_avg(self.recall, other.recall)
            self.f1 = weighted_avg(self.f1, other.f1)
            self.count_error = weighted_avg(self.count_error,
                                            other.count_error)
            self.gt_count = total_gt_count

        if other.conf_mat is not None:
            if self.class_name == 'average':
                if self.conf_mat is None:
                    # Make first row all zeros so that the array indices
                    # correspond to valid class ids (ie. &gt;= 1).
                    self.conf_mat = np.concatenate(
                        [
                            np.zeros_like(other.conf_mat)[np.newaxis, :],
                            np.array(other.conf_mat)[np.newaxis, :]
                        ],
                        axis=0)
                else:
                    self.conf_mat = np.concatenate(
                        [self.conf_mat, other.conf_mat[np.newaxis, :]], axis=0)
            else:
                self.conf_mat += other.conf_mat

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 82:</b> &nbsp; 2 fragments, nominal size 28 lines, similarity 77%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1119')" href="javascript:;">
raster-vision-0.11.0/rastervision/task/semantic_segmentation.py: 98-154
</a>
<div class="mid" id="frag1119" style="display:none"><pre>
    def make_chips(self, train_scenes, validation_scenes, augmentors, tmp_dir):
        """Make training chips.

        Convert Scenes with a ground_truth_label_store into training
        chips in MLBackend-specific format, and write to URI specified in
        options.

        Args:
            train_scenes: list of Scenes
            validation_scenes: list of Scenes
                (that is disjoint from train_scenes)
            augmentors: Augmentors used to augment training data
        """

        def _process_scene(scene, type_, augment):
            with scene.activate():
                data = TrainingData()
                log.info('Making {} chips for scene: {}'.format(
                    type_, scene.id))
                windows = self.get_train_windows(scene)
                for window in windows:
                    chip = scene.raster_source.get_chip(window)
                    labels = self.get_train_labels(window, scene)

                    # If chip has ignore labels, fill in those pixels with
                    # nodata.
                    label_arr = labels.get_label_arr(window)
                    zero_inds = label_arr.ravel() == 0
                    chip_shape = chip.shape
                    if np.any(zero_inds):
                        chip = np.reshape(chip, (-1, chip.shape[2]))
                        chip[zero_inds, :] = 0
                        chip = np.reshape(chip, chip_shape)

                    data.append(chip, window, labels)
                # Shuffle data so the first N samples which are displayed in
                # Tensorboard are more diverse.
                data.shuffle()

                # Process augmentation
                if augment:
                    for augmentor in augmentors:
                        data = augmentor.process(data, tmp_dir)

                return self.backend.process_scene_data(scene, data, tmp_dir)

        def _process_scenes(scenes, type_, augment):
            return [_process_scene(scene, type_, augment) for scene in scenes]

        processed_training_results = _process_scenes(
            train_scenes, TRAIN, augment=True)
        processed_validation_results = _process_scenes(
            validation_scenes, VALIDATION, augment=False)

        self.backend.process_sceneset_results(
            processed_training_results, processed_validation_results, tmp_dir)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1154')" href="javascript:;">
raster-vision-0.11.0/rastervision/task/task.py: 88-133
</a>
<div class="mid" id="frag1154" style="display:none"><pre>
    def make_chips(self, train_scenes, validation_scenes, augmentors, tmp_dir):
        """Make training chips.

        Convert Scenes with a ground_truth_label_store into training
        chips in MLBackend-specific format, and write to URI specified in
        options.

        Args:
            train_scenes: list of Scenes
            validation_scenes: list of Scenes
                (that is disjoint from train_scenes)
            augmentors: Augmentors used to augment training data
        """

        def _process_scene(scene, type_, augment):
            with scene.activate():
                data = TrainingData()
                log.info('Making {} chips for scene: {}'.format(
                    type_, scene.id))
                windows = self.get_train_windows(scene)
                for window in windows:
                    chip = scene.raster_source.get_chip(window)
                    labels = self.get_train_labels(window, scene)
                    data.append(chip, window, labels)
                # Shuffle data so the first N samples which are displayed in
                # Tensorboard are more diverse.
                data.shuffle()

                # Process augmentation
                if augment:
                    for augmentor in augmentors:
                        data = augmentor.process(data, tmp_dir)

                return self.backend.process_scene_data(scene, data, tmp_dir)

        def _process_scenes(scenes, type_, augment):
            return [_process_scene(scene, type_, augment) for scene in scenes]

        processed_training_results = _process_scenes(
            train_scenes, TRAIN, augment=True)
        processed_validation_results = _process_scenes(
            validation_scenes, VALIDATION, augment=False)

        self.backend.process_sceneset_results(
            processed_training_results, processed_validation_results, tmp_dir)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 83:</b> &nbsp; 2 fragments, nominal size 19 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1138')" href="javascript:;">
raster-vision-0.11.0/rastervision/task/object_detection.py: 11-41
</a>
<div class="mid" id="frag1138" style="display:none"><pre>
def _make_chip_pos_windows(image_extent, label_store, chip_size):
    chip_size = chip_size
    pos_windows = []
    boxes = label_store.get_labels().get_boxes()
    done_boxes = set()

    # Get a random window around each box. If a box was previously included
    # in a window, then it is skipped.
    for box in boxes:
        if box.tuple_format() not in done_boxes:
            # If this  object is bigger than the chip,
            # don't use this box.
            if chip_size &lt; box.get_width() or chip_size &lt; box.get_height():
                log.warning('Label is larger than chip size: {} '
                            'Skipping this label'.format(box.tuple_format()))
                continue

            window = box.make_random_square_container(chip_size)
            pos_windows.append(window)

            # Get boxes that lie completely within window
            window_boxes = label_store.get_labels(window=window)
            window_boxes = ObjectDetectionLabels.get_overlapping(
                window_boxes, window, ioa_thresh=1.0)
            window_boxes = window_boxes.get_boxes()
            window_boxes = [box.tuple_format() for box in window_boxes]
            done_boxes.update(window_boxes)

    return pos_windows


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1967')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/rv_pipeline/object_detection.py: 14-44
</a>
<div class="mid" id="frag1967" style="display:none"><pre>
def _make_chip_pos_windows(image_extent, label_store, chip_size):
    chip_size = chip_size
    pos_windows = []
    boxes = label_store.get_labels().get_boxes()
    done_boxes = set()

    # Get a random window around each box. If a box was previously included
    # in a window, then it is skipped.
    for box in boxes:
        if box.tuple_format() not in done_boxes:
            # If this  object is bigger than the chip,
            # don't use this box.
            if chip_size &lt; box.get_width() or chip_size &lt; box.get_height():
                log.warning('Label is larger than chip size: {} '
                            'Skipping this label'.format(box.tuple_format()))
                continue

            window = box.make_random_square_container(chip_size)
            pos_windows.append(window)

            # Get boxes that lie completely within window
            window_boxes = label_store.get_labels(window=window)
            window_boxes = ObjectDetectionLabels.get_overlapping(
                window_boxes, window, ioa_thresh=1.0)
            window_boxes = window_boxes.get_boxes()
            window_boxes = [box.tuple_format() for box in window_boxes]
            done_boxes.update(window_boxes)

    return pos_windows


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 84:</b> &nbsp; 2 fragments, nominal size 17 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1141')" href="javascript:;">
raster-vision-0.11.0/rastervision/task/object_detection.py: 61-83
</a>
<div class="mid" id="frag1141" style="display:none"><pre>
def make_neg_windows(raster_source, label_store, chip_size, nb_windows,
                     max_attempts, filter_windows):
    extent = raster_source.get_extent()
    neg_windows = []
    for _ in range(max_attempts):
        for _ in range(max_attempts):
            window = extent.make_random_square(chip_size)
            if any(filter_windows([window])):
                break
        chip = raster_source.get_chip(window)
        labels = ObjectDetectionLabels.get_overlapping(
            label_store.get_labels(), window, ioa_thresh=0.2)

        # If no labels and not blank, append the chip
        if len(labels) == 0 and np.sum(chip.ravel()) &gt; 0:
            neg_windows.append(window)

        if len(neg_windows) == nb_windows:
            break

    return list(neg_windows)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1970')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/rv_pipeline/object_detection.py: 64-86
</a>
<div class="mid" id="frag1970" style="display:none"><pre>
def make_neg_windows(raster_source, label_store, chip_size, nb_windows,
                     max_attempts, filter_windows):
    extent = raster_source.get_extent()
    neg_windows = []
    for _ in range(max_attempts):
        for _ in range(max_attempts):
            window = extent.make_random_square(chip_size)
            if any(filter_windows([window])):
                break
        chip = raster_source.get_chip(window)
        labels = ObjectDetectionLabels.get_overlapping(
            label_store.get_labels(), window, ioa_thresh=0.2)

        # If no labels and not blank, append the chip
        if len(labels) == 0 and np.sum(chip.ravel()) &gt; 0:
            neg_windows.append(window)

        if len(neg_windows) == nb_windows:
            break

    return list(neg_windows)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 85:</b> &nbsp; 2 fragments, nominal size 21 lines, similarity 80%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1166')" href="javascript:;">
raster-vision-0.11.0/rastervision/task/semantic_segmentation_config.py: 56-80
</a>
<div class="mid" id="frag1166" style="display:none"><pre>
    def to_proto(self):
        msg = super().to_proto()
        chip_options = TaskConfigMsg.SemanticSegmentationConfig.ChipOptions(
            window_method=self.chip_options.window_method,
            target_classes=self.chip_options.target_classes,
            debug_chip_probability=self.chip_options.debug_chip_probability,
            negative_survival_probability=self.chip_options.
            negative_survival_probability,
            chips_per_scene=self.chip_options.chips_per_scene,
            target_count_threshold=self.chip_options.target_count_threshold,
            stride=self.chip_options.stride)

        conf = TaskConfigMsg.SemanticSegmentationConfig(
            chip_size=self.chip_size,
            predict_chip_size=self.predict_chip_size,
            class_items=self.class_map.to_proto(),
            chip_options=chip_options)
        msg.MergeFrom(
            TaskConfigMsg(
                semantic_segmentation_config=conf,
                predict_package_uri=self.predict_package_uri))

        return msg


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1191')" href="javascript:;">
raster-vision-0.11.0/rastervision/task/object_detection_config.py: 48-71
</a>
<div class="mid" id="frag1191" style="display:none"><pre>
    def to_proto(self):
        msg = super().to_proto()
        chip_options = TaskConfigMsg.ObjectDetectionConfig.ChipOptions(
            neg_ratio=self.chip_options.neg_ratio,
            ioa_thresh=self.chip_options.ioa_thresh,
            window_method=self.chip_options.window_method,
            label_buffer=self.chip_options.label_buffer)

        predict_options = TaskConfigMsg.ObjectDetectionConfig.PredictOptions(
            merge_thresh=self.predict_options.merge_thresh,
            score_thresh=self.predict_options.score_thresh)

        conf = TaskConfigMsg.ObjectDetectionConfig(
            chip_size=self.chip_size,
            class_items=self.class_map.to_proto(),
            chip_options=chip_options,
            predict_options=predict_options)
        msg.MergeFrom(
            TaskConfigMsg(
                object_detection_config=conf,
                predict_package_uri=self.predict_package_uri))

        return msg

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 86:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 92%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1202')" href="javascript:;">
raster-vision-0.11.0/rastervision/task/chip_classification.py: 32-45
</a>
<div class="mid" id="frag1202" style="display:none"><pre>
    def get_train_windows(self, scene):
        result = []
        extent = scene.raster_source.get_extent()
        chip_size = self.config.chip_size
        stride = chip_size
        windows = extent.get_windows(chip_size, stride)
        if scene.aoi_polygons:
            windows = Box.filter_by_aoi(windows, scene.aoi_polygons)
        for window in windows:
            chip = scene.raster_source.get_chip(window)
            if np.sum(chip.ravel()) &gt; 0:
                result.append(window)
        return result

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1977')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/rv_pipeline/chip_classification.py: 11-24
</a>
<div class="mid" id="frag1977" style="display:none"><pre>
def get_train_windows(scene, chip_size):
    train_windows = []
    extent = scene.raster_source.get_extent()
    stride = chip_size
    windows = extent.get_windows(chip_size, stride)
    if scene.aoi_polygons:
        windows = Box.filter_by_aoi(windows, scene.aoi_polygons)
    for window in windows:
        chip = scene.raster_source.get_chip(window)
        if np.sum(chip.ravel()) &gt; 0:
            train_windows.append(window)
    return train_windows


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 87:</b> &nbsp; 2 fragments, nominal size 48 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1225')" href="javascript:;">
raster-vision-0.11.0/rastervision/core/raster_stats.py: 59-137
</a>
<div class="mid" id="frag1225" style="display:none"><pre>
    def compute(self, raster_sources, sample_prob=None):
        """Compute the mean and stds over all the raster_sources.

        This ignores NODATA values.

        If sample_prob is set, then a subset of each scene is used to compute stats which
        speeds up the computation. Roughly speaking, if sample_prob=0.5, then half the
        pixels in the scene will be used. More precisely, the number of chips is equal to
        sample_prob * (width * height / 300^2), or 1, whichever is greater. Each chip is
        uniformly sampled from the scene with replacement. Otherwise, it uses a sliding
        window over the entire scene to compute stats.

        Args:
            raster_sources: list of RasterSource
            sample_prob: (float or None) between 0 and 1
        """
        stride = chip_size
        nb_channels = raster_sources[0].num_channels

        def get_chip(raster_source, window):
            """Return chip or None if all values are NODATA."""
            chip = raster_source.get_raw_chip(window).astype(np.float32)
            # Convert shape from [h,w,c] to [c,h*w]
            chip = np.reshape(np.transpose(chip, [2, 0, 1]), (nb_channels, -1))

            # Ignore NODATA values.
            chip[chip == 0.0] = np.nan
            if np.any(~np.isnan(chip)):
                return chip
            return None

        def sliding_chip_stream():
            """Get stream of chips using a sliding window of size 300."""
            for raster_source in raster_sources:
                with raster_source.activate():
                    windows = raster_source.get_extent().get_windows(
                        chip_size, stride)
                    for window in windows:
                        chip = get_chip(raster_source, window)
                        if chip is not None:
                            yield chip

        def random_chip_stream():
            """Get random stream of chips."""
            for raster_source in raster_sources:
                with raster_source.activate():
                    extent = raster_source.get_extent()
                    num_pixels = extent.get_width() * extent.get_height()
                    num_chips = round(
                        sample_prob * (num_pixels / (chip_size**2)))
                    num_chips = max(1, num_chips)
                    for _ in range(num_chips):
                        window = raster_source.get_extent().make_random_square(
                            chip_size)
                        chip = get_chip(raster_source, window)
                        if chip is not None:
                            yield chip

        # For each chip, compute the mean and var of that chip and then update the
        # running mean and var.
        count = 0
        mean = np.zeros((nb_channels, ))
        var = np.zeros((nb_channels, ))
        chip_stream = (sliding_chip_stream()
                       if sample_prob is None else random_chip_stream())

        for c in chip_stream:
            chip_means = np.nanmean(c, axis=1)
            chip_vars = np.nanvar(c, axis=1)
            chip_count = np.sum(c[0] != np.nan)

            var = parallel_variance(chip_means, chip_count, chip_vars, mean,
                                    count, var)
            mean = parallel_mean(chip_means, chip_count, mean, count)
            count += chip_count

        self.means = mean
        self.stds = np.sqrt(var)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1615')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/raster_stats.py: 59-137
</a>
<div class="mid" id="frag1615" style="display:none"><pre>
    def compute(self, raster_sources, sample_prob=None):
        """Compute the mean and stds over all the raster_sources.

        This ignores NODATA values.

        If sample_prob is set, then a subset of each scene is used to compute stats which
        speeds up the computation. Roughly speaking, if sample_prob=0.5, then half the
        pixels in the scene will be used. More precisely, the number of chips is equal to
        sample_prob * (width * height / 300^2), or 1, whichever is greater. Each chip is
        uniformly sampled from the scene with replacement. Otherwise, it uses a sliding
        window over the entire scene to compute stats.

        Args:
            raster_sources: list of RasterSource
            sample_prob: (float or None) between 0 and 1
        """
        stride = chip_sz
        nb_channels = raster_sources[0].num_channels

        def get_chip(raster_source, window):
            """Return chip or None if all values are NODATA."""
            chip = raster_source.get_raw_chip(window).astype(np.float32)
            # Convert shape from [h,w,c] to [c,h*w]
            chip = np.reshape(np.transpose(chip, [2, 0, 1]), (nb_channels, -1))

            # Ignore NODATA values.
            chip[chip == 0.0] = np.nan
            if np.any(~np.isnan(chip)):
                return chip
            return None

        def sliding_chip_stream():
            """Get stream of chips using a sliding window of size 300."""
            for raster_source in raster_sources:
                with raster_source.activate():
                    windows = raster_source.get_extent().get_windows(
                        chip_sz, stride)
                    for window in windows:
                        chip = get_chip(raster_source, window)
                        if chip is not None:
                            yield chip

        def random_chip_stream():
            """Get random stream of chips."""
            for raster_source in raster_sources:
                with raster_source.activate():
                    extent = raster_source.get_extent()
                    num_pixels = extent.get_width() * extent.get_height()
                    num_chips = round(
                        sample_prob * (num_pixels / (chip_sz**2)))
                    num_chips = max(1, num_chips)
                    for _ in range(num_chips):
                        window = raster_source.get_extent().make_random_square(
                            chip_sz)
                        chip = get_chip(raster_source, window)
                        if chip is not None:
                            yield chip

        # For each chip, compute the mean and var of that chip and then update the
        # running mean and var.
        count = 0
        mean = np.zeros((nb_channels, ))
        var = np.zeros((nb_channels, ))
        chip_stream = (sliding_chip_stream()
                       if sample_prob is None else random_chip_stream())

        for c in chip_stream:
            chip_means = np.nanmean(c, axis=1)
            chip_vars = np.nanvar(c, axis=1)
            chip_count = np.sum(c[0] != np.nan)

            var = parallel_variance(chip_means, chip_count, chip_vars, mean,
                                    count, var)
            mean = parallel_mean(chip_means, chip_count, mean, count)
            count += chip_count

        self.means = mean
        self.stds = np.sqrt(var)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 88:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1275')" href="javascript:;">
raster-vision-0.11.0/rastervision/core/box.py: 102-124
</a>
<div class="mid" id="frag1275" style="display:none"><pre>
    def make_random_square_container(self, size):
        """Return a new square Box that contains this Box.

        Args:
            size: the width and height of the new Box

        """
        if size &lt; self.get_width():
            raise BoxSizeError('size of random container cannot be &lt; width')

        if size &lt; self.get_height():  # pragma: no cover
            raise BoxSizeError('size of random container cannot be &lt; height')

        lb = self.ymin - (size - self.get_height())
        ub = self.ymin
        rand_y = random.randint(int(lb), int(ub))

        lb = self.xmin - (size - self.get_width())
        ub = self.xmin
        rand_x = random.randint(int(lb), int(ub))

        return Box.make_square(rand_y, rand_x, size)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1888')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/box.py: 102-124
</a>
<div class="mid" id="frag1888" style="display:none"><pre>
    def make_random_square_container(self, size):
        """Return a new square Box that contains this Box.

        Args:
            size: the width and height of the new Box

        """
        if size &lt; self.get_width():
            raise BoxSizeError('size of random container cannot be &lt; width')

        if size &lt; self.get_height():  # pragma: no cover
            raise BoxSizeError('size of random container cannot be &lt; height')

        lb = self.ymin - (size - self.get_height())
        ub = self.ymin
        rand_y = random.randint(int(lb), int(ub))

        lb = self.xmin - (size - self.get_width())
        ub = self.xmin
        rand_x = random.randint(int(lb), int(ub))

        return Box.make_square(rand_y, rand_x, size)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 89:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1276')" href="javascript:;">
raster-vision-0.11.0/rastervision/core/box.py: 125-147
</a>
<div class="mid" id="frag1276" style="display:none"><pre>
    def make_random_square(self, size):
        """Return new randomly positioned square Box that lies inside this Box.

        Args:
            size: the height and width of the new Box

        """
        if size &gt;= self.get_width():
            raise BoxSizeError('size of random square cannot be &gt;= width')

        if size &gt;= self.get_height():  # pragma: no cover
            raise BoxSizeError('size of random square cannot be &gt;= height')

        lb = self.ymin
        ub = self.ymax - size
        rand_y = random.randint(int(lb), int(ub))

        lb = self.xmin
        ub = self.xmax - size
        rand_x = random.randint(int(lb), int(ub))

        return Box.make_square(rand_y, rand_x, size)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1889')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/box.py: 125-147
</a>
<div class="mid" id="frag1889" style="display:none"><pre>
    def make_random_square(self, size):
        """Return new randomly positioned square Box that lies inside this Box.

        Args:
            size: the height and width of the new Box

        """
        if size &gt;= self.get_width():
            raise BoxSizeError('size of random square cannot be &gt;= width')

        if size &gt;= self.get_height():  # pragma: no cover
            raise BoxSizeError('size of random square cannot be &gt;= height')

        lb = self.ymin
        ub = self.ymax - size
        rand_y = random.randint(int(lb), int(ub))

        lb = self.xmin
        ub = self.xmax - size
        rand_x = random.randint(int(lb), int(ub))

        return Box.make_square(rand_y, rand_x, size)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 90:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1285')" href="javascript:;">
raster-vision-0.11.0/rastervision/core/box.py: 214-236
</a>
<div class="mid" id="frag1285" style="display:none"><pre>
    def make_buffer(self, buffer_size, max_extent):
        """Return new Box whose sides are buffered by buffer_size.

        The resulting box is clipped so that the values of the corners are
        always greater than zero and less than the height and width of
        max_extent.

        """
        buffer_size = max(0., buffer_size)
        if buffer_size &lt; 1.:
            delta_width = int(round(buffer_size * self.get_width()))
            delta_height = int(round(buffer_size * self.get_height()))
        else:
            delta_height = delta_width = int(round(buffer_size))

        return Box(
            max(0, math.floor(self.ymin - delta_height)),
            max(0, math.floor(self.xmin - delta_width)),
            min(max_extent.get_height(),
                int(self.ymax) + delta_height),
            min(max_extent.get_width(),
                int(self.xmax) + delta_width))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1898')" href="javascript:;">
raster-vision-0.11.0/rastervision2/core/box.py: 214-236
</a>
<div class="mid" id="frag1898" style="display:none"><pre>
    def make_buffer(self, buffer_sz, max_extent):
        """Return new Box whose sides are buffered by buffer_sz.

        The resulting box is clipped so that the values of the corners are
        always greater than zero and less than the height and width of
        max_extent.

        """
        buffer_sz = max(0., buffer_sz)
        if buffer_sz &lt; 1.:
            delta_width = int(round(buffer_sz * self.get_width()))
            delta_height = int(round(buffer_sz * self.get_height()))
        else:
            delta_height = delta_width = int(round(buffer_sz))

        return Box(
            max(0, math.floor(self.ymin - delta_height)),
            max(0, math.floor(self.xmin - delta_width)),
            min(max_extent.get_height(),
                int(self.ymax) + delta_height),
            min(max_extent.get_width(),
                int(self.xmax) + delta_width))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 91:</b> &nbsp; 2 fragments, nominal size 16 lines, similarity 81%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1364')" href="javascript:;">
raster-vision-0.11.0/rastervision2/pytorch_learner/examples/classification.py: 10-26
</a>
<div class="mid" id="frag1364" style="display:none"><pre>
def get_config(runner, test=False):
    base_uri = ('s3://raster-vision-lf-dev/learner/classification' if
                runner == 'aws_batch' else '/opt/data/learner/classification')
    root_uri = join(base_uri, 'output')
    data_uri = join(base_uri, 'tiny-buildings.zip')

    model = ModelConfig(backbone='resnet50')
    solver = SolverConfig(lr=2e-4, num_epochs=3, batch_sz=8, one_cycle=True)
    data = ClassificationDataConfig(
        data_format='image_folder',
        uri=data_uri,
        img_sz=200,
        labels=['building', 'no_building'])
    learner = ClassificationLearnerConfig(
        model=model, solver=solver, data=data, test_mode=test)
    pipeline = LearnerPipelineConfig(root_uri=root_uri, learner=learner)
    return pipeline
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1365')" href="javascript:;">
raster-vision-0.11.0/rastervision2/pytorch_learner/examples/regression.py: 9-26
</a>
<div class="mid" id="frag1365" style="display:none"><pre>
def get_config(runner, test=False):
    base_uri = ('s3://raster-vision-lf-dev/learner/regression'
                if runner == 'aws_batch' else '/opt/data/learner/regression')
    root_uri = join(base_uri, 'output')
    data_uri = join(base_uri, 'tiny-buildings.zip')

    model = RegressionModelConfig(backbone='resnet50')
    solver = SolverConfig(lr=1e-4, num_epochs=10, batch_sz=8, one_cycle=True)
    data = RegressionDataConfig(
        data_format='image_csv',
        uri=data_uri,
        img_sz=200,
        labels=['has_buildings'])
    learner = RegressionLearnerConfig(
        model=model, solver=solver, data=data, test_mode=test)

    pipeline = LearnerPipelineConfig(root_uri=root_uri, learner=learner)
    return pipeline
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 92:</b> &nbsp; 2 fragments, nominal size 33 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1367')" href="javascript:;">
raster-vision-0.11.0/rastervision2/pytorch_learner/classification_learner.py: 32-71
</a>
<div class="mid" id="frag1367" style="display:none"><pre>
    def _get_datasets(self, uri):
        cfg = self.cfg
        class_names = cfg.data.class_names

        if cfg.data.data_format == ClassificationDataFormat.image_folder:
            data_dirs = self.unzip_data(uri)

        transform, aug_transform = self.get_data_transforms()

        train_ds, valid_ds, test_ds = [], [], []
        for data_dir in data_dirs:
            train_dir = join(data_dir, 'train')
            valid_dir = join(data_dir, 'valid')

            if isdir(train_dir):
                if cfg.overfit_mode:
                    train_ds.append(
                        AlbumentationsDataset(
                            ImageFolder(train_dir, classes=class_names),
                            transform=transform))
                else:
                    train_ds.append(
                        AlbumentationsDataset(
                            ImageFolder(train_dir, classes=class_names),
                            transform=aug_transform))

            if isdir(valid_dir):
                valid_ds.append(
                    AlbumentationsDataset(
                        ImageFolder(valid_dir, classes=class_names),
                        transform=transform))
                test_ds.append(
                    AlbumentationsDataset(
                        ImageFolder(valid_dir, classes=class_names),
                        transform=transform))

        train_ds, valid_ds, test_ds = \
            ConcatDataset(train_ds), ConcatDataset(valid_ds), ConcatDataset(test_ds)

        return train_ds, valid_ds, test_ds
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1412')" href="javascript:;">
raster-vision-0.11.0/rastervision2/pytorch_learner/regression_learner.py: 86-125
</a>
<div class="mid" id="frag1412" style="display:none"><pre>
    def _get_datasets(self, uri):
        cfg = self.cfg
        data_dirs = self.unzip_data(uri)
        transform, aug_transform = self.get_data_transforms()

        train_ds, valid_ds, test_ds = [], [], []
        for data_dir in data_dirs:
            train_dir = join(data_dir, 'train')
            valid_dir = join(data_dir, 'valid')

            if isdir(train_dir):
                if cfg.overfit_mode:
                    train_ds.append(
                        AlbumentationsDataset(
                            ImageRegressionDataset(train_dir,
                                                   cfg.data.class_names),
                            transform=transform))
                else:
                    train_ds.append(
                        AlbumentationsDataset(
                            ImageRegressionDataset(train_dir,
                                                   cfg.data.class_names),
                            transform=aug_transform))

            if isdir(valid_dir):
                valid_ds.append(
                    AlbumentationsDataset(
                        ImageRegressionDataset(valid_dir,
                                               cfg.data.class_names),
                        transform=transform))
                test_ds.append(
                    AlbumentationsDataset(
                        ImageRegressionDataset(valid_dir,
                                               cfg.data.class_names),
                        transform=transform))

        train_ds, valid_ds, test_ds = \
            ConcatDataset(train_ds), ConcatDataset(valid_ds), ConcatDataset(test_ds)

        return train_ds, valid_ds, test_ds
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 93:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1991')" href="javascript:;">
raster-vision-0.11.0/tests_v2/pipeline/test_utils.py: 7-22
</a>
<div class="mid" id="frag1991" style="display:none"><pre>
    def test_split_into_groups(self):
        lst = [1, 2, 3, 4, 5, 6]

        g1 = split_into_groups(lst[:5], 3)
        self.assertEqual(g1, [[1, 2], [3, 4], [5]])

        g2 = split_into_groups(lst, 7)
        self.assertEqual(g2, [[1], [2], [3], [4], [5], [6]])

        g3 = split_into_groups(lst[0:1], 7)
        self.assertEqual(g3, [[1]])

        g4 = split_into_groups(lst, 3)
        self.assertEqual(g4, [[1, 2], [3, 4], [5, 6]])


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2743')" href="javascript:;">
raster-vision-0.11.0/tests/utils/test_misc.py: 213-226
</a>
<div class="mid" id="frag2743" style="display:none"><pre>
    def test_split_into_groups(self):
        lst = [1, 2, 3, 4, 5, 6]

        g1 = split_into_groups(lst[:5], 3)
        self.assertEqual(g1, [[1, 2], [3, 4], [5]])

        g2 = split_into_groups(lst, 7)
        self.assertEqual(g2, [[1], [2], [3], [4], [5], [6]])

        g3 = split_into_groups(lst[0:1], 7)
        self.assertEqual(g3, [[1]])

        g4 = split_into_groups(lst, 3)
        self.assertEqual(g4, [[1, 2], [3, 4], [5, 6]])
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 94:</b> &nbsp; 6 fragments, nominal size 11 lines, similarity 81%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2005')" href="javascript:;">
raster-vision-0.11.0/tests_v2/pipeline/test_file_system.py: 136-150
</a>
<div class="mid" id="frag2005" style="display:none"><pre>
    def setUp(self):
        # Setup mock S3 bucket.
        self.mock_s3 = mock_s3()
        self.mock_s3.start()
        self.s3 = boto3.client('s3')
        self.bucket_name = 'mock_bucket'
        self.s3.create_bucket(Bucket=self.bucket_name)

        self.content_str = 'hello'
        self.file_name = 'hello.txt'
        self.s3_path = 's3://{}/{}'.format(self.bucket_name, self.file_name)

        self.tmp_dir = rv_config.get_tmp_dir()
        self.local_path = os.path.join(self.tmp_dir.name, self.file_name)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2039')" href="javascript:;">
raster-vision-0.11.0/tests_v2/pipeline/test_file_system.py: 459-471
</a>
<div class="mid" id="frag2039" style="display:none"><pre>
    def setUp(self):
        # Setup mock S3 bucket.
        self.mock_s3 = mock_s3()
        self.mock_s3.start()
        self.s3 = boto3.client('s3')
        self.bucket_name = 'mock_bucket'
        self.s3.create_bucket(Bucket=self.bucket_name)

        self.content_str = 'hello'
        self.file_name = 'hello.txt'
        self.tmp_dir = rv_config.get_tmp_dir()
        self.cache_dir = os.path.join(self.tmp_dir.name, 'cache')

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2804')" href="javascript:;">
raster-vision-0.11.0/tests/utils/test_files.py: 529-541
</a>
<div class="mid" id="frag2804" style="display:none"><pre>
    def setUp(self):
        # Setup mock S3 bucket.
        self.mock_s3 = mock_s3()
        self.mock_s3.start()
        self.s3 = boto3.client('s3')
        self.bucket_name = 'mock_bucket'
        self.s3.create_bucket(Bucket=self.bucket_name)

        self.content_str = 'hello'
        self.file_name = 'hello.txt'
        self.temp_dir = RVConfig.get_tmp_dir()
        self.cache_dir = os.path.join(self.temp_dir.name, 'cache')

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2009')" href="javascript:;">
raster-vision-0.11.0/tests_v2/pipeline/test_file_system.py: 181-195
</a>
<div class="mid" id="frag2009" style="display:none"><pre>
    def setUp(self):
        # Setup mock S3 bucket.
        self.mock_s3 = mock_s3()
        self.mock_s3.start()
        self.s3 = boto3.client('s3')
        self.bucket_name = 'mock_bucket'
        self.s3.create_bucket(Bucket=self.bucket_name)

        self.content_str = 'hello'
        self.file_name = 'hello.txt'
        self.s3_path = 's3://{}/{}'.format(self.bucket_name, self.file_name)

        self.tmp_dir = rv_config.get_tmp_dir()
        self.local_path = os.path.join(self.tmp_dir.name, self.file_name)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2763')" href="javascript:;">
raster-vision-0.11.0/tests/utils/test_files.py: 141-155
</a>
<div class="mid" id="frag2763" style="display:none"><pre>
    def setUp(self):
        # Setup mock S3 bucket.
        self.mock_s3 = mock_s3()
        self.mock_s3.start()
        self.s3 = boto3.client('s3')
        self.bucket_name = 'mock_bucket'
        self.s3.create_bucket(Bucket=self.bucket_name)

        self.content_str = 'hello'
        self.file_name = 'hello.txt'
        self.s3_path = 's3://{}/{}'.format(self.bucket_name, self.file_name)

        self.temp_dir = RVConfig.get_tmp_dir()
        self.local_path = os.path.join(self.temp_dir.name, self.file_name)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2767')" href="javascript:;">
raster-vision-0.11.0/tests/utils/test_files.py: 186-200
</a>
<div class="mid" id="frag2767" style="display:none"><pre>
    def setUp(self):
        # Setup mock S3 bucket.
        self.mock_s3 = mock_s3()
        self.mock_s3.start()
        self.s3 = boto3.client('s3')
        self.bucket_name = 'mock_bucket'
        self.s3.create_bucket(Bucket=self.bucket_name)

        self.content_str = 'hello'
        self.file_name = 'hello.txt'
        self.s3_path = 's3://{}/{}'.format(self.bucket_name, self.file_name)

        self.temp_dir = RVConfig.get_tmp_dir()
        self.local_path = os.path.join(self.temp_dir.name, self.file_name)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 95:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 90%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2012')" href="javascript:;">
raster-vision-0.11.0/tests_v2/pipeline/test_file_system.py: 209-223
</a>
<div class="mid" id="frag2012" style="display:none"><pre>
    def test_download_if_needed_s3(self):
        with self.assertRaises(NotReadableError):
            file_to_str(self.s3_path)

        str_to_file(self.content_str, self.local_path)
        upload_or_copy(self.local_path, self.s3_path)
        local_path = download_if_needed(self.s3_path, self.tmp_dir.name)
        content_str = file_to_str(local_path)
        self.assertEqual(self.content_str, content_str)

        wrong_path = 's3://wrongpath/x.txt'
        with self.assertRaises(NotWritableError):
            upload_or_copy(local_path, wrong_path)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2770')" href="javascript:;">
raster-vision-0.11.0/tests/utils/test_files.py: 214-228
</a>
<div class="mid" id="frag2770" style="display:none"><pre>
    def test_download_if_needed_s3(self):
        with self.assertRaises(NotReadableError):
            download_if_needed(self.s3_path, self.temp_dir.name)

        str_to_file(self.content_str, self.local_path)
        upload_or_copy(self.local_path, self.s3_path)
        local_path = download_if_needed(self.s3_path, self.temp_dir.name)
        content_str = file_to_str(local_path)
        self.assertEqual(self.content_str, content_str)

        wrong_path = 's3://wrongpath/x.txt'
        with self.assertRaises(NotWritableError):
            upload_or_copy(local_path, wrong_path)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 96:</b> &nbsp; 6 fragments, nominal size 10 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2015')" href="javascript:;">
raster-vision-0.11.0/tests_v2/pipeline/test_file_system.py: 242-255
</a>
<div class="mid" id="frag2015" style="display:none"><pre>
    def test_last_modified_s3(self):
        path = os.path.join(self.tmp_dir.name, 'lorem', 'ipsum1.txt')
        s3_path = 's3://{}/lorem1.txt'.format(self.bucket_name)
        directory = os.path.dirname(path)
        make_dir(directory, check_empty=False)

        fs = FileSystem.get_file_system(s3_path, 'r')

        str_to_file(self.lorem, path)
        upload_or_copy(path, s3_path)
        stamp = fs.last_modified(s3_path)

        self.assertTrue(isinstance(stamp, datetime.datetime))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2781')" href="javascript:;">
raster-vision-0.11.0/tests/utils/test_files.py: 326-338
</a>
<div class="mid" id="frag2781" style="display:none"><pre>
    def test_list_paths_s3(self):
        path = os.path.join(self.temp_dir.name, 'lorem', 'ipsum.txt')
        s3_path = 's3://{}/xxx/lorem.txt'.format(self.bucket_name)
        s3_directory = 's3://{}/xxx/'.format(self.bucket_name)
        directory = os.path.dirname(path)
        make_dir(directory, check_empty=False)

        str_to_file(self.lorem, path)
        upload_or_copy(path, s3_path)

        list_paths(s3_directory)
        self.assertEqual(len(list_paths(s3_directory)), 1)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2780')" href="javascript:;">
raster-vision-0.11.0/tests/utils/test_files.py: 312-325
</a>
<div class="mid" id="frag2780" style="display:none"><pre>
    def test_last_modified_s3(self):
        path = os.path.join(self.temp_dir.name, 'lorem', 'ipsum1.txt')
        s3_path = 's3://{}/lorem1.txt'.format(self.bucket_name)
        directory = os.path.dirname(path)
        make_dir(directory, check_empty=False)

        fs = FileSystem.get_file_system(s3_path, 'r')

        str_to_file(self.lorem, path)
        upload_or_copy(path, s3_path)
        stamp = fs.last_modified(s3_path)

        self.assertTrue(isinstance(stamp, datetime.datetime))

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2016')" href="javascript:;">
raster-vision-0.11.0/tests_v2/pipeline/test_file_system.py: 256-268
</a>
<div class="mid" id="frag2016" style="display:none"><pre>
    def test_list_paths_s3(self):
        path = os.path.join(self.tmp_dir.name, 'lorem', 'ipsum.txt')
        s3_path = 's3://{}/xxx/lorem.txt'.format(self.bucket_name)
        s3_directory = 's3://{}/xxx/'.format(self.bucket_name)
        directory = os.path.dirname(path)
        make_dir(directory, check_empty=False)

        str_to_file(self.lorem, path)
        upload_or_copy(path, s3_path)

        list_paths(s3_directory)
        self.assertEqual(len(list_paths(s3_directory)), 1)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2790')" href="javascript:;">
raster-vision-0.11.0/tests/utils/test_files.py: 420-432
</a>
<div class="mid" id="frag2790" style="display:none"><pre>
    def test_copy_to_local(self):
        path1 = os.path.join(self.temp_dir.name, 'lorem', 'ipsum.txt')
        path2 = os.path.join(self.temp_dir.name, 'yyy', 'ipsum.txt')
        dir1 = os.path.dirname(path1)
        dir2 = os.path.dirname(path2)
        make_dir(dir1, check_empty=False)
        make_dir(dir2, check_empty=False)

        str_to_file(self.lorem, path1)

        upload_or_copy(path1, path2)
        self.assertEqual(len(list_paths(dir2)), 1)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2025')" href="javascript:;">
raster-vision-0.11.0/tests_v2/pipeline/test_file_system.py: 350-362
</a>
<div class="mid" id="frag2025" style="display:none"><pre>
    def test_copy_to_local(self):
        path1 = os.path.join(self.tmp_dir.name, 'lorem', 'ipsum.txt')
        path2 = os.path.join(self.tmp_dir.name, 'yyy', 'ipsum.txt')
        dir1 = os.path.dirname(path1)
        dir2 = os.path.dirname(path2)
        make_dir(dir1, check_empty=False)
        make_dir(dir2, check_empty=False)

        str_to_file(self.lorem, path1)

        upload_or_copy(path1, path2)
        self.assertEqual(len(list_paths(dir2)), 1)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 97:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2017')" href="javascript:;">
raster-vision-0.11.0/tests_v2/pipeline/test_file_system.py: 269-286
</a>
<div class="mid" id="frag2017" style="display:none"><pre>
    def test_file_exists(self):
        path = os.path.join(self.tmp_dir.name, 'lorem', 'ipsum.txt')
        s3_path = 's3://{}/xxx/lorem.txt'.format(self.bucket_name)
        s3_path_prefix = 's3://{}/xxx/lorem'.format(self.bucket_name)
        s3_directory = 's3://{}/xxx/'.format(self.bucket_name)
        make_dir(path, check_empty=False, use_dirname=True)

        str_to_file(self.lorem, path)
        upload_or_copy(path, s3_path)

        self.assertTrue(file_exists(s3_directory, include_dir=True))
        self.assertTrue(file_exists(s3_path, include_dir=False))
        self.assertFalse(file_exists(s3_path_prefix, include_dir=True))
        self.assertFalse(file_exists(s3_directory, include_dir=False))
        self.assertFalse(
            file_exists(s3_directory + 'NOTPOSSIBLE', include_dir=False))


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2782')" href="javascript:;">
raster-vision-0.11.0/tests/utils/test_files.py: 339-356
</a>
<div class="mid" id="frag2782" style="display:none"><pre>
    def test_file_exists(self):
        path = os.path.join(self.temp_dir.name, 'lorem', 'ipsum.txt')
        s3_path = 's3://{}/xxx/lorem.txt'.format(self.bucket_name)
        s3_path_prefix = 's3://{}/xxx/lorem'.format(self.bucket_name)
        s3_directory = 's3://{}/xxx/'.format(self.bucket_name)
        make_dir(path, check_empty=False, use_dirname=True)

        str_to_file(self.lorem, path)
        upload_or_copy(path, s3_path)

        self.assertTrue(file_exists(s3_directory, include_dir=True))
        self.assertTrue(file_exists(s3_path, include_dir=False))
        self.assertFalse(file_exists(s3_path_prefix, include_dir=True))
        self.assertFalse(file_exists(s3_directory, include_dir=False))
        self.assertFalse(
            file_exists(s3_directory + 'NOTPOSSIBLE', include_dir=False))


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 98:</b> &nbsp; 4 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2022')" href="javascript:;">
raster-vision-0.11.0/tests_v2/pipeline/test_file_system.py: 313-325
</a>
<div class="mid" id="frag2022" style="display:none"><pre>
    def test_sync_from_dir_local(self):
        path = os.path.join(self.tmp_dir.name, 'lorem', 'ipsum.txt')
        src = os.path.dirname(path)
        dst = os.path.join(self.tmp_dir.name, 'xxx')
        make_dir(src, check_empty=False)
        make_dir(dst, check_empty=False)

        fs = FileSystem.get_file_system(path, 'r')
        fs.write_bytes(path, bytes([0x00, 0x01]))
        sync_from_dir(src, dst, delete=True)

        self.assertEqual(len(list_paths(dst)), 1)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2789')" href="javascript:;">
raster-vision-0.11.0/tests/utils/test_files.py: 407-419
</a>
<div class="mid" id="frag2789" style="display:none"><pre>
    def test_sync_to_dir_local(self):
        path = os.path.join(self.temp_dir.name, 'lorem', 'ipsum.txt')
        src = os.path.dirname(path)
        dst = os.path.join(self.temp_dir.name, 'xxx')
        make_dir(src, check_empty=False)
        make_dir(dst, check_empty=False)

        fs = FileSystem.get_file_system(path, 'r')
        fs.write_bytes(path, bytes([0x00, 0x01]))
        sync_to_dir(src, dst, delete=True)

        self.assertEqual(len(list_paths(dst)), 1)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2787')" href="javascript:;">
raster-vision-0.11.0/tests/utils/test_files.py: 383-395
</a>
<div class="mid" id="frag2787" style="display:none"><pre>
    def test_sync_from_dir_local(self):
        path = os.path.join(self.temp_dir.name, 'lorem', 'ipsum.txt')
        src = os.path.dirname(path)
        dst = os.path.join(self.temp_dir.name, 'xxx')
        make_dir(src, check_empty=False)
        make_dir(dst, check_empty=False)

        fs = FileSystem.get_file_system(path, 'r')
        fs.write_bytes(path, bytes([0x00, 0x01]))
        sync_from_dir(src, dst, delete=True)

        self.assertEqual(len(list_paths(dst)), 1)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2024')" href="javascript:;">
raster-vision-0.11.0/tests_v2/pipeline/test_file_system.py: 337-349
</a>
<div class="mid" id="frag2024" style="display:none"><pre>
    def test_sync_to_dir_local(self):
        path = os.path.join(self.tmp_dir.name, 'lorem', 'ipsum.txt')
        src = os.path.dirname(path)
        dst = os.path.join(self.tmp_dir.name, 'xxx')
        make_dir(src, check_empty=False)
        make_dir(dst, check_empty=False)

        fs = FileSystem.get_file_system(path, 'r')
        fs.write_bytes(path, bytes([0x00, 0x01]))
        sync_to_dir(src, dst, delete=True)

        self.assertEqual(len(list_paths(dst)), 1)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 99:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2027')" href="javascript:;">
raster-vision-0.11.0/tests_v2/pipeline/test_file_system.py: 375-390
</a>
<div class="mid" id="frag2027" style="display:none"><pre>
    def test_file_exists(self):
        fs = FileSystem.get_file_system(self.tmp_dir.name, 'r')

        path1 = os.path.join(self.tmp_dir.name, 'lorem', 'ipsum.txt')
        dir1 = os.path.dirname(path1)
        make_dir(dir1, check_empty=False)

        str_to_file(self.lorem, path1)

        self.assertTrue(fs.file_exists(dir1, include_dir=True))
        self.assertTrue(fs.file_exists(path1, include_dir=False))
        self.assertFalse(fs.file_exists(dir1, include_dir=False))
        self.assertFalse(
            fs.file_exists(dir1 + 'NOTPOSSIBLE', include_dir=False))


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2792')" href="javascript:;">
raster-vision-0.11.0/tests/utils/test_files.py: 445-460
</a>
<div class="mid" id="frag2792" style="display:none"><pre>
    def test_file_exists(self):
        fs = FileSystem.get_file_system(self.temp_dir.name, 'r')

        path1 = os.path.join(self.temp_dir.name, 'lorem', 'ipsum.txt')
        dir1 = os.path.dirname(path1)
        make_dir(dir1, check_empty=False)

        str_to_file(self.lorem, path1)

        self.assertTrue(fs.file_exists(dir1, include_dir=True))
        self.assertTrue(fs.file_exists(path1, include_dir=False))
        self.assertFalse(fs.file_exists(dir1, include_dir=False))
        self.assertFalse(
            fs.file_exists(dir1 + 'NOTPOSSIBLE', include_dir=False))


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 100:</b> &nbsp; 2 fragments, nominal size 17 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2042')" href="javascript:;">
raster-vision-0.11.0/tests_v2/pipeline/test_file_system.py: 483-503
</a>
<div class="mid" id="frag2042" style="display:none"><pre>
    def test_local_zip(self):
        local_path = os.path.join(self.tmp_dir.name, self.file_name)
        local_gz_path = local_path + '.gz'
        with gzip.open(local_gz_path, 'wb') as f:
            f.write(bytes(self.content_str, encoding='utf-8'))

        with patch('gzip.open', side_effect=gzip.open) as patched_gzip_open:
            path = get_cached_file(self.cache_dir, local_gz_path)
            self.assertTrue(os.path.isfile(path))
            self.assertNotEqual(path, local_gz_path)
            with open(path, 'r') as f:
                self.assertEqual(f.read(), self.content_str)

            # Check that calling it again doesn't invoke the gzip.open method again.
            path = get_cached_file(self.cache_dir, local_gz_path)
            self.assertTrue(os.path.isfile(path))
            self.assertNotEqual(path, local_gz_path)
            with open(path, 'r') as f:
                self.assertEqual(f.read(), self.content_str)
            self.assertEqual(patched_gzip_open.call_count, 1)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2807')" href="javascript:;">
raster-vision-0.11.0/tests/utils/test_files.py: 553-573
</a>
<div class="mid" id="frag2807" style="display:none"><pre>
    def test_local_zip(self):
        local_path = os.path.join(self.temp_dir.name, self.file_name)
        local_gz_path = local_path + '.gz'
        with gzip.open(local_gz_path, 'wb') as f:
            f.write(bytes(self.content_str, encoding='utf-8'))

        with patch('gzip.open', side_effect=gzip.open) as patched_gzip_open:
            path = get_cached_file(self.cache_dir, local_gz_path)
            self.assertTrue(os.path.isfile(path))
            self.assertNotEqual(path, local_gz_path)
            with open(path, 'r') as f:
                self.assertEqual(f.read(), self.content_str)

            # Check that calling it again doesn't invoke the gzip.open method again.
            path = get_cached_file(self.cache_dir, local_gz_path)
            self.assertTrue(os.path.isfile(path))
            self.assertNotEqual(path, local_gz_path)
            with open(path, 'r') as f:
                self.assertEqual(f.read(), self.content_str)
            self.assertEqual(patched_gzip_open.call_count, 1)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 101:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 90%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2043')" href="javascript:;">
raster-vision-0.11.0/tests_v2/pipeline/test_file_system.py: 504-517
</a>
<div class="mid" id="frag2043" style="display:none"><pre>
    def test_remote(self):
        with patch(
                'rastervision2.pipeline.file_system.utils.download_if_needed',
                side_effect=download_if_needed) as patched_download:
            s3_path = 's3://{}/{}'.format(self.bucket_name, self.file_name)
            str_to_file(self.content_str, s3_path)
            path = get_cached_file(self.cache_dir, s3_path)
            self.assertTrue(os.path.isfile(path))

            # Check that calling it again doesn't invoke the download method again.
            self.assertTrue(os.path.isfile(path))
            self.assertEqual(patched_download.call_count, 1)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2808')" href="javascript:;">
raster-vision-0.11.0/tests/utils/test_files.py: 574-588
</a>
<div class="mid" id="frag2808" style="display:none"><pre>
    def test_remote(self):
        with patch(
                'rastervision.utils.files.download_if_needed',
                side_effect=download_if_needed) as patched_download:
            s3_path = 's3://{}/{}'.format(self.bucket_name, self.file_name)
            str_to_file(self.content_str, s3_path)
            path = get_cached_file(self.cache_dir, s3_path)
            self.assertTrue(os.path.isfile(path))

            # Check that calling it again doesn't invoke the download method again.
            path = get_cached_file(self.cache_dir, s3_path)
            self.assertTrue(os.path.isfile(path))
            self.assertEqual(patched_download.call_count, 1)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 102:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 81%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2044')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/label_source/test_semantic_segmentation_label_source.py: 11-21
</a>
<div class="mid" id="frag2044" style="display:none"><pre>
    def test_enough_target_pixels_true(self):
        data = np.zeros((10, 10, 1), dtype=np.uint8)
        data[4:, 4:, :] = 1
        null_class_id = 2
        raster_source = MockRasterSource([0], 1)
        raster_source.set_raster(data)
        label_source = SemanticSegmentationLabelSource(raster_source, null_class_id)
        with label_source.activate():
            extent = Box(0, 0, 10, 10)
            self.assertTrue(label_source.enough_target_pixels(extent, 30, [1]))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2045')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/label_source/test_semantic_segmentation_label_source.py: 22-33
</a>
<div class="mid" id="frag2045" style="display:none"><pre>
    def test_enough_target_pixels_false(self):
        data = np.zeros((10, 10, 1), dtype=np.uint8)
        data[7:, 7:, :] = 1
        null_class_id = 2
        raster_source = MockRasterSource([0], 1)
        raster_source.set_raster(data)
        label_source = SemanticSegmentationLabelSource(raster_source, null_class_id)
        with label_source.activate():
            extent = Box(0, 0, 10, 10)
            self.assertFalse(
                label_source.enough_target_pixels(extent, 30, [1]))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 103:</b> &nbsp; 5 fragments, nominal size 13 lines, similarity 71%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2046')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/label_source/test_semantic_segmentation_label_source.py: 34-47
</a>
<div class="mid" id="frag2046" style="display:none"><pre>
    def test_get_labels(self):
        data = np.zeros((10, 10, 1), dtype=np.uint8)
        data[7:, 7:, 0] = 1
        null_class_id = 2
        raster_source = MockRasterSource([0], 1)
        raster_source.set_raster(data)
        label_source = SemanticSegmentationLabelSource(raster_source, null_class_id)
        with label_source.activate():
            window = Box.make_square(7, 7, 3)
            labels = label_source.get_labels(window=window)
            label_arr = labels.get_label_arr(window)
            expected_label_arr = np.ones((3, 3))
            np.testing.assert_array_equal(label_arr, expected_label_arr)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2603')" href="javascript:;">
raster-vision-0.11.0/tests/data/label_source/test_semantic_segmentation_label_source.py: 39-51
</a>
<div class="mid" id="frag2603" style="display:none"><pre>
    def test_get_labels(self):
        data = np.zeros((10, 10, 1), dtype=np.uint8)
        data[7:, 7:, 0] = 1
        raster_source = MockRasterSource([0, 1, 2], 3)
        raster_source.set_raster(data)
        label_source = SemanticSegmentationLabelSource(source=raster_source)
        with label_source.activate():
            window = Box.make_square(7, 7, 3)
            labels = label_source.get_labels(window=window)
            label_arr = labels.get_label_arr(window)
            expected_label_arr = np.ones((3, 3))
            np.testing.assert_array_equal(label_arr, expected_label_arr)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2047')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/label_source/test_semantic_segmentation_label_source.py: 48-62
</a>
<div class="mid" id="frag2047" style="display:none"><pre>
    def test_get_labels_off_edge(self):
        data = np.zeros((10, 10, 1), dtype=np.uint8)
        data[7:, 7:, 0] = 1
        null_class_id = 2
        raster_source = MockRasterSource([0], 1)
        raster_source.set_raster(data)
        label_source = SemanticSegmentationLabelSource(raster_source, null_class_id)
        with label_source.activate():
            window = Box.make_square(7, 7, 6)
            labels = label_source.get_labels(window=window)
            label_arr = labels.get_label_arr(window)
            expected_label_arr = np.full((6, 6), 2)
            expected_label_arr[0:3, 0:3] = 1
            np.testing.assert_array_equal(label_arr, expected_label_arr)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2604')" href="javascript:;">
raster-vision-0.11.0/tests/data/label_source/test_semantic_segmentation_label_source.py: 52-66
</a>
<div class="mid" id="frag2604" style="display:none"><pre>
    def test_get_labels_rgb(self):
        data = np.zeros((10, 10, 3), dtype=np.uint8)
        data[7:, 7:, :] = [1, 1, 1]
        raster_source = MockRasterSource([0, 1, 2], 3)
        raster_source.set_raster(data)
        rgb_class_map = ClassMap([ClassItem(id=1, color='#010101')])
        label_source = SemanticSegmentationLabelSource(
            source=raster_source, rgb_class_map=rgb_class_map)
        with label_source.activate():
            window = Box.make_square(7, 7, 3)
            labels = label_source.get_labels(window=window)
            label_arr = labels.get_label_arr(window)
            expected_label_arr = np.ones((3, 3))
            np.testing.assert_array_equal(label_arr, expected_label_arr)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2048')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/label_source/test_semantic_segmentation_label_source.py: 63-80
</a>
<div class="mid" id="frag2048" style="display:none"><pre>
    def test_get_labels_rgb(self):
        data = np.zeros((10, 10, 3), dtype=np.uint8)
        data[7:, 7:, :] = [1, 1, 1]
        null_class_id = 2
        raster_source = MockRasterSource([0, 1, 2], 3)
        raster_source.set_raster(data)
        rgb_class_config = ClassConfig(names=['a'], colors=['#010101'])
        rgb_class_config.ensure_null_class()
        label_source = SemanticSegmentationLabelSource(
            raster_source, null_class_id, rgb_class_config=rgb_class_config)
        with label_source.activate():
            window = Box.make_square(7, 7, 3)
            labels = label_source.get_labels(window=window)
            label_arr = labels.get_label_arr(window)
            expected_label_arr = np.zeros((3, 3))
            np.testing.assert_array_equal(label_arr, expected_label_arr)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 104:</b> &nbsp; 2 fragments, nominal size 44 lines, similarity 89%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2049')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/label_source/test_chip_classification_label_source.py: 18-71
</a>
<div class="mid" id="frag2049" style="display:none"><pre>
    def setUp(self):
        self.crs_transformer = DoubleCRSTransformer()
        self.geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'type': 'Feature',
                'geometry': {
                    'type':
                    'MultiPolygon',
                    'coordinates': [[[[0., 0.], [0., 2.], [2., 2.], [2., 0.],
                                      [0., 0.]]]]
                },
                'properties': {
                    'class_name': 'car',
                    'class_id': 0,
                    'score': 0.0
                }
            }, {
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[2., 2.], [2., 4.], [4., 4.], [4., 2.],
                                     [2., 2.]]]
                },
                'properties': {
                    'score': 0.0,
                    'class_name': 'house',
                    'class_id': 1
                }
            }]
        }

        self.class_config = ClassConfig(names=['car', 'house'])

        self.box1 = Box.make_square(0, 0, 4)
        self.box2 = Box.make_square(4, 4, 4)
        self.class_id1 = 0
        self.class_id2 = 1
        self.background_class_id = 2

        geoms = []
        for f in self.geojson['features']:
            g = shape(f['geometry'])
            g.class_id = f['properties']['class_id']
            geoms.append(g)
        self.str_tree = STRtree(geoms)

        self.file_name = 'labels.json'
        self.tmp_dir = rv_config.get_tmp_dir()
        self.uri = os.path.join(self.tmp_dir.name, self.file_name)
        json_to_file(self.geojson, self.uri)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2608')" href="javascript:;">
raster-vision-0.11.0/tests/data/label_source/test_chip_classification_label_source.py: 18-77
</a>
<div class="mid" id="frag2608" style="display:none"><pre>
    def setUp(self):
        self.crs_transformer = DoubleCRSTransformer()
        self.geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'type': 'Feature',
                'geometry': {
                    'type':
                    'MultiPolygon',
                    'coordinates': [[[[0., 0.], [0., 2.], [2., 2.], [2., 0.],
                                      [0., 0.]]]]
                },
                'properties': {
                    'class_name': 'car',
                    'class_id': 1,
                    'score': 0.0
                }
            }, {
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[2., 2.], [2., 4.], [4., 4.], [4., 2.],
                                     [2., 2.]]]
                },
                'properties': {
                    'score': 0.0,
                    'class_name': 'house',
                    'class_id': 2
                }
            }]
        }

        self.class_map = ClassMap([ClassItem(1, 'car'), ClassItem(2, 'house')])

        class MockTaskConfig():
            def __init__(self, class_map):
                self.class_map = class_map

        self.task_config = MockTaskConfig(self.class_map)

        self.box1 = Box.make_square(0, 0, 4)
        self.box2 = Box.make_square(4, 4, 4)
        self.class_id1 = 1
        self.class_id2 = 2
        self.background_class_id = 3

        geoms = []
        for f in self.geojson['features']:
            g = shape(f['geometry'])
            g.class_id = f['properties']['class_id']
            geoms.append(g)
        self.str_tree = STRtree(geoms)

        self.file_name = 'labels.json'
        self.temp_dir = RVConfig.get_tmp_dir()
        self.uri = os.path.join(self.temp_dir.name, self.file_name)
        json_to_file(self.geojson, self.uri)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 105:</b> &nbsp; 16 fragments, nominal size 10 lines, similarity 90%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2051')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/label_source/test_chip_classification_label_source.py: 75-87
</a>
<div class="mid" id="frag2051" style="display:none"><pre>
    def test_infer_cell1(self):
        # More of box 1 is in cell.
        cell = Box.make_square(0, 0, 3)
        ioa_thresh = 0.5
        use_intersection_over_cell = False
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.class_id1)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2052')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/label_source/test_chip_classification_label_source.py: 88-100
</a>
<div class="mid" id="frag2052" style="display:none"><pre>
    def test_infer_cell2(self):
        # More of box 2 is in cell.
        cell = Box.make_square(1, 1, 3)
        ioa_thresh = 0.5
        use_intersection_over_cell = False
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.class_id2)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2053')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/label_source/test_chip_classification_label_source.py: 101-113
</a>
<div class="mid" id="frag2053" style="display:none"><pre>
    def test_infer_cell3(self):
        # Only box 2 is in cell, but IOA isn't high enough.
        cell = Box.make_square(3, 3, 3)
        ioa_thresh = 0.5
        use_intersection_over_cell = False
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, None)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2612')" href="javascript:;">
raster-vision-0.11.0/tests/data/label_source/test_chip_classification_label_source.py: 94-106
</a>
<div class="mid" id="frag2612" style="display:none"><pre>
    def test_infer_cell2(self):
        # More of box 2 is in cell.
        cell = Box.make_square(1, 1, 3)
        ioa_thresh = 0.5
        use_intersection_over_cell = False
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.class_id2)

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2054')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/label_source/test_chip_classification_label_source.py: 114-127
</a>
<div class="mid" id="frag2054" style="display:none"><pre>
    def test_infer_cell4(self):
        # Both boxes inside cell, but using intersection_over_cell,
        # the IOA isn't high enough.
        cell = Box.make_square(0, 0, 10)
        ioa_thresh = 0.5
        use_intersection_over_cell = True
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, None)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2611')" href="javascript:;">
raster-vision-0.11.0/tests/data/label_source/test_chip_classification_label_source.py: 81-93
</a>
<div class="mid" id="frag2611" style="display:none"><pre>
    def test_infer_cell1(self):
        # More of box 1 is in cell.
        cell = Box.make_square(0, 0, 3)
        ioa_thresh = 0.5
        use_intersection_over_cell = False
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.class_id1)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2618')" href="javascript:;">
raster-vision-0.11.0/tests/data/label_source/test_chip_classification_label_source.py: 174-187
</a>
<div class="mid" id="frag2618" style="display:none"><pre>
    def test_infer_cell8(self):
        # box2 overlaps more than box1, but using pick_min_class_id, so
        # picks box1.
        cell = Box.make_square(1, 1, 3)
        ioa_thresh = 0.5
        use_intersection_over_cell = False
        background_class_id = None
        pick_min_class_id = True

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.class_id2)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2058')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/label_source/test_chip_classification_label_source.py: 168-181
</a>
<div class="mid" id="frag2058" style="display:none"><pre>
    def test_infer_cell8(self):
        # box2 overlaps more than box1, but using pick_min_class_id, so
        # picks box1.
        cell = Box.make_square(1, 1, 3)
        ioa_thresh = 0.5
        use_intersection_over_cell = False
        background_class_id = None
        pick_min_class_id = True

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.class_id2)

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2615')" href="javascript:;">
raster-vision-0.11.0/tests/data/label_source/test_chip_classification_label_source.py: 134-147
</a>
<div class="mid" id="frag2615" style="display:none"><pre>
    def test_infer_cell5(self):
        # More of box1 in cell, using intersection_over_cell with the
        # IOA high enough.
        cell = Box.make_square(0, 0, 3)
        ioa_thresh = 0.4
        use_intersection_over_cell = True
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.class_id1)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2056')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/label_source/test_chip_classification_label_source.py: 142-154
</a>
<div class="mid" id="frag2056" style="display:none"><pre>
    def test_infer_cell6(self):
        # No boxes overlap enough, use background_class_id
        cell = Box.make_square(0, 0, 10)
        ioa_thresh = 0.5
        use_intersection_over_cell = True
        background_class_id = self.background_class_id
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.background_class_id)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2055')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/label_source/test_chip_classification_label_source.py: 128-141
</a>
<div class="mid" id="frag2055" style="display:none"><pre>
    def test_infer_cell5(self):
        # More of box1 in cell, using intersection_over_cell with the
        # IOA high enough.
        cell = Box.make_square(0, 0, 3)
        ioa_thresh = 0.4
        use_intersection_over_cell = True
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.class_id1)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2617')" href="javascript:;">
raster-vision-0.11.0/tests/data/label_source/test_chip_classification_label_source.py: 161-173
</a>
<div class="mid" id="frag2617" style="display:none"><pre>
    def test_infer_cell7(self):
        # Cell doesn't overlap with any boxes.
        cell = Box.make_square(10, 10, 1)
        ioa_thresh = 0.5
        use_intersection_over_cell = True
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, None)

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2616')" href="javascript:;">
raster-vision-0.11.0/tests/data/label_source/test_chip_classification_label_source.py: 148-160
</a>
<div class="mid" id="frag2616" style="display:none"><pre>
    def test_infer_cell6(self):
        # No boxes overlap enough, use background_class_id
        cell = Box.make_square(0, 0, 10)
        ioa_thresh = 0.5
        use_intersection_over_cell = True
        background_class_id = self.background_class_id
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, self.background_class_id)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2057')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/label_source/test_chip_classification_label_source.py: 155-167
</a>
<div class="mid" id="frag2057" style="display:none"><pre>
    def test_infer_cell7(self):
        # Cell doesn't overlap with any boxes.
        cell = Box.make_square(10, 10, 1)
        ioa_thresh = 0.5
        use_intersection_over_cell = True
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, None)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2614')" href="javascript:;">
raster-vision-0.11.0/tests/data/label_source/test_chip_classification_label_source.py: 120-133
</a>
<div class="mid" id="frag2614" style="display:none"><pre>
    def test_infer_cell4(self):
        # Both boxes inside cell, but using intersection_over_cell,
        # the IOA isn't high enough.
        cell = Box.make_square(0, 0, 10)
        ioa_thresh = 0.5
        use_intersection_over_cell = True
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, None)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2613')" href="javascript:;">
raster-vision-0.11.0/tests/data/label_source/test_chip_classification_label_source.py: 107-119
</a>
<div class="mid" id="frag2613" style="display:none"><pre>
    def test_infer_cell3(self):
        # Only box 2 is in cell, but IOA isn't high enough.
        cell = Box.make_square(3, 3, 3)
        ioa_thresh = 0.5
        use_intersection_over_cell = False
        background_class_id = None
        pick_min_class_id = False

        class_id = infer_cell(cell, self.str_tree, ioa_thresh,
                              use_intersection_over_cell, background_class_id,
                              pick_min_class_id)
        self.assertEqual(class_id, None)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 106:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 92%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2060')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/label_source/test_chip_classification_label_source.py: 209-226
</a>
<div class="mid" id="frag2060" style="display:none"><pre>
    def test_get_labels_small_extent(self):
        # Extent only has enough of first box in it.
        extent = Box.make_square(0, 0, 2)

        config = ChipClassificationLabelSourceConfig(
            vector_source=GeoJSONVectorSourceConfig(
                uri=self.uri, default_class_id=None))
        source = config.build(
            self.class_config, self.crs_transformer, extent, self.tmp_dir.name)
        labels = source.get_labels()

        cells = labels.get_cells()
        self.assertEqual(len(cells), 1)
        class_id = labels.get_cell_class_id(self.box1)
        self.assertEqual(class_id, self.class_id1)
        class_id = labels.get_cell_class_id(self.box2)
        self.assertEqual(class_id, None)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2061')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/label_source/test_chip_classification_label_source.py: 227-245
</a>
<div class="mid" id="frag2061" style="display:none"><pre>
    def test_get_labels(self):
        # Extent contains both boxes.
        extent = Box.make_square(0, 0, 8)

        config = ChipClassificationLabelSourceConfig(
            vector_source=GeoJSONVectorSourceConfig(
                uri=self.uri, default_class_id=None))
        source = config.build(
            self.class_config, self.crs_transformer, extent, self.tmp_dir.name)
        labels = source.get_labels()

        cells = labels.get_cells()
        self.assertEqual(len(cells), 2)
        class_id = labels.get_cell_class_id(self.box1)
        self.assertEqual(class_id, self.class_id1)
        class_id = labels.get_cell_class_id(self.box2)
        self.assertEqual(class_id, self.class_id2)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 107:</b> &nbsp; 4 fragments, nominal size 31 lines, similarity 71%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2065')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/label_source/test_object_detection_label_source.py: 17-56
</a>
<div class="mid" id="frag2065" style="display:none"><pre>
    def setUp(self):
        self.file_name = 'labels.json'
        self.tmp_dir = rv_config.get_tmp_dir()
        self.file_path = os.path.join(self.tmp_dir.name, self.file_name)

        self.crs_transformer = DoubleCRSTransformer()
        self.geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[0., 0.], [0., 1.], [1., 1.], [1., 0.],
                                     [0., 0.]]]
                },
                'properties': {
                    'class_id': 0,
                    'score': 0.9
                }
            }, {
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[1., 1.], [1., 2.], [2., 2.], [2., 1.],
                                     [1., 1.]]]
                },
                'properties': {
                    'score': 0.9,
                    'class_id': 1
                }
            }]
        }

        self.extent = Box.make_square(0, 0, 10)
        self.class_config = ClassConfig(names=['car', 'house'])
        json_to_file(self.geojson, self.file_path)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2735')" href="javascript:;">
raster-vision-0.11.0/tests/data/label_store/test_object_detection_geojson_store.py: 19-59
</a>
<div class="mid" id="frag2735" style="display:none"><pre>
    def setUp(self):
        self.file_name = 'labels.json'
        self.temp_dir = RVConfig.get_tmp_dir()
        self.file_path = os.path.join(self.temp_dir.name, self.file_name)

        self.crs_transformer = DoubleCRSTransformer()
        self.geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[0., 0.], [0., 1.], [1., 1.], [1., 0.],
                                     [0., 0.]]]
                },
                'properties': {
                    'class_id': 1,
                    'score': 0.9
                }
            }, {
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[1., 1.], [1., 2.], [2., 2.], [2., 1.],
                                     [1., 1.]]]
                },
                'properties': {
                    'score': 0.9,
                    'class_id': 2
                }
            }]
        }

        self.extent = Box.make_square(0, 0, 10)
        self.class_map = ClassMap([ClassItem(1, 'car'), ClassItem(2, 'house')])

        json_to_file(self.geojson, self.file_path)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2629')" href="javascript:;">
raster-vision-0.11.0/tests/data/label_source/test_object_detection_label_source.py: 23-70
</a>
<div class="mid" id="frag2629" style="display:none"><pre>
    def setUp(self):
        self.prev_keys = (os.environ.get('AWS_ACCESS_KEY_ID'),
                          os.environ.get('AWS_SECRET_ACCESS_KEY'))
        os.environ['AWS_ACCESS_KEY_ID'] = 'DUMMY'
        os.environ['AWS_SECRET_ACCESS_KEY'] = 'DUMMY'
        self.mock_s3 = mock_s3()
        self.mock_s3.start()

        self.file_name = 'labels.json'
        self.temp_dir = RVConfig.get_tmp_dir()
        self.file_path = os.path.join(self.temp_dir.name, self.file_name)

        self.crs_transformer = DoubleCRSTransformer()
        self.geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[0., 0.], [0., 1.], [1., 1.], [1., 0.],
                                     [0., 0.]]]
                },
                'properties': {
                    'class_id': 1,
                    'score': 0.9
                }
            }, {
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[1., 1.], [1., 2.], [2., 2.], [2., 1.],
                                     [1., 1.]]]
                },
                'properties': {
                    'score': 0.9,
                    'class_id': 2
                }
            }]
        }

        self.extent = Box.make_square(0, 0, 10)
        self.class_map = ClassMap([ClassItem(1, 'car'), ClassItem(2, 'house')])

        json_to_file(self.geojson, self.file_path)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2731')" href="javascript:;">
raster-vision-0.11.0/tests/data/label_store/test_chip_classification_geojson_store.py: 14-57
</a>
<div class="mid" id="frag2731" style="display:none"><pre>
    def setUp(self):
        self.crs_transformer = DoubleCRSTransformer()
        self.geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[0., 0.], [0., 1.], [1., 1.], [1., 0.],
                                     [0., 0.]]]
                },
                'properties': {
                    'class_name': 'car',
                    'class_id': 1
                }
            }, {
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[1., 1.], [1., 2.], [2., 2.], [2., 1.],
                                     [1., 1.]]]
                },
                'properties': {
                    'class_name': 'house',
                    'class_id': 2
                }
            }]
        }

        self.class_map = ClassMap([ClassItem(1, 'car'), ClassItem(2, 'house')])

        class MockTaskConfig():
            def __init__(self, class_map):
                self.class_map = class_map

        self.task_config = MockTaskConfig(self.class_map)
        self.temp_dir = RVConfig.get_tmp_dir()
        self.uri = os.path.join(self.temp_dir.name, 'labels.json')

        json_to_file(self.geojson, self.uri)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 108:</b> &nbsp; 2 fragments, nominal size 27 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2068')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/label_source/test_object_detection_label_source.py: 76-109
</a>
<div class="mid" id="frag2068" style="display:none"><pre>
    def test_read_with_extent(self):
        # Extent only includes the first box.
        extent = Box.make_square(0, 0, 3)
        config = ObjectDetectionLabelSourceConfig(
            vector_source=GeoJSONVectorSourceConfig(
                uri=self.file_path, default_class_id=None))
        source = config.build(
            self.class_config, self.crs_transformer, extent, self.tmp_dir.name)
        labels = source.get_labels()

        npboxes = np.array([[0., 0., 2., 2.]])
        class_ids = np.array([0])
        scores = np.array([0.9])
        expected_labels = ObjectDetectionLabels(
            npboxes, class_ids, scores=scores)
        labels.assert_equal(expected_labels)

        # Extent includes both boxes, but clips the second.
        extent = Box.make_square(0, 0, 3.9)
        config = ObjectDetectionLabelSourceConfig(
            vector_source=GeoJSONVectorSourceConfig(
                uri=self.file_path, default_class_id=None))
        source = config.build(
            self.class_config, self.crs_transformer, extent, self.tmp_dir.name)
        labels = source.get_labels()

        npboxes = np.array([[0., 0., 2., 2.], [2., 2., 3.9, 3.9]])
        class_ids = np.array([0, 1])
        scores = np.array([0.9, 0.9])
        expected_labels = ObjectDetectionLabels(
            npboxes, class_ids, scores=scores)
        labels.assert_equal(expected_labels)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2633')" href="javascript:;">
raster-vision-0.11.0/tests/data/label_source/test_object_detection_label_source.py: 106-138
</a>
<div class="mid" id="frag2633" style="display:none"><pre>
    def test_read_with_extent(self):
        # Extent only includes the first box.
        extent = Box.make_square(0, 0, 3)
        store = ObjectDetectionLabelSource(
            self.file_path,
            self.crs_transformer,
            self.class_map,
            extent=extent)
        labels = store.get_labels()

        npboxes = np.array([[0., 0., 2., 2.]])
        class_ids = np.array([1])
        scores = np.array([0.9])
        expected_labels = ObjectDetectionLabels(
            npboxes, class_ids, scores=scores)
        labels.assert_equal(expected_labels)

        # Extent includes both boxes, but clips the second.
        extent = Box.make_square(0, 0, 3.9)
        store = ObjectDetectionLabelSource(
            self.file_path,
            self.crs_transformer,
            self.class_map,
            extent=extent)
        labels = store.get_labels()

        npboxes = np.array([[0., 0., 2., 2.], [2., 2., 3.9, 3.9]])
        class_ids = np.array([1, 2])
        scores = np.array([0.9, 0.9])
        expected_labels = ObjectDetectionLabels(
            npboxes, class_ids, scores=scores)
        labels.assert_equal(expected_labels)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 109:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 91%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2069')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/raster_transformer/test_raster_transformer.py: 11-28
</a>
<div class="mid" id="frag2069" style="display:none"><pre>
    def test_stats_transformer(self):
        raster_stats = RasterStats()
        raster_stats.means = list(np.ones((4, )))
        raster_stats.stds = list(np.ones((4, )) * 2)

        with rv_config.get_tmp_dir() as tmp_dir:
            stats_uri = os.path.join(tmp_dir, 'stats.json')
            raster_stats.save(stats_uri)

            # All values have z-score of 1, which translates to
            # uint8 value of 170.
            transformer = StatsTransformerConfig(stats_uri=stats_uri).build()
            chip = np.ones((2, 2, 4)) * 3
            out_chip = transformer.transform(chip)
            expected_out_chip = np.ones((2, 2, 4)) * 170
            np.testing.assert_equal(out_chip, expected_out_chip)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2639')" href="javascript:;">
raster-vision-0.11.0/tests/data/raster_transformer/test_raster_transformer.py: 12-29
</a>
<div class="mid" id="frag2639" style="display:none"><pre>
    def test_stats_transformer(self):
        raster_stats = RasterStats()
        raster_stats.means = list(np.ones((4, )))
        raster_stats.stds = list(np.ones((4, )) * 2)

        with RVConfig.get_tmp_dir() as tmp_dir:
            stats_uri = os.path.join(tmp_dir, 'stats.json')
            raster_stats.save(stats_uri)

            # All values have z-score of 1, which translates to
            # uint8 value of 170.
            transformer = rv.RasterTransformerConfig.builder(rv.STATS_TRANSFORMER) \
                                                    .with_stats_uri(stats_uri) \
                                                    .build() \
                                                    .create_transformer()
            chip = np.ones((2, 2, 4)) * 3
            out_chip = transformer.transform(chip)
            expected_out_chip = np.ones((2, 2, 4)) * 170
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 110:</b> &nbsp; 4 fragments, nominal size 24 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2072')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/raster_source/test_rasterio_source.py: 25-51
</a>
<div class="mid" id="frag2072" style="display:none"><pre>
    def test_nodata_val(self):
        # make geotiff filled with ones and zeros with nodata == 1
        img_path = join(self.tmp_dir, 'tmp.tif')
        height = 100
        width = 100
        nb_channels = 3
        with rasterio.open(
                img_path,
                'w',
                driver='GTiff',
                height=height,
                width=width,
                count=nb_channels,
                dtype=np.uint8,
                nodata=1) as img_dataset:
            im = np.random.randint(
                0, 2, (height, width, nb_channels)).astype(np.uint8)
            for channel in range(nb_channels):
                img_dataset.write(im[:, :, channel], channel + 1)

        config = RasterioSourceConfig(uris=[img_path])
        source = config.build(tmp_dir=self.tmp_dir)
        with source.activate():
            out_chip = source.get_image_array()
            expected_out_chip = np.zeros((height, width, nb_channels))
            np.testing.assert_equal(out_chip, expected_out_chip)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2640')" href="javascript:;">
raster-vision-0.11.0/tests/data/raster_source/test_rasterio_source.py: 20-46
</a>
<div class="mid" id="frag2640" style="display:none"><pre>
    def test_nodata_val(self):
        with RVConfig.get_tmp_dir() as temp_dir:
            # make geotiff filled with ones and zeros with nodata == 1
            image_path = os.path.join(temp_dir, 'temp.tif')
            height = 100
            width = 100
            nb_channels = 3
            with rasterio.open(
                    image_path,
                    'w',
                    driver='GTiff',
                    height=height,
                    width=width,
                    count=nb_channels,
                    dtype=np.uint8,
                    nodata=1) as image_dataset:
                im = np.random.randint(
                    0, 2, (height, width, nb_channels)).astype(np.uint8)
                for channel in range(nb_channels):
                    image_dataset.write(im[:, :, channel], channel + 1)

            source = rv.RasterSourceConfig.builder(rv.RASTERIO_SOURCE) \
                                          .with_uri(image_path) \
                                          .build() \
                                          .create_source(tmp_dir=temp_dir)
            with source.activate():
                out_chip = source.get_image_array()
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2073')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/raster_source/test_rasterio_source.py: 52-79
</a>
<div class="mid" id="frag2073" style="display:none"><pre>
    def test_mask(self):
        # make geotiff filled with ones and zeros and mask the whole image
        img_path = join(self.tmp_dir, 'tmp.tif')
        height = 100
        width = 100
        nb_channels = 3
        with rasterio.open(
                img_path,
                'w',
                driver='GTiff',
                height=height,
                width=width,
                count=nb_channels,
                dtype=np.uint8) as img_dataset:
            im = np.random.randint(
                0, 2, (height, width, nb_channels)).astype(np.uint8)
            for channel in range(nb_channels):
                img_dataset.write(im[:, :, channel], channel + 1)
            img_dataset.write_mask(
                np.zeros(im.shape[0:2]).astype(np.bool))

        config = RasterioSourceConfig(uris=[img_path])
        source = config.build(tmp_dir=self.tmp_dir)
        with source.activate():
            out_chip = source.get_image_array()
            expected_out_chip = np.zeros((height, width, nb_channels))
            np.testing.assert_equal(out_chip, expected_out_chip)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2641')" href="javascript:;">
raster-vision-0.11.0/tests/data/raster_source/test_rasterio_source.py: 47-74
</a>
<div class="mid" id="frag2641" style="display:none"><pre>
                expected_out_chip = np.zeros((height, width, nb_channels))
                np.testing.assert_equal(out_chip, expected_out_chip)

    def test_mask(self):
        with RVConfig.get_tmp_dir() as temp_dir:
            # make geotiff filled with ones and zeros and mask the whole image
            image_path = os.path.join(temp_dir, 'temp.tif')
            height = 100
            width = 100
            nb_channels = 3
            with rasterio.open(
                    image_path,
                    'w',
                    driver='GTiff',
                    height=height,
                    width=width,
                    count=nb_channels,
                    dtype=np.uint8) as image_dataset:
                im = np.random.randint(
                    0, 2, (height, width, nb_channels)).astype(np.uint8)
                for channel in range(nb_channels):
                    image_dataset.write(im[:, :, channel], channel + 1)
                image_dataset.write_mask(
                    np.zeros(im.shape[0:2]).astype(np.bool))

            source = rv.RasterSourceConfig.builder(rv.RASTERIO_SOURCE) \
                                          .with_uri(image_path) \
                                          .build() \
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 111:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 92%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2076')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/raster_source/test_rasterio_source.py: 96-113
</a>
<div class="mid" id="frag2076" style="display:none"><pre>
    def test_shift_x(self):
        # Specially-engineered image w/ one meter per pixel resolution
        # in the x direction.
        img_path = data_file_path('ones.tif')
        channel_order = [0]

        config = RasterioSourceConfig(
            uris=[img_path], channel_order=channel_order,
            x_shift=1.0, y_shift=0.0)
        source = config.build(tmp_dir=self.tmp_dir)

        with source.activate():
            extent = source.get_extent()
            data = source.get_chip(extent)
            self.assertEqual(data.sum(), 2**16 - 256)
            column = data[:, 255, 0]
            self.assertEqual(column.sum(), 0)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2077')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/raster_source/test_rasterio_source.py: 114-131
</a>
<div class="mid" id="frag2077" style="display:none"><pre>
    def test_shift_y(self):
        # Specially-engineered image w/ one meter per pixel resolution
        # in the y direction.
        img_path = data_file_path('ones.tif')
        channel_order = [0]

        config = RasterioSourceConfig(
            uris=[img_path], channel_order=channel_order,
            x_shift=0.0, y_shift=1.0)
        source = config.build(tmp_dir=self.tmp_dir)

        with source.activate():
            extent = source.get_extent()
            data = source.get_chip(extent)
            self.assertEqual(data.sum(), 2**16 - 256)
            row = data[0, :, 0]
            self.assertEqual(row.sum(), 0)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 112:</b> &nbsp; 2 fragments, nominal size 15 lines, similarity 73%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2079')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/raster_source/test_rasterio_source.py: 155-172
</a>
<div class="mid" id="frag2079" style="display:none"><pre>
    def test_uses_channel_order(self):
        img_path = join(self.tmp_dir, 'img.tif')
        chip = np.ones((2, 2, 4)).astype(np.uint8)
        chip[:, :, :] *= np.array([0, 1, 2, 3]).astype(np.uint8)
        save_img(chip, img_path)

        channel_order = [0, 1, 2]
        config = RasterioSourceConfig(
            uris=[img_path], channel_order=channel_order)
        source = config.build(tmp_dir=self.tmp_dir)

        with source.activate():
            out_chip = source.get_image_array()
            expected_out_chip = np.ones((2, 2, 3)).astype(np.uint8)
            expected_out_chip[:, :, :] *= np.array([0, 1,
                                                    2]).astype(np.uint8)
            np.testing.assert_equal(out_chip, expected_out_chip)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2648')" href="javascript:;">
raster-vision-0.11.0/tests/data/raster_source/test_rasterio_source.py: 172-187
</a>
<div class="mid" id="frag2648" style="display:none"><pre>
            stats = RasterStats()
            stats.compute([
                rv.RasterSourceConfig.builder(rv.RASTERIO_SOURCE)
                .with_uri(img_path).build().create_source(temp_dir)
            ])
            stats.save(stats_uri)

            transformer = rv.RasterTransformerConfig.builder(rv.STATS_TRANSFORMER) \
                                                    .with_stats_uri(stats_uri) \
                                                    .build()

            msg = rv.RasterSourceConfig.builder(rv.RASTERIO_SOURCE) \
                                       .with_uri(img_path) \
                                       .with_channel_order(channel_order) \
                                       .with_transformer(transformer) \
                                       .build() \
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 113:</b> &nbsp; 2 fragments, nominal size 15 lines, similarity 80%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2081')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/raster_source/test_rasterio_source.py: 185-204
</a>
<div class="mid" id="frag2081" style="display:none"><pre>
    def test_detects_alpha(self):
        # Set first channel to alpha. Expectation is that when omitting channel_order,
        # only the second and third channels will be in output.
        img_path = join(self.tmp_dir, 'img.tif')
        chip = np.ones((2, 2, 3)).astype(np.uint8)
        chip[:, :, :] *= np.array([0, 1, 2]).astype(np.uint8)
        save_img(chip, img_path)

        ci = (ColorInterp.alpha, ColorInterp.blue, ColorInterp.green)
        with rasterio.open(img_path, 'r+') as src:
            src.colorinterp = ci

        config = RasterioSourceConfig(uris=[img_path])
        source = config.build(tmp_dir=self.tmp_dir)
        with source.activate():
            out_chip = source.get_image_array()
            expected_out_chip = np.ones((2, 2, 2)).astype(np.uint8)
            expected_out_chip[:, :, :] *= np.array([1, 2]).astype(np.uint8)
            np.testing.assert_equal(out_chip, expected_out_chip)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2650')" href="javascript:;">
raster-vision-0.11.0/tests/data/raster_source/test_rasterio_source.py: 199-218
</a>
<div class="mid" id="frag2650" style="display:none"><pre>
            img_path = os.path.join(tmp_dir, 'img.tif')
            chip = np.ones((2, 2, 4)).astype(np.uint8)
            chip[:, :, :] *= np.array([0, 1, 2, 3]).astype(np.uint8)
            save_img(chip, img_path)

            channel_order = [0, 1, 2]
            source = rv.RasterSourceConfig.builder(rv.RASTERIO_SOURCE) \
                                          .with_uri(img_path) \
                                          .with_channel_order(channel_order) \
                                          .build() \
                                          .create_source(tmp_dir=tmp_dir)
            with source.activate():
                out_chip = source.get_image_array()
                expected_out_chip = np.ones((2, 2, 3)).astype(np.uint8)
                expected_out_chip[:, :, :] *= np.array([0, 1,
                                                        2]).astype(np.uint8)
                np.testing.assert_equal(out_chip, expected_out_chip)

    def test_channel_order_error(self):
        with RVConfig.get_tmp_dir() as tmp_dir:
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 114:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 78%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2082')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/raster_source/test_rasterio_source.py: 205-224
</a>
<div class="mid" id="frag2082" style="display:none"><pre>
    def test_non_geo(self):
        # Check if non-georeferenced image files can be read and CRSTransformer
        # implements the identity function.
        img_path = join(self.tmp_dir, 'img.png')
        chip = np.ones((2, 2, 3)).astype(np.uint8)
        save_img(chip, img_path)

        config = RasterioSourceConfig(uris=[img_path])
        source = config.build(tmp_dir=self.tmp_dir)
        with source.activate():
            out_chip = source.get_image_array()
            np.testing.assert_equal(out_chip, chip)

            p = (3, 4)
            out_p = source.get_crs_transformer().map_to_pixel(p)
            np.testing.assert_equal(out_p, p)

            out_p = source.get_crs_transformer().pixel_to_map(p)
            np.testing.assert_equal(out_p, p)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2652')" href="javascript:;">
raster-vision-0.11.0/tests/data/raster_source/test_rasterio_source.py: 225-244
</a>
<div class="mid" id="frag2652" style="display:none"><pre>
            with self.assertRaises(ChannelOrderError):
                rv.RasterSourceConfig.builder(rv.RASTERIO_SOURCE) \
                                     .with_uri(img_path) \
                                     .with_channel_order(channel_order) \
                                     .build() \
                                     .create_source(tmp_dir=tmp_dir)

    def test_detects_alpha(self):
        # Set first channel to alpha. Expectation is that when omitting channel_order,
        # only the second and third channels will be in output.
        with RVConfig.get_tmp_dir() as tmp_dir:
            img_path = os.path.join(tmp_dir, 'img.tif')
            chip = np.ones((2, 2, 3)).astype(np.uint8)
            chip[:, :, :] *= np.array([0, 1, 2]).astype(np.uint8)
            save_img(chip, img_path)

            ci = (ColorInterp.alpha, ColorInterp.blue, ColorInterp.green)
            with rasterio.open(img_path, 'r+') as src:
                src.colorinterp = ci

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 115:</b> &nbsp; 2 fragments, nominal size 24 lines, similarity 87%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2083')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/raster_source/test_rasterio_source.py: 225-252
</a>
<div class="mid" id="frag2083" style="display:none"><pre>
    def test_no_epsg(self):
        crs = rasterio.crs.CRS()
        img_path = join(self.tmp_dir, 'tmp.tif')
        height = 100
        width = 100
        nb_channels = 3
        with rasterio.open(
                img_path,
                'w',
                driver='GTiff',
                height=height,
                width=width,
                count=nb_channels,
                dtype=np.uint8,
                crs=crs) as img_dataset:
            im = np.zeros((height, width, nb_channels)).astype(np.uint8)
            for channel in range(nb_channels):
                img_dataset.write(im[:, :, channel], channel + 1)

        try:
            config = RasterioSourceConfig(uris=[img_path])
            config.build(tmp_dir=self.tmp_dir)
        except Exception:
            self.fail(
                'Creating RasterioSource with CRS with no EPSG attribute '
                'raised an exception when it should not have.')


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2658')" href="javascript:;">
raster-vision-0.11.0/tests/data/raster_source/test_rasterio_source.py: 285-311
</a>
<div class="mid" id="frag2658" style="display:none"><pre>

    def test_with_stats_transformer(self):
        config = rv.RasterSourceConfig.builder(rv.RASTERIO_SOURCE) \
                                      .with_uri('dummy') \
                                      .with_stats_transformer() \
                                      .build()

        self.assertEqual(len(config.transformers), 1)
        self.assertIsInstance(config.transformers[0],
                              rv.data.StatsTransformerConfig)

    def test_missing_config_uri(self):
        with self.assertRaises(rv.ConfigError):
            rv.data.RasterSourceConfig.builder(rv.RASTERIO_SOURCE).build()

    def test_no_missing_config(self):
        try:
            rv.data.RasterSourceConfig.builder(
                rv.RASTERIO_SOURCE).with_uri('').build()
        except rv.ConfigError:
            self.fail('ConfigError raised unexpectedly')

    def test_backcompat_geotiff_source(self):
        msg = RasterSourceMsg()
        uris = ['a', 'b']
        x = 5
        y = 6
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 116:</b> &nbsp; 2 fragments, nominal size 29 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2087')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/raster_source/test_rasterized_source.py: 41-78
</a>
<div class="mid" id="frag2087" style="display:none"><pre>
    def test_get_chip(self):
        geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[0., 0.], [0., 5.], [5., 5.], [5., 0.],
                                     [0., 0.]]]
                },
                'properties': {
                    'class_id': self.class_id,
                }
            }, {
                'type': 'Feature',
                'geometry': {
                    'type': 'LineString',
                    'coordinates': [[7., 0.], [7., 9.]]
                },
                'properties': {
                    'class_id': self.class_id
                }
            }]
        }

        source = self.build_source(geojson)
        with source.activate():
            self.assertEqual(source.get_extent(), self.extent)
            chip = source.get_image_array()
            self.assertEqual(chip.shape, (10, 10, 1))

            expected_chip = self.background_class_id * np.ones((10, 10, 1))
            expected_chip[0:5, 0:5, 0] = self.class_id
            expected_chip[0:10, 6:8] = self.class_id
            np.testing.assert_array_equal(chip, expected_chip)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2663')" href="javascript:;">
raster-vision-0.11.0/tests/data/raster_source/test_rasterized_source.py: 40-77
</a>
<div class="mid" id="frag2663" style="display:none"><pre>
        source = config.create_source(self.uri, self.crs_transformer,
                                      self.extent)

        return source

    def test_get_chip(self):
        geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[0., 0.], [0., 5.], [5., 5.], [5., 0.],
                                     [0., 0.]]]
                },
                'properties': {
                    'class_id': self.class_id,
                }
            }, {
                'type': 'Feature',
                'geometry': {
                    'type': 'LineString',
                    'coordinates': [[7., 0.], [7., 9.]]
                },
                'properties': {
                    'class_id': self.class_id
                }
            }]
        }

        source = self.build_source(geojson)
        with source.activate():
            self.assertEqual(source.get_extent(), self.extent)
            chip = source.get_image_array()
            self.assertEqual(chip.shape, (10, 10, 1))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 117:</b> &nbsp; 2 fragments, nominal size 25 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2089')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/raster_source/test_rasterized_source.py: 93-123
</a>
<div class="mid" id="frag2089" style="display:none"><pre>
    def test_get_chip_all_touched(self):
        geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[0., 0.], [0., 0.4], [0.4, 0.4],
                                     [0.4, 0.], [0., 0.]]]
                },
                'properties': {
                    'class_id': self.class_id,
                }
            }]
        }

        false_source = self.build_source(geojson, all_touched=False)
        true_source = self.build_source(geojson, all_touched=True)
        with false_source.activate():
            chip = false_source.get_image_array()
            expected_chip = self.background_class_id * np.ones((10, 10, 1))
            np.testing.assert_array_equal(chip, expected_chip)

        with true_source.activate():
            chip = true_source.get_image_array()
            expected_chip = self.background_class_id * np.ones((10, 10, 1))
            expected_chip[0:1, 0:1, 0] = self.class_id
            np.testing.assert_array_equal(chip, expected_chip)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2665')" href="javascript:;">
raster-vision-0.11.0/tests/data/raster_source/test_rasterized_source.py: 94-124
</a>
<div class="mid" id="frag2665" style="display:none"><pre>
            expected_chip = np.zeros((10, 10, 1))
            expected_chip[0:5, 0:5, :] = self.background_class_id

            np.testing.assert_array_equal(chip, expected_chip)

    def test_get_chip_all_touched(self):
        geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'type': 'Feature',
                'geometry': {
                    'type':
                    'Polygon',
                    'coordinates': [[[0., 0.], [0., 0.4], [0.4, 0.4],
                                     [0.4, 0.], [0., 0.]]]
                },
                'properties': {
                    'class_id': self.class_id,
                }
            }]
        }

        false_source = self.build_source(geojson, all_touched=False)
        true_source = self.build_source(geojson, all_touched=True)
        with false_source.activate():
            chip = false_source.get_image_array()
            expected_chip = self.background_class_id * np.ones((10, 10, 1))
            np.testing.assert_array_equal(chip, expected_chip)

        with true_source.activate():
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 118:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2092')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/mock_raster_source.py: 15-31
</a>
<div class="mid" id="frag2092" style="display:none"><pre>
    def set_return_vals(self, raster=None):
        self.mock.get_extent.return_value = Box.make_square(0, 0, 2)
        self.mock.get_dtype.return_value = np.uint8
        self.mock.get_crs_transformer.return_value = IdentityCRSTransformer()
        self.mock._get_chip.return_value = np.random.rand(1, 2, 2, 3)

        if raster is not None:
            self.mock.get_extent.return_value = Box(0, 0, raster.shape[0],
                                                    raster.shape[1])
            self.mock.get_dtype.return_value = raster.dtype

            def get_chip(window):
                return raster[window.ymin:window.ymax, window.xmin:
                              window.xmax, :]

            self.mock._get_chip.side_effect = get_chip

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2261')" href="javascript:;">
raster-vision-0.11.0/tests/mock/raster_source.py: 23-39
</a>
<div class="mid" id="frag2261" style="display:none"><pre>

    def set_return_vals(self, raster=None):
        self.mock.get_extent.return_value = Box.make_square(0, 0, 2)
        self.mock.get_dtype.return_value = np.uint8
        self.mock.get_crs_transformer.return_value = IdentityCRSTransformer()
        self.mock._get_chip.return_value = np.random.rand(1, 2, 2, 3)

        if raster is not None:
            self.mock.get_extent.return_value = Box(0, 0, raster.shape[0],
                                                    raster.shape[1])
            self.mock.get_dtype.return_value = raster.dtype

            def get_chip(window):
                return raster[window.ymin:window.ymax, window.xmin:
                              window.xmax, :]

            self.mock._get_chip.side_effect = get_chip
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 119:</b> &nbsp; 2 fragments, nominal size 25 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2103')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/vector_source/test_geojson_vector_source.py: 24-53
</a>
<div class="mid" id="frag2103" style="display:none"><pre>
    def _test_class_inf(self, props, exp_class_ids, default_class_id=None):
        geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'properties': props,
                'geometry': {
                    'type': 'Point',
                    'coordinates': [1, 1]
                }
            }]
        }
        json_to_file(geojson, self.uri)

        class_config = ClassConfig(names=['building', 'car', 'tree'])
        class_id_to_filter = {
            0: ['==', 'type', 'building'],
            1: ['any', ['==', 'type', 'car'], ['==', 'type', 'auto']]
        }
        vs_cfg = GeoJSONVectorSourceConfig(
            uri=self.uri,
            class_id_to_filter=class_id_to_filter,
            default_class_id=default_class_id)
        vs = vs_cfg.build(class_config, IdentityCRSTransformer())
        trans_geojson = vs.get_geojson()
        class_ids = [
            f['properties']['class_id'] for f in trans_geojson['features']
        ]
        self.assertEqual(class_ids, exp_class_ids)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2684')" href="javascript:;">
raster-vision-0.11.0/tests/data/vector_source/test_geojson_vector_source.py: 27-57
</a>
<div class="mid" id="frag2684" style="display:none"><pre>
    def _test_class_inf(self, props, exp_class_ids, default_class_id=None):
        geojson = {
            'type':
            'FeatureCollection',
            'features': [{
                'properties': props,
                'geometry': {
                    'type': 'Point',
                    'coordinates': [1, 1]
                }
            }]
        }
        json_to_file(geojson, self.uri)

        class_map = ClassMap.construct_from(['building', 'car', 'tree'])
        class_id_to_filter = {
            1: ['==', 'type', 'building'],
            2: ['any', ['==', 'type', 'car'], ['==', 'type', 'auto']]
        }
        b = GeoJSONVectorSourceConfigBuilder() \
            .with_class_inference(class_id_to_filter=class_id_to_filter,
                                  default_class_id=default_class_id) \
            .with_uri(self.uri) \
            .build()
        msg = b.to_proto()
        config = GeoJSONVectorSourceConfig.from_proto(msg)
        source = config.create_source(
            crs_transformer=IdentityCRSTransformer(), class_map=class_map)
        trans_geojson = source.get_geojson()
        class_ids = [
            f['properties']['class_id'] for f in trans_geojson['features']
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 120:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2112')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/vector_source/test_geojson_vector_source.py: 97-113
</a>
<div class="mid" id="frag2112" style="display:none"><pre>
    def test_transform_geojson_geom_coll(self):
        geom = {
            'type':
            'GeometryCollection',
            'geometries': [{
                'type': 'MultiPoint',
                'coordinates': [[10, 10], [20, 20]]
            }]
        }
        geojson = self.geom_to_geojson(geom)
        trans_geojson = self.transform_geojson(geojson)

        feats = trans_geojson['features']
        self.assertEqual(len(feats), 2)
        self.assertEqual(feats[0]['geometry']['type'], 'Polygon')
        self.assertEqual(feats[1]['geometry']['type'], 'Polygon')

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2693')" href="javascript:;">
raster-vision-0.11.0/tests/data/vector_source/test_geojson_vector_source.py: 100-116
</a>
<div class="mid" id="frag2693" style="display:none"><pre>
        geom = {'type': 'Point', 'coordinates': []}
        geojson = self.geom_to_geojson(geom)
        trans_geojson = self.transform_geojson(geojson)

        self.assertEqual(0, len(trans_geojson['features']))

    def test_transform_geojson_geom_coll(self):
        geom = {
            'type':
            'GeometryCollection',
            'geometries': [{
                'type': 'MultiPoint',
                'coordinates': [[10, 10], [20, 20]]
            }]
        }
        geojson = self.geom_to_geojson(geom)
        trans_geojson = self.transform_geojson(geojson)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 121:</b> &nbsp; 4 fragments, nominal size 12 lines, similarity 91%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2114')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/vector_source/test_geojson_vector_source.py: 124-139
</a>
<div class="mid" id="frag2114" style="display:none"><pre>
    def test_transform_geojson_line_buf(self):
        geom = {'type': 'LineString', 'coordinates': [[10, 10], [10, 20]]}
        geojson = self.geom_to_geojson(geom)

        trans_geojson = self.transform_geojson(geojson, line_bufs={0: 5.0})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).buffer(5.0).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(geojson, line_bufs={1: 5.0})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).buffer(1.0).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(geojson, line_bufs={0: None})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).equals(shape(trans_geom)))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2115')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/vector_source/test_geojson_vector_source.py: 140-155
</a>
<div class="mid" id="frag2115" style="display:none"><pre>
    def test_transform_point_buf(self):
        geom = {'type': 'Point', 'coordinates': [10, 10]}
        geojson = self.geom_to_geojson(geom)

        trans_geojson = self.transform_geojson(geojson, point_bufs={0: 5.0})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).buffer(5.0).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(geojson, point_bufs={1: 5.0})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).buffer(1.0).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(geojson, point_bufs={0: None})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).equals(shape(trans_geom)))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2696')" href="javascript:;">
raster-vision-0.11.0/tests/data/vector_source/test_geojson_vector_source.py: 143-158
</a>
<div class="mid" id="frag2696" style="display:none"><pre>
        self.assertTrue(shape(geom).buffer(1.0).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(geojson, line_bufs={1: None})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).equals(shape(trans_geom)))

    def test_transform_point_buf(self):
        geom = {'type': 'Point', 'coordinates': [10, 10]}
        geojson = self.geom_to_geojson(geom)

        trans_geojson = self.transform_geojson(geojson, point_bufs={1: 5.0})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).buffer(5.0).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(geojson, point_bufs={2: 5.0})
        trans_geom = trans_geojson['features'][0]['geometry']
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2695')" href="javascript:;">
raster-vision-0.11.0/tests/data/vector_source/test_geojson_vector_source.py: 127-142
</a>
<div class="mid" id="frag2695" style="display:none"><pre>

        feats = trans_geojson['features']
        self.assertEqual(len(feats), 2)
        self.assertEqual(feats[0]['geometry']['type'], 'Polygon')
        self.assertEqual(feats[1]['geometry']['type'], 'Polygon')

    def test_transform_geojson_line_buf(self):
        geom = {'type': 'LineString', 'coordinates': [[10, 10], [10, 20]]}
        geojson = self.geom_to_geojson(geom)

        trans_geojson = self.transform_geojson(geojson, line_bufs={1: 5.0})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).buffer(5.0).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(geojson, line_bufs={2: 5.0})
        trans_geom = trans_geojson['features'][0]['geometry']
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 122:</b> &nbsp; 2 fragments, nominal size 21 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2116')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/vector_source/test_geojson_vector_source.py: 156-183
</a>
<div class="mid" id="frag2116" style="display:none"><pre>
    def test_transform_polygon(self):
        geom = {
            'type': 'Polygon',
            'coordinates': [[[0, 0], [0, 10], [10, 10], [10, 0], [0, 0]]]
        }
        geojson = self.geom_to_geojson(geom)

        trans_geojson = self.transform_geojson(geojson)
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(
            geojson, crs_transformer=DoubleCRSTransformer())
        trans_geom = trans_geojson['features'][0]['geometry']
        exp_geom = {
            'type': 'Polygon',
            'coordinates': [[[0, 0], [0, 20], [20, 20], [20, 0], [0, 0]]]
        }
        self.assertTrue(shape(exp_geom).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(
            geojson,
            crs_transformer=DoubleCRSTransformer(),
            to_map_coords=True)
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).equals(shape(trans_geom)))


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2697')" href="javascript:;">
raster-vision-0.11.0/tests/data/vector_source/test_geojson_vector_source.py: 159-185
</a>
<div class="mid" id="frag2697" style="display:none"><pre>
        self.assertTrue(shape(geom).buffer(1.0).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(geojson, point_bufs={1: None})
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).equals(shape(trans_geom)))

    def test_transform_polygon(self):
        geom = {
            'type': 'Polygon',
            'coordinates': [[[0, 0], [0, 10], [10, 10], [10, 0], [0, 0]]]
        }
        geojson = self.geom_to_geojson(geom)

        trans_geojson = self.transform_geojson(geojson)
        trans_geom = trans_geojson['features'][0]['geometry']
        self.assertTrue(shape(geom).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(
            geojson, crs_transformer=DoubleCRSTransformer())
        trans_geom = trans_geojson['features'][0]['geometry']
        exp_geom = {
            'type': 'Polygon',
            'coordinates': [[[0, 0], [0, 20], [20, 20], [20, 0], [0, 0]]]
        }
        self.assertTrue(shape(exp_geom).equals(shape(trans_geom)))

        trans_geojson = self.transform_geojson(
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 123:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 90%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2119')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/label/test_object_detection_labels.py: 13-23
</a>
<div class="mid" id="frag2119" style="display:none"><pre>
    def setUp(self):
        self.class_config = ClassConfig(names=['car', 'house'])
        self.npboxes = np.array([
            [0., 0., 2., 2.],
            [2., 2., 4., 4.],
        ])
        self.class_ids = np.array([0, 1])
        self.scores = np.array([0.9, 0.9])
        self.labels = ObjectDetectionLabels(
            self.npboxes, self.class_ids, scores=self.scores)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2706')" href="javascript:;">
raster-vision-0.11.0/tests/data/label/test_object_detection_labels.py: 12-23
</a>
<div class="mid" id="frag2706" style="display:none"><pre>
    def setUp(self):
        self.class_map = ClassMap([ClassItem(1, 'car'), ClassItem(2, 'house')])

        self.npboxes = np.array([
            [0., 0., 2., 2.],
            [2., 2., 4., 4.],
        ])
        self.class_ids = np.array([1, 2])
        self.scores = np.array([0.9, 0.9])
        self.labels = ObjectDetectionLabels(
            self.npboxes, self.class_ids, scores=self.scores)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 124:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2122')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/label/test_object_detection_labels.py: 41-53
</a>
<div class="mid" id="frag2122" style="display:none"><pre>
    def test_constructor(self):
        labels = ObjectDetectionLabels(
            self.npboxes, self.class_ids, scores=self.scores)
        expected_labels = ObjectDetectionLabels(self.npboxes, self.class_ids,
                                                self.scores)
        labels.assert_equal(expected_labels)

        labels = ObjectDetectionLabels(self.npboxes, self.class_ids)
        scores = np.ones(self.class_ids.shape)
        expected_labels = ObjectDetectionLabels(
            self.npboxes, self.class_ids, scores=scores)
        labels.assert_equal(expected_labels)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2709')" href="javascript:;">
raster-vision-0.11.0/tests/data/label/test_object_detection_labels.py: 42-54
</a>
<div class="mid" id="frag2709" style="display:none"><pre>
    def test_constructor(self):
        labels = ObjectDetectionLabels(
            self.npboxes, self.class_ids, scores=self.scores)
        expected_labels = ObjectDetectionLabels(self.npboxes, self.class_ids,
                                                self.scores)
        labels.assert_equal(expected_labels)

        labels = ObjectDetectionLabels(self.npboxes, self.class_ids)
        scores = np.ones(self.class_ids.shape)
        expected_labels = ObjectDetectionLabels(
            self.npboxes, self.class_ids, scores=scores)
        labels.assert_equal(expected_labels)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 125:</b> &nbsp; 2 fragments, nominal size 23 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2129')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/label/test_object_detection_labels.py: 104-129
</a>
<div class="mid" id="frag2129" style="display:none"><pre>
    def test_get_overlapping(self):
        window = Box.make_square(0, 0, 2.01)
        labels = ObjectDetectionLabels.get_overlapping(self.labels, window)
        labels.assert_equal(self.labels)

        window = Box.make_square(0, 0, 3)
        labels = ObjectDetectionLabels.get_overlapping(
            self.labels, window, ioa_thresh=0.5)
        npboxes = np.array([[0., 0., 2., 2.]])
        class_ids = np.array([0])
        scores = np.array([0.9])
        expected_labels = ObjectDetectionLabels(
            npboxes, class_ids, scores=scores)
        labels.assert_equal(expected_labels)

        window = Box.make_square(0, 0, 3)
        labels = ObjectDetectionLabels.get_overlapping(
            self.labels, window, ioa_thresh=0.1, clip=True)
        expected_npboxes = np.array([
            [0., 0., 2., 2.],
            [2., 2., 3., 3.],
        ])
        expected_labels = ObjectDetectionLabels(
            expected_npboxes, self.class_ids, scores=self.scores)
        labels.assert_equal(expected_labels)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2716')" href="javascript:;">
raster-vision-0.11.0/tests/data/label/test_object_detection_labels.py: 105-130
</a>
<div class="mid" id="frag2716" style="display:none"><pre>
    def test_get_overlapping(self):
        window = Box.make_square(0, 0, 2.01)
        labels = ObjectDetectionLabels.get_overlapping(self.labels, window)
        labels.assert_equal(self.labels)

        window = Box.make_square(0, 0, 3)
        labels = ObjectDetectionLabels.get_overlapping(
            self.labels, window, ioa_thresh=0.5)
        npboxes = np.array([[0., 0., 2., 2.]])
        class_ids = np.array([1])
        scores = np.array([0.9])
        expected_labels = ObjectDetectionLabels(
            npboxes, class_ids, scores=scores)
        labels.assert_equal(expected_labels)

        window = Box.make_square(0, 0, 3)
        labels = ObjectDetectionLabels.get_overlapping(
            self.labels, window, ioa_thresh=0.1, clip=True)
        expected_npboxes = np.array([
            [0., 0., 2., 2.],
            [2., 2., 3., 3.],
        ])
        expected_labels = ObjectDetectionLabels(
            expected_npboxes, self.class_ids, scores=self.scores)
        labels.assert_equal(expected_labels)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 126:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2130')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/label/test_object_detection_labels.py: 130-144
</a>
<div class="mid" id="frag2130" style="display:none"><pre>
    def test_concatenate(self):
        npboxes = np.array([[4., 4., 5., 5.]])
        class_ids = np.array([1])
        scores = np.array([0.3])
        labels = ObjectDetectionLabels(npboxes, class_ids, scores=scores)
        new_labels = ObjectDetectionLabels.concatenate(self.labels, labels)

        npboxes = np.array([[0., 0., 2., 2.], [2., 2., 4., 4.],
                            [4., 4., 5., 5.]])
        class_ids = np.array([0, 1, 1])
        scores = np.array([0.9, 0.9, 0.3])
        expected_labels = ObjectDetectionLabels(
            npboxes, class_ids, scores=scores)
        new_labels.assert_equal(expected_labels)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2717')" href="javascript:;">
raster-vision-0.11.0/tests/data/label/test_object_detection_labels.py: 131-145
</a>
<div class="mid" id="frag2717" style="display:none"><pre>
    def test_concatenate(self):
        npboxes = np.array([[4., 4., 5., 5.]])
        class_ids = np.array([2])
        scores = np.array([0.3])
        labels = ObjectDetectionLabels(npboxes, class_ids, scores=scores)
        new_labels = ObjectDetectionLabels.concatenate(self.labels, labels)

        npboxes = np.array([[0., 0., 2., 2.], [2., 2., 4., 4.],
                            [4., 4., 5., 5.]])
        class_ids = np.array([1, 2, 2])
        scores = np.array([0.9, 0.9, 0.3])
        expected_labels = ObjectDetectionLabels(
            npboxes, class_ids, scores=scores)
        new_labels.assert_equal(expected_labels)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 127:</b> &nbsp; 2 fragments, nominal size 27 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2131')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/label/test_object_detection_labels.py: 145-182
</a>
<div class="mid" id="frag2131" style="display:none"><pre>
    def test_prune_duplicates(self):
        # This first box has a score below score_thresh so it should get
        # pruned. The third box overlaps with the second, but has higher score,
        # so the second one should get pruned. The fourth box overlaps with
        # the second less than merge_thresh, so it should not get pruned.
        npboxes = np.array([[0., 0., 2., 2.], [2., 2., 4., 4.],
                            [2.1, 2.1, 4.1, 4.1], [3.5, 3.5, 5.5, 5.5]])
        class_ids = np.array([0, 1, 0, 1])
        scores = np.array([0.2, 0.9, 0.9, 1.0])
        labels = ObjectDetectionLabels(npboxes, class_ids, scores=scores)
        score_thresh = 0.5
        merge_thresh = 0.5
        pruned_labels = ObjectDetectionLabels.prune_duplicates(
            labels, score_thresh, merge_thresh)

        self.assertEqual(len(pruned_labels), 2)

        expected_npboxes = np.array([[2.1, 2.1, 4.1, 4.1],
                                     [3.5, 3.5, 5.5, 5.5]])
        expected_class_ids = np.array([0, 1])
        expected_scores = np.array([0.9, 1.0])

        # prune_duplicates does not maintain ordering of boxes, so find match
        # between pruned boxes and expected_npboxes.
        pruned_npboxes = pruned_labels.get_npboxes()
        pruned_inds = [None, None]
        for box_ind, box in enumerate(expected_npboxes):
            for pruned_box_ind, pruned_box in enumerate(pruned_npboxes):
                if np.array_equal(pruned_box, box):
                    pruned_inds[box_ind] = pruned_box_ind
        self.assertTrue(np.all(pruned_inds is not None))

        expected_labels = ObjectDetectionLabels(
            expected_npboxes[pruned_inds],
            expected_class_ids[pruned_inds],
            scores=expected_scores[pruned_inds])
        pruned_labels.assert_equal(expected_labels)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2718')" href="javascript:;">
raster-vision-0.11.0/tests/data/label/test_object_detection_labels.py: 146-183
</a>
<div class="mid" id="frag2718" style="display:none"><pre>
    def test_prune_duplicates(self):
        # This first box has a score below score_thresh so it should get
        # pruned. The third box overlaps with the second, but has higher score,
        # so the second one should get pruned. The fourth box overlaps with
        # the second less than merge_thresh, so it should not get pruned.
        npboxes = np.array([[0., 0., 2., 2.], [2., 2., 4., 4.],
                            [2.1, 2.1, 4.1, 4.1], [3.5, 3.5, 5.5, 5.5]])
        class_ids = np.array([1, 2, 1, 2])
        scores = np.array([0.2, 0.9, 0.9, 1.0])
        labels = ObjectDetectionLabels(npboxes, class_ids, scores=scores)
        score_thresh = 0.5
        merge_thresh = 0.5
        pruned_labels = ObjectDetectionLabels.prune_duplicates(
            labels, score_thresh, merge_thresh)

        self.assertEqual(len(pruned_labels), 2)

        expected_npboxes = np.array([[2.1, 2.1, 4.1, 4.1],
                                     [3.5, 3.5, 5.5, 5.5]])
        expected_class_ids = np.array([1, 2])
        expected_scores = np.array([0.9, 1.0])

        # prune_duplicates does not maintain ordering of boxes, so find match
        # between pruned boxes and expected_npboxes.
        pruned_npboxes = pruned_labels.get_npboxes()
        pruned_inds = [None, None]
        for box_ind, box in enumerate(expected_npboxes):
            for pruned_box_ind, pruned_box in enumerate(pruned_npboxes):
                if np.array_equal(pruned_box, box):
                    pruned_inds[box_ind] = pruned_box_ind
        self.assertTrue(np.all(pruned_inds is not None))

        expected_labels = ObjectDetectionLabels(
            expected_npboxes[pruned_inds],
            expected_class_ids[pruned_inds],
            scores=expected_scores[pruned_inds])
        pruned_labels.assert_equal(expected_labels)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 128:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2132')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/label/test_object_detection_labels.py: 183-198
</a>
<div class="mid" id="frag2132" style="display:none"><pre>
    def test_filter_by_aoi(self):
        aois = [Box.make_square(0, 0, 2).to_shapely()]
        filt_labels = self.labels.filter_by_aoi(aois)

        npboxes = np.array([[0., 0., 2., 2.]])
        class_ids = np.array([0])
        scores = np.array([0.9])
        exp_labels = ObjectDetectionLabels(npboxes, class_ids, scores=scores)
        self.assertEqual(filt_labels, exp_labels)

        aois = [Box.make_square(4, 4, 2).to_shapely()]
        filt_labels = self.labels.filter_by_aoi(aois)
        exp_labels = ObjectDetectionLabels.make_empty()
        self.assertEqual(filt_labels, exp_labels)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2719')" href="javascript:;">
raster-vision-0.11.0/tests/data/label/test_object_detection_labels.py: 184-199
</a>
<div class="mid" id="frag2719" style="display:none"><pre>
    def test_filter_by_aoi(self):
        aois = [Box.make_square(0, 0, 2).to_shapely()]
        filt_labels = self.labels.filter_by_aoi(aois)

        npboxes = np.array([[0., 0., 2., 2.]])
        class_ids = np.array([1])
        scores = np.array([0.9])
        exp_labels = ObjectDetectionLabels(npboxes, class_ids, scores=scores)
        self.assertEqual(filt_labels, exp_labels)

        aois = [Box.make_square(4, 4, 2).to_shapely()]
        filt_labels = self.labels.filter_by_aoi(aois)
        exp_labels = ObjectDetectionLabels.make_empty()
        self.assertEqual(filt_labels, exp_labels)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 129:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2139')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/data/label/test_chip_classification_labels.py: 67-83
</a>
<div class="mid" id="frag2139" style="display:none"><pre>
    def test_filter_by_aoi(self):
        aois = [Box.make_square(0, 0, 2).to_shapely()]
        filt_labels = self.labels.filter_by_aoi(aois)

        exp_labels = ChipClassificationLabels()
        cell1 = Box.make_square(0, 0, 2)
        class_id1 = 1
        exp_labels.set_cell(cell1, class_id1)
        self.assertEqual(filt_labels, exp_labels)

        aois = [Box.make_square(4, 4, 2).to_shapely()]
        filt_labels = self.labels.filter_by_aoi(aois)

        exp_labels = ChipClassificationLabels()
        self.assertEqual(filt_labels, exp_labels)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2726')" href="javascript:;">
raster-vision-0.11.0/tests/data/label/test_chip_classification_labels.py: 66-82
</a>
<div class="mid" id="frag2726" style="display:none"><pre>
    def test_filter_by_aoi(self):
        aois = [Box.make_square(0, 0, 2).to_shapely()]
        filt_labels = self.labels.filter_by_aoi(aois)

        exp_labels = ChipClassificationLabels()
        cell1 = Box.make_square(0, 0, 2)
        class_id1 = 1
        exp_labels.set_cell(cell1, class_id1)
        self.assertEqual(filt_labels, exp_labels)

        aois = [Box.make_square(4, 4, 2).to_shapely()]
        filt_labels = self.labels.filter_by_aoi(aois)

        exp_labels = ChipClassificationLabels()
        self.assertEqual(filt_labels, exp_labels)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 130:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2167')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/test_box.py: 144-156
</a>
<div class="mid" id="frag2167" style="display:none"><pre>

    def test_make_buffer(self):
        buffer_size = 1
        max_extent = Box.make_square(0, 0, 3)
        buffer_box = Box(0, 0, 3, 3)
        output_buffer_box = self.box.make_buffer(buffer_size, max_extent)
        self.assertEqual(output_buffer_box, buffer_box)

        buffer_size = 0.5
        max_extent = Box.make_square(0, 0, 5)
        buffer_box = Box(0, 0, 3, 5)
        output_buffer_box = self.box.make_buffer(buffer_size, max_extent)
        self.assertEqual(output_buffer_box, buffer_box)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2911')" href="javascript:;">
raster-vision-0.11.0/tests/core/test_box.py: 144-156
</a>
<div class="mid" id="frag2911" style="display:none"><pre>

    def test_make_buffer(self):
        buffer_size = 1
        max_extent = Box.make_square(0, 0, 3)
        buffer_box = Box(0, 0, 3, 3)
        output_buffer_box = self.box.make_buffer(buffer_size, max_extent)
        self.assertEqual(output_buffer_box, buffer_box)

        buffer_size = 0.5
        max_extent = Box.make_square(0, 0, 5)
        buffer_box = Box(0, 0, 3, 5)
        output_buffer_box = self.box.make_buffer(buffer_size, max_extent)
        self.assertEqual(output_buffer_box, buffer_box)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 131:</b> &nbsp; 2 fragments, nominal size 29 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2169')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/test_box.py: 162-197
</a>
<div class="mid" id="frag2169" style="display:none"><pre>

    def test_get_windows(self):
        extent = Box(0, 0, 100, 100)
        windows = list(extent.get_windows(10, 10))
        self.assertEqual(len(windows), 100)

        extent = Box(0, 0, 100, 100)
        windows = list(extent.get_windows(10, 5))
        self.assertEqual(len(windows), 400)

        extent = Box(0, 0, 20, 20)
        windows = set(
            [window.tuple_format() for window in extent.get_windows(10, 10)])
        expected_windows = [
            Box.make_square(0, 0, 10),
            Box.make_square(10, 0, 10),
            Box.make_square(0, 10, 10),
            Box.make_square(10, 10, 10)
        ]
        expected_windows = set(
            [window.tuple_format() for window in expected_windows])
        self.assertSetEqual(windows, expected_windows)

        extent = Box(10, 10, 20, 20)
        windows = set(
            [window.tuple_format() for window in extent.get_windows(6, 6)])
        expected_windows = [
            Box.make_square(10, 10, 6),
            Box.make_square(10, 16, 6),
            Box.make_square(16, 10, 6),
            Box.make_square(16, 16, 6)
        ]
        expected_windows = set(
            [window.tuple_format() for window in expected_windows])
        self.assertSetEqual(windows, expected_windows)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2913')" href="javascript:;">
raster-vision-0.11.0/tests/core/test_box.py: 162-197
</a>
<div class="mid" id="frag2913" style="display:none"><pre>

    def test_get_windows(self):
        extent = Box(0, 0, 100, 100)
        windows = list(extent.get_windows(10, 10))
        self.assertEqual(len(windows), 100)

        extent = Box(0, 0, 100, 100)
        windows = list(extent.get_windows(10, 5))
        self.assertEqual(len(windows), 400)

        extent = Box(0, 0, 20, 20)
        windows = set(
            [window.tuple_format() for window in extent.get_windows(10, 10)])
        expected_windows = [
            Box.make_square(0, 0, 10),
            Box.make_square(10, 0, 10),
            Box.make_square(0, 10, 10),
            Box.make_square(10, 10, 10)
        ]
        expected_windows = set(
            [window.tuple_format() for window in expected_windows])
        self.assertSetEqual(windows, expected_windows)

        extent = Box(10, 10, 20, 20)
        windows = set(
            [window.tuple_format() for window in extent.get_windows(6, 6)])
        expected_windows = [
            Box.make_square(10, 10, 6),
            Box.make_square(10, 16, 6),
            Box.make_square(16, 10, 6),
            Box.make_square(16, 16, 6)
        ]
        expected_windows = set(
            [window.tuple_format() for window in expected_windows])
        self.assertSetEqual(windows, expected_windows)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 132:</b> &nbsp; 2 fragments, nominal size 40 lines, similarity 82%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2170')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/evaluation/test_semantic_segmentation_evaluation.py: 13-61
</a>
<div class="mid" id="frag2170" style="display:none"><pre>
    def test_compute(self):
        class_config = ClassConfig(names=['one', 'two'])
        class_config.update()
        class_config.ensure_null_class()
        null_class_id = class_config.get_null_class_id()

        gt_array = np.zeros((4, 4, 1), dtype=np.uint8)
        gt_array[2, 2, 0] = 1
        gt_array[0, 0, 0] = 2
        gt_raster = MockRasterSource([0], 1)
        gt_raster.set_raster(gt_array)
        gt_label_source = SemanticSegmentationLabelSource(gt_raster, null_class_id)

        p_array = np.zeros((4, 4, 1), dtype=np.uint8)
        p_array[1, 1, 0] = 1
        p_raster = MockRasterSource([0], 1)
        p_raster.set_raster(p_array)
        p_label_source = SemanticSegmentationLabelSource(p_raster, null_class_id)

        eval = SemanticSegmentationEvaluation(class_config)
        eval.compute(gt_label_source.get_labels(), p_label_source.get_labels())

        tp0 = 16 - 3  # 4*4 - 3 true positives for class 0
        fp0 = 1  # 1 false positive (2,2) and one don't care at (0,0)
        fn0 = 1  # one false negative (1,1)
        precision0 = float(tp0) / (tp0 + fp0)
        recall0 = float(tp0) / (tp0 + fn0)
        f10 = 2 * float(precision0 * recall0) / (precision0 + recall0)

        tp1 = 0  # 0 true positives for class 1
        fn1 = 1  # one false negative (2,2)
        precision1 = 0  # float(tp1) / (tp1 + fp1) where fp1 == 1
        recall1 = float(tp1) / (tp1 + fn1)
        f11 = None

        self.assertAlmostEqual(precision0,
                               eval.class_to_eval_item[0].precision)
        self.assertAlmostEqual(recall0, eval.class_to_eval_item[0].recall)
        self.assertAlmostEqual(f10, eval.class_to_eval_item[0].f1)

        self.assertEqual(precision1, eval.class_to_eval_item[1].precision)
        self.assertAlmostEqual(recall1, eval.class_to_eval_item[1].recall)
        self.assertAlmostEqual(f11, eval.class_to_eval_item[1].f1)

        avg_conf_mat = np.array([[0, 0, 0], [13., 1, 0], [1, 0, 0]])
        avg_recall = (14 / 15) * recall0 + (1 / 15) * recall1
        self.assertTrue(np.array_equal(avg_conf_mat, eval.avg_item.conf_mat))
        self.assertEqual(avg_recall, eval.avg_item.recall)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2830')" href="javascript:;">
raster-vision-0.11.0/tests/evaluation/test_semantic_segmentation_evaluation.py: 15-63
</a>
<div class="mid" id="frag2830" style="display:none"><pre>
    def test_compute(self):
        class_map = ClassMap(
            [ClassItem(id=1, name='one'),
             ClassItem(id=2, name='two')])

        # Mismatches: 0 -&gt; 1, 2 -&gt; 1, 1 -&gt; 0
        gt_array = np.ones((4, 4, 1), dtype=np.uint8)
        gt_array[0, 0, 0] = 0
        gt_array[2, 2, 0] = 2
        gt_raster = MockRasterSource([0], 1)
        gt_raster.set_raster(gt_array)
        gt_label_source = SemanticSegmentationLabelSource(source=gt_raster)

        p_array = np.ones((4, 4, 1), dtype=np.uint8)
        p_array[1, 1, 0] = 0
        p_raster = MockRasterSource([0], 1)
        p_raster.set_raster(p_array)
        p_label_source = SemanticSegmentationLabelSource(source=p_raster)

        eval = SemanticSegmentationEvaluation(class_map)
        eval.compute(gt_label_source.get_labels(), p_label_source.get_labels())

        tp1 = 16 - 3  # 4*4 - 3 true positives for class 1
        fp1 = 1  # 1 false positive (2,2) and one don't care at (0,0)
        fn1 = 1  # one false negative (1,1)
        precision1 = float(tp1) / (tp1 + fp1)
        recall1 = float(tp1) / (tp1 + fn1)
        f11 = 2 * float(precision1 * recall1) / (precision1 + recall1)

        tp2 = 0  # 0 true positives for class 2
        fn2 = 1  # one false negative (2,2)
        precision2 = None  # float(tp2) / (tp2 + fp2) where fp2 == 0
        recall2 = float(tp2) / (tp2 + fn2)
        f12 = None

        self.assertAlmostEqual(precision1,
                               eval.class_to_eval_item[1].precision)
        self.assertAlmostEqual(recall1, eval.class_to_eval_item[1].recall)
        self.assertAlmostEqual(f11, eval.class_to_eval_item[1].f1)

        self.assertEqual(precision2, eval.class_to_eval_item[2].precision)
        self.assertAlmostEqual(recall2, eval.class_to_eval_item[2].recall)
        self.assertAlmostEqual(f12, eval.class_to_eval_item[2].f1)

        avg_conf_mat = np.array([[0, 0, 0], [1., 13, 0], [0, 1, 0]])
        avg_recall = (14 / 15) * recall1 + (1 / 15) * recall2
        self.assertTrue(np.array_equal(avg_conf_mat, eval.avg_item.conf_mat))
        self.assertEqual(avg_recall, eval.avg_item.recall)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 133:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 80%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2172')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/evaluation/test_semantic_segmentation_evaluation.py: 86-109
</a>
<div class="mid" id="frag2172" style="display:none"><pre>
    def test_vector_compute(self):
        class_config = ClassConfig(names=['one', 'two'])
        class_config.update()
        class_config.ensure_null_class()

        gt_uri = data_file_path('2-gt-polygons.geojson')
        pred_uri = data_file_path('2-pred-polygons.geojson')

        eval = SemanticSegmentationEvaluation(class_config)
        eval.compute_vector(gt_uri, pred_uri, 'polygons', 0)

        # NOTE: The  two geojson files referenced  above contain three
        # unique geometries total, each  file contains two geometries,
        # and there is one geometry shared between the two.
        tp = 1.0
        fp = 1.0
        fn = 1.0
        precision = float(tp) / (tp + fp)
        recall = float(tp) / (tp + fn)

        self.assertAlmostEqual(precision, eval.class_to_eval_item[0].precision)
        self.assertAlmostEqual(recall, eval.class_to_eval_item[0].recall)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2832')" href="javascript:;">
raster-vision-0.11.0/tests/evaluation/test_semantic_segmentation_evaluation.py: 88-108
</a>
<div class="mid" id="frag2832" style="display:none"><pre>
    def test_vector_compute(self):
        class_map = ClassMap([ClassItem(id=1, name='one', color='#000021')])
        gt_uri = data_file_path('3-gt-polygons.geojson')
        pred_uri = data_file_path('3-pred-polygons.geojson')

        eval = SemanticSegmentationEvaluation(class_map)
        eval.compute_vector(gt_uri, pred_uri, 'polygons', 1)

        # NOTE: The  two geojson files referenced  above contain three
        # unique geometries total, each  file contains two geometries,
        # and there is one geometry shared between the two.
        tp = 1.0
        fp = 1.0
        fn = 1.0
        precision = float(tp) / (tp + fp)
        recall = float(tp) / (tp + fn)

        self.assertAlmostEqual(precision, eval.class_to_eval_item[1].precision)
        self.assertAlmostEqual(recall, eval.class_to_eval_item[1].recall)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 134:</b> &nbsp; 2 fragments, nominal size 17 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2174')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/evaluation/test_chip_classification_evaluation.py: 13-37
</a>
<div class="mid" id="frag2174" style="display:none"><pre>
    def make_labels(self, class_ids):
        """Make 2x2 grid label store.

        Args:
            class_ids: 2x2 array of class_ids to use
        """
        cell_size = 200
        y_cells = 2
        x_cells = 2
        labels = ChipClassificationLabels()

        for yind in range(y_cells):
            for xind in range(x_cells):
                ymin = yind * cell_size
                xmin = xind * cell_size
                ymax = ymin + cell_size
                xmax = xmin + cell_size
                window = Box(ymin, xmin, ymax, xmax)
                class_id = class_ids[yind][xind]
                new_labels = ChipClassificationLabels()
                new_labels.set_cell(window, class_id)
                labels.extend(new_labels)

        return labels

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2836')" href="javascript:;">
raster-vision-0.11.0/tests/evaluation/test_chip_classification_evaluation.py: 14-38
</a>
<div class="mid" id="frag2836" style="display:none"><pre>
    def make_labels(self, class_ids):
        """Make 2x2 grid label store.

        Args:
            class_ids: 2x2 array of class_ids to use
        """
        cell_size = 200
        y_cells = 2
        x_cells = 2
        labels = ChipClassificationLabels()

        for yind in range(y_cells):
            for xind in range(x_cells):
                ymin = yind * cell_size
                xmin = xind * cell_size
                ymax = ymin + cell_size
                xmax = xmin + cell_size
                window = Box(ymin, xmin, ymax, xmax)
                class_id = class_ids[yind][xind]
                new_labels = ChipClassificationLabels()
                new_labels.set_cell(window, class_id)
                labels.extend(new_labels)

        return labels

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 135:</b> &nbsp; 2 fragments, nominal size 16 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2175')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/evaluation/test_chip_classification_evaluation.py: 38-56
</a>
<div class="mid" id="frag2175" style="display:none"><pre>
    def assert_eval_single_null(self, eval):
        eval_item0 = eval.class_to_eval_item[0]
        self.assertEqual(eval_item0.gt_count, 2)
        self.assertEqual(eval_item0.precision, 1.0)
        self.assertEqual(eval_item0.recall, 0.5)
        self.assertAlmostEqual(eval_item0.f1, 2 / 3, places=2)

        eval_item1 = eval.class_to_eval_item[1]
        self.assertEqual(eval_item1.gt_count, 1)
        self.assertEqual(eval_item1.precision, 0.5)
        self.assertEqual(eval_item1.recall, 1.0)
        self.assertAlmostEqual(eval_item1.f1, 2 / 3, places=2)

        avg_item = eval.avg_item
        self.assertEqual(avg_item.gt_count, 3)
        self.assertAlmostEqual(avg_item.precision, 0.83, places=2)
        self.assertAlmostEqual(avg_item.recall, 2 / 3, places=2)
        self.assertAlmostEqual(avg_item.f1, 2 / 3, places=2)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2837')" href="javascript:;">
raster-vision-0.11.0/tests/evaluation/test_chip_classification_evaluation.py: 39-57
</a>
<div class="mid" id="frag2837" style="display:none"><pre>
    def assert_eval_single_null(self, eval):
        eval_item1 = eval.class_to_eval_item[1]
        self.assertEqual(eval_item1.gt_count, 2)
        self.assertEqual(eval_item1.precision, 1.0)
        self.assertEqual(eval_item1.recall, 0.5)
        self.assertAlmostEqual(eval_item1.f1, 2 / 3, places=2)

        eval_item2 = eval.class_to_eval_item[2]
        self.assertEqual(eval_item2.gt_count, 1)
        self.assertEqual(eval_item2.precision, 0.5)
        self.assertEqual(eval_item2.recall, 1.0)
        self.assertAlmostEqual(eval_item2.f1, 2 / 3, places=2)

        avg_item = eval.avg_item
        self.assertEqual(avg_item.gt_count, 3)
        self.assertAlmostEqual(avg_item.precision, 0.83, places=2)
        self.assertAlmostEqual(avg_item.recall, 2 / 3, places=2)
        self.assertAlmostEqual(avg_item.f1, 2 / 3, places=2)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 136:</b> &nbsp; 4 fragments, nominal size 10 lines, similarity 90%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2180')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/evaluation/test_class_evaluation_item.py: 20-30
</a>
<div class="mid" id="frag2180" style="display:none"><pre>
    def test_merge_first_empty(self):
        a = ClassEvaluationItem()
        b = ClassEvaluationItem(
            precision=1, recall=1, f1=1, count_error=0, gt_count=1)
        a.merge(b)
        self.assertEqual(a.precision, 1)
        self.assertEqual(a.recall, 1)
        self.assertEqual(a.f1, 1)
        self.assertEqual(a.count_error, 0)
        self.assertEqual(a.gt_count, 1)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2181')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/evaluation/test_class_evaluation_item.py: 31-41
</a>
<div class="mid" id="frag2181" style="display:none"><pre>
    def test_merge_second_empty(self):
        a = ClassEvaluationItem(
            precision=1, recall=1, f1=1, count_error=0, gt_count=1)
        b = ClassEvaluationItem()
        a.merge(b)
        self.assertEqual(a.precision, 1)
        self.assertEqual(a.recall, 1)
        self.assertEqual(a.f1, 1)
        self.assertEqual(a.count_error, 0)
        self.assertEqual(a.gt_count, 1)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2842')" href="javascript:;">
raster-vision-0.11.0/tests/evaluation/test_class_evaluation_item.py: 20-30
</a>
<div class="mid" id="frag2842" style="display:none"><pre>
    def test_merge_first_empty(self):
        a = ClassEvaluationItem()
        b = ClassEvaluationItem(
            precision=1, recall=1, f1=1, count_error=0, gt_count=1)
        a.merge(b)
        self.assertEqual(a.precision, 1)
        self.assertEqual(a.recall, 1)
        self.assertEqual(a.f1, 1)
        self.assertEqual(a.count_error, 0)
        self.assertEqual(a.gt_count, 1)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2843')" href="javascript:;">
raster-vision-0.11.0/tests/evaluation/test_class_evaluation_item.py: 31-41
</a>
<div class="mid" id="frag2843" style="display:none"><pre>
    def test_merge_second_empty(self):
        a = ClassEvaluationItem(
            precision=1, recall=1, f1=1, count_error=0, gt_count=1)
        b = ClassEvaluationItem()
        a.merge(b)
        self.assertEqual(a.precision, 1)
        self.assertEqual(a.recall, 1)
        self.assertEqual(a.f1, 1)
        self.assertEqual(a.count_error, 0)
        self.assertEqual(a.gt_count, 1)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 137:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2182')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/evaluation/test_class_evaluation_item.py: 42-54
</a>
<div class="mid" id="frag2182" style="display:none"><pre>
    def test_merge(self):
        a = ClassEvaluationItem(
            precision=1, recall=1, f1=1, count_error=0, gt_count=1)
        b = ClassEvaluationItem(
            precision=0, recall=0, f1=0, count_error=1, gt_count=2)
        a.merge(b)
        self.assertEqual(a.precision, 1 / 3)
        self.assertEqual(a.recall, 1 / 3)
        self.assertEqual(a.f1, 1 / 3)
        self.assertEqual(a.count_error, 2 / 3)
        self.assertEqual(a.gt_count, 3)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2844')" href="javascript:;">
raster-vision-0.11.0/tests/evaluation/test_class_evaluation_item.py: 42-54
</a>
<div class="mid" id="frag2844" style="display:none"><pre>
    def test_merge(self):
        a = ClassEvaluationItem(
            precision=1, recall=1, f1=1, count_error=0, gt_count=1)
        b = ClassEvaluationItem(
            precision=0, recall=0, f1=0, count_error=1, gt_count=2)
        a.merge(b)
        self.assertEqual(a.precision, 1 / 3)
        self.assertEqual(a.recall, 1 / 3)
        self.assertEqual(a.f1, 1 / 3)
        self.assertEqual(a.count_error, 2 / 3)
        self.assertEqual(a.gt_count, 3)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 138:</b> &nbsp; 6 fragments, nominal size 21 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2187')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/evaluation/test_object_detection_evaluation.py: 36-60
</a>
<div class="mid" id="frag2187" style="display:none"><pre>
    def test_compute(self):
        class_config = self.make_class_config()
        eval = ObjectDetectionEvaluation(class_config)
        gt_labels = self.make_ground_truth_labels()
        pred_labels = self.make_predicted_labels()

        eval.compute(gt_labels, pred_labels)
        eval_item1 = eval.class_to_eval_item[0]
        self.assertEqual(eval_item1.gt_count, 2)
        self.assertEqual(eval_item1.precision, 1.0)
        self.assertEqual(eval_item1.recall, 1.0)
        self.assertEqual(eval_item1.f1, 1.0)

        eval_item2 = eval.class_to_eval_item[1]
        self.assertEqual(eval_item2.gt_count, 2)
        self.assertEqual(eval_item2.precision, 1.0)
        self.assertEqual(eval_item2.recall, 0.5)
        self.assertEqual(eval_item2.f1, 2 / 3)

        avg_item = eval.avg_item
        self.assertEqual(avg_item.gt_count, 4)
        self.assertAlmostEqual(avg_item.precision, 1.0)
        self.assertEqual(avg_item.recall, 0.75)
        self.assertAlmostEqual(avg_item.f1, 0.83, places=2)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2188')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/evaluation/test_object_detection_evaluation.py: 61-85
</a>
<div class="mid" id="frag2188" style="display:none"><pre>
    def test_compute_no_preds(self):
        class_config = self.make_class_config()
        eval = ObjectDetectionEvaluation(class_config)
        gt_labels = self.make_ground_truth_labels()
        pred_labels = ObjectDetectionLabels.make_empty()

        eval.compute(gt_labels, pred_labels)
        eval_item1 = eval.class_to_eval_item[0]
        self.assertEqual(eval_item1.gt_count, 2)
        self.assertEqual(eval_item1.precision, None)
        self.assertEqual(eval_item1.recall, 0.0)
        self.assertEqual(eval_item1.f1, None)

        eval_item2 = eval.class_to_eval_item[1]
        self.assertEqual(eval_item2.gt_count, 2)
        self.assertEqual(eval_item2.precision, None)
        self.assertEqual(eval_item2.recall, 0.0)
        self.assertEqual(eval_item2.f1, None)

        avg_item = eval.avg_item
        self.assertEqual(avg_item.gt_count, 4)
        self.assertEqual(avg_item.precision, 0.0)
        self.assertEqual(avg_item.recall, 0.0)
        self.assertEqual(avg_item.f1, 0.0)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2850')" href="javascript:;">
raster-vision-0.11.0/tests/evaluation/test_object_detection_evaluation.py: 63-87
</a>
<div class="mid" id="frag2850" style="display:none"><pre>
    def test_compute_no_preds(self):
        class_map = self.make_class_map()
        eval = ObjectDetectionEvaluation(class_map)
        gt_labels = self.make_ground_truth_labels()
        pred_labels = ObjectDetectionLabels.make_empty()

        eval.compute(gt_labels, pred_labels)
        eval_item1 = eval.class_to_eval_item[1]
        self.assertEqual(eval_item1.gt_count, 2)
        self.assertEqual(eval_item1.precision, None)
        self.assertEqual(eval_item1.recall, 0.0)
        self.assertEqual(eval_item1.f1, None)

        eval_item2 = eval.class_to_eval_item[2]
        self.assertEqual(eval_item2.gt_count, 2)
        self.assertEqual(eval_item2.precision, None)
        self.assertEqual(eval_item2.recall, 0.0)
        self.assertEqual(eval_item2.f1, None)

        avg_item = eval.avg_item
        self.assertEqual(avg_item.gt_count, 4)
        self.assertEqual(avg_item.precision, 0.0)
        self.assertEqual(avg_item.recall, 0.0)
        self.assertEqual(avg_item.f1, 0.0)

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2849')" href="javascript:;">
raster-vision-0.11.0/tests/evaluation/test_object_detection_evaluation.py: 38-62
</a>
<div class="mid" id="frag2849" style="display:none"><pre>
    def test_compute(self):
        class_map = self.make_class_map()
        eval = ObjectDetectionEvaluation(class_map)
        gt_labels = self.make_ground_truth_labels()
        pred_labels = self.make_predicted_labels()

        eval.compute(gt_labels, pred_labels)
        eval_item1 = eval.class_to_eval_item[1]
        self.assertEqual(eval_item1.gt_count, 2)
        self.assertEqual(eval_item1.precision, 1.0)
        self.assertEqual(eval_item1.recall, 1.0)
        self.assertEqual(eval_item1.f1, 1.0)

        eval_item2 = eval.class_to_eval_item[2]
        self.assertEqual(eval_item2.gt_count, 2)
        self.assertEqual(eval_item2.precision, 1.0)
        self.assertEqual(eval_item2.recall, 0.5)
        self.assertEqual(eval_item2.f1, 2 / 3)

        avg_item = eval.avg_item
        self.assertEqual(avg_item.gt_count, 4)
        self.assertAlmostEqual(avg_item.precision, 1.0)
        self.assertEqual(avg_item.recall, 0.75)
        self.assertAlmostEqual(avg_item.f1, 0.83, places=2)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2851')" href="javascript:;">
raster-vision-0.11.0/tests/evaluation/test_object_detection_evaluation.py: 88-113
</a>
<div class="mid" id="frag2851" style="display:none"><pre>
    def test_compute_no_ground_truth(self):
        class_map = self.make_class_map()
        eval = ObjectDetectionEvaluation(class_map)
        gt_labels = ObjectDetectionLabels.make_empty()
        pred_labels = self.make_predicted_labels()

        eval.compute(gt_labels, pred_labels)
        eval_item1 = eval.class_to_eval_item[1]
        self.assertEqual(eval_item1.gt_count, 0)
        self.assertEqual(eval_item1.precision, None)
        self.assertEqual(eval_item1.recall, None)
        self.assertEqual(eval_item1.f1, None)

        eval_item2 = eval.class_to_eval_item[2]
        self.assertEqual(eval_item2.gt_count, 0)
        self.assertEqual(eval_item2.precision, None)
        self.assertEqual(eval_item2.recall, None)
        self.assertEqual(eval_item2.f1, None)

        avg_item = eval.avg_item
        self.assertEqual(avg_item.gt_count, 0)
        self.assertEqual(avg_item.precision, None)
        self.assertEqual(avg_item.recall, None)
        self.assertEqual(avg_item.f1, None)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2189')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/evaluation/test_object_detection_evaluation.py: 86-111
</a>
<div class="mid" id="frag2189" style="display:none"><pre>
    def test_compute_no_ground_truth(self):
        class_config = self.make_class_config()
        eval = ObjectDetectionEvaluation(class_config)
        gt_labels = ObjectDetectionLabels.make_empty()
        pred_labels = self.make_predicted_labels()

        eval.compute(gt_labels, pred_labels)
        eval_item1 = eval.class_to_eval_item[0]
        self.assertEqual(eval_item1.gt_count, 0)
        self.assertEqual(eval_item1.precision, None)
        self.assertEqual(eval_item1.recall, None)
        self.assertEqual(eval_item1.f1, None)

        eval_item2 = eval.class_to_eval_item[1]
        self.assertEqual(eval_item2.gt_count, 0)
        self.assertEqual(eval_item2.precision, None)
        self.assertEqual(eval_item2.recall, None)
        self.assertEqual(eval_item2.f1, None)

        avg_item = eval.avg_item
        self.assertEqual(avg_item.gt_count, 0)
        self.assertEqual(avg_item.precision, None)
        self.assertEqual(avg_item.recall, None)
        self.assertEqual(avg_item.f1, None)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 139:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 85%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2192')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/evaluation/test_semantic_segmentation_evaluator.py: 33-52
</a>
<div class="mid" id="frag2192" style="display:none"><pre>
    def get_scene(self, class_id):
        # Make scene where ground truth is all set to class_id
        # and predictions are set to half 0's and half 1's
        scene_id = str(class_id)
        rs = MockRasterSource(channel_order=[0, 1, 2], num_channels=3)
        rs.set_raster(np.zeros((10, 10, 3)))

        gt_rs = MockRasterSource(channel_order=[0], num_channels=1)
        gt_arr = np.full((10, 10, 1), class_id)
        gt_rs.set_raster(gt_arr)
        gt_ls = SemanticSegmentationLabelSource(gt_rs, self.null_class_id)

        pred_rs = MockRasterSource(channel_order=[0], num_channels=1)
        pred_arr = np.zeros((10, 10, 1))
        pred_arr[5:10, :, :] = 1
        pred_rs.set_raster(pred_arr)
        pred_ls = SemanticSegmentationLabelSource(pred_rs, self.null_class_id)

        return Scene(scene_id, rs, gt_ls, pred_ls)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2854')" href="javascript:;">
raster-vision-0.11.0/tests/evaluation/test_semantic_segmentation_evaluator.py: 29-48
</a>
<div class="mid" id="frag2854" style="display:none"><pre>
    def get_scene(self, class_id):
        # Make scene where ground truth is all set to class_id
        # and predictions are set to half 1's and half 2's
        scene_id = str(class_id)
        rs = MockRasterSource(channel_order=[0, 1, 2], num_channels=3)
        rs.set_raster(np.zeros((10, 10, 3)))

        gt_rs = MockRasterSource(channel_order=[0], num_channels=1)
        gt_arr = np.full((10, 10, 1), class_id)
        gt_rs.set_raster(gt_arr)
        gt_ls = SemanticSegmentationLabelSource(source=gt_rs)

        pred_rs = MockRasterSource(channel_order=[0], num_channels=1)
        pred_arr = np.ones((10, 10, 1))
        pred_arr[5:10, :, :] = 2
        pred_rs.set_raster(pred_arr)
        pred_ls = SemanticSegmentationLabelSource(source=pred_rs)

        return Scene(scene_id, rs, gt_ls, pred_ls)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 140:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2195')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/evaluation/test_semantic_segmentation_evaluator.py: 101-116
</a>
<div class="mid" id="frag2195" style="display:none"><pre>
    def test_vector_evaluator(self):
        output_uri = join(self.tmp_dir.name, 'raster-out.json')
        vector_output_uri = join(self.tmp_dir.name, 'vector-out.json')
        scenes = [self.get_vector_scene(0), self.get_vector_scene(1)]
        evaluator = SemanticSegmentationEvaluator(
            self.class_config, output_uri, vector_output_uri)
        evaluator.process(scenes, self.tmp_dir.name)
        vector_eval_json = file_to_json(vector_output_uri)
        exp_vector_eval_json = file_to_json(data_file_path('expected-vector-eval.json'))

        # NOTE:  The precision  and recall  values found  in the  file
        # `expected-vector-eval.json`  are equal to fractions of  the
        # form (n-1)/n for  n &lt;= 7 which  can be seen to  be (and have
        # been manually verified to be) correct.
        self.assertDictEqual(vector_eval_json, exp_vector_eval_json)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2196')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/evaluation/test_semantic_segmentation_evaluator.py: 117-134
</a>
<div class="mid" id="frag2196" style="display:none"><pre>
    def test_vector_evaluator_with_aoi(self):
        output_uri = join(self.tmp_dir.name, 'raster-out.json')
        vector_output_uri = join(self.tmp_dir.name, 'vector-out.json')
        scenes = [self.get_vector_scene(0, use_aoi=True)]
        evaluator = SemanticSegmentationEvaluator(
            self.class_config, output_uri, vector_output_uri)
        evaluator.process(scenes, self.tmp_dir.name)
        vector_eval_json = file_to_json(vector_output_uri)
        exp_vector_eval_json = file_to_json(
            data_file_path('expected-vector-eval-with-aoi.json'))

        # NOTE:  The precision  and recall  values found  in the  file
        # `expected-vector-eval.json`  are equal to fractions of  the
        # form (n-1)/n for  n &lt;= 7 which  can be seen to  be (and have
        # been manually verified to be) correct.
        self.assertDictEqual(vector_eval_json, exp_vector_eval_json)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 141:</b> &nbsp; 2 fragments, nominal size 42 lines, similarity 81%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2199')" href="javascript:;">
raster-vision-0.11.0/tests_v2/core/test_stats_analyzer.py: 20-64
</a>
<div class="mid" id="frag2199" style="display:none"><pre>
    def _test(self, is_random=False):
        stats_uri = os.path.join(self.tmp_dir.name, 'stats.json')
        scenes = []
        raster_sources = []
        imgs = []
        sample_prob = 0.5
        for i in range(3):
            rs = MockRasterSource([0, 1, 2], 3)
            img = np.zeros((600, 600, 3))
            img[:, :, 0] = 1 + i
            img[:, :, 1] = 2 + i
            img[:, :, 2] = 3 + i
            if not is_random:
                img[300:, 300:, :] = np.nan

            imgs.append(img)
            rs.set_raster(img)
            raster_sources.append(rs)
            scenes.append(Scene(str(i), rs))

        channel_vals = list(map(lambda x: np.expand_dims(x, axis=0), imgs))
        channel_vals = np.concatenate(channel_vals, axis=0)
        channel_vals = np.transpose(channel_vals, [3, 0, 1, 2])
        channel_vals = np.reshape(channel_vals, (3, -1))
        exp_means = np.nanmean(channel_vals, axis=1)
        exp_stds = np.nanstd(channel_vals, axis=1)

        analyzer_cfg = StatsAnalyzerConfig(output_uri=stats_uri, sample_prob=None)
        if is_random:
            analyzer_cfg = StatsAnalyzerConfig(
                output_uri=stats_uri, sample_prob=sample_prob)
        analyzer = analyzer_cfg.build()
        analyzer.process(scenes, self.tmp_dir.name)

        stats = RasterStats.load(stats_uri)
        np.testing.assert_array_almost_equal(stats.means, exp_means, decimal=3)
        np.testing.assert_array_almost_equal(stats.stds, exp_stds, decimal=3)
        if is_random:
            for rs in raster_sources:
                width = rs.get_extent().get_width()
                height = rs.get_extent().get_height()
                exp_num_chips = round(
                    ((width * height) / (chip_sz**2)) * sample_prob)
                self.assertEqual(rs.mock._get_chip.call_count, exp_num_chips)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2921')" href="javascript:;">
raster-vision-0.11.0/tests/core/test_stats_analyzer.py: 20-69
</a>
<div class="mid" id="frag2921" style="display:none"><pre>
    def _test(self, is_random=False, is_backcompat=False):
        stats_uri = os.path.join(self.temp_dir.name, 'stats.json')
        scenes = []
        raster_sources = []
        imgs = []
        sample_prob = 0.5
        for i in range(3):
            rs = MockRasterSource([0, 1, 2], 3)
            img = np.zeros((600, 600, 3))
            img[:, :, 0] = 1 + i
            img[:, :, 1] = 2 + i
            img[:, :, 2] = 3 + i
            if not is_random:
                img[300:, 300:, :] = np.nan

            imgs.append(img)
            rs.set_raster(img)
            raster_sources.append(rs)
            scenes.append(Scene(str(i), rs))

        channel_vals = list(map(lambda x: np.expand_dims(x, axis=0), imgs))
        channel_vals = np.concatenate(channel_vals, axis=0)
        channel_vals = np.transpose(channel_vals, [3, 0, 1, 2])
        channel_vals = np.reshape(channel_vals, (3, -1))
        exp_means = np.nanmean(channel_vals, axis=1)
        exp_stds = np.nanstd(channel_vals, axis=1)

        analyzer_builder = rv.AnalyzerConfig.builder(rv.STATS_ANALYZER)
        if is_random:
            analyzer_builder = analyzer_builder.with_sample_prob(sample_prob)
        analyzer_msg = analyzer_builder.with_stats_uri(stats_uri) \
                                       .build().to_proto()
        if is_backcompat:
            analyzer_msg.stats_analyzer_config.stats_uri = ''
            analyzer_msg.stats_uri = stats_uri

        analyzer_config = rv.AnalyzerConfig.builder(rv.STATS_ANALYZER) \
                            .from_proto(analyzer_msg).build()
        analyzer = analyzer_config.create_analyzer()
        analyzer.process(scenes, self.temp_dir.name)

        stats = RasterStats.load(stats_uri)
        np.testing.assert_array_almost_equal(stats.means, exp_means, decimal=3)
        np.testing.assert_array_almost_equal(stats.stds, exp_stds, decimal=3)
        if is_random:
            for rs in raster_sources:
                width = rs.get_extent().get_width()
                height = rs.get_extent().get_height()
                exp_num_chips = round(
                    ((width * height) / (chip_size**2)) * sample_prob)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 142:</b> &nbsp; 2 fragments, nominal size 59 lines, similarity 88%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2203')" href="javascript:;">
raster-vision-0.11.0/integration_tests2/semantic_segmentation/config.py: 15-82
</a>
<div class="mid" id="frag2203" style="display:none"><pre>
def get_config(runner, root_uri, data_uri=None, full_train=False):
    def get_path(part):
        if full_train:
            return join(data_uri, part)
        else:
            return join(dirname(__file__), part)

    class_config = ClassConfig(
        names=['red', 'green'],
        colors=['red', 'green'])

    def make_scene(id, img_path, label_path):
        raster_source = RasterioSourceConfig(
            channel_order=[0, 1, 2], uris=[img_path])
        label_source = SemanticSegmentationLabelSourceConfig(
            rgb_class_config=class_config,
            raster_source=RasterioSourceConfig(uris=[label_path]))
        label_store = SemanticSegmentationLabelStoreConfig(
            rgb=True, vector_output=[
                PolygonVectorOutputConfig(class_id=0),
                BuildingVectorOutputConfig(class_id=1)])

        return SceneConfig(
            id=id,
            raster_source=raster_source,
            label_source=label_source,
            label_store=label_store)

    if full_train:
        model = SemanticSegmentationModelConfig(backbone=Backbone.resnet50)
        solver = SolverConfig(
            lr=1e-4, num_epochs=300, batch_sz=8, one_cycle=True,
            sync_interval=300)
    else:
        pretrained_uri = (
            's3://raster-vision-lf-dev/integration_tests/semantic_segmentation/output/'
            'train/last-model.pth')
        model = SemanticSegmentationModelConfig(
            backbone=Backbone.resnet50, init_weights=pretrained_uri)
        solver = SolverConfig(
            lr=1e-9, num_epochs=1, batch_sz=2, one_cycle=True, sync_interval=200)
    backend = PyTorchSemanticSegmentationConfig(
        model=model,
        solver=solver,
        log_tensorboard=False,
        run_tensorboard=False,
        augmentors=[])

    scenes = [
        make_scene(
            'test-scene', get_path('scene/image.tif'), get_path('scene/labels.tif')),
        make_scene(
            'test-scene2', get_path('scene/image2.tif'), get_path('scene/labels2.tif'))]
    dataset = DatasetConfig(
        class_config=class_config,
        train_scenes=scenes,
        validation_scenes=scenes)

    chip_options = SemanticSegmentationChipOptions(
        window_method=SemanticSegmentationWindowMethod.sliding, stride=300)

    return SemanticSegmentationConfig(
        root_uri=root_uri,
        dataset=dataset,
        backend=backend,
        train_chip_sz=300,
        predict_chip_sz=300,
        chip_options=chip_options)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2221')" href="javascript:;">
raster-vision-0.11.0/integration_tests2/object_detection/config.py: 13-76
</a>
<div class="mid" id="frag2221" style="display:none"><pre>
def get_config(runner, root_uri, data_uri=None, full_train=False):
    def get_path(part):
        if full_train:
            return join(data_uri, part)
        else:
            return join(dirname(__file__), part)

    class_config = ClassConfig(
        names=['car', 'building'],
        colors=['blue', 'red'])

    def make_scene(scene_id, img_path, label_path):
        raster_source = RasterioSourceConfig(
            channel_order=[0, 1, 2], uris=[img_path])
        label_source = ObjectDetectionLabelSourceConfig(
            vector_source=GeoJSONVectorSourceConfig(
                uri=label_path, default_class_id=None))
        return SceneConfig(
            id=scene_id,
            raster_source=raster_source,
            label_source=label_source)

    if full_train:
        model = ObjectDetectionModelConfig(backbone=Backbone.resnet18)
        solver = SolverConfig(
            lr=1e-4, num_epochs=300, batch_sz=8, one_cycle=True,
            sync_interval=300)
    else:
        pretrained_uri = (
            's3://raster-vision-lf-dev/integration_tests/object_detection/output/train/'
            'last-model.pth')
        model = ObjectDetectionModelConfig(
            backbone=Backbone.resnet18, init_weights=pretrained_uri)
        solver = SolverConfig(
            lr=1e-9, num_epochs=1, batch_sz=2, one_cycle=True, sync_interval=200)
    backend = PyTorchObjectDetectionConfig(
        model=model,
        solver=solver,
        log_tensorboard=False,
        run_tensorboard=False,
        augmentors=[])

    scenes = [
        make_scene(
            'od_test', get_path('scene/image.tif'), get_path('scene/labels.json')),
        make_scene(
            'od_test-2', get_path('scene/image2.tif'), get_path('scene/labels2.json'))]
    dataset = DatasetConfig(
        class_config=class_config,
        train_scenes=scenes,
        validation_scenes=scenes)

    chip_options = ObjectDetectionChipOptions(neg_ratio=1.0, ioa_thresh=1.0)
    predict_options = ObjectDetectionPredictOptions(
        merge_thresh=0.1, score_thresh=0.5)

    return ObjectDetectionConfig(
        root_uri=root_uri,
        dataset=dataset,
        backend=backend,
        train_chip_sz=300,
        predict_chip_sz=300,
        chip_options=chip_options,
        predict_options=predict_options)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 143:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2214')" href="javascript:;">
raster-vision-0.11.0/integration_tests2/integration_tests.py: 62-78
</a>
<div class="mid" id="frag2214" style="display:none"><pre>
def check_eval_item(test, expected_item, actual_item):
    errors = []
    f1_threshold = 0.05
    class_name = expected_item['class_name']

    expected_f1 = expected_item['f1'] or 0.0
    actual_f1 = actual_item['f1'] or 0.0
    if math.fabs(expected_f1 - actual_f1) &gt; f1_threshold:
        errors.append(
            TestError(
                test, 'F1 scores are not close enough',
                'for class_name: {} expected f1: {}, actual f1: {}'.format(
                    class_name, expected_item['f1'], actual_item['f1'])))

    return errors


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2937')" href="javascript:;">
raster-vision-0.11.0/integration_tests/integration_tests.py: 89-105
</a>
<div class="mid" id="frag2937" style="display:none"><pre>
        return json.load(file)


def check_eval_item(test, expected_item, actual_item):
    errors = []
    f1_threshold = 0.01
    class_name = expected_item['class_name']

    expected_f1 = expected_item['f1'] or 0.0
    actual_f1 = actual_item['f1'] or 0.0
    if math.fabs(expected_f1 - actual_f1) &gt; f1_threshold:
        errors.append(
            TestError(
                test, 'F1 scores are not close enough',
                'for class_name: {} expected f1: {}, actual f1: {}'.format(
                    class_name, expected_item['f1'], actual_item['f1'])))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 144:</b> &nbsp; 2 fragments, nominal size 17 lines, similarity 94%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2215')" href="javascript:;">
raster-vision-0.11.0/integration_tests2/integration_tests.py: 79-101
</a>
<div class="mid" id="frag2215" style="display:none"><pre>
def check_eval(test, tmp_dir):
    errors = []

    actual_eval_path = get_actual_eval_path(test, tmp_dir)
    expected_eval_path = get_expected_eval_path(test)

    if isfile(actual_eval_path):
        expected_eval = file_to_json(expected_eval_path)['overall']
        actual_eval = file_to_json(actual_eval_path)['overall']

        for expected_item in expected_eval:
            class_name = expected_item['class_name']
            actual_item = \
                next(filter(
                    lambda x: x['class_name'] == class_name, actual_eval))
            errors.extend(check_eval_item(test, expected_item, actual_item))
    else:
        errors.append(
            TestError(test, 'actual eval file does not exist',
                      actual_eval_path))

    return errors

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2938')" href="javascript:;">
raster-vision-0.11.0/integration_tests/integration_tests.py: 106-128
</a>
<div class="mid" id="frag2938" style="display:none"><pre>
    return errors


def check_eval(test, temp_dir):
    errors = []

    actual_eval_path = get_actual_eval_path(test, temp_dir)
    expected_eval_path = get_expected_eval_path(test)

    if os.path.isfile(actual_eval_path):
        expected_eval = open_json(expected_eval_path)['overall']
        actual_eval = open_json(actual_eval_path)['overall']

        for expected_item in expected_eval:
            class_name = expected_item['class_name']
            actual_item = \
                next(filter(
                    lambda x: x['class_name'] == class_name, actual_eval))
            errors.extend(check_eval_item(test, expected_item, actual_item))
    else:
        errors.append(
            TestError(test, 'actual eval file does not exist',
                      actual_eval_path))
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 145:</b> &nbsp; 2 fragments, nominal size 24 lines, similarity 80%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2220')" href="javascript:;">
raster-vision-0.11.0/integration_tests2/integration_tests.py: 232-264
</a>
<div class="mid" id="frag2220" style="display:none"><pre>
    '--verbose', '-v', is_flag=True, help=('Sets the logging level to DEBUG.'))
def main(tests, root_uri, verbose):
    """Runs RV end-to-end and checks that evaluation metrics are correct."""
    if len(tests) == 0:
        tests = all_tests

    if verbose:
        rv_config.set(verbosity=Verbosity.DEBUG)

    with rv_config.get_tmp_dir() as tmp_dir:
        if root_uri:
            tmp_dir = root_uri

        errors = []
        for test in tests:
            if test not in all_tests:
                print('{} is not a valid test.'.format(test))
                return

            errors.extend(run_test(test, tmp_dir))

            for error in errors:
                print(error)

        for test in tests:
            nb_test_errors = len(
                list(filter(lambda error: error.test == test, errors)))
            if nb_test_errors == 0:
                print('{} test passed!'.format(test))

        if errors:
            exit(1)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2944')" href="javascript:;">
raster-vision-0.11.0/integration_tests/integration_tests.py: 293-328
</a>
<div class="mid" id="frag2944" style="display:none"><pre>
    '-t',
    help=('Sets the rv_root directory used. '
          'If set, test will not clean this directory up.'))
@click.option(
    '--verbose', '-v', is_flag=True, help=('Sets the logging level to DEBUG.'))
@click.option(
    '--use-tf', '-v', is_flag=True, help=('Run using TF-based backends.'))
def main(tests, rv_root, verbose, use_tf):
    """Runs RV end-to-end and checks that evaluation metrics are correct."""
    if len(tests) == 0:
        tests = all_tests

    if verbose:
        rv._registry.initialize_config(
            verbosity=rv.cli.verbosity.Verbosity.DEBUG)

    tests = list(map(lambda x: x.upper(), tests))

    with RVConfig.get_tmp_dir() as temp_dir:
        if rv_root:
            temp_dir = rv_root

        errors = []
        for test in tests:
            if test not in all_tests:
                print('{} is not a valid test.'.format(test))
                return

            errors.extend(run_test(test, use_tf, temp_dir))

            for error in errors:
                print(error)

        for test in tests:
            nb_test_errors = len(
                list(filter(lambda error: error.test == test, errors)))
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 146:</b> &nbsp; 2 fragments, nominal size 17 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2227')" href="javascript:;">
raster-vision-0.11.0/integration_tests2/util/flip_scene.py: 8-31
</a>
<div class="mid" id="frag2227" style="display:none"><pre>
def flip_geom(m, b, geom):
    """Flips a geom along a straight line y = mx + b.
    """

    def traverse_coords(coords, dst_coords):
        for p in coords:
            if type(p[0]) is list:
                lst = []
                traverse_coords(p, lst)
                dst_coords.append(lst)
            else:
                x, y = p[0], p[1]
                d = (x + (y - b) * m) / (1 + m * m)
                x2 = 2 * d - x
                y2 = 2 * d * m - y + 2 * b
                dst_coords.append((x2, y2))
        return dst_coords

    return {
        'type': geom['type'],
        'coordinates': traverse_coords(geom['coordinates'], [])
    }


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2952')" href="javascript:;">
raster-vision-0.11.0/integration_tests/util/flip_scene.py: 8-31
</a>
<div class="mid" id="frag2952" style="display:none"><pre>
def flip_geom(m, b, geom):
    """Flips a geom along a straight line y = mx + b.
    """

    def traverse_coords(coords, dst_coords):
        for p in coords:
            if type(p[0]) is list:
                lst = []
                traverse_coords(p, lst)
                dst_coords.append(lst)
            else:
                x, y = p[0], p[1]
                d = (x + (y - b) * m) / (1 + m * m)
                x2 = 2 * d - x
                y2 = 2 * d * m - y + 2 * b
                dst_coords.append((x2, y2))
        return dst_coords

    return {
        'type': geom['type'],
        'coordinates': traverse_coords(geom['coordinates'], [])
    }


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 147:</b> &nbsp; 2 fragments, nominal size 59 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2229')" href="javascript:;">
raster-vision-0.11.0/integration_tests2/util/flip_scene.py: 37-120
</a>
<div class="mid" id="frag2229" style="display:none"><pre>
def flip_scene(src_tiff_path, src_labels_path, dst_tiff_path, dst_labels_path):
    """Flips a scene and it's labels.

    Useful for generating multiple training scenes for integration test usage.
    """

    labels_are_tif = src_labels_path.endswith('.tif')

    with rasterio.open(src_tiff_path) as src:
        profile = src.profile
        bands = src.read()

        with rasterio.open(dst_tiff_path, 'w', **profile) as dst:
            fbands = np.flip(bands, 1)
            dst.write(fbands)

        if not labels_are_tif:

            img_crs = pyproj.Proj(init=src.crs['init'])
            map_crs = pyproj.Proj(init='epsg:4326')

            def t(x, y):
                return pyproj.transform(img_crs, map_crs, x, y)

            # Find the center horizontal line through the image.

            ll = (src.bounds.left, src.bounds.bottom)
            ul = (src.bounds.left, src.bounds.top)
            ur = (src.bounds.right, src.bounds.top)
            lr = (src.bounds.right, src.bounds.bottom)

            left = t(ul[0] - ((ul[0] - ll[0]) / 2),
                     ul[1] - ((ul[1] - ll[1]) / 2))

            right = t(ur[0] - ((ur[0] - lr[0]) / 2),
                      ur[1] - ((ur[1] - lr[1]) / 2))

            m = abs(left[1] - right[1]) / abs(left[0] - right[0])
            b = left[1] - (m * left[0])

    if labels_are_tif:
        with rasterio.open(src_labels_path) as src:
            profile = src.profile
            bands = src.read()

            with rasterio.open(dst_labels_path, 'w', **profile) as dst:
                fbands = np.flip(bands, 1)
                dst.write(fbands)
    else:

        def traverse_labels(src, dst):
            for key in src:
                e = src[key]
                if type(e) is dict:
                    if key == 'geometry':
                        dst[key] = flip_geom(m, b, src[key])
                    else:
                        dst[key] = {}
                        traverse_labels(e, dst[key])
                elif type(e) is list:
                    d_list = []
                    for x in e:
                        if type(x) is dict:
                            ne = {}
                            traverse_labels(x, ne)
                            d_list.append(ne)
                        else:
                            d_list.append(x)
                    dst[key] = d_list
                else:
                    dst[key] = e
            return dst

        with open(src_labels_path) as src_labels_file:
            source_labels = json.loads(src_labels_file.read())

        dst_labels = traverse_labels(source_labels, {})

        with open(dst_labels_path, 'w') as dst_labels_file:
            dst_labels_file.write(json.dumps(dst_labels, indent=4))

    print('done.')


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2954')" href="javascript:;">
raster-vision-0.11.0/integration_tests/util/flip_scene.py: 37-120
</a>
<div class="mid" id="frag2954" style="display:none"><pre>
def flip_scene(src_tiff_path, src_labels_path, dst_tiff_path, dst_labels_path):
    """Flips a scene and it's labels.

    Useful for generating multiple training scenes for integration test usage.
    """

    labels_are_tif = src_labels_path.endswith('.tif')

    with rasterio.open(src_tiff_path) as src:
        profile = src.profile
        bands = src.read()

        with rasterio.open(dst_tiff_path, 'w', **profile) as dst:
            fbands = np.flip(bands, 1)
            dst.write(fbands)

        if not labels_are_tif:

            img_crs = pyproj.Proj(init=src.crs['init'])
            map_crs = pyproj.Proj(init='epsg:4326')

            def t(x, y):
                return pyproj.transform(img_crs, map_crs, x, y)

            # Find the center horizontal line through the image.

            ll = (src.bounds.left, src.bounds.bottom)
            ul = (src.bounds.left, src.bounds.top)
            ur = (src.bounds.right, src.bounds.top)
            lr = (src.bounds.right, src.bounds.bottom)

            left = t(ul[0] - ((ul[0] - ll[0]) / 2),
                     ul[1] - ((ul[1] - ll[1]) / 2))

            right = t(ur[0] - ((ur[0] - lr[0]) / 2),
                      ur[1] - ((ur[1] - lr[1]) / 2))

            m = abs(left[1] - right[1]) / abs(left[0] - right[0])
            b = left[1] - (m * left[0])

    if labels_are_tif:
        with rasterio.open(src_labels_path) as src:
            profile = src.profile
            bands = src.read()

            with rasterio.open(dst_labels_path, 'w', **profile) as dst:
                fbands = np.flip(bands, 1)
                dst.write(fbands)
    else:

        def traverse_labels(src, dst):
            for key in src:
                e = src[key]
                if type(e) is dict:
                    if key == 'geometry':
                        dst[key] = flip_geom(m, b, src[key])
                    else:
                        dst[key] = {}
                        traverse_labels(e, dst[key])
                elif type(e) is list:
                    d_list = []
                    for x in e:
                        if type(x) is dict:
                            ne = {}
                            traverse_labels(x, ne)
                            d_list.append(ne)
                        else:
                            d_list.append(x)
                    dst[key] = d_list
                else:
                    dst[key] = e
            return dst

        with open(src_labels_path) as src_labels_file:
            source_labels = json.loads(src_labels_file.read())

        dst_labels = traverse_labels(source_labels, {})

        with open(dst_labels_path, 'w') as dst_labels_file:
            dst_labels_file.write(json.dumps(dst_labels, indent=4))

    print('done.')


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 148:</b> &nbsp; 2 fragments, nominal size 60 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2232')" href="javascript:;">
raster-vision-0.11.0/integration_tests2/util/generate_scene.py: 24-112
</a>
<div class="mid" id="frag2232" style="display:none"><pre>
def generate_scene(task, tiff_path, labels_path, chip_size,
                   chips_per_dimension):
    """Generate a synthetic object detection scene.

    Randomly generates a GeoTIFF with red and greed boxes denoting two
    classes and a corresponding label file. This is useful for generating
    synthetic scenes for testing purposes.
    """
    class_map = ClassMap([ClassItem(1, 'car'), ClassItem(2, 'building')])

    # make extent that's divisible by chip_size
    chip_size = chip_size
    ymax = chip_size * chips_per_dimension
    xmax = chip_size * chips_per_dimension
    extent = Box(0, 0, ymax, xmax)

    # make windows along grid
    windows = extent.get_windows(chip_size, chip_size)

    # for each window, make some random boxes within it and render to image
    nb_channels = 3
    image = np.zeros((ymax, xmax, nb_channels)).astype(np.uint8)
    boxes = []
    class_ids = []
    for window in windows:
        # leave some windows blank
        if random.uniform(0, 1) &gt; 0.3:
            # pick a random class
            class_id = random.randint(1, 2)
            box = window.make_random_square(50).to_int()

            boxes.append(box)
            class_ids.append(class_id)

            image[box.ymin:box.ymax, box.xmin:box.xmax, class_id - 1] = 255

    # save image as geotiff centered in philly
    transform = from_origin(-75.163506, 39.952536, 0.000001, 0.000001)

    print('Generated {} boxes with {} different classes.'.format(
        len(boxes), len(set(class_ids))))

    with rasterio.open(
            tiff_path,
            'w',
            driver='GTiff',
            height=ymax,
            transform=transform,
            crs='EPSG:4326',
            compression=rasterio.enums.Compression.none,
            width=xmax,
            count=nb_channels,
            dtype='uint8') as dst:
        for channel_ind in range(0, nb_channels):
            dst.write(image[:, :, channel_ind], channel_ind + 1)

    if task == 'object_detection':
        # make OD labels and make boxes
        npboxes = Box.to_npboxes(boxes)
        class_ids = np.array(class_ids)
        labels = ObjectDetectionLabels(npboxes, class_ids)

        # save labels to geojson
        with rasterio.open(tiff_path) as image_dataset:
            crs_transformer = RasterioCRSTransformer(image_dataset)
            od_file = ObjectDetectionGeoJSONStore(labels_path, crs_transformer,
                                                  class_map)
            od_file.save(labels)
    elif task == 'semantic_segmentation':
        label_image = np.zeros((ymax, xmax, 1)).astype(np.uint8)

        for box, class_id in zip(boxes, class_ids):
            label_image[box.ymin:box.ymax, box.xmin:box.xmax, 0] = class_id

        # save labels to raster
        with rasterio.open(
                labels_path,
                'w',
                driver='GTiff',
                height=ymax,
                transform=transform,
                crs='EPSG:4326',
                compression=rasterio.enums.Compression.none,
                width=xmax,
                count=1,
                dtype='uint8') as dst:
            dst.write(label_image[:, :, 0], 1)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2957')" href="javascript:;">
raster-vision-0.11.0/integration_tests/util/generate_scene.py: 24-112
</a>
<div class="mid" id="frag2957" style="display:none"><pre>
def generate_scene(task, tiff_path, labels_path, chip_size,
                   chips_per_dimension):
    """Generate a synthetic object detection scene.

    Randomly generates a GeoTIFF with red and greed boxes denoting two
    classes and a corresponding label file. This is useful for generating
    synthetic scenes for testing purposes.
    """
    class_map = ClassMap([ClassItem(1, 'car'), ClassItem(2, 'building')])

    # make extent that's divisible by chip_size
    chip_size = chip_size
    ymax = chip_size * chips_per_dimension
    xmax = chip_size * chips_per_dimension
    extent = Box(0, 0, ymax, xmax)

    # make windows along grid
    windows = extent.get_windows(chip_size, chip_size)

    # for each window, make some random boxes within it and render to image
    nb_channels = 3
    image = np.zeros((ymax, xmax, nb_channels)).astype(np.uint8)
    boxes = []
    class_ids = []
    for window in windows:
        # leave some windows blank
        if random.uniform(0, 1) &gt; 0.3:
            # pick a random class
            class_id = random.randint(1, 2)
            box = window.make_random_square(50).to_int()

            boxes.append(box)
            class_ids.append(class_id)

            image[box.ymin:box.ymax, box.xmin:box.xmax, class_id - 1] = 255

    # save image as geotiff centered in philly
    transform = from_origin(-75.163506, 39.952536, 0.000001, 0.000001)

    print('Generated {} boxes with {} different classes.'.format(
        len(boxes), len(set(class_ids))))

    with rasterio.open(
            tiff_path,
            'w',
            driver='GTiff',
            height=ymax,
            transform=transform,
            crs='EPSG:4326',
            compression=rasterio.enums.Compression.none,
            width=xmax,
            count=nb_channels,
            dtype='uint8') as dst:
        for channel_ind in range(0, nb_channels):
            dst.write(image[:, :, channel_ind], channel_ind + 1)

    if task == 'object_detection':
        # make OD labels and make boxes
        npboxes = Box.to_npboxes(boxes)
        class_ids = np.array(class_ids)
        labels = ObjectDetectionLabels(npboxes, class_ids)

        # save labels to geojson
        with rasterio.open(tiff_path) as image_dataset:
            crs_transformer = RasterioCRSTransformer(image_dataset)
            od_file = ObjectDetectionGeoJSONStore(labels_path, crs_transformer,
                                                  class_map)
            od_file.save(labels)
    elif task == 'semantic_segmentation':
        label_image = np.zeros((ymax, xmax, 1)).astype(np.uint8)

        for box, class_id in zip(boxes, class_ids):
            label_image[box.ymin:box.ymax, box.xmin:box.xmax, 0] = class_id

        # save labels to raster
        with rasterio.open(
                labels_path,
                'w',
                driver='GTiff',
                height=ymax,
                transform=transform,
                crs='EPSG:4326',
                compression=rasterio.enums.Compression.none,
                width=xmax,
                count=1,
                dtype='uint8') as dst:
            dst.write(label_image[:, :, 0], 1)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 149:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 80%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2270')" href="javascript:;">
raster-vision-0.11.0/tests/mock/raster_source.py: 63-73
</a>
<div class="mid" id="frag2270" style="display:none"><pre>
class MockRasterSourceConfig(SupressDeepCopyMixin, RasterSourceConfig):
    def __init__(self, transformers=None, channel_order=None):
        super().__init__(MOCK_SOURCE, transformers, channel_order)
        self.mock = Mock()
        self.mock.to_proto.return_value = None
        self.mock.create_source.return_value = None
        self.mock.update_for_command.return_value = None
        self.mock.save_bundle_files.return_value = (self, [])
        self.mock.load_bundle_files.return_value = self
        self.mock.for_prediction.return_value = self
        self.mock.create_local.return_value = self
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2330')" href="javascript:;">
raster-vision-0.11.0/tests/mock/raster_transformer.py: 29-40
</a>
<div class="mid" id="frag2330" style="display:none"><pre>
                                  RasterTransformerConfig):
    def __init__(self):
        super().__init__(MOCK_TRANSFORMER)
        self.mock = Mock()

        self.mock.to_proto.return_value = None
        self.mock.create_transformer.return_value = None
        self.mock.update_for_command.return_value = None
        self.mock.save_bundle_files.return_value = (self, [])
        self.mock.load_bundle_files.return_value = self
        self.mock.for_prediction.return_value = self
        self.mock.create_local.return_value = self
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 150:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2360')" href="javascript:;">
raster-vision-0.11.0/tests/mock/command.py: 75-88
</a>
<div class="mid" id="frag2360" style="display:none"><pre>

    def get_root_uri(self, experiment_config):
        mock_key = experiment_config.custom_config.get('mock_key')
        if not mock_key:
            mock_uri = experiment_config.custom_config.get('mock_uri')
            if not mock_uri:
                raise rv.ConfigError(
                    'MockCommand requires a mock_key or mock_uri '
                    'be set in the experiment custom_config')
        else:
            mock_uri = os.path.join(experiment_config.root_uri, 'mock',
                                    mock_key)

        return mock_uri
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2399')" href="javascript:;">
raster-vision-0.11.0/tests/data-files/plugins/noop_command.py: 53-66
</a>
<div class="mid" id="frag2399" style="display:none"><pre>

    def get_root_uri(self, experiment_config):
        noop_key = experiment_config.custom_config.get('noop_key')
        if not noop_key:
            noop_uri = experiment_config.custom_config.get('noop_uri')
            if not noop_uri:
                raise rv.ConfigError(
                    'NoopCommand requires a noop_key or noop_uri '
                    'be set in the experiment custom_config')
        else:
            noop_uri = os.path.join(experiment_config.root_uri, 'noop',
                                    noop_key)

        return noop_uri
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 151:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2541')" href="javascript:;">
raster-vision-0.11.0/tests/command/test_aux_command.py: 26-43
</a>
<div class="mid" id="frag2541" style="display:none"><pre>

            self.assertTrue(cmd.mock.run.called)

    def test_command_from_experiment(self):
        with RVConfig.get_tmp_dir() as tmp_dir:
            uris = [('one', '1'), ('two', '2'), ('three', '3'), ('four', '4')]

            e = mk.create_mock_experiment().to_builder() \
                                           .with_root_uri(tmp_dir) \
                                           .with_custom_config({
                                               'mock_aux_command': {
                                                   'key': 'mock',
                                                   'config': {
                                                       'uris': uris
                                                   }
                                               }
                                           }) \
                                           .build()
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2542')" href="javascript:;">
raster-vision-0.11.0/tests/command/test_aux_command.py: 44-61
</a>
<div class="mid" id="frag2542" style="display:none"><pre>

            rv.ExperimentRunner.get_runner(rv.LOCAL).run(
                e, splits=2, commands_to_run=[mk.MOCK_AUX_COMMAND])

            # Nothing to assert here, just ensures code path runs.

    def test_command_from_experiment_case_insensitive(self):
        with RVConfig.get_tmp_dir() as tmp_dir:
            uris = [('one', '1'), ('two', '2'), ('three', '3'), ('four', '4')]

            e = mk.create_mock_experiment().to_builder() \
                                           .with_root_uri(tmp_dir) \
                                           .with_custom_config({
                                               'MOCK_AUX_COMMAND': {
                                                   'key': 'mock',
                                                   'config': {
                                                       'uris': uris
                                                   }
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 152:</b> &nbsp; 2 fragments, nominal size 15 lines, similarity 80%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2545')" href="javascript:;">
raster-vision-0.11.0/tests/command/test_analyze_command.py: 14-35
</a>
<div class="mid" id="frag2545" style="display:none"><pre>
    def test_command_create(self):
        task = rv.TaskConfig.builder(mk.MOCK_TASK).build()
        with RVConfig.get_tmp_dir() as tmp_dir:
            img_path = os.path.join(tmp_dir, 'img.tif')
            chip = np.ones((2, 2, 4)).astype(np.uint8)
            chip[:, :, :] *= np.array([0, 1, 2, 3]).astype(np.uint8)
            save_img(chip, img_path)

            source = rv.data.RasterioSourceConfig(img_path)

            scenes = [rv.data.SceneConfig('', source)]
            analyzers = [
                rv.analyzer.StatsAnalyzerConfig(stats_uri='dummy_path')
            ]

            cmd_conf = rv.CommandConfig.builder(rv.ANALYZE) \
                                       .with_task(task) \
                                       .with_root_uri(tmp_dir) \
                                       .with_scenes(scenes) \
                                       .with_analyzers(analyzers) \
                                       .build()

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2580')" href="javascript:;">
raster-vision-0.11.0/tests/command/test_eval_command.py: 14-33
</a>
<div class="mid" id="frag2580" style="display:none"><pre>
    def test_command_create(self):
        task = rv.TaskConfig.builder(mk.MOCK_TASK).build()
        with RVConfig.get_tmp_dir() as tmp_dir:
            img_path = os.path.join(tmp_dir, 'img.tif')
            chip = np.ones((2, 2, 4)).astype(np.uint8)
            chip[:, :, :] *= np.array([0, 1, 2, 3]).astype(np.uint8)
            save_img(chip, img_path)

            source = rv.data.RasterioSourceConfig(img_path)

            scenes = [rv.data.SceneConfig('scene_id', source)]
            evaluator = rv.EvaluatorConfig.builder(mk.MOCK_EVALUATOR).build()

            cmd_conf = rv.CommandConfig.builder(rv.EVAL) \
                                       .with_task(task) \
                                       .with_root_uri(tmp_dir) \
                                       .with_scenes(scenes) \
                                       .with_evaluators([evaluator]) \
                                       .build()

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 153:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2556')" href="javascript:;">
raster-vision-0.11.0/tests/command/test_predict_command.py: 44-60
</a>
<div class="mid" id="frag2556" style="display:none"><pre>
            rv.CommandConfig.builder(rv.PREDICT) \
                            .with_task('') \
                            .with_backend('') \
                            .build()

    def test_no_config_error(self):
        task = rv.task.ChipClassificationConfig({})
        backend = rv.backend.KerasClassificationConfig('')
        try:
            with RVConfig.get_tmp_dir() as tmp_dir:
                rv.CommandConfig.builder(rv.PREDICT) \
                                .with_task(task) \
                                .with_root_uri(tmp_dir) \
                                .with_backend(backend) \
                                .with_scenes(['']) \
                                .build()
        except rv.ConfigError:
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2563')" href="javascript:;">
raster-vision-0.11.0/tests/command/test_chip_command.py: 47-61
</a>
<div class="mid" id="frag2563" style="display:none"><pre>
                            .with_task('') \
                            .with_backend('') \
                            .with_val_scenes('') \
                            .build()

    def test_missing_config_val_scenes(self):
        with self.assertRaises(rv.ConfigError):
            rv.CommandConfig.builder(rv.CHIP) \
                            .with_task('') \
                            .with_backend('') \
                            .with_train_scenes('') \
                            .build()

    def test_no_config_error(self):
        task = rv.task.ChipClassificationConfig({})
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 154:</b> &nbsp; 2 fragments, nominal size 16 lines, similarity 81%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2564')" href="javascript:;">
raster-vision-0.11.0/tests/command/aux/test_cogify_command.py: 13-34
</a>
<div class="mid" id="frag2564" style="display:none"><pre>
    def test_command_create(self):
        src_path = data_file_path('small-rgb-tile.tif')
        with RVConfig.get_tmp_dir() as tmp_dir:
            cog_path = os.path.join(tmp_dir, 'cog.tif')

            cmd_conf = rv.CommandConfig.builder(rv.COGIFY) \
                                       .with_root_uri(tmp_dir) \
                                       .with_config(uris=[(src_path, cog_path)],
                                                    block_size=128) \
                                       .build()

            cmd_conf = rv.command.CommandConfig.from_proto(cmd_conf.to_proto())
            cmd = cmd_conf.create_command()

            self.assertTrue(cmd, rv.command.aux.CogifyCommand)

            cmd.run(tmp_dir)

            # Check that it's cogified
            with rasterio.open(cog_path) as ds:
                self.assertEqual(ds.block_shapes, [(128, 128), (128, 128),
                                                   (128, 128)])
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2565')" href="javascript:;">
raster-vision-0.11.0/tests/command/aux/test_cogify_command.py: 35-57
</a>
<div class="mid" id="frag2565" style="display:none"><pre>
                self.assertEqual(ds.overviews(1), [2, 4, 8, 16, 32])
                self.assertEqual(ds.compression.value, 'DEFLATE')

    def test_command_create_no_compression(self):
        src_path = data_file_path('small-rgb-tile.tif')
        with RVConfig.get_tmp_dir() as tmp_dir:
            cog_path = os.path.join(tmp_dir, 'cog.tif')

            cmd_conf = rv.CommandConfig.builder(rv.COGIFY) \
                                       .with_root_uri(tmp_dir) \
                                       .with_config(uris=[(src_path, cog_path)],
                                                    block_size=128,
                                                    compression='none') \
                                       .build()

            cmd_conf = rv.command.CommandConfig.from_proto(cmd_conf.to_proto())
            cmd = cmd_conf.create_command()

            self.assertTrue(cmd, rv.command.aux.CogifyCommand)

            cmd.run(tmp_dir)

            # Check that it's cogified
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 155:</b> &nbsp; 2 fragments, nominal size 31 lines, similarity 87%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2569')" href="javascript:;">
raster-vision-0.11.0/tests/command/test_bundle_command.py: 32-70
</a>
<div class="mid" id="frag2569" style="display:none"><pre>
        raster_source = rv.RasterSourceConfig \
                          .builder(rv.RASTERIO_SOURCE) \
                          .with_uri('TEST') \
                          .with_transformer(transformer) \
                          .build()

        scene = rv.SceneConfig.builder() \
                              .with_id('TEST') \
                              .with_raster_source(raster_source) \
                              .build()
        return scene

    def test_bundle_cc_command(self):
        def get_task(tmp_dir):
            predict_package_uri = os.path.join(tmp_dir, 'predict_package.zip')
            t = rv.TaskConfig.builder(rv.CHIP_CLASSIFICATION) \
                             .with_predict_package_uri(predict_package_uri) \
                             .with_classes(['class1']) \
                             .build()
            return t

        def get_backend(task, tmp_dir):
            model_uri = os.path.join(tmp_dir, 'model')
            with open(model_uri, 'w') as f:
                f.write('DUMMY')
            b = rv.BackendConfig.builder(rv.KERAS_CLASSIFICATION) \
                                .with_task(task) \
                                .with_model_defaults(rv.RESNET50_IMAGENET) \
                                .with_model_uri(model_uri) \
                                .build()
            return b

        with RVConfig.get_tmp_dir() as tmp_dir:
            task = get_task(tmp_dir)
            backend = get_backend(task, tmp_dir)
            analyzer = self.get_analyzer(tmp_dir)
            scene = self.get_scene(tmp_dir)
            cmd = rv.CommandConfig.builder(rv.BUNDLE) \
                                  .with_task(task) \
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2572')" href="javascript:;">
raster-vision-0.11.0/tests/command/test_bundle_command.py: 71-111
</a>
<div class="mid" id="frag2572" style="display:none"><pre>
                                  .with_root_uri(tmp_dir) \
                                  .with_backend(backend) \
                                  .with_analyzers([analyzer]) \
                                  .with_scene(scene) \
                                  .build() \
                                  .create_command(tmp_dir)

            cmd.run(tmp_dir)

            package_dir = os.path.join(tmp_dir, 'package')
            make_dir(package_dir)
            with zipfile.ZipFile(task.predict_package_uri, 'r') as package_zip:
                package_zip.extractall(path=package_dir)

            bundle_config_path = os.path.join(package_dir,
                                              'bundle_config.json')
            bundle_config = load_json_config(bundle_config_path,
                                             CommandConfigMsg())

            self.assertEqual(bundle_config.command_type, rv.BUNDLE)

            actual = set(os.listdir(package_dir))
            expected = set(['stats.json', 'model', 'bundle_config.json'])

            self.assertEqual(actual, expected)

    def test_bundle_od_command(self):
        def get_task(tmp_dir):
            predict_package_uri = os.path.join(tmp_dir, 'predict_package.zip')
            t = rv.TaskConfig.builder(rv.OBJECT_DETECTION) \
                             .with_predict_package_uri(predict_package_uri) \
                             .with_classes(['class1']) \
                             .build()
            return t

        def get_backend(task, tmp_dir):
            model_uri = os.path.join(tmp_dir, 'model')
            template_uri = data_file_path(
                'tf_object_detection/embedded_ssd_mobilenet_v1_coco.config')
            with open(model_uri, 'w') as f:
                f.write('DUMMY')
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 156:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 83%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2601')" href="javascript:;">
raster-vision-0.11.0/tests/data/label_source/test_semantic_segmentation_label_source.py: 14-25
</a>
<div class="mid" id="frag2601" style="display:none"><pre>
    def test_enough_target_pixels_true(self):
        data = np.zeros((10, 10, 3), dtype=np.uint8)
        data[4:, 4:, :] = [1, 1, 1]
        raster_source = MockRasterSource([0, 1, 2], 3)
        raster_source.set_raster(data)
        rgb_class_map = ClassMap([ClassItem(id=1, color='#010101')])
        label_source = SemanticSegmentationLabelSource(
            source=raster_source, rgb_class_map=rgb_class_map)
        with label_source.activate():
            extent = Box(0, 0, 10, 10)
            self.assertTrue(label_source.enough_target_pixels(extent, 30, [1]))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2602')" href="javascript:;">
raster-vision-0.11.0/tests/data/label_source/test_semantic_segmentation_label_source.py: 26-38
</a>
<div class="mid" id="frag2602" style="display:none"><pre>
    def test_enough_target_pixels_false(self):
        data = np.zeros((10, 10, 3), dtype=np.uint8)
        data[7:, 7:, :] = [1, 1, 1]
        raster_source = MockRasterSource([0, 1, 2], 3)
        raster_source.set_raster(data)
        rgb_class_map = ClassMap([ClassItem(id=1, color='#010101')])
        label_source = SemanticSegmentationLabelSource(
            source=raster_source, rgb_class_map=rgb_class_map)
        with label_source.activate():
            extent = Box(0, 0, 10, 10)
            self.assertFalse(
                label_source.enough_target_pixels(extent, 30, [1]))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 157:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 92%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2620')" href="javascript:;">
raster-vision-0.11.0/tests/data/label_source/test_chip_classification_label_source.py: 209-225
</a>
<div class="mid" id="frag2620" style="display:none"><pre>
        self.assertEqual(labels.get_cell_class_id(self.box1), self.class_id1)
        self.assertEqual(labels.get_cell_class_id(self.box2), self.class_id2)
        self.assertEqual(
            labels.get_cell_class_id(Box.make_square(0, 4, 4)),
            self.background_class_id)
        self.assertEqual(
            labels.get_cell_class_id(Box.make_square(4, 0, 4)),
            self.background_class_id)

    def test_get_labels_small_extent(self):
        # Extent only has enough of first box in it.
        extent = Box.make_square(0, 0, 2)

        msg = rv.LabelSourceConfig.builder(rv.CHIP_CLASSIFICATION) \
                .with_uri(self.uri) \
                .build().to_proto()
        config = rv.LabelSourceConfig.builder(rv.CHIP_CLASSIFICATION) \
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2621')" href="javascript:;">
raster-vision-0.11.0/tests/data/label_source/test_chip_classification_label_source.py: 226-242
</a>
<div class="mid" id="frag2621" style="display:none"><pre>
                   .from_proto(msg).build()
        source = config.create_source(self.task_config, extent,
                                      self.crs_transformer, self.temp_dir.name)
        labels = source.get_labels()

        cells = labels.get_cells()
        self.assertEqual(len(cells), 1)
        class_id = labels.get_cell_class_id(self.box1)
        self.assertEqual(class_id, self.class_id1)
        class_id = labels.get_cell_class_id(self.box2)
        self.assertEqual(class_id, None)

    def test_get_labels(self):
        # Extent contains both boxes.
        extent = Box.make_square(0, 0, 8)

        msg = rv.LabelSourceConfig.builder(rv.CHIP_CLASSIFICATION) \
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 158:</b> &nbsp; 2 fragments, nominal size 16 lines, similarity 93%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2644')" href="javascript:;">
raster-vision-0.11.0/tests/data/raster_source/test_rasterio_source.py: 93-114
</a>
<div class="mid" id="frag2644" style="display:none"><pre>
        source = rv.data.RasterioSourceConfig(uris=[img_path],
                                              channel_order=channel_order) \
                        .create_source(tmp_dir=None)

        with source.activate():
            out_chip = source.get_raw_image_array()
            self.assertEqual(out_chip.shape[2], 3)

    def test_shift_x(self):
        # Specially-engineered image w/ one meter per pixel resolution
        # in the x direction.
        img_path = data_file_path('ones.tif')
        channel_order = [0]

        msg = rv.data.RasterioSourceConfig(uris=[img_path],
                                           x_shift_meters=1.0,
                                           y_shift_meters=0.0,
                                           channel_order=channel_order) \
                     .to_proto()

        tmp_dir = RVConfig.get_tmp_dir().name
        make_dir(tmp_dir)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2645')" href="javascript:;">
raster-vision-0.11.0/tests/data/raster_source/test_rasterio_source.py: 115-136
</a>
<div class="mid" id="frag2645" style="display:none"><pre>
        source = rv.RasterSourceConfig.from_proto(msg) \
                                      .create_source(tmp_dir=tmp_dir)

        with source.activate():
            extent = source.get_extent()
            data = source.get_chip(extent)
            self.assertEqual(data.sum(), 2**16 - 256)
            column = data[:, 255, 0]
            self.assertEqual(column.sum(), 0)

    def test_shift_y(self):
        # Specially-engineered image w/ one meter per pixel resolution
        # in the y direction.
        img_path = data_file_path('ones.tif')
        channel_order = [0]

        msg = rv.data.RasterioSourceConfig(uris=[img_path],
                                           x_shift_meters=0.0,
                                           y_shift_meters=1.0,
                                           channel_order=channel_order) \
                     .to_proto()

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 159:</b> &nbsp; 3 fragments, nominal size 35 lines, similarity 89%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2740')" href="javascript:;">
raster-vision-0.11.0/tests/utils/test_misc.py: 57-107
</a>
<div class="mid" id="frag2740" style="display:none"><pre>
    def test_set_nested_keys_finds_nested(self):
        d = {
            'one': 1,
            'two': 2,
            'three': {
                'four': 4,
                'five': 5,
                'six': [
                    {
                        'seven': 7
                    },
                    {
                        'eight': 8
                    },
                    {
                        'nine': 9
                    },
                ],
                'ten': {
                    'eleven': 11
                }
            }
        }

        expected = {
            'one': 1,
            'two': 2,
            'three': {
                'four': 4,
                'five': 55,
                'six': [
                    {
                        'seven': 7
                    },
                    {
                        'eight': 8
                    },
                    {
                        'nine': 9
                    },
                ],
                'ten': {
                    'eleven': 11
                }
            }
        }

        set_nested_keys(d, {'five': 55})

        self.assertEqual(d, expected)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2742')" href="javascript:;">
raster-vision-0.11.0/tests/utils/test_misc.py: 159-212
</a>
<div class="mid" id="frag2742" style="display:none"><pre>
    def test_set_nested_keys_sets_missing_keys_in_dict(self):
        d = {
            'one': 1,
            'two': 2,
            'three': {
                'four': 4,
                'five': 5,
                'six': [
                    {
                        'seven': 7
                    },
                    {
                        'eight': 8
                    },
                    {
                        'nine': 9
                    },
                ],
                'ten': {
                    'eleven': 11
                }
            }
        }

        expected = {
            'one': 1,
            'two': 2,
            'three': {
                'four': 4,
                'five': 5,
                'six': [
                    {
                        'seven': 7
                    },
                    {
                        'eight': 8
                    },
                    {
                        'nine': 9
                    },
                ],
                'ten': {
                    'eleven': 11
                },
                'twelve': 12
            }
        }

        mod = {'three': {'twelve': 12}}

        set_nested_keys(d, mod, set_missing_keys=True)

        self.assertEqual(d, expected)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2741')" href="javascript:;">
raster-vision-0.11.0/tests/utils/test_misc.py: 108-158
</a>
<div class="mid" id="frag2741" style="display:none"><pre>
    def test_set_nested_keys_ignores_missing_keys(self):
        d = {
            'one': 1,
            'two': 2,
            'three': {
                'four': 4,
                'five': 5,
                'six': [
                    {
                        'seven': 7
                    },
                    {
                        'eight': 8
                    },
                    {
                        'nine': 9
                    },
                ],
                'ten': {
                    'eleven': 11
                }
            }
        }

        expected = {
            'one': 1,
            'two': 2,
            'three': {
                'four': 4,
                'five': 5,
                'six': [
                    {
                        'seven': 7
                    },
                    {
                        'eight': 8
                    },
                    {
                        'nine': 9
                    },
                ],
                'ten': {
                    'eleven': 11
                }
            }
        }

        set_nested_keys(d, {'twenty': 20}, ignore_missing_keys=True)

        self.assertEqual(d, expected)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 160:</b> &nbsp; 3 fragments, nominal size 14 lines, similarity 71%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2856')" href="javascript:;">
raster-vision-0.11.0/tests/evaluation/test_semantic_segmentation_evaluator.py: 86-99
</a>
<div class="mid" id="frag2856" style="display:none"><pre>
    def test_evaluator(self):
        class_map = ClassMap([
            ClassItem(id=1, name='one'),
            ClassItem(id=2, name='two'),
        ])
        output_uri = join(self.tmp_dir.name, 'out.json')
        scenes = [self.get_scene(1), self.get_scene(2)]
        evaluator = SemanticSegmentationEvaluator(class_map, output_uri, None)
        evaluator.process(scenes, self.tmp_dir.name)
        eval_json = json.loads(file_to_str(output_uri))
        exp_eval_json = json.loads(
            file_to_str(data_file_path('expected-eval.json')))
        self.assertDictEqual(eval_json, exp_eval_json)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2858')" href="javascript:;">
raster-vision-0.11.0/tests/evaluation/test_semantic_segmentation_evaluator.py: 120-140
</a>
<div class="mid" id="frag2858" style="display:none"><pre>
    def test_vector_evaluator_with_aoi(self):
        class_map = ClassMap([
            ClassItem(id=1, name='one'),
        ])
        output_uri = join(self.tmp_dir.name, 'raster-out.json')
        vector_output_uri = join(self.tmp_dir.name, 'vector-out.json')
        scenes = [self.get_vector_scene(1, use_aoi=True)]
        evaluator = SemanticSegmentationEvaluator(class_map, output_uri,
                                                  vector_output_uri)
        evaluator.process(scenes, self.tmp_dir.name)
        vector_eval_json = json.loads(file_to_str(vector_output_uri))
        exp_vector_eval_json = json.loads(
            file_to_str(data_file_path('expected-vector-eval-with-aoi.json')))

        # NOTE:  The precision  and recall  values found  in the  file
        # `expected-vector-eval.json`  are equal to fractions of  the
        # form (n-1)/n for  n &lt;= 7 which  can be seen to  be (and have
        # been manually verified to be) correct.
        self.assertDictEqual(vector_eval_json, exp_vector_eval_json)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2857')" href="javascript:;">
raster-vision-0.11.0/tests/evaluation/test_semantic_segmentation_evaluator.py: 100-119
</a>
<div class="mid" id="frag2857" style="display:none"><pre>
    def test_vector_evaluator(self):
        class_map = ClassMap([
            ClassItem(id=1, name='one'),
            ClassItem(id=2, name='two'),
        ])
        output_uri = join(self.tmp_dir.name, 'raster-out.json')
        vector_output_uri = join(self.tmp_dir.name, 'vector-out.json')
        scenes = [self.get_vector_scene(1), self.get_vector_scene(2)]
        evaluator = SemanticSegmentationEvaluator(class_map, output_uri,
                                                  vector_output_uri)
        evaluator.process(scenes, self.tmp_dir.name)
        vector_eval_json = json.loads(file_to_str(vector_output_uri))
        exp_vector_eval_json = json.loads(
            file_to_str(data_file_path('expected-vector-eval.json')))
        # NOTE:  The precision  and recall  values found  in the  file
        # `expected-vector-eval.json`  are equal to fractions of  the
        # form (n-1)/n for  n &lt;= 7 which  can be seen to  be (and have
        # been manually verified to be) correct.
        self.assertDictEqual(vector_eval_json, exp_vector_eval_json)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 161:</b> &nbsp; 3 fragments, nominal size 20 lines, similarity 85%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2863')" href="javascript:;">
raster-vision-0.11.0/tests/task/test_semantic_segmentation_config.py: 22-48
</a>
<div class="mid" id="frag2863" style="display:none"><pre>
        self.assertListEqual(t.class_map.get_items(), expected)
        self.assertListEqual(t.chip_options.target_classes, [1, 2])

    def test_build_task_from_proto(self):
        task_config = {
            'task_type': rv.SEMANTIC_SEGMENTATION,
            'semantic_segmentation_config': {
                'chip_options': {
                    'debug_chip_probability': 0.75
                },
                'chip_size':
                500,
                'class_items': [{
                    'id': 1,
                    'name': 'car',
                    'color': 'red'
                }, {
                    'id': 2,
                    'name': 'building',
                    'color': 'blue'
                }]
            }
        }
        msg = json_format.Parse(json.dumps(task_config), TaskConfigMsg())
        task = rv.TaskConfig.from_proto(msg)

        self.assertEqual(task.class_map.get_by_name('building').id, 2)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2872')" href="javascript:;">
raster-vision-0.11.0/tests/task/test_object_detection_config.py: 21-47
</a>
<div class="mid" id="frag2872" style="display:none"><pre>
        self.assertListEqual(t.class_map.get_items(), expected)

    def test_build_task_from_proto(self):
        task_config = {
            'task_type': rv.OBJECT_DETECTION,
            'object_detection_config': {
                'chip_size':
                500,
                'class_items': [{
                    'id': 1,
                    'name': 'car',
                    'color': 'red'
                }, {
                    'id': 2,
                    'name': 'building',
                    'color': 'blue'
                }, {
                    'id': 3,
                    'name': 'background',
                    'color': 'black'
                }]
            }
        }
        msg = json_format.Parse(json.dumps(task_config), TaskConfigMsg())
        task = rv.TaskConfig.from_proto(msg)

        self.assertEqual(task.class_map.get_by_name('building').id, 2)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2867')" href="javascript:;">
raster-vision-0.11.0/tests/task/test_chip_classification_config.py: 21-48
</a>
<div class="mid" id="frag2867" style="display:none"><pre>
        self.assertListEqual(t.class_map.get_items(), expected)

    def test_build_task_from_proto(self):
        task_config = {
            'task_type': rv.CHIP_CLASSIFICATION,
            'chip_classification_config': {
                'chip_size':
                500,
                'class_items': [{
                    'id': 1,
                    'name': 'car',
                    'color': 'red'
                }, {
                    'id': 2,
                    'name': 'building',
                    'color': 'blue'
                }, {
                    'id': 3,
                    'name': 'background',
                    'color': 'black'
                }]
            }
        }
        msg = json_format.Parse(json.dumps(task_config), TaskConfigMsg())

        task = rv.TaskConfig.from_proto(msg)

        self.assertEqual(task.class_map.get_by_name('building').id, 2)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 162:</b> &nbsp; 3 fragments, nominal size 12 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2864')" href="javascript:;">
raster-vision-0.11.0/tests/task/test_semantic_segmentation_config.py: 49-68
</a>
<div class="mid" id="frag2864" style="display:none"><pre>
        self.assertEqual(task.chip_size, 500)
        self.assertEqual(task.chip_options.debug_chip_probability, 0.75)

    def test_create_proto_from_task(self):
        t = rv.TaskConfig.builder(rv.SEMANTIC_SEGMENTATION) \
                         .with_classes(['car', 'boat']) \
                         .with_chip_size(500) \
                         .build()

        msg = t.to_proto()

        expected_classes = [
            ClassItemMsg(name='car', id=1),
            ClassItemMsg(name='boat', id=2)
        ]

        self.assertEqual(msg.task_type, rv.SEMANTIC_SEGMENTATION)
        self.assertEqual(msg.semantic_segmentation_config.chip_size, 500)

        actual_class_items = dict(
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2868')" href="javascript:;">
raster-vision-0.11.0/tests/task/test_chip_classification_config.py: 49-67
</a>
<div class="mid" id="frag2868" style="display:none"><pre>
        self.assertEqual(task.chip_size, 500)

    def test_create_proto_from_task(self):
        t = rv.TaskConfig.builder(rv.CHIP_CLASSIFICATION) \
                         .with_classes(['car', 'boat']) \
                         .with_chip_size(500) \
                         .build()

        msg = t.to_proto()

        expected_classes = [
            ClassItemMsg(name='car', id=1),
            ClassItemMsg(name='boat', id=2)
        ]

        self.assertEqual(msg.task_type, rv.CHIP_CLASSIFICATION)
        self.assertEqual(msg.chip_classification_config.chip_size, 500)

        actual_class_items = dict(
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2873')" href="javascript:;">
raster-vision-0.11.0/tests/task/test_object_detection_config.py: 48-66
</a>
<div class="mid" id="frag2873" style="display:none"><pre>
        self.assertEqual(task.chip_size, 500)

    def test_create_proto_from_task(self):
        t = rv.TaskConfig.builder(rv.OBJECT_DETECTION) \
                         .with_classes(['car', 'boat']) \
                         .with_chip_size(500) \
                         .build()

        msg = t.to_proto()

        expected_classes = [
            ClassItemMsg(name='car', id=1),
            ClassItemMsg(name='boat', id=2)
        ]

        self.assertEqual(msg.task_type, rv.OBJECT_DETECTION)
        self.assertEqual(msg.object_detection_config.chip_size, 500)

        actual_class_items = dict(
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 163:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 90%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2883')" href="javascript:;">
raster-vision-0.11.0/tests/core/test_class_map.py: 57-68
</a>
<div class="mid" id="frag2883" style="display:none"><pre>

    def test_construct_from_protos(self):
        source = [
            ClassItemMsg(id=1, name='one', color='red'),
            ClassItemMsg(id=2, name='two', color='green'),
            ClassItemMsg(id=3, name='three', color='blue')
        ]
        cm = ClassMap.construct_from(source)
        for i, msg in enumerate(source):
            expected = ClassItem.from_proto(msg)
            actual = cm.get_by_id(i + 1)
            self.assertEqual(actual, expected)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2884')" href="javascript:;">
raster-vision-0.11.0/tests/core/test_class_map.py: 69-80
</a>
<div class="mid" id="frag2884" style="display:none"><pre>

    def test_construct_from_class_items(self):
        source = [
            ClassItem(id=1, name='one', color='red'),
            ClassItem(id=2, name='two', color='green'),
            ClassItem(id=3, name='three', color='blue')
        ]
        cm = ClassMap.construct_from(source)
        for i, item in enumerate(source):
            expected = item
            actual = cm.get_by_id(i + 1)
            self.assertEqual(actual, expected)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 164:</b> &nbsp; 2 fragments, nominal size 45 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2945')" href="javascript:;">
raster-vision-0.11.0/integration_tests/chip_classification_tests/experiment.py: 8-73
</a>
<div class="mid" id="frag2945" style="display:none"><pre>
    def exp_main(self, root_uri, data_uri=None, full_train=False,
                 use_tf=False):
        full_train = str_to_bool(full_train)
        use_tf = str_to_bool(use_tf)

        def get_path(part):
            if full_train:
                return os.path.join(data_uri, part)
            else:
                return os.path.join(os.path.dirname(__file__), part)

        img_path = get_path('scene/image.tif')
        label_path = get_path('scene/labels.json')

        img2_path = get_path('scene/image2.tif')
        label2_path = get_path('scene/labels2.json')

        backend_conf_path = get_path('configs/backend.config')

        task = rv.TaskConfig.builder(rv.CHIP_CLASSIFICATION) \
                            .with_chip_size(200) \
                            .with_classes({
                                'car': (1, 'red'),
                                'building': (2, 'blue'),
                                'background': (3, 'black')
                            }) \
                            .with_debug(True) \
                            .build()

        if use_tf:
            pretrained_model = (
                'https://github.com/azavea/raster-vision-data/'
                'releases/download/v0.0.7/chip-classification-test-weights.hdf5'
            )

            backend = rv.BackendConfig.builder(rv.KERAS_CLASSIFICATION) \
                .with_task(task) \
                .with_debug(True) \
                .with_template(backend_conf_path) \
                .with_num_epochs(8) \
                .with_pretrained_model(pretrained_model) \
                .with_train_options(sync_interval=None,
                                    do_monitoring=False,
                                    replace_model=True) \
                .build()
        else:
            if full_train:
                backend = rv.BackendConfig.builder(rv.PYTORCH_CHIP_CLASSIFICATION) \
                    .with_task(task) \
                    .with_train_options(
                        batch_size=16,
                        num_epochs=10,
                        sync_interval=200) \
                    .build()
            else:
                pretrained_uri = (
                    'https://github.com/azavea/raster-vision-data/releases/download/'
                    'v0.9.0/pytorch_chip_classification_test.pth')
                backend = rv.BackendConfig.builder(rv.PYTORCH_CHIP_CLASSIFICATION) \
                    .with_task(task) \
                    .with_train_options(
                        batch_size=2,
                        num_epochs=1,
                        lr=1e-9) \
                    .with_pretrained_uri(pretrained_uri) \
                    .build()
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2950')" href="javascript:;">
raster-vision-0.11.0/integration_tests/object_detection_tests/experiment.py: 8-67
</a>
<div class="mid" id="frag2950" style="display:none"><pre>
    def exp_main(self, root_uri, data_uri=None, full_train=False,
                 use_tf=False):
        full_train = str_to_bool(full_train)
        use_tf = str_to_bool(use_tf)

        def get_path(part):
            if full_train:
                return os.path.join(data_uri, part)
            else:
                return os.path.join(os.path.dirname(__file__), part)

        img_path = get_path('scene/image.tif')
        label_path = get_path('scene/labels.json')
        img2_path = get_path('scene/image2.tif')
        label2_path = get_path('scene/labels2.json')
        backend_conf_path = get_path('configs/backend.config')

        task = rv.TaskConfig.builder(rv.OBJECT_DETECTION) \
                            .with_chip_size(300) \
                            .with_classes({
                                'car': (1, 'blue'),
                                'building': (2, 'red')
                            }) \
                            .with_chip_options(neg_ratio=1.0,
                                               ioa_thresh=1.0,
                                               window_method='sliding') \
                            .with_predict_options(merge_thresh=0.1,
                                                  score_thresh=0.5) \
                            .build()

        if use_tf:
            pretrained_model = (
                'https://github.com/azavea/raster-vision-data/'
                'releases/download/v0.0.7/object-detection-test.tar.gz')

            backend = rv.BackendConfig.builder(rv.TF_OBJECT_DETECTION) \
                                    .with_task(task) \
                                    .with_num_steps(200) \
                                    .with_template(backend_conf_path) \
                                    .with_pretrained_model(pretrained_model) \
                                    .with_train_options(sync_interval=None,
                                                        do_monitoring=False,
                                                        replace_model=True) \
                                    .with_debug(True) \
                                    .build()
        else:
            if full_train:
                backend = rv.BackendConfig.builder(rv.PYTORCH_OBJECT_DETECTION) \
                    .with_task(task) \
                    .with_train_options(
                        batch_size=8,
                        num_epochs=200,
                        sync_interval=200) \
                    .build()
            else:
                pretrained_uri = (
                    'https://github.com/azavea/raster-vision-data/releases/download/'
                    'v0.9.0/pytorch_object_detection_test.pth')

                backend = rv.BackendConfig.builder(rv.PYTORCH_OBJECT_DETECTION) \
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<script language="JavaScript">
function ShowHide(divId) { 
    if(document.getElementById(divId).style.display == 'none') {
        document.getElementById(divId).style.display='block';
    } else { 
        document.getElementById(divId).style.display = 'none';
    } 
}
</script>
</body>
</html>
