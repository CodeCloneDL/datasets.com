<html>
<head>
    <title>NiCad6 Clone Report</title>
    <style type="text/css">
        body {font-family:sans-serif;}
        table {background-color:white; border:0px; padding:0px; border-spacing:4px; width:auto; margin-left:30px; margin-right:auto;}
        td {background-color:rgba(192,212,238,0.8); border:0px; padding:8px; width:auto; vertical-align:top; border-radius:8px}
        pre {background-color:white; padding:4px;}
        a {color:darkblue;}
    </style>
</head>
<body>
<h2>NiCad6 Clone Report</h2>
<table>
<tr style="font-size:14pt">
<td><b>System:</b> &nbsp; autokeras-1.0.16</td>
<td><b>Clone pairs:</b> &nbsp; 48</td>
<td><b>Clone classes:</b> &nbsp; 14</td>
</tr>
<tr style="font-size:12pt">
<td style="background-color:white">Clone type: &nbsp; 3-2</td>
<td style="background-color:white">Granularity: &nbsp; functions-blind</td>
<td style="background-color:white">Max diff threshold: &nbsp; 30%</td>
<td style="background-color:white">Clone size: &nbsp; 10 - 2500 lines</td>
<td style="background-color:white">Total functions-blind: &nbsp; 687</td>
</tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 1:</b> &nbsp; 2 fragments, nominal size 20 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag9')" href="javascript:;">
autokeras-1.0.16/tests/performance.py: 25-55
</a>
<div class="mid" id="frag9" style="display:none"><pre>
def imdb_raw(num_instances=100):
    dataset = tf.keras.utils.get_file(
        fname="aclImdb.tar.gz",
        origin="http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz",
        extract=True,
    )

    # set path to dataset
    IMDB_DATADIR = os.path.join(os.path.dirname(dataset), "aclImdb")

    classes = ["pos", "neg"]
    train_data = load_files(
        os.path.join(IMDB_DATADIR, "train"), shuffle=True, categories=classes
    )
    test_data = load_files(
        os.path.join(IMDB_DATADIR, "test"), shuffle=False, categories=classes
    )

    x_train = np.array(train_data.data)
    y_train = np.array(train_data.target)
    x_test = np.array(test_data.data)
    y_test = np.array(test_data.target)

    if num_instances is not None:
        x_train = x_train[:num_instances]
        y_train = y_train[:num_instances]
        x_test = x_test[:num_instances]
        y_test = y_test[:num_instances]
    return (x_train, y_train), (x_test, y_test)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag678')" href="javascript:;">
autokeras-1.0.16/benchmark/experiments/text.py: 35-57
</a>
<div class="mid" id="frag678" style="display:none"><pre>
    def load_data():
        dataset = tf.keras.utils.get_file(
            fname="aclImdb.tar.gz",
            origin="http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz",
            extract=True,
        )

        # set path to dataset
        IMDB_DATADIR = os.path.join(os.path.dirname(dataset), "aclImdb")

        classes = ["pos", "neg"]
        train_data = load_files(
            os.path.join(IMDB_DATADIR, "train"), shuffle=True, categories=classes
        )
        test_data = load_files(
            os.path.join(IMDB_DATADIR, "test"), shuffle=False, categories=classes
        )

        x_train = np.array(train_data.data)
        y_train = np.array(train_data.target)
        x_test = np.array(test_data.data)
        y_test = np.array(test_data.target)
        return (x_train, y_train), (x_test, y_test)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 2:</b> &nbsp; 2 fragments, nominal size 15 lines, similarity 75%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag22')" href="javascript:;">
autokeras-1.0.16/tests/unit_tests/analysers/input_analysers_test.py: 42-59
</a>
<div class="mid" id="frag22" style="display:none"><pre>
def test_structured_data_infer_col_types():
    analyser = input_analysers.StructuredDataAnalyser(
        column_names=utils.COLUMN_NAMES,
        column_types=None,
    )
    x = pd.read_csv(utils.TRAIN_CSV_PATH)
    x.pop("survived")
    dataset = tf.data.Dataset.from_tensor_slices(x.values.astype(np.unicode)).batch(
        32
    )

    for data in dataset:
        analyser.update(data)
    analyser.finalize()

    assert analyser.column_types == utils.COLUMN_TYPES


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag23')" href="javascript:;">
autokeras-1.0.16/tests/unit_tests/analysers/input_analysers_test.py: 60-81
</a>
<div class="mid" id="frag23" style="display:none"><pre>
def test_dont_infer_specified_column_types():
    column_types = copy.copy(utils.COLUMN_TYPES)
    column_types.pop("sex")
    column_types["age"] = "categorical"

    analyser = input_analysers.StructuredDataAnalyser(
        column_names=utils.COLUMN_NAMES,
        column_types=column_types,
    )
    x = pd.read_csv(utils.TRAIN_CSV_PATH)
    x.pop("survived")
    dataset = tf.data.Dataset.from_tensor_slices(x.values.astype(np.unicode)).batch(
        32
    )

    for data in dataset:
        analyser.update(data)
    analyser.finalize()

    assert analyser.column_types["age"] == "categorical"


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 3:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag24')" href="javascript:;">
autokeras-1.0.16/tests/unit_tests/analysers/input_analysers_test.py: 82-98
</a>
<div class="mid" id="frag24" style="display:none"><pre>
def test_structured_data_input_with_illegal_dim():
    analyser = input_analysers.StructuredDataAnalyser(
        column_names=utils.COLUMN_NAMES,
        column_types=None,
    )
    dataset = tf.data.Dataset.from_tensor_slices(np.random.rand(100, 32, 32)).batch(
        32
    )

    with pytest.raises(ValueError) as info:
        for data in dataset:
            analyser.update(data)
        analyser.finalize()

    assert "Expect the data to StructuredDataInput to have shape" in str(info.value)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag31')" href="javascript:;">
autokeras-1.0.16/tests/unit_tests/analysers/input_analysers_test.py: 171-185
</a>
<div class="mid" id="frag31" style="display:none"><pre>
def test_time_series_input_with_illegal_dim():
    analyser = input_analysers.TimeseriesAnalyser(
        column_names=utils.COLUMN_NAMES,
        column_types=None,
    )
    dataset = tf.data.Dataset.from_tensor_slices(np.random.rand(100, 32, 32)).batch(
        32
    )

    with pytest.raises(ValueError) as info:
        for data in dataset:
            analyser.update(data)
        analyser.finalize()

    assert "Expect the data to TimeseriesInput to have shape" in str(info.value)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 4:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag117')" href="javascript:;">
autokeras-1.0.16/tests/unit_tests/tuners/task_specific_test.py: 104-120
</a>
<div class="mid" id="frag117" style="display:none"><pre>
def test_sd_clf_init_hp0_equals_hp_of_a_model(tmp_path):
    clf = ak.StructuredDataClassifier(
        directory=tmp_path,
        column_names=["a", "b"],
        column_types={"a": "numerical", "b": "numerical"},
    )
    clf.inputs[0].shape = (2,)
    clf.outputs[0].in_blocks[0].shape = (10,)
    init_hp = task_specific.STRUCTURED_DATA_CLASSIFIER[0]
    hp = keras_tuner.HyperParameters()
    hp.values = copy.copy(init_hp)

    clf.tuner.hypermodel.build(hp)

    assert set(init_hp.keys()) == set(hp._hps.keys())


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag118')" href="javascript:;">
autokeras-1.0.16/tests/unit_tests/tuners/task_specific_test.py: 121-135
</a>
<div class="mid" id="frag118" style="display:none"><pre>
def test_sd_reg_init_hp0_equals_hp_of_a_model(tmp_path):
    clf = ak.StructuredDataRegressor(
        directory=tmp_path,
        column_names=["a", "b"],
        column_types={"a": "numerical", "b": "numerical"},
    )
    clf.inputs[0].shape = (2,)
    clf.outputs[0].in_blocks[0].shape = (10,)
    init_hp = task_specific.STRUCTURED_DATA_REGRESSOR[0]
    hp = keras_tuner.HyperParameters()
    hp.values = copy.copy(init_hp)

    clf.tuner.hypermodel.build(hp)

    assert set(init_hp.keys()) == set(hp._hps.keys())
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 5:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 90%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag176')" href="javascript:;">
autokeras-1.0.16/tests/unit_tests/blocks/reduction_test.py: 23-36
</a>
<div class="mid" id="frag176" style="display:none"><pre>
def test_merge_build_return_tensor():
    block = blocks.Merge()

    outputs = block.build(
        keras_tuner.HyperParameters(),
        [
            tf.keras.Input(shape=(32,), dtype=tf.float32),
            tf.keras.Input(shape=(4, 8), dtype=tf.float32),
        ],
    )

    assert len(nest.flatten(outputs)) == 1


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag178')" href="javascript:;">
autokeras-1.0.16/tests/unit_tests/blocks/reduction_test.py: 48-61
</a>
<div class="mid" id="frag178" style="display:none"><pre>
def test_merge_inputs_with_same_shape_return_tensor():
    block = blocks.Merge()

    outputs = block.build(
        keras_tuner.HyperParameters(),
        [
            tf.keras.Input(shape=(32,), dtype=tf.float32),
            tf.keras.Input(shape=(32,), dtype=tf.float32),
        ],
    )

    assert len(nest.flatten(outputs)) == 1


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 6:</b> &nbsp; 3 fragments, nominal size 15 lines, similarity 93%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag190')" href="javascript:;">
autokeras-1.0.16/tests/unit_tests/blocks/heads_test.py: 28-44
</a>
<div class="mid" id="frag190" style="display:none"><pre>
def test_two_classes_infer_binary_crossentropy():
    dataset = np.array(["a", "a", "a", "b"])
    head = head_module.ClassificationHead(name="a", shape=(1,))
    adapter = head.get_adapter()
    dataset = adapter.adapt(dataset, batch_size=32)
    analyser = head.get_analyser()
    for data in dataset:
        analyser.update(data)
    analyser.finalize()
    head.config_from_analyser(analyser)
    head.build(
        keras_tuner.HyperParameters(),
        input_module.Input(shape=(32,)).build_node(keras_tuner.HyperParameters()),
    )
    assert head.loss.name == "binary_crossentropy"


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag198')" href="javascript:;">
autokeras-1.0.16/tests/unit_tests/blocks/heads_test.py: 133-146
</a>
<div class="mid" id="frag198" style="display:none"><pre>
def test_segmentation():
    dataset = np.array(["a", "a", "c", "b"])
    head = head_module.SegmentationHead(name="a", shape=(1,))
    adapter = head.get_adapter()
    dataset = adapter.adapt(dataset, batch_size=32)
    analyser = head.get_analyser()
    for data in dataset:
        analyser.update(data)
    analyser.finalize()
    head.config_from_analyser(analyser)
    head.build(
        keras_tuner.HyperParameters(),
        ak.Input(shape=(32,)).build_node(keras_tuner.HyperParameters()),
    )
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag191')" href="javascript:;">
autokeras-1.0.16/tests/unit_tests/blocks/heads_test.py: 45-61
</a>
<div class="mid" id="frag191" style="display:none"><pre>
def test_three_classes_infer_categorical_crossentropy():
    dataset = np.array(["a", "a", "c", "b"])
    head = head_module.ClassificationHead(name="a", shape=(1,))
    adapter = head.get_adapter()
    dataset = adapter.adapt(dataset, batch_size=32)
    analyser = head.get_analyser()
    for data in dataset:
        analyser.update(data)
    analyser.finalize()
    head.config_from_analyser(analyser)
    head.build(
        keras_tuner.HyperParameters(),
        input_module.Input(shape=(32,)).build_node(keras_tuner.HyperParameters()),
    )
    assert head.loss.name == "categorical_crossentropy"


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 7:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag287')" href="javascript:;">
autokeras-1.0.16/tests/unit_tests/graph_test.py: 24-38
</a>
<div class="mid" id="frag287" style="display:none"><pre>
def test_input_output_disconnect():
    input_node1 = ak.Input()
    output_node = input_node1
    _ = ak.DenseBlock()(output_node)

    input_node = ak.Input()
    output_node = input_node
    output_node = ak.DenseBlock()(output_node)
    output_node = ak.RegressionHead()(output_node)

    with pytest.raises(ValueError) as info:
        graph_module.Graph(inputs=input_node1, outputs=output_node)
    assert "Inputs and outputs not connected." in str(info.value)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag289')" href="javascript:;">
autokeras-1.0.16/tests/unit_tests/graph_test.py: 54-66
</a>
<div class="mid" id="frag289" style="display:none"><pre>
def test_input_missing():
    input_node1 = ak.Input()
    input_node2 = ak.Input()
    output_node1 = ak.DenseBlock()(input_node1)
    output_node2 = ak.DenseBlock()(input_node2)
    output_node = ak.Merge()([output_node1, output_node2])
    output_node = ak.RegressionHead()(output_node)

    with pytest.raises(ValueError) as info:
        graph_module.Graph(inputs=input_node1, outputs=output_node)
    assert "A required input is missing for HyperModel" in str(info.value)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 8:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 91%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag302')" href="javascript:;">
autokeras-1.0.16/tests/integration_tests/task_api_test.py: 79-93
</a>
<div class="mid" id="frag302" style="display:none"><pre>
def test_structured_data_regressor(tmp_path):
    num_data = 500
    num_train = 400
    data = pd.read_csv(utils.TRAIN_CSV_PATH).to_numpy().astype(np.unicode)[:num_data]
    x_train, x_test = data[:num_train], data[num_train:]
    y = utils.generate_data(num_instances=num_data, shape=tuple())
    y_train, y_test = y[:num_train], y[num_train:]
    clf = ak.StructuredDataRegressor(
        directory=tmp_path, max_trials=2, seed=utils.SEED
    )
    clf.fit(x_train, y_train, epochs=11, validation_data=(x_train, y_train))
    clf.export_model()
    assert clf.predict(x_test).shape == (len(y_test), 1)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag303')" href="javascript:;">
autokeras-1.0.16/tests/integration_tests/task_api_test.py: 94-108
</a>
<div class="mid" id="frag303" style="display:none"><pre>
def test_structured_data_classifier(tmp_path):
    num_data = 500
    num_train = 400
    data = pd.read_csv(utils.TRAIN_CSV_PATH).to_numpy().astype(np.unicode)[:num_data]
    x_train, x_test = data[:num_train], data[num_train:]
    y = utils.generate_one_hot_labels(num_instances=num_data, num_classes=3)
    y_train, y_test = y[:num_train], y[num_train:]
    clf = ak.StructuredDataClassifier(
        directory=tmp_path, max_trials=1, seed=utils.SEED
    )
    clf.fit(x_train, y_train, epochs=2, validation_data=(x_train, y_train))
    clf.export_model()
    assert clf.predict(x_test).shape == (len(y_test), 3)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 9:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 72%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag386')" href="javascript:;">
autokeras-1.0.16/autokeras/nodes.py: 165-175
</a>
<div class="mid" id="frag386" style="display:none"><pre>
    def __init__(
        self,
        column_names: Optional[List[str]] = None,
        column_types: Optional[Dict[str, str]] = None,
        name: Optional[str] = None,
        **kwargs
    ):
        super().__init__(name=name, **kwargs)
        self.column_names = column_names
        self.column_types = column_types

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag393')" href="javascript:;">
autokeras-1.0.16/autokeras/nodes.py: 224-236
</a>
<div class="mid" id="frag393" style="display:none"><pre>
    def __init__(
        self,
        lookback: Optional[int] = None,
        column_names: Optional[List[str]] = None,
        column_types: Optional[Dict[str, str]] = None,
        name: Optional[str] = None,
        **kwargs
    ):
        super().__init__(
            column_names=column_names, column_types=column_types, name=name, **kwargs
        )
        self.lookback = lookback

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 10:</b> &nbsp; 5 fragments, nominal size 24 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag423')" href="javascript:;">
autokeras-1.0.16/autokeras/tasks/structured_data.py: 77-149
</a>
<div class="mid" id="frag423" style="display:none"><pre>
    def fit(
        self,
        x=None,
        y=None,
        epochs=None,
        callbacks=None,
        validation_split=0.2,
        validation_data=None,
        **kwargs
    ):
        """Search for the best model and hyperparameters for the AutoModel.

        # Arguments
            x: String, numpy.ndarray, pandas.DataFrame or tensorflow.Dataset.
                Training data x. If the data is from a csv file, it should be a
                string specifying the path of the csv file of the training data.
            y: String, numpy.ndarray, or tensorflow.Dataset. Training data y.
                If the data is from a csv file, it should be a string, which is the
                name of the target column. Otherwise, it can be single-column or
                multi-column. The values should all be numerical.
            epochs: Int. The number of epochs to train each model during the search.
                If unspecified, we would use epochs equal to 1000 and early stopping
                with patience equal to 30.
            callbacks: List of Keras callbacks to apply during training and
                validation.
            validation_split: Float between 0 and 1. Defaults to 0.2.
                Fraction of the training data to be used as validation data.
                The model will set apart this fraction of the training data,
                will not train on it, and will evaluate
                the loss and any model metrics
                on this data at the end of each epoch.
                The validation data is selected from the last samples
                in the `x` and `y` data provided, before shuffling. This argument is
                not supported when `x` is a dataset.
                The best model found would be fit on the entire dataset including the
                validation data.
            validation_data: Data on which to evaluate the loss and any model metrics
                at the end of each epoch. The model will not be trained on this data.
                `validation_data` will override `validation_split`. The type of the
                validation data should be the same as the training data.
                The best model found would be fit on the training dataset without the
                validation data.
            **kwargs: Any arguments supported by
                [keras.Model.fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit).
        # Returns
            history: A Keras History object corresponding to the best model.
                Its History.history attribute is a record of training
                loss values and metrics values at successive epochs, as well as
                validation loss values and validation metrics values (if applicable).
        """
        # x is file path of training data
        if isinstance(x, str):
            self._target_col_name = y
            x, y = self._read_from_csv(x, y)

        if validation_data and not isinstance(validation_data, tf.data.Dataset):
            x_val, y_val = validation_data
            if isinstance(x_val, str):
                validation_data = self._read_from_csv(x_val, y_val)

        self.check_in_fit(x)

        history = super().fit(
            x=x,
            y=y,
            epochs=epochs,
            callbacks=callbacks,
            validation_split=validation_split,
            validation_data=validation_data,
            **kwargs
        )
        return history

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag434')" href="javascript:;">
autokeras-1.0.16/autokeras/tasks/text.py: 235-301
</a>
<div class="mid" id="frag434" style="display:none"><pre>
    def fit(
        self,
        x=None,
        y=None,
        epochs=None,
        callbacks=None,
        validation_split=0.2,
        validation_data=None,
        **kwargs
    ):
        """Search for the best model and hyperparameters for the AutoModel.

        It will search for the best model based on the performances on
        validation data.

        # Arguments
            x: numpy.ndarray or tensorflow.Dataset. Training data x. The input data
                should be numpy.ndarray or tf.data.Dataset. The data should be one
                dimensional. Each element in the data should be a string which is a
                full sentence.
            y: numpy.ndarray or tensorflow.Dataset. Training data y. The targets
                passing to the head would have to be tf.data.Dataset, np.ndarray,
                pd.DataFrame or pd.Series. It can be single-column or multi-column.
                The values should all be numerical.
            epochs: Int. The number of epochs to train each model during the search.
                If unspecified, by default we train for a maximum of 1000 epochs,
                but we stop training if the validation loss stops improving for 10
                epochs (unless you specified an EarlyStopping callback as part of
                the callbacks argument, in which case the EarlyStopping callback you
                specified will determine early stopping).
            callbacks: List of Keras callbacks to apply during training and
                validation.
            validation_split: Float between 0 and 1. Defaults to 0.2.
                Fraction of the training data to be used as validation data.
                The model will set apart this fraction of the training data,
                will not train on it, and will evaluate
                the loss and any model metrics
                on this data at the end of each epoch.
                The validation data is selected from the last samples
                in the `x` and `y` data provided, before shuffling. This argument is
                not supported when `x` is a dataset.
                The best model found would be fit on the entire dataset including the
                validation data.
            validation_data: Data on which to evaluate the loss and any model metrics
                at the end of each epoch. The model will not be trained on this data.
                `validation_data` will override `validation_split`. The type of the
                validation data should be the same as the training data.
                The best model found would be fit on the training dataset without the
                validation data.
            **kwargs: Any arguments supported by
                [keras.Model.fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit).
        # Returns
            history: A Keras History object corresponding to the best model.
                Its History.history attribute is a record of training
                loss values and metrics values at successive epochs, as well as
                validation loss values and validation metrics values (if applicable).
        """
        history = super().fit(
            x=x,
            y=y,
            epochs=epochs,
            callbacks=callbacks,
            validation_split=validation_split,
            validation_data=validation_data,
            **kwargs
        )
        return history
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag447')" href="javascript:;">
autokeras-1.0.16/autokeras/tasks/time_series_forecaster.py: 58-98
</a>
<div class="mid" id="frag447" style="display:none"><pre>
    def fit(
        self,
        x=None,
        y=None,
        epochs=None,
        callbacks=None,
        validation_split=0.2,
        validation_data=None,
        **kwargs
    ):
        # x is file path of training data
        if isinstance(x, str):
            self._target_col_name = y
            x, y = self._read_from_csv(x, y)

        if validation_data:
            x_val, y_val = validation_data
            if isinstance(x_val, str):
                validation_data = self._read_from_csv(x_val, y_val)

        self.check_in_fit(x)
        self.train_len = len(y)

        if validation_data:
            x_val, y_val = validation_data
            train_len = len(y_val)
            x_val = x_val[:train_len]
            y_val = y_val[self.lookback - 1 :]
            validation_data = x_val, y_val

        history = super().fit(
            x=x[: self.train_len],
            y=y[self.lookback - 1 :],
            epochs=epochs,
            callbacks=callbacks,
            validation_split=validation_split,
            validation_data=validation_data,
            **kwargs
        )
        return history

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag432')" href="javascript:;">
autokeras-1.0.16/autokeras/tasks/text.py: 103-171
</a>
<div class="mid" id="frag432" style="display:none"><pre>
    def fit(
        self,
        x=None,
        y=None,
        epochs=None,
        callbacks=None,
        validation_split=0.2,
        validation_data=None,
        **kwargs
    ):
        """Search for the best model and hyperparameters for the AutoModel.

        It will search for the best model based on the performances on
        validation data.

        # Arguments
            x: numpy.ndarray or tensorflow.Dataset. Training data x. The input data
                should be numpy.ndarray or tf.data.Dataset. The data should be one
                dimensional. Each element in the data should be a string which is a
                full sentence.
            y: numpy.ndarray or tensorflow.Dataset. Training data y. It can be raw
                labels, one-hot encoded if more than two classes, or binary encoded
                for binary classification.
            epochs: Int. The number of epochs to train each model during the search.
                If unspecified, by default we train for a maximum of 1000 epochs,
                but we stop training if the validation loss stops improving for 10
                epochs (unless you specified an EarlyStopping callback as part of
                the callbacks argument, in which case the EarlyStopping callback you
                specified will determine early stopping).
            callbacks: List of Keras callbacks to apply during training and
                validation.
            validation_split: Float between 0 and 1. Defaults to 0.2.
                Fraction of the training data to be used as validation data.
                The model will set apart this fraction of the training data,
                will not train on it, and will evaluate
                the loss and any model metrics
                on this data at the end of each epoch.
                The validation data is selected from the last samples
                in the `x` and `y` data provided, before shuffling. This argument is
                not supported when `x` is a dataset.
                The best model found would be fit on the entire dataset including the
                validation data.
            validation_data: Data on which to evaluate the loss and any model metrics
                at the end of each epoch. The model will not be trained on this data.
                `validation_data` will override `validation_split`. The type of the
                validation data should be the same as the training data.
                The best model found would be fit on the training dataset without the
                validation data.
            **kwargs: Any arguments supported by
                [keras.Model.fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit).

        # Returns
            history: A Keras History object corresponding to the best model.
                Its History.history attribute is a record of training
                loss values and metrics values at successive epochs, as well as
                validation loss values and validation metrics values (if applicable).
        """
        history = super().fit(
            x=x,
            y=y,
            epochs=epochs,
            callbacks=callbacks,
            validation_split=validation_split,
            validation_data=validation_data,
            **kwargs
        )
        return history


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag428')" href="javascript:;">
autokeras-1.0.16/autokeras/tasks/structured_data.py: 279-337
</a>
<div class="mid" id="frag428" style="display:none"><pre>
    def fit(
        self,
        x=None,
        y=None,
        epochs=None,
        callbacks=None,
        validation_split=0.2,
        validation_data=None,
        **kwargs
    ):
        """Search for the best model and hyperparameters for the AutoModel.

        # Arguments
            x: String, numpy.ndarray, pandas.DataFrame or tensorflow.Dataset.
                Training data x. If the data is from a csv file, it should be a
                string specifying the path of the csv file of the training data.
            y: String, numpy.ndarray, or tensorflow.Dataset. Training data y.
                If the data is from a csv file, it should be a string, which is the
                name of the target column. Otherwise, It can be raw labels, one-hot
                encoded if more than two classes, or binary encoded for binary
                classification.
            epochs: Int. The number of epochs to train each model during the search.
                If unspecified, we would use epochs equal to 1000 and early stopping
                with patience equal to 30.
            callbacks: List of Keras callbacks to apply during training and
                validation.
            validation_split: Float between 0 and 1. Defaults to 0.2.
                Fraction of the training data to be used as validation data.
                The model will set apart this fraction of the training data,
                will not train on it, and will evaluate
                the loss and any model metrics
                on this data at the end of each epoch.
                The validation data is selected from the last samples
                in the `x` and `y` data provided, before shuffling. This argument is
                not supported when `x` is a dataset.
            validation_data: Data on which to evaluate the loss and any model metrics
                at the end of each epoch. The model will not be trained on this data.
                `validation_data` will override `validation_split`. The type of the
                validation data should be the same as the training data.
            **kwargs: Any arguments supported by
                [keras.Model.fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit).
        # Returns
            history: A Keras History object corresponding to the best model.
                Its History.history attribute is a record of training
                loss values and metrics values at successive epochs, as well as
                validation loss values and validation metrics values (if applicable).
        """
        history = super().fit(
            x=x,
            y=y,
            epochs=epochs,
            callbacks=callbacks,
            validation_split=validation_split,
            validation_data=validation_data,
            **kwargs
        )
        return history


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 11:</b> &nbsp; 8 fragments, nominal size 35 lines, similarity 76%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag427')" href="javascript:;">
autokeras-1.0.16/autokeras/tasks/structured_data.py: 239-278
</a>
<div class="mid" id="frag427" style="display:none"><pre>
    def __init__(
        self,
        column_names: Optional[List[str]] = None,
        column_types: Optional[Dict] = None,
        num_classes: Optional[int] = None,
        multi_label: bool = False,
        loss: Optional[types.LossType] = None,
        metrics: Optional[types.MetricsType] = None,
        project_name: str = "structured_data_classifier",
        max_trials: int = 100,
        directory: Optional[Union[str, pathlib.Path]] = None,
        objective: str = "val_accuracy",
        tuner: Union[str, Type[tuner.AutoTuner]] = None,
        overwrite: bool = False,
        seed: Optional[int] = None,
        max_model_size: Optional[int] = None,
        **kwargs
    ):
        if tuner is None:
            tuner = task_specific.StructuredDataClassifierTuner
        super().__init__(
            outputs=blocks.ClassificationHead(
                num_classes=num_classes,
                multi_label=multi_label,
                loss=loss,
                metrics=metrics,
            ),
            column_names=column_names,
            column_types=column_types,
            max_trials=max_trials,
            directory=directory,
            project_name=project_name,
            objective=objective,
            tuner=tuner,
            overwrite=overwrite,
            seed=seed,
            max_model_size=max_model_size,
            **kwargs
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag450')" href="javascript:;">
autokeras-1.0.16/autokeras/tasks/time_series_forecaster.py: 187-231
</a>
<div class="mid" id="frag450" style="display:none"><pre>
    def __init__(
        self,
        output_dim: Optional[int] = None,
        column_names: Optional[List[str]] = None,
        column_types: Optional[Dict[str, str]] = None,
        lookback: Optional[int] = None,
        predict_from: int = 1,
        predict_until: Optional[int] = None,
        loss: types.LossType = "mean_squared_error",
        metrics: Optional[types.MetricsType] = None,
        project_name: str = "time_series_forecaster",
        max_trials: int = 100,
        directory: Union[str, Path, None] = None,
        objective: str = "val_loss",
        tuner: Union[str, Type[tuner.AutoTuner]] = None,
        overwrite: bool = False,
        seed: Optional[int] = None,
        max_model_size: Optional[int] = None,
        **kwargs
    ):
        if tuner is None:
            tuner = greedy.Greedy
        super().__init__(
            outputs=blocks.RegressionHead(
                output_dim=output_dim, loss=loss, metrics=metrics
            ),
            column_names=column_names,
            column_types=column_types,
            lookback=lookback,
            predict_from=predict_from,
            predict_until=predict_until,
            project_name=project_name,
            max_trials=max_trials,
            directory=directory,
            objective=objective,
            tuner=tuner,
            overwrite=overwrite,
            seed=seed,
            max_model_size=max_model_size,
            **kwargs
        )
        self.lookback = lookback
        self.predict_from = predict_from
        self.predict_until = predict_until

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag431')" href="javascript:;">
autokeras-1.0.16/autokeras/tasks/text.py: 67-102
</a>
<div class="mid" id="frag431" style="display:none"><pre>
    def __init__(
        self,
        num_classes: Optional[int] = None,
        multi_label: bool = False,
        loss: types.LossType = None,
        metrics: Optional[types.MetricsType] = None,
        project_name: str = "text_classifier",
        max_trials: int = 100,
        directory: Union[str, Path, None] = None,
        objective: str = "val_loss",
        tuner: Union[str, Type[tuner.AutoTuner]] = None,
        overwrite: bool = False,
        seed: Optional[int] = None,
        max_model_size: Optional[int] = None,
        **kwargs
    ):
        if tuner is None:
            tuner = task_specific.TextClassifierTuner
        super().__init__(
            outputs=blocks.ClassificationHead(
                num_classes=num_classes,
                multi_label=multi_label,
                loss=loss,
                metrics=metrics,
            ),
            max_trials=max_trials,
            directory=directory,
            project_name=project_name,
            objective=objective,
            tuner=tuner,
            overwrite=overwrite,
            seed=seed,
            max_model_size=max_model_size,
            **kwargs
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag429')" href="javascript:;">
autokeras-1.0.16/autokeras/tasks/structured_data.py: 377-411
</a>
<div class="mid" id="frag429" style="display:none"><pre>
    def __init__(
        self,
        column_names: Optional[List[str]] = None,
        column_types: Optional[Dict[str, str]] = None,
        output_dim: Optional[int] = None,
        loss: types.LossType = "mean_squared_error",
        metrics: Optional[types.MetricsType] = None,
        project_name: str = "structured_data_regressor",
        max_trials: int = 100,
        directory: Union[str, pathlib.Path, None] = None,
        objective: str = "val_loss",
        tuner: Union[str, Type[tuner.AutoTuner]] = None,
        overwrite: bool = False,
        seed: Optional[int] = None,
        max_model_size: Optional[int] = None,
        **kwargs
    ):
        if tuner is None:
            tuner = task_specific.StructuredDataRegressorTuner
        super().__init__(
            outputs=blocks.RegressionHead(
                output_dim=output_dim, loss=loss, metrics=metrics
            ),
            column_names=column_names,
            column_types=column_types,
            max_trials=max_trials,
            directory=directory,
            project_name=project_name,
            objective=objective,
            tuner=tuner,
            overwrite=overwrite,
            seed=seed,
            max_model_size=max_model_size,
            **kwargs
        )
</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag436')" href="javascript:;">
autokeras-1.0.16/autokeras/tasks/image.py: 71-106
</a>
<div class="mid" id="frag436" style="display:none"><pre>
    def __init__(
        self,
        num_classes: Optional[int] = None,
        multi_label: bool = False,
        loss: types.LossType = None,
        metrics: Optional[types.MetricsType] = None,
        project_name: str = "image_classifier",
        max_trials: int = 100,
        directory: Union[str, Path, None] = None,
        objective: str = "val_loss",
        tuner: Union[str, Type[tuner.AutoTuner]] = None,
        overwrite: bool = False,
        seed: Optional[int] = None,
        max_model_size: Optional[int] = None,
        **kwargs
    ):
        if tuner is None:
            tuner = task_specific.ImageClassifierTuner
        super().__init__(
            outputs=blocks.ClassificationHead(
                num_classes=num_classes,
                multi_label=multi_label,
                loss=loss,
                metrics=metrics,
            ),
            max_trials=max_trials,
            directory=directory,
            project_name=project_name,
            objective=objective,
            tuner=tuner,
            overwrite=overwrite,
            seed=seed,
            max_model_size=max_model_size,
            **kwargs
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag440')" href="javascript:;">
autokeras-1.0.16/autokeras/tasks/image.py: 339-368
</a>
<div class="mid" id="frag440" style="display:none"><pre>
    def __init__(
        self,
        num_classes: Optional[int] = None,
        loss: types.LossType = None,
        metrics: Optional[types.MetricsType] = None,
        project_name: str = "image_segmenter",
        max_trials: int = 100,
        directory: Union[str, Path, None] = None,
        objective: str = "val_loss",
        tuner: Union[str, Type[tuner.AutoTuner]] = None,
        overwrite: bool = False,
        seed: Optional[int] = None,
        **kwargs
    ):
        if tuner is None:
            tuner = greedy.Greedy
        super().__init__(
            outputs=blocks.SegmentationHead(
                num_classes=num_classes, loss=loss, metrics=metrics
            ),
            max_trials=max_trials,
            directory=directory,
            project_name=project_name,
            objective=objective,
            tuner=tuner,
            overwrite=overwrite,
            seed=seed,
            **kwargs
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag433')" href="javascript:;">
autokeras-1.0.16/autokeras/tasks/text.py: 203-234
</a>
<div class="mid" id="frag433" style="display:none"><pre>
    def __init__(
        self,
        output_dim: Optional[int] = None,
        loss: types.LossType = "mean_squared_error",
        metrics: Optional[types.MetricsType] = None,
        project_name: str = "text_regressor",
        max_trials: int = 100,
        directory: Union[str, Path, None] = None,
        objective: str = "val_loss",
        tuner: Union[str, Type[tuner.AutoTuner]] = None,
        overwrite: bool = False,
        seed: Optional[int] = None,
        max_model_size: Optional[int] = None,
        **kwargs
    ):
        if tuner is None:
            tuner = greedy.Greedy
        super().__init__(
            outputs=blocks.RegressionHead(
                output_dim=output_dim, loss=loss, metrics=metrics
            ),
            max_trials=max_trials,
            directory=directory,
            project_name=project_name,
            objective=objective,
            tuner=tuner,
            overwrite=overwrite,
            seed=seed,
            max_model_size=max_model_size,
            **kwargs
        )

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag438')" href="javascript:;">
autokeras-1.0.16/autokeras/tasks/image.py: 207-238
</a>
<div class="mid" id="frag438" style="display:none"><pre>
    def __init__(
        self,
        output_dim: Optional[int] = None,
        loss: types.LossType = "mean_squared_error",
        metrics: Optional[types.MetricsType] = None,
        project_name: str = "image_regressor",
        max_trials: int = 100,
        directory: Union[str, Path, None] = None,
        objective: str = "val_loss",
        tuner: Union[str, Type[tuner.AutoTuner]] = None,
        overwrite: bool = False,
        seed: Optional[int] = None,
        max_model_size: Optional[int] = None,
        **kwargs
    ):
        if tuner is None:
            tuner = greedy.Greedy
        super().__init__(
            outputs=blocks.RegressionHead(
                output_dim=output_dim, loss=loss, metrics=metrics
            ),
            max_trials=max_trials,
            directory=directory,
            project_name=project_name,
            objective=objective,
            tuner=tuner,
            overwrite=overwrite,
            seed=seed,
            max_model_size=max_model_size,
            **kwargs
        )

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 12:</b> &nbsp; 3 fragments, nominal size 21 lines, similarity 95%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag437')" href="javascript:;">
autokeras-1.0.16/autokeras/tasks/image.py: 107-175
</a>
<div class="mid" id="frag437" style="display:none"><pre>
    def fit(
        self,
        x: Optional[types.DatasetType] = None,
        y: Optional[types.DatasetType] = None,
        epochs: Optional[int] = None,
        callbacks: Optional[List[tf.keras.callbacks.Callback]] = None,
        validation_split: Optional[float] = 0.2,
        validation_data: Union[
            tf.data.Dataset, Tuple[types.DatasetType, types.DatasetType], None
        ] = None,
        **kwargs
    ):
        """Search for the best model and hyperparameters for the AutoModel.

        It will search for the best model based on the performances on
        validation data.

        # Arguments
            x: numpy.ndarray or tensorflow.Dataset. Training data x. The shape of
                the data should be (samples, width, height)
                or (samples, width, height, channels).
            y: numpy.ndarray or tensorflow.Dataset. Training data y. It can be raw
                labels, one-hot encoded if more than two classes, or binary encoded
                for binary classification.
            epochs: Int. The number of epochs to train each model during the search.
                If unspecified, by default we train for a maximum of 1000 epochs,
                but we stop training if the validation loss stops improving for 10
                epochs (unless you specified an EarlyStopping callback as part of
                the callbacks argument, in which case the EarlyStopping callback you
                specified will determine early stopping).
            callbacks: List of Keras callbacks to apply during training and
                validation.
            validation_split: Float between 0 and 1. Defaults to 0.2.
                Fraction of the training data to be used as validation data.
                The model will set apart this fraction of the training data,
                will not train on it, and will evaluate
                the loss and any model metrics
                on this data at the end of each epoch.
                The validation data is selected from the last samples
                in the `x` and `y` data provided, before shuffling. This argument is
                not supported when `x` is a dataset.
                The best model found would be fit on the entire dataset including the
                validation data.
            validation_data: Data on which to evaluate the loss and any model metrics
                at the end of each epoch. The model will not be trained on this data.
                `validation_data` will override `validation_split`. The type of the
                validation data should be the same as the training data.
                The best model found would be fit on the training dataset without the
                validation data.
            **kwargs: Any arguments supported by
                [keras.Model.fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit).
        # Returns
            history: A Keras History object corresponding to the best model.
                Its History.history attribute is a record of training
                loss values and metrics values at successive epochs, as well as
                validation loss values and validation metrics values (if applicable).
        """
        history = super().fit(
            x=x,
            y=y,
            epochs=epochs,
            callbacks=callbacks,
            validation_split=validation_split,
            validation_data=validation_data,
            **kwargs
        )
        return history


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag441')" href="javascript:;">
autokeras-1.0.16/autokeras/tasks/image.py: 369-438
</a>
<div class="mid" id="frag441" style="display:none"><pre>
    def fit(
        self,
        x: Optional[types.DatasetType] = None,
        y: Optional[types.DatasetType] = None,
        epochs: Optional[int] = None,
        callbacks: Optional[List[tf.keras.callbacks.Callback]] = None,
        validation_split: Optional[float] = 0.2,
        validation_data: Union[
            types.DatasetType, Tuple[types.DatasetType], None
        ] = None,
        **kwargs
    ):
        """Search for the best model and hyperparameters for the AutoModel.

        It will search for the best model based on the performances on
        validation data.

        # Arguments
            x: numpy.ndarray or tensorflow.Dataset. Training image dataset x.
                The shape of the data should be (samples, width, height) or
                (samples, width, height, channels).
            y: numpy.ndarray or tensorflow.Dataset. Training image data set y.
                It should be a tensor and the height and width should be the same
                as x. Each element in the tensor is the label of the corresponding
                pixel.
            epochs: Int. The number of epochs to train each model during the search.
                If unspecified, by default we train for a maximum of 1000 epochs,
                but we stop training if the validation loss stops improving for 10
                epochs (unless you specified an EarlyStopping callback as part of
                the callbacks argument, in which case the EarlyStopping callback you
                specified will determine early stopping).
            callbacks: List of Keras callbacks to apply during training and
                validation.
            validation_split: Float between 0 and 1. Defaults to 0.2.
                Fraction of the training data to be used as validation data.
                The model will set apart this fraction of the training data,
                will not train on it, and will evaluate
                the loss and any model metrics
                on this data at the end of each epoch.
                The validation data is selected from the last samples
                in the `x` and `y` data provided, before shuffling. This argument is
                not supported when `x` is a dataset.
                The best model found would be fit on the entire dataset including the
                validation data.
            validation_data: Data on which to evaluate the loss and any model metrics
                at the end of each epoch. The model will not be trained on this data.
                `validation_data` will override `validation_split`. The type of the
                validation data should be the same as the training data.
                The best model found would be fit on the training dataset without the
                validation data.
            **kwargs: Any arguments supported by
                [keras.Model.fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit).
        # Returns
            history: A Keras History object corresponding to the best model.
                Its History.history attribute is a record of training
                loss values and metrics values at successive epochs, as well as
                validation loss values and validation metrics values (if applicable).
        """
        history = super().fit(
            x=x,
            y=y,
            epochs=epochs,
            callbacks=callbacks,
            validation_split=validation_split,
            validation_data=validation_data,
            **kwargs
        )
        return history


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag439')" href="javascript:;">
autokeras-1.0.16/autokeras/tasks/image.py: 239-308
</a>
<div class="mid" id="frag439" style="display:none"><pre>
    def fit(
        self,
        x: Optional[types.DatasetType] = None,
        y: Optional[types.DatasetType] = None,
        epochs: Optional[int] = None,
        callbacks: Optional[List[tf.keras.callbacks.Callback]] = None,
        validation_split: Optional[float] = 0.2,
        validation_data: Union[
            types.DatasetType, Tuple[types.DatasetType], None
        ] = None,
        **kwargs
    ):
        """Search for the best model and hyperparameters for the AutoModel.

        It will search for the best model based on the performances on
        validation data.

        # Arguments
            x: numpy.ndarray or tensorflow.Dataset. Training data x. The shape of
                the data should be (samples, width, height) or
                (samples, width, height, channels).
            y: numpy.ndarray or tensorflow.Dataset. Training data y. The targets
                passing to the head would have to be tf.data.Dataset, np.ndarray,
                pd.DataFrame or pd.Series. It can be single-column or multi-column.
                The values should all be numerical.
            epochs: Int. The number of epochs to train each model during the search.
                If unspecified, by default we train for a maximum of 1000 epochs,
                but we stop training if the validation loss stops improving for 10
                epochs (unless you specified an EarlyStopping callback as part of
                the callbacks argument, in which case the EarlyStopping callback you
                specified will determine early stopping).
            callbacks: List of Keras callbacks to apply during training and
                validation.
            validation_split: Float between 0 and 1. Defaults to 0.2.
                Fraction of the training data to be used as validation data.
                The model will set apart this fraction of the training data,
                will not train on it, and will evaluate
                the loss and any model metrics
                on this data at the end of each epoch.
                The validation data is selected from the last samples
                in the `x` and `y` data provided, before shuffling. This argument is
                not supported when `x` is a dataset.
                The best model found would be fit on the entire dataset including the
                validation data.
            validation_data: Data on which to evaluate the loss and any model metrics
                at the end of each epoch. The model will not be trained on this data.
                `validation_data` will override `validation_split`. The type of the
                validation data should be the same as the training data.
                The best model found would be fit on the training dataset without the
                validation data.
            **kwargs: Any arguments supported by
                [keras.Model.fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit).
        # Returns
            history: A Keras History object corresponding to the best model.
                Its History.history attribute is a record of training
                loss values and metrics values at successive epochs, as well as
                validation loss values and validation metrics values (if applicable).
        """
        history = super().fit(
            x=x,
            y=y,
            epochs=epochs,
            callbacks=callbacks,
            validation_split=validation_split,
            validation_data=validation_data,
            **kwargs
        )
        return history


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 13:</b> &nbsp; 4 fragments, nominal size 12 lines, similarity 70%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag589')" href="javascript:;">
autokeras-1.0.16/autokeras/blocks/wrapper.py: 52-63
</a>
<div class="mid" id="frag589" style="display:none"><pre>
    def __init__(
        self,
        block_type: Optional[str] = None,
        normalize: Optional[bool] = None,
        augment: Optional[bool] = None,
        **kwargs
    ):
        super().__init__(**kwargs)
        self.block_type = block_type
        self.normalize = normalize
        self.augment = augment

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag593')" href="javascript:;">
autokeras-1.0.16/autokeras/blocks/wrapper.py: 130-141
</a>
<div class="mid" id="frag593" style="display:none"><pre>
    def __init__(
        self,
        block_type: Optional[str] = None,
        max_tokens: Optional[int] = None,
        pretraining: Optional[str] = None,
        **kwargs
    ):
        super().__init__(**kwargs)
        self.block_type = block_type
        self.max_tokens = max_tokens
        self.pretraining = pretraining

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag597')" href="javascript:;">
autokeras-1.0.16/autokeras/blocks/wrapper.py: 206-219
</a>
<div class="mid" id="frag597" style="display:none"><pre>
    def __init__(
        self,
        categorical_encoding: bool = True,
        normalize: Optional[bool] = None,
        seed: Optional[int] = None,
        **kwargs
    ):
        super().__init__(**kwargs)
        self.categorical_encoding = categorical_encoding
        self.normalize = normalize
        self.seed = seed
        self.column_types = None
        self.column_names = None

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag650')" href="javascript:;">
autokeras-1.0.16/autokeras/blocks/preprocessing.py: 166-183
</a>
<div class="mid" id="frag650" style="display:none"><pre>
    def __init__(
        self,
        translation_factor: Optional[Union[float, Tuple[float, float]]] = None,
        vertical_flip: Optional[bool] = None,
        horizontal_flip: Optional[bool] = None,
        rotation_factor: Optional[float] = None,
        zoom_factor: Optional[Union[float, Tuple[float, float]]] = None,
        contrast_factor: Optional[Union[float, Tuple[float, float]]] = None,
        **kwargs
    ):
        super().__init__(**kwargs)
        self.translation_factor = translation_factor
        self.horizontal_flip = horizontal_flip
        self.vertical_flip = vertical_flip
        self.rotation_factor = rotation_factor
        self.zoom_factor = zoom_factor
        self.contrast_factor = contrast_factor

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 14:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 91%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag599')" href="javascript:;">
autokeras-1.0.16/autokeras/blocks/wrapper.py: 229-241
</a>
<div class="mid" id="frag599" style="display:none"><pre>
    def get_config(self):
        config = super().get_config()
        config.update(
            {
                "categorical_encoding": self.categorical_encoding,
                "normalize": self.normalize,
                "seed": self.seed,
                "column_types": self.column_types,
                "column_names": self.column_names,
            }
        )
        return config

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag653')" href="javascript:;">
autokeras-1.0.16/autokeras/blocks/preprocessing.py: 250-264
</a>
<div class="mid" id="frag653" style="display:none"><pre>
    def get_config(self):
        config = super().get_config()
        config.update(
            {
                "translation_factor": self.translation_factor,
                "horizontal_flip": self.horizontal_flip,
                "vertical_flip": self.vertical_flip,
                "rotation_factor": self.rotation_factor,
                "zoom_factor": self.zoom_factor,
                "contrast_factor": self.contrast_factor,
            }
        )
        return config


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<script language="JavaScript">
function ShowHide(divId) { 
    if(document.getElementById(divId).style.display == 'none') {
        document.getElementById(divId).style.display='block';
    } else { 
        document.getElementById(divId).style.display = 'none';
    } 
}
</script>
</body>
</html>
