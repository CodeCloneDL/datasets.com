<clonepair1>
<source file="systems/Hub-2.2.2/hub/core/chunk/test_chunk_compressed.py" startline="52" endline="107" pcid="360"></source>
def test_read_write_sequence_big(cat_path, compression, random):
    tensor_meta = create_tensor_meta()
    common_args["tensor_meta"] = tensor_meta
    common_args["compression"] = compression
    dtype = tensor_meta.dtype
    data_in = []
    for i in range(50):
        if i % 10 == 0:
            data_in.append(
                np.random.randint(0, 255, size=(6001, 3000, 3)).astype(dtype) * random
            )
        elif i % 3 == 0:
            data_in.append(
                hub.read(cat_path) if random else np.zeros((900, 900, 3), dtype=dtype)
            )
        else:
            data_in.append(
                np.random.randint(0, 255, size=(1000, 500, 3)).astype(dtype) * random
            )
    data_in2 = data_in.copy()
    tiles = []
    original_length = len(data_in)
    tiled = False
    while data_in:
        chunk = ChunkCompressedChunk(**common_args)
        chunk._compression_ratio = 10  # start with a bad compression ratio to hit exponential back off code path
        num_samples = chunk.extend_if_has_space(data_in)
        if num_samples == PARTIAL_NUM_SAMPLES:
            tiled = True
            tiles.append(chunk.read_sample(0))
            sample = data_in[0]
            assert isinstance(sample, SampleTiles)
            if sample.is_last_write:
                current_length = len(data_in)
                index = original_length - current_length
                full_data_out = np_list_to_sample(
                    tiles,
                    sample.sample_shape,
                    sample.tile_shape,
                    sample.layout_shape,
                    dtype,
                )
                np.testing.assert_array_equal(full_data_out, data_in2[index])
                data_in = data_in[1:]
                tiles = []

        elif num_samples > 0:
            data_out = [chunk.read_sample(i) for i in range(num_samples)]
            for i, item in enumerate(data_out):
                if isinstance(item, Sample):
                    item = item.array
                np.testing.assert_array_equal(item, data_in[i])
            data_in = data_in[num_samples:]
    assert tiled


</clonepair1>

<clonepair1>
<source file="systems/Hub-2.2.2/hub/core/chunk/test_sample_compressed.py" startline="49" endline="95" pcid="364"></source>
def test_read_write_sequence_big(cat_path, compression):
    tensor_meta = create_tensor_meta()
    common_args["tensor_meta"] = tensor_meta
    common_args["compression"] = compression
    dtype = tensor_meta.dtype
    data_in = []
    for i in range(50):
        if i % 10 == 0:
            data_in.append(np.random.rand(6001, 3000, 3).astype(dtype))
        elif i % 3 == 0:
            data_in.append(hub.read(cat_path))
        else:
            data_in.append(np.random.rand(1000, 500, 3).astype(dtype))
    data_in2 = data_in.copy()
    tiles = []
    original_length = len(data_in)

    while data_in:
        chunk = SampleCompressedChunk(**common_args)
        num_samples = chunk.extend_if_has_space(data_in)
        if num_samples == PARTIAL_NUM_SAMPLES:
            tiles.append(chunk.read_sample(0))
            sample = data_in[0]
            assert isinstance(sample, SampleTiles)
            if sample.is_last_write:
                current_length = len(data_in)
                index = original_length - current_length
                full_data_out = np_list_to_sample(
                    tiles,
                    sample.sample_shape,
                    sample.tile_shape,
                    sample.layout_shape,
                    dtype,
                )
                np.testing.assert_array_equal(full_data_out, data_in2[index])
                data_in = data_in[1:]
                tiles = []

        elif num_samples > 0:
            data_out = [chunk.read_sample(i) for i in range(num_samples)]
            for i, item in enumerate(data_out):
                if isinstance(item, Sample):
                    item = item.array
                np.testing.assert_array_equal(item, data_in[i])
            data_in = data_in[num_samples:]


</clonepair1>
<clonepair2>
<source file="systems/Hub-2.2.2/hub/core/chunk/test_chunk_compressed.py" startline="52" endline="107" pcid="360"></source>
def test_read_write_sequence_big(cat_path, compression, random):
    tensor_meta = create_tensor_meta()
    common_args["tensor_meta"] = tensor_meta
    common_args["compression"] = compression
    dtype = tensor_meta.dtype
    data_in = []
    for i in range(50):
        if i % 10 == 0:
            data_in.append(
                np.random.randint(0, 255, size=(6001, 3000, 3)).astype(dtype) * random
            )
        elif i % 3 == 0:
            data_in.append(
                hub.read(cat_path) if random else np.zeros((900, 900, 3), dtype=dtype)
            )
        else:
            data_in.append(
                np.random.randint(0, 255, size=(1000, 500, 3)).astype(dtype) * random
            )
    data_in2 = data_in.copy()
    tiles = []
    original_length = len(data_in)
    tiled = False
    while data_in:
        chunk = ChunkCompressedChunk(**common_args)
        chunk._compression_ratio = 10  # start with a bad compression ratio to hit exponential back off code path
        num_samples = chunk.extend_if_has_space(data_in)
        if num_samples == PARTIAL_NUM_SAMPLES:
            tiled = True
            tiles.append(chunk.read_sample(0))
            sample = data_in[0]
            assert isinstance(sample, SampleTiles)
            if sample.is_last_write:
                current_length = len(data_in)
                index = original_length - current_length
                full_data_out = np_list_to_sample(
                    tiles,
                    sample.sample_shape,
                    sample.tile_shape,
                    sample.layout_shape,
                    dtype,
                )
                np.testing.assert_array_equal(full_data_out, data_in2[index])
                data_in = data_in[1:]
                tiles = []

        elif num_samples > 0:
            data_out = [chunk.read_sample(i) for i in range(num_samples)]
            for i, item in enumerate(data_out):
                if isinstance(item, Sample):
                    item = item.array
                np.testing.assert_array_equal(item, data_in[i])
            data_in = data_in[num_samples:]
    assert tiled


</clonepair2>

<clonepair2>
<source file="systems/Hub-2.2.2/hub/core/chunk/test_uncompressed.py" startline="43" endline="87" pcid="354"></source>
def test_read_write_sequence_big(cat_path):
    tensor_meta = create_tensor_meta()
    common_args["tensor_meta"] = tensor_meta
    dtype = tensor_meta.dtype
    data_in = []
    for i in range(50):
        if i % 10 == 0:
            data_in.append(np.random.rand(3001, 3000, 3).astype(dtype))
        elif i % 3 == 0:
            data_in.append(hub.read(cat_path))
        else:
            data_in.append(np.random.rand(500, 500, 3).astype(dtype))
    data_in2 = data_in.copy()
    tiles = []
    original_length = len(data_in)

    while data_in:
        chunk = UncompressedChunk(**common_args)
        num_samples = chunk.extend_if_has_space(data_in)
        if num_samples == PARTIAL_NUM_SAMPLES:
            tiles.append(chunk.read_sample(0))
            sample = data_in[0]
            assert isinstance(sample, SampleTiles)
            if sample.is_last_write:
                current_length = len(data_in)
                index = original_length - current_length
                full_data_out = np_list_to_sample(
                    tiles,
                    sample.sample_shape,
                    sample.tile_shape,
                    sample.layout_shape,
                    dtype,
                )
                np.testing.assert_array_equal(full_data_out, data_in2[index])
                data_in = data_in[1:]
                tiles = []
        elif num_samples > 0:
            data_out = [chunk.read_sample(i) for i in range(num_samples)]
            for i, item in enumerate(data_out):
                if isinstance(item, Sample):
                    item = item.array
                np.testing.assert_array_equal(item, data_in[i])
            data_in = data_in[num_samples:]


</clonepair2>
<clonepair3>
<source file="systems/Hub-2.2.2/hub/core/chunk/test_sample_compressed.py" startline="49" endline="95" pcid="364"></source>
def test_read_write_sequence_big(cat_path, compression):
    tensor_meta = create_tensor_meta()
    common_args["tensor_meta"] = tensor_meta
    common_args["compression"] = compression
    dtype = tensor_meta.dtype
    data_in = []
    for i in range(50):
        if i % 10 == 0:
            data_in.append(np.random.rand(6001, 3000, 3).astype(dtype))
        elif i % 3 == 0:
            data_in.append(hub.read(cat_path))
        else:
            data_in.append(np.random.rand(1000, 500, 3).astype(dtype))
    data_in2 = data_in.copy()
    tiles = []
    original_length = len(data_in)

    while data_in:
        chunk = SampleCompressedChunk(**common_args)
        num_samples = chunk.extend_if_has_space(data_in)
        if num_samples == PARTIAL_NUM_SAMPLES:
            tiles.append(chunk.read_sample(0))
            sample = data_in[0]
            assert isinstance(sample, SampleTiles)
            if sample.is_last_write:
                current_length = len(data_in)
                index = original_length - current_length
                full_data_out = np_list_to_sample(
                    tiles,
                    sample.sample_shape,
                    sample.tile_shape,
                    sample.layout_shape,
                    dtype,
                )
                np.testing.assert_array_equal(full_data_out, data_in2[index])
                data_in = data_in[1:]
                tiles = []

        elif num_samples > 0:
            data_out = [chunk.read_sample(i) for i in range(num_samples)]
            for i, item in enumerate(data_out):
                if isinstance(item, Sample):
                    item = item.array
                np.testing.assert_array_equal(item, data_in[i])
            data_in = data_in[num_samples:]


</clonepair3>

<clonepair3>
<source file="systems/Hub-2.2.2/hub/core/chunk/test_uncompressed.py" startline="43" endline="87" pcid="354"></source>
def test_read_write_sequence_big(cat_path):
    tensor_meta = create_tensor_meta()
    common_args["tensor_meta"] = tensor_meta
    dtype = tensor_meta.dtype
    data_in = []
    for i in range(50):
        if i % 10 == 0:
            data_in.append(np.random.rand(3001, 3000, 3).astype(dtype))
        elif i % 3 == 0:
            data_in.append(hub.read(cat_path))
        else:
            data_in.append(np.random.rand(500, 500, 3).astype(dtype))
    data_in2 = data_in.copy()
    tiles = []
    original_length = len(data_in)

    while data_in:
        chunk = UncompressedChunk(**common_args)
        num_samples = chunk.extend_if_has_space(data_in)
        if num_samples == PARTIAL_NUM_SAMPLES:
            tiles.append(chunk.read_sample(0))
            sample = data_in[0]
            assert isinstance(sample, SampleTiles)
            if sample.is_last_write:
                current_length = len(data_in)
                index = original_length - current_length
                full_data_out = np_list_to_sample(
                    tiles,
                    sample.sample_shape,
                    sample.tile_shape,
                    sample.layout_shape,
                    dtype,
                )
                np.testing.assert_array_equal(full_data_out, data_in2[index])
                data_in = data_in[1:]
                tiles = []
        elif num_samples > 0:
            data_out = [chunk.read_sample(i) for i in range(num_samples)]
            for i, item in enumerate(data_out):
                if isinstance(item, Sample):
                    item = item.array
                np.testing.assert_array_equal(item, data_in[i])
            data_in = data_in[num_samples:]


</clonepair3>
<clonepair4>
<source file="systems/Hub-2.2.2/hub/core/chunk/test_chunk_compressed.py" startline="109" endline="133" pcid="361"></source>
def test_update(compression):
    tensor_meta = create_tensor_meta()
    common_args["tensor_meta"] = tensor_meta
    common_args["compression"] = compression
    dtype = tensor_meta.dtype
    arr = np.random.randint(0, 255, size=(7, 300, 200, 3)).astype(dtype)
    data_in = list(arr)
    chunk = ChunkCompressedChunk(**common_args)
    chunk.extend_if_has_space(data_in)

    data_out = np.array([chunk.read_sample(i) for i in range(7)])
    np.testing.assert_array_equal(data_out, data_in)

    data_3 = np.random.randint(0, 255, size=(1400, 700, 3)).astype(dtype)
    data_5 = np.random.randint(0, 255, size=(2000, 3000, 3)).astype(dtype)

    chunk.update_sample(3, data_3)
    chunk.update_sample(5, data_5)
    for i in range(7):
        if i == 3:
            np.testing.assert_array_equal(chunk.read_sample(i), data_3)
        elif i == 5:
            np.testing.assert_array_equal(chunk.read_sample(i), data_5)
        else:
            np.testing.assert_array_equal(chunk.read_sample(i), data_in[i])
</clonepair4>

<clonepair4>
<source file="systems/Hub-2.2.2/hub/core/chunk/test_uncompressed.py" startline="123" endline="145" pcid="357"></source>
def test_update():
    tensor_meta = create_tensor_meta()
    common_args["tensor_meta"] = tensor_meta
    dtype = tensor_meta.dtype
    data_in = np.random.rand(7, 500, 500).astype(dtype)
    chunk = UncompressedChunk(**common_args)
    chunk.extend_if_has_space(data_in)

    data_out = np.array([chunk.read_sample(i) for i in range(7)])
    np.testing.assert_array_equal(data_out, data_in)

    data_3 = np.random.rand(700, 700).astype(dtype)
    data_5 = np.random.rand(3000, 3000).astype(dtype)

    chunk.update_sample(3, data_3)
    chunk.update_sample(5, data_5)
    for i in range(7):
        if i == 3:
            np.testing.assert_array_equal(chunk.read_sample(i), data_3)
        elif i == 5:
            np.testing.assert_array_equal(chunk.read_sample(i), data_5)
        else:
            np.testing.assert_array_equal(chunk.read_sample(i), data_in[i])
</clonepair4>
<clonepair5>
<source file="systems/Hub-2.2.2/hub/core/chunk/test_chunk_compressed.py" startline="31" endline="49" pcid="359"></source>
def test_read_write_sequence(compression):
    tensor_meta = create_tensor_meta()
    common_args["tensor_meta"] = tensor_meta
    common_args["compression"] = compression
    dtype = tensor_meta.dtype
    data_in = [
        np.random.randint(0, 255, size=(1000, 500)).astype(dtype) for _ in range(10)
    ]
    data_in2 = data_in.copy()
    while data_in:
        chunk = ChunkCompressedChunk(**common_args)
        num_samples = int(chunk.extend_if_has_space(data_in))
        chunk._decompressed_samples = None
        data_out = [chunk.read_sample(i) for i in range(num_samples)]
        np.testing.assert_array_equal(data_out, data_in2[:num_samples])
        data_in = data_in[num_samples:]
        data_in2 = data_in2[num_samples:]


</clonepair5>

<clonepair5>
<source file="systems/Hub-2.2.2/hub/core/chunk/test_sample_compressed.py" startline="32" endline="47" pcid="363"></source>
def test_read_write_sequence(compression):
    tensor_meta = create_tensor_meta()
    common_args["tensor_meta"] = tensor_meta
    common_args["compression"] = compression
    dtype = tensor_meta.dtype
    data_in = [np.random.rand(1000, 500, 3).astype(dtype) for _ in range(10)]
    data_in2 = data_in.copy()
    while data_in:
        chunk = SampleCompressedChunk(**common_args)
        num_samples = int(chunk.extend_if_has_space(data_in))
        data_out = [chunk.read_sample(i) for i in range(num_samples)]
        np.testing.assert_array_equal(data_out, data_in2[:num_samples])
        data_in = data_in[num_samples:]
        data_in2 = data_in2[num_samples:]


</clonepair5>
