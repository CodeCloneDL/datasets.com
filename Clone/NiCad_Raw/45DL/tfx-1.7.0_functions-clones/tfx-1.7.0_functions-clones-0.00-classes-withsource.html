<html>
<head>
    <title>NiCad6 Clone Report</title>
    <style type="text/css">
        body {font-family:sans-serif;}
        table {background-color:white; border:0px; padding:0px; border-spacing:4px; width:auto; margin-left:30px; margin-right:auto;}
        td {background-color:rgba(192,212,238,0.8); border:0px; padding:8px; width:auto; vertical-align:top; border-radius:8px}
        pre {background-color:white; padding:4px;}
        a {color:darkblue;}
    </style>
</head>
<body>
<h2>NiCad6 Clone Report</h2>
<table>
<tr style="font-size:14pt">
<td><b>System:</b> &nbsp; tfx-1.7.0</td>
<td><b>Clone pairs:</b> &nbsp; 29</td>
<td><b>Clone classes:</b> &nbsp; 18</td>
</tr>
<tr style="font-size:12pt">
<td style="background-color:white">Clone type: &nbsp; 1</td>
<td style="background-color:white">Granularity: &nbsp; functions</td>
<td style="background-color:white">Max diff threshold: &nbsp; 0%</td>
<td style="background-color:white">Clone size: &nbsp; 10 - 2500 lines</td>
<td style="background-color:white">Total functions: &nbsp; 3249</td>
</tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 1:</b> &nbsp; 4 fragments, nominal size 26 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag331')" href="javascript:;">
tfx-1.7.0/tfx/components/testdata/module_file/trainer_module.py: 88-133
</a>
<div class="mid" id="frag331" style="display:none"><pre>
def _build_estimator(config, hidden_units=None, warm_start_from=None):
  """Build an estimator for predicting the tipping behavior of taxi riders.

  Args:
    config: tf.estimator.RunConfig defining the runtime environment for the
      estimator (including model_dir).
    hidden_units: [int], the layer sizes of the DNN (input layer first)
    warm_start_from: Optional directory to warm start from.

  Returns:
    A dict of the following:
      - estimator: The estimator that will be used for training and eval.
      - train_spec: Spec for training.
      - eval_spec: Spec for eval.
      - eval_input_receiver_fn: Input function for eval.
  """
  real_valued_columns = [
      tf.feature_column.numeric_column(key, shape=())
      for key in _transformed_names(_DENSE_FLOAT_FEATURE_KEYS)
  ]
  categorical_columns = [
      tf.feature_column.categorical_column_with_identity(
          key, num_buckets=_VOCAB_SIZE + _OOV_SIZE, default_value=0)
      for key in _transformed_names(_VOCAB_FEATURE_KEYS)
  ]
  categorical_columns += [
      tf.feature_column.categorical_column_with_identity(
          key, num_buckets=_FEATURE_BUCKET_COUNT, default_value=0)
      for key in _transformed_names(_BUCKET_FEATURE_KEYS)
  ]
  categorical_columns += [
      tf.feature_column.categorical_column_with_identity(  # pylint: disable=g-complex-comprehension
          key,
          num_buckets=num_buckets,
          default_value=0) for key, num_buckets in zip(
              _transformed_names(_CATEGORICAL_FEATURE_KEYS),
              _MAX_CATEGORICAL_FEATURE_VALUES)
  ]
  return tf.estimator.DNNLinearCombinedClassifier(
      config=config,
      linear_feature_columns=categorical_columns,
      dnn_feature_columns=real_valued_columns,
      dnn_hidden_units=hidden_units or [100, 70, 50, 25],
      warm_start_from=warm_start_from)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag3095')" href="javascript:;">
tfx-1.7.0/tfx/examples/custom_components/slack/example/taxi_utils_slack.py: 143-188
</a>
<div class="mid" id="frag3095" style="display:none"><pre>
def _build_estimator(config, hidden_units=None, warm_start_from=None):
  """Build an estimator for predicting the tipping behavior of taxi riders.

  Args:
    config: tf.contrib.learn.RunConfig defining the runtime environment for the
      estimator (including model_dir).
    hidden_units: [int], the layer sizes of the DNN (input layer first)
    warm_start_from: Optional directory to warm start from.

  Returns:
    A dict of the following:
      - estimator: The estimator that will be used for training and eval.
      - train_spec: Spec for training.
      - eval_spec: Spec for eval.
      - eval_input_receiver_fn: Input function for eval.
  """
  real_valued_columns = [
      tf.feature_column.numeric_column(key, shape=())
      for key in _transformed_names(_DENSE_FLOAT_FEATURE_KEYS)
  ]
  categorical_columns = [
      tf.feature_column.categorical_column_with_identity(
          key, num_buckets=_VOCAB_SIZE + _OOV_SIZE, default_value=0)
      for key in _transformed_names(_VOCAB_FEATURE_KEYS)
  ]
  categorical_columns += [
      tf.feature_column.categorical_column_with_identity(
          key, num_buckets=_FEATURE_BUCKET_COUNT, default_value=0)
      for key in _transformed_names(_BUCKET_FEATURE_KEYS)
  ]
  categorical_columns += [
      tf.feature_column.categorical_column_with_identity(  # pylint: disable=g-complex-comprehension
          key,
          num_buckets=num_buckets,
          default_value=0) for key, num_buckets in zip(
              _transformed_names(_CATEGORICAL_FEATURE_KEYS),
              _MAX_CATEGORICAL_FEATURE_VALUES)
  ]
  return tf.estimator.DNNLinearCombinedClassifier(
      config=config,
      linear_feature_columns=categorical_columns,
      dnn_feature_columns=real_valued_columns,
      dnn_hidden_units=hidden_units or [100, 70, 50, 25],
      warm_start_from=warm_start_from)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2993')" href="javascript:;">
tfx-1.7.0/tfx/examples/bigquery_ml/taxi_utils_bqml.py: 148-193
</a>
<div class="mid" id="frag2993" style="display:none"><pre>
def _build_estimator(config, hidden_units=None, warm_start_from=None):
  """Build an estimator for predicting the tipping behavior of taxi riders.

  Args:
    config: tf.estimator.RunConfig defining the runtime environment for the
      estimator (including model_dir).
    hidden_units: [int], the layer sizes of the DNN (input layer first)
    warm_start_from: Optional directory to warm start from.

  Returns:
    A dict of the following:
      - estimator: The estimator that will be used for training and eval.
      - train_spec: Spec for training.
      - eval_spec: Spec for eval.
      - eval_input_receiver_fn: Input function for eval.
  """
  real_valued_columns = [
      tf.feature_column.numeric_column(key, shape=())
      for key in _transformed_names(_DENSE_FLOAT_FEATURE_KEYS)
  ]
  categorical_columns = [
      tf.feature_column.categorical_column_with_identity(
          key, num_buckets=_VOCAB_SIZE + _OOV_SIZE, default_value=0)
      for key in _transformed_names(_VOCAB_FEATURE_KEYS)
  ]
  categorical_columns += [
      tf.feature_column.categorical_column_with_identity(
          key, num_buckets=_FEATURE_BUCKET_COUNT, default_value=0)
      for key in _transformed_names(_BUCKET_FEATURE_KEYS)
  ]
  categorical_columns += [
      tf.feature_column.categorical_column_with_identity(  # pylint: disable=g-complex-comprehension
          key,
          num_buckets=num_buckets,
          default_value=0) for key, num_buckets in zip(
              _transformed_names(_CATEGORICAL_FEATURE_KEYS),
              _MAX_CATEGORICAL_FEATURE_VALUES)
  ]
  return tf.estimator.DNNLinearCombinedClassifier(
      config=config,
      linear_feature_columns=categorical_columns,
      dnn_feature_columns=real_valued_columns,
      dnn_hidden_units=hidden_units or [100, 70, 50, 25],
      warm_start_from=warm_start_from)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag3122')" href="javascript:;">
tfx-1.7.0/tfx/examples/chicago_taxi_pipeline/taxi_utils.py: 142-187
</a>
<div class="mid" id="frag3122" style="display:none"><pre>
def _build_estimator(config, hidden_units=None, warm_start_from=None):
  """Build an estimator for predicting the tipping behavior of taxi riders.

  Args:
    config: tf.estimator.RunConfig defining the runtime environment for the
      estimator (including model_dir).
    hidden_units: [int], the layer sizes of the DNN (input layer first)
    warm_start_from: Optional directory to warm start from.

  Returns:
    A dict of the following:
      - estimator: The estimator that will be used for training and eval.
      - train_spec: Spec for training.
      - eval_spec: Spec for eval.
      - eval_input_receiver_fn: Input function for eval.
  """
  real_valued_columns = [
      tf.feature_column.numeric_column(key, shape=())
      for key in _transformed_names(_DENSE_FLOAT_FEATURE_KEYS)
  ]
  categorical_columns = [
      tf.feature_column.categorical_column_with_identity(
          key, num_buckets=_VOCAB_SIZE + _OOV_SIZE, default_value=0)
      for key in _transformed_names(_VOCAB_FEATURE_KEYS)
  ]
  categorical_columns += [
      tf.feature_column.categorical_column_with_identity(
          key, num_buckets=_FEATURE_BUCKET_COUNT, default_value=0)
      for key in _transformed_names(_BUCKET_FEATURE_KEYS)
  ]
  categorical_columns += [
      tf.feature_column.categorical_column_with_identity(  # pylint: disable=g-complex-comprehension
          key,
          num_buckets=num_buckets,
          default_value=0) for key, num_buckets in zip(
              _transformed_names(_CATEGORICAL_FEATURE_KEYS),
              _MAX_CATEGORICAL_FEATURE_VALUES)
  ]
  return tf.estimator.DNNLinearCombinedClassifier(
      config=config,
      linear_feature_columns=categorical_columns,
      dnn_feature_columns=real_valued_columns,
      dnn_hidden_units=hidden_units or [100, 70, 50, 25],
      warm_start_from=warm_start_from)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 2:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag332')" href="javascript:;">
tfx-1.7.0/tfx/components/testdata/module_file/trainer_module.py: 134-157
</a>
<div class="mid" id="frag332" style="display:none"><pre>
def _example_serving_receiver_fn(tf_transform_output, schema):
  """Build the serving in inputs.

  Args:
    tf_transform_output: A TFTransformOutput.
    schema: the schema of the input data.

  Returns:
    Tensorflow graph which parses examples, applying tf-transform to them.
  """
  raw_feature_spec = _get_raw_feature_spec(schema)
  raw_feature_spec.pop(_LABEL_KEY)

  raw_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(
      raw_feature_spec, default_batch_size=None)
  serving_input_receiver = raw_input_fn()

  transformed_features = tf_transform_output.transform_raw_features(
      serving_input_receiver.features)

  return tf.estimator.export.ServingInputReceiver(
      transformed_features, serving_input_receiver.receiver_tensors)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag3123')" href="javascript:;">
tfx-1.7.0/tfx/examples/chicago_taxi_pipeline/taxi_utils.py: 188-211
</a>
<div class="mid" id="frag3123" style="display:none"><pre>
def _example_serving_receiver_fn(tf_transform_output, schema):
  """Build the serving in inputs.

  Args:
    tf_transform_output: A TFTransformOutput.
    schema: the schema of the input data.

  Returns:
    Tensorflow graph which parses examples, applying tf-transform to them.
  """
  raw_feature_spec = _get_raw_feature_spec(schema)
  raw_feature_spec.pop(_LABEL_KEY)

  raw_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(
      raw_feature_spec, default_batch_size=None)
  serving_input_receiver = raw_input_fn()

  transformed_features = tf_transform_output.transform_raw_features(
      serving_input_receiver.features)

  return tf.estimator.export.ServingInputReceiver(
      transformed_features, serving_input_receiver.receiver_tensors)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 3:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag333')" href="javascript:;">
tfx-1.7.0/tfx/components/testdata/module_file/trainer_module.py: 158-200
</a>
<div class="mid" id="frag333" style="display:none"><pre>
def _eval_input_receiver_fn(tf_transform_output, schema):
  """Build everything needed for the tf-model-analysis to run the model.

  Args:
    tf_transform_output: A TFTransformOutput.
    schema: the schema of the input data.

  Returns:
    EvalInputReceiver function, which contains:
      - Tensorflow graph which parses raw untransformed features, applies the
        tf-transform preprocessing operators.
      - Set of raw, untransformed features.
      - Label against which predictions will be compared.
  """
  # Notice that the inputs are raw features, not transformed features here.
  raw_feature_spec = _get_raw_feature_spec(schema)

  serialized_tf_example = tf.compat.v1.placeholder(
      dtype=tf.string, shape=[None], name='input_example_tensor')

  # Add a parse_example operator to the tensorflow graph, which will parse
  # raw, untransformed, tf examples.
  features = tf.io.parse_example(
      serialized=serialized_tf_example, features=raw_feature_spec)

  # Now that we have our raw examples, process them through the tf-transform
  # function computed during the preprocessing step.
  transformed_features = tf_transform_output.transform_raw_features(
      features)

  # The key name MUST be 'examples'.
  receiver_tensors = {'examples': serialized_tf_example}

  # NOTE: Model is driven by transformed features (since training works on the
  # materialized output of TFT, but slicing will happen on raw features.
  features.update(transformed_features)

  return tfma.export.EvalInputReceiver(
      features=features,
      receiver_tensors=receiver_tensors,
      labels=transformed_features[_transformed_name(_LABEL_KEY)])


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag3124')" href="javascript:;">
tfx-1.7.0/tfx/examples/chicago_taxi_pipeline/taxi_utils.py: 212-254
</a>
<div class="mid" id="frag3124" style="display:none"><pre>
def _eval_input_receiver_fn(tf_transform_output, schema):
  """Build everything needed for the tf-model-analysis to run the model.

  Args:
    tf_transform_output: A TFTransformOutput.
    schema: the schema of the input data.

  Returns:
    EvalInputReceiver function, which contains:
      - Tensorflow graph which parses raw untransformed features, applies the
        tf-transform preprocessing operators.
      - Set of raw, untransformed features.
      - Label against which predictions will be compared.
  """
  # Notice that the inputs are raw features, not transformed features here.
  raw_feature_spec = _get_raw_feature_spec(schema)

  serialized_tf_example = tf.compat.v1.placeholder(
      dtype=tf.string, shape=[None], name='input_example_tensor')

  # Add a parse_example operator to the tensorflow graph, which will parse
  # raw, untransformed, tf examples.
  features = tf.io.parse_example(
      serialized=serialized_tf_example, features=raw_feature_spec)

  # Now that we have our raw examples, process them through the tf-transform
  # function computed during the preprocessing step.
  transformed_features = tf_transform_output.transform_raw_features(
      features)

  # The key name MUST be 'examples'.
  receiver_tensors = {'examples': serialized_tf_example}

  # NOTE: Model is driven by transformed features (since training works on the
  # materialized output of TFT, but slicing will happen on raw features.
  features.update(transformed_features)

  return tfma.export.EvalInputReceiver(
      features=features,
      receiver_tensors=receiver_tensors,
      labels=transformed_features[_transformed_name(_LABEL_KEY)])


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 4:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag775')" href="javascript:;">
tfx-1.7.0/tfx/extensions/google_cloud_big_query/pusher/component.py: 34-57
</a>
<div class="mid" id="frag775" style="display:none"><pre>
  def __init__(self,
               model: Optional[types.Channel] = None,
               model_blessing: Optional[types.Channel] = None,
               infra_blessing: Optional[types.Channel] = None,
               custom_config: Optional[Dict[str, Any]] = None):
    """Construct a Pusher component.

    Args:
      model: An optional Channel of type `standard_artifacts.Model`, usually
        produced by a Trainer component.
      model_blessing: An optional Channel of type
        `standard_artifacts.ModelBlessing`, usually produced from an Evaluator
        component.
      infra_blessing: An optional Channel of type
        `standard_artifacts.InfraBlessing`, usually produced from an
        InfraValidator component.
      custom_config: A dict which contains the deployment job parameters to be
        passed to Cloud platforms.
    """
    super().__init__(
        model=model,
        model_blessing=model_blessing,
        infra_blessing=infra_blessing,
        custom_config=custom_config)
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag893')" href="javascript:;">
tfx-1.7.0/tfx/extensions/google_cloud_ai_platform/pusher/component.py: 29-53
</a>
<div class="mid" id="frag893" style="display:none"><pre>
  def __init__(self,
               model: Optional[types.Channel] = None,
               model_blessing: Optional[types.Channel] = None,
               infra_blessing: Optional[types.Channel] = None,
               custom_config: Optional[Dict[str, Any]] = None):
    """Construct a Pusher component.

    Args:
      model: An optional Channel of type `standard_artifacts.Model`, usually
        produced by a Trainer component, representing the model used for
        training.
      model_blessing: An optional Channel of type
        `standard_artifacts.ModelBlessing`, usually produced from an Evaluator
        component, containing the blessing model.
      infra_blessing: An optional Channel of type
        `standard_artifacts.InfraBlessing`, usually produced from an
        InfraValidator component, containing the validation result.
      custom_config: A dict which contains the deployment job parameters to be
        passed to Cloud platforms.
    """
    super().__init__(
        model=model,
        model_blessing=model_blessing,
        infra_blessing=infra_blessing,
        custom_config=custom_config)
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 5:</b> &nbsp; 2 fragments, nominal size 16 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1519')" href="javascript:;">
tfx-1.7.0/tfx/orchestration/launcher/docker_component_launcher_e2e_test.py: 51-69
</a>
<div class="mid" id="frag1519" style="display:none"><pre>
def _create_pipeline(
    pipeline_name,
    pipeline_root,
    metadata_path,
    name,
):
  hello_world = _HelloWorldComponent(name=name)

  return pipeline.Pipeline(
      pipeline_name=pipeline_name,
      pipeline_root=pipeline_root,
      components=[hello_world],
      enable_cache=True,
      metadata_connection_config=metadata.sqlite_metadata_connection_config(
          metadata_path),
      additional_pipeline_args={},
  )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1994')" href="javascript:;">
tfx-1.7.0/tfx/orchestration/portable/docker_executor_operator_e2e_test.py: 51-69
</a>
<div class="mid" id="frag1994" style="display:none"><pre>
def _create_pipeline(
    pipeline_name,
    pipeline_root,
    metadata_path,
    name,
):
  hello_world = _HelloWorldComponent(name=name)

  return pipeline.Pipeline(
      pipeline_name=pipeline_name,
      pipeline_root=pipeline_root,
      components=[hello_world],
      enable_cache=True,
      metadata_connection_config=metadata.sqlite_metadata_connection_config(
          metadata_path),
      additional_pipeline_args={},
  )


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 6:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1520')" href="javascript:;">
tfx-1.7.0/tfx/orchestration/launcher/docker_component_launcher_e2e_test.py: 72-83
</a>
<div class="mid" id="frag1520" style="display:none"><pre>
  def setUp(self):
    super().setUp()
    self._test_dir = os.path.join(
        os.environ.get('TEST_UNDECLARED_OUTPUTS_DIR', self.get_temp_dir()),
        self._testMethodName)

    self._pipeline_name = 'docker_e2e_test'
    self._pipeline_root = os.path.join(self._test_dir, 'tfx', 'pipelines',
                                       self._pipeline_name)
    self._metadata_path = os.path.join(self._test_dir, 'tfx', 'metadata',
                                       self._pipeline_name, 'metadata.db')

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1995')" href="javascript:;">
tfx-1.7.0/tfx/orchestration/portable/docker_executor_operator_e2e_test.py: 72-83
</a>
<div class="mid" id="frag1995" style="display:none"><pre>
  def setUp(self):
    super().setUp()
    self._test_dir = os.path.join(
        os.environ.get('TEST_UNDECLARED_OUTPUTS_DIR', self.get_temp_dir()),
        self._testMethodName)

    self._pipeline_name = 'docker_e2e_test'
    self._pipeline_root = os.path.join(self._test_dir, 'tfx', 'pipelines',
                                       self._pipeline_name)
    self._metadata_path = os.path.join(self._test_dir, 'tfx', 'metadata',
                                       self._pipeline_name, 'metadata.db')

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 7:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1521')" href="javascript:;">
tfx-1.7.0/tfx/orchestration/launcher/docker_component_launcher_e2e_test.py: 84-98
</a>
<div class="mid" id="frag1521" style="display:none"><pre>
  def testDockerComponentLauncherInBeam(self):

    beam_dag_runner.BeamDagRunner().run(
        _create_pipeline(
            pipeline_name=self._pipeline_name,
            pipeline_root=self._pipeline_root,
            metadata_path=self._metadata_path,
            name='docker_e2e_test_in_beam'))

    metadata_config = metadata.sqlite_metadata_connection_config(
        self._metadata_path)
    with metadata.Metadata(metadata_config) as m:
      self.assertEqual(1, len(m.store.get_executions()))


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1996')" href="javascript:;">
tfx-1.7.0/tfx/orchestration/portable/docker_executor_operator_e2e_test.py: 84-98
</a>
<div class="mid" id="frag1996" style="display:none"><pre>
  def testDockerComponentLauncherInBeam(self):

    beam_dag_runner.BeamDagRunner().run(
                _create_pipeline(
                    pipeline_name=self._pipeline_name,
                    pipeline_root=self._pipeline_root,
                    metadata_path=self._metadata_path,
                    name='docker_e2e_test_in_beam'))

    metadata_config = metadata.sqlite_metadata_connection_config(
        self._metadata_path)
    with metadata.Metadata(metadata_config) as m:
      self.assertEqual(1, len(m.store.get_executions()))


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 8:</b> &nbsp; 2 fragments, nominal size 15 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2175')" href="javascript:;">
tfx-1.7.0/tfx/orchestration/test_pipelines/download_grep_print_pipeline.py: 118-136
</a>
<div class="mid" id="frag2175" style="display:none"><pre>
def create_pipeline_component_instances(text_url: str, pattern: str):
  """Creates tasks for the download_grep_print pipeline."""

  downloader_task = downloader_component(url=text_url)
  grep_task = grep_component(
      text=downloader_task.outputs['data'],
      pattern=pattern,
  )
  print_task = print_component(
      text=grep_task.outputs['filtered_text'],
  )

  component_instances = [
      downloader_task,
      grep_task,
      print_task,
  ]

  return component_instances
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag3070')" href="javascript:;">
tfx-1.7.0/tfx/examples/custom_components/container_components/download_grep_print_pipeline.py: 118-136
</a>
<div class="mid" id="frag3070" style="display:none"><pre>
def create_pipeline_component_instances(text_url: str, pattern: str):
  """Creates tasks for the download_grep_print pipeline."""

  downloader_task = downloader_component(url=text_url)
  grep_task = grep_component(
      text=downloader_task.outputs['data'],
      pattern=pattern,
  )
  print_task = print_component(
      text=grep_task.outputs['filtered_text'],
  )

  component_instances = [
      downloader_task,
      grep_task,
      print_task,
  ]

  return component_instances
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 9:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2721')" href="javascript:;">
tfx-1.7.0/tfx/tools/cli/testdata/test_pipeline_local_2.py: 36-53
</a>
<div class="mid" id="frag2721" style="display:none"><pre>
def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,
                     metadata_path: str) -&gt; pipeline.Pipeline:
  """Implements the chicago taxi pipeline with TFX."""

  # Brings data into the pipeline or otherwise joins/converts training data.
  example_gen = CsvExampleGen(input_base=data_root)

  return pipeline.Pipeline(
      pipeline_name=pipeline_name,
      pipeline_root=pipeline_root,
      components=[example_gen],
      enable_cache=True,
      metadata_connection_config=metadata.sqlite_metadata_connection_config(
          metadata_path),
      additional_pipeline_args={},
  )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2732')" href="javascript:;">
tfx-1.7.0/tfx/tools/cli/testdata/test_pipeline_beam_2.py: 36-53
</a>
<div class="mid" id="frag2732" style="display:none"><pre>
def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,
                     metadata_path: str) -&gt; pipeline.Pipeline:
  """Implements the chicago taxi pipeline with TFX."""

  # Brings data into the pipeline or otherwise joins/converts training data.
  example_gen = CsvExampleGen(input_base=data_root)

  return pipeline.Pipeline(
      pipeline_name=pipeline_name,
      pipeline_root=pipeline_root,
      components=[example_gen],
      enable_cache=True,
      metadata_connection_config=metadata.sqlite_metadata_connection_config(
          metadata_path),
      additional_pipeline_args={},
  )


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 10:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2725')" href="javascript:;">
tfx-1.7.0/tfx/tools/cli/testdata/test_pipeline_beam_1.py: 37-60
</a>
<div class="mid" id="frag2725" style="display:none"><pre>
def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,
                     metadata_path: str) -&gt; pipeline.Pipeline:
  """Implements the chicago taxi pipeline with TFX."""

  # Brings data into the pipeline or otherwise joins/converts training data.
  example_gen = CsvExampleGen(input_base=data_root)

  # Computes statistics over data for visualization and example validation.
  statistics_gen = StatisticsGen(examples=example_gen.outputs['examples'])

  # Generates schema based on statistics files.
  infer_schema = SchemaGen(statistics=statistics_gen.outputs['statistics'])

  return pipeline.Pipeline(
      pipeline_name=pipeline_name,
      pipeline_root=pipeline_root,
      components=[example_gen, statistics_gen, infer_schema],
      enable_cache=True,
      metadata_connection_config=metadata.sqlite_metadata_connection_config(
          metadata_path),
      additional_pipeline_args={},
  )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2733')" href="javascript:;">
tfx-1.7.0/tfx/tools/cli/testdata/test_pipeline_local_1.py: 39-63
</a>
<div class="mid" id="frag2733" style="display:none"><pre>
def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,
                     metadata_path: str) -&gt; pipeline.Pipeline:
  """Implements the chicago taxi pipeline with TFX."""

  # Brings data into the pipeline or otherwise joins/converts training data.
  example_gen = CsvExampleGen(input_base=data_root)

  # Computes statistics over data for visualization and example validation.
  statistics_gen = StatisticsGen(examples=example_gen.outputs['examples'])

  # Generates schema based on statistics files.
  infer_schema = SchemaGen(statistics=statistics_gen.outputs['statistics'])

  return pipeline.Pipeline(
      pipeline_name=pipeline_name,
      pipeline_root=pipeline_root,
      components=[example_gen, statistics_gen, infer_schema],
      enable_cache=True,
      metadata_connection_config=metadata.sqlite_metadata_connection_config(
          metadata_path),
      additional_pipeline_args={},
  )

# We need to guard this in this conditional because this file is loaded multiple
# times in a single test run of local_handler_test.py.
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 11:</b> &nbsp; 2 fragments, nominal size 17 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2726')" href="javascript:;">
tfx-1.7.0/tfx/tools/cli/testdata/test_pipeline_local_3.py: 51-79
</a>
<div class="mid" id="frag2726" style="display:none"><pre>
def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,
                     metadata_path: str) -&gt; pipeline.Pipeline:
  """Implements the chicago taxi pipeline with TFX."""

  # Brings data into the pipeline or otherwise joins/converts training data.
  example_gen = CsvExampleGen(input_base=data_root)

  # Computes statistics over data for visualization and example validation.
  statistics_gen = StatisticsGen(examples=example_gen.outputs['examples'])

  # Generates schema based on statistics files.
  infer_schema = SchemaGen(statistics=statistics_gen.outputs['statistics'])

  # Performs anomaly detection based on statistics and data schema.
  validate_stats = ExampleValidator(
      statistics=statistics_gen.outputs['statistics'],
      schema=infer_schema.outputs['schema'])

  return pipeline.Pipeline(
      pipeline_name=pipeline_name,
      pipeline_root=pipeline_root,
      components=[example_gen, statistics_gen, infer_schema, validate_stats],
      enable_cache=True,
      metadata_connection_config=metadata.sqlite_metadata_connection_config(
          metadata_path),
      additional_pipeline_args={},
  )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2729')" href="javascript:;">
tfx-1.7.0/tfx/tools/cli/testdata/test_pipeline_beam_3.py: 51-79
</a>
<div class="mid" id="frag2729" style="display:none"><pre>
def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,
                     metadata_path: str) -&gt; pipeline.Pipeline:
  """Implements the chicago taxi pipeline with TFX."""

  # Brings data into the pipeline or otherwise joins/converts training data.
  example_gen = CsvExampleGen(input_base=data_root)

  # Computes statistics over data for visualization and example validation.
  statistics_gen = StatisticsGen(examples=example_gen.outputs['examples'])

  # Generates schema based on statistics files.
  infer_schema = SchemaGen(statistics=statistics_gen.outputs['statistics'])

  # Performs anomaly detection based on statistics and data schema.
  validate_stats = ExampleValidator(
      statistics=statistics_gen.outputs['statistics'],
      schema=infer_schema.outputs['schema'])

  return pipeline.Pipeline(
      pipeline_name=pipeline_name,
      pipeline_root=pipeline_root,
      components=[example_gen, statistics_gen, infer_schema, validate_stats],
      enable_cache=True,
      metadata_connection_config=metadata.sqlite_metadata_connection_config(
          metadata_path),
      additional_pipeline_args={},
  )


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 12:</b> &nbsp; 2 fragments, nominal size 22 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2796')" href="javascript:;">
tfx-1.7.0/tfx/experimental/templates/taxi/kubeflow_runner.py: 50-97
</a>
<div class="mid" id="frag2796" style="display:none"><pre>
def run():
  """Define a kubeflow pipeline."""

  # Metadata config. The defaults works work with the installation of
  # KF Pipelines using Kubeflow. If installing KF Pipelines using the
  # lightweight deployment option, you may need to override the defaults.
  # If you use Kubeflow, metadata will be written to MySQL database inside
  # Kubeflow cluster.
  metadata_config = tfx.orchestration.experimental.get_default_kubeflow_metadata_config(
  )

  runner_config = tfx.orchestration.experimental.KubeflowDagRunnerConfig(
      kubeflow_metadata_config=metadata_config,
      tfx_image=configs.PIPELINE_IMAGE)
  pod_labels = {
      'add-pod-env': 'true',
      tfx.orchestration.experimental.LABEL_KFP_SDK_ENV: 'tfx-template'
  }
  tfx.orchestration.experimental.KubeflowDagRunner(
      config=runner_config, pod_labels_to_attach=pod_labels
  ).run(
      pipeline.create_pipeline(
          pipeline_name=configs.PIPELINE_NAME,
          pipeline_root=PIPELINE_ROOT,
          data_path=DATA_PATH,
          # TODO(step 7): (Optional) Uncomment below to use BigQueryExampleGen.
          # query=configs.BIG_QUERY_QUERY,
          # TODO(step 5): (Optional) Set the path of the customized schema.
          # schema_path=generated_schema_path,
          preprocessing_fn=configs.PREPROCESSING_FN,
          run_fn=configs.RUN_FN,
          train_args=tfx.proto.TrainArgs(num_steps=configs.TRAIN_NUM_STEPS),
          eval_args=tfx.proto.EvalArgs(num_steps=configs.EVAL_NUM_STEPS),
          eval_accuracy_threshold=configs.EVAL_ACCURACY_THRESHOLD,
          serving_model_dir=SERVING_MODEL_DIR,
          # TODO(step 7): (Optional) Uncomment below to use provide GCP related
          #               config for BigQuery with Beam DirectRunner.
          # beam_pipeline_args=configs
          # .BIG_QUERY_WITH_DIRECT_RUNNER_BEAM_PIPELINE_ARGS,
          # TODO(step 8): (Optional) Uncomment below to use Dataflow.
          # beam_pipeline_args=configs.DATAFLOW_BEAM_PIPELINE_ARGS,
          # TODO(step 9): (Optional) Uncomment below to use Cloud AI Platform.
          # ai_platform_training_args=configs.GCP_AI_PLATFORM_TRAINING_ARGS,
          # TODO(step 9): (Optional) Uncomment below to use Cloud AI Platform.
          # ai_platform_serving_args=configs.GCP_AI_PLATFORM_SERVING_ARGS,
      ))


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2839')" href="javascript:;">
tfx-1.7.0/tfx/experimental/templates/penguin/kubeflow_runner.py: 50-90
</a>
<div class="mid" id="frag2839" style="display:none"><pre>
def run():
  """Define a kubeflow pipeline."""

  # Metadata config. The defaults works work with the installation of
  # KF Pipelines using Kubeflow. If installing KF Pipelines using the
  # lightweight deployment option, you may need to override the defaults.
  # If you use Kubeflow, metadata will be written to MySQL database inside
  # Kubeflow cluster.
  metadata_config = tfx.orchestration.experimental.get_default_kubeflow_metadata_config(
  )

  runner_config = tfx.orchestration.experimental.KubeflowDagRunnerConfig(
      kubeflow_metadata_config=metadata_config,
      tfx_image=configs.PIPELINE_IMAGE)
  pod_labels = {
      'add-pod-env': 'true',
      tfx.orchestration.experimental.LABEL_KFP_SDK_ENV: 'tfx-template'
  }
  tfx.orchestration.experimental.KubeflowDagRunner(
      config=runner_config, pod_labels_to_attach=pod_labels
  ).run(
      pipeline.create_pipeline(
          pipeline_name=configs.PIPELINE_NAME,
          pipeline_root=PIPELINE_ROOT,
          data_path=DATA_PATH,
          # NOTE: Use `query` instead of `data_path` to use BigQueryExampleGen.
          # query=configs.BIG_QUERY_QUERY,
          # NOTE: Set the path of the customized schema if any.
          # schema_path=generated_schema_path,
          preprocessing_fn=configs.PREPROCESSING_FN,
          run_fn=configs.RUN_FN,
          train_args=tfx.proto.TrainArgs(num_steps=configs.TRAIN_NUM_STEPS),
          eval_args=tfx.proto.EvalArgs(num_steps=configs.EVAL_NUM_STEPS),
          eval_accuracy_threshold=configs.EVAL_ACCURACY_THRESHOLD,
          serving_model_dir=SERVING_MODEL_DIR,
          # NOTE: Provide GCP configs to use BigQuery with Beam DirectRunner.
          # beam_pipeline_args=configs.
          # BIG_QUERY_WITH_DIRECT_RUNNER_BEAM_PIPELINE_ARGS,
      ))


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 13:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2815')" href="javascript:;">
tfx-1.7.0/tfx/experimental/templates/taxi/local_runner.py: 52-77
</a>
<div class="mid" id="frag2815" style="display:none"><pre>
def run():
  """Define a local pipeline."""

  tfx.orchestration.LocalDagRunner().run(
      pipeline.create_pipeline(
          pipeline_name=configs.PIPELINE_NAME,
          pipeline_root=PIPELINE_ROOT,
          data_path=DATA_PATH,
          # TODO(step 7): (Optional) Uncomment here to use BigQueryExampleGen.
          # query=configs.BIG_QUERY_QUERY,
          # TODO(step 5): (Optional) Set the path of the customized schema.
          # schema_path=generated_schema_path,
          preprocessing_fn=configs.PREPROCESSING_FN,
          run_fn=configs.RUN_FN,
          train_args=tfx.proto.TrainArgs(num_steps=configs.TRAIN_NUM_STEPS),
          eval_args=tfx.proto.EvalArgs(num_steps=configs.EVAL_NUM_STEPS),
          eval_accuracy_threshold=configs.EVAL_ACCURACY_THRESHOLD,
          serving_model_dir=SERVING_MODEL_DIR,
          # TODO(step 7): (Optional) Uncomment here to use provide GCP related
          #               config for BigQuery with Beam DirectRunner.
          # beam_pipeline_args=configs.
          # BIG_QUERY_WITH_DIRECT_RUNNER_BEAM_PIPELINE_ARGS,
          metadata_connection_config=tfx.orchestration.metadata
          .sqlite_metadata_connection_config(METADATA_PATH)))


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2854')" href="javascript:;">
tfx-1.7.0/tfx/experimental/templates/penguin/local_runner.py: 53-77
</a>
<div class="mid" id="frag2854" style="display:none"><pre>
def run():
  """Define a pipeline."""

  tfx.orchestration.LocalDagRunner().run(
      pipeline.create_pipeline(
          pipeline_name=configs.PIPELINE_NAME,
          pipeline_root=PIPELINE_ROOT,
          data_path=DATA_PATH,
          # NOTE: Use `query` instead of `data_path` to use BigQueryExampleGen.
          # query=configs.BIG_QUERY_QUERY,
          # NOTE: Set the path of the customized schema if any.
          # schema_path=generated_schema_path,
          preprocessing_fn=configs.PREPROCESSING_FN,
          run_fn=configs.RUN_FN,
          train_args=tfx.proto.TrainArgs(num_steps=configs.TRAIN_NUM_STEPS),
          eval_args=tfx.proto.EvalArgs(num_steps=configs.EVAL_NUM_STEPS),
          eval_accuracy_threshold=configs.EVAL_ACCURACY_THRESHOLD,
          serving_model_dir=SERVING_MODEL_DIR,
          # NOTE: Provide GCP configs to use BigQuery with Beam DirectRunner.
          # beam_pipeline_args=configs.
          # BIG_QUERY_WITH_DIRECT_RUNNER_BEAM_PIPELINE_ARGS,
          metadata_connection_config=tfx.orchestration.metadata
          .sqlite_metadata_connection_config(METADATA_PATH)))


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 14:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2932')" href="javascript:;">
tfx-1.7.0/tfx/examples/bert/cola/bert_cola_utils.py: 158-184
</a>
<div class="mid" id="frag2932" style="display:none"><pre>
def _input_fn(file_pattern: List[str],
              data_accessor: tfx.components.DataAccessor,
              tf_transform_output: tft.TFTransformOutput,
              batch_size: int = 200) -&gt; tf.data.Dataset:
  """Generates features and label for tuning/training.

  Args:
    file_pattern: List of paths or patterns of materialized transformed input
      tfrecord files.
    data_accessor: DataAccessor for converting input to RecordBatch.
    tf_transform_output: A TFTransformOutput.
    batch_size: representing the number of consecutive elements of returned
      dataset to combine in a single batch

  Returns:
    A dataset that contains (features, indices) tuple where features is a
      dictionary of Tensors, and indices is a single Tensor of label indices.
  """
  dataset = data_accessor.tf_dataset_factory(
      file_pattern,
      tfxio.TensorFlowDatasetOptions(
          batch_size=batch_size, label_key=_LABEL_KEY),
      tf_transform_output.transformed_metadata.schema)
  dataset = dataset.repeat()
  return dataset.prefetch(tf.data.AUTOTUNE)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2940')" href="javascript:;">
tfx-1.7.0/tfx/examples/bert/mrpc/bert_mrpc_utils.py: 157-183
</a>
<div class="mid" id="frag2940" style="display:none"><pre>
def _input_fn(file_pattern: List[str],
              data_accessor: tfx.components.DataAccessor,
              tf_transform_output: tft.TFTransformOutput,
              batch_size: int = 200) -&gt; tf.data.Dataset:
  """Generates features and label for tuning/training.

  Args:
    file_pattern: List of paths or patterns of input tfrecord files.
    data_accessor: DataAccessor for converting input to RecordBatch.
    tf_transform_output: A TFTransformOutput.
    batch_size: representing the number of consecutive elements of returned
      dataset to combine in a single batch

  Returns:
    A dataset that contains (features, indices) tuple where features is a
      dictionary of Tensors, and indices is a single Tensor of label indices.
  """
  dataset = data_accessor.tf_dataset_factory(
      file_pattern,
      tfxio.TensorFlowDatasetOptions(
          batch_size=batch_size, label_key=_LABEL_KEY),
      tf_transform_output.transformed_metadata.schema)
  dataset = dataset.repeat()

  return dataset.prefetch(tf.data.AUTOTUNE)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 15:</b> &nbsp; 3 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2933')" href="javascript:;">
tfx-1.7.0/tfx/examples/bert/cola/bert_cola_utils.py: 185-204
</a>
<div class="mid" id="frag2933" style="display:none"><pre>
def _get_serve_tf_examples_fn(model, tf_transform_output):
  """Returns a function that parses a serialized tf.Example."""

  model.tft_layer = tf_transform_output.transform_features_layer()

  @tf.function
  def serve_tf_examples_fn(serialized_tf_examples):
    """Returns the output to be used in the serving signature."""
    feature_spec = tf_transform_output.raw_feature_spec()
    feature_spec.pop(_LABEL_KEY)
    parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)

    transformed_features = model.tft_layer(parsed_features)

    return model(transformed_features)

  return serve_tf_examples_fn


# TFX Trainer will call this function.
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag3046')" href="javascript:;">
tfx-1.7.0/tfx/examples/imdb/imdb_utils_native_keras.py: 155-171
</a>
<div class="mid" id="frag3046" style="display:none"><pre>
def _get_serve_tf_examples_fn(model, tf_transform_output):
  """Returns a function that parses a serialized tf.Example."""
  model.tft_layer = tf_transform_output.transform_features_layer()

  @tf.function
  def serve_tf_examples_fn(serialized_tf_examples):
    """Returns the output to be used in the serving signature."""
    feature_spec = tf_transform_output.raw_feature_spec()
    feature_spec.pop(_LABEL_KEY)
    parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)
    transformed_features = model.tft_layer(parsed_features)
    return model(transformed_features)

  return serve_tf_examples_fn


# TFX Trainer will call this function.
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2941')" href="javascript:;">
tfx-1.7.0/tfx/examples/bert/mrpc/bert_mrpc_utils.py: 184-205
</a>
<div class="mid" id="frag2941" style="display:none"><pre>
def _get_serve_tf_examples_fn(model, tf_transform_output):
  """Returns a function that parses a serialized tf.Example."""

  model.tft_layer = tf_transform_output.transform_features_layer()

  @tf.function
  def serve_tf_examples_fn(serialized_tf_examples):
    """Returns the output to be used in the serving signature."""
    feature_spec = tf_transform_output.raw_feature_spec()
    feature_spec.pop(_LABEL_KEY)
    parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)

    transformed_features = model.tft_layer(parsed_features)

    return model(transformed_features)

  return serve_tf_examples_fn


# TFX Trainer will call this function.


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 16:</b> &nbsp; 2 fragments, nominal size 15 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2965')" href="javascript:;">
tfx-1.7.0/tfx/examples/cifar10/cifar10_pipeline_native_keras_e2e_test.py: 46-64
</a>
<div class="mid" id="frag2965" style="display:none"><pre>
  def assertExecutedOnce(self, component: str) -&gt; None:
    """Check the component is executed exactly once."""
    component_path = os.path.join(self._pipeline_root, component)
    self.assertTrue(fileio.exists(component_path))
    outputs = fileio.listdir(component_path)

    self.assertIn('.system', outputs)
    outputs.remove('.system')
    system_paths = [
        os.path.join('.system', path)
        for path in fileio.listdir(os.path.join(component_path, '.system'))
    ]
    self.assertNotEmpty(system_paths)
    self.assertIn('.system/executor_execution', system_paths)
    outputs.extend(system_paths)
    for output in outputs:
      execution = fileio.listdir(os.path.join(component_path, output))
      self.assertLen(execution, 1)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag3057')" href="javascript:;">
tfx-1.7.0/tfx/examples/tfjs_next_page_prediction/tfjs_next_page_prediction_e2e_test.py: 44-62
</a>
<div class="mid" id="frag3057" style="display:none"><pre>
  def assertExecutedOnce(self, component: str) -&gt; None:
    """Check the component is executed exactly once."""
    component_path = os.path.join(self._pipeline_root, component)
    self.assertTrue(fileio.exists(component_path))
    outputs = fileio.listdir(component_path)

    self.assertIn('.system', outputs)
    outputs.remove('.system')
    system_paths = [
        os.path.join('.system', path)
        for path in fileio.listdir(os.path.join(component_path, '.system'))
    ]
    self.assertNotEmpty(system_paths)
    self.assertIn('.system/executor_execution', system_paths)
    outputs.extend(system_paths)
    for output in outputs:
      execution = fileio.listdir(os.path.join(component_path, output))
      self.assertLen(execution, 1)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 17:</b> &nbsp; 3 fragments, nominal size 16 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2980')" href="javascript:;">
tfx-1.7.0/tfx/examples/mnist/mnist_pipeline_native_keras_e2e_test.py: 51-69
</a>
<div class="mid" id="frag2980" style="display:none"><pre>
  def assertExecutedOnce(self, component: str) -&gt; None:
    """Check the component is executed exactly once."""
    component_path = os.path.join(self._pipeline_root, component)
    self.assertTrue(fileio.exists(component_path))
    outputs = fileio.listdir(component_path)
    self.assertIn('.system', outputs)
    outputs.remove('.system')
    system_paths = [
        os.path.join('.system', path)
        for path in fileio.listdir(os.path.join(component_path, '.system'))
    ]
    self.assertNotEmpty(system_paths)
    self.assertIn('.system/executor_execution', system_paths)
    outputs.extend(system_paths)
    self.assertNotEmpty(outputs)
    for output in outputs:
      execution = fileio.listdir(os.path.join(component_path, output))
      self.assertLen(execution, 1)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag3128')" href="javascript:;">
tfx-1.7.0/tfx/examples/chicago_taxi_pipeline/taxi_pipeline_local_e2e_test.py: 43-62
</a>
<div class="mid" id="frag3128" style="display:none"><pre>
  def assertExecutedOnce(self, component: str) -&gt; None:
    """Check the component is executed exactly once."""
    component_path = os.path.join(self._pipeline_root, component)
    self.assertTrue(fileio.exists(component_path))
    outputs = fileio.listdir(component_path)

    self.assertIn('.system', outputs)
    outputs.remove('.system')
    system_paths = [
        os.path.join('.system', path)
        for path in fileio.listdir(os.path.join(component_path, '.system'))
    ]
    self.assertNotEmpty(system_paths)
    self.assertIn('.system/executor_execution', system_paths)
    outputs.extend(system_paths)
    self.assertNotEmpty(outputs)
    for output in outputs:
      execution = fileio.listdir(os.path.join(component_path, output))
      self.assertLen(execution, 1)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag3112')" href="javascript:;">
tfx-1.7.0/tfx/examples/chicago_taxi_pipeline/taxi_pipeline_native_keras_e2e_test.py: 49-67
</a>
<div class="mid" id="frag3112" style="display:none"><pre>
  def assertExecutedOnce(self, component: str) -&gt; None:
    """Check the component is executed exactly once."""
    component_path = os.path.join(self._pipeline_root, component)
    self.assertTrue(fileio.exists(component_path))
    outputs = fileio.listdir(component_path)
    self.assertIn('.system', outputs)
    outputs.remove('.system')
    system_paths = [
        os.path.join('.system', path)
        for path in fileio.listdir(os.path.join(component_path, '.system'))
    ]
    self.assertNotEmpty(system_paths)
    self.assertIn('.system/executor_execution', system_paths)
    outputs.extend(system_paths)
    self.assertNotEmpty(outputs)
    for output in outputs:
      execution = fileio.listdir(os.path.join(component_path, output))
      self.assertLen(execution, 1)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 18:</b> &nbsp; 3 fragments, nominal size 23 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2992')" href="javascript:;">
tfx-1.7.0/tfx/examples/bigquery_ml/taxi_utils_bqml.py: 106-147
</a>
<div class="mid" id="frag2992" style="display:none"><pre>
def preprocessing_fn(inputs):
  """tf.transform's callback function for preprocessing inputs.

  Args:
    inputs: map from feature keys to raw not-yet-transformed features.

  Returns:
    Map from string feature key to transformed feature operations.
  """
  outputs = {}
  for key in _DENSE_FLOAT_FEATURE_KEYS:
    # If sparse make it dense, setting nan's to 0 or '', and apply zscore.
    outputs[_transformed_name(key)] = tft.scale_to_z_score(
        _fill_in_missing(inputs[key]))

  for key in _VOCAB_FEATURE_KEYS:
    # Build a vocabulary for this feature.
    outputs[_transformed_name(key)] = tft.compute_and_apply_vocabulary(
        _fill_in_missing(inputs[key]),
        top_k=_VOCAB_SIZE,
        num_oov_buckets=_OOV_SIZE)

  for key in _BUCKET_FEATURE_KEYS:
    outputs[_transformed_name(key)] = tft.bucketize(
        _fill_in_missing(inputs[key]), _FEATURE_BUCKET_COUNT)

  for key in _CATEGORICAL_FEATURE_KEYS:
    outputs[_transformed_name(key)] = _fill_in_missing(inputs[key])

  # Was this passenger a big tipper?
  taxi_fare = _fill_in_missing(inputs[_FARE_KEY])
  tips = _fill_in_missing(inputs[_LABEL_KEY])
  outputs[_transformed_name(_LABEL_KEY)] = tf.compat.v1.where(
      tf.math.is_nan(taxi_fare),
      tf.cast(tf.zeros_like(taxi_fare), tf.int64),
      # Test if the tip was &gt; 20% of the fare.
      tf.cast(
          tf.greater(tips, tf.multiply(taxi_fare, tf.constant(0.2))), tf.int64))

  return outputs


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag3121')" href="javascript:;">
tfx-1.7.0/tfx/examples/chicago_taxi_pipeline/taxi_utils.py: 100-141
</a>
<div class="mid" id="frag3121" style="display:none"><pre>
def preprocessing_fn(inputs):
  """tf.transform's callback function for preprocessing inputs.

  Args:
    inputs: map from feature keys to raw not-yet-transformed features.

  Returns:
    Map from string feature key to transformed feature operations.
  """
  outputs = {}
  for key in _DENSE_FLOAT_FEATURE_KEYS:
    # If sparse make it dense, setting nan's to 0 or '', and apply zscore.
    outputs[_transformed_name(key)] = tft.scale_to_z_score(
        _fill_in_missing(inputs[key]))

  for key in _VOCAB_FEATURE_KEYS:
    # Build a vocabulary for this feature.
    outputs[_transformed_name(key)] = tft.compute_and_apply_vocabulary(
        _fill_in_missing(inputs[key]),
        top_k=_VOCAB_SIZE,
        num_oov_buckets=_OOV_SIZE)

  for key in _BUCKET_FEATURE_KEYS:
    outputs[_transformed_name(key)] = tft.bucketize(
        _fill_in_missing(inputs[key]), _FEATURE_BUCKET_COUNT)

  for key in _CATEGORICAL_FEATURE_KEYS:
    outputs[_transformed_name(key)] = _fill_in_missing(inputs[key])

  # Was this passenger a big tipper?
  taxi_fare = _fill_in_missing(inputs[_FARE_KEY])
  tips = _fill_in_missing(inputs[_LABEL_KEY])
  outputs[_transformed_name(_LABEL_KEY)] = tf.compat.v1.where(
      tf.math.is_nan(taxi_fare),
      tf.cast(tf.zeros_like(taxi_fare), tf.int64),
      # Test if the tip was &gt; 20% of the fare.
      tf.cast(
          tf.greater(tips, tf.multiply(taxi_fare, tf.constant(0.2))), tf.int64))

  return outputs


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag3094')" href="javascript:;">
tfx-1.7.0/tfx/examples/custom_components/slack/example/taxi_utils_slack.py: 101-142
</a>
<div class="mid" id="frag3094" style="display:none"><pre>
def preprocessing_fn(inputs):
  """tf.transform's callback function for preprocessing inputs.

  Args:
    inputs: map from feature keys to raw not-yet-transformed features.

  Returns:
    Map from string feature key to transformed feature operations.
  """
  outputs = {}
  for key in _DENSE_FLOAT_FEATURE_KEYS:
    # If sparse make it dense, setting nan's to 0 or '', and apply zscore.
    outputs[_transformed_name(key)] = tft.scale_to_z_score(
        _fill_in_missing(inputs[key]))

  for key in _VOCAB_FEATURE_KEYS:
    # Build a vocabulary for this feature.
    outputs[_transformed_name(key)] = tft.compute_and_apply_vocabulary(
        _fill_in_missing(inputs[key]),
        top_k=_VOCAB_SIZE,
        num_oov_buckets=_OOV_SIZE)

  for key in _BUCKET_FEATURE_KEYS:
    outputs[_transformed_name(key)] = tft.bucketize(
        _fill_in_missing(inputs[key]), _FEATURE_BUCKET_COUNT)

  for key in _CATEGORICAL_FEATURE_KEYS:
    outputs[_transformed_name(key)] = _fill_in_missing(inputs[key])

  # Was this passenger a big tipper?
  taxi_fare = _fill_in_missing(inputs[_FARE_KEY])
  tips = _fill_in_missing(inputs[_LABEL_KEY])
  outputs[_transformed_name(_LABEL_KEY)] = tf.compat.v1.where(
      tf.math.is_nan(taxi_fare),
      tf.cast(tf.zeros_like(taxi_fare), tf.int64),
      # Test if the tip was &gt; 20% of the fare.
      tf.cast(
          tf.greater(tips, tf.multiply(taxi_fare, tf.constant(0.2))), tf.int64))

  return outputs


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<script language="JavaScript">
function ShowHide(divId) { 
    if(document.getElementById(divId).style.display == 'none') {
        document.getElementById(divId).style.display='block';
    } else { 
        document.getElementById(divId).style.display = 'none';
    } 
}
</script>
</body>
</html>
