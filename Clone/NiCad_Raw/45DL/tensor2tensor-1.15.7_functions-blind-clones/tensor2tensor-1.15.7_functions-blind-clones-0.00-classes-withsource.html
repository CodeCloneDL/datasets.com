<html>
<head>
    <title>NiCad6 Clone Report</title>
    <style type="text/css">
        body {font-family:sans-serif;}
        table {background-color:white; border:0px; padding:0px; border-spacing:4px; width:auto; margin-left:30px; margin-right:auto;}
        td {background-color:rgba(192,212,238,0.8); border:0px; padding:8px; width:auto; vertical-align:top; border-radius:8px}
        pre {background-color:white; padding:4px;}
        a {color:darkblue;}
    </style>
</head>
<body>
<h2>NiCad6 Clone Report</h2>
<table>
<tr style="font-size:14pt">
<td><b>System:</b> &nbsp; tensor2tensor-1.15.7</td>
<td><b>Clone pairs:</b> &nbsp; 149</td>
<td><b>Clone classes:</b> &nbsp; 53</td>
</tr>
<tr style="font-size:12pt">
<td style="background-color:white">Clone type: &nbsp; 2</td>
<td style="background-color:white">Granularity: &nbsp; functions-blind</td>
<td style="background-color:white">Max diff threshold: &nbsp; 0%</td>
<td style="background-color:white">Clone size: &nbsp; 10 - 2500 lines</td>
<td style="background-color:white">Total functions-blind: &nbsp; 5247</td>
</tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 1:</b> &nbsp; 8 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag25')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/wnli.py: 75-86
</a>
<div class="mid" id="frag25" style="display:none"><pre>
  def _maybe_download_corpora(self, tmp_dir):
    wnli_filename = "WNLI.zip"
    wnli_finalpath = os.path.join(tmp_dir, "WNLI")
    if not tf.gfile.Exists(wnli_finalpath):
      zip_filepath = generator_utils.maybe_download(
          tmp_dir, wnli_filename, self._WNLI_URL)
      zip_ref = zipfile.ZipFile(zip_filepath, "r")
      zip_ref.extractall(tmp_dir)
      zip_ref.close()

    return wnli_finalpath

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1717')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/cola.py: 71-82
</a>
<div class="mid" id="frag1717" style="display:none"><pre>
  def _maybe_download_corpora(self, tmp_dir):
    cola_filename = "CoLA.zip"
    cola_finalpath = os.path.join(tmp_dir, "CoLA")
    if not tf.gfile.Exists(cola_finalpath):
      zip_filepath = generator_utils.maybe_download(
          tmp_dir, cola_filename, self._COLA_URL)
      zip_ref = zipfile.ZipFile(zip_filepath, "r")
      zip_ref.extractall(tmp_dir)
      zip_ref.close()

    return cola_finalpath

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag448')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/stanford_nli.py: 70-81
</a>
<div class="mid" id="frag448" style="display:none"><pre>
  def _maybe_download_corpora(self, tmp_dir):
    snli_filename = "SNLI.zip"
    snli_finalpath = os.path.join(tmp_dir, "snli_1.0")
    if not tf.gfile.Exists(snli_finalpath):
      zip_filepath = generator_utils.maybe_download(
          tmp_dir, snli_filename, self._SNLI_URL)
      zip_ref = zipfile.ZipFile(zip_filepath, "r")
      zip_ref.extractall(tmp_dir)
      zip_ref.close()

    return snli_finalpath

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1488')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/sst_binary.py: 71-82
</a>
<div class="mid" id="frag1488" style="display:none"><pre>
  def _maybe_download_corpora(self, tmp_dir):
    sst_binary_filename = "SST-2.zip"
    sst_binary_finalpath = os.path.join(tmp_dir, "SST-2")
    if not tf.gfile.Exists(sst_binary_finalpath):
      zip_filepath = generator_utils.maybe_download(
          tmp_dir, sst_binary_filename, self._SST2_URL)
      zip_ref = zipfile.ZipFile(zip_filepath, "r")
      zip_ref.extractall(tmp_dir)
      zip_ref.close()

    return sst_binary_finalpath

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag661')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/scitail.py: 70-81
</a>
<div class="mid" id="frag661" style="display:none"><pre>
  def _maybe_download_corpora(self, tmp_dir):
    scitail_filename = "SciTailV1.1.zip"
    scitail_finalpath = os.path.join(tmp_dir, "SciTailV1.1")
    if not tf.gfile.Exists(scitail_finalpath):
      zip_filepath = generator_utils.maybe_download(
          tmp_dir, scitail_filename, self._SCITAIL_URL)
      zip_ref = zipfile.ZipFile(zip_filepath, "r")
      zip_ref.extractall(tmp_dir)
      zip_ref.close()

    return scitail_finalpath

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1014')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/quora_qpairs.py: 70-81
</a>
<div class="mid" id="frag1014" style="display:none"><pre>
  def _maybe_download_corpora(self, tmp_dir):
    qqp_filename = "QQP.zip"
    qqp_finalpath = os.path.join(tmp_dir, "QQP")
    if not tf.gfile.Exists(qqp_finalpath):
      zip_filepath = generator_utils.maybe_download(
          tmp_dir, qqp_filename, self._QQP_URL)
      zip_ref = zipfile.ZipFile(zip_filepath, "r")
      zip_ref.extractall(tmp_dir)
      zip_ref.close()

    return qqp_finalpath

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag85')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/qnli.py: 71-82
</a>
<div class="mid" id="frag85" style="display:none"><pre>
  def _maybe_download_corpora(self, tmp_dir):
    qnli_filename = "QNLI.zip"
    qnli_finalpath = os.path.join(tmp_dir, "QNLI")
    if not tf.gfile.Exists(qnli_finalpath):
      zip_filepath = generator_utils.maybe_download(
          tmp_dir, qnli_filename, self._QNLI_URL)
      zip_ref = zipfile.ZipFile(zip_filepath, "r")
      zip_ref.extractall(tmp_dir)
      zip_ref.close()

    return qnli_finalpath

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag798')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/rte.py: 71-82
</a>
<div class="mid" id="frag798" style="display:none"><pre>
  def _maybe_download_corpora(self, tmp_dir):
    rte_filename = "RTE.zip"
    rte_finalpath = os.path.join(tmp_dir, "RTE")
    if not tf.gfile.Exists(rte_finalpath):
      zip_filepath = generator_utils.maybe_download(
          tmp_dir, rte_filename, self._RTE_URL)
      zip_ref = zipfile.ZipFile(zip_filepath, "r")
      zip_ref.extractall(tmp_dir)
      zip_ref.close()

    return rte_finalpath

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 2:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag86')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/qnli.py: 83-95
</a>
<div class="mid" id="frag86" style="display:none"><pre>
  def example_generator(self, filename):
    label_list = self.class_labels(data_dir=None)
    for idx, line in enumerate(tf.gfile.Open(filename, "rb")):
      if idx == 0: continue  # skip header
      line = text_encoder.to_unicode_utf8(line.strip())
      _, s1, s2, l = line.split("\t")
      inputs = [s1, s2]
      l = label_list.index(l)
      yield {
          "inputs": inputs,
          "label": l
      }

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag799')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/rte.py: 83-95
</a>
<div class="mid" id="frag799" style="display:none"><pre>
  def example_generator(self, filename):
    label_list = self.class_labels(data_dir=None)
    for idx, line in enumerate(tf.gfile.Open(filename, "rb")):
      if idx == 0: continue  # skip header
      line = text_encoder.to_unicode_utf8(line.strip())
      _, s1, s2, l = line.split("\t")
      inputs = [s1, s2]
      l = label_list.index(l)
      yield {
          "inputs": inputs,
          "label": l
      }

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 3:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag151')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/wiki_multi_problems.py: 95-106
</a>
<div class="mid" id="frag151" style="display:none"><pre>
  def problems_and_rates(self):
    """Returns a list of (weight, also_reverse, problem_class) triples."""
    return [
        (1.0, True, wiki_lm.LanguagemodelDeEnFrRoWiki64kFitbPacked1k),
        (1.0, True, translate_ende.TranslateEndeWmtMulti64kPacked1k),
        (1.0, True, translate_enfr.TranslateEnfrWmtMulti64kPacked1k),
        (1.0, True, translate_enro.TranslateEnroWmtMultiTiny64kPacked1k),
        (1.0, True, cnn_dailymail.SummarizeCnnDailymailMulti64kPacked1k),
        (1.0, False, multinli.MultiNLIText2textMulti64kPacked1k),
        (1.0, False, squad.SquadText2textMulti64kPacked1k),
    ]

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag156')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/wiki_multi_problems.py: 130-142
</a>
<div class="mid" id="frag156" style="display:none"><pre>
  def problems_and_rates(self):
    """Returns a list of (weight, also_reverse, problem_class) triples."""
    return [
        (1.0, True, wiki_lm.LanguagemodelDeEnFrRoWiki64kFitbPacked1k),
        (3.0, True, translate_ende.TranslateEndeWmtMulti64kPacked1k),
        (1.0, True, translate_enfr.TranslateEnfrWmtMulti64kPacked1k),
        (100.0, True, translate_enro.TranslateEnroWmtMultiTiny64kPacked1k),
        (1.0, True, cnn_dailymail.SummarizeCnnDailymailMulti64kPacked1k),
        (10.0, False, multinli.MultiNLIText2textMulti64kPacked1k),
        (10.0, False, squad.SquadText2textMulti64kPacked1k),
    ]


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 4:</b> &nbsp; 3 fragments, nominal size 13 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag200')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/allen_brain.py: 346-361
</a>
<div class="mid" id="frag200" style="display:none"><pre>
  def example_reading_spec(self):
    data_fields = {
        "image/encoded": tf.FixedLenFeature((), tf.string),
        "image/format": tf.FixedLenFeature((), tf.string),
    }

    data_items_to_decoders = {
        "targets":
            contrib.slim().tfexample_decoder.Image(
                image_key="image/encoded",
                format_key="image/format",
                channels=self.num_channels),
    }

    return data_fields, data_items_to_decoders

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1642')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/image_utils.py: 168-183
</a>
<div class="mid" id="frag1642" style="display:none"><pre>
  def example_reading_spec(self):
    data_fields = {
        "image/encoded": tf.FixedLenFeature((), tf.string),
        "image/format": tf.FixedLenFeature((), tf.string),
    }

    data_items_to_decoders = {
        "inputs":
            contrib.slim().tfexample_decoder.Image(
                image_key="image/encoded",
                format_key="image/format",
                channels=self.num_channels),
    }

    return data_fields, data_items_to_decoders

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1530')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/video_utils.py: 672-687
</a>
<div class="mid" id="frag1530" style="display:none"><pre>
  def example_reading_spec(self):
    data_fields = {
        "image/encoded": tf.FixedLenFeature((), tf.string),
        "image/format": tf.FixedLenFeature((), tf.string),
    }

    data_items_to_decoders = {
        "inputs":
            contrib.slim().tfexample_decoder.Image(
                image_key="image/encoded",
                format_key="image/format",
                channels=self.num_channels),
    }

    return data_fields, data_items_to_decoders

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 5:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag215')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/imagenet_test.py: 35-46
</a>
<div class="mid" id="frag215" style="display:none"><pre>
  def testImagenetMultiResolutionPreprocessExample(self, resize_method):
    example = {"inputs": tf.random_uniform([64, 64, 3], minval=-1.)}
    mode = tf.estimator.ModeKeys.TRAIN
    hparams = hparam.HParams(resolutions=[8, 16, 32])
    if resize_method is not None:
      hparams.resize_method = resize_method

    problem = imagenet.ImageImagenetMultiResolutionGen()
    preprocessed_example = problem.preprocess_example(example, mode, hparams)
    self.assertLen(preprocessed_example, 1)
    self.assertEqual(preprocessed_example["inputs"].shape, (42, 32, 3))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag504')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/mscoco_test.py: 35-47
</a>
<div class="mid" id="frag504" style="display:none"><pre>
  def testMsCocoMultiResolutionPreprocessExample(self, resize_method):
    example = {"inputs": tf.random_uniform([400, 400, 3], minval=-1.)}
    mode = tf.estimator.ModeKeys.TRAIN
    hparams = hparam.HParams(resolutions=[8, 16, 32])
    if resize_method is not None:
      hparams.resize_method = resize_method

    problem = mscoco.ImageTextMsCocoMultiResolution()
    preprocessed_example = problem.preprocess_example(example, mode, hparams)
    self.assertLen(preprocessed_example, 1)
    self.assertEqual(preprocessed_example["inputs"].shape, (42, 32, 3))


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 6:</b> &nbsp; 2 fragments, nominal size 15 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag298')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/wiki_revision_utils.py: 275-307
</a>
<div class="mid" id="frag298" style="display:none"><pre>
def _find_and_replace(text, start_string, end_string, replace_fn):
  """Remove everything found between instances of start_string and end_string.

  Replace each such instance with replace_fn(removed_text)

  e.g. _find_and_replace("the [[fat]] cat [[sat]]", "[[", "]]", lambda x: x)
    = "the fat cat sat"

  Args:
    text: a string
    start_string: a string
    end_string: a string
    replace_fn: a unary function from string to string

  Returns:
    a string
  """
  ret = ""
  current_pos = 0
  while True:
    start_pos = text.find(start_string, current_pos)
    if start_pos == -1:
      ret += text[current_pos:]
      break
    ret += text[current_pos:start_pos]
    end_pos = text.find(end_string, start_pos + len(start_string))
    if end_pos == -1:
      break
    ret += replace_fn(text[start_pos + len(start_string):end_pos])
    current_pos = end_pos + len(end_string)
  return ret


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1285')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/wiki.py: 309-341
</a>
<div class="mid" id="frag1285" style="display:none"><pre>
def _find_and_replace(text, start_string, end_string, replace_fn):
  """Remove everything found between instances of start_string and end_string.

  Replace each such instance with replace_fn(removed_text)

  e.g. _find_and_replace(u"the [[fat]] cat [[sat]]", u"[[", u"]]", lambda x: x)
    = u"the fat cat sat"

  Args:
    text: a unicode string
    start_string: a unicode string
    end_string: a unicode string
    replace_fn: a unary function from unicode string to unicode string

  Returns:
    a string
  """
  ret = u""
  current_pos = 0
  while True:
    start_pos = text.find(start_string, current_pos)
    if start_pos == -1:
      ret += text[current_pos:]
      break
    ret += text[current_pos:start_pos]
    end_pos = text.find(end_string, start_pos + len(start_string))
    if end_pos == -1:
      break
    ret += replace_fn(text[start_pos + len(start_string):end_pos])
    current_pos = end_pos + len(end_string)
  return ret


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 7:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag371')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/problem_test.py: 99-112
</a>
<div class="mid" id="frag371" style="display:none"><pre>
  def testProblemHparamsInputOnlyModality(self):
    class InputOnlyProblem(problem_module.Problem):

      def hparams(self, defaults, model_hparams):
        hp = defaults
        hp.modality = {"inputs": modalities.ModalityType.SYMBOL}
        hp.vocab_size = {"inputs": 2}

    problem = InputOnlyProblem(False, False)
    p_hparams = problem.get_hparams()
    self.assertEqual(p_hparams.modality["inputs"],
                     modalities.ModalityType.SYMBOL)
    self.assertLen(p_hparams.modality, 1)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag373')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/problem_test.py: 114-127
</a>
<div class="mid" id="frag373" style="display:none"><pre>
  def testProblemHparamsTargetOnlyModality(self):
    class TargetOnlyProblem(problem_module.Problem):

      def hparams(self, defaults, model_hparams):
        hp = defaults
        hp.modality = {"targets": modalities.ModalityType.SYMBOL}
        hp.vocab_size = {"targets": 3}

    problem = TargetOnlyProblem(False, False)
    p_hparams = problem.get_hparams()
    self.assertEqual(p_hparams.modality["targets"],
                     modalities.ModalityType.SYMBOL)
    self.assertLen(p_hparams.modality, 1)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 8:</b> &nbsp; 8 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag393')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/wikitext103.py: 112-123
</a>
<div class="mid" id="frag393" style="display:none"><pre>
  def dataset_splits(self):
    return [{
        "split": problem.DatasetSplit.TRAIN,
        "shards": 10,
    }, {
        "split": problem.DatasetSplit.EVAL,
        "shards": 1,
    }, {
        "split": problem.DatasetSplit.TEST,
        "shards": 1,
    }]

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1598')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/lambada.py: 234-250
</a>
<div class="mid" id="frag1598" style="display:none"><pre>
  def dataset_splits(self):
    """Splits of data to produce and number of output shards for each.

    Returns:
      A dict containing splits information.
    """
    return [{
        "split": problem.DatasetSplit.TRAIN,
        "shards": 10,
    }, {
        "split": problem.DatasetSplit.EVAL,
        "shards": 1,
    }, {
        "split": problem.DatasetSplit.TEST,
        "shards": 1,
    }]

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1589')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/lambada.py: 143-159
</a>
<div class="mid" id="frag1589" style="display:none"><pre>
  def dataset_splits(self):
    """Splits of data to produce and number of output shards for each.

    Returns:
      A dict containing splits information.
    """
    return [{
        "split": problem.DatasetSplit.TRAIN,
        "shards": 10,
    }, {
        "split": problem.DatasetSplit.EVAL,
        "shards": 1,
    }, {
        "split": problem.DatasetSplit.TEST,
        "shards": 1,
    }]

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1344')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/wiki_lm.py: 109-121
</a>
<div class="mid" id="frag1344" style="display:none"><pre>
  def dataset_splits(self):
    """Splits of data to produce and number of output shards for each."""
    return [{
        "split": problem.DatasetSplit.TRAIN,
        "shards": 100,
    }, {
        "split": problem.DatasetSplit.EVAL,
        "shards": 1,
    }, {
        "split": problem.DatasetSplit.TEST,
        "shards": 1,
    }]

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1625')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/text_problems_test.py: 223-234
</a>
<div class="mid" id="frag1625" style="display:none"><pre>
  def dataset_splits(self):
    return [{
        "split": problem_lib.DatasetSplit.TRAIN,
        "shards": 2,
    }, {
        "split": problem_lib.DatasetSplit.EVAL,
        "shards": 3,
    }, {
        "split": problem_lib.DatasetSplit.TEST,
        "shards": 4,
    }]

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag999')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/mrpc.py: 53-64
</a>
<div class="mid" id="frag999" style="display:none"><pre>
  def dataset_splits(self):
    return [{
        "split": problem.DatasetSplit.TRAIN,
        "shards": 10,
    }, {
        "split": problem.DatasetSplit.EVAL,
        "shards": 1,
    }, {
        "split": problem.DatasetSplit.TEST,
        "shards": 1,
    }]

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1330')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/enwik8.py: 72-84
</a>
<div class="mid" id="frag1330" style="display:none"><pre>
  def dataset_splits(self):
    """Splits of data to produce and number of output shards for each."""
    return [{
        "split": problem.DatasetSplit.TRAIN,
        "shards": 16,
    }, {
        "split": problem.DatasetSplit.EVAL,
        "shards": 1,
    }, {
        "split": problem.DatasetSplit.TEST,
        "shards": 1,
    }]

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1134')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/dialog_abstract.py: 92-103
</a>
<div class="mid" id="frag1134" style="display:none"><pre>
  def dataset_splits(self):
    return [{
        'split': problem.DatasetSplit.TRAIN,
        'shards': 1,
    }, {
        'split': problem.DatasetSplit.EVAL,
        'shards': 1,
    }, {
        'split': problem.DatasetSplit.TEST,
        'shards': 1,
    }]

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 9:</b> &nbsp; 4 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag439')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/style_transfer_test.py: 29-42
</a>
<div class="mid" id="frag439" style="display:none"><pre>
  def testSourceAndTargetPathsTrainModern2Shakespeare(self):
    tmp_dir = "tmp_dir"
    modern_to_shakespeare_data_gen = (
        style_transfer.StyleTransferModernToShakespeare())
    actual_source, actual_target = (
        modern_to_shakespeare_data_gen.source_target_paths(
            problem.DatasetSplit.TRAIN, tmp_dir))

    expected_source = "{}/train.modern".format(tmp_dir)
    expected_target = "{}/train.original".format(tmp_dir)

    self.assertEqual(actual_source, expected_source)
    self.assertEqual(actual_target, expected_target)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag441')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/style_transfer_test.py: 57-70
</a>
<div class="mid" id="frag441" style="display:none"><pre>
  def testSourceAndTargetPathsDevModern2Shakespeare(self):
    tmp_dir = "tmp_dir"
    modern_to_shakespeare_data_gen = (
        style_transfer.StyleTransferModernToShakespeare())
    actual_source, actual_target = (
        modern_to_shakespeare_data_gen.source_target_paths(
            problem.DatasetSplit.EVAL, tmp_dir))

    expected_source = "{}/dev.modern".format(tmp_dir)
    expected_target = "{}/dev.original".format(tmp_dir)

    self.assertEqual(actual_source, expected_source)
    self.assertEqual(actual_target, expected_target)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag442')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/style_transfer_test.py: 71-85
</a>
<div class="mid" id="frag442" style="display:none"><pre>
  def testSourceAndTargetPathsDevShakespeare2Modern(self):
    tmp_dir = "tmp_dir"
    shakespeare_to_modern_data_gen = (
        style_transfer.StyleTransferShakespeareToModern())
    actual_source, actual_target = (
        shakespeare_to_modern_data_gen.source_target_paths(
            problem.DatasetSplit.EVAL, tmp_dir))

    expected_source = "{}/dev.original".format(tmp_dir)
    expected_target = "{}/dev.modern".format(tmp_dir)

    self.assertEqual(actual_source, expected_source)
    self.assertEqual(actual_target, expected_target)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag440')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/style_transfer_test.py: 43-56
</a>
<div class="mid" id="frag440" style="display:none"><pre>
  def testSourceAndTargetPathsTrainShakespeare2Modern(self):
    tmp_dir = "tmp_dir"
    shakespeare_to_modern_data_gen = (
        style_transfer.StyleTransferShakespeareToModern())
    actual_source, actual_target = (
        shakespeare_to_modern_data_gen.source_target_paths(
            problem.DatasetSplit.TRAIN, tmp_dir))

    expected_source = "{}/train.original".format(tmp_dir)
    expected_target = "{}/train.modern".format(tmp_dir)

    self.assertEqual(actual_source, expected_source)
    self.assertEqual(actual_target, expected_target)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 10:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag466')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/celeba.py: 96-106
</a>
<div class="mid" id="frag466" style="display:none"><pre>
    def process_landmarks(raw_data):
      landmarks = {}
      lines = raw_data.split("\n")
      headings = lines[1].strip().split()
      for line in lines[2:-1]:
        values = line.strip().split()
        img_name = values[0]
        landmark_values = [int(v) for v in values[1:]]
        landmarks[img_name] = landmark_values
      return landmarks, headings

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag467')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/celeba.py: 107-117
</a>
<div class="mid" id="frag467" style="display:none"><pre>
    def process_attrs(raw_data):
      attrs = {}
      lines = raw_data.split("\n")
      headings = lines[1].strip().split()
      for line in lines[2:-1]:
        values = line.strip().split()
        img_name = values[0]
        attr_values = [int(v) for v in values[1:]]
        attrs[img_name] = attr_values
      return attrs, headings

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 11:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag841')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/yelp_polarity.py: 63-75
</a>
<div class="mid" id="frag841" style="display:none"><pre>
  def doc_generator(self, yelp_dir, dataset, include_label=False):

    file_path = os.path.join(yelp_dir, dataset + ".csv")
    with tf.gfile.Open(file_path) as yelp_f:
      lines = yelp_f.readlines()
      for line in lines:
        label = line[1]
        doc = line[5:-2].strip()
        if include_label:
          yield doc, label
        else:
          yield doc

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1562')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/yelp_full.py: 63-75
</a>
<div class="mid" id="frag1562" style="display:none"><pre>
  def doc_generator(self, yelp_dir, dataset, include_label=False):

    file_path = os.path.join(yelp_dir, dataset + ".csv")
    with tf.gfile.Open(file_path) as yelp_f:
      lines = yelp_f.readlines()
      for line in lines:
        label = line[1]
        doc = line[5:-2].strip()
        if include_label:
          yield doc, label
        else:
          yield doc

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 12:</b> &nbsp; 3 fragments, nominal size 15 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag842')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/yelp_polarity.py: 76-96
</a>
<div class="mid" id="frag842" style="display:none"><pre>
  def generate_samples(self, data_dir, tmp_dir, dataset_split):
    """Generate examples."""
    # Download and extract
    compressed_filename = os.path.basename(self.URL)
    download_path = generator_utils.maybe_download(tmp_dir, compressed_filename,
                                                   self.URL)
    yelp_dir = os.path.join(tmp_dir, "yelp_review_polarity_csv")
    if not tf.gfile.Exists(yelp_dir):
      with tarfile.open(download_path, "r:gz") as tar:
        tar.extractall(tmp_dir)

    # Generate examples
    train = dataset_split == problem.DatasetSplit.TRAIN
    dataset = "train" if train else "test"
    for doc, label in self.doc_generator(yelp_dir, dataset, include_label=True):
      yield {
          "inputs": doc,
          "label": int(label),
      }


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag941')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/imdb.py: 76-96
</a>
<div class="mid" id="frag941" style="display:none"><pre>
  def generate_samples(self, data_dir, tmp_dir, dataset_split):
    """Generate examples."""
    # Download and extract
    compressed_filename = os.path.basename(self.URL)
    download_path = generator_utils.maybe_download(tmp_dir, compressed_filename,
                                                   self.URL)
    imdb_dir = os.path.join(tmp_dir, "aclImdb")
    if not tf.gfile.Exists(imdb_dir):
      with tarfile.open(download_path, "r:gz") as tar:
        tar.extractall(tmp_dir)

    # Generate examples
    train = dataset_split == problem.DatasetSplit.TRAIN
    dataset = "train" if train else "test"
    for doc, label in self.doc_generator(imdb_dir, dataset, include_label=True):
      yield {
          "inputs": doc,
          "label": int(label),
      }


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1563')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/yelp_full.py: 76-96
</a>
<div class="mid" id="frag1563" style="display:none"><pre>
  def generate_samples(self, data_dir, tmp_dir, dataset_split):
    """Generate examples."""
    # Download and extract
    compressed_filename = os.path.basename(self.URL)
    download_path = generator_utils.maybe_download(tmp_dir, compressed_filename,
                                                   self.URL)
    yelp_dir = os.path.join(tmp_dir, "yelp_review_full_csv")
    if not tf.gfile.Exists(yelp_dir):
      with tarfile.open(download_path, "r:gz") as tar:
        tar.extractall(tmp_dir)

    # Generate examples
    train = dataset_split == problem.DatasetSplit.TRAIN
    dataset = "train" if train else "test"
    for doc, label in self.doc_generator(yelp_dir, dataset, include_label=True):
      yield {
          "inputs": doc,
          "label": int(label),
      }


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 13:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1120')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/algorithmic_test.py: 79-89
</a>
<div class="mid" id="frag1120" style="display:none"><pre>
  def testAdditionGenerator(self):
    addition_problem = algorithmic.AlgorithmicAdditionBinary40()
    counter = 0
    for d in addition_problem.generator(4, 8, 10):
      counter += 1
      self.assertEqual(d["inputs"].count(4), 1)
      self.assertEqual(d["inputs"].count(5), 0)
      self.assertEqual(d["targets"].count(4), 0)
      self.assertEqual(d["targets"].count(5), 0)
    self.assertEqual(counter, 10)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1121')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/algorithmic_test.py: 90-100
</a>
<div class="mid" id="frag1121" style="display:none"><pre>
  def testMultiplicationGenerator(self):
    multiplication_problem = algorithmic.AlgorithmicMultiplicationBinary40()
    counter = 0
    for d in multiplication_problem.generator(4, 8, 10):
      counter += 1
      self.assertEqual(d["inputs"].count(4), 1)
      self.assertEqual(d["inputs"].count(5), 0)
      self.assertEqual(d["targets"].count(4), 0)
      self.assertEqual(d["targets"].count(5), 0)
    self.assertEqual(counter, 10)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 14:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1445')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/common_voice.py: 157-178
</a>
<div class="mid" id="frag1445" style="display:none"><pre>
  def generate_data(self, data_dir, tmp_dir, task_id=-1):
    train_paths = self.training_filepaths(
        data_dir, self.num_shards, shuffled=False)
    dev_paths = self.dev_filepaths(
        data_dir, self.num_dev_shards, shuffled=False)
    test_paths = self.test_filepaths(
        data_dir, self.num_test_shards, shuffled=True)

    generator_utils.generate_files(
        self.generator(data_dir, tmp_dir, self.TEST_DATASETS), test_paths)

    if self.use_train_shards_for_dev:
      all_paths = train_paths + dev_paths
      generator_utils.generate_files(
          self.generator(data_dir, tmp_dir, self.TRAIN_DATASETS), all_paths)
      generator_utils.shuffle_dataset(all_paths)
    else:
      generator_utils.generate_dataset_and_shuffle(
          self.generator(data_dir, tmp_dir, self.TRAIN_DATASETS), train_paths,
          self.generator(data_dir, tmp_dir, self.DEV_DATASETS), dev_paths)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1573')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/librispeech.py: 160-181
</a>
<div class="mid" id="frag1573" style="display:none"><pre>
  def generate_data(self, data_dir, tmp_dir, task_id=-1):
    train_paths = self.training_filepaths(
        data_dir, self.num_shards, shuffled=False)
    dev_paths = self.dev_filepaths(
        data_dir, self.num_dev_shards, shuffled=False)
    test_paths = self.test_filepaths(
        data_dir, self.num_test_shards, shuffled=True)

    generator_utils.generate_files(
        self.generator(data_dir, tmp_dir, self.TEST_DATASETS), test_paths)

    if self.use_train_shards_for_dev:
      all_paths = train_paths + dev_paths
      generator_utils.generate_files(
          self.generator(data_dir, tmp_dir, self.TRAIN_DATASETS), all_paths)
      generator_utils.shuffle_dataset(all_paths)
    else:
      generator_utils.generate_dataset_and_shuffle(
          self.generator(data_dir, tmp_dir, self.TRAIN_DATASETS), train_paths,
          self.generator(data_dir, tmp_dir, self.DEV_DATASETS), dev_paths)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 15:</b> &nbsp; 3 fragments, nominal size 13 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1450')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/common_voice.py: 195-226
</a>
<div class="mid" id="frag1450" style="display:none"><pre>
  def filepattern(self, data_dir, mode, shard=None):
    """Get filepattern for data files for mode.

    Matches mode to a suffix.
    * DatasetSplit.TRAIN: train
    * DatasetSplit.EVAL: dev
    * DatasetSplit.TEST: test
    * tf.estimator.ModeKeys.PREDICT: dev

    Args:
      data_dir: str, data directory.
      mode: DatasetSplit
      shard: int, if provided, will only read data from the specified shard.

    Returns:
      filepattern str
    """
    shard_str = "-%05d" % shard if shard is not None else ""
    if mode == problem.DatasetSplit.TRAIN:
      path = os.path.join(data_dir, "common_voice")
      suffix = "train"
    elif mode in [problem.DatasetSplit.EVAL, tf.estimator.ModeKeys.PREDICT]:
      path = os.path.join(data_dir, "common_voice_clean")
      suffix = "dev"
    else:
      assert mode == problem.DatasetSplit.TEST
      path = os.path.join(data_dir, "common_voice_clean")
      suffix = "test"

    return "%s-%s%s*" % (path, suffix, shard_str)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1583')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/librispeech.py: 246-277
</a>
<div class="mid" id="frag1583" style="display:none"><pre>
  def filepattern(self, data_dir, mode, shard=None):
    """Get filepattern for data files for mode.

    Matches mode to a suffix.
    * DatasetSplit.TRAIN: train
    * DatasetSplit.EVAL: dev
    * DatasetSplit.TEST: test
    * tf.estimator.ModeKeys.PREDICT: dev

    Args:
      data_dir: str, data directory.
      mode: DatasetSplit
      shard: int, if provided, will only read data from the specified shard.

    Returns:
      filepattern str
    """
    shard_str = "-%05d" % shard if shard is not None else ""
    if mode == problem.DatasetSplit.TRAIN:
      path = os.path.join(data_dir, "librispeech")
      suffix = "train"
    elif mode in [problem.DatasetSplit.EVAL, tf.estimator.ModeKeys.PREDICT]:
      path = os.path.join(data_dir, "librispeech_noisy")
      suffix = "dev"
    else:
      assert mode == problem.DatasetSplit.TEST
      path = os.path.join(data_dir, "librispeech_noisy")
      suffix = "test"

    return "%s-%s%s*" % (path, suffix, shard_str)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1578')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/data_generators/librispeech.py: 198-229
</a>
<div class="mid" id="frag1578" style="display:none"><pre>
  def filepattern(self, data_dir, mode, shard=None):
    """Get filepattern for data files for mode.

    Matches mode to a suffix.
    * DatasetSplit.TRAIN: train
    * DatasetSplit.EVAL: dev
    * DatasetSplit.TEST: test
    * tf.estimator.ModeKeys.PREDICT: dev

    Args:
      data_dir: str, data directory.
      mode: DatasetSplit
      shard: int, if provided, will only read data from the specified shard.

    Returns:
      filepattern str
    """
    shard_str = "-%05d" % shard if shard is not None else ""
    if mode == problem.DatasetSplit.TRAIN:
      path = os.path.join(data_dir, "librispeech")
      suffix = "train"
    elif mode in [problem.DatasetSplit.EVAL, tf.estimator.ModeKeys.PREDICT]:
      path = os.path.join(data_dir, "librispeech_clean")
      suffix = "dev"
    else:
      assert mode == problem.DatasetSplit.TEST
      path = os.path.join(data_dir, "librispeech_clean")
      suffix = "test"

    return "%s-%s%s*" % (path, suffix, shard_str)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 16:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1831')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/mtf_transformer2.py: 44-56
</a>
<div class="mid" id="frag1831" style="display:none"><pre>
  def batch_dims(self):
    hparams = self._hparams
    if hparams.outer_batch_size == 0:
      return [mtf.Dimension("batch", hparams.batch_size)]
    else:
      if hparams.batch_size % hparams.outer_batch_size != 0:
        raise ValueError(
            "hparams.outer_batch_size must divide hparams.batch_size")
      return [
          mtf.Dimension("outer_batch", hparams.outer_batch_size),
          mtf.Dimension("inner_batch",
                        hparams.batch_size // hparams.outer_batch_size)]

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2093')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/mtf_transformer.py: 60-72
</a>
<div class="mid" id="frag2093" style="display:none"><pre>
  def batch_dims(self):
    hparams = self._hparams
    if hparams.outer_batch_size == 0:
      return [mtf.Dimension("batch", hparams.batch_size)]
    else:
      if hparams.batch_size % hparams.outer_batch_size != 0:
        raise ValueError(
            "hparams.outer_batch_size must divide hparams.batch_size")
      return [
          mtf.Dimension("outer_batch", hparams.outer_batch_size),
          mtf.Dimension("inner_batch",
                        hparams.batch_size // hparams.outer_batch_size)]

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 17:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1907')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/mtf_resnet.py: 199-211
</a>
<div class="mid" id="frag1907" style="display:none"><pre>
  def set_activation_type(self):
    hparams = self._hparams
    if hparams.activation_dtype == "float32":
      activation_dtype = tf.float32
    elif hparams.activation_dtype == "float16":
      activation_dtype = tf.float16
    elif hparams.activation_dtype == "bfloat16":
      activation_dtype = tf.bfloat16
    else:
      raise ValueError(
          "unknown hparams.activation_dtype %s" % hparams.activation_dtype)
    return activation_dtype

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2596')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/mtf_image_transformer.py: 108-120
</a>
<div class="mid" id="frag2596" style="display:none"><pre>
  def activation_type(self):
    hparams = self._hparams
    if hparams.activation_dtype == "float32":
      activation_dtype = tf.float32
    elif hparams.activation_dtype == "float16":
      activation_dtype = tf.float16
    elif hparams.activation_dtype == "bfloat16":
      activation_dtype = tf.bfloat16
    else:
      raise ValueError(
          "unknown hparams.activation_dtype %s" % hparams.activation_dtype)
    return activation_dtype

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 18:</b> &nbsp; 2 fragments, nominal size 17 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1916')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/mtf_image_transformer_test.py: 74-95
</a>
<div class="mid" id="frag1916" style="display:none"><pre>
  def testMtfImageTransformer(self):
    hparams = mtf_image_transformer.mtf_image_transformer_single()

    # need to know layout ahead of time for local attention.
    hparams.mesh_shape = ""
    hparams.layout = ""
    model, features, hparams = get_model(hparams)
    mesh, mesh_impl = get_placement_mesh(hparams)

    logits, _ = model.mtf_model_fn(features, mesh)
    lowering = mtf.Lowering(mesh.graph, {mesh: mesh_impl})
    tf_group = lowering.copy_masters_to_slices()
    tf_logits = lowering.export_to_tf_tensor(logits)

    with self.test_session() as session:
      session.run(tf.global_variables_initializer())
      session.run(tf_group)
      res = session.run(tf_logits)
    self.assertEqual(res.shape,
                     (BATCH_SIZE, IMG_LENGTH, IMG_LENGTH,
                      hparams.num_channels, VOCAB_SIZE))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1917')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/mtf_image_transformer_test.py: 96-117
</a>
<div class="mid" id="frag1917" style="display:none"><pre>
  def testMtfImageTransformerDataParallel(self):
    hparams = mtf_image_transformer.mtf_image_transformer_single()

    # need to know layout ahead of time for local attention.
    hparams.mesh_shape = "all:2"
    hparams.layout = "batch:all"
    model, features, hparams = get_model(hparams)
    mesh, mesh_impl = get_placement_mesh(hparams)

    logits, _ = model.mtf_model_fn(features, mesh)
    lowering = mtf.Lowering(mesh.graph, {mesh: mesh_impl})
    tf_group = lowering.copy_masters_to_slices()
    tf_logits = lowering.export_to_tf_tensor(logits)

    with self.test_session() as session:
      session.run(tf.global_variables_initializer())
      session.run(tf_group)
      res = session.run(tf_logits)
    self.assertEqual(res.shape,
                     (BATCH_SIZE, IMG_LENGTH, IMG_LENGTH,
                      hparams.num_channels, VOCAB_SIZE))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 19:</b> &nbsp; 2 fragments, nominal size 15 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1929')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/image_transformer.py: 302-319
</a>
<div class="mid" id="frag1929" style="display:none"><pre>
def imagetransformer_base_tpu():
  """Transformer base params for cifar-10."""
  hparams = imagetransformer_bas8l_8h_big_uncond_dr03_imgnet()
  update_hparams_for_tpu(hparams)
  hparams.batch_size = 4
  hparams.num_heads = 4   # heads are expensive on tpu
  hparams.num_decoder_layers = 12
  hparams.block_length = 128
  hparams.hidden_size = 512
  hparams.filter_size = 2048
  hparams.learning_rate = 0.2
  hparams.learning_rate_warmup_steps = 6000
  hparams.layer_preprocess_sequence = "none"
  hparams.layer_postprocess_sequence = "dan"
  hparams.layer_prepostprocess_dropout = 0.3
  return hparams


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1995')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/image_transformer.py: 1066-1083
</a>
<div class="mid" id="frag1995" style="display:none"><pre>
def imagetransformer_b12l_4h_b128_h512_uncond_dr03_tpu():
  """TPU related big model."""
  hparams = imagetransformer_bas8l_8h_big_uncond_dr03_imgnet()
  update_hparams_for_tpu(hparams)
  hparams.batch_size = 4
  hparams.num_heads = 4   # heads are expensive on tpu
  hparams.num_decoder_layers = 12
  hparams.block_length = 128
  hparams.hidden_size = 512
  hparams.filter_size = 2048
  hparams.learning_rate = 0.2
  hparams.learning_rate_warmup_steps = 6000
  hparams.layer_preprocess_sequence = "none"
  hparams.layer_postprocess_sequence = "dan"
  hparams.layer_prepostprocess_dropout = 0.3
  return hparams


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 20:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1965')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/image_transformer.py: 688-703
</a>
<div class="mid" id="frag1965" style="display:none"><pre>
def imagetransformer1d_base_8l_64by64():
  """hparams fo 12 layer big 1d model for imagenet 64x64."""
  hparams = image_transformer_base()
  hparams.num_heads = 8
  hparams.hidden_size = 512
  hparams.filter_size = 2048
  hparams.num_decoder_layers = 8
  hparams.batch_size = 1
  hparams.block_length = 512
  hparams.block_width = 768
  hparams.layer_prepostprocess_dropout = 0.1
  hparams.max_length = 14000
  hparams.unconditional = int(False)
  return hparams


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1966')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/image_transformer.py: 705-720
</a>
<div class="mid" id="frag1966" style="display:none"><pre>
def imagetransformer1d_base_12l_64by64():
  """hparams fo 12 layer big 1d model for imagenet 64x64."""
  hparams = image_transformer_base()
  hparams.num_heads = 8
  hparams.hidden_size = 512
  hparams.filter_size = 2048
  hparams.num_decoder_layers = 12
  hparams.batch_size = 1
  hparams.block_length = 512
  hparams.block_width = 768
  hparams.layer_prepostprocess_dropout = 0.1
  hparams.max_length = 14000
  hparams.unconditional = int(False)
  return hparams


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 21:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1990')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/image_transformer.py: 999-1014
</a>
<div class="mid" id="frag1990" style="display:none"><pre>
def imagetransformer_b12l_4h_big_uncond_dr03_tpu():
  """TPU 12 layer model."""
  hparams = imagetransformer_bas8l_8h_big_uncond_dr03_imgnet()
  update_hparams_for_tpu(hparams)
  hparams.batch_size = 4
  hparams.num_heads = 4   # heads are expensive on tpu
  hparams.num_decoder_layers = 12
  hparams.block_length = 128
  hparams.hidden_size = 512
  hparams.filter_size = 1024
  hparams.layer_preprocess_sequence = "none"
  hparams.layer_postprocess_sequence = "dan"
  hparams.layer_prepostprocess_dropout = 0.3
  return hparams


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1999')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/image_transformer.py: 1130-1145
</a>
<div class="mid" id="frag1999" style="display:none"><pre>
def imagetransformer_b12l_8h_b256_uncond_dr03_tpu():
  """TPU related 12 layer 8 heads model."""
  hparams = imagetransformer_bas8l_8h_big_uncond_dr03_imgnet()
  update_hparams_for_tpu(hparams)
  hparams.batch_size = 2
  hparams.num_heads = 8   # heads are expensive on tpu
  hparams.num_decoder_layers = 12
  hparams.block_length = 256
  hparams.hidden_size = 512
  hparams.filter_size = 2048
  hparams.layer_preprocess_sequence = "none"
  hparams.layer_postprocess_sequence = "dan"
  hparams.layer_prepostprocess_dropout = 0.3
  return hparams


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 22:</b> &nbsp; 2 fragments, nominal size 19 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2023')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/lstm_test.py: 75-94
</a>
<div class="mid" id="frag2023" style="display:none"><pre>
  def testLSTMSeq2seqBidirectionalEncoder(self):
    vocab_size = 9
    x = np.random.randint(1, high=vocab_size, size=(3, 5, 1, 1))
    y = np.random.randint(1, high=vocab_size, size=(3, 6, 1, 1))
    hparams = lstm.lstm_seq2seq()
    p_hparams = problem_hparams.test_problem_hparams(vocab_size,
                                                     vocab_size,
                                                     hparams)
    with self.test_session() as session:
      features = {
          "inputs": tf.constant(x, dtype=tf.int32),
          "targets": tf.constant(y, dtype=tf.int32),
      }
      model = lstm.LSTMSeq2seqBidirectionalEncoder(
          hparams, tf.estimator.ModeKeys.TRAIN, p_hparams)
      logits, _ = model(features)
      session.run(tf.global_variables_initializer())
      res = session.run(logits)
    self.assertEqual(res.shape, (3, 6, 1, 1, vocab_size))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2575')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/bytenet_test.py: 31-51
</a>
<div class="mid" id="frag2575" style="display:none"><pre>
  def testByteNet(self):
    vocab_size = 9
    x = np.random.randint(1, high=vocab_size, size=(3, 5, 1, 1))
    y = np.random.randint(1, high=vocab_size, size=(3, 6, 1, 1))
    hparams = bytenet.bytenet_base()
    p_hparams = problem_hparams.test_problem_hparams(vocab_size,
                                                     vocab_size,
                                                     hparams)
    with self.test_session() as session:
      features = {
          "inputs": tf.constant(x, dtype=tf.int32),
          "targets": tf.constant(y, dtype=tf.int32),
      }
      model = bytenet.ByteNet(
          hparams, tf.estimator.ModeKeys.TRAIN, p_hparams)
      logits, _ = model(features)
      session.run(tf.global_variables_initializer())
      res = session.run(logits)
    self.assertEqual(res.shape, (3, 50, 1, 1, vocab_size))


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 23:</b> &nbsp; 2 fragments, nominal size 20 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2064')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/neural_assistant.py: 509-532
</a>
<div class="mid" id="frag2064" style="display:none"><pre>
def neural_assistant_base():
  """HParams for a base neural_assistant model."""
  hparams = transformer.transformer_tpu()
  hparams.add_hparam("pos_weight", 1.0)  # weight for positive triples
  hparams.add_hparam("similarity_fuction",
                     "bilinear")  # dot_product or bilinear
  hparams.add_hparam("pool_technique", "average")  # avg or max pool or last
  hparams.add_hparam("last_k", 1)  # number of last indices for averaging
  hparams.add_hparam("max_triple_length", 30)  # max length of every triple
  hparams.add_hparam("train_triple_num",
                     5000)  # max number of triples during training
  hparams.add_hparam("attend_kb", True)  # if False, it's a transformer model
  hparams.add_hparam("kb_loss_weight", 0.0)  # weight for distant supervision
  hparams.add_hparam("test_triple_num",
                     28483)  # max triples of KB
  hparams.add_hparam("margin", 0.0)  # KB training max-margin loss
  hparams.add_hparam(
      "num_negative_samples",
      1)  # Sampling number of different adversarial training examples
  hparams.add_hparam("kb_train_weight", 0.0)
  # KB_training loss weight which combines Language model and KB selection loss
  return hparams


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2065')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/neural_assistant.py: 534-557
</a>
<div class="mid" id="frag2065" style="display:none"><pre>
def neural_assistant_tiny():
  """HParams for tiny neural_assistant model."""
  hparams = transformer.transformer_tiny_tpu()
  hparams.add_hparam("pos_weight", 1.0)  # weight for positive triples
  hparams.add_hparam("similarity_fuction",
                     "bilinear")  # dot_product or bilinear
  hparams.add_hparam("pool_technique", "average")  # avg or max pool or last
  hparams.add_hparam("last_k", 1)  # number of last indices for averaging
  hparams.add_hparam("max_triple_length", 30)  # max length of every triple
  hparams.add_hparam("train_triple_num",
                     5000)  # max number of triples during training
  hparams.add_hparam("attend_kb", True)  # if False, it's a transformer model
  hparams.add_hparam("kb_loss_weight", 0.0)  # weight for distant supervision
  hparams.add_hparam("test_triple_num",
                     28483)  # max triples of KB
  hparams.add_hparam("margin", 1.0)  # KB training max-margin loss
  hparams.add_hparam(
      "num_negative_samples",
      1)  # Sampling number of different adversarial training examples
  hparams.add_hparam("kb_train_weight", 0.0)
  # KB_training loss weight which combines Language model and KB selection loss
  return hparams


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 24:</b> &nbsp; 5 fragments, nominal size 15 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2069')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/mtf_transformer_test.py: 78-96
</a>
<div class="mid" id="frag2069" style="display:none"><pre>
  def testMtfTransformer(self):
    hparams = mtf_transformer.mtf_transformer_single()

    model, features, hparams = get_model(hparams)
    hparams.mesh_shape = ""
    hparams.layout = ""
    mesh, mesh_impl = get_placement_mesh(hparams)

    logits, _ = model.mtf_model_fn(features, mesh)
    lowering = mtf.Lowering(mesh.graph, {mesh: mesh_impl})
    tf_group = lowering.copy_masters_to_slices()
    tf_logits = lowering.export_to_tf_tensor(logits)

    with self.test_session() as session:
      session.run(tf.global_variables_initializer())
      session.run(tf_group)
      res = session.run(tf_logits)
    self.assertEqual(res.shape, (BATCH_SIZE, TARGET_LENGTH, VOCAB_SIZE))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2072')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/mtf_transformer_test.py: 135-153
</a>
<div class="mid" id="frag2072" style="display:none"><pre>
  def testMtfTransformerDataModelParallel(self):
    hparams = mtf_transformer.mtf_transformer_single()

    model, features, hparams = get_model(hparams)
    hparams.mesh_shape = "batch:2;model:2"
    hparams.layout = "batch:batch;vocab:model;d_ff:model;heads:model"
    mesh, mesh_impl = get_placement_mesh(hparams)

    logits, _ = model.mtf_model_fn(features, mesh)
    lowering = mtf.Lowering(mesh.graph, {mesh: mesh_impl})
    tf_group = lowering.copy_masters_to_slices()
    tf_logits = lowering.export_to_tf_tensor(logits)

    with self.test_session() as session:
      session.run(tf.global_variables_initializer())
      session.run(tf_group)
      res = session.run(tf_logits)
    self.assertEqual(res.shape, (BATCH_SIZE, TARGET_LENGTH, VOCAB_SIZE))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2071')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/mtf_transformer_test.py: 116-134
</a>
<div class="mid" id="frag2071" style="display:none"><pre>
  def testMtfTransformerModelParallel(self):
    hparams = mtf_transformer.mtf_transformer_single()

    model, features, hparams = get_model(hparams)
    hparams.mesh_shape = "all:2"
    hparams.layout = "length:all"
    mesh, mesh_impl = get_placement_mesh(hparams)

    logits, _ = model.mtf_model_fn(features, mesh)
    lowering = mtf.Lowering(mesh.graph, {mesh: mesh_impl})
    tf_group = lowering.copy_masters_to_slices()
    tf_logits = lowering.export_to_tf_tensor(logits)

    with self.test_session() as session:
      session.run(tf.global_variables_initializer())
      session.run(tf_group)
      res = session.run(tf_logits)
    self.assertEqual(res.shape, (BATCH_SIZE, TARGET_LENGTH, VOCAB_SIZE))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2073')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/mtf_transformer_test.py: 154-173
</a>
<div class="mid" id="frag2073" style="display:none"><pre>
  def testMtfTransformerEncoderDataModelParallel(self):
    hparams = mtf_transformer.mtf_transformer_enc_single()

    model, features, hparams = get_model(hparams)
    hparams.mesh_shape = "batch:2;model:2"
    hparams.layout = "batch:batch;vocab:model;d_ff:model;heads:model"
    mesh, mesh_impl = get_placement_mesh(hparams)

    logits, _ = model.mtf_model_fn(features, mesh)
    lowering = mtf.Lowering(mesh.graph, {mesh: mesh_impl})
    tf_group = lowering.copy_masters_to_slices()
    tf_logits = lowering.export_to_tf_tensor(logits)

    with self.test_session() as session:
      session.run(tf.global_variables_initializer())
      session.run(tf_group)
      res = session.run(tf_logits)
    self.assertEqual(res.shape, (BATCH_SIZE, TARGET_LENGTH, VOCAB_SIZE))


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2070')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/mtf_transformer_test.py: 97-115
</a>
<div class="mid" id="frag2070" style="display:none"><pre>
  def testMtfTransformerDataParallel(self):
    hparams = mtf_transformer.mtf_transformer_single()

    model, features, hparams = get_model(hparams)
    hparams.mesh_shape = "all:2"
    hparams.layout = "batch:all"
    mesh, mesh_impl = get_placement_mesh(hparams)

    logits, _ = model.mtf_model_fn(features, mesh)
    lowering = mtf.Lowering(mesh.graph, {mesh: mesh_impl})
    tf_group = lowering.copy_masters_to_slices()
    tf_logits = lowering.export_to_tf_tensor(logits)

    with self.test_session() as session:
      session.run(tf.global_variables_initializer())
      session.run(tf_group)
      res = session.run(tf_logits)
    self.assertEqual(res.shape, (BATCH_SIZE, TARGET_LENGTH, VOCAB_SIZE))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 25:</b> &nbsp; 2 fragments, nominal size 20 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2074')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/slicenet_test.py: 34-54
</a>
<div class="mid" id="frag2074" style="display:none"><pre>
  def testSliceNet(self):
    x = np.random.randint(256, size=(3, 5, 5, 3))
    y = np.random.randint(10, size=(3, 5, 1, 1))
    hparams = slicenet.slicenet_params1_tiny()
    hparams.add_hparam("data_dir", "")
    problem = registry.problem("image_cifar10")
    p_hparams = problem.get_hparams(hparams)
    hparams.problem_hparams = p_hparams
    with self.test_session() as session:
      features = {
          "inputs": tf.constant(x, dtype=tf.int32),
          "targets": tf.constant(y, dtype=tf.int32),
          "target_space_id": tf.constant(1, dtype=tf.int32),
      }
      model = slicenet.SliceNet(hparams, tf.estimator.ModeKeys.TRAIN,
                                p_hparams)
      logits, _ = model(features)
      session.run(tf.global_variables_initializer())
      res = session.run(logits)
    self.assertEqual(res.shape, (3, 1, 1, 1, 10))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2075')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/slicenet_test.py: 55-76
</a>
<div class="mid" id="frag2075" style="display:none"><pre>
  def testSliceNetImageToText(self):
    x = np.random.randint(256, size=(3, 5, 5, 3))
    y = np.random.randint(10, size=(3, 5, 1, 1))
    hparams = slicenet.slicenet_params1_tiny()
    hparams.add_hparam("data_dir", "")
    problem = registry.problem("image_ms_coco_characters")
    p_hparams = problem.get_hparams(hparams)
    hparams.problem_hparams = p_hparams
    with self.test_session() as session:
      features = {
          "inputs": tf.constant(x, dtype=tf.int32),
          "targets": tf.constant(y, dtype=tf.int32),
          "target_space_id": tf.constant(1, dtype=tf.int32),
      }
      model = slicenet.SliceNet(hparams, tf.estimator.ModeKeys.TRAIN,
                                p_hparams)
      logits, _ = model(features)
      session.run(tf.global_variables_initializer())
      res = session.run(logits)
    self.assertEqual(res.shape, (3, 5, 1, 1, 258))


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 26:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2176')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/image_transformer_2d.py: 523-538
</a>
<div class="mid" id="frag2176" style="display:none"><pre>
def imagetransformer2d_base_8l_8_64_64by64():
  """hparams fo 12 layer big 2d model for imagenet 64x64."""
  hparams = image_transformer2d_base()
  hparams.num_heads = 8
  hparams.hidden_size = 512
  hparams.filter_size = 2048
  hparams.num_decoder_layers = 8
  hparams.batch_size = 1
  hparams.layer_prepostprocess_dropout = 0.1
  hparams.query_shape = (8, 64)
  hparams.memory_flange = (4, 32)
  hparams.unconditional = int(False)
  hparams.max_length = 14000
  return hparams


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2177')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/image_transformer_2d.py: 540-555
</a>
<div class="mid" id="frag2177" style="display:none"><pre>
def imagetransformer2d_base_12l_8_64_64by64():
  """hparams fo 12 layer big 2d model for imagenet 64x64."""
  hparams = image_transformer2d_base()
  hparams.num_heads = 8
  hparams.hidden_size = 512
  hparams.filter_size = 2048
  hparams.num_decoder_layers = 12
  hparams.batch_size = 1
  hparams.layer_prepostprocess_dropout = 0.1
  hparams.query_shape = (8, 64)
  hparams.memory_flange = (4, 32)
  hparams.unconditional = int(False)
  hparams.max_length = 14000
  return hparams


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 27:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2400')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/video/tests_utils.py: 257-267
</a>
<div class="mid" id="frag2400" style="display:none"><pre>
  def TestOnVariousInputOutputSizes(
      self, hparams, model, expected_last_dim, test_infer=True):
    test_funcs = [self.TestVideoModel]
    if test_infer:
      test_funcs += [self.TestVideoModelInfer]
    for test_func in test_funcs:
      test_func(1, 1, hparams, model, expected_last_dim)
      test_func(1, 6, hparams, model, expected_last_dim)
      test_func(4, 1, hparams, model, expected_last_dim)
      test_func(7, 5, hparams, model, expected_last_dim)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2402')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/video/tests_utils.py: 278-288
</a>
<div class="mid" id="frag2402" style="display:none"><pre>
  def TestWithActionAndRewards(
      self, hparams, model, expected_last_dim, test_infer=True):
    test_funcs = [self.TestVideoModelWithActionAndRewards]
    if test_infer:
      test_funcs += [self.TestVideoModelWithActionAndRewardsInfer]
    for test_func in test_funcs:
      test_func(1, 1, hparams, model, expected_last_dim)
      test_func(1, 6, hparams, model, expected_last_dim)
      test_func(4, 1, hparams, model, expected_last_dim)
      test_func(7, 5, hparams, model, expected_last_dim)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 28:</b> &nbsp; 2 fragments, nominal size 16 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2416')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/video/basic_stochastic.py: 215-233
</a>
<div class="mid" id="frag2416" style="display:none"><pre>
def next_frame_basic_stochastic():
  """Basic 2-frame conv model with stochastic tower."""
  hparams = basic_deterministic_params.next_frame_basic_deterministic()
  hparams.stochastic_model = True
  hparams.add_hparam("latent_channels", 1)
  hparams.add_hparam("latent_std_min", -5.0)
  hparams.add_hparam("num_iterations_1st_stage", 15000)
  hparams.add_hparam("num_iterations_2nd_stage", 15000)
  hparams.add_hparam("latent_loss_multiplier", 1e-3)
  hparams.add_hparam("latent_loss_multiplier_dynamic", False)
  hparams.add_hparam("latent_loss_multiplier_alpha", 1e-5)
  hparams.add_hparam("latent_loss_multiplier_epsilon", 1.0)
  hparams.add_hparam("latent_loss_multiplier_schedule", "constant")
  hparams.add_hparam("latent_num_frames", 0)  # 0 means use all frames.
  hparams.add_hparam("anneal_end", 50000)
  hparams.add_hparam("information_capacity", 0.0)
  return hparams


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2417')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/video/basic_stochastic.py: 235-253
</a>
<div class="mid" id="frag2417" style="display:none"><pre>
def next_frame_sampling_stochastic():
  """Basic 2-frame conv model with stochastic tower."""
  hparams = basic_deterministic_params.next_frame_sampling()
  hparams.stochastic_model = True
  hparams.add_hparam("latent_channels", 1)
  hparams.add_hparam("latent_std_min", -5.0)
  hparams.add_hparam("num_iterations_1st_stage", 15000)
  hparams.add_hparam("num_iterations_2nd_stage", 15000)
  hparams.add_hparam("latent_loss_multiplier", 1e-3)
  hparams.add_hparam("latent_loss_multiplier_dynamic", False)
  hparams.add_hparam("latent_loss_multiplier_alpha", 1e-5)
  hparams.add_hparam("latent_loss_multiplier_epsilon", 1.0)
  hparams.add_hparam("latent_loss_multiplier_schedule", "constant")
  hparams.add_hparam("latent_num_frames", 0)  # 0 means use all frames.
  hparams.add_hparam("anneal_end", 40000)
  hparams.add_hparam("information_capacity", 0.0)
  return hparams


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 29:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2441')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/resnet.py: 612-632
</a>
<div class="mid" id="frag2441" style="display:none"><pre>
  def infer(self,
            features=None,
            decode_length=50,
            beam_size=1,
            top_beams=1,
            alpha=0.0,
            use_tpu=False):
    """Predict."""
    del decode_length, beam_size, top_beams, alpha, use_tpu
    assert features is not None
    logits, _ = self(features)  # pylint: disable=not-callable
    assert len(logits.get_shape()) == 5
    logits = tf.squeeze(logits, [1, 2, 3])
    log_probs = common_layers.log_prob_from_logits(logits)
    predictions, scores = common_layers.argmax_with_score(log_probs)
    return {
        "outputs": predictions,
        "scores": scores,
    }


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2835')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/research/vqa_attention.py: 103-123
</a>
<div class="mid" id="frag2835" style="display:none"><pre>
  def infer(self,
            features=None,
            decode_length=1,
            beam_size=1,
            top_beams=1,
            alpha=0.0,
            use_tpu=False):
    """Predict."""
    del decode_length, beam_size, top_beams, alpha, use_tpu
    assert features is not None
    logits, _ = self(features)
    assert len(logits.get_shape()) == 5
    logits = tf.squeeze(logits, [1, 2, 3])
    log_probs = common_layers.log_prob_from_logits(logits)
    predictions, scores = common_layers.argmax_with_score(log_probs)
    return {
        "outputs": predictions,
        "scores": scores,
    }


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 30:</b> &nbsp; 2 fragments, nominal size 33 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2563')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/neural_architecture_search/nas_model_test.py: 386-425
</a>
<div class="mid" id="frag2563" style="display:none"><pre>
  def test_calculate_branching_model_parameters_output_size_only_final(self):
    left_inputs = [0, 1, 2, 3]
    right_inputs = [0, 1, 2, 3]
    left_output_dims = [1, 10, 100, 1000]
    right_output_dims = [10000, 100000, 1000000, 10000000]
    right_layers = [
        layers.IDENTITY_REGISTRY_KEY, layers.STANDARD_CONV_1X1_REGISTRY_KEY,
        layers.STANDARD_CONV_1X1_REGISTRY_KEY, layers.IDENTITY_REGISTRY_KEY
    ]
    combiner_functions = [
        translation_nas_net.ADD_COMBINER_FUNC_KEY,
        translation_nas_net.ADD_COMBINER_FUNC_KEY,
        translation_nas_net.MULTIPLY_COMBINER_FUNC_KEY,
        translation_nas_net.CONCAT_COMBINER_FUNC_KEY
    ]

    (num_cells, _, left_layers, _, _, _, _, _, final_combiner_function,
     dummy_activations, dummy_norms, layer_registry,
     _) = _get_transformer_branching_encoder_config()

    # Get predicted number of parameters.
    (_, output_size, _,
     _) = translation_nas_net.calculate_branching_model_parameters(
         encoding_depth=_EMBEDDING_DEPTH,
         left_inputs=left_inputs,
         left_layers=left_layers,
         left_output_dims=left_output_dims,
         right_inputs=right_inputs,
         right_layers=right_layers,
         right_output_dims=right_output_dims,
         combiner_functions=combiner_functions,
         final_combiner_function=final_combiner_function,
         layer_registry=layer_registry,
         num_cells=num_cells,
         encoder_depth=_EMBEDDING_DEPTH,
         enforce_output_size=False,
         enforce_fixed_output_sizes=False)

    self.assertEqual(output_size, 10001000)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2564')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/neural_architecture_search/nas_model_test.py: 426-466
</a>
<div class="mid" id="frag2564" style="display:none"><pre>
  def test_calculate_branching_model_parameters_output_size_last_two(self):
    left_inputs = [0, 1, 2, 2]
    right_inputs = [0, 1, 2, 2]
    left_output_dims = [1, 10, 100, 1000]
    right_output_dims = [10000, 100000, 1000000, 10000000]
    right_layers = [
        layers.IDENTITY_REGISTRY_KEY, layers.STANDARD_CONV_1X1_REGISTRY_KEY,
        layers.STANDARD_CONV_1X1_REGISTRY_KEY, layers.IDENTITY_REGISTRY_KEY
    ]
    combiner_functions = [
        translation_nas_net.ADD_COMBINER_FUNC_KEY,
        translation_nas_net.ADD_COMBINER_FUNC_KEY,
        translation_nas_net.MULTIPLY_COMBINER_FUNC_KEY,
        translation_nas_net.CONCAT_COMBINER_FUNC_KEY
    ]

    (num_cells, _, left_layers, _, _, _, _, _, final_combiner_function,
     dummy_activations, dummy_norms, layer_registry,
     _) = _get_transformer_branching_encoder_config()

    # Get predicted number of parameters.
    (_, output_size, _,
     _) = translation_nas_net.calculate_branching_model_parameters(
         encoding_depth=_EMBEDDING_DEPTH,
         left_inputs=left_inputs,
         left_layers=left_layers,
         left_output_dims=left_output_dims,
         right_inputs=right_inputs,
         right_layers=right_layers,
         right_output_dims=right_output_dims,
         combiner_functions=combiner_functions,
         final_combiner_function=final_combiner_function,
         layer_registry=layer_registry,
         num_cells=num_cells,
         encoder_depth=_EMBEDDING_DEPTH,
         enforce_output_size=False,
         enforce_fixed_output_sizes=False)

    self.assertEqual(output_size, 11001000)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 31:</b> &nbsp; 3 fragments, nominal size 18 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2568')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/xception.py: 77-96
</a>
<div class="mid" id="frag2568" style="display:none"><pre>
    def xnet_resblock(x, filters, res_relu, name):
      """Resblock."""
      with tf.variable_scope(name):
        y = common_layers.separable_conv_block(
            x,
            filters, [((1, 1), (3, 3)), ((1, 1), (3, 3))],
            first_relu=True,
            padding="SAME",
            force2d=True,
            name="sep_conv_block")
        y = common_layers.pool(y, (3, 3), "MAX", "SAME", strides=(2, 2))
        return y + common_layers.conv_block(
            x,
            filters, [((1, 1), (1, 1))],
            padding="SAME",
            strides=(2, 2),
            first_relu=res_relu,
            force2d=True,
            name="res_conv0")

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag4885')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/layers/modalities.py: 144-165
</a>
<div class="mid" id="frag4885" style="display:none"><pre>
    def xnet_resblock(x, filters, res_relu, name):
      """Xception block."""
      with tf.variable_scope(name):
        # Typically audio samples are &gt;100k samples in length and have a width
        # of 2 or 4. Mono audio has a single channel while stereo has 2.
        y = common_layers.separable_conv_block(
            x,
            filters, [((1, 1), (3, 3)), ((1, 1), (3, 3))],
            first_relu=True,
            padding="SAME",
            force2d=True,
            name="sep_conv_block")
        y = common_layers.pool(y, (3, 3), "MAX", "SAME", strides=(2, 2))
        return y + common_layers.conv_block(
            x,
            filters, [((1, 1), (1, 1))],
            padding="SAME",
            strides=(2, 2),
            first_relu=res_relu,
            force2d=True,
            name="res_conv0")

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag4887')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/layers/modalities.py: 192-214
</a>
<div class="mid" id="frag4887" style="display:none"><pre>
    def xnet_resblock(x, filters, res_relu, name):
      """Xception-like block."""
      with tf.variable_scope(name):
        # We only stride along the length dimension to preserve the spectral
        # bins (which are tiny in dimensionality relative to length)
        y = common_layers.separable_conv_block(
            x,
            filters, [((1, 1), (3, 3)), ((1, 1), (3, 3))],
            first_relu=True,
            padding="SAME",
            force2d=True,
            name="sep_conv_block")
        y = common_layers.pool(y, (3, 3), "MAX", "SAME", strides=(2, 1))
        return y + common_layers.conv_block(
            x,
            filters, [((1, 1), (1, 1))],
            padding="SAME",
            strides=(2, 1),
            first_relu=res_relu,
            force2d=True,
            name="res_conv0")

    # Bitcast back from int32
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 32:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2608')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/mtf_image_transformer.py: 465-477
</a>
<div class="mid" id="frag2608" style="display:none"><pre>
def mtf_image_transformer_tiny_spatial1d():
  """Small single parameters."""
  hparams = mtf_image_transformer_tiny()
  hparams.num_decoder_layers = 6
  hparams.filter_size = 128
  hparams.block_height = 8
  hparams.block_width = 8
  hparams.attention_type = "local1d_spatial"
  hparams.mesh_shape = ""
  hparams.layout = ""
  return hparams


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2609')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/mtf_image_transformer.py: 479-491
</a>
<div class="mid" id="frag2609" style="display:none"><pre>
def mtf_image_transformer_tiny_spatial2d():
  """Small single parameters."""
  hparams = mtf_image_transformer_tiny()
  hparams.num_decoder_layers = 6
  hparams.filter_size = 128
  hparams.block_height = 8
  hparams.block_width = 8
  hparams.attention_type = "local2d_spatial"
  hparams.mesh_shape = "b1:2,b2:2"
  hparams.layout = "num_h_blocks:b1,num_wblocks:b2"
  return hparams


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 33:</b> &nbsp; 3 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2614')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/mtf_image_transformer.py: 555-567
</a>
<div class="mid" id="frag2614" style="display:none"><pre>
def mtf_image_transformer_base_imagenet_mp():
  """Model parallel ImageNet parameters."""
  hparams = mtf_image_transformer_base_imagenet()
  hparams.mesh_shape = "model:4;batch:8"
  hparams.layout = "batch:batch;d_ff:model;heads:model"
  hparams.batch_size = 32
  hparams.num_heads = 8
  hparams.d_ff = 8192
  hparams.learning_rate_warmup_steps = 31250
  hparams.unconditional = True
  return hparams


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2959')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/research/transformer_vae.py: 973-985
</a>
<div class="mid" id="frag2959" style="display:none"><pre>
def transformer_ae_base_noatt():
  """Set of hyperparameters."""
  hparams = transformer_ae_base()
  hparams.reshape_method = "slice"
  hparams.bottleneck_kind = "dvq"
  hparams.hidden_size = 512
  hparams.num_blocks = 1
  hparams.num_decode_blocks = 1
  hparams.z_size = 12
  hparams.do_attend_decompress = False
  return hparams


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2960')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/research/transformer_vae.py: 987-999
</a>
<div class="mid" id="frag2960" style="display:none"><pre>
def transformer_ae_small_noatt():
  """Set of hyperparameters."""
  hparams = transformer_ae_small()
  hparams.reshape_method = "slice"
  hparams.bottleneck_kind = "dvq"
  hparams.hidden_size = 512
  hparams.num_blocks = 1
  hparams.num_decode_blocks = 1
  hparams.z_size = 12
  hparams.do_attend_decompress = False
  return hparams


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 34:</b> &nbsp; 2 fragments, nominal size 38 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2776')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/research/neural_stack_test.py: 130-183
</a>
<div class="mid" id="frag2776" style="display:none"><pre>
  def test_push_pop(self):
    """Test pushing a popping from a NeuralStackCell.

    The sequence of operations is:
      push([1.0, 0.0, 0.0])
      push([0.0, 1.0, 0.0])
      pop()
    """
    input_values = np.array([[[[1.0, 0.0, 0.0]],
                              [[0.0, 1.0, 0.0]],
                              [[0.0, 0.0, 1.0]]]])

    expected_values = np.array([[[1.0, 0.0, 0.0],
                                 [0.0, 1.0, 0.0],
                                 [0.0, 0.0, 1.0],
                                 [0.0, 0.0, 0.0],
                                 [0.0, 0.0, 0.0],
                                 [0.0, 0.0, 0.0]]])
    expected_read_strengths = np.array([
        [[[1.0], [0.0], [0.0], [0.0], [0.0], [0.0]]]])
    expected_write_strengths = np.array([
        [[[0.0], [0.0], [0.], [1.0], [0.0], [0.0]]]])
    expected_top = np.array([[[1.0, 0.0, 0.0]]])

    batch_size = 1
    embedding_size = 3
    memory_size = 6
    num_units = 8

    stack = neural_stack.NeuralStackCell(num_units, memory_size, embedding_size)
    stack_input = tf.constant(input_values, dtype=tf.float32)

    stack_zero_state = tf.zeros([batch_size, num_units])
    controller_outputs = stack.call_controller(None, None, stack_zero_state,
                                               batch_size)
    assert_controller_shapes(self, controller_outputs,
                             stack.get_controller_shape(batch_size))

    (outputs, state) = tf.nn.dynamic_rnn(cell=stack,
                                         inputs=stack_input,
                                         time_major=False,
                                         dtype=tf.float32)

    with self.test_session() as sess:
      sess.run(tf.global_variables_initializer())
      _, state_vals = sess.run([outputs, state])
      (_, stack_top, values, read_strengths, write_strengths) = state_vals

      self.assertAllClose(expected_values, values)
      self.assertAllClose(expected_write_strengths, write_strengths)
      self.assertAllClose(expected_read_strengths, read_strengths)
      self.assertAllClose(expected_top, stack_top)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2777')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/research/neural_stack_test.py: 198-250
</a>
<div class="mid" id="frag2777" style="display:none"><pre>
  def test_enqueue_dequeue(self):
    """Test enqueueing a dequeueing from a NeuralQueueCell.

    The sequence of operations is:
      enqueue([1.0, 0.0, 0.0])
      enqueue([0.0, 1.0, 0.0])
      dequeue()
    """
    input_values = np.array([[[[1.0, 0.0, 0.0]],
                              [[0.0, 1.0, 0.0]],
                              [[0.0, 0.0, 1.0]]]])
    expected_values = np.array([[[1.0, 0.0, 0.0],
                                 [0.0, 1.0, 0.0],
                                 [0.0, 0.0, 1.0],
                                 [0.0, 0.0, 0.0],
                                 [0.0, 0.0, 0.0],
                                 [0.0, 0.0, 0.0]]])
    expected_read_strengths = np.array([
        [[[0.0], [1.0], [0.0], [0.0], [0.0], [0.0]]]])
    expected_write_strengths = np.array([
        [[[0.0], [0.0], [0.0], [1.0], [0.0], [0.0]]]])
    expected_front = np.array([[[0.0, 1.0, 0.0]]])

    batch_size = 1
    num_units = 8
    embedding_size = 3
    memory_size = 6

    queue = neural_stack.NeuralQueueCell(num_units, memory_size, embedding_size)
    rnn_input = tf.constant(input_values, dtype=tf.float32)

    queue_zero_state = tf.zeros([batch_size, num_units])
    controller_outputs = queue.call_controller(None, None, queue_zero_state,
                                               batch_size)
    assert_controller_shapes(self, controller_outputs,
                             queue.get_controller_shape(batch_size))

    (outputs, state) = tf.nn.dynamic_rnn(cell=queue,
                                         inputs=rnn_input,
                                         time_major=False,
                                         dtype=tf.float32)

    with self.test_session() as sess:
      sess.run(tf.global_variables_initializer())
      _, state_vals = sess.run([outputs, state])
      (_, queue_front, values, read_strengths, write_strengths) = state_vals

      self.assertAllClose(expected_values, values)
      self.assertAllClose(expected_write_strengths, write_strengths)
      self.assertAllClose(expected_read_strengths, read_strengths)
      self.assertAllClose(expected_front, queue_front)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 35:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag2928')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/research/transformer_vae.py: 46-62
</a>
<div class="mid" id="frag2928" style="display:none"><pre>
def residual_conv(x, repeat, k, hparams, name, reuse=None):
  """A stack of convolution blocks with residual connections."""
  with tf.variable_scope(name, reuse=reuse):
    dilations_and_kernels = [((1, 1), k) for _ in range(3)]
    for i in range(repeat):
      with tf.variable_scope("repeat_%d" % i):
        y = common_layers.conv_block(
            common_layers.layer_norm(x, hparams.hidden_size, name="lnorm"),
            hparams.hidden_size,
            dilations_and_kernels,
            padding="SAME",
            name="residual_conv")
        y = tf.nn.dropout(y, 1.0 - hparams.dropout)
        x += y
    return x


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag2971')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/research/transformer_nat.py: 121-137
</a>
<div class="mid" id="frag2971" style="display:none"><pre>
def residual_conv(x, repeat, k, hparams, name, reuse=None):
  """A stack of convolution blocks with residual connections."""
  with tf.variable_scope(name, reuse=reuse):
    dilations_and_kernels = [((1, 1), k) for _ in range(3)]
    for i in range(repeat):
      with tf.variable_scope("repeat_%d" % i):
        y = common_layers.conv_block(
            common_layers.layer_norm(x, hparams.hidden_size, name="lnorm"),
            hparams.hidden_size,
            dilations_and_kernels,
            padding="SAME",
            name="residual_conv")
        y = tf.nn.dropout(y, 1.0 - hparams.dropout)
        x += y
    return x


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 36:</b> &nbsp; 2 fragments, nominal size 15 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag3108')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/research/neural_stack.py: 625-643
</a>
<div class="mid" id="frag3108" style="display:none"><pre>
def neural_stack():
  """HParams for neural stacks and queues."""
  hparams = common_hparams.basic_params1()
  hparams.daisy_chain_variables = False
  hparams.batch_size = 10
  hparams.clip_grad_norm = 1.0
  hparams.initializer = "uniform_unit_scaling"
  hparams.initializer_gain = 1.0
  hparams.optimizer = "RMSProp"
  hparams.learning_rate = 0.0001
  hparams.weight_decay = 0.0

  hparams.add_hparam("controller_layer_sizes", [256, 512])
  hparams.add_hparam("memory_size", 128)
  hparams.add_hparam("embedding_size", 64)
  hparams.hidden_size = hparams.embedding_size
  return hparams


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag3109')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/research/neural_stack.py: 645-661
</a>
<div class="mid" id="frag3109" style="display:none"><pre>
def neural_deque():
  """HParams for neural deques."""
  hparams = common_hparams.basic_params1()
  hparams.daisy_chain_variables = False
  hparams.batch_size = 10
  hparams.clip_grad_norm = 1.0
  hparams.initializer = "uniform_unit_scaling"
  hparams.initializer_gain = 1.0
  hparams.optimizer = "RMSProp"
  hparams.learning_rate = 0.0001
  hparams.weight_decay = 0.0

  hparams.add_hparam("controller_layer_sizes", [256, 512])
  hparams.add_hparam("memory_size", 256)
  hparams.add_hparam("embedding_size", 64)
  hparams.hidden_size = hparams.embedding_size
  return hparams
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 37:</b> &nbsp; 2 fragments, nominal size 16 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag3180')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/research/vqa_self_attention.py: 448-479
</a>
<div class="mid" id="frag3180" style="display:none"><pre>
def prepare_image_question_encoder(image_feat, question, hparams):
  """Prepare encoder.

  Args:
    image_feat: a Tensor.
    question: a Tensor.
    hparams: run hyperparameters

  Returns:
    encoder_input: a Tensor, bottom of encoder stack
    encoder_self_attention_bias: a bias tensor for use in encoder self-attention
  """

  encoder_input = tf.concat([image_feat, question], axis=1)
  encoder_padding = common_attention.embedding_to_padding(encoder_input)
  ignore_padding = common_attention.attention_bias_ignore_padding(
      encoder_padding)
  encoder_self_attention_bias = ignore_padding
  encoder_decoder_attention_bias = ignore_padding
  # Usual case - not a packed dataset.
  if hparams.pos == "timing":
    question = common_attention.add_timing_signal_1d(question)
  elif hparams.pos == "emb":
    question = common_attention.add_positional_embedding(
        question, hparams.max_length, "inputs_positional_embedding",
        None)
  encoder_input = tf.concat([image_feat, question], axis=1)

  return (encoder_input, encoder_self_attention_bias,
          encoder_decoder_attention_bias)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag3234')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/models/research/vqa_recurrent_self_attention.py: 106-137
</a>
<div class="mid" id="frag3234" style="display:none"><pre>
def prepare_image_question_encoder(image_feat, question, hparams):
  """Prepare encoder.

  Args:
    image_feat: a Tensor.
    question: a Tensor.
    hparams: run hyperparameters

  Returns:
    encoder_input: a Tensor, bottom of encoder stack
    encoder_self_attention_bias: a bias tensor for use in encoder self-attention
  """

  encoder_input = tf.concat([image_feat, question], axis=1)
  encoder_padding = common_attention.embedding_to_padding(encoder_input)
  ignore_padding = common_attention.attention_bias_ignore_padding(
      encoder_padding)
  encoder_self_attention_bias = ignore_padding
  encoder_decoder_attention_bias = ignore_padding
  # Usual case - not a packed dataset.
  if hparams.pos == "timing":
    question = common_attention.add_timing_signal_1d(question)
  elif hparams.pos == "emb":
    question = common_attention.add_positional_embedding(
        question, hparams.max_length, "inputs_positional_embedding",
        None)
  encoder_input = tf.concat([image_feat, question], axis=1)

  return (encoder_input, encoder_self_attention_bias,
          encoder_decoder_attention_bias)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 38:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag3352')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/rl/dopamine_connector.py: 109-119
</a>
<div class="mid" id="frag3352" style="display:none"><pre>
  def __init__(self, env_batch_size, *args, **kwargs):
    super(BatchDQNAgent, self).__init__(*args, **kwargs)
    self.env_batch_size = env_batch_size
    obs_size = dqn_agent.NATURE_DQN_OBSERVATION_SHAPE
    state_shape = [self.env_batch_size, obs_size[0], obs_size[1],
                   dqn_agent.NATURE_DQN_STACK_SIZE]
    self.state_batch = np.zeros(state_shape)
    self.state = None  # assure it will be not used
    self._observation = None  # assure it will be not used
    self.reset_current_rollouts()

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag3371')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/rl/dopamine_connector.py: 302-312
</a>
<div class="mid" id="frag3371" style="display:none"><pre>
  def __init__(self, env_batch_size, *args, **kwargs):
    super(BatchRainbowAgent, self).__init__(*args, **kwargs)
    self.env_batch_size = env_batch_size
    obs_size = dqn_agent.NATURE_DQN_OBSERVATION_SHAPE
    state_shape = [self.env_batch_size, obs_size[0], obs_size[1],
                   dqn_agent.NATURE_DQN_STACK_SIZE]
    self.state_batch = np.zeros(state_shape)
    self.state = None  # assure it will be not used
    self._observation = None  # assure it will be not used
    self.reset_current_rollouts()

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 39:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag3359')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/rl/dopamine_connector.py: 157-171
</a>
<div class="mid" id="frag3359" style="display:none"><pre>
  def step(self, reward, observation):
    self._last_observation = self._observation_batch
    self._record_observation(observation)

    if not self.eval_mode:
      self._update_current_rollouts(self._last_observation, self.action, reward,
                                    [False] * self.env_batch_size)
      # We want to have the same train_step:env_step ratio not depending on
      # batch size.
      for _ in range(self.env_batch_size):
        self._train_step()

    self.action = self._select_action()
    return self.action

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag3378')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/rl/dopamine_connector.py: 350-364
</a>
<div class="mid" id="frag3378" style="display:none"><pre>
  def step(self, reward, observation):
    self._last_observation = self._observation_batch
    self._record_observation(observation)

    if not self.eval_mode:
      self._update_current_rollouts(self._last_observation, self.action, reward,
                                    [False] * self.env_batch_size)
      # We want to have the same train_step:env_step ratio not depending on
      # batch size.
      for _ in range(self.env_batch_size):
        self._train_step()

    self.action = self._select_action()
    return self.action

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 40:</b> &nbsp; 2 fragments, nominal size 15 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag3361')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/rl/dopamine_connector.py: 179-199
</a>
<div class="mid" id="frag3361" style="display:none"><pre>
  def _select_action(self):
    epsilon = self.epsilon_eval
    if not self.eval_mode:
      epsilon = self.epsilon_fn(
          self.epsilon_decay_period,
          self.training_steps,
          self.min_replay_history,
          self.epsilon_train)

    def choose_action(ix):
      if random.random() &lt;= epsilon:
        # Choose a random action with probability epsilon.
        return random.randint(0, self.num_actions - 1)
      else:
        # Choose the action with highest Q-value at the current state.
        return self._sess.run(self._q_argmax,
                              {self.state_ph: self.state_batch[ix:ix+1]})

    return np.array([choose_action(ix) for ix in range(self.env_batch_size)])


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag3380')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/rl/dopamine_connector.py: 372-392
</a>
<div class="mid" id="frag3380" style="display:none"><pre>
  def _select_action(self):
    epsilon = self.epsilon_eval
    if not self.eval_mode:
      epsilon = self.epsilon_fn(
          self.epsilon_decay_period,
          self.training_steps,
          self.min_replay_history,
          self.epsilon_train)

    def choose_action(ix):
      if random.random() &lt;= epsilon:
        # Choose a random action with probability epsilon.
        return random.randint(0, self.num_actions - 1)
      else:
        # Choose the action with highest Q-value at the current state.
        return self._sess.run(self._q_argmax,
                              {self.state_ph: self.state_batch[ix:ix+1]})

    return np.array([choose_action(ix) for ix in range(self.env_batch_size)])


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 41:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag3565')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/rl/gym_utils_test.py: 119-132
</a>
<div class="mid" id="frag3565" style="display:none"><pre>
  def test_rendered_env_continuous_1d(self):
    env = gym_utils.RenderedEnv(
        SimpleContinuousActionsEnv(dimensions=1),
        resize_to=(64, 12))
    obs, _, _, _ = env.step(0.5)
    self.assertTrue(np.allclose(np.zeros([64, 12, 3], np.uint8), obs))

    env = gym_utils.RenderedEnv(
        SimpleContinuousActionsEnv(dimensions=1),
        resize_to=(64, 12),
        output_dtype=np.float32)
    obs, _, _, _ = env.step(1)
    self.assertTrue(np.allclose(np.zeros([64, 12, 3], np.float32), obs))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag3566')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/rl/gym_utils_test.py: 133-146
</a>
<div class="mid" id="frag3566" style="display:none"><pre>
  def test_rendered_env_continuous_2d(self):
    env = gym_utils.RenderedEnv(
        SimpleContinuousActionsEnv(dimensions=2),
        resize_to=(64, 12))
    obs, _, _, _ = env.step(0.5)
    self.assertTrue(np.allclose(np.zeros([64, 12, 3], np.uint8), obs))

    env = gym_utils.RenderedEnv(
        SimpleContinuousActionsEnv(dimensions=2),
        resize_to=(64, 12),
        output_dtype=np.float32)
    obs, _, _, _ = env.step(1)
    self.assertTrue(np.allclose(np.zeros([64, 12, 3], np.float32), obs))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 42:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag3578')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/rl/evaluator.py: 112-123
</a>
<div class="mid" id="frag3578" style="display:none"><pre>
def planner_tiny():
  return hparam.HParams(
      num_rollouts=1,
      planning_horizon=2,
      rollout_agent_type="random",
      batch_size=1,
      env_type="simulated",
      uct_const=0.0,
      uniform_first_action=True,
  )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag3579')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/rl/evaluator.py: 125-136
</a>
<div class="mid" id="frag3579" style="display:none"><pre>
def planner_small():
  return hparam.HParams(
      num_rollouts=64,
      planning_horizon=16,
      rollout_agent_type="policy",
      batch_size=64,
      env_type="simulated",
      uct_const=0.0,
      uniform_first_action=True,
  )


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 43:</b> &nbsp; 2 fragments, nominal size 55 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag3839')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/utils/multistep_with_adamoptimizer_test.py: 42-109
</a>
<div class="mid" id="frag3839" style="display:none"><pre>
  def testMultistep(self):
    dtype = tf.float32
    beta1 = 0.2
    beta2 = 0.99
    alpha = 10.0
    grads0_np_lst = [
        np.array([0.1, 0.1], dtype=dtype.as_numpy_dtype),
        np.array([0.2, -0.1], dtype=dtype.as_numpy_dtype),
        np.array([0.3, 0.1], dtype=dtype.as_numpy_dtype),
        np.array([0.4, -0.1], dtype=dtype.as_numpy_dtype)
    ]
    grads1_np_lst = [
        np.array([0.01, 0.01], dtype=dtype.as_numpy_dtype),
        np.array([0.02, 0.02], dtype=dtype.as_numpy_dtype),
        np.array([-0.04, 0.04], dtype=dtype.as_numpy_dtype),
        np.array([-0.04, 0.06], dtype=dtype.as_numpy_dtype)
    ]
    var0_np = np.array([1.0, 2.0], dtype=dtype.as_numpy_dtype)
    var1_np = np.array([3.0, 4.0], dtype=dtype.as_numpy_dtype)
    # Test accumulating gradients for n=1..4 steps
    for n in range(1, 5):
      with tf.Graph().as_default():
        with tf.Session():
          singlestep_var0 = tf.Variable(var0_np)
          singlestep_var1 = tf.Variable(var1_np)

          multistep_var0 = tf.Variable(var0_np)
          multistep_var1 = tf.Variable(var1_np)

          singlestep_opt = tf.train.AdamOptimizer(
              beta1=beta1, beta2=beta2, learning_rate=alpha)
          multistep_opt = multistep_with_adamoptimizer.MultistepAdamOptimizer(
              n=n, beta1=beta1, beta2=beta2, learning_rate=alpha)

          singlestep_update = singlestep_opt.apply_gradients([
              (tf.constant(sum(grads0_np_lst[:n]) / n), singlestep_var0),
              (tf.constant(sum(grads1_np_lst[:n]) / n), singlestep_var1)])
          multistep_updates = [
              multistep_opt.apply_gradients([(tf.constant(g0), multistep_var0),
                                             (tf.constant(g1), multistep_var1)])
              for g0, g1 in zip(grads0_np_lst, grads1_np_lst)][:n]

          self.evaluate(tf.global_variables_initializer())
          (singlestep_beta1_power,
           singlestep_beta2_power) = singlestep_opt._get_beta_accumulators()
          (multistep_beta1_power,
           multistep_beta2_power) = multistep_opt._get_beta_accumulators()

          # Run 3 steps of Adam
          for _ in range(1, 4):
            self.evaluate(singlestep_update)
            for multistep_update in multistep_updates:
              self.evaluate(multistep_update)

            self.assertAllCloseAccordingToType(
                self.evaluate(singlestep_beta1_power),
                self.evaluate(multistep_beta1_power))
            self.assertAllCloseAccordingToType(
                self.evaluate(singlestep_beta2_power),
                self.evaluate(multistep_beta2_power))
            # Validate updated params
            self.assertAllCloseAccordingToType(
                self.evaluate(singlestep_var0),
                self.evaluate(multistep_var0))
            self.assertAllCloseAccordingToType(
                self.evaluate(singlestep_var1),
                self.evaluate(multistep_var1))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag4151')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/utils/multistep_optimizer_test.py: 28-95
</a>
<div class="mid" id="frag4151" style="display:none"><pre>
  def testMultistep(self):
    dtype = tf.float32
    beta1 = 0.2
    beta2 = 0.99
    alpha = 10.0
    grads0_np_lst = [
        np.array([0.1, 0.1], dtype=dtype.as_numpy_dtype),
        np.array([0.2, -0.1], dtype=dtype.as_numpy_dtype),
        np.array([0.3, 0.1], dtype=dtype.as_numpy_dtype),
        np.array([0.4, -0.1], dtype=dtype.as_numpy_dtype)
    ]
    grads1_np_lst = [
        np.array([0.01, 0.01], dtype=dtype.as_numpy_dtype),
        np.array([0.02, 0.02], dtype=dtype.as_numpy_dtype),
        np.array([-0.04, 0.04], dtype=dtype.as_numpy_dtype),
        np.array([-0.04, 0.06], dtype=dtype.as_numpy_dtype)
    ]
    var0_np = np.array([1.0, 2.0], dtype=dtype.as_numpy_dtype)
    var1_np = np.array([3.0, 4.0], dtype=dtype.as_numpy_dtype)
    # Test accumulating gradients for n=1..4 steps
    for n in range(1, 5):
      with tf.Graph().as_default():
        with tf.Session():
          singlestep_var0 = tf.Variable(var0_np)
          singlestep_var1 = tf.Variable(var1_np)

          multistep_var0 = tf.Variable(var0_np)
          multistep_var1 = tf.Variable(var1_np)

          singlestep_opt = tf.train.AdamOptimizer(
              beta1=beta1, beta2=beta2, learning_rate=alpha)
          multistep_opt = multistep_optimizer.MultistepAdamOptimizer(
              n=n, beta1=beta1, beta2=beta2, learning_rate=alpha)

          singlestep_update = singlestep_opt.apply_gradients([
              (tf.constant(sum(grads0_np_lst[:n]) / n), singlestep_var0),
              (tf.constant(sum(grads1_np_lst[:n]) / n), singlestep_var1)])
          multistep_updates = [
              multistep_opt.apply_gradients([(tf.constant(g0), multistep_var0),
                                             (tf.constant(g1), multistep_var1)])
              for g0, g1 in zip(grads0_np_lst, grads1_np_lst)][:n]

          self.evaluate(tf.global_variables_initializer())
          (singlestep_beta1_power,
           singlestep_beta2_power) = singlestep_opt._get_beta_accumulators()
          (multistep_beta1_power,
           multistep_beta2_power) = multistep_opt._get_beta_accumulators()

          # Run 3 steps of Adam
          for _ in range(1, 4):
            self.evaluate(singlestep_update)
            for multistep_update in multistep_updates:
              self.evaluate(multistep_update)

            self.assertAllCloseAccordingToType(
                self.evaluate(singlestep_beta1_power),
                self.evaluate(multistep_beta1_power))
            self.assertAllCloseAccordingToType(
                self.evaluate(singlestep_beta2_power),
                self.evaluate(multistep_beta2_power))
            # Validate updated params
            self.assertAllCloseAccordingToType(
                self.evaluate(singlestep_var0),
                self.evaluate(multistep_var0))
            self.assertAllCloseAccordingToType(
                self.evaluate(singlestep_var1),
                self.evaluate(multistep_var1))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 44:</b> &nbsp; 2 fragments, nominal size 19 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag4016')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/utils/metrics_test.py: 304-326
</a>
<div class="mid" id="frag4016" style="display:none"><pre>
  def testSigmoidPrecisionOneHot(self):
    logits = np.array([
        [-1., 1.],
        [1., -1.],
        [1., -1.],
        [1., -1.]
    ])
    labels = np.array([
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1]
    ])
    logits = np.expand_dims(np.expand_dims(logits, 1), 1)
    labels = np.expand_dims(np.expand_dims(labels, 1), 1)

    with self.test_session() as session:
      score, _ = metrics.sigmoid_precision_one_hot(logits, labels)
      session.run(tf.global_variables_initializer())
      session.run(tf.local_variables_initializer())
      s = session.run(score)
    self.assertEqual(s, 0.25)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag4017')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/utils/metrics_test.py: 327-349
</a>
<div class="mid" id="frag4017" style="display:none"><pre>
  def testSigmoidRecallOneHot(self):
    logits = np.array([
        [-1., 1.],
        [1., -1.],
        [1., -1.],
        [1., -1.]
    ])
    labels = np.array([
        [0, 1],
        [0, 1],
        [0, 1],
        [0, 1]
    ])
    logits = np.expand_dims(np.expand_dims(logits, 1), 1)
    labels = np.expand_dims(np.expand_dims(labels, 1), 1)

    with self.test_session() as session:
      score, _ = metrics.sigmoid_recall_one_hot(logits, labels)
      session.run(tf.global_variables_initializer())
      session.run(tf.local_variables_initializer())
      s = session.run(score)
    self.assertEqual(s, 0.25)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 45:</b> &nbsp; 6 fragments, nominal size 14 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag4461')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/layers/common_attention_test.py: 876-891
</a>
<div class="mid" id="frag4461" style="display:none"><pre>
  def testRelativeAttentionV2(self):
    # (batch, heads, length, depth)
    x = np.random.rand(5, 4, 16, 7)
    y = np.random.rand(5, 4, 16, 7)
    max_relative_position = 3
    a = common_attention.dot_product_self_attention_relative_v2(
        tf.constant(x, dtype=tf.float32),
        tf.constant(y, dtype=tf.float32),
        tf.constant(y, dtype=tf.float32),
        None,
        max_relative_position=max_relative_position,
        heads_share_relative_embedding=False)
    self.evaluate(tf.global_variables_initializer())
    res = self.evaluate(a)
    self.assertEqual(res.shape, (5, 4, 16, 7))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag4462')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/layers/common_attention_test.py: 893-908
</a>
<div class="mid" id="frag4462" style="display:none"><pre>
  def testRelativeAttentionV2SharedRel(self):
    # (batch, heads, length, depth)
    x = np.random.rand(5, 4, 16, 7)
    y = np.random.rand(5, 4, 16, 7)
    max_relative_position = 3
    a = common_attention.dot_product_self_attention_relative_v2(
        tf.constant(x, dtype=tf.float32),
        tf.constant(y, dtype=tf.float32),
        tf.constant(y, dtype=tf.float32),
        None,
        max_relative_position=max_relative_position,
        heads_share_relative_embedding=True)
    self.evaluate(tf.global_variables_initializer())
    res = self.evaluate(a)
    self.assertEqual(res.shape, (5, 4, 16, 7))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag4476')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/layers/common_attention_test.py: 1433-1448
</a>
<div class="mid" id="frag4476" style="display:none"><pre>
  def testRelativeAttentionV2UnmaskedSharedRel(self):
    # (batch, heads, length, depth)
    x = np.random.rand(5, 4, 16, 7)
    y = np.random.rand(5, 4, 16, 7)
    max_relative_position = 3
    a = common_attention.dot_product_unmasked_self_attention_relative_v2(
        tf.constant(x, dtype=tf.float32),
        tf.constant(y, dtype=tf.float32),
        tf.constant(y, dtype=tf.float32),
        None,
        max_relative_position=max_relative_position,
        heads_share_relative_embedding=True)
    self.evaluate(tf.global_variables_initializer())
    res = self.evaluate(a)
    self.assertEqual(res.shape, (5, 4, 16, 7))

</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag4463')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/layers/common_attention_test.py: 910-925
</a>
<div class="mid" id="frag4463" style="display:none"><pre>
  def testRelativeAttentionV2MaxRelativeLargerThanLength(self):
    # (batch, heads, length, depth)
    x = np.random.rand(5, 4, 3, 7)
    y = np.random.rand(5, 4, 3, 7)
    max_relative_position = 16
    a = common_attention.dot_product_self_attention_relative_v2(
        tf.constant(x, dtype=tf.float32),
        tf.constant(y, dtype=tf.float32),
        tf.constant(y, dtype=tf.float32),
        None,
        max_relative_position=max_relative_position,
        heads_share_relative_embedding=False)
    self.evaluate(tf.global_variables_initializer())
    res = self.evaluate(a)
    self.assertEqual(res.shape, (5, 4, 3, 7))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag4475')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/layers/common_attention_test.py: 1416-1431
</a>
<div class="mid" id="frag4475" style="display:none"><pre>
  def testRelativeAttentionV2Unmasked(self):
    # (batch, heads, length, depth)
    x = np.random.rand(5, 4, 16, 7)
    y = np.random.rand(5, 4, 16, 7)
    max_relative_position = 3
    a = common_attention.dot_product_unmasked_self_attention_relative_v2(
        tf.constant(x, dtype=tf.float32),
        tf.constant(y, dtype=tf.float32),
        tf.constant(y, dtype=tf.float32),
        None,
        max_relative_position=max_relative_position,
        heads_share_relative_embedding=False)
    self.evaluate(tf.global_variables_initializer())
    res = self.evaluate(a)
    self.assertEqual(res.shape, (5, 4, 16, 7))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag4477')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/layers/common_attention_test.py: 1450-1465
</a>
<div class="mid" id="frag4477" style="display:none"><pre>
  def testRelativeAttentionV2UnmaskedRelativeLargerThanLength(self):
    # (batch, heads, length, depth)
    x = np.random.rand(5, 4, 3, 7)
    y = np.random.rand(5, 4, 3, 7)
    max_relative_position = 16
    a = common_attention.dot_product_unmasked_self_attention_relative_v2(
        tf.constant(x, dtype=tf.float32),
        tf.constant(y, dtype=tf.float32),
        tf.constant(y, dtype=tf.float32),
        None,
        max_relative_position=max_relative_position,
        heads_share_relative_embedding=False)
    self.evaluate(tf.global_variables_initializer())
    res = self.evaluate(a)
    self.assertEqual(res.shape, (5, 4, 3, 7))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 46:</b> &nbsp; 2 fragments, nominal size 15 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag4478')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/layers/common_attention_test.py: 1467-1483
</a>
<div class="mid" id="frag4478" style="display:none"><pre>
  def testMaskedRelativeLocalAttentionV2(self):
    # (batch, heads, length, depth)
    x = np.random.rand(5, 4, 16, 7)
    y = np.random.rand(5, 4, 16, 7)
    block_length = 3
    a = common_attention.masked_relative_local_attention_1d(
        tf.constant(x, dtype=tf.float32),
        tf.constant(y, dtype=tf.float32),
        tf.constant(y, dtype=tf.float32),
        block_length=block_length,
        heads_share_relative_embedding=True,
        add_relative_to_values=False,
        name="masked_relative_local_attention_1d")
    self.evaluate(tf.global_variables_initializer())
    res = self.evaluate(a)
    self.assertEqual(res.shape, (5, 4, 16, 7))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag4479')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/layers/common_attention_test.py: 1485-1501
</a>
<div class="mid" id="frag4479" style="display:none"><pre>
  def testMaskedRelativeLocalAttentionV2AddRelativeValues(self):
    # (batch, heads, length, depth)
    x = np.random.rand(5, 4, 16, 7)
    y = np.random.rand(5, 4, 16, 7)
    block_length = 3
    a = common_attention.masked_relative_local_attention_1d(
        tf.constant(x, dtype=tf.float32),
        tf.constant(y, dtype=tf.float32),
        tf.constant(y, dtype=tf.float32),
        block_length=block_length,
        heads_share_relative_embedding=True,
        add_relative_to_values=False,
        name="masked_relative_local_attention_1d")
    self.evaluate(tf.global_variables_initializer())
    res = self.evaluate(a)
    self.assertEqual(res.shape, (5, 4, 16, 7))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 47:</b> &nbsp; 2 fragments, nominal size 14 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag4480')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/layers/common_attention_test.py: 1503-1518
</a>
<div class="mid" id="frag4480" style="display:none"><pre>
  def testMaskedRelativeLocalAttentionV2SeqShorterThanBlockLength(self):
    # (batch, heads, length, depth)
    x = np.random.rand(5, 7, 2, 7)
    y = np.random.rand(5, 7, 2, 7)
    block_length = 3
    a = common_attention.masked_relative_local_attention_1d(
        tf.constant(x, dtype=tf.float32),
        tf.constant(y, dtype=tf.float32),
        tf.constant(y, dtype=tf.float32),
        block_length=block_length,
        heads_share_relative_embedding=True,
        name="masked_relative_local_attention_1d")
    self.evaluate(tf.global_variables_initializer())
    res = self.evaluate(a)
    self.assertEqual(res.shape, (5, 7, 2, 7))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag4481')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/layers/common_attention_test.py: 1520-1535
</a>
<div class="mid" id="frag4481" style="display:none"><pre>
  def testMaskedRelativeLocalAttentionV2SeqShorterThanTwiceBlockLength(self):
    # (batch, heads, length, depth)
    x = np.random.rand(5, 7, 5, 7)
    y = np.random.rand(5, 7, 5, 7)
    block_length = 3
    a = common_attention.masked_relative_local_attention_1d(
        tf.constant(x, dtype=tf.float32),
        tf.constant(y, dtype=tf.float32),
        tf.constant(y, dtype=tf.float32),
        block_length=block_length,
        heads_share_relative_embedding=True,
        name="masked_relative_local_attention_1d")
    self.evaluate(tf.global_variables_initializer())
    res = self.evaluate(a)
    self.assertEqual(res.shape, (5, 7, 5, 7))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 48:</b> &nbsp; 2 fragments, nominal size 18 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag4482')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/layers/common_attention_test.py: 1536-1558
</a>
<div class="mid" id="frag4482" style="display:none"><pre>
  def testBiasBatchCoordinates(self):
    """Testing the batch coordinates mask."""
    q = tf.constant([0, 0, 1, 1, 1, 1, 2, 2, 2], dtype=tf.int32)
    q = tf.expand_dims(q, axis=-1)

    k = tf.constant([0, 0, 0, 2, 2, 3, 3, 3], dtype=tf.int32)
    k = tf.expand_dims(k, axis=-1)

    ground_truth = np.array([
        [0, 0, 0, 1, 1, 1, 1, 1],  # 0
        [0, 0, 0, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1],  # 1 (just masked)
        [1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 0, 0, 1, 1, 1],  # 2
        [1, 1, 1, 0, 0, 1, 1, 1],
        [1, 1, 1, 0, 0, 1, 1, 1],
    ], np.float32) * -1e9

    bias = common_attention.attention_bias_coordinates(q, k)
    self.assertAllClose(self.evaluate(bias), ground_truth)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag4483')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/layers/common_attention_test.py: 1560-1582
</a>
<div class="mid" id="frag4483" style="display:none"><pre>
  def testBiasFuture(self):
    """Testing the sequence order mask."""
    q = tf.constant([0, 1, 2, 3, 0, 1, 2, 0, 1], dtype=tf.int32)
    q = tf.expand_dims(q, axis=-1)

    k = tf.constant([0, 1, 2, 3, 4, 0, 1, 2], dtype=tf.int32)
    k = tf.expand_dims(k, axis=-1)

    ground_truth = np.array([
        [0, 1, 1, 1, 1, 0, 1, 1],  # 0
        [0, 0, 1, 1, 1, 0, 0, 1],  # 1
        [0, 0, 0, 1, 1, 0, 0, 0],  # 2
        [0, 0, 0, 0, 1, 0, 0, 0],  # 3
        [0, 1, 1, 1, 1, 0, 1, 1],  # 0
        [0, 0, 1, 1, 1, 0, 0, 1],  # 1
        [0, 0, 0, 1, 1, 0, 0, 0],  # 2
        [0, 1, 1, 1, 1, 0, 1, 1],  # 0
        [0, 0, 1, 1, 1, 0, 0, 1],  # 1
    ], np.float32) * -1e9

    bias = common_attention.attention_bias_future(q, k)
    self.assertAllClose(self.evaluate(bias), ground_truth)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 49:</b> &nbsp; 3 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag4920')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/layers/modalities.py: 714-738
</a>
<div class="mid" id="frag4920" style="display:none"><pre>
def one_hot_class_label_loss(top_out,
                             targets,
                             model_hparams,
                             vocab_size,
                             weights_fn):
  """Apply softmax cross-entropy between outputs and targets.

  Args:
    top_out: logits Tensor with shape [batch, ?, ?, num_classes]
    targets: one-hot encoding Tensor with shape [batch, ?, ?, num_classes]
    model_hparams: HParams, model hyperparmeters.
    vocab_size: int, vocabulary size.
    weights_fn:

  Returns:
    loss_scale (cross-entropy), loss_denom
  """
  del model_hparams, vocab_size  # unused arg
  loss_scale = tf.losses.softmax_cross_entropy(
      onehot_labels=targets, logits=top_out)
  weights = weights_fn(targets)
  loss_denom = tf.reduce_sum(weights)
  return loss_scale, loss_denom


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag4923')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/layers/modalities.py: 768-783
</a>
<div class="mid" id="frag4923" style="display:none"><pre>
def sigmoid_class_label_loss(top_out,
                             targets,
                             model_hparams,
                             vocab_size,
                             weights_fn):
  """Loss for class label."""
  # Expect inputs of size [batch-size, timesteps, 1, num-classes], where the
  # last dimension of num-classes represents logits for binary labels
  del model_hparams, vocab_size  # unused arg
  loss_scale = tf.losses.sigmoid_cross_entropy(
      multi_class_labels=targets, logits=top_out)
  weights = weights_fn(targets)
  loss_denom = tf.reduce_sum(weights)
  return loss_scale, loss_denom


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag4924')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/layers/modalities.py: 784-799
</a>
<div class="mid" id="frag4924" style="display:none"><pre>
def sigmoid_max_pooling_class_label_loss(top_out,
                                         targets,
                                         model_hparams,
                                         vocab_size,
                                         weights_fn):
  """Loss for class label."""
  # Expect inputs of size [batch-size, 1, 1, num-classes], where the
  # last dimension of num-classes represents logits for binary labels
  del model_hparams, vocab_size  # unused arg
  loss_scale = tf.losses.sigmoid_cross_entropy(
      multi_class_labels=targets, logits=top_out)
  weights = weights_fn(targets)
  loss_denom = tf.reduce_sum(weights)
  return loss_scale, loss_denom


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 50:</b> &nbsp; 3 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag4941')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/layers/modalities.py: 1036-1061
</a>
<div class="mid" id="frag4941" style="display:none"><pre>
def sigmoid_max_pooling_class_label_top(body_output,
                                        targets,
                                        model_hparams,
                                        vocab_size):
  """Transform inputs from model space to target space.

  Average over inner dims and a linear layer to logits.

  Args:
    body_output: A Tensor with shape [batch, timesteps, 1, body_output_size].
    targets:
    model_hparams: HParams, model hyperparmeters.
    vocab_size: int, vocabulary size.

  Returns:
    a Tensors, each with shape [batch_size, 1, 1, vocab_size]
  """
  del targets  # unused arg
  with tf.variable_scope(
      "sigmoid_max_pooling_class_symbol_modality_%d_%d" % (
          vocab_size, model_hparams.hidden_size)):
    x = body_output
    x = tf.reduce_max(x, axis=1, keepdims=True)
    return tf.layers.dense(x, vocab_size)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag4944')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/layers/modalities.py: 1090-1103
</a>
<div class="mid" id="frag4944" style="display:none"><pre>
def softmax_max_pooling_class_label_top(body_output,
                                        targets,
                                        model_hparams,
                                        vocab_size):
  """Loss for class label."""
  del targets  # unused arg
  with tf.variable_scope(
      "softmax_max_pooling_onehot_class_label_modality_%d_%d" % (
          vocab_size, model_hparams.hidden_size)):
    x = body_output
    x = tf.reduce_max(x, axis=1, keepdims=True)
    return tf.layers.dense(x, vocab_size)


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag4942')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/layers/modalities.py: 1062-1075
</a>
<div class="mid" id="frag4942" style="display:none"><pre>
def softmax_average_pooling_class_label_top(body_output,
                                            targets,
                                            model_hparams,
                                            vocab_size):
  """Loss for class label."""
  del targets  # unused arg
  with tf.variable_scope(
      "softmax_average_pooling_onehot_class_label_modality_%d_%d" % (
          vocab_size, model_hparams.hidden_size)):
    x = body_output
    x = tf.reduce_mean(x, axis=1, keepdims=True)
    return tf.layers.dense(x, vocab_size)


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 51:</b> &nbsp; 2 fragments, nominal size 15 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag5044')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/layers/common_layers_test.py: 532-547
</a>
<div class="mid" id="frag5044" style="display:none"><pre>
  def testWeightsMultiProblemAll(self):
    labels = tf.constant(np.array([[12, 15, 1, 20, 100],
                                   [67, 1, 34, 45, 124],
                                   [78, 2, 34, 18, 29],
                                   [78, 123, 55, 1, 33],
                                   [1, 18, 22, 36, 59]]), dtype=tf.int32)
    taskid = 1
    expected_mask = np.array([[1, 1, 1, 1, 1],
                              [1, 1, 1, 1, 1],
                              [0, 0, 0, 0, 0],
                              [1, 1, 1, 1, 1],
                              [1, 1, 1, 1, 1]])
    actual_mask = common_layers.weights_multi_problem_all(labels, taskid)
    actual_mask_eval = self.evaluate(actual_mask)
    self.assertAllClose(expected_mask, actual_mask_eval)

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag5045')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/layers/common_layers_test.py: 549-564
</a>
<div class="mid" id="frag5045" style="display:none"><pre>
  def testWeightsMultiProblem(self):
    labels = tf.constant(np.array([[12, 15, 1, 20, 100],
                                   [67, 1, 34, 45, 124],
                                   [78, 2, 34, 18, 29],
                                   [78, 123, 55, 1, 33],
                                   [1, 18, 22, 36, 59]]), dtype=tf.int32)
    taskid = 1
    expected_mask = np.array([[0, 0, 0, 1, 1],
                              [0, 0, 1, 1, 1],
                              [0, 0, 0, 0, 0],
                              [0, 0, 0, 0, 1],
                              [0, 1, 1, 1, 1]])
    actual_mask = common_layers.weights_multi_problem(labels, taskid)
    actual_mask_eval = self.evaluate(actual_mask)
    self.assertAllClose(expected_mask, actual_mask_eval)

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 52:</b> &nbsp; 2 fragments, nominal size 16 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag5055')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/layers/common_layers_test.py: 757-775
</a>
<div class="mid" id="frag5055" style="display:none"><pre>
  def testCycleGANUpsampleNnUpsampleConv(self):
    batch = 8
    height = 32
    width = 32
    num_channels = 3
    output_filters = 10
    stride = [2, 3]  # we want height to be x2 and width to be x3
    random_input = np.random.rand(batch, height, width, num_channels).astype(
        np.float32)

    # nn_upsample_conv gives exactly the shapes we'd expect.
    upsampled_output = common_layers.cyclegan_upsample(
        random_input, output_filters, stride, "nn_upsample_conv")
    upsampled_output_shape = tf.shape(upsampled_output)
    self.evaluate(tf.global_variables_initializer())
    self.assertAllEqual(
        [batch, height * stride[0], width * stride[1], output_filters],
        self.evaluate(upsampled_output_shape))

</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag5056')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/layers/common_layers_test.py: 777-795
</a>
<div class="mid" id="frag5056" style="display:none"><pre>
  def testCycleGANUpsampleBilinearUpsampleConv(self):
    batch = 8
    height = 32
    width = 32
    num_channels = 3
    output_filters = 10
    stride = [2, 3]  # we want height to be x2 and width to be x3
    random_input = np.random.rand(batch, height, width, num_channels).astype(
        np.float32)

    # bilinear_upsample_conv gives exactly the shapes we'd expect.
    upsampled_output = common_layers.cyclegan_upsample(
        random_input, output_filters, stride, "bilinear_upsample_conv")
    upsampled_output_shape = tf.shape(upsampled_output)
    self.evaluate(tf.global_variables_initializer())
    self.assertAllEqual(
        [batch, height * stride[0], width * stride[1], output_filters],
        self.evaluate(upsampled_output_shape))

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 53:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag5236')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/layers/common_attention.py: 5841-5867
</a>
<div class="mid" id="frag5236" style="display:none"><pre>
def deconv_elems_1d(x, factor, out_depth=None):
  """Increase the length and change the dimensionality.

  Expand/project each positions of dim depth of the input into
  factor*tokens of dim out_depth

  Args:
    x (tf.Tensor): shape [batch_size, length, depth]
    factor (int): Multiplicative factor of each tokens.
    out_depth (int): Output depth (if None, keep depth constant)

  Returns:
    tf.Tensor: shape [batch_size, length*factor, out_depth]
  """
  out_depth = out_depth or x.get_shape().as_list()[-1]
  x = tf.expand_dims(x, 1)  # [batch_size, 1, length, depth]
  x = layers().Conv2DTranspose(
      filters=out_depth,
      kernel_size=(1, factor),
      strides=(1, factor),
      padding="valid",
      data_format="channels_last",
  )(x)  # [batch_size, 1, length*factor, out_depth]
  x = tf.squeeze(x, 1)  # [batch_size, length*factor, depth]
  return x


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag5237')" href="javascript:;">
tensor2tensor-1.15.7/tensor2tensor/layers/common_attention.py: 5869-5899
</a>
<div class="mid" id="frag5237" style="display:none"><pre>
def conv_elems_1d(x, factor, out_depth=None):
  """Decrease the length and change the dimensionality.

  Merge/restore/compress factors positions of dim depth of the input into
  a single position of dim out_depth.
  This is basically just a strided convolution without overlap
  between each strides. The original length has to be divided by factor.

  Args:
    x (tf.Tensor): shape [batch_size, length, depth]
    factor (int): Length compression factor.
    out_depth (int): Output depth

  Returns:
    tf.Tensor: shape [batch_size, length//factor, out_depth]
  """
  out_depth = out_depth or x.get_shape().as_list()[-1]
  # with tf.control_dependencies(  # Dynamic assertion
  #     [tf.assert_equal(tf.shape(x)[1] % factor, 0)]):
  x = tf.expand_dims(x, 1)  # [batch_size, 1, length, depth]
  x = layers().Conv2D(
      filters=out_depth,
      kernel_size=(1, factor),
      strides=(1, factor),
      padding="valid",
      data_format="channels_last",
  )(x)  # [batch_size, 1, length//factor, out_depth]
  x = tf.squeeze(x, 1)  # [batch_size, length//factor, depth]
  return x


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<script language="JavaScript">
function ShowHide(divId) { 
    if(document.getElementById(divId).style.display == 'none') {
        document.getElementById(divId).style.display='block';
    } else { 
        document.getElementById(divId).style.display = 'none';
    } 
}
</script>
</body>
</html>
