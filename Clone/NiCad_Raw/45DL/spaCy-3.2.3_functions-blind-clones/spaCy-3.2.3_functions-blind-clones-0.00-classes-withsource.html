<html>
<head>
    <title>NiCad6 Clone Report</title>
    <style type="text/css">
        body {font-family:sans-serif;}
        table {background-color:white; border:0px; padding:0px; border-spacing:4px; width:auto; margin-left:30px; margin-right:auto;}
        td {background-color:rgba(192,212,238,0.8); border:0px; padding:8px; width:auto; vertical-align:top; border-radius:8px}
        pre {background-color:white; padding:4px;}
        a {color:darkblue;}
    </style>
</head>
<body>
<h2>NiCad6 Clone Report</h2>
<table>
<tr style="font-size:14pt">
<td><b>System:</b> &nbsp; spaCy-3.2.3</td>
<td><b>Clone pairs:</b> &nbsp; 319</td>
<td><b>Clone classes:</b> &nbsp; 25</td>
</tr>
<tr style="font-size:12pt">
<td style="background-color:white">Clone type: &nbsp; 2</td>
<td style="background-color:white">Granularity: &nbsp; functions-blind</td>
<td style="background-color:white">Max diff threshold: &nbsp; 0%</td>
<td style="background-color:white">Clone size: &nbsp; 10 - 2500 lines</td>
<td style="background-color:white">Total functions-blind: &nbsp; 1944</td>
</tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 1:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag187')" href="javascript:;">
spaCy-3.2.3/spacy/tests/training/test_new_example.py: 258-270
</a>
<div class="mid" id="frag187" style="display:none"><pre>
def test_Example_from_dict_with_spans(annots):
    vocab = Vocab()
    predicted = Doc(vocab, words=annots["words"])
    example = Example.from_dict(predicted, annots)
    assert len(list(example.reference.ents)) == 0
    assert len(list(example.reference.spans["cities"])) == 2
    assert len(list(example.reference.spans["people"])) == 1
    for span in example.reference.spans["cities"]:
        assert span.label_ == "LOC"
    for span in example.reference.spans["people"]:
        assert span.label_ == "PERSON"


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag188')" href="javascript:;">
spaCy-3.2.3/spacy/tests/training/test_new_example.py: 283-295
</a>
<div class="mid" id="frag188" style="display:none"><pre>
def test_Example_from_dict_with_spans_overlapping(annots):
    vocab = Vocab()
    predicted = Doc(vocab, words=annots["words"])
    example = Example.from_dict(predicted, annots)
    assert len(list(example.reference.ents)) == 0
    assert len(list(example.reference.spans["cities"])) == 3
    assert len(list(example.reference.spans["people"])) == 1
    for span in example.reference.spans["cities"]:
        assert span.label_ == "LOC"
    for span in example.reference.spans["people"]:
        assert span.label_ == "PERSON"


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 2:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag295')" href="javascript:;">
spaCy-3.2.3/spacy/tests/matcher/test_matcher_api.py: 418-429
</a>
<div class="mid" id="frag295" style="display:none"><pre>
def test_matcher_regex(en_vocab):
    matcher = Matcher(en_vocab)
    pattern = [{"ORTH": {"REGEX": r"(?:a|an)"}}]
    matcher.add("A_OR_AN", [pattern])
    doc = Doc(en_vocab, words=["an", "a", "hi"])
    matches = matcher(doc)
    assert len(matches) == 2
    doc = Doc(en_vocab, words=["bye"])
    matches = matcher(doc)
    assert len(matches) == 0


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag296')" href="javascript:;">
spaCy-3.2.3/spacy/tests/matcher/test_matcher_api.py: 430-441
</a>
<div class="mid" id="frag296" style="display:none"><pre>
def test_matcher_regex_shape(en_vocab):
    matcher = Matcher(en_vocab)
    pattern = [{"SHAPE": {"REGEX": r"^[^x]+$"}}]
    matcher.add("NON_ALPHA", [pattern])
    doc = Doc(en_vocab, words=["99", "problems", "!"])
    matches = matcher(doc)
    assert len(matches) == 2
    doc = Doc(en_vocab, words=["bye"])
    matches = matcher(doc)
    assert len(matches) == 0


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 3:</b> &nbsp; 2 fragments, nominal size 17 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag395')" href="javascript:;">
spaCy-3.2.3/spacy/tests/parser/test_preset_sbd.py: 24-45
</a>
<div class="mid" id="frag395" style="display:none"><pre>
def parser(vocab):
    vocab.strings.add("ROOT")
    cfg = {"model": DEFAULT_PARSER_MODEL}
    model = registry.resolve(cfg, validate=True)["model"]
    parser = DependencyParser(vocab, model)
    parser.cfg["token_vector_width"] = 4
    parser.cfg["hidden_width"] = 32
    # parser.add_label('right')
    parser.add_label("left")
    parser.initialize(lambda: [_parser_example(parser)])
    sgd = Adam(0.001)

    for i in range(10):
        losses = {}
        doc = Doc(vocab, words=["a", "b", "c", "d"])
        example = Example.from_dict(
            doc, {"heads": [1, 1, 3, 3], "deps": ["left", "ROOT", "left", "ROOT"]}
        )
        parser.update([example], sgd=sgd, losses=losses)
    return parser


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag492')" href="javascript:;">
spaCy-3.2.3/spacy/tests/parser/test_parse.py: 70-91
</a>
<div class="mid" id="frag492" style="display:none"><pre>
def parser(vocab):
    vocab.strings.add("ROOT")
    cfg = {"model": DEFAULT_PARSER_MODEL}
    model = registry.resolve(cfg, validate=True)["model"]
    parser = DependencyParser(vocab, model)
    parser.cfg["token_vector_width"] = 4
    parser.cfg["hidden_width"] = 32
    # parser.add_label('right')
    parser.add_label("left")
    parser.initialize(lambda: [_parser_example(parser)])
    sgd = Adam(0.001)

    for i in range(10):
        losses = {}
        doc = Doc(vocab, words=["a", "b", "c", "d"])
        example = Example.from_dict(
            doc, {"heads": [1, 1, 3, 3], "deps": ["left", "ROOT", "left", "ROOT"]}
        )
        parser.update([example], sgd=sgd, losses=losses)
    return parser


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 4:</b> &nbsp; 2 fragments, nominal size 13 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag622')" href="javascript:;">
spaCy-3.2.3/spacy/tests/pipeline/test_attributeruler.py: 18-34
</a>
<div class="mid" id="frag622" style="display:none"><pre>
def pattern_dicts():
    return [
        {
            "patterns": [[{"ORTH": "a"}], [{"ORTH": "irrelevant"}]],
            "attrs": {"LEMMA": "the", "MORPH": "Case=Nom|Number=Plur"},
        },
        # one pattern sets the lemma
        {"patterns": [[{"ORTH": "test"}]], "attrs": {"LEMMA": "cat"}},
        # another pattern sets the morphology
        {
            "patterns": [[{"ORTH": "test"}]],
            "attrs": {"MORPH": "Case=Nom|Number=Sing"},
            "index": 0,
        },
    ]


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag629')" href="javascript:;">
spaCy-3.2.3/spacy/tests/pipeline/test_attributeruler.py: 109-124
</a>
<div class="mid" id="frag629" style="display:none"><pre>
    def attribute_ruler_patterns():
        return [
            {
                "patterns": [[{"ORTH": "a"}], [{"ORTH": "irrelevant"}]],
                "attrs": {"LEMMA": "the", "MORPH": "Case=Nom|Number=Plur"},
            },
            # one pattern sets the lemma
            {"patterns": [[{"ORTH": "test"}]], "attrs": {"LEMMA": "cat"}},
            # another pattern sets the morphology
            {
                "patterns": [[{"ORTH": "test"}]],
                "attrs": {"MORPH": "Case=Nom|Number=Sing"},
                "index": 0,
            },
        ]

</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 5:</b> &nbsp; 5 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1007')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/sr/test_tokenizer.py: 103-114
</a>
<div class="mid" id="frag1007" style="display:none"><pre>
def test_sr_tokenizer_two_diff_punct(
    sr_tokenizer, punct_open, punct_close, punct_open2, punct_close2, text
):
    tokens = sr_tokenizer(punct_open2 + punct_open + text + punct_close + punct_close2)
    assert len(tokens) == 5
    assert tokens[0].text == punct_open2
    assert tokens[1].text == punct_open
    assert tokens[2].text == text
    assert tokens[3].text == punct_close
    assert tokens[4].text == punct_close2


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1236')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/ru/test_tokenizer.py: 103-114
</a>
<div class="mid" id="frag1236" style="display:none"><pre>
def test_ru_tokenizer_two_diff_punct(
    ru_tokenizer, punct_open, punct_close, punct_open2, punct_close2, text
):
    tokens = ru_tokenizer(punct_open2 + punct_open + text + punct_close + punct_close2)
    assert len(tokens) == 5
    assert tokens[0].text == punct_open2
    assert tokens[1].text == punct_open
    assert tokens[2].text == text
    assert tokens[3].text == punct_close
    assert tokens[4].text == punct_close2


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1139')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/uk/test_tokenizer.py: 119-130
</a>
<div class="mid" id="frag1139" style="display:none"><pre>
def test_uk_tokenizer_two_diff_punct(
    uk_tokenizer, punct_open, punct_close, punct_open2, punct_close2, text
):
    tokens = uk_tokenizer(punct_open2 + punct_open + text + punct_close + punct_close2)
    assert len(tokens) == 5
    assert tokens[0].text == punct_open2
    assert tokens[1].text == punct_open
    assert tokens[2].text == text
    assert tokens[3].text == punct_close
    assert tokens[4].text == punct_close2


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1352')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tl/test_punct.py: 105-116
</a>
<div class="mid" id="frag1352" style="display:none"><pre>
def test_tl_tokenizer_two_diff_punct(
    tl_tokenizer, punct_open, punct_close, punct_open2, punct_close2, text
):
    tokens = tl_tokenizer(punct_open2 + punct_open + text + punct_close + punct_close2)
    assert len(tokens) == 5
    assert tokens[0].text == punct_open2
    assert tokens[1].text == punct_open
    assert tokens[2].text == text
    assert tokens[3].text == punct_close
    assert tokens[4].text == punct_close2


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1394')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/en/test_punct.py: 105-116
</a>
<div class="mid" id="frag1394" style="display:none"><pre>
def test_en_tokenizer_two_diff_punct(
    en_tokenizer, punct_open, punct_close, punct_open2, punct_close2, text
):
    tokens = en_tokenizer(punct_open2 + punct_open + text + punct_close + punct_close2)
    assert len(tokens) == 5
    assert tokens[0].text == punct_open2
    assert tokens[1].text == punct_open
    assert tokens[2].text == text
    assert tokens[3].text == punct_close
    assert tokens[4].text == punct_close2


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 6:</b> &nbsp; 3 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1056')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/ko/test_serialize.py: 7-20
</a>
<div class="mid" id="frag1056" style="display:none"><pre>
def test_ko_tokenizer_serialize(ko_tokenizer):
    tokenizer_bytes = ko_tokenizer.to_bytes()
    nlp = Korean()
    nlp.tokenizer.from_bytes(tokenizer_bytes)
    assert tokenizer_bytes == nlp.tokenizer.to_bytes()

    with make_tempdir() as d:
        file_path = d / "tokenizer"
        ko_tokenizer.to_disk(file_path)
        nlp = Korean()
        nlp.tokenizer.from_disk(file_path)
        assert tokenizer_bytes == nlp.tokenizer.to_bytes()


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1447')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/th/test_serialize.py: 7-20
</a>
<div class="mid" id="frag1447" style="display:none"><pre>
def test_th_tokenizer_serialize(th_tokenizer):
    tokenizer_bytes = th_tokenizer.to_bytes()
    nlp = Thai()
    nlp.tokenizer.from_bytes(tokenizer_bytes)
    assert tokenizer_bytes == nlp.tokenizer.to_bytes()

    with make_tempdir() as d:
        file_path = d / "tokenizer"
        th_tokenizer.to_disk(file_path)
        nlp = Thai()
        nlp.tokenizer.from_disk(file_path)
        assert tokenizer_bytes == nlp.tokenizer.to_bytes()


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1187')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/zh/test_serialize.py: 6-19
</a>
<div class="mid" id="frag1187" style="display:none"><pre>
def zh_tokenizer_serialize(zh_tokenizer):
    tokenizer_bytes = zh_tokenizer.to_bytes()
    nlp = Chinese()
    nlp.tokenizer.from_bytes(tokenizer_bytes)
    assert tokenizer_bytes == nlp.tokenizer.to_bytes()

    with make_tempdir() as d:
        file_path = d / "tokenizer"
        zh_tokenizer.to_disk(file_path)
        nlp = Chinese()
        nlp.tokenizer.from_disk(file_path)
        assert tokenizer_bytes == nlp.tokenizer.to_bytes()


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 7:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1097')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/de/test_parser.py: 4-15
</a>
<div class="mid" id="frag1097" style="display:none"><pre>
def test_de_parser_noun_chunks_standard_de(de_vocab):
    words = ["Eine", "Tasse", "steht", "auf", "dem", "Tisch", "."]
    heads = [1, 2, 2, 2, 5, 3, 2]
    pos = ["DET", "NOUN", "VERB", "ADP", "DET", "NOUN", "PUNCT"]
    deps = ["nk", "sb", "ROOT", "mo", "nk", "nk", "punct"]
    doc = Doc(de_vocab, words=words, pos=pos, deps=deps, heads=heads)
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 2
    assert chunks[0].text_with_ws == "Eine Tasse "
    assert chunks[1].text_with_ws == "dem Tisch "


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1404')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/en/test_parser.py: 29-40
</a>
<div class="mid" id="frag1404" style="display:none"><pre>
def test_en_parser_noun_chunks_pp_chunks(en_vocab):
    words = ["A", "phrase", "with", "another", "phrase", "occurs", "."]
    heads = [1, 5, 1, 4, 2, 5, 5]
    pos = ["DET", "NOUN", "ADP", "DET", "NOUN", "VERB", "PUNCT"]
    deps = ["det", "nsubj", "prep", "det", "pobj", "ROOT", "punct"]
    doc = Doc(en_vocab, words=words, pos=pos, deps=deps, heads=heads)
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 2
    assert chunks[0].text_with_ws == "A phrase "
    assert chunks[1].text_with_ws == "another phrase "


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 8:</b> &nbsp; 5 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1292')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 4-17
</a>
<div class="mid" id="frag1292" style="display:none"><pre>
def test_tr_noun_chunks_amod_simple(tr_tokenizer):
    text = "sarı kedi"
    heads = [1, 1]
    deps = ["amod", "ROOT"]
    pos = ["ADJ", "NOUN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "sarı kedi "


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1306')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 200-213
</a>
<div class="mid" id="frag1306" style="display:none"><pre>
def test_tr_noun_chunks_acl_verb(tr_tokenizer):
    text = "sevdiğim sanatçılar"
    heads = [1, 1]
    deps = ["acl", "ROOT"]
    pos = ["VERB", "NOUN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "sevdiğim sanatçılar "


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1293')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 18-31
</a>
<div class="mid" id="frag1293" style="display:none"><pre>
def test_tr_noun_chunks_nmod_simple(tr_tokenizer):
    text = "arkadaşımın kedisi"  # my friend's cat
    heads = [1, 1]
    deps = ["nmod", "ROOT"]
    pos = ["NOUN", "NOUN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "arkadaşımın kedisi "


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1325')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 479-492
</a>
<div class="mid" id="frag1325" style="display:none"><pre>
def test_tr_noun_chunks_flat_simple(tr_tokenizer):
    text = "New York"
    heads = [0, 0]
    deps = ["ROOT", "flat"]
    pos = ["PROPN", "PROPN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "New York "


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1294')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 32-45
</a>
<div class="mid" id="frag1294" style="display:none"><pre>
def test_tr_noun_chunks_determiner_simple(tr_tokenizer):
    text = "O kedi"  # that cat
    heads = [1, 1]
    deps = ["det", "ROOT"]
    pos = ["DET", "NOUN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "O kedi "


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 9:</b> &nbsp; 9 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1295')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 46-59
</a>
<div class="mid" id="frag1295" style="display:none"><pre>
def test_tr_noun_chunks_nmod_amod(tr_tokenizer):
    text = "okulun eski müdürü"
    heads = [2, 2, 2]
    deps = ["nmod", "amod", "ROOT"]
    pos = ["NOUN", "ADJ", "NOUN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "okulun eski müdürü "


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1309')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 242-255
</a>
<div class="mid" id="frag1309" style="display:none"><pre>
def test_tr_noun_chunks_np_recursive_nsubj_to_root(tr_tokenizer):
    text = "Simge'nin okuduğu kitap"
    heads = [1, 2, 2]
    deps = ["nsubj", "acl", "ROOT"]
    pos = ["PROPN", "VERB", "NOUN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "Simge'nin okuduğu kitap "


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1299')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 102-115
</a>
<div class="mid" id="frag1299" style="display:none"><pre>
def test_tr_noun_chunks_nmod_two(tr_tokenizer):
    text = "kızın saçının rengi"
    heads = [1, 2, 2]
    deps = ["nmod", "nmod", "ROOT"]
    pos = ["NOUN", "NOUN", "NOUN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "kızın saçının rengi "


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1327')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 507-520
</a>
<div class="mid" id="frag1327" style="display:none"><pre>
def test_tr_noun_chunks_flat_names_and_title2(tr_tokenizer):
    text = "Ahmet Vefik Paşa"
    heads = [2, 0, 2]
    deps = ["nmod", "flat", "ROOT"]
    pos = ["PROPN", "PROPN", "PROPN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "Ahmet Vefik Paşa "


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1310')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 256-269
</a>
<div class="mid" id="frag1310" style="display:none"><pre>
def test_tr_noun_chunks_np_recursive_nsubj_attached_to_pron_root(tr_tokenizer):
    text = "Simge'nin konuşabileceği birisi"
    heads = [1, 2, 2]
    deps = ["nsubj", "acl", "ROOT"]
    pos = ["PROPN", "VERB", "PRON"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "Simge'nin konuşabileceği birisi "


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1305')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 186-199
</a>
<div class="mid" id="frag1305" style="display:none"><pre>
def test_tr_noun_chunks_acl_simple(tr_tokenizer):
    text = "bahçesi olan okul"
    heads = [2, 0, 2]
    deps = ["acl", "cop", "ROOT"]
    pos = ["NOUN", "AUX", "NOUN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "bahçesi olan okul "


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1326')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 493-506
</a>
<div class="mid" id="frag1326" style="display:none"><pre>
def test_tr_noun_chunks_flat_names_and_title(tr_tokenizer):
    text = "Gazi Mustafa Kemal"
    heads = [1, 1, 1]
    deps = ["nmod", "ROOT", "flat"]
    pos = ["PROPN", "PROPN", "PROPN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "Gazi Mustafa Kemal "


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1297')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 74-87
</a>
<div class="mid" id="frag1297" style="display:none"><pre>
def test_tr_noun_chunks_two_adjs_simple(tr_tokenizer):
    text = "beyaz tombik kedi"
    heads = [2, 2, 2]
    deps = ["amod", "amod", "ROOT"]
    pos = ["ADJ", "ADJ", "NOUN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "beyaz tombik kedi "


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1296')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 60-73
</a>
<div class="mid" id="frag1296" style="display:none"><pre>
def test_tr_noun_chunks_one_det_one_adj_simple(tr_tokenizer):
    text = "O sarı kedi"
    heads = [2, 2, 2]
    deps = ["det", "amod", "ROOT"]
    pos = ["DET", "ADJ", "NOUN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "O sarı kedi "


</pre></div>
</td>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 10:</b> &nbsp; 12 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1298')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 88-101
</a>
<div class="mid" id="frag1298" style="display:none"><pre>
def test_tr_noun_chunks_one_det_two_adjs_simple(tr_tokenizer):
    text = "o beyaz tombik kedi"
    heads = [3, 3, 3, 3]
    deps = ["det", "amod", "amod", "ROOT"]
    pos = ["DET", "ADJ", "ADJ", "NOUN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "o beyaz tombik kedi "


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1307')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 214-227
</a>
<div class="mid" id="frag1307" style="display:none"><pre>
def test_tr_noun_chunks_acl_nmod(tr_tokenizer):
    text = "en sevdiğim ses sanatçısı"
    heads = [1, 3, 3, 3]
    deps = ["advmod", "acl", "nmod", "ROOT"]
    pos = ["ADV", "VERB", "NOUN", "NOUN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "en sevdiğim ses sanatçısı "


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1304')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 172-185
</a>
<div class="mid" id="frag1304" style="display:none"><pre>
def test_tr_noun_chunks_det_amod_nmod(tr_tokenizer):
    text = "bazı eski oyun kuralları"
    heads = [3, 3, 3, 3]
    deps = ["det", "nmod", "nmod", "ROOT"]
    pos = ["DET", "ADJ", "NOUN", "NOUN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "bazı eski oyun kuralları "


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1303')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 158-171
</a>
<div class="mid" id="frag1303" style="display:none"><pre>
def test_tr_noun_chunks_nmod_three(tr_tokenizer):
    text = "güney Afrika ülkelerinden Mozambik"
    heads = [1, 2, 3, 3]
    deps = ["nmod", "nmod", "nmod", "ROOT"]
    pos = ["NOUN", "PROPN", "NOUN", "PROPN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "güney Afrika ülkelerinden Mozambik "


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1300')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 116-129
</a>
<div class="mid" id="frag1300" style="display:none"><pre>
def test_tr_noun_chunks_chain_nmod_with_adj(tr_tokenizer):
    text = "ev sahibinin tatlı köpeği"
    heads = [1, 3, 3, 3]
    deps = ["nmod", "nmod", "amod", "ROOT"]
    pos = ["NOUN", "NOUN", "ADJ", "NOUN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "ev sahibinin tatlı köpeği "


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1308')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 228-241
</a>
<div class="mid" id="frag1308" style="display:none"><pre>
def test_tr_noun_chunks_acl_nmod2(tr_tokenizer):
    text = "bildiğim bir turizm şirketi"
    heads = [3, 3, 3, 3]
    deps = ["acl", "det", "nmod", "ROOT"]
    pos = ["VERB", "DET", "NOUN", "NOUN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "bildiğim bir turizm şirketi "


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1301')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 130-143
</a>
<div class="mid" id="frag1301" style="display:none"><pre>
def test_tr_noun_chunks_chain_nmod_with_acl(tr_tokenizer):
    text = "ev sahibinin gelen köpeği"
    heads = [1, 3, 3, 3]
    deps = ["nmod", "nmod", "acl", "ROOT"]
    pos = ["NOUN", "NOUN", "VERB", "NOUN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "ev sahibinin gelen köpeği "


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1302')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 144-157
</a>
<div class="mid" id="frag1302" style="display:none"><pre>
def test_tr_noun_chunks_chain_nmod_head_with_amod_acl(tr_tokenizer):
    text = "arabanın kırdığım sol aynası"
    heads = [3, 3, 3, 3]
    deps = ["nmod", "acl", "amod", "ROOT"]
    pos = ["NOUN", "VERB", "ADJ", "NOUN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "arabanın kırdığım sol aynası "


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1328')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 521-534
</a>
<div class="mid" id="frag1328" style="display:none"><pre>
def test_tr_noun_chunks_flat_name_lastname_and_title(tr_tokenizer):
    text = "Cumhurbaşkanı Ahmet Necdet Sezer"
    heads = [1, 1, 1, 1]
    deps = ["nmod", "ROOT", "flat", "flat"]
    pos = ["NOUN", "PROPN", "PROPN", "PROPN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "Cumhurbaşkanı Ahmet Necdet Sezer "


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1317')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 357-370
</a>
<div class="mid" id="frag1317" style="display:none"><pre>
def test_tr_noun_chunks_two_nouns_in_nmod2(tr_tokenizer):
    text = "tatlı ve gürbüz çocuklar"
    heads = [3, 2, 0, 3]
    deps = ["amod", "cc", "conj", "ROOT"]
    pos = ["ADJ", "CCONJ", "NOUN", "NOUN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "tatlı ve gürbüz çocuklar "


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1311')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 270-283
</a>
<div class="mid" id="frag1311" style="display:none"><pre>
def test_tr_noun_chunks_np_recursive_nsubj_in_subnp(tr_tokenizer):
    text = "Simge'nin yarın gideceği yer"
    heads = [2, 2, 3, 3]
    deps = ["nsubj", "obl", "acl", "ROOT"]
    pos = ["PROPN", "NOUN", "VERB", "NOUN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "Simge'nin yarın gideceği yer "


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1316')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 343-356
</a>
<div class="mid" id="frag1316" style="display:none"><pre>
def test_tr_noun_chunks_two_nouns_in_nmod(tr_tokenizer):
    text = "kız ve erkek çocuklar"
    heads = [3, 2, 0, 3]
    deps = ["nmod", "cc", "conj", "ROOT"]
    pos = ["NOUN", "CCONJ", "NOUN", "NOUN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "kız ve erkek çocuklar "


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 11:</b> &nbsp; 4 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1312')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 284-297
</a>
<div class="mid" id="frag1312" style="display:none"><pre>
def test_tr_noun_chunks_np_recursive_two_nmods(tr_tokenizer):
    text = "ustanın kapısını degiştireceği çamasır makinası"
    heads = [2, 2, 4, 4, 4]
    deps = ["nsubj", "obj", "acl", "nmod", "ROOT"]
    pos = ["NOUN", "NOUN", "VERB", "NOUN", "NOUN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "ustanın kapısını degiştireceği çamasır makinası "


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1329')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 535-548
</a>
<div class="mid" id="frag1329" style="display:none"><pre>
def test_tr_noun_chunks_flat_in_nmod(tr_tokenizer):
    text = "Ahmet Sezer adında bir ögrenci"
    heads = [2, 0, 4, 4, 4]
    deps = ["nmod", "flat", "nmod", "det", "ROOT"]
    pos = ["PROPN", "PROPN", "NOUN", "DET", "NOUN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "Ahmet Sezer adında bir ögrenci "


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1313')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 298-311
</a>
<div class="mid" id="frag1313" style="display:none"><pre>
def test_tr_noun_chunks_np_recursive_four_nouns(tr_tokenizer):
    text = "kızına piyano dersi verdiğim hanım"
    heads = [3, 2, 3, 4, 4]
    deps = ["obl", "nmod", "obj", "acl", "ROOT"]
    pos = ["NOUN", "NOUN", "NOUN", "VERB", "NOUN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "kızına piyano dersi verdiğim hanım "


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1330')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 549-562
</a>
<div class="mid" id="frag1330" style="display:none"><pre>
def test_tr_noun_chunks_flat_and_chain_nmod(tr_tokenizer):
    text = "Batı Afrika ülkelerinden Sierra Leone"
    heads = [1, 2, 3, 3, 3]
    deps = ["nmod", "nmod", "nmod", "ROOT", "flat"]
    pos = ["NOUN", "PROPN", "NOUN", "PROPN", "PROPN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 1
    assert chunks[0].text_with_ws == "Batı Afrika ülkelerinden Sierra Leone "


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 12:</b> &nbsp; 2 fragments, nominal size 12 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1318')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 371-385
</a>
<div class="mid" id="frag1318" style="display:none"><pre>
def test_tr_noun_chunks_conj_simple(tr_tokenizer):
    text = "Sen ya da ben"
    heads = [0, 3, 1, 0]
    deps = ["ROOT", "cc", "fixed", "conj"]
    pos = ["PRON", "CCONJ", "CCONJ", "PRON"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 2
    assert chunks[0].text_with_ws == "ben "
    assert chunks[1].text_with_ws == "Sen "


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1321')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 418-432
</a>
<div class="mid" id="frag1321" style="display:none"><pre>
def test_tr_noun_chunks_conj_and_adj_phrase(tr_tokenizer):
    text = "ben ve akıllı çocuk"
    heads = [0, 3, 3, 0]
    deps = ["ROOT", "cc", "amod", "conj"]
    pos = ["PRON", "CCONJ", "ADJ", "NOUN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 2
    assert chunks[0].text_with_ws == "akıllı çocuk "
    assert chunks[1].text_with_ws == "ben "


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 13:</b> &nbsp; 3 fragments, nominal size 12 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1322')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 433-447
</a>
<div class="mid" id="frag1322" style="display:none"><pre>
def test_tr_noun_chunks_conj_fixed_adj_phrase(tr_tokenizer):
    text = "ben ya da akıllı çocuk"
    heads = [0, 4, 1, 4, 0]
    deps = ["ROOT", "cc", "fixed", "amod", "conj"]
    pos = ["PRON", "CCONJ", "CCONJ", "ADJ", "NOUN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 2
    assert chunks[0].text_with_ws == "akıllı çocuk "
    assert chunks[1].text_with_ws == "ben "


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1331')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 563-575
</a>
<div class="mid" id="frag1331" style="display:none"><pre>
def test_tr_noun_chunks_two_flats_conjed(tr_tokenizer):
    text = "New York ve Sierra Leone"
    heads = [0, 0, 3, 0, 3]
    deps = ["ROOT", "flat", "cc", "conj", "flat"]
    pos = ["PROPN", "PROPN", "CCONJ", "PROPN", "PROPN"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 2
    assert chunks[0].text_with_ws == "Sierra Leone "
    assert chunks[1].text_with_ws == "New York "
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1323')" href="javascript:;">
spaCy-3.2.3/spacy/tests/lang/tr/test_parser.py: 448-462
</a>
<div class="mid" id="frag1323" style="display:none"><pre>
def test_tr_noun_chunks_conj_subject(tr_tokenizer):
    text = "Sen ve ben iyi anlaşıyoruz"
    heads = [4, 2, 0, 2, 4]
    deps = ["nsubj", "cc", "conj", "adv", "ROOT"]
    pos = ["PRON", "CCONJ", "PRON", "ADV", "VERB"]
    tokens = tr_tokenizer(text)
    doc = Doc(
        tokens.vocab, words=[t.text for t in tokens], pos=pos, heads=heads, deps=deps
    )
    chunks = list(doc.noun_chunks)
    assert len(chunks) == 2
    assert chunks[0].text_with_ws == "ben "
    assert chunks[1].text_with_ws == "Sen "


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 14:</b> &nbsp; 10 fragments, nominal size 13 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1798')" href="javascript:;">
spaCy-3.2.3/spacy/lang/sv/lex_attrs.py: 44-58
</a>
<div class="mid" id="frag1798" style="display:none"><pre>
def like_num(text):
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text.lower() in _num_words:
        return True
    return False


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1801')" href="javascript:;">
spaCy-3.2.3/spacy/lang/sr/lex_attrs.py: 51-65
</a>
<div class="mid" id="frag1801" style="display:none"><pre>
def like_num(text):
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text.lower() in _num_words:
        return True
    return False


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1894')" href="javascript:;">
spaCy-3.2.3/spacy/lang/es/lex_attrs.py: 50-64
</a>
<div class="mid" id="frag1894" style="display:none"><pre>
def like_num(text):
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text.lower() in _num_words:
        return True
    return False


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1885')" href="javascript:;">
spaCy-3.2.3/spacy/lang/ru/lex_attrs.py: 51-65
</a>
<div class="mid" id="frag1885" style="display:none"><pre>
def like_num(text):
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text.lower() in _num_words:
        return True
    return False


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1830')" href="javascript:;">
spaCy-3.2.3/spacy/lang/hy/lex_attrs.py: 42-56
</a>
<div class="mid" id="frag1830" style="display:none"><pre>
def like_num(text):
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text.lower() in _num_words:
        return True
    return False


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1871')" href="javascript:;">
spaCy-3.2.3/spacy/lang/cs/lex_attrs.py: 46-60
</a>
<div class="mid" id="frag1871" style="display:none"><pre>
def like_num(text):
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text.lower() in _num_words:
        return True
    return False


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1803')" href="javascript:;">
spaCy-3.2.3/spacy/lang/bg/lex_attrs.py: 73-87
</a>
<div class="mid" id="frag1803" style="display:none"><pre>
def like_num(text):
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text.lower() in _num_words:
        return True
    return False


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1907')" href="javascript:;">
spaCy-3.2.3/spacy/lang/ne/lex_attrs.py: 80-94
</a>
<div class="mid" id="frag1907" style="display:none"><pre>
def like_num(text):
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(", ", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text.lower() in _num_words:
        return True
    return False


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1802')" href="javascript:;">
spaCy-3.2.3/spacy/lang/sk/lex_attrs.py: 44-58
</a>
<div class="mid" id="frag1802" style="display:none"><pre>
def like_num(text):
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text.lower() in _num_words:
        return True
    return False


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1873')" href="javascript:;">
spaCy-3.2.3/spacy/lang/vi/lex_attrs.py: 24-38
</a>
<div class="mid" id="frag1873" style="display:none"><pre>
def like_num(text):
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text.lower() in _num_words:
        return True
    return False


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 15:</b> &nbsp; 14 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1800')" href="javascript:;">
spaCy-3.2.3/spacy/lang/sv/__init__.py: 40-52
</a>
<div class="mid" id="frag1800" style="display:none"><pre>
def make_lemmatizer(
    nlp: Language,
    model: Optional[Model],
    name: str,
    mode: str,
    overwrite: bool,
    scorer: Optional[Callable],
):
    return Lemmatizer(
        nlp.vocab, model, name, mode=mode, overwrite=overwrite, scorer=scorer
    )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1895')" href="javascript:;">
spaCy-3.2.3/spacy/lang/es/__init__.py: 37-49
</a>
<div class="mid" id="frag1895" style="display:none"><pre>
def make_lemmatizer(
    nlp: Language,
    model: Optional[Model],
    name: str,
    mode: str,
    overwrite: bool,
    scorer: Optional[Callable],
):
    return SpanishLemmatizer(
        nlp.vocab, model, name, mode=mode, overwrite=overwrite, scorer=scorer
    )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1828')" href="javascript:;">
spaCy-3.2.3/spacy/lang/mk/__init__.py: 49-61
</a>
<div class="mid" id="frag1828" style="display:none"><pre>
def make_lemmatizer(
    nlp: Language,
    model: Optional[Model],
    name: str,
    mode: str,
    overwrite: bool,
    scorer: Optional[Callable],
):
    return MacedonianLemmatizer(
        nlp.vocab, model, name, mode=mode, overwrite=overwrite, scorer=scorer
    )


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1833')" href="javascript:;">
spaCy-3.2.3/spacy/lang/uk/__init__.py: 34-46
</a>
<div class="mid" id="frag1833" style="display:none"><pre>
def make_lemmatizer(
    nlp: Language,
    model: Optional[Model],
    name: str,
    mode: str,
    overwrite: bool,
    scorer: Optional[Callable],
):
    return UkrainianLemmatizer(
        nlp.vocab, model, name, mode=mode, overwrite=overwrite, scorer=scorer
    )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1864')" href="javascript:;">
spaCy-3.2.3/spacy/lang/ca/__init__.py: 40-52
</a>
<div class="mid" id="frag1864" style="display:none"><pre>
def make_lemmatizer(
    nlp: Language,
    model: Optional[Model],
    name: str,
    mode: str,
    overwrite: bool,
    scorer: Optional[Callable],
):
    return CatalanLemmatizer(
        nlp.vocab, model, name, mode=mode, overwrite=overwrite, scorer=scorer
    )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1891')" href="javascript:;">
spaCy-3.2.3/spacy/lang/fr/__init__.py: 42-54
</a>
<div class="mid" id="frag1891" style="display:none"><pre>
def make_lemmatizer(
    nlp: Language,
    model: Optional[Model],
    name: str,
    mode: str,
    overwrite: bool,
    scorer: Optional[Callable],
):
    return FrenchLemmatizer(
        nlp.vocab, model, name, mode=mode, overwrite=overwrite, scorer=scorer
    )


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1905')" href="javascript:;">
spaCy-3.2.3/spacy/lang/it/__init__.py: 34-46
</a>
<div class="mid" id="frag1905" style="display:none"><pre>
def make_lemmatizer(
    nlp: Language,
    model: Optional[Model],
    name: str,
    mode: str,
    overwrite: bool,
    scorer: Optional[Callable],
):
    return ItalianLemmatizer(
        nlp.vocab, model, name, mode=mode, overwrite=overwrite, scorer=scorer
    )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1816')" href="javascript:;">
spaCy-3.2.3/spacy/lang/nb/__init__.py: 37-49
</a>
<div class="mid" id="frag1816" style="display:none"><pre>
def make_lemmatizer(
    nlp: Language,
    model: Optional[Model],
    name: str,
    mode: str,
    overwrite: bool,
    scorer: Optional[Callable],
):
    return Lemmatizer(
        nlp.vocab, model, name, mode=mode, overwrite=overwrite, scorer=scorer
    )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1918')" href="javascript:;">
spaCy-3.2.3/spacy/lang/el/__init__.py: 39-51
</a>
<div class="mid" id="frag1918" style="display:none"><pre>
def make_lemmatizer(
    nlp: Language,
    model: Optional[Model],
    name: str,
    mode: str,
    overwrite: bool,
    scorer: Optional[Callable],
):
    return GreekLemmatizer(
        nlp.vocab, model, name, mode=mode, overwrite=overwrite, scorer=scorer
    )


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1822')" href="javascript:;">
spaCy-3.2.3/spacy/lang/nl/__init__.py: 41-53
</a>
<div class="mid" id="frag1822" style="display:none"><pre>
def make_lemmatizer(
    nlp: Language,
    model: Optional[Model],
    name: str,
    mode: str,
    overwrite: bool,
    scorer: Optional[Callable],
):
    return DutchLemmatizer(
        nlp.vocab, model, name, mode=mode, overwrite=overwrite, scorer=scorer
    )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1875')" href="javascript:;">
spaCy-3.2.3/spacy/lang/bn/__init__.py: 34-46
</a>
<div class="mid" id="frag1875" style="display:none"><pre>
def make_lemmatizer(
    nlp: Language,
    model: Optional[Model],
    name: str,
    mode: str,
    overwrite: bool,
    scorer: Optional[Callable],
):
    return Lemmatizer(
        nlp.vocab, model, name, mode=mode, overwrite=overwrite, scorer=scorer
    )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1886')" href="javascript:;">
spaCy-3.2.3/spacy/lang/ru/__init__.py: 33-45
</a>
<div class="mid" id="frag1886" style="display:none"><pre>
def make_lemmatizer(
    nlp: Language,
    model: Optional[Model],
    name: str,
    mode: str,
    overwrite: bool,
    scorer: Optional[Callable],
):
    return RussianLemmatizer(
        nlp.vocab, model, name, mode=mode, overwrite=overwrite, scorer=scorer
    )


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1924')" href="javascript:;">
spaCy-3.2.3/spacy/lang/en/__init__.py: 37-49
</a>
<div class="mid" id="frag1924" style="display:none"><pre>
def make_lemmatizer(
    nlp: Language,
    model: Optional[Model],
    name: str,
    mode: str,
    overwrite: bool,
    scorer: Optional[Callable],
):
    return EnglishLemmatizer(
        nlp.vocab, model, name, mode=mode, overwrite=overwrite, scorer=scorer
    )


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1877')" href="javascript:;">
spaCy-3.2.3/spacy/lang/fa/__init__.py: 37-49
</a>
<div class="mid" id="frag1877" style="display:none"><pre>
def make_lemmatizer(
    nlp: Language,
    model: Optional[Model],
    name: str,
    mode: str,
    overwrite: bool,
    scorer: Optional[Callable],
):
    return Lemmatizer(
        nlp.vocab, model, name, mode=mode, overwrite=overwrite, scorer=scorer
    )


</pre></div>
</td>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 16:</b> &nbsp; 7 fragments, nominal size 13 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1804')" href="javascript:;">
spaCy-3.2.3/spacy/lang/ky/lex_attrs.py: 33-47
</a>
<div class="mid" id="frag1804" style="display:none"><pre>
def like_num(text):
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text in _num_words:
        return True
    return False


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1835')" href="javascript:;">
spaCy-3.2.3/spacy/lang/tt/lex_attrs.py: 43-57
</a>
<div class="mid" id="frag1835" style="display:none"><pre>
def like_num(text):
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text in _num_words:
        return True
    return False


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1872')" href="javascript:;">
spaCy-3.2.3/spacy/lang/sa/lex_attrs.py: 109-126
</a>
<div class="mid" id="frag1872" style="display:none"><pre>
def like_num(text):
    """
    Check if text resembles a number
    """
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text in _num_words:
        return True
    return False


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1934')" href="javascript:;">
spaCy-3.2.3/spacy/lang/fi/lex_attrs.py: 41-55
</a>
<div class="mid" id="frag1934" style="display:none"><pre>
def like_num(text):
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(".", "").replace(",", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text in _num_words:
        return True
    return False


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1926')" href="javascript:;">
spaCy-3.2.3/spacy/lang/th/lex_attrs.py: 44-58
</a>
<div class="mid" id="frag1926" style="display:none"><pre>
def like_num(text):
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text in _num_words:
        return True
    return False


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1806')" href="javascript:;">
spaCy-3.2.3/spacy/lang/ml/lex_attrs.py: 59-76
</a>
<div class="mid" id="frag1806" style="display:none"><pre>
def like_num(text):
    """
    Check if text resembles a number
    """
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text in _num_words:
        return True
    return False


</pre></div>
</td>
</tr><tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1862')" href="javascript:;">
spaCy-3.2.3/spacy/lang/ca/lex_attrs.py: 44-58
</a>
<div class="mid" id="frag1862" style="display:none"><pre>
def like_num(text):
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text in _num_words:
        return True
    return False


</pre></div>
</td>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 17:</b> &nbsp; 4 fragments, nominal size 15 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1805')" href="javascript:;">
spaCy-3.2.3/spacy/lang/ar/lex_attrs.py: 77-96
</a>
<div class="mid" id="frag1805" style="display:none"><pre>
def like_num(text):
    """
    Check if text resembles a number
    """
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text in _num_words:
        return True
    if text in _ordinal_words:
        return True
    return False


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1897')" href="javascript:;">
spaCy-3.2.3/spacy/lang/ur/lex_attrs.py: 28-44
</a>
<div class="mid" id="frag1897" style="display:none"><pre>
def like_num(text):
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text in _num_words:
        return True
    if text in _ordinal_words:
        return True
    return False


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1834')" href="javascript:;">
spaCy-3.2.3/spacy/lang/eu/lex_attrs.py: 59-75
</a>
<div class="mid" id="frag1834" style="display:none"><pre>
def like_num(text):
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text in _num_words:
        return True
    if text in _ordinal_words:
        return True
    return False


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1933')" href="javascript:;">
spaCy-3.2.3/spacy/lang/he/lex_attrs.py: 74-94
</a>
<div class="mid" id="frag1933" style="display:none"><pre>
def like_num(text):
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True

    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True

    if text in _num_words:
        return True

    # Check ordinal number
    if text in _ordinal_words:
        return True
    return False


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 18:</b> &nbsp; 3 fragments, nominal size 24 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1809')" href="javascript:;">
spaCy-3.2.3/spacy/lang/id/syntax_iterators.py: 8-40
</a>
<div class="mid" id="frag1809" style="display:none"><pre>
def noun_chunks(doclike: Union[Doc, Span]) -&gt; Iterator[Tuple[int, int, int]]:
    """
    Detect base noun phrases from a dependency parse. Works on both Doc and Span.
    """
    # fmt: off
    labels = ["nsubj", "nsubj:pass", "obj", "iobj", "ROOT", "appos", "nmod", "nmod:poss"]
    # fmt: on
    doc = doclike.doc  # Ensure works on both Doc and Span.
    if not doc.has_annotation("DEP"):
        raise ValueError(Errors.E029)
    np_deps = [doc.vocab.strings[label] for label in labels]
    conj = doc.vocab.strings.add("conj")
    np_label = doc.vocab.strings.add("NP")
    prev_end = -1
    for i, word in enumerate(doclike):
        if word.pos not in (NOUN, PROPN, PRON):
            continue
        # Prevent nested chunks from being produced
        if word.left_edge.i &lt;= prev_end:
            continue
        if word.dep in np_deps:
            prev_end = word.right_edge.i
            yield word.left_edge.i, word.right_edge.i + 1, np_label
        elif word.dep == conj:
            head = word.head
            while head.dep == conj and head.head.i &lt; head.i:
                head = head.head
            # If the head is an NP, and we're coordinated to it, we're an NP
            if head.dep in np_deps:
                prev_end = word.right_edge.i
                yield word.left_edge.i, word.right_edge.i + 1, np_label


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1815')" href="javascript:;">
spaCy-3.2.3/spacy/lang/nb/syntax_iterators.py: 8-38
</a>
<div class="mid" id="frag1815" style="display:none"><pre>
def noun_chunks(doclike: Union[Doc, Span]) -&gt; Iterator[Tuple[int, int, int]]:
    """Detect base noun phrases from a dependency parse. Works on Doc and Span."""
    # fmt: off
    labels = ["nsubj", "nsubj:pass", "obj", "iobj", "ROOT", "appos", "nmod", "nmod:poss"]
    # fmt: on
    doc = doclike.doc  # Ensure works on both Doc and Span.
    if not doc.has_annotation("DEP"):
        raise ValueError(Errors.E029)
    np_deps = [doc.vocab.strings[label] for label in labels]
    conj = doc.vocab.strings.add("conj")
    np_label = doc.vocab.strings.add("NP")
    prev_end = -1
    for i, word in enumerate(doclike):
        if word.pos not in (NOUN, PROPN, PRON):
            continue
        # Prevent nested chunks from being produced
        if word.left_edge.i &lt;= prev_end:
            continue
        if word.dep in np_deps:
            prev_end = word.right_edge.i
            yield word.left_edge.i, word.right_edge.i + 1, np_label
        elif word.dep == conj:
            head = word.head
            while head.dep == conj and head.head.i &lt; head.i:
                head = head.head
            # If the head is an NP, and we're coordinated to it, we're an NP
            if head.dep in np_deps:
                prev_end = word.right_edge.i
                yield word.left_edge.i, word.right_edge.i + 1, np_label


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1890')" href="javascript:;">
spaCy-3.2.3/spacy/lang/fr/syntax_iterators.py: 8-38
</a>
<div class="mid" id="frag1890" style="display:none"><pre>
def noun_chunks(doclike: Union[Doc, Span]) -&gt; Iterator[Tuple[int, int, int]]:
    """Detect base noun phrases from a dependency parse. Works on Doc and Span."""
    # fmt: off
    labels = ["nsubj", "nsubj:pass", "obj", "iobj", "ROOT", "appos", "nmod", "nmod:poss"]
    # fmt: on
    doc = doclike.doc  # Ensure works on both Doc and Span.
    if not doc.has_annotation("DEP"):
        raise ValueError(Errors.E029)
    np_deps = [doc.vocab.strings[label] for label in labels]
    conj = doc.vocab.strings.add("conj")
    np_label = doc.vocab.strings.add("NP")
    prev_end = -1
    for i, word in enumerate(doclike):
        if word.pos not in (NOUN, PROPN, PRON):
            continue
        # Prevent nested chunks from being produced
        if word.left_edge.i &lt;= prev_end:
            continue
        if word.dep in np_deps:
            prev_end = word.right_edge.i
            yield word.left_edge.i, word.right_edge.i + 1, np_label
        elif word.dep == conj:
            head = word.head
            while head.dep == conj and head.head.i &lt; head.i:
                head = head.head
            # If the head is an NP, and we're coordinated to it, we're an NP
            if head.dep in np_deps:
                prev_end = word.right_edge.i
                yield word.left_edge.i, word.right_edge.i + 1, np_label


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 19:</b> &nbsp; 3 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1811')" href="javascript:;">
spaCy-3.2.3/spacy/lang/si/lex_attrs.py: 48-60
</a>
<div class="mid" id="frag1811" style="display:none"><pre>
def like_num(text):
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text.lower() in _num_words:
        return True
    return False


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1870')" href="javascript:;">
spaCy-3.2.3/spacy/lang/pl/lex_attrs.py: 53-65
</a>
<div class="mid" id="frag1870" style="display:none"><pre>
def like_num(text):
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text.lower() in _num_words:
        return True
    return False


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1925')" href="javascript:;">
spaCy-3.2.3/spacy/lang/te/lex_attrs.py: 41-53
</a>
<div class="mid" id="frag1925" style="display:none"><pre>
def like_num(text):
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text.lower() in _num_words:
        return True
    return False


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 20:</b> &nbsp; 3 fragments, nominal size 19 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1814')" href="javascript:;">
spaCy-3.2.3/spacy/lang/tn/lex_attrs.py: 82-106
</a>
<div class="mid" id="frag1814" style="display:none"><pre>
def like_num(text):
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True

    text_lower = text.lower()
    if text_lower in _num_words:
        return True

    # CHeck ordinal number
    if text_lower in _ordinal_words:
        return True
    if text_lower.endswith("th"):
        if text_lower[:-2].isdigit():
            return True

    return False


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1892')" href="javascript:;">
spaCy-3.2.3/spacy/lang/ti/lex_attrs.py: 48-72
</a>
<div class="mid" id="frag1892" style="display:none"><pre>
def like_num(text):
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True

    text_lower = text.lower()
    if text_lower in _num_words:
        return True

    # Check ordinal number
    if text_lower in _ordinal_words:
        return True
    if text_lower.endswith("ይ"):
        if text_lower[:-2].isdigit():
            return True

    return False


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1893')" href="javascript:;">
spaCy-3.2.3/spacy/lang/am/lex_attrs.py: 77-101
</a>
<div class="mid" id="frag1893" style="display:none"><pre>
def like_num(text):
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True

    text_lower = text.lower()
    if text_lower in _num_words:
        return True

    # Check ordinal number
    if text_lower in _ordinal_words:
        return True
    if text_lower.endswith("ኛ"):
        if text_lower[:-2].isdigit():
            return True

    return False


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 21:</b> &nbsp; 2 fragments, nominal size 11 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1832')" href="javascript:;">
spaCy-3.2.3/spacy/lang/uk/lex_attrs.py: 57-69
</a>
<div class="mid" id="frag1832" style="display:none"><pre>
def like_num(text):
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text in _num_words:
        return True
    return False


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1919')" href="javascript:;">
spaCy-3.2.3/spacy/lang/tl/lex_attrs.py: 44-56
</a>
<div class="mid" id="frag1919" style="display:none"><pre>
def like_num(text):
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text in _num_words:
        return True
    return False


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 22:</b> &nbsp; 3 fragments, nominal size 15 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1858')" href="javascript:;">
spaCy-3.2.3/spacy/lang/ro/lex_attrs.py: 26-42
</a>
<div class="mid" id="frag1858" style="display:none"><pre>
def like_num(text):
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text.lower() in _num_words:
        return True
    if text.lower() in _ordinal_words:
        return True
    return False


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1889')" href="javascript:;">
spaCy-3.2.3/spacy/lang/fr/lex_attrs.py: 25-43
</a>
<div class="mid" id="frag1889" style="display:none"><pre>
def like_num(text):
    # Might require more work?
    # See this discussion: https://github.com/explosion/spaCy/pull/1161
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text.lower() in _num_words:
        return True
    if text.lower() in _ordinal_words:
        return True
    return False


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1879')" href="javascript:;">
spaCy-3.2.3/spacy/lang/da/lex_attrs.py: 34-50
</a>
<div class="mid" id="frag1879" style="display:none"><pre>
def like_num(text):
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    if text.lower() in _num_words:
        return True
    if text.lower() in _ordinal_words:
        return True
    return False


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 23:</b> &nbsp; 2 fragments, nominal size 56 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1861')" href="javascript:;">
spaCy-3.2.3/spacy/lang/ca/lemmatizer.py: 26-81
</a>
<div class="mid" id="frag1861" style="display:none"><pre>
    def rule_lemmatize(self, token: Token) -&gt; List[str]:
        cache_key = (token.orth, token.pos)
        if cache_key in self.cache:
            return self.cache[cache_key]
        string = token.text
        univ_pos = token.pos_.lower()
        if univ_pos in ("", "eol", "space"):
            return [string.lower()]
        elif "lemma_rules" not in self.lookups or univ_pos not in (
            "noun",
            "verb",
            "adj",
            "adp",
            "adv",
            "aux",
            "cconj",
            "det",
            "pron",
            "punct",
            "sconj",
        ):
            return self.lookup_lemmatize(token)
        index_table = self.lookups.get_table("lemma_index", {})
        exc_table = self.lookups.get_table("lemma_exc", {})
        rules_table = self.lookups.get_table("lemma_rules", {})
        lookup_table = self.lookups.get_table("lemma_lookup", {})
        index = index_table.get(univ_pos, {})
        exceptions = exc_table.get(univ_pos, {})
        rules = rules_table.get(univ_pos, [])
        string = string.lower()
        forms = []
        if string in index:
            forms.append(string)
            self.cache[cache_key] = forms
            return forms
        forms.extend(exceptions.get(string, []))
        oov_forms = []
        if not forms:
            for old, new in rules:
                if string.endswith(old):
                    form = string[: len(string) - len(old)] + new
                    if not form:
                        pass
                    elif form in index or not form.isalpha():
                        forms.append(form)
                    else:
                        oov_forms.append(form)
        if not forms:
            forms.extend(oov_forms)
        if not forms and string in lookup_table.keys():
            forms.append(self.lookup_lemmatize(token)[0])
        if not forms:
            forms.append(string)
        forms = list(dict.fromkeys(forms))
        self.cache[cache_key] = forms
        return forms
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1888')" href="javascript:;">
spaCy-3.2.3/spacy/lang/fr/lemmatizer.py: 25-80
</a>
<div class="mid" id="frag1888" style="display:none"><pre>
    def rule_lemmatize(self, token: Token) -&gt; List[str]:
        cache_key = (token.orth, token.pos)
        if cache_key in self.cache:
            return self.cache[cache_key]
        string = token.text
        univ_pos = token.pos_.lower()
        if univ_pos in ("", "eol", "space"):
            return [string.lower()]
        elif "lemma_rules" not in self.lookups or univ_pos not in (
            "noun",
            "verb",
            "adj",
            "adp",
            "adv",
            "aux",
            "cconj",
            "det",
            "pron",
            "punct",
            "sconj",
        ):
            return self.lookup_lemmatize(token)
        index_table = self.lookups.get_table("lemma_index", {})
        exc_table = self.lookups.get_table("lemma_exc", {})
        rules_table = self.lookups.get_table("lemma_rules", {})
        lookup_table = self.lookups.get_table("lemma_lookup", {})
        index = index_table.get(univ_pos, {})
        exceptions = exc_table.get(univ_pos, {})
        rules = rules_table.get(univ_pos, [])
        string = string.lower()
        forms = []
        if string in index:
            forms.append(string)
            self.cache[cache_key] = forms
            return forms
        forms.extend(exceptions.get(string, []))
        oov_forms = []
        if not forms:
            for old, new in rules:
                if string.endswith(old):
                    form = string[: len(string) - len(old)] + new
                    if not form:
                        pass
                    elif form in index or not form.isalpha():
                        forms.append(form)
                    else:
                        oov_forms.append(form)
        if not forms:
            forms.extend(oov_forms)
        if not forms and string in lookup_table.keys():
            forms.append(self.lookup_lemmatize(token)[0])
        if not forms:
            forms.append(string)
        forms = list(dict.fromkeys(forms))
        self.cache[cache_key] = forms
        return forms
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 24:</b> &nbsp; 2 fragments, nominal size 10 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1869')" href="javascript:;">
spaCy-3.2.3/spacy/lang/pl/lemmatizer.py: 75-86
</a>
<div class="mid" id="frag1869" style="display:none"><pre>
    def lemmatize_noun(
        self, string: str, morphology: dict, lookup_table: Dict[str, str]
    ) -&gt; List[str]:
        # this method is case-sensitive, in order to work
        # for incorrectly tagged proper names
        if string != string.lower():
            if string.lower() in lookup_table:
                return [lookup_table[string.lower()]]
            elif string in lookup_table:
                return [lookup_table[string]]
            return [string.lower()]
        return [lookup_table.get(string, string)]
</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1904')" href="javascript:;">
spaCy-3.2.3/spacy/lang/it/lemmatizer.py: 121-132
</a>
<div class="mid" id="frag1904" style="display:none"><pre>
    def lemmatize_noun(
        self, string: str, morphology: dict, lookup_table: Dict[str, str]
    ) -&gt; List[str]:
        # this method is case-sensitive, in order to work
        # for incorrectly tagged proper names
        if string != string.lower():
            if string.lower() in lookup_table:
                return [lookup_table[string.lower()]]
            elif string in lookup_table:
                return [lookup_table[string]]
            return [string.lower()]
        return [lookup_table.get(string, string)]
</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<br>
<table style="width:1000px; border:2px solid lightgrey; border-radius:8px;">
<tr><td style="background-color:white">
<p style="font-size:14pt"><b>Class 25:</b> &nbsp; 2 fragments, nominal size 19 lines, similarity 100%</p>
<table cellpadding=4 border=2>
<tr>
<td width="auto">
<a onclick="javascript:ShowHide('frag1896')" href="javascript:;">
spaCy-3.2.3/spacy/lang/az/lex_attrs.py: 66-88
</a>
<div class="mid" id="frag1896" style="display:none"><pre>
def like_num(text):
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    text_lower = text.lower()
    # Check cardinal number
    if text_lower in _num_words:
        return True
    # Check ordinal number
    if text_lower in _ordinal_words:
        return True
    if text_lower.endswith(_ordinal_endings):
        if text_lower[:-3].isdigit() or text_lower[:-4].isdigit():
            return True
    return False


</pre></div>
</td>
<td width="auto">
<a onclick="javascript:ShowHide('frag1910')" href="javascript:;">
spaCy-3.2.3/spacy/lang/tr/lex_attrs.py: 66-88
</a>
<div class="mid" id="frag1910" style="display:none"><pre>
def like_num(text):
    if text.startswith(("+", "-", "±", "~")):
        text = text[1:]
    text = text.replace(",", "").replace(".", "")
    if text.isdigit():
        return True
    if text.count("/") == 1:
        num, denom = text.split("/")
        if num.isdigit() and denom.isdigit():
            return True
    text_lower = text.lower()
    # Check cardinal number
    if text_lower in _num_words:
        return True
    # Check ordinal number
    if text_lower in _ordinal_words:
        return True
    if text_lower.endswith(_ordinal_endings):
        if text_lower[:-3].isdigit() or text_lower[:-4].isdigit():
            return True
    return False


</pre></div>
</td>
</tr><tr>
</tr>
</table>
</td></tr>
</table>
<script language="JavaScript">
function ShowHide(divId) { 
    if(document.getElementById(divId).style.display == 'none') {
        document.getElementById(divId).style.display='block';
    } else { 
        document.getElementById(divId).style.display = 'none';
    } 
}
</script>
</body>
</html>
